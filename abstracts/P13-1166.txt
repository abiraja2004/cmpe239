
Repeating experiments is an important in-
strument in the scientific toolbox to vali-
date previous work and build upon exist-
ing work. We present two concrete use
cases involving key techniques in the NLP
domain for which we show that reproduc-
ing results is still difficult. We show that
the deviation that can be found in repro-
duction efforts leads to questions about
how our results should be interpreted.
Moreover, investigating these deviations
provides new insights and a deeper under-
standing of the examined techniques. We
identify five aspects that can influence the
outcomes of experiments that are typically
not addressed in research papers. Our use
cases show that these aspects may change
the answer to research questions leading
us to conclude that more care should be
taken in interpreting our results and more
research involving systematic testing of
methods is required in our field.
1 