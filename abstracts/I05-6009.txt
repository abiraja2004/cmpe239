 
In this paper, we discuss how error 
annotation for learner corpora should 
be done by explaining the state of the 
art of error tagging schemes in learner 
corpus research. Several learner 
corpora, including the NICT JLE 
(Japanese Learner English) Corpus that 
we have compiled are annotated with 
error tagsets designed by categorizing 
?likely? errors implied from the 
existing canonical grammar rules or 
POS (part-of-speech) system in 
advance. Such error tagging can help to 
successfully assess to what extent 
learners can command the basic 
language system, especially grammar, 
but is insufficient for describing 
learners? communicative competence. 
To overcome this limitation, we re-
examined learner language in the NICT 
JLE Corpus by focusing on 
?intelligibility? and ?naturalness?, and 
determined how the current error tagset 
should be revised. 
1 