
We outline different methods to detect er-
rors in automatically-parsed dependency
corpora, by comparing so-called depen-
dency rules to their representation in the
training data and flagging anomalous ones.
By comparing each new rule to every rel-
evant rule from training, we can identify
parts of parse trees which are likely erro-
neous. Even the relatively simple methods
of comparison we propose show promise
for speeding up the annotation process.
1 