
Many classification problems require decisions
among a large number of competing classes. These
tasks, however, are not handled well by general pur-
pose learning methods and are usually addressed in
an ad-hoc fashion. We suggest a general approach
? a sequential learning model that utilizes classi-
fiers to sequentially restrict the number of compet-
ing classes while maintaining, with high probability,
the presence of the true outcome in the candidates
set. Some theoretical and computational properties
of the model are discussed and we argue that these
are important in NLP-like domains. The advantages
of the model are illustrated in an experiment in part-
of-speech tagging.
1 