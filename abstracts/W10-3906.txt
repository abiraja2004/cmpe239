
This paper presents a new computation
of lexical distributional similarity, which
is a corpus-based method for computing
similarity of any two words. Although
the conventional method focuses on em-
phasizing features with which a given
word is associated, we propose that even
unassociated features of two input words
can further improve the performance in
total. We also report in addition that
more than 90% of the features has no
contribution and thus could be reduced
in future.
1 