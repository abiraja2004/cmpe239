
We show that categories induced by unsuper-
vised word clustering can surpass the perfor-
mance of gold part-of-speech tags in depen-
dency grammar induction. Unlike classic clus-
tering algorithms, our method allows a word
to have different tags in different contexts.
In an ablative analysis, we first demonstrate
that this context-dependence is crucial to the
superior performance of gold tags ? requir-
ing a word to always have the same part-of-
speech significantly degrades the performance
of manual tags in grammar induction, elim-
inating the advantage that human annotation
has over unsupervised tags. We then introduce
a sequence modeling technique that combines
the output of a word clustering algorithm with
context-colored noise, to allow words to be
tagged differently in different contexts. With
these new induced tags as input, our state-of-
the-art dependency grammar inducer achieves
59.1% directed accuracy on Section 23 (all
sentences) of the Wall Street Journal (WSJ)
corpus ? 0.7% higher than using gold tags.
1 