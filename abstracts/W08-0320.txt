
We describe the experiments of the UC Berke-
ley team on improving English-Spanish ma-
chine translation of news text, as part of the
WMT?08 Shared Translation Task. We ex-
periment with domain adaptation, combin-
ing a small in-domain news bi-text and a
large out-of-domain one from the Europarl
corpus, building two separate phrase transla-
tion models and two separate language mod-
els. We further add a third phrase transla-
tion model trained on a version of the news
bi-text augmented with monolingual sentence-
level syntactic paraphrases on the source-
language side, and we combine all models in
a log-linear model using minimum error rate
training. Finally, we experiment with differ-
ent tokenization and recasing rules, achieving
35.09% Bleu score on the WMT?07 news test
data when translating from English to Span-
ish, which is a sizable improvement over the
highest Bleu score achieved on that dataset
at WMT?07: 33.10% (in fact, by our sys-
tem). On the WMT?08 English to Spanish
news translation, we achieve 21.92%, which
makes our team the second best on Bleu score.
1 