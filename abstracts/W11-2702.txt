
Recent years have seen a trend towards em-
pirically motivated and more data-driven ap-
proaches in the field of referring expression
generation (REG). Much of this work has fo-
cussed on initial reference to objects in visual
scenes. While this scenario of use is one of
the strongest contenders for real-world appli-
cations of referring expression generation, ex-
isting data sets still only embody very sim-
ple stimulus scenes. To move this research
forward, we require data sets built around in-
creasingly complex scenes, and we need much
larger data sets to accommodate their higher
dimensionality. To control the complexity,
we also need to adopt a hypothesis-driven ap-
proach to scene design. In this paper, we de-
scribe GRE3D7, the largest corpus of human-
produced distinguishing descriptions available
to date, discuss the hypotheses that underlie its
design, and offer a number of analyses of the
4480 descriptions it contains.
1 