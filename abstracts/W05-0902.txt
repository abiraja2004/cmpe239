
We address the issue of human subjec-
tivity when authoring summaries, aiming
at a simple, robust evaluation of machine
generated summaries. Applying a cross
comprehension test on human authored
short summaries from broadcast news, the
level of subjectivity is gauged among four
authors. The instruction set is simple,
thus there is enough room for subjectiv-
ity. However the approach is robust be-
cause the test does not use the absolute
score, relying instead on relative compar-
ison, effectively alleviating the subjectiv-
ity. Finally we illustrate the application of
the above scheme when evaluating the in-
formativeness of machine generated sum-
maries.
1 