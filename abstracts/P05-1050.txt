
In this paper we present a supervised
Word Sense Disambiguation methodol-
ogy, that exploits kernel methods to model
sense distinctions. In particular a combi-
nation of kernel functions is adopted to
estimate independently both syntagmatic
and domain similarity. We defined a ker-
nel function, namely the Domain Kernel,
that allowed us to plug ?external knowl-
edge? into the supervised learning pro-
cess. External knowledge is acquired from
unlabeled data in a totally unsupervised
way, and it is represented by means of Do-
main Models. We evaluated our method-
ology on several lexical sample tasks in
different languages, outperforming sig-
nificantly the state-of-the-art for each of
them, while reducing the amount of la-
beled training data required for learning.
1 