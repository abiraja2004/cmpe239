
Human evaluations of machine translation
are extensive but expensive. Human eval-
uations can take months to finish and in-
volve human labor that can not be reused.
We propose a method of automatic ma-
chine translation evaluation that is quick,
inexpensive, and language-independent,
that correlates highly with human evalu-
ation, and that has little marginal cost per
run. We present this method as an auto-
mated understudy to skilled human judges
which substitutes for them when there is
need for quick or frequent evaluations.1
1 