
We are interested in the task of image an-
notation using noisy natural text as training
data. An image and its caption convey dif-
ferent information, but are generated by the
same underlying concepts. In this paper, we
learn latent mixtures of topics that generate
image and product descriptions on shopping
websites by adapting a topic model for multi-
lingual data (Mimno et al, 2009). We use the
trained model to annotate test images without
corresponding text. We capture visual prop-
erties such as color, texture, shape, and ori-
entation by computing low-level image fea-
tures, and measure the contribution of each
type of visual feature towards the accuracy of
the model. Our model significantly outper-
forms both a competitive baseline and a pre-
vious topic model-based system.
1 