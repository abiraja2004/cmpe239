 
We have constructed a corpus of news ar-
ticles in which events are annotated for 
estimated bounds on their duration. Here 
we describe a method for measuring in-
ter-annotator agreement for these event 
duration distributions. We then show that 
machine learning techniques applied to 
this data yield coarse-grained event dura-
tion information, considerably outper-
forming a baseline and approaching hu-
man performance. 
1 