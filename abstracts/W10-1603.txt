
Variable-Length Markov Chains (VLMCs) of-
fer a way of modeling contexts longer than
trigrams without suffering from data sparsity
and state space complexity. However, in His-
torical Portuguese, two words show a high de-
gree of ambiguity: que and a. The number
of errors tagging these words corresponds to a
quarter of the total errors made by a VLMC-
based tagger. Moreover, these words seem to
show two different types of ambiguity: one
depending on non-local context and another
on right context. We searched ways of ex-
panding the VLMC-based tagger with a num-
ber of different models and methods in order
to tackle these issues. The methods showed
variable degrees of success, with one particu-
lar method solving much of the ambiguity of
a. We explore reasons why this happened, and
how everything we tried fails to improve the
precision of que.
1 