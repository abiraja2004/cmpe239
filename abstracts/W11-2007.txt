 
Human dialogue serves as a valuable model for learning the behavior of dialogue systems. Hidden Markov models? sequential structure is well suited to modeling human dialogue, and their theoretical underpinnings are consistent with the conception of dialogue as a stochastic process with a layer of implicit, highly influen-tial structure. HMMs have been shown to be effective for a variety of descriptive and pre-dictive dialogue tasks. For task-oriented dia-logue, understanding the learning behavior of HMMs is an important step toward building unsupervised models of human dialogue. This paper examines the behavior of HMMs under six experimental conditions including different task-oriented feature sets and preprocessing approaches. The findings highlight the im-portance of providing HMM learning algo-rithms with rich task-based information. Additionally, the results suggest how specific metrics should be used depending on whether the models will be employed primarily in a de-scriptive or predictive manner.  1 