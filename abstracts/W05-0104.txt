
In the fall term of 2004, I taught a
new statistical NLP course focusing
on core tools and machine-learning al-
gorithms. The course work was or-
ganized around four substantial pro-
gramming assignments in which the
students implemented the important
parts of several core tools, including
language models (for speech rerank-
ing), a maximum entropy classifier, a
part-of-speech tagger, a PCFG parser,
and a word-alignment system. Using
provided scaffolding, students built re-
alistic tools with nearly state-of-the-
art performance in most cases. This
paper briefly outlines the coverage of
the course, the scope of the assign-
ments, and some of the lessons learned
in teaching the course in this way.
1 