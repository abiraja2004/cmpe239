
This paper proposes a novel smoothing
model with a combinatorial optimization
scheme for all-words word sense disam-
biguation from untagged corpora. By gen-
eralizing discrete senses to a continuum,
we introduce a smoothing in context-sense
space to cope with data-sparsity result-
ing from a large variety of linguistic con-
text and sense, as well as to exploit sense-
interdependency among the words in the
same text string. Through the smoothing,
all the optimal senses are obtained at one
time under maximum marginal likelihood
criterion, by competitive probabilistic ker-
nels made to reinforce one another among
nearby words, and to suppress conflicting
sense hypotheses within the same word.
Experimental results confirmed the superi-
ority of the proposed method over conven-
tional ones by showing the better perfor-
mances beyond most-frequent-sense base-
line performance where none of SemEval-
2 unsupervised systems reached.
1 