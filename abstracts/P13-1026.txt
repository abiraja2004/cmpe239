
Recently, researchers have begun explor-
ing methods of scoring student essays with
respect to particular dimensions of qual-
ity such as coherence, technical errors,
and relevance to prompt, but there is rel-
atively little work on modeling thesis clar-
ity. We present a new annotated corpus
and propose a learning-based approach to
scoring essays along the thesis clarity di-
mension. Additionally, in order to pro-
vide more valuable feedback on why an
essay is scored as it is, we propose a sec-
ond learning-based approach to identify-
ing what kinds of errors an essay has that
may lower its thesis clarity score.
1 