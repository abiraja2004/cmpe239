
A large number of Open Relation Extrac-
tion approaches have been proposed recently,
covering a wide range of NLP machinery,
from ?shallow? (e.g., part-of-speech tagging)
to ?deep? (e.g., semantic role labeling?SRL).
A natural question then is what is the trade-
off between NLP depth (and associated com-
putational cost) versus effectiveness. This pa-
per presents a fair and objective experimental
comparison of 8 state-of-the-art approaches
over 5 different datasets, and sheds some light
on the issue. The paper also describes a novel
method, EXEMPLAR, which adapts ideas from
SRL to less costly NLP machinery, resulting
in substantial gains both in efficiency and ef-
fectiveness, over binary and n-ary relation ex-
traction tasks.
1 