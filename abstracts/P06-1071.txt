 
Recent developments in statistical modeling 
of various linguistic phenomena have shown 
that additional features give consistent per-
formance improvements. Quite often, im-
provements are limited by the number of fea-
tures a system is able to explore. This paper 
describes a novel progressive training algo-
rithm that selects features from virtually 
unlimited feature spaces for conditional 
maximum entropy (CME) modeling. Experi-
mental results in edit region identification 
demonstrate the benefits of the progressive 
feature selection (PFS) algorithm: the PFS 
algorithm maintains the same accuracy per-
formance as previous CME feature selection 
algorithms (e.g., Zhou et al, 2003) when the 
same feature spaces are used. When addi-
tional features and their combinations are 
used, the PFS gives 17.66% relative im-
provement over the previously reported best 
result in edit region identification on 
Switchboard corpus (Kahn et al, 2005), 
which leads to a 20% relative error reduction 
in parsing the Switchboard corpus when gold 
edits are used as the upper bound. 
1 