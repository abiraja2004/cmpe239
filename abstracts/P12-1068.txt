
We argue that multilingual parallel data pro-
vides a valuable source of indirect supervision
for induction of shallow semantic representa-
tions. Specifically, we consider unsupervised
induction of semantic roles from sentences an-
notated with automatically-predicted syntactic
dependency representations and use a state-
of-the-art generative Bayesian non-parametric
model. At inference time, instead of only
seeking the model which explains the mono-
lingual data available for each language, we
regularize the objective by introducing a soft
constraint penalizing for disagreement in ar-
gument labeling on aligned sentences. We
propose a simple approximate learning algo-
rithm for our set-up which results in efficient
inference. When applied to German-English
parallel data, our method obtains a substantial
improvement over a model trained without us-
ing the agreement signal, when both are tested
on non-parallel sentences.
1 