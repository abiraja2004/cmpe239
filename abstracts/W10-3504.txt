
In this paper we propose a novel method
to automatically extract large textual en-
tailment datasets homogeneous to existing
ones. The key idea is the combination of
two intuitions: (1) the use of Wikipedia
to extract a large set of textual entail-
ment pairs; (2) the application of semi-
supervised machine learning methods to
make the extracted dataset homogeneous
to the existing ones. We report empirical
evidence that our method successfully ex-
pands existing textual entailment corpora.
1 