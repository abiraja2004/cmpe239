
The IBM translation models have been hugely
influential in statistical machine translation;
they are the basis of the alignment models
used in modern translation systems. Exclud-
ing IBM Model 1, the IBM translation mod-
els, and practically all variants proposed in the
literature, have relied on the optimization of
likelihood functions or similar functions that
are non-convex, and hence have multiple lo-
cal optima. In this paper we introduce a con-
vex relaxation of IBM Model 2, and describe
an optimization algorithm for the relaxation
based on a subgradient method combined
with exponentiated-gradient updates. Our ap-
proach gives the same level of alignment ac-
curacy as IBM Model 2.
1 