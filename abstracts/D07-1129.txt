
Following (Blitzer et al, 2006), we present
an application of structural correspondence
learning to non-projective dependency pars-
ing (McDonald et al, 2005). To induce the
correspondences among dependency edges
from different domains, we looked at ev-
ery two tokens in a sentence and examined
whether or not there is a preposition, a de-
terminer or a helping verb between them.
Three binary linear classifiers were trained
to predict the existence of a preposition,
etc, on unlabeled data and we used singu-
lar value decomposition to induce new fea-
tures. During the training, the parser was
trained with these additional features in ad-
dition to these described in (McDonald et
al., 2005). We discriminatively trained our
parser in an on-line fashion using a vari-
ant of the voted perceptron (Collins, 2002;
Collins and Roark, 2004; Crammer and
Singer, 2003).
1 