
Open-ended spoken interactions are typi-
cally characterised by both structural com-
plexity and high levels of uncertainty,
making dialogue management in such set-
tings a particularly challenging problem.
Traditional approaches have focused on
providing theoretical accounts for either
the uncertainty or the complexity of spo-
ken dialogue, but rarely considered the
two issues simultaneously. This paper de-
scribes ongoing work on a new approach
to dialogue management which attempts
to fill this gap. We represent the interac-
tion as a Partially Observable Markov De-
cision Process (POMDP) over a rich state
space incorporating both dialogue, user,
and environment models. The tractability
of the resulting POMDP can be preserved
using a mechanism for dynamically con-
straining the action space based on prior
knowledge over locally relevant dialogue
structures. These constraints are encoded
in a small set of general rules expressed as
a Markov Logic network. The first-order
expressivity of Markov Logic enables us
to leverage the rich relational structure of
the problem and efficiently abstract over
large regions of the state and action spaces.
1 