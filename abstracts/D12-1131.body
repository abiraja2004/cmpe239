
State-of-the-art statistical parsers and POS
taggers perform very well when trained with
large amounts of in-domain data. When train-
ing data is out-of-domain or limited, accuracy
degrades. In this paper, we aim to compen-
sate for the lack of available training data by
exploiting similarities between test set sen-
tences. We show how to augment sentence-
level models for parsing and POS tagging with
inter-sentence consistency constraints. To deal
with the resulting global objective, we present
an efficient and exact dual decomposition de-
coding algorithm. In experiments, we add
consistency constraints to the MST parser
and the Stanford part-of-speech tagger and
demonstrate significant error reduction in the
domain adaptation and the lightly supervised
settings across five languages.
1 