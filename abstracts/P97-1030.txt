 
This paper proposes a mistake-driven mix- 
ture method for learning a tag model. The 
method iteratively performs two proce- 
dures: 1. constructing a tag model based 
on the current data distribution and 2. 
updating the distribution by focusing on 
data that are not well predicted by the 
constructed model. The final tag model 
is constructed by mixing all the models 
according to their performance. To well 
reflect the data distribution, we repre- 
sent each tag model as a hierarchical tag 
(i.e.,NTT 1 < proper noun < noun) con- 
text tree. By using the hierarchical tag 
context ree, the constituents ofsequential 
tag models gradually change from broad 
coverage tags (e.g.,noun) to specific excep- 
tional words that cannot be captured by 
generM tags. In other words, the method 
incorporates not only frequent connec- 
tions but also infrequent ones that are of- 
ten considered to be collocationah We 
evaluate several tag models by implement- 
ing Japanese part-of-speech taggers that 
share all other conditions (i.e.,dictionary 
and word model) other than their tag 
models. The experimental results show 
the proposed method significantly outper- 
forms both hand-crafted and conventional 
statistical methods. 
1 