
We present a probabilistic parsing model
for German trained on the Negra tree-
bank. We observe that existing lexicalized
parsing models using head-head depen-
dencies, while successful for English, fail
to outperform an unlexicalized baseline
model for German. Learning curves show
that this effect is not due to lack of training
data. We propose an alternative model that
uses sister-head dependencies instead of
head-head dependencies. This model out-
performs the baseline, achieving a labeled
precision and recall of up to 74%. This in-
dicates that sister-head dependencies are
more appropriate for treebanks with very
flat structures such as Negra.
1 