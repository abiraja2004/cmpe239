
One of the main obstacles to produc-
ing high quality joint models is the lack
of jointly annotated data. Joint model-
ing of multiple natural language process-
ing tasks outperforms single-task models
learned from the same data, but still under-
performs compared to single-task models
learned on the more abundant quantities
of available single-task annotated data. In
this paper we present a novel model which
makes use of additional single-task anno-
tated data to improve the performance of
a joint model. Our model utilizes a hier-
archical prior to link the feature weights
for shared features in several single-task
models and the joint model. Experiments
on joint parsing and named entity recog-
nition, using the OntoNotes corpus, show
that our hierarchical joint model can pro-
duce substantial gains over a joint model
trained on only the jointly annotated data.
1 