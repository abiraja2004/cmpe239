
Previous research on domain adaptation (DA)
for statistical machine translation (SMT) has
mainly focused on the translation model (TM)
and the language model (LM). To the best of
our knowledge, there is no previous work on
reordering model (RM) adaptation for phrase-
based SMT. In this paper, we demonstrate
that mixture model adaptation of a lexical-
ized RM can significantly improve SMT per-
formance, even when the system already con-
tains a domain-adapted TM and LM. We find
that, surprisingly, different training corpora
can vary widely in their reordering character-
istics for particular phrase pairs. Furthermore,
particular training corpora may be highly suit-
able for training the TM or the LM, but unsuit-
able for training the RM, or vice versa, so mix-
ture weights for these models should be esti-
mated separately. An additional contribution
of the paper is to propose two improvements
to mixture model adaptation: smoothing the
in-domain sample, and weighting instances
by document frequency. Applied to mixture
RMs in our experiments, these techniques (es-
pecially smoothing) yield significant perfor-
mance improvements.
1 