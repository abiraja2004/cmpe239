
We present a syntactically enriched vec-
tor model that supports the computation
of contextualized semantic representations
in a quasi compositional fashion. It em-
ploys a systematic combination of first- and
second-order context vectors. We apply
our model to two different tasks and show
that (i) it substantially outperforms previ-
ous work on a paraphrase ranking task, and
(ii) achieves promising results on a word-
sense similarity task; to our knowledge, it is
the first time that an unsupervised method
has been applied to this task.
1 