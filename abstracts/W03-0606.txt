
The objective of this research is to develop a system for
miniature language learning based on a minimum of pre-
wired language-specific functionality, that is compatible
with observations of perceptual and language capabilities in
human development.  In the proposed system, meaning is
extracted from video images based on detection of physical
contact and its parameters.  Mapping of sentence form to
meaning is performed by learning grammatical
constructions that are retrieved from a construction
inventory based on the constellation of closed class items
uniquely identifying the target sentence structure.  The
resulting system displays robust acquisition behavior that
reproduces certain observations from developmental
studies, with very modest ?innate? language specificity.
1. 