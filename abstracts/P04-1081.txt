
We introduce a new method for disambiguating
word senses that exploits a nonlinear Kernel Prin-
cipal Component Analysis (KPCA) technique to
achieve accuracy superior to the best published indi-
vidual models. We present empirical results demon-
strating significantly better accuracy compared to
the state-of-the-art achieved by either na??ve Bayes
or maximum entropy models, on Senseval-2 data.
We also contrast against another type of kernel
method, the support vector machine (SVM) model,
and show that our KPCA-based model outperforms
the SVM-based model. It is hoped that these highly
encouraging first results on KPCA for natural lan-
guage processing tasks will inspire further develop-
ment of these directions.
1 