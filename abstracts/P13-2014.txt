
Conversational implicatures involve rea-
soning about multiply nested belief struc-
tures. This complexity poses significant
challenges for computational models of
conversation and cognition. We show that
agents in the multi-agent Decentralized-
POMDP reach implicature-rich interpreta-
tions simply as a by-product of the way
they reason about each other to maxi-
mize joint utility. Our simulations involve
a reference game of the sort studied in
psychology and linguistics as well as a
dynamic, interactional scenario involving
implemented artificial agents.
1 