
This paper provides a preliminary analysis of American Sign Language
predicate motion signatures, obtained using a motion capture system, to-
ward identification of a predicate?s event structure as telic or atelic. The
pilot data demonstrates that production differences between signed pred-
icates can be used to model the probabilities of a predicate belonging to
telic or atelic classes based on their motion signature in 3D, using either
maximal velocity achieved within the sign, or maximal velocity and mini-
mal acceleration data from each predicate. The solution to the problem of
computationally identifying predicate types in ASL video data could sig-
nificantly simplify the task of identifying verbal complements, arguments
and modifiers, which compose the rest of the sentence, and ultimately
contribute to solving the problem of automatic ASL recognition.
155
156 Malaia, Borneman, and Wilbur
1 