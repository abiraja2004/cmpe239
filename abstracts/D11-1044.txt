
We present a quasi-synchronous dependency
grammar (Smith and Eisner, 2006) for ma-
chine translation in which the leaves of the
tree are phrases rather than words as in pre-
vious work (Gimpel and Smith, 2009). This
formulation allows us to combine structural
components of phrase-based and syntax-based
MT in a single model. We describe a method
of extracting phrase dependencies from paral-
lel text using a target-side dependency parser.
For decoding, we describe a coarse-to-fine ap-
proach based on lattice dependency parsing of
phrase lattices. We demonstrate performance
improvements for Chinese-English and Urdu-
English translation over a phrase-based base-
line. We also investigate the use of unsuper-
vised dependency parsers, reporting encourag-
ing preliminary results.
1 