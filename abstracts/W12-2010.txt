 
This paper presents an exploration into auto-mated content scoring of non-native sponta-neous speech using ontology-based information to enhance a vector space ap-proach. We use content vector analysis as a baseline and evaluate the correlations between human rater proficiency scores and two co-sine-similarity-based features, previously used in the context of automated essay scoring. We use two ontology-facilitated approaches to improve feature correlations by exploiting the semantic knowledge encoded in WordNet: (1) extending word vectors with semantic con-cepts from the WordNet ontology (synsets); and (2) using a reasoning approach for esti-mating the concept weights of concepts not present in the set of training responses by ex-ploiting the hierarchical structure of WordNet. Furthermore, we compare features computed from human transcriptions of spoken respons-es with features based on output from an au-tomatic speech recognizer. We find that (1) for one of the two features, both ontologically based approaches improve average feature correlations with human scores, and that (2) the correlations for both features decrease on-ly marginally when moving from human speech transcriptions to speech recognizer output. 1 