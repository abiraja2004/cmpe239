
Developing dialogue systems is a complex pro-
cess. In particular, designing efficient dialogue
management strategies is often difficult as there
are no precise guidelines to develop them and no
sure test to validate them. Several suggestions
have been made recently to use reinforcement
learning to search for the optimal management
strategy for specific dialogue situations. These
approaches have produced interesting results,
including applications involving real world dia-
logue systems. However, reinforcement learning
suffers from the fact that it is state based. In
other words, the optimal strategy is expressed
as a decision table specifying which action to
take in each specific state. It is therefore diffi-
cult to see whether there is any generality across
states. This limits the analysis of the optimal
strategy and its potential for re-use in other di-
alogue situations. In this paper we tackle this
problem by learning rules that generalize the
state-based strategy. These rules are more read-
able than the underlying strategy and therefore
easier to explain and re-use. We also investi-
gate the capability of these rules in directing
the search for the optimal strategy by looking
for generalization whilst the search proceeds.
1 