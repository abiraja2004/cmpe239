
To date, researchers have proposed different
ways to compute the readability and coher-
ence of a text using a variety of lexical, syn-
tax, entity and discourse properties. But these
metrics have not been defined with special rel-
evance to any particular genre but rather pro-
posed as general indicators of writing qual-
ity. In this thesis, we propose and evalu-
ate novel text quality metrics that utilize the
unique properties of different genres. We fo-
cus on three genres: academic publications,
news articles about science, and machine gen-
erated text, in particular the output from auto-
matic text summarization systems.
1 