
This paper presents a language-independent
probabilistic answer ranking framework for
question answering. The framework esti-
mates the probability of an individual an-
swer candidate given the degree of answer
relevance and the amount of supporting evi-
dence provided in the set of answer candi-
dates for the question. Our approach was
evaluated by comparing the candidate an-
swer sets generated by Chinese and Japanese
answer extractors with the re-ranked answer
sets produced by the answer ranking frame-
work. Empirical results from testing on NT-
CIR factoid questions show a 40% perfor-
mance improvement in Chinese answer se-
lection and a 45% improvement in Japanese
answer selection.
1 