
Reranking models have been successfully ap-
plied to many tasks of Natural Language Pro-
cessing. However, there are two aspects of
this approach that need a deeper investiga-
tion: (i) Assessment of hypotheses generated
for reranking at classification phase: baseline
models generate a list of hypotheses and these
are used for reranking without any assess-
ment; (ii) Detection of cases where rerank-
ing models provide a worst result: the best
hypothesis provided by the reranking model
is assumed to be always the best result. In
some cases the reranking model provides an
incorrect hypothesis while the baseline best
hypothesis is correct, especially when base-
line models are accurate. In this paper we
propose solutions for these two aspects: (i)
a semantic inconsistency metric to select pos-
sibly more correct n-best hypotheses, from a
large set generated by an SLU basiline model.
The selected hypotheses are reranked apply-
ing a state-of-the-art model based on Partial
Tree Kernels, which encode SLU hypothe-
ses in Support Vector Machines with com-
plex structured features; (ii) finally, we apply
a decision strategy, based on confidence val-
ues, to select the final hypothesis between the
first ranked hypothesis provided by the base-
line SLU model and the first ranked hypothe-
sis provided by the re-ranker. We show the ef-
fectiveness of these solutions presenting com-
parative results obtained reranking hypothe-
ses generated by a very accurate Conditional
Random Field model. We evaluate our ap-
proach on the French MEDIA corpus. The re-
sults show significant improvements with re-
spect to current state-of-the-art and previous
re-ranking models.
1 