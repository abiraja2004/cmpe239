
Word-final /t/-deletion refers to a common
phenomenon in spoken English where
words such as /wEst/ ?west? are pro-
nounced as [wEs] ?wes? in certain con-
texts. Phonological variation like this is
common in naturally occurring speech.
Current computational models of unsu-
pervised word segmentation usually as-
sume idealized input that is devoid of
these kinds of variation. We extend a
non-parametric model of word segmenta-
tion by adding phonological rules that map
from underlying forms to surface forms
to produce a mathematically well-defined
joint model as a first step towards han-
dling variation and segmentation in a sin-
gle model. We analyse how our model
handles /t/-deletion on a large corpus of
transcribed speech, and show that the joint
model can perform word segmentation and
recover underlying /t/s. We find that Bi-
gram dependencies are important for per-
forming well on real data and for learning
appropriate deletion probabilities for dif-
ferent contexts.1
1 