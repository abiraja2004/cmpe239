
Tree Adjoining Grammars have well-known
advantages, but are typically considered too
difficult for practical systems. We demon-
strate that, when done right, adjoining im-
proves translation quality without becoming
computationally intractable. Using adjoining
to model optionality allows general translation
patterns to be learned without the clutter of
endless variations of optional material. The
appropriate modifiers can later be spliced in as
needed.
In this paper, we describe a novel method
for learning a type of Synchronous Tree Ad-
joining Grammar and associated probabilities
from aligned tree/string training data. We in-
troduce a method of converting these gram-
mars to a weakly equivalent tree transducer
for decoding. Finally, we show that adjoining
results in an end-to-end improvement of +0.8
BLEU over a baseline statistical syntax-based
MTmodel on a large-scale Arabic/EnglishMT
task.
1 