
A re-scoring strategy is proposed that makes
it feasible to capture more long-distance de-
pendencies in the natural language. Two pass
strategies have become popular in a num-
ber of recognition tasks such as ASR (au-
tomatic speech recognition), MT (machine
translation) and OCR (optical character recog-
nition). The first pass typically applies a
weak language model (n-grams) to a lattice
and the second pass applies a stronger lan-
guage model to N best lists. The stronger lan-
guage model is intended to capture more long-
distance dependencies. The proposed method
uses RNN-LM (recurrent neural network lan-
guage model), which is a long span LM, to re-
score word lattices in the second pass. A hill
climbing method (iterative decoding) is pro-
posed to search over islands of confusability
in the word lattice. An evaluation based on
Broadcast News shows speedups of 20 over
basic N best re-scoring, and word error rate
reduction of 8% (relative) on a highly compet-
itive setup.
1 