
We present a new family of models for unsu-
pervised parsing, Dependency and Boundary
models, that use cues at constituent bound-
aries to inform head-outward dependency tree
generation. We build on three intuitions that
are explicit in phrase-structure grammars but
only implicit in standard dependency formu-
lations: (i) Distributions of words that oc-
cur at sentence boundaries ? such as English
determiners ? resemble constituent edges.
(ii) Punctuation at sentence boundaries fur-
ther helps distinguish full sentences from
fragments like headlines and titles, allow-
ing us to model grammatical differences be-
tween complete and incomplete sentences.
(iii) Sentence-internal punctuation boundaries
help with longer-distance dependencies, since
punctuation correlates with constituent edges.
Our models induce state-of-the-art depen-
dency grammars for many languages without
special knowledge of optimal input sentence
lengths or biased, manually-tuned initializers.
1 