
We present the results of the WMT13
shared tasks, which included a translation
task, a task for run-time estimation of ma-
chine translation quality, and an unoffi-
cial metrics task. This year, 143 machine
translation systems were submitted to the
ten translation tasks from 23 institutions.
An additional 6 anonymized systems were
included, and were then evaluated both au-
tomatically and manually, in our largest
manual evaluation to date. The quality es-
timation task had four subtasks, with a to-
tal of 14 teams, submitting 55 entries.
1 