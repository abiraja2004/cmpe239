
In this paper we generalise the sen-
tence compression task. Rather than sim-
ply shorten a sentence by deleting words
or constituents, as in previous work, we
rewrite it using additional operations such
as substitution, reordering, and insertion.
We present a new corpus that is suited
to our task and a discriminative tree-to-
tree transduction model that can naturally
account for structural and lexical mis-
matches. The model incorporates a novel
grammar extraction method, uses a lan-
guage model for coherent output, and can
be easily tuned to a wide range of compres-
sion specific loss functions.
1 