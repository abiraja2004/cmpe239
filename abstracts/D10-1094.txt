
In this paper, we consider the problem of gen-
erating candidate corrections for the task of
correcting errors in text. We focus on the
task of correcting errors in preposition usage
made by non-native English speakers, using
discriminative classifiers. The standard ap-
proach to the problem assumes that the set of
candidate corrections for a preposition con-
sists of all preposition choices participating
in the task. We determine likely preposition
confusions using an annotated corpus of non-
native text and use this knowledge to produce
smaller sets of candidates.
We propose several methods of restricting
candidate sets. These methods exclude candi-
date prepositions that are not observed as valid
corrections in the annotated corpus and take
into account the likelihood of each preposi-
tion confusion in the non-native text. We find
that restricting candidates to those that are ob-
served in the non-native data improves both
the precision and the recall compared to the
approach that views all prepositions as pos-
sible candidates. Furthermore, the approach
that takes into account the likelihood of each
preposition confusion is shown to be the most
effective.
1 