
This paper describes an approach for the generation
of multimodal deixis to be uttered by an anthro-
pomorphic agent in virtual reality. The proposed
algorithm integrates pointing and definite descrip-
tion. Doing so, the context-dependent discrimina-
tory power of the gesture determines the content-
selection for the verbal constituent. The concept
of a pointing cone is used to model the region sin-
gled out by a pointing gesture and to distinguish
two referential functions called object-pointing and
region-pointing.
1 