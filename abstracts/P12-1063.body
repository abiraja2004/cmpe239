
This paper studies the problem of sentence-
level semantic coherence by answering SAT-
style sentence completion questions. These
questions test the ability of algorithms to dis-
tinguish sense from nonsense based on a vari-
ety of sentence-level phenomena. We tackle
the problem with two approaches: methods
that use local lexical information, such as the
n-grams of a classical language model; and
methods that evaluate global coherence, such
as latent semantic analysis. We evaluate these
methods on a suite of practice SAT questions,
and on a recently released sentence comple-
tion task based on data taken from five Conan
Doyle novels. We find that by fusing local
and global information, we can exceed 50%
on this task (chance baseline is 20%), and we
suggest some avenues for further research.
1 