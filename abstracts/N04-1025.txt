
We demonstrate a new research approach to the
problem of predicting the reading difficulty of a
text passage, by recasting readability in terms of
statistical language modeling.  We derive a measure
based on an extension of multinomial na?ve Bayes
classification that combines multiple language
models to estimate the most likely grade level for a
given passage.  The resulting classifier is not spe-
cific to any particular subject and can be trained
with relatively little labeled data.  We perform pre-
dictions for individual Web pages in English and
compare our performance to widely-used semantic
variables from traditional readability measures.  We
show that with minimal changes, the classifier may
be retrained for use with French Web documents.
For both English and French, the classifier main-
tains consistently good correlation with labeled
grade level (0.63 to 0.79) across all test sets.  Some
traditional semantic variables such as type-token
ratio gave the best performance on commercial cal-
ibrated test passages, while our language modeling
approach gave better accuracy for Web documents
and very short passages (less than 10 words).
1 