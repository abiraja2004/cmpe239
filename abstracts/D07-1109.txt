
We develop latent Dirichlet alocation with
WORDNET (LDAWN), an unsupervised
probabilistic topic model that includes word
sense as a hidden variable. We develop a
probabilistic posterior inference algorithm
for simultaneously disambiguating a corpus
and learning the domains in which to con-
sider each word. Using the WORDNET hi-
erarchy, we embed the construction of Ab-
ney and Light (1999) in the topic model and
show that automatically learned domains
improve WSD accuracy compared to alter-
native contexts.
1 