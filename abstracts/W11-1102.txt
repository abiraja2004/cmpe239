
We propose the use of a nonparametric Bayesian
model, the Hierarchical Dirichlet Process (HDP),
for the task of Word Sense Induction. Results are
shown through comparison against Latent Dirich-
let Allocation (LDA), a parametric Bayesian model
employed by Brody and Lapata (2009) for this task.
We find that the two models achieve similar levels
of induction quality, while the HDP confers the ad-
vantage of automatically inducing a variable num-
ber of senses per word, as compared to manually
fixing the number of senses a priori, as in LDA.
This flexibility allows for the model to adapt to
terms with greater or lesser polysemy, when ev-
idenced by corpus distributional statistics. When
trained on out-of-domain data, experimental results
confirm the model?s ability to make use of a re-
stricted set of topically coherent induced senses,
when then applied in a restricted domain.
1 