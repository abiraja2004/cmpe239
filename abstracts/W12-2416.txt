 
Manually annotating clinical document corpora to generate reference standards for Natural Language Processing (NLP) sys-tems or Machine Learning (ML) is a time-consuming and labor-intensive endeavor. Although a variety of open source annota-tion tools currently exist, there is a clear opportunity to develop new tools and assess functionalities that introduce efficiencies into the process of generating reference standards. These features include: man-agement of document corpora and batch as-signment, integration of machine-assisted verification functions, semi-automated cu-ration of annotated information, and sup-port of machine-assisted pre-annotation. The goals of reducing annotator workload and improving the quality of reference standards are important considerations for development of new tools. An infrastruc-ture is also needed that will support large-scale but secure annotation of sensitive clinical data as well as crowdsourcing which has proven successful for a variety of annotation tasks. We introduce the Ex-tensible Human Oracle Suite of Tools  (eHOST) http://code.google.com/p/ehost that provides such functionalities that when coupled with server integration offer an end-to-end solution to carry out small or large scale as well as crowd sourced anno-tation projects. 1 