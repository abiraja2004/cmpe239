 
c-rater is Educational Testing Service?s 
technology for the content scoring of short 
student responses.  A major step in the scor-
ing process is Model Building where vari-
ants of model answers are generated that 
correspond to the rubric for each item or test 
question. Until recently, Model Building 
was knowledge-engineered (KE) and hence 
labor and time intensive. In this paper, we 
describe our approach to automating Model 
Building in c-rater. We show that c-rater 
achieves comparable accuracy on automati-
cally built and KE models. 
1 