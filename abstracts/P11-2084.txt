
A topic model outputs a set of multinomial
distributions over words for each topic. In
this paper, we investigate the value of bilin-
gual topic models, i.e., a bilingual Latent
Dirichlet Allocation model for finding trans-
lations of terms in comparable corpora with-
out using any linguistic resources. Experi-
ments on a document-aligned English-Italian
Wikipedia corpus confirm that the developed
methods which only use knowledge from
word-topic distributions outperform methods
based on similarity measures in the original
word-document space. The best results, ob-
tained by combining knowledge from word-
topic distributions with similarity measures in
the original space, are also reported.
1 