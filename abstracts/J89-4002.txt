 Action. 
between two actions A and B, with no links between 
any actions inside the "lump" and any actions outside. 
If the subgraph between the actions is sufficiently 
complex (has more structure than two simple actions in 
parallel), the strategy suggests that its explanation 
should be postponed to a separate "section." Mean- 
while the whole subgraph is incorporated into the 
current explanation as if it were a simple action (this is, 
of course, the same strategy that is applied for an action 
that is above the primitive level in the abstraction 
hierarchy). Forward description is deemed appropriate 
when the action graph is a right-branching structure; in 
this case the actions are generally dealt with in time 
order, giving a message of one of the forms: 
time_then (result (Act, State) . . . .  ) 
neutra\]_seq ( 
result (Act, State), 
embed (causes (State, 
state (user, enabled (Acts))),  
.... \[\]) 
where Act is the first action, State a state that it makes 
true, and " . . . "  is the message derived from the 
subsequent actions. When the action graph is a left 
branching structure, however, the strategy of back- 
wards description is suggested. This gives rise to mes- 
sages of the form: 
embed (prereqs(user~ct,Pres) ,  
now (state(user, 
enabled (
~9? ??? 
Figure 9 Closure of Expansion. 
?? 
242 Computational Linguistics Volume 15, Number 4, December 1989 
Chris MeUish and Roger Evans Natural Language Generation from Plans 
Lump: 
~ 0  gQ  
O I
Forwards: 
Backwards: ~ m  I QQ 
When you have done A 
you can do B and C 
? 
8 Q 
?. Before you can do A 
you must do B and C 
Figure 10 Rhetorical Strategies. 
parallel (Act, 
achieve (State))))) 
where Act is the first action, with preconditions Pres 
and effects State, and " . . . "  is the message derived 
from the subsequent actions. 
All of these kinds of messages require the insertion of 
preconditions and effects of actions. It is necessary for 
the system to compute those preconditions and effects 
that are actually relevent for the current plan, rather 
than simply the total sets of preconditions and effects. 
This amounts to determining the justifications for the 
action ordering chosen. The justification for action A 
coming before action B can be of one of two types. 
Either A is needed to create a state where a precondi- 
tion of B is true, or A comes before B because otherwise 
B would create a state where a precondition of A was 
not true. The two different possibilities give rise to 
different modes of presentation, but if the justification is
redundant or not available from the plan, it is simply 
missed out. 
4.3 IMPROVING THE MESSAGE 
As the last section suggests, the initial version of the 
message is put together in a very direct way from the 
structure of the plan. As a result, it is often unneces- 
sarily cumbersome. Message simplification concerns 
rewriting the message xpression generated by message 
planning into one that is "simpler" in some sense. Since 
the amount of material we wish to deal with could be 
large, we have avoided considering expensive global 
simplification techniques in favor of emphasizing local 
simplification techniques analogous to "peephole" op- 
timizing techniques in compiling. Of course, a crucial 
difference between language generation and compila- 
tion is that in the former there is no clear notion of what 
"optimality" is. In the absence of a formal and detailed 
psychological theory of discourse comprehension, re- 
searchers in natural anguage generation are reduced 
more or less to using their intuitions about whether one 
way of phrasing something is "easier to understand" 
than another. We have regretfully had to follow the 
same course in designing and evaluating our own sys- 
tem. 
The domain-independent simplification rules used by 
our message simplification system are treated equally, 
but conceptually they seem to be of four main types. 
Members of the first type tidy up special cases that 
could as easily be detected when the expression is 
constructed. Here is an example of such a rule (\[ \] 
denotes the empty utterance): 
(1) neutral_seq (X,\[ \]) --* X. 
Thus any utterance xpression of type neutral_seq will 
be rewritten by this rule if its second component is 
empty. Such an expression is rewritten simply to its first 
component. Incorporating such rules into the simplifi- 
cation stage means that the message-planning compo- 
nent can be simpler and more perspicuous. 
The second kind of rule expresses knowledge about 
planning and plan execution. Here are two such rules: 
(2) achieve (state (user, done (Act))) --* Act. 
(3) parallel (X, wait (Y)) --* then (X, walt (Y)). 
Rule (2) expresses the fact that the only way to create a 
state where you have done an action is to do the action. 
Rule (3) expresses the fact that waiting is an action that 
is always postponed until there is nothing else to do. 
Both of these principles are useful in finding the best 
way to express a given action. 
A third kind of rule really reflects the linguistic 
coverage of the system in an indirect manner. If there is 
a special way available for saying a particular kind of 
thing, then that should be preferred to using a more 
general technique. Here is such a rule: 
(4) prereqs (user, X, state (user, done (Y))) --* 
neccbefore (user, Y, X). 
This rule is about a special case of the prereqs tructure 
arising in the message. When one is calling attention to 
the prerequisite(s) of an action X, a special case arises 
when the only prerequisite is the achievement of an- 
other action Y. In this case, the prerequisites statement 
amounts to saying simply that Y must happen before X. 
In general, one would expect hat expressing the state- 
ment in this second way would result in a simpler piece 
of text than using a general-purpose trategy for ex- 
pressing prereqs statements. It is arguable that such 
rules should really exist as special-case structure build- 
ing rules. Such an approach would, however, preclude 
the use of simplification rules that made further use of 
the output of such rules. 
Finally, there are rules that are motivated by notions 
of simplicity of structure. For instance, the rule: 
(5)  time_parallel (do (X) ,  do (Y ) )  --* do (paral lel  (X, 
Y)). 
Computational Linguistics Volume 15, Number 4, December 1989 243 
Chris Meilish and Roger Evans Natural Language Generation from Plans 
results in an expression with one fewer "connectives." 
Such rules should really be backed up by a (perhaps 
psychological) theory of the complexity of messages. 
Here is an example of how a message language 
expression can be simplified using these rules. 
neutr~.\] ~eq (
prereqs (user, 
achieve (state (user, done (al))), 
state (user, 
done (parallel (a2, wait (s))))), 
\[\]) 
is simplified by rule (1) to: 
prereqs (user, 
achieve (state (user, done (al))), 
state (user, 
done (parallel (a2, wait(s))))) 
which is simplified by rule (2) to: 
prereqs (user, 
el, 
state (user, done (parallel (a2, wait(s))))) 
which is simplified by rule (3) to: 
prereqs (user, 
el, 
state (user, done (then (a2, walt(s))))) 
which is simplified by rule (4) to: 
neccbefore (user,  then  (a2, wa i t ( s ) ) ,  a l )  
Here the simplification would result in the difference 
between a text like: 
In order to get you to have washed the baby you must 
have undressed the baby and waited until the bath is 
full. 
and one like the following: 
You must undress the baby and then wait until the bath 
is full before you can wash the baby 
The rewrite rules we have discussed so far in this 
section are independent of the domain in which the plan 
is made. Our system also allows for domain-dependent 
rules to be provided for a given planning domain. This 
provides a way of automatically rewriting every occur- 
rence of a given expression coming from the planner 
into another given expression. One purpose of this kind 
of rule is to provide a translation for states, which may 
be primitive objects to the planner but are required to be 
somewhat more complex by the generator. For exam- 
ple, in the car domain, there is a rule that rewrites the 
planner primitive positioned (X) to be the complex 
term state (X, positioned). Domain-dependent rewrite 
rules can also be used to show correspondances be- 
tween action and state names that seem independent but 
are in fact strongly connected. For instance, in the 
house-building plan, there is an action lay_basement_ 
floor and a domain state basement_floor_laid (not a 
legal message state). Not surprisingly, the second is an 
effect of the first and can only come about by the first 
244 
having been done. Given that we can deal with complex 
states and actions, we would do well to replace the 
second by a formula involving the first, in fact state 
(user', done (lay_basement_floor)). In this way we can 
simplify certain expressions in the message. For in- 
stance, the expression: 
do (achieve (basement_floor_laid)) 
is equivalent to: 
do (achieve (state (user, done (lay_basement_floor))) 
which simplifies to: 
do ( ls~r_basement-floor ) 
by simplification rule (2) above. Given this domain- 
dependent rule and the simplifications thus enabled, the 
expression do (achieve (basement__floorAaid)) would 
be realized as something like "lay the basement floor," 
rather than "get the basement floor to be laid," which 
would arise from a more straightforward encoding of the 
state basement_floor_laid in terms of verbs and cases. 
Domain-dependent rewrite rules allow us, in princi- 
ple, infinitely to enrich the semantics of actions and 
state,~ represented in the plan. They thus provide one 
way of compensating for the shallowness of the plan- 
ner's representation. The basic framework on which the 
plan actions and states hang is, however, fixed by the 
planner and cannot be changed by the generator. Thus 
not all deficiencies of the planner can be rectified by this 
method. The extensive use of domain-dependent re- 
write rules is in any case unattractive, asit takes away 
from the domain-independence of the system. We will 
return to this topic later. 
4.4 :KNOWLEDGE SOURCES IN MESSAGE CONSTRUCTION 
Before we leave our discussion of how messages are 
constructed, it is useful to summarize the different 
knowledge sources that have an effect on the text 
generated from a plan. The gross organization of the 
message is determined by rhetorical strategies that look 
for patterns in the plan structure. Such strategies are 
specific only to the kind of plan that we are taking as 
input (i.e., hierarchical, nonlinear plans). Message sim- 
plification is usually responsible for the finer-grain 
structure of the message, as its rewrite rules operate 
strictly locally in the message. The domain-independent 
rewrite rules exploit the redundancy in the message 
language and express heuristics about how a given 
proposition might be expressed most simply. Such rules 
embody simple knowledge about planning and the facil- 
ities of the message language. Finally, domain-depen- 
dent rewrite rules enable some of the hidden structure in 
the planner's representation to be revealed. 
Once a final message has been decided on, its real- 
ization as text makes use of structure building rules that 
depend on the natural language being used. At this point 
most of the significant decisions have already been 
made. The structure-building rules are able to make a 
Computational Linguistics Volume 15, Number 4, December 1989 
Chris Mellish and Roger Evans Natural Language Generation from Plans 
Figure 11 Installing the Services. 
limited choice among possible syntactic structures and 
are able to introduce pronominalization where it seems 
appropriate, but their scope is heavily constrained by 
the message. During structure building, a domain-de- 
pendent lexicon makes available a verb entry for each 
domain state and action, as well as a fixed NP that can 
be used to denote each domain object. Although it is 
useful to assess the effectiveness of the system by 
considering the text output, many of the more interest- 
ing problems with the system are really already visible 
at the message stage. 
5. DISCUSSION 
5.1 FURTHER EXAMPLES 
The system has been tested using a number of different 
domains with rather different characteristics, and the 
results have been correspondingly varied. One domain 
that seems to work fairly well is that of cookery recipes 
such as the following: 
MAKING PAPRIKA POTATOES AND SMOKED SAUSAGES 
Melt the fat, fry the onion in it, add the flour to it and 
add the paprika to it. After this, stir the sauce until it 
boils. Meanwhile peel the potatoes and cut them into 
pieces. After this, add them to the sauce, cover the pan 
and make the sauce boil, stirring the sauce occasion- 
ally. Meanwhile cook the sausages. After this, add them 
to the sauce. 
This text was actually produced from a "mockup" of 
plausible planner output, rather than a real plan, and did 
not include enough information (about preconditions, 
effects, etc.) to warrant he system adding justifications 
about ordering. This does not seem to matter too much, 
probably because cookery recipes are traditionally pre- 
sented as instructions to be followed more or less 
blindly. 
For an example where our techniques produce a less 
pleasing result, consider the "installing the services" 
extract from the house-building plan (discussed above) 
shown in Figure 11. In this action graph (which shows 
no preconditions or effects), we have indicated the 
actions with abbreviated names. Those actions in low- 
ercase are not actually part of installing the services (but 
are "intruder" actions that are nevertheless crucial to 
this part of the plan); they will be described elsewhere in
the text. Here is the English produced for this plan 
fragment: 
INSTALLING THE SERVICES 
Installing the services involves finishing the electrical 
work and laying the storm drains. 
You must paint the house before finishing the electrical 
work. 
In order to paint the house you must have installed the 
finished plumbing and installed the kitchen equipment. 
You must lay the finished flooring before installing the 
finished plumbing and installing the kitchen equipment. 
You must fasten the plaster and plaster board before 
laying the finished flooring. In order to fasten the 
plaster and plaster board you must have installed the 
air conditioning and installed the rough plumbing and 
installed the rough wiring. 
Install the drains and then install the air conditioning, 
installing the rough plumbing. 
Meanwhile install the rough wiring, 
You can now fasten the plaster and plaster board. 
You can now lay the finishedflooring. 
You can now install the finished plumbing and install 
the kitchen equipment. 
You can now paint the house. 
You can now finish the electrical work. 
Meanwhile lay the storm drains. 
You have now finished installing the services. 
This account is basically comprehensible, but is repet- 
itive and quite hard to follow. One reason for the 
repetition is that the subject matter is really very boring 
and uninformative, and it would be quite a challenging 
task for a human being to produce interesting and 
readable text from the same information. We discuss 
below some other reasons why this text is less than 
optimal. 
5.2 DEFICIENCIES IN PLANS 
Although generating explanations from the output of an 
AI planner appears to be a promising application of 
natural language generation research, there are a num- 
ber of special problems that we have encountered with 
this task. Indeed, we can explain some of the deft- 
ciences in the text we have been able to generate purely 
in terms of deficiencies of the planner and/or its plans. 
Some problems tem from the use of plan operators not 
designed with text generation in mind, and can be 
solved within the scope of the planning system. More 
serious are problems that arise because of deficiencies 
in the planner methodology itself. In the development of 
our system we have encountered a number of these, 
ranging from trivial to quite fundamental. Some of these 
are properties of NONLIN in particular; others apply 
more generally to most AI planning systems. It is not 
appropriate to discuss the full details of these problems 
here, but we shall mention some of the main points. 
GRANULARITY 
One might ask why, unlike in the cookery recipe, there 
is no pronominalization in the text for installing the 
services. The coherence of the text would be improved 
Computational Linguistics Volume 15, Number 4, December 1989 245 
Chris Mellish and Roger Evans Natural Language Generation from Plans 
considerably by the judicious use of pronouns. Unfor- 
tunately, whereas in the cookery domain (which we 
encoded by hand) a particular action of 'frying' is 
treated as an instance of a general action that can 
potentially be applied to different objects; in the house- 
building domain the objects acted on by an action are 
fundamentally built into that action. The difference can 
be seen from example lexical entries from the two 
domains: 
ix (fry (Food, In), fry, \[obj: Food, in: In\]). 
lx (install_rough_wiring, install, 
\[obj : @ 'the rough wiring'\]). 
To use pronominalization, one needs to be able to 
determine that the same domain object is being men- 
tioned several times, but only the first type of represen- 
tation here actually supports the representation f do- 
main objects. What has happened here is that, from the 
point of view of making a house-building plan, the 
planner cannot make use of properties of a general 
action like 'install,' and so its representation f actions 
is at a coarser level of granularity than that required to 
produce good text. 
In common with most plans in traditional AI work, 
NONLIN plans only encode very weak information 
about causality and temporal relationships. For in- 
stance, when there is an action that achieves an effect, 
there is no way to tell from the plan whether we are 
dealing with an instantaneous action, an extended ac- 
tion that terminates as soon as the effect is achieved, or 
an extended action where the effect is achieved some- 
time during the execution. A natural language like 
English provides ways of distinguishing between these 
cases: 
Turn on the switch and the light will be on. 
Pour in the water until the bucket is full. 
Prepare a chicken curry so that the chicken scraps are 
used up. 
Because there is no way to distinguish between these in 
the NONLIN representation f effects, our generator is
forced to try to find a neutral way to express all of them. 
As a result, there is a homogeneity in the text that is not 
necessarily reflected in the actual plan execution. Again 
the problem can be thought of as a mismatch between 
the granularity of the representation used for planning 
and that needed to exploit the facilities of the natural 
language. 
The effect of the granularity problem can be lessened 
by allowing the plan generator to provide deeper infor- 
mation about he internal structure of actions and states 
through domain-dependent rewrite rules. Our message 
language allows us to talk about repeated actions, for 
instance, and so we can specify that certain domain 
actions are really shorthand for more complex expres- 
sions: 
filLbucket -~ repeat (pour (water, bucket), 
state (bucket, full)). 
246 
Messages containing these complex actions can then be 
simplified by domain-independent rules like: 
result (repeat (Act, State), State) -* 
do (repeat (Act, State)). 
Similarly we can use domain-dependent rewrite rules to 
introduce tokens tanding for domain objects and hence 
give us a basis for pronominalization. The more one 
reliies on domain-dependent rewrite rules for good text, 
however, the less one can claim to have a domain- 
independent basis for generating text from plans. 
CONCEPTUAL FRAMEWORK 
Domain-dependent rewrite rules can be regarded as a 
way of embellishing the planner's output o match up 
better with the requirements for generation. The basic 
framework of the plan is, however, something that 
cannot be changed unless the generator itself is to start 
doing some of the planning. Assuming that there is some 
point in distinguishing the planner from the generator, 
the generator is therefore sometimes faced with a mis- 
match between self-evident concepts in the planner's 
conceptual framework and those concepts that can be 
expressed simply in natural language. Consider, for 
instance, the notion of (primitive) actions that are 
unordered in the plan. If two actions have no ordering 
relation between them, then this indicates that the 
actions can be performed in any order relative to one 
another. To express correctly the plan's semantics, one 
should therefore make use of expressions like: 
Install the drains and install the rough wiring, in any 
order. 
In practice, however, we have chosen to map such a 
piece of plan into a message like: 
do (parallel (instalLdrains, inst~.11 rough_wiring)). 
which then gives rise to a text such as: 
Install the drains. Meanwhile install the rough wiring, 
Treating unordered actions as parallel actions may 
indeed both produce good text and even capture the 
reality of plan execution, as in: 
Make the sauce boil, stirring the sauce occasionally. 
but this will only be so if at least one of the actions takes 
place over a period of time and the actions can be and 
are recommended to be executed concurrently. There 
is, of course, no way to determine from the planner's 
representation whether this is so. Indeed, since the 
planner egards all primitive actions as essentially in- 
stantaneous, in all cases it is in some sense incorrect to 
express the planner's recommendations i  this way. If 
the correct execution of the plan were critical, for 
instance, then it could be very dangerous to hide the 
limited way in which the planner views the world as we 
have done. It might thus be suggested that a generator 
working from plans could and should always strive to 
convey the plan semantics accurately, even if this 
Comput~tional Linguistics Volume 15, Number 4, December 1989 
Chris Mellish and Roger Evans Natural Language Generation from Plans 
involves long-winded and unnatural prose. But in the 
end one is faced with an incompatibility between the 
planner's conceptual framework and the limits of what 
our language can express. For instance, it unclear how 
the action of "installing the rough wiring" can be 
expressed in English in such a way that the action can 
only be interpreted as an instantaneous action, which is 
the way the planner sees it. 
EXPLANATORY POWER 
The texts that we have generated from plans are in- 
tended to do more than simply tell the reader how to 
execute a series of actions. We always hoped that the 
justification structure built by the planner would also 
help us to explain why the given actions, with the 
ordering described, are the right ones to achieve the 
plan's goal. In practice, however, our texts have failed 
to be explanatory for a number of reasons. One problem 
is that, unlike instructions generated by human beings, 
our texts only tell you what to do, and not what not to 
do. It is often just as important for a person to be 
warned about he unpleasant consequences of doing the 
wrong thing as it is to be told what the right thing is. 
Unfortunately, the notion of "plan" we have adopted 
only makes reference to the successful actions, even 
though the plan generator may have spent a lot of time 
exploring other possibilities that did not work out. It 
might therefore be appropriate, in future work, to 
consider natural language generation based on the trace 
of a planning system, rather than on the final result. 
Similarly, in many of the texts produced by our 
system the reader is told what to do but is given no 
illumination as to why things have to be done in this 
way. Unfortunately, although in principle every plan is 
justified by earlier actions achieving the preconditions 
of later actions, many plans do not contain this infor- 
mation in a useful form--in the housebuilding plan, for 
instance, the only preconditions that are required for an 
action in this plan to be performed are the successful 
completion of previous actions. That is, the person who 
has encoded the operators in terms of which the plan is 
constructed has "compiled in" certain ordering con- 
straints without using the language of preconditions and 
effects effectively to explain them. One is reminded 
here of the problems that Swartout (1983) encountered 
in producing explanations from expert systems. The 
problem was that just because a set of rules was 
sufficient to produce xpert behavior did not mean that 
those rules contained anything illuminating to put into 
explanations. Similarly in the planning area, there is no 
reason why a set of operators that are effective for 
producing useful plans need contain anything very 
interesting that can be put into a natural language 
account. Unfortunately, one cannot necessarily expect 
machine-generated plans to come at the right level of 
detail to be really useful to a human being. For instance, 
a house-building plan that enabled one to see why the 
rough plumbing must be installed after the drains (pre- 
Computational Linguistics Volume 15, Number 4, December 1989 
sumably because otherwise it is hard to make the pipes 
line up) would be very large, and it would be well 
beyond the state of the art for such a plan to be 
produced automatically. Moreover, such a plan would 
undoubtably contain a lot of information that was 
blindingly obvious to a human reader and hence of no 
interest whatsoever. 
ARBITRARY PLANNER RESTRICTIONS 
As is typical with application programs, most planners 
have particular features that represent non-standard or
novel approaches to certain situations. This fact means 
that any natural language generator using plans as input 
must customize itself somewhat to the peculiarities of 
the particular planner it is working with. One problem 
peculiar to NONLIN's representation language con- 
cerns the manner in which preconditions are specified. 
In NONLIN an operator specifies how a goal is ex- 
panded to a network of subgoals. As was observed in 
the earliest AI planners, the most common case is that 
a goal has preconditions, goals that must be true before 
the given goal can be achieved. In NONLIN, one has to 
use an expansion to represent this, with the conse- 
quence that one wants the original goal itself to occur in 
the expansion (that is Goal expands to Pre ~ . . . . .  Pre y, 
Goal). NONLIN will not allow this, so there have to be 
two distinct representations of the goal. So in the car 
example, we have {goal ...} for the high level goal and 
{act ...} for the low level version (although this scheme 
might not work in every domain). By this means we can 
make NONLIN behave, but give ourselves a linguistic 
problem--every action occurs twice. For example, we 
might get: 
STARTING THE ENGINE 
Go to the cab and then start the engine and you will 
have finished starting it. 
Roughly speaking, the distinction is between 'starting 
the engine' (the whole task) and 'actually starting the 
engine' (the specific operation). To some extent we can 
avoid the problem by using different phrases (e.g., 'turn 
on the engine'), but it does not make the generation task 
easier. 
5.3 DEFICIENCIES IN OUR APPROACH 
The problems with our natural language accounts are, of 
course, not entirely due to deficiencies in the plans we 
are working on. We have deliberately held closely to 
some basic guiding principles to evaluate their applica- 
bility. So it is important to pinpoint heir failings in our 
current system and mention possible alternative ap- 
proaches. 
RELYING ON PLAN STRUCTURE 
To build a domain-independent system to generate text 
from plans, we have deliberately tried to use only 
information that the planner itself understands; i.e., 
information about the structure of the plan. One of the 
247 
Chris Meilish and Roger Evans Natural Language Generation from Plans 
fundamental tenets of our approach was thus that the 
plan abstraction hierarchy would be a useful source of 
information about how the text should be organized. 
But our experience suggests that it may not be as useful 
as one might think. As well as the kind of problems 
described above (which might be corrected in a different 
planning system), there seem to be more general dis- 
crepancies between the kind of abstraction useful to a 
planner and the kind useful to a text generator. 
For example, our car domain and many of the 
blocksworld plans that have been studied in AI tend to 
have a deeper abstraction hierarchy than one might 
expect from the apparent simplicity of the tasks. A 
generator that tries to exploit them all ends up produc- 
ing too much structure in its text. Thus the example 
used in Section 3 also has a 'section': 
GAINING ACCESS TO THE DISTRIBUTOR 
Detach the dirt cover f rom the engine and you will have 
f inished gaining access to the distributor. 
Here there is a level of abstraction that is useful to the 
planner, but not to the human reader: it would probably 
have been better to insert this section "in-line" in the 
higher level description. On the other hand, the single 
"section" devoted to installing the services in the 
house-building plan would have gained from being bro- 
ken up in some way. There may be a linguistic solution 
to the problem of whether a piece of information 
deserves a ful l" section," perhaps in terms of a domain- 
dependent model of what is and is not worth saying, or 
the problem may point to a fundamental difference 
between the ways the planner and a human perceives 
the planning task. Either way, what is clear is that the 
planner's abstraction hierachy alone is not fully ade- 
quate for text generation. Whether we can devise gen- 
eral principles for producing alternative decompositions 
of plans more suitable for text generation remains an 
open research area. 
REPETITION 
We have commented above on reasons why the raw 
material we can gain from plans is liable to lead to 
repetitiveness in the text. Even if we managed to enrich 
the plan representations suitably, however, the genera- 
tor would still be deficient when the input really is 
uniform. In particular, the uniformity of the text output 
often leads to unwanted ambiguities, imply because of 
the lack of variation in the stylistic devices used. For 
instance, in the following excerpt it is unclear whether 
the potato peeling is supposed to be "in parallel with" 
melting the fat, or just with stirring the sauce: 
Melt the fat  . . . .  
After this, stir the sauce until it boils. 
Meanwhile peel the potatoes and cut them into pieces. 
We originally hoped to overcome the problem of repe- 
tition by providing several structure-building rules for 
each type of message language construction, which 
would be sensitive to the form of the objects involved in 
248 
the construction. To some extent we succeeded in 
producing such rules, but the effect on the text was not 
great. The problem here is that, even with these extra 
rules, our structure-building is based solely on local 
patterns in the message, whereas the problem of repe- 
tition can only be solved by a global planning of the 
text. It :might be possible to gain some improvement in 
our system by having the choice of structure-building 
rules be determined partially by some random factor, 
but a proper solution requires a more radical redesign. 
LINGUISTIC SIMPLIFICATIONS 
There are a number of stylistic issues that the system 
cannot easily accommodate. For instance, operations 
such as "heavy NP shift," segmentation into sentences, 
coordination, and ellipsis all require detailed stylistic 
control and evaluation. The message language is delib- 
erately nonlinguistic and so can only approximately 
represent the kinds of language-dependent stylistic in- 
formation such processing needs. For instance, rewrite 
rules can decide how to group information on the basis 
of the complexity of the message, but this only indi- 
rectly reflects the complexity of the text that will be 
generated. The effective use of different stylistic de- 
vices depends in the end on simplifications that are 
justified on linguistic, rather than conceptual, grounds, 
and this suggests that our architecture should really 
in~zorporate a style module capable of reasoning at this 
level. Such a style module would necessarily have to 
take a more global view, looking at the overall inguistic 
effect of the localized basic text generation processes. It
might be possible to introduce linguistic simplifications 
at structure-building time, relaxing the requirement of 
compositionality (indeed, this is how McDonald 1983 
operates). We believe, however, that it would be pref- 
erable to attempt to treat it at least conceptually as a 
subsequent processing stage. 
5.4 WAYS FORWARD 
In this paper we have described a system for generating 
natural anguage from automatically generated plans. 
Our main aim in developing the system was to produce 
a model of a complete system using state-of-the-art 
methodology and techniques, partly to evaluate the 
current state of knowledge, and partly to provide a basis 
for comparison for future work. Logically, then, there 
are two strands to further work based on this research: 
building on the evaluation to learn lessons about the 
design of generation systems and the systems they 
interact with, and building on the system itself to 
produce better generation-from-plans sy tems. 
One of the key evaluative l ssons concerns the plan 
structures a system like this depends on. We found the 
plan,; produced by NONLIN unsatisfactory and we 
have begun to understand why. We must now specify 
what we would like a plan to look like and contain, 
within the general constraint hat a planning system 
couht reasonably produce it. Our present approach to 
Comlmtational Linguistics Volume 15, Number 4, December 1989 
Chris Meilish and Roger Evans Natural Language Generation from Plans 
this top ic  is to take a very  fo rmal  v iew o f  p lans as 
a lgebra ic  express ions  over  states ( rather  than act ions  or  
goals)  w i th  a we l l -de f ined  fo rmal  semant ics ,  a l lowing us 
to be c lear  about  the semant ic  e f fect  o f  p lan t ransfor -  
mat ions .  
The system itself falls broadly into two parts, build- 
ing and simplifying the message, and turning the mes- 
sage into text. Of these the latter is the more modular, 
more declarative, and probably more successful at 
present. To a certain extent it can serve as a piece of 
enabling technology for research on the message com- 
ponent. Its major deficiency as discussed above is 
global stylistic control. Its handling of morphology is
currently rather unprincipled, but the utilization of a 
morphological representation language such as Datr 
(Evans and Gazdar 1989 a,b) would rectify this. 
The biggest outstanding task, however, is the mes- 
sage planner itself. The mechanism described above 
employs some quite powerful techniques in a fairly 
effective way, but it is not very perspicuous or exten- 
sible. We have begun work on a new message planner 
module that applies transformation rules to plans of the 
algebraic type mentioned above, gradually transforming 
the plan into an optimized message structure. This will 
provide us with a rule-based semideclarative framework 
in which to explore further the issues of message 
planning. 
ACKNOWLEDGMENTS 
The work reported here was made possible by SERC grant GR/D/ 
08876. Both authors are currently supported by SERC Advanced 
Fellowships. 
REFERENCES 
Chester, Daniel 1976 The Translation of Formal Proofs into English. 
Artificial Intelligence, Vol 7, 261. 
Conklin, E. Jeffrey and McDonald, David D. 1982 Salience: The Key 
to the Selection Problem in Natural Language Generation. In: 
Proceedings of the 20th Meeting of the Association for Computa- 
tional Linguistics, Toronto, Canada. 
Dale, Robert 1986 The Pronominalization Decision in Language 
Generation. Dissertation Abstracts International Report 276, Uni- 
versity of Edinburgh, Edinburgh, U.K. 
Evans, Roger and Gazdar, Gerald 1989 Inference in Datr. In: Pro- 
ceedings of the 1989 European Association for Computational 
Linguistics, UMIST. 
Evans, Roger and Gazdar, Gerald 1989 The Semantics of Datr. In: 
Proceedings of the 1989 Artificial Intelligence Society of Great 
Britain, University of Sussex. 
Gazdar, Gerald; Klein, Ewan; PuUum, Geoffrey; and Sag, Ivan 1985 
Generalised Phrase Structure Grammar. Blackwell. 
Grosz, Barbara J. 1977 The Representation and Use of Focus in 
Dialogue Understanding. SRI Technical Report 151. 
Kay, Martin 1979 Functional Grammar. In: Proceedings of the 5th 
Annual Meeting of the Berkeley Linguistics Society. Berkeley, 
CA. 
Kay, Martin 1984 Functional Unification Grammar: A Formalism for 
Machine Translation. In: Proceedings of COLING-84. Stanford, 
CA. 
Mann, William C. and Moore, James A. 1981 Computer Generation of 
Multiparagraph English Text. American Journal of Computational 
Linguistics, Vol 7, No 1. 
Mann, William; Bates, Madeleine; Grosz, Barbara; McDonald, Dav- 
id; McKeown, Kathleen; and Swartout, William 1982 Text Gen- 
eration. American Journal of Computational Linguistics. Vol 8, 
No 2. 
McDonald, David D. 1983 Natural Language Generation as a Com- 
putational Problem: An 