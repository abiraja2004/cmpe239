
This paper presents a novel approach for lever-
aging automatically extracted textual knowl-
edge to improve the performance of control
applications such as games. Our ultimate goal
is to enrich a stochastic player with high-
level guidance expressed in text. Our model
jointly learns to identify text that is relevant
to a given game state in addition to learn-
ing game strategies guided by the selected
text. Our method operates in the Monte-Carlo
search framework, and learns both text anal-
ysis and game strategies based only on envi-
ronment feedback. We apply our approach to
the complex strategy game Civilization II us-
ing the official game manual as the text guide.
Our results show that a linguistically-informed
game-playing agent significantly outperforms
its language-unaware counterpart, yielding a
27% absolute improvement and winning over
78% of games when playing against the built-
in AI of Civilization II. 1
1 