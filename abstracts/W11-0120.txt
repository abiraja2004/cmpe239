
Measures of similarity have traditionally focused on computing the semantic relatedness between
pairs of words and texts. In this paper, we construct an evaluation framework to quantify cross-modal
semantic relationships that exist between arbitrary pairs of words and images. We study the effec-
tiveness of a corpus-based approach to automatically derive the semantic relatedness between words
and images, and perform empirical evaluations by measuring its correlation with human annotators.
1 