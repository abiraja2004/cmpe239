
We present the results of several machine
learning tasks designed to predict rhetori-
cal relations that hold between clauses in
discourse. We demonstrate that organizing
rhetorical relations into different granularity
categories (based on relative degree of detail)
increases average prediction accuracy from
58% to 70%. Accuracy further increases to
80% with the inclusion of clause types. These
results, which are competitive with existing
systems, hold across several modes of written
discourse and suggest that features of informa-
tion structure are an important consideration
in the machine learnability of discourse.
1 