
This paper presents efficient algorithms for
expected similarity maximization, which co-
incides with minimum Bayes decoding for a
similarity-based loss function. Our algorithms
are designed for similarity functions that are
sequence kernels in a general class of posi-
tive definite symmetric kernels. We discuss
both a general algorithm and a more efficient
algorithm applicable in a common unambigu-
ous scenario. We also describe the applica-
tion of our algorithms to machine translation
and report the results of experiments with sev-
eral translation data sets which demonstrate a
substantial speed-up. In particular, our results
show a speed-up by two orders of magnitude
with respect to the original method of Tromble
et al (2008) and by a factor of 3 or more
even with respect to an approximate algorithm
specifically designed for that task. These re-
sults open the path for the exploration of more
appropriate or optimal kernels for the specific
tasks considered.
1 