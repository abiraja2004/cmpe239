
When faced with the task of building machine
learning or NLP models, it is often worthwhile
to turn to active learning to obtain human an-
notations at minimal costs. Traditional active
learning schemes query a human for labels of
intelligently chosen examples. However, hu-
man effort can also be expended in collecting
alternative forms of annotations. For example,
one may attempt to learn a text classifier by
labeling class-indicating words, instead of, or
in addition to, documents. Learning from two
different kinds of supervision brings a new,
unexplored dimension to the problem of ac-
tive learning. In this paper, we demonstrate
the value of such active dual supervision in
the context of sentiment analysis. We show
how interleaving queries for both documents
and words significantly reduces human effort
? more than what is possible through tradi-
tional one-dimensional active learning, or by
passive combinations of supervisory inputs.
1 