
We present an annotated corpus of conversa-
tional facial displays designed to be used for
generation. The corpus is based on a record-
ing of a single speaker reading scripted out-
put in the domain of the target generation
system. The data in the corpus consists of
the syntactic derivation tree of each sentence
annotated with the full syntactic and prag-
matic context, as well as the eye and eye-
brow displays and rigid head motion used
by the the speaker. The behaviours of the
speaker show several contextual patterns,
many of which agree with previous findings
on conversational facial displays. The cor-
pus data has been used in several studies ex-
ploring different strategies for selecting fa-
cial displays for a synthetic talking head.
1 