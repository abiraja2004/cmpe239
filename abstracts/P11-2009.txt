
This paper introduces a new training set con-
densation technique designed for mixtures
of labeled and unlabeled data. It finds a
condensed set of labeled and unlabeled data
points, typically smaller than what is obtained
using condensed nearest neighbor on the la-
beled data only, and improves classification
accuracy. We evaluate the algorithm on semi-
supervised part-of-speech tagging and present
the best published result on the Wall Street
Journal data set.
1 