
We present a pilot study of word-sense an-
notation using multiple annotators, relatively
polysemous words, and a heterogenous cor-
pus. Annotators selected senses for words in
context, using an annotation interface that pre-
sented WordNet senses. Interannotator agree-
ment (IA) results show that annotators agree
well or not, depending primarily on the indi-
vidual words and their general usage proper-
ties. Our focus is on identifying systematic
differences across words and annotators that
can account for IA variation. We identify three
lexical use factors: semantic specificity of the
context, sense concreteness, and similarity of
senses. We discuss systematic differences in
sense selection across annotators, and present
the use of association rules to mine the data
for systematic differences across annotators.
1 