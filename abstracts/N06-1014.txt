
We present an unsupervised approach to
symmetric word alignment in which two
simple asymmetric models are trained
jointly to maximize a combination of
data likelihood and agreement between
the models. Compared to the stan-
dard practice of intersecting predictions of
independently-trained models, joint train-
ing provides a 32% reduction in AER.
Moreover, a simple and efficient pair of
HMM aligners provides a 29% reduction
in AER over symmetrized IBM model 4
predictions.
1 