
Spoken dialogue managers have benefited
from using stochastic planners such as
Markov Decision Processes (MDPs). How-
ever, so far, MDPs do not handle well noisy
and ambiguous speech utterances. We use a
Partially Observable Markov Decision Pro-
cess (POMDP)-style approach to generate
dialogue strategies by inverting the notion of
dialogue state; the state represents the user?s
intentions, rather than the system state. We
demonstrate that under the same noisy con-
ditions, a POMDP dialogue manager makes
fewer mistakes than an MDP dialogue man-
ager. Furthermore, as the quality of speech
recognition degrades, the POMDP dialogue
manager automatically adjusts the policy.
1 