 lexical rule example. 
from our perspective, since the use of defaults to encode information that does not 
persist beyond the lexicon requires uch an interface in any case. The cost of the fully 
monotonic version of lexical rules is that the complete history of rule application has 
to be accessible, ither explicitly, as with Riehemann's approach, or implicitly (e.g., via 
junk slots). However, our current approach does mean that some potential applications 
of lexical rules are precluded, which we discuss further in Section 7. 
In contrast with Meurer's notation, it is not possible to straightforwardly compile 
out our lexical rules into equivalent rules that do not use defaults, even when TFSs 
rather than TDFSs are considered. Consider the abstract example shown in Figure 10. 
To state this using conventional lexical rules would be extremely complex, since it 
would require a whole series of rules to deal with the possible values of F, each with 
negative conditions to prevent them applying incorrectly. Contrast this to Meurer's ap- 
proach, where all inputs would give a result where F had the value a. Essentially the 
difference is that whereas our approach can be paraphrased as"transfer all information 
for a feature F that does not conflict with information on the output," Meurer's deft- 
nition can be paraphrased "transfer all values for a feature F unless any information 
is stated about F." The example shown in Figure 9 illustrates one case for which our 
approach leads to desirable results. Another example arises when inflection is imple- 
mented using lexical rules, as with the example of the Third Singular Verb Formation 
rule (Figure 7). With conventional lexical rules it is impossible to carry over informa- 
tion about the type of the input to the output (unless the rule is totally monotonic 
in operation, in which case it is equivalent to the use of simple subsumption-based 
inheritance). Therefore lexical types cannot persist after inflectional rules are applied, 
unless the rule is split so that one subrule applies to each type (see, for example, 
Copestake \[1992\] for further discussion). This class of problems is avoided with our 
current approach. 
In other respects, this version of lexical rules is intermediate in expressivity be- 
tween simple inheritance and conventional lexical rules. It is more powerful than 
simple inheritance, because the "input" and "output" types of lexical rules do not 
have to be in a fixed inheritance hierarchy, and recursive application of rules is pos- 
sible. Consider for example, an alternative encoding, using simple inheritance, of the 
Causative-Inchoative rule shown in Figure 9. This requires that a type caus-or-inch- 
502 
Briscoe and Copestake Lexical Rules 
verb exists that has intrans-verb and trans-caus-verb as subtypes. However, in order 
to encode further alternations, these types themselves have to have subtypes corre- 
sponding to each rule. For example, if the goal PP in John galloped the horse to the 
barn / The horse galloped to the barn is encoded as an argument, hen intrans-verb and 
trans-caus-verb oth have to have subtypes for the goal PP and this configuration 
has to be replicated for all subtypes of intrans-verb, such as intrans-movt-verb. This 
quickly leads to highly complex type hierarchies, ince the configuration of the types 
encodes "reachability," aswell as inheritance. Furthermore, ncoding lexical rules by 
inheritance does not allow for any notion of semiproductivity of a rule. Individual 
exceptions to a rule can be encoded, for example, if run is encoded as an intrans-verb 
and not specified to be of the higher type caus-or-inch-verb, then causative forms of 
run will not be generated. But this leaves it as an accident that, at least for this class 
of movement verbs, it is generally the causative rather than the inchoative form that 
is impossible or marked. We will discuss how we can exploit he asymmetry of TDFS 
lexical rules to allow for semiproductivity n Section 6. 
Our approach to lexical rules is, on the other hand, less powerful than conventional 
HPSG-style lexical rules because it is not possible to arbitrarily "rearrange" material 
between the input and the output structures: a value that is present on a particular 
path in the input can either be unified with a value on the same path in the output 
structure, or be overridden, but it cannot be moved to a new position within the 
output feature structure. This approach therefore shares some of the restrictions of 
simple inheritance with respect o encoding potentially recursive operations, and we 
discuss the implications of this further in Section 7. 
It is clear that the notion of lexical rules that we have presented encodes omething 
like "type reachability" rules for lexical types. This is an inherently more restricted 
notion than that of HPSG-style lexical rules, which can also encode arbitrary operations 
on list-valued features. A consequence of this more restricted notion is that lexical rules 
cannot be used to rearrange the order of list-valued features and cannot be applied 
recursively in a manner that makes such lists unbounded. In fact, since lexical rules 
simply relate lexical types predefined in the lexicon, they cannot increase the generative 
capacity of the overall system in which they are embedded. 4 
In Section 5, nevertheless, we show that an insightful account of one rule that 
would be encoded via SUBCAT list manipulations can be stated in this more restrictive 
framework. In Section 7 we consider the extent o which our approach can capture 
other putative lexical rules and argue for a clearer distinction between lexical rules 
and (unary) syntactic rules. 5 
5. Dative Constructions 
Lascarides, Copestake, and Briscoe (1996) present an account of the dative alterna- 
tion that illustrates the utility of the TDFS framework for encoding defeasible l xical 
semantic entailments in terms of Dowty's (1989) proto thematic roles, and the interac- 
4 We omit a formal proof as this would require more detailed specification of the syntactic omponent 
than is warranted in the rest of the paper. 
5 An alternative method of exploiting the TDFS formalism to encode rules was mentioned in L&C 
(page 87) and has been explored by Malouf (1999). This technique uses the TDFS description language 
to allow a very succinct statement of rules that use coindexation to relate their input and output: 
effectively, paths in the input and output structure can be specified to be coindexed by default. The 
expanded rules have the same properties as the lexical rule variants described by Copestake (1992) or 
Riehemann (1993). Thus, in terms of the current paper, this encoding is a way of improving the 
representation f syntactic rules. 
503 
Computational Linguistics Volume 25, Number 4 
tion of these with the dative alternation (e.g., Green 1974). This account draws heavily 
on Goldberg's (1995) analysis of dative in construction grammar (e.g., Fillmore, Kay, 
and O'Connor 1988), and attempts to integrate her insights and general approach into 
a more formally explicit constraint-based framework. In this section, we extend this 
account by embedding the account in a syntactic framework based on UCG (Zeevat, 
Klein, and Calder 1987), as integrated with Dowty's approach to thematic roles and 
extended by Sanfilippo (1990, 1992, 1993), and augmented with linking theory (Chang 
1995). 6This allows us to utilize TDFS lexical rules in an insightful way to express an 
alternation otherwise naturally treated in terms of rearrangement of a list-valued SUB- 
CAT feature. In Section 8 we go on to propose a probabilistic interpretation f TDFS 
lexical rules that allows us to capture the semiproductivity of the dative alternation, 
and other lexical rules. 
Following Goldberg (1995) we argue that there is a family of dative constructions 
that exhibit he same syntactic properties and related semantic properties, exemplified 
in (6). 
(6) a. Mary gave Joe a present 
b. Joe painted Sally a picture 
c. Mary promised Joe a new car 
d. He tipped Bill two pounds 
e. The medicine brought him relief 
f. The music lent the party a festive air 
g. Jo gave Bob a punch 
h. He blew his wife a kiss 
i. She smiled herself an upgrade 
The core dative construction i volves a volitional agent and willing recipient and 
carries the entailments hat the agent causes the recipient to receive the object denoted 
by the patient/affected-object argument, as in (6a). Under this interpretation, (6b) 
involves a shift in meaning where the recipient may or may not receive the affected- 
object, but the agent acts with this intention, whilst (6c) involves a similar shift as the 
act of transfer is intended to take place at some point in the future and may not in 
fact occur. (6d), unlike the previous examples, does not have an oblique counterpart. 
The remaining examples all appear to involve metaphorical or idiomatic extensions to 
the core dative construction. 
We represent the difference in the basic (abstract) meaning of the dative construc- 
tion in (6a) and (6b) in terms of entailments associated with proto thematic roles, so 
that agent becomes p-agt-cause-transfer in (6a) and p-agt-cause-make-intend-transfer 
in (6b). There are lexical rules that relate the dative construction with the alternative 
oblique complementation patterns involving to and for PP arguments, respectively, 
which alter the proto-agent role of a "creation" verb such as paint from p-agt-cause- 
make to p-agt-cause-make-intend-transfer. We abbreviate the different entailments 
(willingness and successful transfer) concerning the first object in (6a) and (6b) as 
6 Nevertheless, the general pproach tolexical rules is equally compatible with HPSG, combinatory 
categorial grammar (e.g., Steedman 1996), tree adjoining rammar (e.g., Joshi 1987) or indeed any 
grammatical theory embeddable in the T(D)FS representation language. 
504 
Briscoe and Copestake Lexical Rules 
- dative-verb 
PHON : phon 
SYN:\ [  RESULT , \[ RESULT : \[RESULT " s s i g n  ACTIVE npsig ACTIVE npsign J i l l  
L ACTIVE : npsign 
. . . .  \[ t~-a~,t-caus/p-agt-cause-transfer \] / verD-reJ / / ~Vl~NT / 
SEM : < \[ Eii~RN~;~':!a~RGb: i: i~A~EbGIN/~z-?ebj. 1-recip\]!'  
L :Y J L  : J 
Figure 11 
The dative type constraint. 
oblique-transfer-verb 
PHON : phon 
\[ \[ \[RESULT:ssign \ ] \ ]  1 RESULT : RESULT : \[ ACTIVE npsign j
SYN, ACTIVE npsign 
L ACTIVE : pptosign 
p-agt-cause-transfer \] \[ p-pat-aff-obj \] \[ p-obl-recip \] 
SEM:< \[\[EVENTVerb'rel e\] '  EVENT:e | , \ ]EVENT:e / . |EVENT:e  / > 
: ARG:x J LARG:y \] LARG:z \] 
Figure 12 
The oblique-transfer type constraint. 
recipient and benefactive, respectively. It should only be necessary to state the form 
of the dative construction once. Furthermore, it should not be necessary to say that 
verbs of creation, such as paint, are lexically ambiguous between two- and three-place 
predicates; rather, it is participation in the dative construction itself that creates the 
third benefactive argument for these inherently two-place predicates. We also assume 
without explicit argument here that the for PP variant is produced by a lexical rule 
introducing the optional PP. 
In the TDFS framework we can state the semantics of the dative construction 
independently of specific lexical heads (or arguments) as a type constraint on the set of 
dative lexical items. The type constraint expressed as a TDFS in Figure 11 achieves this 
and utilizes default specification of the proto-roles on the arguments so that specific 
verbs can override the core entailments. This constraint stipulates that dative verbs will 
necessarily have a p-agt-cause role, but, by default, this will be specialized to p-agt- 
cause-transfer, thus expressing the generalization that the dative construction usually 
implies that some transfer has taken place. Similarly, the role on the proto-patient 
is p-pat-aff-obj by default, since the object will usually be affected, and p-obl-recip 
captures the entailment that the oblique argument usually corresponds to a recipient. 
(We assume that the second object is treated as an oblique \[indirect object\] argument 
in the framework, though nothing particularly rests on this assumption.) 
Most verbs will not be directly specified in the lexicon as being of type dative, 
but will become associated with this type via the lexical rules relating oblique-transfer 
verbs and transitive-creation verbs to it. The type constraints for these source types 
are given in Figure 12 and Figure 13, respectively. (We ignore the issue of how the in- 
formation represented atthese types might be factored between supertypes to capture 
further generalizations concerning verb classes; see, for example, Sanfilippo \[1993\].) 
The two lexical rules required are given in Figure 14. 
505 
Computational Linguistics Volume 25, Number 4 
? trans-create-verb 
PHON phon 
|RESULT: ssign 1 1 SYN : RESULT : L ACTIVE : npslgn j
J ACTIVE npsign i \] : < . /EVENT : e . EVENT: e > SEM \[ EVENT : e L ARG : x ARG : y 
Figure 13 
The transitive-creation type constraint. 
The Dative Lexical Rule 
oblique-transfer-verb .-+ dative-verb 
Create-to-Benef-Dative Lexical Rule 
r dative-verb 
| r verb-rel ~ F D-a~t-cause-make-intend-transfer 1 
trans-create-verb,-~ \]SEM:< \[EVENT:e\]'\[~AV~G NTe .\] 
| F p-pat-aff-obj \] F p-obl-benef 
| |EVENT:e | . |EVENT:e  | > 
L LARG:y J LARG:z J 
Figure 14 
Dative lexical rules. 
These rules can be stated quite simply with reference to the type system for verbs. 
The first rule, which is the core (recipient) Dative rule, is simply stipulated as a "reach- 
ability" relationship between the two types oblique-transfer-verb and dative-verb. 
However, when this rule is applied to a lexical entry of type oblique-transfer-verb, 
the specifications of the proto-roles as p-agt-cause-transfer and p-obl-recip in the result 
will be indefeasible, in contrast o their defeasible status in dative-verb, because they 
are indefeasible in the basic type. We show the input and output TDFSs for a transfer 
verb (give) undergoing this rule in Figure 15. In contrast, the benefactive Dative rule 
specializes the dative type so that the proto-role entailments stipulated override the 
defaults on the type dative-verb. Thus, p-agt-cause-make-intend-transfer overrides p- 
agt-cause-transfer and p-obl-benef overrides p-obl-recip. The effect is that the result 
does not imply that transfer of the affected object was necessarily successful. Figure 16 
shows the input and output for a creation verb (paint) undergoing this rule. Thus these 
rules correct predict that while (6a) implies successful transfer, (6b) only implies that 
transfer was intended. 
The verb types shown so far do not make explicit the linking between proto-role 
arguments and the semantic indices of syntactic arguments. In HPSG and construction 
grammar, such linking is provided on a construction-by-construction basis in the type 
definitions for each construction/sign. The standard way of linking arguments in a 
(T)FS framework is to make the semantic indices of the syntactic arguments reentrant 
with the indices representing the arguments of the (proto) thematic roles. However, 
if we adopted this approach, default unifying linked versions of oblique-transfer- 
verb with dative-verb would result in the incoherent structure shown in Figure 17 
because the reentrancies in the input type description are consistent with the output 
type description, and are thus incorrectly preserved. 
506 
Briscoe and Copestake Lexical Rules 
In )ut: 
oblique-transfer-verb 
PHON : give 
SYN : RESULT , RESULT : \[ ACTIVE : npsign 1 
L ACTIVE npsign 
k ACTIVE : pptosign 
,  WNT:  
: e LARG : x ARG : y \ [ARG : z 
Output: 
dative-verb 
PHON : give \[ 1\] SYN : RESULT : \[ ACTIVE npslgn \] L ACTIVE npsign ACTIVE npsign 
\[ p-agt-cause-transfer \] \[ p-pat-aff-obj \] \[ p-obl-recip \] 
SEM:< \[EVENTgive'rel e \ ] '  EVENT:e / , |EVENT:e  | . |EVENT:e  
: ARG; x J L ARG: y J LARG: z 
Figure 15 
give 
In 3ut: 
? trans-create-verb 
PHON : paint 
SYN \[RESULT \[RESULT:ssign \ ] \ ]  : ACTIVE : npsign J 
: L ACTIVE npsign 
\] W .V NT:o :< EVENT:e ' ' L ARG : x 
~ -pat-aff-obj 1 VENT : e 
ARG : y 
Output: 
dative-verb 
PHON : paint 
I RESULT: ssign 1 \] \] 
SYN. RESULT: IRESULT: \[ACTIVE: npsign\] / / 
L ACTIVE : npsign J | 
ACTIVE : npsign J . 
r " " r 1 ~ r v-a~t-cause-make-intend-transfer 
SEM:< / ~ .~ e e / ' /~V~NT : e 
' : ~ L ARG: x 
r p-pat-aff-obj r p-obl-benef \] 
\ ]EVENT:e  ? iEVENT:e  | > 
L ARG: y L ARG: z J 
Figure 16 
paint 
There are ways  in which we could extend the formal ism to avoid this problem, 
for instance by al lowing specification of inequalities (Carpenter 1992), which could be 
used to explicitly prevent inappropriate coindexation (see Lascarides and Copestake 
\[1999\] for inequalit ies in the TDFS framework).  However ,  for the purposes of link- 
ing, this restriction on the expressivity of lexical rules is a virtue rather than a vice: 
Pinker (1989) argues on quite independent  grounds that l inking rules should apply 
507 
Computational Linguistics Volume 25, Number 4 
? dative-verb 
PHON : phon 
\[ r ss' n  CTIV SYN : : L npslgn\[\] 
L ACTIVE npsign F~ 
ACTIVE : npsign \[\] 
F verb-rel \] F p-agt-caus/p-agt-cause-transfer" 
:< , \[EVENT:e SEM \[EVENT:ej \[ARG: \[\] 
\[ ~?P~I~'p eat'aff'?b j \ ] ~ A R G :  \[  J' \[ p-obl/p-obl-recip " A R G :  EVENT : e\[\] > 
Figure 17 
Incoherent linked dative TDFS. 
after lexical rules so that all lexical entries are subject o the same linking constraints. 
By factoring linking constraints out of the type constraints on specific constructions 
we can eliminate redundancy and explicitly express the appropriate linking gener- 
alizations. Chang (1995) follows Wechsler (1991) and Davis (1996) in assuming that 
linking generalizations are captured via constraints pecified as TFSs, but makes the 
assumption that linking applies after lexical rule application. She shows how linking 
generalizations can be captured within the TDFS framework assuming the linguistic 
framework of UCG/construction grammar and proto thematic roles outlined above. 
By reorganizing the semantic type hierarchy to take account of the distinction between 
internal and external causation (see Levin and Rappaport Hovav \[1995\]), Chang is able 
to define 11 partly defeasible verbal linking constraints, each specifying the link be- 
tween one thematic role and one argument position, correctly linking monadic, dyadic, 
and triadic predicates that may undergo causative-inchoative, passive, and/or dative 
alternations by persistent default unification of all linking constraints with each dis- 
tinct basic and derived verbal type. Thus, our approach to lexical rules is similar to that 
of Pinker (1989) in that all basic and derived lexical entries are subject o a few gen- 
eral linking constraints that coindex syntactic arguments with appropriate proto-roles. 
However, in common with Goldberg (1995), we adopt the position that such rules are 
not fully reducible to operations on semantic representations, but rather concern the 
interplay of syntax and semantics in (bounded ependency) constructions. 
Verbs such as promise in (6c) are treated as a subclass of transfer verbs, which we 
call future transfer verbs, defined by a subtype of oblique-transfer-verb altering the 
proto-role ntailments analogously to the benefactive case already discussed, so that no 
entailment of actual transfer is made. If the source type description is modified in this 
fashion, the main dative lexical rule will apply and produce an output TDFS in which 
the dative type defeasible proto-role ntailments are overwritten to something like p- 
agt-cause-intend-fut-transfer and p-pat-benef, respectively. Thus, all that is required 
is an extra source type description for this semantic subclass of verbs to produce 
correct behavior. 
The verb tip in (6d) is an example of a small class of verbs (also including envy), 
which show that dative variants can exist without an oblique "source." In an approach 
that generated erived entries strictly from basic source entries, these cases would be 
problematic. However, in an approach such as ours where lexical rules relate inde- 
pendently defined (specialized) type descriptions, there is no prediction that output 
types of lexical rules cannot be basic types for some verbs. We can simply treat tip 
and similar cases as basic dative verbs and alter the defeasible proto-role ntailments 
508 
Briscoe and Copestake Lexical Rules 
dative-met-verb 
PHON : phon 
SYN : I RESULTL ACTIVE : npsignL\[ RESU T : \[ RESULT ~ ss ignACT IVE  npsignACTIVE npslgn 1\]\]\] 
F verb-rel \] Fp-agt-caus/p-agt-cause-met-transfer" 
:< , |EVENT:e SEM LEVENT:e. LARG:x 
EVENT ~ e . EVENT: e > 
ARG : e' ARG : z 
Figure 18 
Metaphorical dative type constraint. 
of the dative type as appropriate. Thus, we make no prediction that the set of dative 
verbs will be a subset of the set of oblique verbs. 
Goldberg (1995) argues that (6e) and (6f) are licensed by a metaphorical extension 
of the transfer elation by which causal events are viewed as transfers. Causing an 
effect in an entity is understood as transferring that effect to it. We capture this by 
altering the entailments a sociated with verbs such as lend by the proto-roles specified 
by oblique-transfer-verb using a lexical rule that creates an entry of a sister type 
met-oblique-transfer-verb that specifies different proto-roles. The Dative lexical rule 
would also apply to this subtype, capturing the fact that this metaphorical extension 
in the dative construction parallels a similar extension of the same verb set in the 
oblique to prepositional phrase construction. 
In contrast, (6g) and (6h) provide evidence that certain quasi-idiomatic expressions 
need to be associated irectly with dative-sign as they have no counterparts in such 
oblique expressions. We assume that (quasi) idioms are best represented assubtypes of 
lexical signs in which not only the syntactic head but also other arguments are severely 
constrained in terms of lexical selection. Thus Goldberg claims the quasi-idiomatic 
expressions in (6g) and (6h) are licensed by a metaphor that involves understanding 
actions intentionally directed at another person as being entities transferred to that 
person. As a first approximation, we might represent this process in terms of the 
subtype of dative-verb shown in Figure 18, in which we have overridden the default 
proto-role specifications with entailments specific to the metaphor, which we assume 
also serve to constrain the range of acceptable arguments o the (transfer) verb. 
Finally, (6i) demonstrates that reflexive datives can sometimes be formed from 
intransitive verbs. The semantic restrictions on the source for such constructions are 
not entirely clear to us, however, all the putative similar examples to the attested (6i) 
seem innovative and much less conventionalized than the core dative examples. It
would be straightforward to introduce a lexical rule mapping intransitive verbs to the 
dative construction. However, the relative productivity of this putative rule should 
be represented as being much lower than the two rules discussed above. Nothing 
in the representation we have presented so far equips us to deal with the issue of 
(semi)productivity which also arises with the two rules introduced earlier; consider 
the famous example of donate, which does not undergo the dative alternation although 
it is uncontroversially an oblique transfer verb. In the next section we consider this 
issue in detail. 
509 
Computational Linguistics Volume 25, Number 4 
6. Semiproductivity and Probabilistic TDFS Grammar 
The search for a fully productive statement ofverb alternations such as dative has led 
to an increasingly semantic perspective on such rules. However, while a reasonable 
case can be made that the conditions on the rules introduced in Figure 14 express 
necessary conditions for their application, they do not capture sufficient conditions 
because of the existence of semantically similar nonalternating verbs, such as donate 
as opposed to give, or create as opposed to paint, as (7a) and (7b) illustrate. 
(7) a. *The president donated the club a trophy 
b. *The architect created them a bridge 
Pinker (1989) argues that so-called broad semantic lasses of the type identified in the 
dative rules given above (i.e., creation or transfer verbs) provide necessary conditions 
for lexical rule application, but that narrow class lexical rules should be specified 
breaking down such rules into a number of fully productive subcases. In the attempt to 
define such subcases Pinker is forced to make subtle and often unintuitive distinctions, 
and to claim that the meaning components involved are features of universal grammar 
to which the grammars of any language may be sensitive. For example, in attempting 
to differentiate he dative alternating and nonalternating subclasses in (8a) and (8b), 
Pinker (1989, 110-111) characterizes those in (8a) as "verbs of continuous imparting 
of force in some manner causing accompanied motion" and those in (8b) as "verbs of 
continuous causation of motion ... in a deictically-specified direction." 
(8) a. *John dragged/pulled Bill the computer / the computer to Bill 
b. John brought/carried/took Bill the computer / the computer to Bill 
c. John pushed Bill his beer / ?calculator / *computer 
d. John slid Bill his beer / ?calculator / *computer 
Furthermore, the continuous nature of force imparted seems crucial to the acceptability 
of dative with the first class: so (8c) is more acceptable, the lighter the affected object 
and the more plausible it is to construct a scenario in which push is synonymous with 
slide, as in (8d). 
Notwithstanding the subtle distinctions Pinker makes and the often very tiny size 
of the narrow verb classes he identifies, there remain exceptions to his generalizations. 
For example, in British English, which is generally slightly more liberal with respect to 
the dative alternation than American English, the examples in (9a) and (9b) are pairs, 
classified in the same narrow class by Pinker, where one is acceptable in the dative 
and one is not. 
(9) a. John designed / *created them a bridge 
b. I picked / *indicated her a dress 
Such dialectal disparities would be less problematic f they applied uniformly to nar- 
row classes but instead they appear to be insensitive to Pinker's classifications. In
addition, Pirelli, Ruimy, and Montemagni (1994) and Nicholls (1995) document cases 
where Pinker's narrow classes do not generalize to equivalent alternations in Italian 
and French, respectively; demonstrating that cross-linguistic disparities are similarly 
510 
Briscoe and Copestake Lexical Rules 
insensitive to putative narrow classes. More generally, Pinker's notion of a fully pro- 
ductive narrow-class lexical rule is falsified by many examples cited in Boguraev and 
Briscoe (1989), Levin (1992), and Sch/~tze (1997). We conclude that the program of 
treating all exceptions to dative as systematic, as opposed to accidental or idiosyn- 
cratic (Wasow 1980), fails for dative movement, and will, we suspect, fail for most 
verb diathesis alternations. Therefore, it is not possible to characterize such rules as a 
fully productive generative operation. 
Within the generative tradition of work on lexical rules, the only alternative to 
treating such rules as fully productive generalizations is to treat them as redundancy 
rules of some form (e.g., Jackendoff \[1975\] and see the discussion in Section 2). How- 
ever, this approach does not account for the semiproductive nature of such rules. For 
example, Pinker notes with respect o the dative alternation that a variety of recent 
nonce verbs readily undergo dative because they are clearly members of the commu- 
nication subclass of transfer verbs, as (10a) illustrates. 
(10) a. John faxed / xeroxed / emailed his colleagues a copy of the report 
b. Sun donated us a bunch of computers 
c. John explained me the problem 
d. He stripped him the ball 
A redundancy rule only relates existing lexical entries to achieve abbreviation i the 
statement of the lexicon. It cannot be generatively applied to nonce usages. Similarly, 
the examples in (10b), (10c), and (10d) are all attested uses of the dative that violate 
putative (narrow-class) morphological or semantic onstraints on its application from 
Pinker (1989, 155-157). The existence of creative or analogous application to nonce 
usages and attested exceptions to the narrow-class rules makes the redundancy rule 
approach unsatisfactory, at least, when formalized as a purely abbreviatory device (see 
Section 2 above). 
The search for narrow classes and full productivity seems futile for rules of verb 
alternation because such rules are inherently semiproductive in the same manner that 
derivational rules are often characterized assemiproductive (e.g., Bauer 1983). Instead, 
we argue, following Goldberg (1995), who in turn is influenced by theories of semipro- 
ductivity developed for morphology, that rules of verb alternation are sensitive to both 
type and token frequency effects that determine language users' assessments of the de- 
gree of acceptability of a given derived form and also their willingness to apply a rule 
in producing or interpreting a novel form. Bauer (1983, 71f.), in supporting the view 
that lexical rules should be treated as fully productive generative rules analogous to 
those employed in syntactic description, argues that it is this greater "item-familiarity" 
of lexical items that allows judgements of relative novelty/conventionality to be built 
up. He points out that there are simply too many combinatoric possibilities at the 
sentential level for the frequency of particular combinations to be assessed with any 
confidence by a language user. However, in the case of words and, we might add, 
idioms, the range of possibilities, though large, is not so great that judgements of 
novelty based on frequency of use cannot be acquired. Bauer argues, therefore, that 
accounting for semiproductivity s an issue of performance, not competence. There is 
considerable evidence that language users are very sensitive to the relative frequency 
of variant forms and senses of lexical items. Such assumptions underlie influential 
theories of language variation and change (e.g., Labov 1972) and psycholinguistic 
accounts of preferences and misinterpretation during language comprehension (e.g., 
Kelly and Martin 1994). 
511 
Computational Linguistics Volume 25, Number 4 
The frequency with which a given word form is associated with a particular lexical 
entry (i.e., sense or grammatical realization) is often highly skewed; Church and Mer- 
cer (1993) point out that a model of part-of-speech assignment in context will be 90% 
accurate (for English) if it simply chooses the lexically most frequent part-of-speech for 
a given word. In the LOB corpus, there are about 18 times as many instances of believe 
in the most common subcategorization class (sentential complement) as in the four 
least common classes combined, and other multiple-complement-taking verbs show 
similar strong skews (e.g., Briscoe, Copestake, and Boguraev 1990). In the absence of 
other factors, it seems very likely that language users utilize frequency information to 
resolve indeterminacies in both generation and interpretation. Such a strategy is com- 
patible with and may well underlie the Gricean maxim of manner, in that ambiguities 
in language will be more easily interpretable if there is a tacit agreement ot to utilize 
abnormal or rare means of conveying particular messages. We can model this aspect 
of language use as a conditional probability that a word form will be associated to a 
specific lexical entry, derived using a maximum likelihood estimator: 7 
freq(lexical-entry with word-form) 
Pr?b(lexical-entry I w?rd-f?rm)= freq(word-form) 
This proposal is not novel and is the analogue of proposals to associate proba- 
bilities with initial trees in, for example, a lexicalized tree adjoining rammar (Resnik 
1992; Schabes 1992). However, it differs from recent proposals by, for example, Brew 
(1995), to associate probabilities with values on paths in a TFS formalism underlying 
HPSG, as the probabilistic nformation is much less fine-grained. We associate a single 
probability with each complete TDFS that represents a lexical entry. In a probabilistic 
grammar based on this approach, the probability of a derivation must depend in part 
on details of the grammatical pproach adopted. In a categorial framework it may be 
there are only mutually exclusive schemata for combining lexical entries into phrasal 
and clausal signs, so the probability of a given derivation can be treated as the product 
of the probability of the lexical entries utilized in that derivation. In this case, for word 
forms i in sentence: 
Prob(sent-interp) = II(lex-entry { word-form/) 
i 
In frameworks that incorporate alternative competing syntactic rule schemata or op- 
erations, it might be necessary to associate probabilities with such rules and treat the 
probability of a derivation as the combined product of the probability of the syntac- 
tic operations applied and the lexical entries utilized (e.g., Schabes 1992). Under this 
formulation, the conditional probability of a lexical entry given a word form is inde- 
pendent of the larger context in which the word occurs (except o the extent hat this 
is encoded in the lexical entry). This approximation ties the number of probabilistic 
parameters tobe estimated by the language user to the size of the user's lexicon and 
is thus the probabilistic analogue of the item-familiarity approach described above. It 
7 In what follows we assume familiarity with the basic axioms of probability theory and with statistical 
estimation (e.g., Box and Tiao 1973). We should emphasize that we are proposing a probabilistic version 
of a grammatical theory developed in the TDFS framework, not as a solution to practical engineering 
problems of parsing, but as a theoretical ccount of the item-familiarity view of semiproductivity. We 
doubt that this theory is psycholinguistically accurate in the sense that language users literally compute 
probabilities and abide by the axioms of probability theory. However, probability theory provides a
precise and clear framework in which to represent estimates of the relative likelihood of events. 
512 
Briscoe and Copestake Lexical Rules 
trans-caus-verb 
PHON : fax \[- 
SYN : / RESULT 
/ 
L ACTIVE 
fax-rel SEM: < EVENT 
RESULT : ssign \] 1 ACTIVE : npslgn \[\] 
npsign \[\] 
\] \[ p-agt-causel P p-pat-aff-obj\] 
,\[EVENT:e \[, \]EVENT:e > 
e \[ARG : \[\] J LARG: \[\] 
create/transfer-lexeme-fsm(trans(0.2), oblique-tr(0.3)...) 
Figure 19 
Lexeme for fax. 
says, in effect, that users can track the relative frequency of words/lexemes but not of 
(most) phrases or sentences. 
We assume that lexical probabilities are acquired for both basic and derived lexi- 
cal entries independently of any lexical rules used to create derived entries. Thus we 
make no claim that a derived entry will necessarily be less frequent than a basic one. 
It might seem that this assumption commits us to a "full entry" theory of the lexicon 
(e.g., Aronoff 1976; Jackendoff 1997a) in which all possible words are present; that is, 
the consequences of lexical rules are precomputed. In the limit, the full entry theory 
cannot be correct because of the presence of recursive lexical rules such as derivational 
rules of re-, anti-, or great- prefixation in words such as rereprogram, anti-anti-missile or 
great-great-grandfather. Instead we adopt an intermediate position in which basic entries 
are augmented with a representation f the attested lexical rules that have applied to 
them and any such derived chains, where both the basic entry and these "abbreviated" 
derived entries are associated with a probability. One way of formalizing and imple- 
menting this approach is to adopt the covariation technique of Meurers and Minnen 
(1997) discussed in Section 2, in which finite-state machines (FSMs) representing the 
possible lexical rules that can apply to each basic lexical entry are associated with 
equivalence classes of such entries and the entry is simplified to information common 
between the variants. If we assume a precompiled representation f this form, con- 
ditional probabilities that a word form will be associated with a particular (basic or 
derived) entry can be associated with states in the FSM, as illustrated in Figure 19. 
In this representation, the states of the FSM, which have been given mnemonic 
names corresponding to their types, are each associated with a probability represent- 
ing the relative likelihood that fax will be associated with the derived entry that results 
from applying the rule to the source entry (the probabilities shown here are purely 
for illustrative purposes). We call this representation the lexeme for a given word. 
Figure 20 shows part of the corresponding FSM explicitly. Note that there are states 
with no associated probabilities, reflecting possible but unattested usages. The topol- 
ogy of the FSM associated with a given word may be shared with other words, but the 
specific probabilities associated with the states representing lexical entries will be id- 
iosyncratic, so that the each lexeme representation must minimally encode the unique 
name of the relevant FSM and a probability for each attested state/lexical entry as 
shown in Figure 19. If the derived form is irregular in some way, then the exceptional 
information can be stipulated at the relevant state, and the feature structure calculated 
by default unifying the specified information with the productive output of the lexical 
rule. For example, if beggar is treated as derived by the agentive -er rule (which is 
reasonable synchronically), then the irregular morphology can be stipulated and will 
override the predicted begger. 
513 
Computational Linguistics Volume 25, Number 4 
t r a ~ l  iq@ue_tr 
F create-dative-i ~ r 0.3 
trans benef-dative 
0.2 
Figure 20 
FSM for fax. 
dative-lr 
recip-dative 
use-subst-lr 
substance 
0.84 
Figure 21 
Lexeme for lacquer. 
agent ~ e r s o n  
S / 0.9 instrument-er 
~ O ~ O 
tr~ns instrument 
result-lr resultative 
0.01 
The resulting FSM is not equivalent to a Markov model because probabilities on 
states represent output probabilities and not transition probabilities in the machine. 
In addition, since the probabilities encode the relative likelihood that a given word 
form will associate with a particular lexical entry, the set of probabilities on states of 
an FSM will not be globally normalized. One FSM will represent the application of 
both rules of conversion (zero affixation) and rules of derivation to a given lexeme 
and the latter will change the form of the word, and thus participate in a different 
distribution. See for example, Figure 21, which is intended to cover the noun and 
verb lacquer, plus the derived form, lacquerer (with agentive and instrument readings 
taken as distinct). Thus, probabilities on states in FSMs are not required to sum to one, 
though conditional probabilities of the set of possible (attested and unattested) lexical 
entries for a given word form are. 
One immediate problem with the proposed representation is that certain rules may 
apply cyclically or recursively, creating an infinite set of entries. The FSM encoding 
devised by Meurers and Minnen is specifically developed as a form of precompilation 
compatible with this possibility. The majority of clearly recursive or cyclic rules in 
the literature are derivational, so it is clear from the word form how many times a 
rule has applied. We can extend the probabilistic encoding scheme to allow sets of 
probabilities to be encoded on states annotated with number of affixations (e.g., \[q4, 
\[anti,p1; anti-anti,p2; ...\]\]). We assume for now that rules of conversion, such as most 
verb alternation rules, do not apply cyclically or recursively and discuss apparent 
exceptions in Section 7. 
A second problem with the acquisition of reliable estimates of such probabilities 
for a language user (or implemented parser) is that many possibilities will remain 
514 
Briscoe and Copestake Lexical Rules 
unseen and will, therefore, be unattested. For instance, the fact that donate has not 
been seen in the dative construction may indicate the ungrammaticality of this real- 
ization or merely reflect lack of linguistic exposure to the appropriate dialect, register, 
or whatever. The simple maximum likelihood estimator shown above will assign zero 
probability to unseen events. There are a variety of methods for estimating proba- 
bilistic parameters or smoothing probability distributions that avoid assigning zero 
probability to unseen events. One standard approach assigns a hypothetical single 
observation to each unseen event in a distribution before normalizing frequencies to 
obtain probabilities. This captures the intuition that the more frequent the observation 
of some events in a distribution, the less likely it is that the unseen possibilities will 
occur. Thus, a rare word with only a few observations may be more likely to be seen 
in an alternative realization than a very frequent word that has been observed many 
times in some subset of the possible realizations licensed by the grammar. However, 
all unseen events will be assigned the same probability within each distinct distribu- 
tion and this is at best a gross estimate of their actual distribution. (The technique is
analogous to assuming a uniform prior distribution within the framework of Bayesian 
estimation.) 
In the case of unattested derived lexical entries for a given word form, the relative 
productivity of the lexical rule(s) required to produce the derived entry are the most 
likely source of information to estimate the probability of an unattested derived entry 
given a word form. 8 Within the probabilistic framework presented above lexical rules 
are not directly associated with probabilities. Nevertheless we can represent the relative 
productivity of each lexical rule by calculating the ratio of possible to attested outputs 
for each rule (see Aronoff \[1976\]): 
M Prod(lexical-rule) = 
(where N is the number of attested lexical entries that match the lexical rule input 
and M is the number of attested output entries). This is a very simple estimate of 
productivity, and more complex accounts are considered below. 
The estimate for degree of productivity of a rule can be combined with smoothing 
to obtain a variant-enhanced smoothing method of the type discussed by Church 
and Gale (1991), capable of assigning distinct probabilities to unseen events within 
the same distribution. This can be achieved by estimating the held-back probability 
mass to be distributed between the unseen entries using the basic smoothing method 
outlined above and then distributing this mass differentially by multiplying the total 
mass for unseen entries (expressed as a ratio of the total observations for a given 
word) by a different ratio for each lexical rule. This ratio is obtained by dividing the 
ratio representing the productivity of the lexical rule(s) by the sum of the ratios of the 
lexical rules required to construct all the unseen entries. 
Unseen-pr-mass(word-form) = 
number-of-unattested-entries(word-form) 
freq(word-form)+number-of-unattested-entries(word-form) 
Est-freq(lex-entryi with word-formj) = 
Prod(lri) TT ,~ ~ ,4~ m.~ ~nseen_t,r_mass~wor _ r~,,jj x ~ Prod(lrl),...,Prod(Irn) 
8 An estimate of the relative productivity of a lexical rule would correspond to Goldberg's (1995) notion 
of type frequency, while the conditional probability of a lexical entry being associated with a specific 
word form corresponds to her token frequency. 
515 
Computational Linguistics Volume 25, Number 4 
(where lrl.., lrn are the n lexical rules needed to derive the n unattested entries for 
word-formj). This will yield revised ratios for each given word, which can then be 
normalized to probabilities. 
To make this clearer, consider the use of the probabilities to drive interpretation 
in the case of a nonce usage; for example, a language user faced with an unattested 
realization (in their experience) of fax in a dative construction, such as fax me the 
minutes of the last meeting. Given the assumptions made in the lexeme representation 
in Figure 19, fax may undergo either the benefactive Dative or recipient Dative rules 
to yield a dative realization. These rules would produce either a deputive reading 
where, although the speaker is a beneficiary of the action, the recipient is unspecified, 
or a reading where the speaker is also the recipient of the transfer action. Choosing 
between these rules in the absence of clear contextual information could be achieved 
by choosing the derivation (and thus interpretation) with highest probability. This 
would depend solely on the relative probability of the unseen derived entries created 
by applying these two rules to fax. This would be (pre)computed by applying the 
formulas above to a representation f the lexeme for fax in which ratios represent the 
number of observations of an entry for a given word form over the total number of 
observations of that word form, and unattested entries are noted and assigned one 
observation each: 
create/transfer-lexeme-fsm (trans(~),  oblique-tr (1~0), 
recip-dative (1Y0), benef-dative (1~) . . . .  ) 
Now if we assume that the recipient Dative rule can apply to 100 source entries and 
the resulting derived entries are attested in 60 cases, while the benefactive Dative can 
apply to 1,000 entries and the derived entries are attested in 100 cases, we can compute 
the revised estimates of the probabilities for the unseen entries for fax by instantiating 
the formula for estimated frequency as follows: 
E ' 
Est-freq(fax with recipient-dative) -- ~ x 6~- 100 x 
and similarly for the benefactive-dative case. The resulting ratios can then be converted 
to probabilities by normalizing them along with those for the attested entries for fax. 
In this case, the recipient reading will be preferred as the recipient Dative rule is more 
productive. 
This general approach could be refined in order to take account of Pinker's obser- 
vations concerning narrow-class rules, and already handles the possibility of special- 
ized subcases of more general rules. For example, we could factor the computation of
productivity between subtypes of the input type of a rule and derive more fine-grained 
measures of productivity for each narrow class a rule applies to (assuming the type 
system is not recursive in such a way that the subclasses of the input type are infinite). 
In the case of specialized subcases of lexical rules that apply to a narrower ange of 
lexical items, but yield a more specific interpretation (such as the rules of Meat or Fur 
grinding, as opposed to general Grinding, proposed in Copestake and Briscoe \[1995\]; 
see Section 7), the relative productivity of each rule will be estimated in the manner 
described above, but the more specialized rule is likely to be more productive since 
it will apply to fewer entries than the more general rule. Similarly, in Figure 21, we 
assumed a Use-Substance l xical rule, but a more accurate stimation of probabilities 
might be obtained by considering specialized subclasses. This approach to deriving 
estimates of the productivity of lexical rules is applied to four denominal verb forma- 
516 
Briscoe and Copestake Lexical Rules 
tion rules in Briscoe and Copestake (1996), where the probabilities of the basic and 
derived word forms are estimated from part-of-speech tagged textual corpora. 
The probabilistic approach we have presented is part of a theory of language use 
or performance rather than one of competence orgrammatical representation. As such 
it is not a part of the T(D)FS representation language, which is intended as a general 
formalism in which paradigmatic (lexical) and syntagmatic (syntactic and semantic) 
theories can be encoded or embedded. This probabilistic approach to lexical rules 
integrates neatly with extant proposals to control application of lexical rules efficiently 
within a constraint-based framework, such as those of Meurers and Minnen (1997). 
To our knowledge it is the first attempt to formalize relatively informal accounts of 
semiproductivity based on the item-familiarity view of (morphological) lexical rules. 
As such it serves to highlight a potential difference between genuinely lexical rules 
and unary syntactic rules, such as Adjunct 