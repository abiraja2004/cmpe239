 
In this paper we introduce an automatic sys-tem that generates textual summaries of Inter-net-style video clips by first identifying suitable high-level descriptive features that have been detected in the video (e.g. visual concepts, recognized speech, actions, objects, persons, etc.). Then a natural language genera-tor is constructed using SimpleNLG to com-pile the high-level features into a textual form. The generated summary contains information from both visual and acoustic sources, intend-ing to give a general review and summary of the video. To reduce the complexity of the task, we restrict ourselves to work with videos that show a limited number of ?events?. In this demo paper, we describe the design of the system and present example outputs generated by the video summarization system. 
1 