
Recent ?visual worlds? studies, wherein
researchers study language in context by
monitoring eye-movements in a visual
scene during sentence processing, have re-
vealed much about the interaction of di-
verse information sources and the time
course of their influence on comprehen-
sion. In this study, five experiments that
trade off scene context with a variety of
linguistic factors are modelled with a Sim-
ple Recurrent Network modified to inte-
grate a scene representation with the stan-
dard incremental input of a sentence. The
results show that the model captures the
qualitative behavior observed during the
experiments, while retaining the ability to
develop the correct interpretation in the
absence of visual input.
1 