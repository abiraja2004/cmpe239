
This paper describes discriminative language modeling
for a large vocabulary speech recognition task. We con-
trast two parameter estimation methods: the perceptron
algorithm, and a method based on conditional random
fields (CRFs). The models are encoded as determin-
istic weighted finite state automata, and are applied by
intersecting the automata with word-lattices that are the
output from a baseline recognizer. The perceptron algo-
rithm has the benefit of automatically selecting a rela-
tively small feature set in just a couple of passes over the
training data. However, using the feature set output from
the perceptron algorithm (initialized with their weights),
CRF training provides an additional 0.5% reduction in
word error rate, for a total 1.8% absolute reduction from
the baseline of 39.2%.
1 