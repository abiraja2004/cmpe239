
Tactile maps are important substitutes for vi-
sual maps for blind and visually impaired peo-
ple and the efficiency of tactile-map reading
can largely be improved by giving assisting ut-
terances that make use of spatial language. In
this paper, we elaborate earlier ideas for a sys-
tem that generates such utterances and present
a prototype implementation based on a seman-
tic conceptualization of the movements that the
map user performs. A worked example shows
the plausibility of the solution and the output
that the prototype generates given input derived
from experimental data.
1 