
There has been a proliferation of recent work
on SMT tuning algorithms capable of han-
dling larger feature sets than the traditional
MERT approach. We analyze a number of
these algorithms in terms of their sentence-
level loss functions, which motivates several
new approaches, including a Structured SVM.
We perform empirical comparisons of eight
different tuning strategies, including MERT,
in a variety of settings. Among other results,
we find that a simple and efficient batch ver-
sion of MIRA performs at least as well as
training online, and consistently outperforms
other options.
1 