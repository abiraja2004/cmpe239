
User simulation is frequently used to train
statistical dialog managers for task-oriented
domains. At present, goal-driven simula-
tors (those that have a persistent notion of
what they wish to achieve in the dialog) re-
quire some task-specific engineering, making
them impossible to evaluate intrinsically. In-
stead, they have been evaluated extrinsically
by means of the dialog managers they are in-
tended to train, leading to circularity of argu-
ment. In this paper, we propose the first fully
generative goal-driven simulator that is fully
induced from data, without hand-crafting or
goal annotation. Our goals are latent, and take
the form of topics in a topic model, clustering
together semantically equivalent and phoneti-
cally confusable strings, implicitly modelling
synonymy and speech recognition noise. We
evaluate on two standard dialog resources,
the Communicator and Let?s Go datasets, and
demonstrate that our model has substantially
better fit to held out data than competing ap-
proaches. We also show that features derived
from our model allow significantly greater im-
provement over a baseline at distinguishing
real from randomly permuted dialogs.
1 