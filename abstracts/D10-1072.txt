
In many NLP systems, there is a unidirectional flow
of information in which a parser supplies input to a
semantic role labeler. In this paper, we build a sys-
tem that allows information to flow in both direc-
tions. We make use of semantic role predictions in
choosing a single-best parse. This process relies on
an averaged perceptron model to distinguish likely
semantic roles from erroneous ones. Our system pe-
nalizes parses that give rise to low-scoring semantic
roles. To explore the consequences of this we per-
form two experiments. First, we use a baseline gen-
erative model to produce n-best parses, which are
then re-ordered by our semantic model. Second, we
use a modified version of our semantic role labeler
to predict semantic roles at parse time. The perfor-
mance of this modified labeler is weaker than that
of our best full SRL, because it is restricted to fea-
tures that can be computed directly from the parser?s
packed chart. For both experiments, the resulting se-
mantic predictions are then used to select parses. Fi-
nally, we feed the selected parses produced by each
experiment to the full version of our semantic role
labeler. We find that SRL performance can be im-
proved over this baseline by selecting parses with
likely semantic roles.
1 