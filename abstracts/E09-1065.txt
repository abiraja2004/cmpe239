
In this paper, we explore unsupervised
techniques for the task of automatic short
answer grading. We compare a number of
knowledge-based and corpus-based mea-
sures of text similarity, evaluate the effect
of domain and size on the corpus-based
measures, and also introduce a novel tech-
nique to improve the performance of the
system by integrating automatic feedback
from the student answers. Overall, our
system significantly and consistently out-
performs other unsupervised methods for
short answer grading that have been pro-
posed in the past.
1 