
This paper describes a method for evaluating
interannotator reliability in an email corpus
annotated for type (e.g., question, answer, so-
cial chat) when annotators are allowed to as-
sign multiple labels to a message.  An
augmentation is proposed to Cohen?s kappa
statistic which permits all data to be included
in the reliability measure and which further
permits the identification of more or less re-
liably annotated data points.
1 