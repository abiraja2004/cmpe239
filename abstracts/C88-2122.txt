 
In natural communication situations, multimodal referent specification 
is frequent and efficient. The linguistic component are deictic 
expressions, e.g. 'this' and 'here'. Extralinguistic devices in dialogs are 
different body movements, mainly pointing gestures. Their functional 
equivalent in texts are means like arrows and indices. 
This paper has two intentions. First, it discusses the advantages of 
multimodal reference in interhuman communication which motivate the 
integration of extralinguistic "pointing" devices into NL dialog systems. 
The generation of multimodal output poses specific problems, which 
have no counterpart in the analysis of multimodal input. The second 
part presents the strategy for generating multimodal output which has 
been developed within the framework of the XTRA system (a NL 
access system to expert systems). XTRA allows the combination of 
verbal descriptions and pointing gestures in order to specify elements 
of the given visual context, i.e. a form displayed on the screen. The 
component POPEL generates referential expressions which may be 
accompanied by a pointing gesture. The appearance of these gestures 
depends on several factors, e.g. the type of referent (whether it is a 
region or an entry of the form) and its complexity. 
Acknowledgements 
The work presented here is being supported by the German Science 
Foundation (DFG) in its Special Collaborative Program on AI and 
Knowledge-Based Systems (SFB 314), project N1 (XTRA). We would 
like to thank our colleagues of the XTRA project for their helpful 
comments on an earlier version of this paper. 
1. 