
Efficient decoding for syntactic parsing has
become a necessary research area as statisti-
cal grammars grow in accuracy and size and
as more NLP applications leverage syntac-
tic analyses. We review prior methods for
pruning and then present a new framework
that unifies their strengths into a single ap-
proach. Using a log linear model, we learn
the optimal beam-search pruning parameters
for each CYK chart cell, effectively predicting
the most promising areas of the model space
to explore. We demonstrate that our method
is faster than coarse-to-fine pruning, exempli-
fied in both the Charniak and Berkeley parsers,
by empirically comparing our parser to the
Berkeley parser using the same grammar and
under identical operating conditions.
1 