Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 1033?1041,
Sofia, Bulgaria, August 4-9 2013. c?2013 Association for Computational Linguistics
The effect of non-tightness on Bayesian estimation of PCFGs
Shay B. Cohen
Department of Computer Science
Columbia University
scohen@cs.columbia.edu
Mark Johnson
Department of Computing
Macquarie University
mark.johnson@mq.edu.au
Abstract
Probabilistic context-free grammars have
the unusual property of not always defin-
ing tight distributions (i.e., the sum of the
?probabilities? of the trees the grammar
generates can be less than one). This paper
reviews how this non-tightness can arise
and discusses its impact on Bayesian es-
timation of PCFGs. We begin by present-
ing the notion of ?almost everywhere tight
grammars? and show that linear CFGs fol-
low it. We then propose three different
ways of reinterpreting non-tight PCFGs to
make them tight, show that the Bayesian
estimators in Johnson et al (2007) are
correct under one of them, and provide
MCMC samplers for the other two. We
conclude with a discussion of the impact
of tightness empirically.
1 Introduction
Probabilistic Context-Free Grammars (PCFGs)
play a special role in computational linguistics be-
cause they are perhaps the simplest probabilistic
models of hierarchical structures. Their simplicity
enables us to mathematically analyze their prop-
erties to a detail that would be difficult with lin-
guistically more accurate models. Such analysis
is useful because it is reasonable to expect more
complex models to exhibit similar properties as
well.
The problem of inferring PCFG rule probabil-
ities from training data consisting of yields or
strings alone is interesting from both cognitive and
engineering perspectives. Cognitively it is implau-
sible that children can perceive the parse trees of
the language they are learning, but it is more rea-
sonable to assume that they can obtain the terminal
strings or yield of these trees. Unsupervised meth-
ods for learning a grammar from terminal strings
alone is also interesting from an engineering per-
spective because such training data is cheap and
plentiful, while the manually parsed data required
by supervised methods are expensive to produce
and relatively rare.
Cohen and Smith (2012) show that inferring
PCFG rule probabilities from strings alone is com-
putationally intractable, so we should not expect
to find an efficient, general-purpose algorithm for
the unsupervised problem. Instead, approxima-
tion algorithms are standardly used. For exam-
ple, the Inside-Outside (IO) algorithm efficiently
implements the Expectation-Maximization (EM)
procedure for approximating a Maximum Likeli-
hood estimator (Lari and Young, 1990). Bayesian
estimators for PCFG rule probabilities have also
been attracting attention because they provide a
theoretically-principled way of incorporating prior
information. Kurihara and Sato (2006) proposed
a Variational Bayes estimator based on a mean-
field approximation, and Johnson et al (2007) pro-
posed MCMC samplers for the posterior distribu-
tion over rule probabilities and the parse trees of
the training data strings.
PCFGs have the interesting property (which we
expect most linguistically more realistic models to
also possess) that the distributions they define are
not always properly normalized or ?tight?. In a
non-tight PCFG the partition function (i.e., sum
of the ?probabilities? of all the trees generated by
the PCFG) is less than one. (Booth and Thomp-
son, 1973, called such non-tight PCFGs ?incon-
sistent?, but we follow Chi and Geman (1998)
in calling them ?non-tight? to avoid confusion
with the consistency of statistical estimators). Chi
(1999) showed that renormalized non-tight PCFGs
(which he called ?Gibbs CFGs?) define the same
class of distributions over trees as do tight PCFGs
with the same rules, and provided an algorithm for
mapping any PCFG to a tight PCFG with the same
rules that defines the same distribution over trees.
An obvious question is then: how does tightness
affect the inference of PCFGs? Chi and Geman
(1998) studied the question for Maximum Likeli-
hood (ML) estimation, and showed that ML es-
1033
timates are always tight for both the supervised
case (where the input consists of parse trees) and
the unsupervised case (where the input consists of
yields or terminal strings). This means that ML
estimators can simply ignore issues of tightness,
and rest assured that the PCFGs they estimate are
in fact tight.
The situation is more subtle with Bayesian es-
timators. We show that for the special case of
linear PCFGs (which include HMMs) with non-
degenerate priors the posterior puts zero mass on
non-tight PCFGs, so tightness is not an issue with
Bayesian estimation of such grammars. However,
because all of the commonly used priors (such as
the Dirichlet or the logistic normal) assign non-
zero probability across the whole probability sim-
plex, in general the posterior may assign non-zero
probability to non-tight PCFGs. We discuss three
different possible approaches to this in this paper:
1. the only-tight approach, where we modify the
prior so it only assigns non-zero probability
to tight PCFGs,
2. the renormalization approach, where we
renormalize non-tight PCFGs so they define
a probability distribution over trees, and
3. the sink-element approach, where we reinter-
pret non-tight PCFGs as assigning non-zero
probability to a ?sink element?, so both tight
and non-tight PCFGs are properly normal-
ized.
We show how to modify the Gibbs sampler de-
scribed by Johnson et al (2007) so it produces
samples from the posterior distributions defined
by the only-tight and renormalization approaches.
Perhaps surprisingly, we show that Gibbs sampler
as defined by Johnson et al actually produces
samples from the posterior distributions defined by
the sink-element approach.
We conclude by studying the effect of requir-
ing tightness on the estimation of some simple
PCFGs. Because the Bayesian posterior converges
around the (tight) ML estimate as the size of
the data grows, requiring tightness only seems to
make a difference with highly biased priors or with
very small training corpora.
2 PCFGs and tightness
LetG = (T,N, S,R) be a Context-Free Grammar
in Chomsky normal form with no useless produc-
tions, where T is a finite set of terminal symbols,
N is a finite set of nonterminal symbols (disjoint
from T ), S ? N is a distinguished nonterminal
called the start symbol, andR is a finite set of pro-
ductions of the form A ? BC or A ? w, where
A,B,C ? N and w ? T . In what follows we use
? as a variable ranging over (N ?N) ? T .
A Probabilistic Context-Free Grammar (G,?)
is a pair consisting of a context-free grammar G
and a real-valued vector ? of length |R| indexed
by productions, where ?A?? is the production
probability associated with the production A ?
? ? R. We require that ?A?? ? 0 and that for
all nonterminals A ? N , ?A???RA ?A?? = 1,where RA is the subset of rules R expanding the
nonterminal A.
A PCFG (G,?) defines a measure ?? over
trees t as follows:
??(t) =
?
r?R
?fr(t)r
where fr(t) is the number of times the production
r = A? ? ? R is used in the derivation of t.
The partition function Z or measure of all pos-
sible trees is:
Z(?) =
?
t??T
?
r?R
?fr(t?)r
where T is the set of all (finite) trees generated
by G. A PCFG is tight iff the partition function
Z(?) = 1. In this paper we use ?? to denote the
set of rule probability vectors ? for which G is
non-tight. Nederhof and Satta (2008) survey sev-
eral algorithms for computing Z(?), and hence
for determining whether a PCFG is tight.1
Non-tightness can arise in very simple PCFGs,
such as the ?Catalan? PCFG S ? S S | a. This
grammar produces binary trees where all internal
nodes are labeled as S and the yield of these trees
is a sequence of as. If the probability of the rule
S ? S S is greater than 0.5 then this PCFG is
non-tight.
Perhaps the most straight-forward way to under-
stand this non-tightness is to view this grammar as
defining a branching process where an S can either
?reproduce? with probability ?S?S S or ?die out?
1We found out that finding whether a PCFG is tight by
directly inspecting the partition function value is less stable
than using the method in Wetherell (1980). For this reason,
we used Wetherell?s approach, which is based on finding the
principal eigenvalue of the matrix M .
1034
with probability ?S?a. When ?S?S S > ?S?a the
S nodes reproduce at a faster rate than they die
out, so the derivation has a non-zero probability of
endlessly rewriting (Atherya and Ney, 1972).
3 Bayesian inference for PCFGs
The goal of Bayesian inference for PCFGs is to in-
fer a posterior distribution over the rule probabil-
ity vectors ? given observed data D. This poste-
rior distribution is obtained by combining the like-
lihood P(D | ?) with a prior distribution P(?)
over ? using Bayes Rule.
P(? | D) ? P(D | ?) P(?)
We now formally define the three approaches to
handling non-tightness mentioned earlier:
the only-tight approach: we only permit priors
where P(??) = 0, i.e., we insist that the
prior assign zero mass to non-tight rule prob-
ability vectors, so Z = 1. This means we can
define:
P(t | ?) = ??(t)
the renormalization approach: we renormalize
non-tight PCFGs by dividing by the partition
function:
P(t | ?) = 1Z(?) ??(t) (1)
the sink-element approach: we redefine our
probability distribution so its domain is a set
T ? = T ? {?}, where T is the set of (finite)
trees generated by G and ? 6? T is a new
element that serves as a ?sink state? to which
the ?missing mass? 1 ? Z(?) is assigned.
Then we define:2
P(t | ?) =
{
??(t) if t ? T
1? Z(?) if t = ?
2This definition of a distribution over trees can be induced
by a tight PCFG with a special ? symbol in its vocabulary.
Given G, the first step is to create a tight grammar G0 using
the renormalization approach. Then, a new start symbol is
added to G0, S0, and also rules S0 ? S (where S is the
old start symbol in G0) and S0 ? ?. The first rule is given
probability Z(?) and the second rule is given probability 1?
Z(?). It can be then readily shown that the new tight PCFG
G0 induces a distribution over trees just like in Eq. 3, only
with additional S0 on top of all trees.
With this in hand, we can now define the likeli-
hood term. We consider two types of data D here.
In the supervised setting the data D consists of a
corpus of parse trees D = (t1, . . . , tn) where each
tree ti is generated by the PCFG G, so
P(D | ?) =
n?
i=1
P(ti | ?)
In the unsupervised setting the data D consists
of a corpus of strings D = (w1, . . . , wn) where
each string wi is the yield of one or more trees
generated by G. In this setting
P(D | ?) =
n?
i=1
P(wi | ?),where:
P(w | ?) =
?
t?T :yield(t)=w
P(t | ?)
4 The special case of linear PCFGs
One way to handle the issue of tightness is to iden-
tify a family of CFGs for which practically any pa-
rameter setting will yield a tight PCFG. This is the
focus of this section, in which we identify a sub-
set of CFGs, which are ?almost everywhere? tight.
This family of CFGs includes many of the CFGs
used in NLP applications.
We cannot expect that a CFG will yield a tight
PCFG for any assignment to the rule probabilities
(i.e. that ?? = ?). Even in simple cases, such as
the grammar S ? S|a, the assignment of proba-
bility 1 to S ? S and 0 to the other rule renders
the S nonterminal useless, and places all of the
probability mass on infinite structures of the form
S ? S ? S ? . . ..
However, we can weaken our requirement so
that the cases in which parameter assignment
yields a non-tight PCFG are rare, or have measure
zero. To put it more formally, we say that a prior
P(?) is ?tight almost everywhere for G? if
P(??) =
?
????
P(?) d? = 0.
We now provide a sufficient condition (linear-
ity) for CFGs under which they are tight almost
everywhere with any continuous prior.
For a nonterminal A ? N and ? ? (N ? T )?,
we use A?k ? to denote that A can be re-written
using a sequence of rules from R to the sentential
form ? in k derivation steps. We use A ?+ ? to
denote that there exists a k > 0 such thatA?k ?.
1035
Definition 1 A context-free grammarG is linear if
there are no A ? N such that
A?+ . . . A . . . A . . . .
Definition 2 A nonterminal A ? N in a proba-
bilistic context-free grammar G with parameters
? is nonterminating if
PG(A?+ . . . A . . . |?) = 1.
Here P(A?+ . . . A . . . |?) is defined as:
?
?:?=...A...
PG(A?+ ?|?).
Lemma 1 A linear PCFG G with parameters ?
which does not have any nonterminating nonter-
minals is tight.
Proof: Our proof relies on the properties of a cer-
tain |N | ? |N | matrix M where:
MAB =
?
A???RA
n(?,B) ?A??
where n(?,B) is the number of appearances of the
nonterminal B in the sequence ?. MAB is the ex-
pected number of B nonterminals generated from
an A nonterminal in one single derivational step,
so [Mk]AB is the expected number ofB nontermi-
nals generated from an A nonterminal in a k-step
derivation (Wetherell, 1980).
Since M is a non-negative matrix, under some
regularity conditions, the Frobenius-Perron theo-
rem states that the largest eigenvalue of this ma-
trix (in absolute value) is a real number. Let this
eigenvalue be denoted by ?.
A PCFG is called ?subcritical? if ? < 1 and
supercritical if ? > 1. Then, in turn, a PCFG is
tight if it is subcritical. It is not tight if it is su-
percritical. The case of ? = 1 is a borderline case
that does not give sufficient information to know
whether the PCFG is tight or not. In the Bayesian
case, for a continuous prior such as the Dirichlet
prior, this borderline case will have measure zero
under the prior.
Now let A ? N . Since the grammar is lin-
ear, there is no derivation A ?+ . . . A . . . A . . ..
Therefore, any derivation of the form A ?+
. . . A . . . includes A on the right hand-side exactly
once. Because the grammar has no useless non-
terminals, the probability of such a derivation is
strictly smaller than 1.
For each A ? N , define:
pA =
?
?=...A...
P(A?|N | ?|?).
Since A is not useless, then pA < 1. Therefore
q = maxA pA < 1. Since any derivation of length
k of the formA? . . . A . . . can be decomposed to
at least k2|N | cycles that start at a terminal B ? N
and end in the same nonterminal B ? N , it holds
that:
[Mk]AA ? q
k
2|N| k??? 0.
This means that trace(Mk) k??? 0. This means
that the eigenvalue of M is strictly smaller than 1
(linear algebra), and therefore the PCFG is tight.
Proposition 1 Any continuous prior P(?) on a
linear grammar G is tight almost everywhere for
G.
Proof: Let G be a linear grammar. With a contin-
uous prior, the probability ofG getting parameters
from the prior which yield a useless non-terminal
is 0 ? it would require setting at least one rule in
the grammar with rule probability which is exactly
1. Therefore, with probability 1, the parameters
taken from the prior yield a PCFG which is linear
and does not have nonterminating nonterminals.
According to Lemma 1, this means the PCFG is
tight. 
Deciding whether a grammar G is linear can
be done in polynomial time using the construction
from Bar-Hillel et al (1964). We can first elimi-
nate the differences between nonterminals and ter-
minal symbols by adding a rule A ? cA for each
nonterminal A ? N , after extending the set of
terminal symbols A with {cA|A ? N}. Let GA
be the grammar G with the start symbol being re-
placed with A. We can then intersect the grammar
GA with the regular language T ?cAT ?cAT ? (for
each nonterminal A ? N ). If for any nontermi-
nal A the intersection is not the empty set (with
respect to the language that the intersection gen-
erates), then the grammar is not linear. Checking
whether the intersection is the empty set or not can
be done in polynomial time.
We conclude this section by remarking that
many of the models used in computational lin-
guistics are in fact equivalent to linear PCFGs, so
continuous Bayesian priors are almost everywhere
tight. For example, HMMs and many kinds of
?stacked? finite-state machines are equivalent to
1036
linear PCFGs, as are the example PCFGs given in
Johnson et al (2007) to motivate the MCMC esti-
mation procedures.
5 Dirichlet priors
The first step in Bayesian inference is to specify a
prior on ?. In the rest of this paper we take P(?)
to be a product of Dirichlet distributions, with one
distribution for each non-terminal A ? N , as this
turns out to simplify the computations consider-
ably. The prior is parameterized by a positive real
valued vector ? indexed by productionsR, so each
production probability ?A?? has a corresponding
Dirichlet parameter ?A?? . As before, let RA be
the set of productions in R with left-hand side A,
and let ?A and ?A refer to the component subvec-
tors of ? and ? respectively indexed by produc-
tions in RA. The Dirichlet prior P(? | ?) is:
P(? | ?) =
?
A?N
PD(?A | ?A),
where
PD(?A | ?A) =
1
C(?A)
?
r?RA
??r?1r and
C(?A) =
?
r?RA ?(?r)
?(
?
r?RA ?r)
where ? is the generalized factorial function and
C(?) is a normalization constant that does not de-
pend on ?A.
Dirichlet priors are useful because they are con-
jugate to the multinomial distribution, which is
the building block of PCFGs. Ignoring issues of
tightness for the moment and setting P(t | ?) =
??(t), this means that in the supervised setting the
posterior distribution P(? | t, ?) given a set of
parse trees t = (t1, . . . , tn) is also a product of
Dirichlets distribution.
P(? | t, ?) ? P(t | ?) P(? | ?)
?
(?
r?R
?fr(t)r
)(?
r?R
??r?1r
)
=
?
r?R
?fr(t)+?r?1r
which is a product of Dirichlet distributions with
parameters f(t) + ?, where f(t) is the vector of
rule counts in t indexed by r ? R. We can thus
write:
P(? | t, ?) = P(? | f(t) + ?)
Input: Grammar G, vector of trees t, vector of
hyperparameters ?, previous parameters ?0.
Result: A vector of parameters ?
repeat
draw ? from products of Dirichlet with
hyperparameters ?+ f(t)
until ? is tight for G;
return ?
Algorithm 1: An algorithm for generating sam-
ples from P(? | t, ?) for the only-tight ap-
proach.
Input: Grammar G, vector of trees t, vector of
hyperparameters ?, previous rule parameters
?0.
Result: A vector of parameters ?
draw a proposal ?? from a product of Dirichlets with
parameters ?+ f(t).
draw a uniform number u from [0, 1].
if u < min{1,
(
Z(?(i?1))/Z(??)
)n
} return ??.
return ?0.
Algorithm 2: One step of Metropolis-Hastings
algorithm for generating samples from P(? |
t, ?) for the renormalization approach.
which makes it clear that the rule counts are di-
rectly added to the parameters of the prior to pro-
duce the parameters of the posterior.
6 Inference in the supervised setting
We first discuss Bayesian inference in the super-
vised setting, as inference in the unsupervised set-
ting is based on inference for the supervised set-
ting. For each of the three approaches to non-
tightness we provide an algorithm that character-
izes the posterior P(? | t), where t = (t1, . . . , tn)
is a sequence of trees, by generating samples from
that posterior. Our MCMC algorithms for the un-
supervised setting build on these samplers for the
supervised setting.
6.1 The only-tight approach
The ?only-tight? approach requires that the prior
assign zero mass to non-tight rule probability vec-
tors ??. One way to define such a distribution is
to restrict the domain of an existing prior distribu-
tion with the set of tight ? and renormalize. In
more detail, if P(?) is a prior over rule probabili-
ties, then its renormalization is the prior P? defined
as:
P?(?) = P(?)I(? /? ?
?)
Z(??) . (2)
where Z(??) = ?? P(?)I(? /? ??)d?.
1037
Input: Grammar G, vector of trees t, vector of
hyperparameters ?, previous parameters ?0.
Result: A vector of parameters ?
draw ? from products of Dirichlet with
hyperparameters ?+ f(t)
return ?
Algorithm 3: An algorithm for generating sam-
ples from P(? | t, ?) for the sink-state approach.
Perhaps surprisingly, it turns out that if P(?)
belongs to a family of conjugate priors, then P?(?)
also belongs to a (different) family of conjugate
priors as well.
Proposition 2 Let P(?|?) be a prior with hyper-
parameters ? over the parameters of G such that
P is conjugate to the grammar likelihood. Then
P?, defined in Eq. 2, is conjugate to the grammar
likelihood as well.
Proof: Assume that trees t are observed, and the
prior over the grammar parameters is the prior de-
fined in Eq. 2. Therefore, the posterior is:
P(?|t, ?) ? P?(?|?)p(t|?)
= P(?|?)p(t|?)I(? /? ?
?)
Z(??)
? P(?|t, ?)I(? /? ?
?)
Z(??) .
Since P(?|?) is a conjugate prior to the PCFG
likelihood, then there exists ?? = ??(t) such that
P(?|t, ?) = P?(?|??). Therefore:
P(?|t, ?) ? P(?|?
?)I(? /? ??)
Z(??) .
which exactly equals P?(?|??). 
Sampling from the posterior over the parame-
ters given a set of trees t is therefore quite sim-
ple when assuming the base prior being renormal-
ized is a product of Dirichlets. Algorithm 1 sam-
ples from a product of Dirichlets distribution with
hyperparameters ? + f(t) repeatedly, each time
checking and rejecting the sample until we obtain
a tight PCFG.
The more mass the Dirichlet distribution with
hyperparameters ? + f(t) puts on non-tight
PCFGs, the more rejections will happen. In gen-
eral, if the probability mass on non-tight PCFGs is
q?, then it would require, on average 1/(1 ? q?)
samples from this distribution in order to obtain a
tight PCFG.
6.2 The renormalization approach
The renormalization approach modifies the likeli-
hood function instead of the prior. Here we use a
product of Dirichlets prior P(? | ?) on rule prob-
ability vectors ?, but the presence of the partition
functionZ(?) in Eq. 1 means that the likelihood is
no longer conjugate to the prior. Instead we have:
P(? | t) =
n?
i=1
??(ti)
Z(?) P(? | ?)
? 1Z(?)n P(? | ?+ f(t)). (3)
Note that the factor Z(?) depends on ?, and
therefore cannot be absorbed into the constant. Al-
gorithm 2 describes a Metropolis-Hastings sam-
pler for sampling from the posterior in Eq. 3
that uses a product of Dirichlets with parameters
?+ f(t) as a proposal distribution.
In our experiments, we use the algorithm from
Nederhof and Satta (2008) to compute the parti-
tion function which is needed in Algorithm 2.
6.3 The ?sink element? approach
The ?sink element? approach does not affect the
likelihood (since the probability of a tree t is just
the product of the probabilities of the rules used
to generate it), nor does it require a change to the
prior. (The sink element ? is not a member of the
set of trees T , so it cannot appear in the data t).
This means that the conjugacy argument given
at the bottom of section 5 holds in this approach,
so the posterior P(? | t, ?) is a product of Dirich-
lets with parameters f(t) + ?. Algorithm 3 gives
a sampler for P(? | t, ?) for the sink element ap-
proach.
7 Inference in the unsupervised setting
Johnson et al (2007) provide two Markov chain
Monte Carlo algorithms for Bayesian inference for
PCFG rule probabilities in the unsupervised set-
ting (i.e., where the data consists of a corpus of
strings w = (w1, . . . , wn) alone). The algorithms
we give here are based on their Gibbs sampler,
which in each iteration first samples parse trees
t = (t1, . . . , tn), where each ti is a parse for
wi, from P(t | w,?), and then samples ? from
P(? | t, ?).
Notice that the conditional distribution P(t |
w,?) is unaffected in each of our three ap-
proaches (the partition functions cancel in the
1038
Input: Grammar G, vector of hyperparameters ?,
vector of strings w = (w1, . . . , wn), previous
rule parameters ?0.
Result: A vector of parameters ?
for i? 1 to n do
draw ti from P(ti|wi,?0)
end
use Algorithm 2 to sample ? given G, t, ? and ?0
return ?
Algorithm 4: One step of the Metropolis-within-
Gibbs sampler for the renormalization approach.
renormalization approach), so the algorithm for
sampling from P(t | w,?) given by Johnson et
al. applies in each of our three approaches as well.
Johnson et al ignored tightness and assumed
that P(? | t, ?) is a product of Dirichlets with
parameters f(t) + ?. As we noted in section 6.3,
this assumption holds for the sink-state approach
to non-tightness, so their sampler is in fact correct
for the sink-state approach.
In fact, we obtain samplers for the unsupervised
setting for each of our approaches by ?plugging
in? the corresponding sampling algorithm (Eq. 1?
3) for P(? | t, ?) into the generic Gibbs sampler
framework of Johnson et al
The one complication is that because we use a
Metropolis-Hastings procedure to generate sam-
ples from P(? | t, ?) in the renormalization ap-
proach, we use the Metropolis-within-Gibbs pro-
cedure given in Algorithm 4 (Robert and Casella,
2004).
8 The expressive power of the three
approaches
Probably the most important question to ask with
respect to the three different approaches to non-
tightness is whether they differ in terms of expres-
sive power. Clearly the three approaches differ in
terms of the grammars they admit (the only-tight
approach requires the prior to only assign non-zero
probability to tight PCFGs, while the other two ap-
proaches permit the prior to assign non-zero prob-
ability to non-tight PCFGs as well). However, if
we regard a grammar as merely a device for defin-
ing a distribution over trees and a prior as defining
a distribution over distributions over trees, it is rea-
sonable to ask whether the class of distributions
over distributions of trees that each of these ap-
proaches define are the same or differ. We believe,
but have not proved, that all three approaches de-
fine the same class of distributions over distribu-
tions of trees in the following sense: any prior used
with one of the approaches can be transformed
into a different prior that can be used with one of
the other approaches, and yield the same posterior
over trees conditioned on a string, marginalizing
out the parameters.
This does not mean that the three approaches
are equivalent, however. In this section we pro-
vide a grammar such that with a uniform prior over
rule probabilities, the conditional distribution over
trees given a fixed string varies under each of the
three different approaches.
The grammar we consider has three rules S ?
S S S|S S|a with probabilities ?1, ?2 and 1? ?1?
?2, respectively. The ? parameters are required to
satisfy ?1 + ?2 ? 1 and ?i ? 0 for i = 1, 2.
We compute the posterior distribution over
parse trees for the string w = a a a. The gram-
mar generates three parse trees for w1, namely:
t1 = S
S
a
S
a
S
a
t2 = S
S
a
S
S
a
S
a
t3 = S
S
S
a
S
a
S
a
The partition function Z for this grammar is the
smallest positive root of the cubic equation:
Z = ?1Z3 + ?2Z2 + (1? ?1 ? ?2)
We used Mathematica to find an analytic solution
for Z in this equation, obtaining not only an ex-
pression for the partition function Z(?) but also
identifying the non-tight region ??.
In order to compute P(t1|w), we used Mathe-
matica to first compute the following quantities:
qsinkElement(ti) =
?
?
??(ti) d?
qtightOnly(ti) =
?
?
??(ti) I(? /? ??) d?
qrenormalization(ti) =
?
?
??(ti)/Z(?) d?
where i ? {1, 2, 3}. We used Mathematica to ana-
lytically compute q(ti) for each approach and each
i ? {1, 2, 3}. Then it?s easy to show that:
P(ti | w) =
q(ti)?3
i?=1 q(ti?)
where the q used is based on the approach to
tightness desired. For the sink-element approach,
1039
010
20
30
0.35 0.40 0.45 0.50 0.55Average f?score
De
nsi
ty
Inference
only?tight
sink?state
renormalise
Figure 1: The density of the F1-scores with the
three approaches. The prior used is a symmetric
Dirichlet with ? = 0.1.
P(t1|w) = 711 ? 0.636364. For the only-tightapproach P(t1|w) = 1117917221 ? 0.649149. Forthe renormalization approach the analytic ex-
pression is too complex to include in this paper,
but it approximately equals 0.619893. A log
of our Mathematica calculations is available
at http://www.cs.columbia.edu/?scohen/
acl13tightness-mathematica.pdf, and we
confirmed these results to three decimal places us-
ing the samplers described above (which required
107 samples per approach).
While the differences between these conditional
probabilities are not great, the conditional prob-
abilities are clearly different, so the three ap-
proaches do in fact define different distributions
over trees under a uniform prior on rule probabili-
ties.
9 Empirical effects of the three
approaches in unsupervised grammar
induction
In this section we present experiments using the
three samplers just described in an unsupervised
grammar induction problem. Our goal here is
not to improve the state-of-the-art in unsupervised
grammar induction, but to try to measure empir-
ical differences in the estimates produced by the
three different approaches to tightness just de-
scribed. The bottom line of our experiments is that
we could not detect any significant difference in
the estimates produced by samplers for these three
different approaches.
In our experiments we used the English Penn
treebank (Marcus et al, 1993). We use the part-
of-speech tag sequences of sentences shorter than
11 words in sections 2?21. The grammar we use is
the PCFG version of the dependency model with
valence (Klein and Manning, 2004), as it appears
in Smith (2006).
We used a symmetric Dirichlet prior with hy-
perparameter ? = 0.1. For each of the three ap-
proaches for handling tightness, we ran 100 times
the samplers in ?7, each for 1,000 iterations. We
discarded the first 900 sweeps of each run, and cal-
culated the F1-scores of the sampled trees every
10th sweep from the last 100 sweeps. For each
run we calculated the average F1-score over the
10 sweeps we evaluated. We thus have 100 aver-
age F1-scores for each of the samplers.
Figure 1 plots the density of F1 scores (com-
pared to the gold standard) resulting from the
Gibbs sampler, using all three approaches. The
mean value for each of the approaches is 0.41
with standard deviation 0.06 (only-tight), 0.41
with standard deviation 0.05 (renormalization)
and 0.42 with standard deviation 0.06 (sink ele-
ment). In addition, the only-tight approach results
in an average of 437 (s.d., 142) rejected propos-
als in 1,000 samples, while the renormalization
approach results in an average of 232 (s.d., 114)
rejected proposals in 1,000 samples. (It?s not sur-
prising that the only-tight approach results in more
rejections as it keeps proposing new ? until a tight
proposal is found, while the renormalization ap-
proach simply uses the old ?).
We performed two-sample Kolmogorov-
Smirnov tests (which are non-parametric tests
designed to determine if two distributions are
different; see DeGroot, 1991) on each of the three
pairs of 100 F1-scores. None of the tests were
close to significant; the p-values were all above
0.5. Thus our experiments provided no evidence
that the samplers produced different distributions
over trees, although it?s reasonable to expect that
these distributions do indeed differ.
In terms of running time, our implementation
of the renormalization approach was several times
slower than our implementations of the other two
approaches because we used the naive fixed-point
algorithm to compute the partition function: per-
haps this could be improved using one of the
more sophisticated partition function algorithms
described in Nederhof and Satta (2008).
1040
10 Conclusion
In this paper we characterized the notion of an al-
most everywhere tight grammar in the Bayesian
setting and showed it holds for linear CFGs. For
non-linear CFGs, we described three different ap-
proaches to handle non-tightness. The ?only-
tight? approach restricts attention to tight PCFGs,
and perhaps surprisingly, we showed that conju-
gacy still obtains when the domain of a product
of Dirichlets prior is restricted to the subset of
tight grammars. The renormalization approach in-
volves renormalizing the PCFG measure ? over
trees when the grammar is non-tight, which de-
stroys conjugacy with a product of Dirichlets prior.
Perhaps most surprisingly of all, the sink-element
approach, which assigns the missing mass in non-
tight PCFG to a sink element ?, turns out to be
equivalent to existing practice where tightness is
ignored.
We studied the posterior distributions over trees
induced by the three approaches under a uniform
prior for a simple grammar and showed that they
differ. We leave for future work the important
question of whether the classes of distributions
over distributions over trees that the three ap-
proaches define are the same or different.
We described samplers for the supervised
and unsupervised settings for each of these ap-
proaches, and applied them to an unsupervised
grammar induction problem. (The code for the
unsupervised samplers is available from http://
web.science.mq.edu.au/?mjohnson).
We could not detect any difference in the pos-
terior distributions over trees produced by these
samplers, despite devoting considerable computa-
tional resources to the problem. This suggests that
for these kinds of problems at least, tightness is
not of practical concern for Bayesian inference of
PCFGs.
Acknowledgements
We thank the anonymous reviewers and Gior-
gio Satta for their valuable comments. Shay
Cohen was supported by the National Science
Foundation under Grant #1136996 to the Com-
puting Research Association for the CIFellows
Project, and Mark Johnson was supported by the
Australian Research Council?s Discovery Projects
funding scheme (project numbers DP110102506
and DP110102593).
References
K. B. Atherya and P. E. Ney. 1972. Branching Pro-
cesses. Dover Publications.
Y. Bar-Hillel, M. Perles, and E. Shamir. 1964. On
formal properties of simple phrase structure gram-
mars. Language and Information: Selected Essays
on Their Theory and Application, pages 116?150.
T. L. Booth and R. A. Thompson. 1973. Applying
probability measures to abstract languages. IEEE
Transactions on Computers, C-22:442?450.
Z. Chi and S. Geman. 1998. Estimation of probabilis-
tic context-free grammars. Computational Linguis-
tics, 24(2):299?305.
Z. Chi. 1999. Statistical properties of probabilistic
context-free grammars. Computational Linguistics,
25(1):131?160.
S. B. Cohen and N. A. Smith. 2012. Empirical risk
minimization for probabilistic grammars: Sample
complexity and hardness of learning. Computa-
tional Linguistics, 38(3):479?526.
M. H. DeGroot. 1991. Probability and Statistics (3rd
edition). Addison-Wesley.
M. Johnson, T. L. Griffiths, and S. Goldwater. 2007.
Bayesian inference for PCFGs via Markov chain
Monte Carlo. In Proceedings of NAACL.
D. Klein and C. D. Manning. 2004. Corpus-based
induction of syntactic structure: Models of depen-
dency and constituency. In Proceedings of ACL.
K. Kurihara and T. Sato. 2006. Variational Bayesian
grammar induction for natural language. In 8th In-
ternational Colloquium on Grammatical Inference.
K. Lari and S.J. Young. 1990. The estimation of
Stochastic Context-Free Grammars using the Inside-
Outside algorithm. Computer Speech and Lan-
guage, 4(35-56).
M. P. Marcus, B. Santorini, and M. A. Marcinkiewicz.
1993. Building a large annotated corpus of En-
glish: The Penn treebank. Computational Linguis-
tics, 19:313?330.
M.-J. Nederhof and G. Satta. 2008. Computing par-
tition functions of PCFGs. Research on Language
and Computation, 6(2):139?162.
C. P. Robert and G. Casella. 2004. Monte Carlo Sta-
tistical Methods. Springer-Verlag New York.
N. A. Smith. 2006. Novel Estimation Methods for Un-
supervised Discovery of Latent Structure in Natural
Language Text. Ph.D. thesis, Johns Hopkins Univer-
sity.
C. S. Wetherell. 1980. Probabilistic languages: A re-
view and some open questions. Computing Surveys,
12:361?379.
1041
