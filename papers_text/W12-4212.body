Proceedings of SSST-6, Sixth Workshop on Syntax, Semantics and Structure in Statistical Translation, pages 102?110,
Jeju, Republic of Korea, 12 July 2012. c?2012 Association for Computational Linguistics
Application of Clause Alignment for Statistical Machine Translation
Svetla Koeva, Borislav Rizov, Ivelina Stoyanova, Svetlozara Leseva, Rositsa Dekova, Angel Genov,
Ekaterina Tarpomanova, Tsvetana Dimitrova and Hristina Kukova
Department of Computational Linguistics
Institute for Bulgarian Language, Bulgarian Academy of Sciences
Sofia 1113, Bulgaria
{svetla,boby,iva,zarka,rosdek,angel,katja,cvetana,hristina}@dcl.bas.bg
Abstract
The paper presents a new resource light flexi-
ble method for clause alignment which com-
bines the Gale-Church algorithm with in-
ternally collected textual information. The
method does not resort to any pre-developed
linguistic resources which makes it very ap-
propriate for resource light clause alignment.
We experiment with a combination of the
method with the original Gale-Church algo-
rithm (1993) applied for clause alignment.
The performance of this flexible method, as it
will be referred to hereafter, is measured over
a specially designed test corpus.
The clause alignment is explored as means
to provide improved training data for the
purposes of Statistical Machine Translation
(SMT). A series of experiments with Moses
demonstrate ways to modify the parallel re-
source and effects on translation quality: (1)
baseline training with a Bulgarian-English
parallel corpus aligned at sentence level; (2)
training based on parallel clause pairs; (3)
training with clause reordering, where clauses
in each source language (SL) sentence are re-
ordered according to order of the clauses in
the target language (TL) sentence. Evaluation
is based on BLEU score and shows small im-
provement when using the clause aligned cor-
pus.
1 Motivation
Evaluation on the performance of MT systems has
shown that a pervasive shortcoming shared by both
the phrase-based and the syntax-based SMT systems
is translating long and (syntactically) complex sen-
tences (Koehn et al., 2003; Li et al., 2007; Sudoh et
al., 2010).
The power of phrase-based SMT lies in local lex-
ical choice and short-distance reordering (Li et al.,
2007). Syntax-based SMT is better suited to cope
with long-distance dependencies, however there also
are problems, some of them originated from the lin-
guistic motivation itself ? incorrect parse-trees, or
reordering that might involve blocks that are not
constituents (Li et al., 2007).
An efficient way to overcome the problem of sen-
tence length and complexity is to process the clauses
in a similar way as sentences. This has incited grow-
ing interest towards the alignment and processing of
clauses ? a group of syntactically and semantically
related words expressing predicative relation and
positioned between sentence borders or clause con-
nectors. (It is known that some predicative relations
can be considered complex being saturated with an-
other predicative relation ? but with the above given
definition this case is simplified).
The differences in word order and phrase structure
across languages can be better captured at a clause
rather than at a sentence level, therefore, monolin-
gual and parallel text processing in the scope of the
clauses may significantly improve syntactic parsing,
automatic translation, etc. The sentences can be very
long and complex in structure, may consist of a con-
siderable number of clauses which in turn may vary
with respect to their relative position to each other
in parallel texts both due to linguistic reasons per se
and translators? choices.
The flexible order, length and number of clauses
102
in sentences, along with the different word order and
ways of lexicalisation across languages contribute to
the complexity of clause alignment as compared to
sentence alignment and call for more sophisticated
approaches. These findings have inspired growing
research into clause-to-clause machine translation
involving clause splitting, alignment and word order
restructuring within the clauses (Cowan et al., 2006;
Ramanathan et al., 2011; Sudoh et al., 2010; Goh et
al., 2011).
A fixed clause order in a language (i.e. rela-
tive clauses in Bulgarian, English, French and many
other languages follow the head noun, while in Chi-
nese, Japanese, Turkish, etc. they precede it) may
correspond to a free order in another (i.e. Bulgar-
ian and English adverbial clauses). The hypothesis
is that a SMT model can be improved by inducing
a straightforward clause alignment through reorder-
ing the clauses of the source language text so as to
correspond to the order of the clauses in the target
language text.
2 State-of-the-art
The task of clause alignment is closely related to
that of sentence alignment (Brown et al., 1990; Gale
and Church, 1993; Kay and Roscheisen, 1993) and
phrase alignment (DeNero and Klein, 2008; Koehn
et al., 2003). There are two main approaches ? sta-
tistical and lexical, often employed together to pro-
duce hybrid methods. Machine learning techniques
are applied to extract models from the data and re-
duce the need of predefined linguistic resources.
Boutsis, Piperidis and others (Boutsis and
Piperidis, 1998; Boutsis and Piperidis, 1998;
Piperidis et al., 2000) employ a method combin-
ing statistical techniques and shallow linguistic pro-
cessing applied on a bilingual parallel corpus of
software documentation which is sentence-aligned,
POS-tagged and shallow parsed. The combined task
of clause borders identification uses linguistic in-
formation (POS tagging and shallow parsing) and
clause alignment based on pure statistical analysis.
The reported precision is 85.7%. Kit et al. (2004)
propose a method for aligning clauses in Hong Kong
legal texts to English which relies on linguistic in-
formation derived from a glossary of bilingual legal
terms and a large-scale bilingual dictionary. The al-
gorithm selects a minimal optimal set of scores in
the similarity matrix that covers all clauses in both
languages. The authors report 94.60% alignment ac-
curacy of the clauses, corresponding to 88.64% of
the words.
The quality of the parallel resources is of cru-
cial importance to the performance of SMT sys-
tems and substantial research is focused on devel-
oping good parallel corpora of high standard. Most
clause alignment methods are applied on domain
specific corpora, in particular administrative cor-
pora and are not extensively tested and evaluated on
general corpora or on texts of other domains. Al-
though clause segmentation is often performed to-
gether with clause alignment (Papageorgiou, 1997)
the former tends to be more language-specific and
therefore clause alignment is performed and eval-
uated independently. The majority of the avail-
able comparative analyses discuss modifications of
one method rather than the performance of different
methods. Moreover, the performance of resource-
free against resource-rich methods has been poorly
explored. To the best of our knowledge, there is
no purely resource-free method for clause alignment
offered so far.
In recent years, handling machine translation at
the clause level has been found to overcome some of
the limitations of phrase-based SMT. Clause aligned
corpora have been successfully employed in the
training of models for clause-to-clause translation,
reordering and subsequent sentence reconstruction
in SMT ? Cowan et al. (2006) for syntax-based
German-to-English SMT, Sudoh et al. (2010) for
English-to-Japanese phrase-based SMT, among oth-
ers.
Cowan et al. (2006) discuss an approach for
tree-to-tree SMT using Tree Adjoining Grammars.
Clause alignment is performed on a corpus (Eu-
roparl) which is then used in the training of a model
for mapping parse trees in the source language to
parse trees in the target language. The performance
of this syntax-based method is similar to the phrase-
based model of Koehn et al. (2003).
Sudoh et al. (2010) propose a method for clause-
to-clause translation by means of a standard SMT
method. The clauses may contain non-terminals as
placeholders for embedded clauses. After transla-
tion is performed, the non-terminals are replaced
103
by their clause translations. The model for clause
translation is trained using a clause-aligned bilin-
gual corpus of research paper abstract. The proposed
improvement by using Moses is 1.4% in BLEU
(33.19% to 34.60%), and 1.3% in TER (57.83% to
56.50%) and 2.2% in BLEU (32.39% to 34.55%)
and 3.5% in TER (58.36% to 54.87%) using a hi-
erarchical phrase-based SMT system.
The potential of clause alignment along with
other sub-sentence levels of alignment in extract-
ing matching translation equivalents from transla-
tion archives has been recognised within the EBMT
framework, as well (Piperidis et al., 2000).
3 Bootstrapping clause alignment
The clause alignment is modelled as a bipartite
graph. Each node in the graph corresponds to a
clause in either the source or the target language.
A pair of clauses that are fully or partially trans-
lational equivalents is connected by an edge in the
graph. The connected components of the graph are
beads (the smallest group of aligned clauses). In
these terms, the task of clause alignment is the task
of the identification of the edges in a bipartite graph,
where the nodes are the clauses (Brown et al., 1990).
A bootstrapping method for clause alignment that
does not exploit any pre-developed linguistic re-
sources is elaborated. The method uses length-
balance based alignment algorithm ? i.e. Gale-
Church (Gale and Church, 1993), for the data col-
lecting. The bootstrapping algorithm attains high
precision and relatively good recall. In order to
improve the recall while preserving the precision
the method is combined with the Gale-Church al-
gorithm applied to clause alignment.
The proposed method consists of the following
stages:
1. Initial clause alignment that serves as training
data.
2. Identifying similarities between clauses in dif-
ferent languages.
3. Building the clause alignment.
3.1 The Gale and Church algorithm
Gale and Church (1993) describe a method for align-
ing sentences based on a simple statistical model of
sentence lengths measured in number of characters.
It relies on the fact that longer sentences in one lan-
guage tend to be translated into longer sentences in
the other language, and vice versa. A probabilis-
tic score is assigned to each proposed correspon-
dence of sentences, based on the scaled difference
and the variance of the lengths of the two sentences.
The method is reported to give less than 4% error in
terms of alignment and is probably the most widely
used sentence alignment method.
The extended version of the Gale-Church aligner
from the Natural Language Toolkit1 is applied for
clause alignment. The original Gale-Church method
applies the 1:1, 0:1, 1:0, 1:2, 2:1 and 2:2 bead mod-
els; in the extended version ? the 1:3, 3:1, 2:3, 3:2,
3:3 models are added.
3.2 Clause alignment training data
The clause beads are identified by applying the
Gale-Church algorithm. The aim is to select a set
of aligned beads which are to serve as a training set
for the subsequent stages. Only beads showing high
probability of correctness are used. For any proba-
bility p we could find ? so that for the Gale-Church
measure within [??, ?] the corresponding bead is
correct with probability p.
3.3 Clause similarity
Clause similarity is measured by means of: a) par-
tial word alignment, b) length similarity, and c)
weighted punctuation similarity.
3.3.1 Word alignment
To align words in the scope of parallel clauses,
word-to-word connections (weighted links between
two words based on word similarity) are calculated
using several methods given below:
? Vector space model
A given word is assigned a vector
< x1, x2, ? ? ? , xn >
in an n-dimensional vector space, where each
dimension represents a bead in the preliminary
clause alignment and x i is the number of the
occurrences of the word in the bead. The set of
these vectors is a matrix.
1http://nltk.googlecode.com
104
The vector space word similarity is the cosine
of the angle between the vectors of the words
(Ruge, 1992; Schu?tze, 1992). Two words are
similar if the cosine is above a specified thresh-
old. The observations over the training and
test data show that the translation equivalents
are identified best when the cosine is higher
than 0.7. However, the word-to-word align-
ment reduces some of the errors which increase
in number when lowering the threshold. There-
fore, the threshold is set at 0.4 acquiring a good
balance between the number of the connections
obtained and the error rate.
A second vector space matrix is built using the
first two words in each clause on the assump-
tion that clause-introducing words may express
stronger word-to-word connections.
Some experiments with word similarity asso-
ciation measures e.g. the chi-square measure
(Evert, 2005) failed to show any improvements.
Word forms are treated as instances of one and
the same word if either their actual or nor-
malised forms are equal (Kay and Roscheisen,
1993). The normalised forms cover correspon-
dences between grammatically and semanti-
cally related words in languages with rich in-
flectional and derivational morphology. The
morphology algorithm proposed by Kay and
Roscheisen (1993) is applied for splitting po-
tential suffixes and prefixes and for obtaining
the normalised word forms. The vector space
word-to-word connections are calculated for
both actual and normalised forms and the ob-
tained similarity measures are summed up.
? Levenshtein measure (Levenshtein, 1966)
Church (1993) employs a method that in-
duces sentence alignment by employing cog-
nates (words that are spelled similarly across
languages). Instead the standard Levenshtein
distance (the number of edits required to trans-
form a string A into another string B) is ap-
plied. The non-Latin characters are transliter-
ated into Latin ones. The distance is calculated
within a tolerance different for a different word
length. The distance is then transformed into
similarity by means of the tolerance.
?
1?
levenshtein
tolerance + 1
.
? Punctuation
Similarity is calculated also if two words con-
tain identical prefixes or suffixes which are
punctuation marks or special characters. Punc-
tuation and special characters are not all equal.
Some of them are more robust, e.g. marks
for currency and measurement, or mathemati-
cal symbols ($, , , %, +,<,>, =) or the different
types of brackets. Others (e.g. comma, hyphen,
colon, semi-colon) may be governed by lan-
guage specific rules and may lead to improve-
ment only for those pairs of languages that em-
ploy similar rules.
The word-to-word similarity measure is the
weighted sum of the above measures where the
Levenshtein similarity is multiplied by 3, the
punctuation similarity by 0.4 and the vector
space similarity measure by 1, which is defined
as a base.
The similarity connections are sorted descend-
ingly and sequentially processed. At each itera-
tion only connections between dangling words
are stored. Thus there is only one connec-
tion left for each word resulting in partial word
alignment. The weights of all obtained word-
to-word connections are summed up to pro-
duce the weight of the clause association that is
propagated to the clause similarity calculation
stage.
3.3.2 Length similarity
Zero-weighted similarity connections between
clauses are collected using Gale-Church?s distance
measure. Thus connections are added without in-
creasing the weight of the existing ones.
3.3.3 Weighted punctuation similarity
This similarity is calculated by the following for-
mula
?
Z?PU
min(count(Z ? cl1), count(Z ? cl2)),
105
where PU is the set of the punctuation marks and
special symbols being prefixes and suffixes of words
in the clauses processed.
3.4 Clause alignment with the bootstrapping
method
The bipartite graph is built by filtering the set of the
calculated clause similarity connections. The con-
nected components of this graph form the clause
beads. A conservative fallback strategy is applied
to add the dangling clauses to the most appropri-
ate bead. The filtering process starts by defining a
threshold for grouping (1,2) and every clause simi-
larity connection with weight above it is considered
strong. In a way similar to word alignment, the re-
maining (weak) connections are sorted descendingly
and processed one by one. If the processed connec-
tion relates clauses that are not attached to any bead,
it passes the filter. In other words these two clauses
form a 1:1 bead.
The bootstrapping method evaluated on the test
corpus has precision above 94% and recall of 77%.
To overcome this low recall we combine the Gale-
Church algorithm with the core method.
3.5 Combined clause alignment
The combined method also distinguishes strong and
weak clause connections by means of a threshold
constant. At the beginning the Gale-Church results
in clause alignment are compared with the strong
connections. If they comply with the Gale-Church?s
beads, the weak connections are processed. The
weak connections are added to the final graph if
they do not contradict Gale-Church?s output, i.e.
when they do not connect clauses from two differ-
ent beads.
In case of a strong connection the Gale-Church?s
alignment is discarded, assuming that the seman-
tic and the syntactic similarities between clauses are
more significant than the length.
4 Clause alignment evaluation
4.1 Test corpus
A test corpus was constructed for the purposes
of method evaluation. It consists of 363,402 to-
kens altogether (174,790 for Bulgarian and 188,612
for English) distributed over five thematic domains:
Fiction (21.4%), News (37.1%), Administrative
(20.5%), Science (11.2%) and Subtitles (9.8%). The
purpose of using a general testing corpus with texts
from a variety of domains is to investigate method
performance in a wider range of contexts.
Both Bulgarian and English parts of the corpus
are first automatically segmented and then aligned
at sentence level. The task of sentence detection
in Bulgarian is carried out using a Bulgarian sen-
tence splitter (Koeva and Genov, 2011). For sen-
tence splitting of the English texts a pre-trained
OpenNLP2 model is used. Sentence alignment is
produced using HunAlign3 (Varga et al., 2005), with
the alignment manually verified by human experts.
Clause splitting is considered a highly language
dependent task and separate linguistic models need
to be developed for each language. For the pur-
poses of the present study, Bulgarian sentences are
manually or semiautomatically split into clauses and
for the English texts a pre-trained OpenNLP parser
is used to determine clause boundaries followed by
manual expert verification and post-editing (the task
of automatic clause splitting falls outside the scope
of the present study).
Subsequently, manual clause alignment is per-
formed. Tables 1 and 2 present the number of sen-
tences and clauses, respectively, in Bulgarian and
English with their average length in tokens (LS(t))
and in characters (LS(ch)).
Language
Sentences
number LS(t) LS(ch)
Bulgarian 13,213 13.23 73.04
English 13,896 13.57 69.21
Total 27,109 ? ?
Table 1: Number of sentences and their length.
Different models of clause alignment reflect in-
terlingual symmetry or assymetry, such as: 1:1 for
equivalent clauses in both languages; 0:1 or 1:0 if
a clause in one of the languages is missing in the
other; 1 : N and N : 1 (N > 1) in the cases of dif-
ferent clause segmentation, when clauses contain the
same information; N : M (N,M > 1) in relatively
rare cases when the information is crossed among
2http://opennlp.apache.org/index.html
3http://mokk.bme.hu/resources/hunalign/
106
Language
Clauses
number LS(t) LS(ch)
Bulgarian 24,409 7.20 39.54
English 28,949 6.57 33.22
Total 53,358 ? ?
Table 2: Number of clauses and their length.
clauses. The distribution of the models is given in
Table 3.
Model Frequency % of all
0:1 553 2.53
1:0 412 1.88
1:1 17,708 80.88
1:2 2,055 9.39
1:3 309 1.41
1:4 98 0.45
2:1 588 2.69
2:2 81 0.37
2:3 15 0.07
3:1 31 0.14
3:2 7 0.03
Table 3: Distribution of bead models in the manually
aligned corpus.
4.2 Evaluation
The precision is calculated as the number of true
connections (between clauses in the two languages)
divided by the number of the proposed connections,
while the recall is the proportion of true connections
to all connections in the corpus. The connections in
a bead are the Cartesian product of the clauses in the
first and the second language. The K : 0 and 0 : K
bead models are considered as K : 1 and 1 : K by
adding a fake clause.
The evaluation is performed both over the corpus
as a whole and on each of the domain specific sub-
corpora included in it.
The evaluation of the clause alignment implemen-
tation of the Gale-Church algorithm on the same cor-
pus shows overall precision of 0.902, recall ? 0.891
and F1 measure ? 0.897. Although the original
Gale-Church method performs very well in terms of
both precision and recall, sentence alignment poses
a greater challenge. The explanation for this fact lies
Domain Precision Recall F1
Total 0.910 0.911 0.911
Administrative 0.865 0.857 0.861
Fiction 0.899 0.902 0.901
News 0.933 0.946 0.940
Science 0.874 0.852 0.862
Subtitles 0.934 0.934 0.934
Table 4: Performance of the flexible method.
in the broader scope of variations of clause corre-
spondences as compared to sentences.
The bootstrapping method performs better in the
translations with clause reordering. An example
is the administrative subcorpus where Gale-Church
gives precision/recall ? 81.5%/79.7% compared to
86.6%/85.8% shown by the bootstrapping method.
In the texts with less clause order asymmetries the
results are close.
5 Application of clause alignment in SMT
Typical Moses4 (Koehn et al., 2007) models are built
on a large amount of parallel data aligned at the sen-
tence level. For the purposes of the present study a
specially designed parallel corpus is used. The aim
is to demonstrate the effect of using syntactically en-
hanced parallel data (clause segmentation and align-
ment, reordering of clauses, etc.).
A series of experiments with Moses is designed
to demonstrate the effect of training data modifica-
tion on the performance of the SMT system. The
different training datasets comprise the same sen-
tences but differ in their syntactic representation.
The baseline model is constructed on the basis of
aligned sentence pairs. The first experiment is based
on aligned clauses rather than sentences. The second
experiment demonstrates the effect of reordering of
the clauses within the source language sentences.
The main purpose of the experiments is to demon-
strate possible applications of the clause alignment
method for training an SMT system, enhanced with
linguistic information.
5.1 Training corpus
For the demonstration purposes of the present study
we apply a small corpus of 27,408 aligned sen-
4http://www.statmt.org/moses/
107
tence pairs (comprising 382,950 tokens in Bulgar-
ian and 409,757 tokens in English) which is semi-
automatically split into clauses and automatically
aligned at clause level. The current purposes of the
research do not include the development of a full
SMT model but focus on the demonstration of the
effect of syntactical information on the performance
of the SMT system. Thus, the size of the train-
ing corpus is considered sufficient for demonstration
purposes. The parallel texts are extracted from sev-
eral domains ? Administrative, Fiction, News, Sci-
ence, Subtitles.
5.2 Test corpus
The test corpus compiled for the purposes of evalu-
ation of the SMT performance is independently de-
rived from the Bulgarian-English parallel corpus and
does not overlap with the training corpus. It how-
ever, resembles its structure and contains texts from
the same domains as the training data. Table 5 gives
the number of tokens in the Bulgarian and in the En-
glish part of the test corpus, with percent of tokens
in the Bulgarian texts.
Domain BG ENl % (BG)
Administrative 36,042 35,185 21.10
Fiction 34,518 38,723 20.21
News 64,169 62,848 37.57
Science 18,912 19,856 11.07
Subtitles 17,147 18,951 10.04
Total 170,788 175,563
Table 5: Number of tokens in the test corpus.
5.3 Baseline model
The baseline model corresponds to the traditional
Moses trained models and is constructed from
aligned sentences in Bulgarian and English. The
BLEU score for translation from Bulgarian into En-
glish is 16.99 while for the reverse it is substantially
lower ? 15.23. In the subsequent tests we observe
the results for the Bulgarian-to-English translation
only.
5.4 Clause level trained model
The first experiment aims to demonstrate that train-
ing of the model based on aligned clauses rather than
sentences yields improvement. The assumption is
that alignment at a sub-sentential level would im-
prove word and phrase alignment precision by limit-
ing the scope of occurrence of translational equiva-
lents. On the other hand, however, lower level align-
ment reduces the number of aligned phrases. For
this purpose clauses are the optimal scope for align-
ment as phrases rarely cross clause boundaries.
The results of the clause level training show small
improvement of 0.11 in the BLEU score from 16.99
(baseline) to 17.10 for the Bulgarian-to-English
translation.
5.5 Reordering of clauses
The second experiment relies on reordering of
clauses within aligned sentences. The experiment
aims at showing that reordering improves perfor-
mance of SMT system.
A simple clause reordering task was carried out
within the sentences on the parallel training cor-
pus. Clause reordering involves linear reordering of
clauses in the source language sentences to match
the linear order of corresponding clauses in the tar-
get language sentences.
Reordering applies to cases where asymmetries
are present in the alignment i.e. crossed connections
between clauses, which is expected to vary across
languages and domains. This suggests that the pro-
portion of the corpus affected by reordering also de-
pends on the language and on the domain. Based on
an experiment with a smaller corpus, approximately
7% of the Bulgarian sentences are affected by re-
ordering when adjusted to the English sentences.
The result is BLEU score of 17.12 compared to
16.99 (baseline) which yields an improvement of
0.13.
5.6 Analysis
The results obtained from the above two experi-
ments show a small yet consistent improvement in
the BLEU score. It shows a possibility to im-
prove the results by applying parallel data enhanced
by syntactic information, namely, aligned pairs at
clause level, or sentences with reordered clauses.
The data, however, are not sufficient to draw a
definite conclusion both on whether the improve-
ment is stable and on which of the two methods ?
108
using clause aligned pairs or reordered sentences ?
performs better.
6 Conclusions
The research done in the scope of this paper has
shown that, on the one hand, the Gale-Church al-
gorithm is applicable for clause alignment. The re-
sults achieved by the bootstrapping method, on the
other hand, show that clause alignment may be ap-
propriately improved by means of similarity mea-
surement especially for the domain dependent tasks
? particularly for the domains for which non-linear
order of the translated clauses is typical. Exper-
iments showed that especially for texts exhibiting
alignment asymmetries our method for clause align-
ment outperforms Gale-Church considerably.
We applied automatic clause alignment for build-
ing a Moses training dataset enhanced with syntac-
tic information. Two experiments were performed
? first, involving aligned clause pairs, and the sec-
ond using clause reordering in the source language
assuming that the order of clauses in the target lan-
guage defines relations specific for the particular
language. The experiments suggest that the clause
reordering might improve translation models.
The series of experiments conducted with Moses
showed possible applications of the clause align-
ment method for training an SMT system, enhanced
with linguistic information.
References
