Proceedings of the ACL-08: HLT Workshop on Parsing German (PaGe-08), pages 1?8,
Columbus, Ohio, USA, June 2008. c?2008 Association for Computational Linguistics
Lexcalised Parsing of German V2
Yo Sato
Department of Computer Science
Queen Mary, University of London
Mile End Road, London E1 4NS, U.K.
Abstract
This paper presents a method and implemen-
tation of parsing German V2 word order by
means of constraints that reside in lexical
heads. It first describes the design of the
underlying parsing engine: the head-corner
chart parsing that incorporates a procedure
that dynamically enforces word order con-
straints. While the parser could potentially
generate all the permutations of terminal sym-
bols, constraint checking is conducted locally
in an efficient manner. The paper then shows
how this parser can adequately cover a variety
of V2 word order patterns with sets of lexi-
cally encoded constraints, including non-local
preposing of an embedded argument or an ad-
verbial.
1 Introduction
This paper presents a method of parsing V2 word
order manifested in a variety of German matrix sen-
tences in a lexicalised and locality-respecting man-
ner: lexicalised, as the V2 pattern is licensed ulti-
mately encoded in verbs, in the form of constraints
that hold amongst its arguments and itself; locality-
respecting, because (a) no constraint that operates on
constituents from different subcategorisation frames
is invoked and (b) the matrix verb and the prever-
bal constituent, however ?distant? its origin is, are
ordered in the same projection via the slash-based
mechanism.
The underlying grammar is loosely linearisation-
based, in the sense that word order is dissoci-
ated from the syntactic structure in a discontinuity-
allowing manner, as presented in Sato (2008). The
main benefit of a linearisation approach is that syn-
tactic constituency becomes independent (to a de-
gree) of its surface realisation and hence discour-
ages constituency manipulation for the sake of word
order. In line of this spirit I will largely adopt the
simple constituency construal that faithfully corre-
spond to its semantics. However, I distance myself
from the more or less standard version of linearisa-
tion grammar where potentially non-local LP con-
ditions are permitted (Reape, 1993) or word order
patterns are imposed at the clause level (as in ?topo-
logical field? model of Kathol (2000)).
The crux of the proposal consists in employing
a head-corner parsing in which the set of word or-
der constraints are incorporated into a VP?s lexical
head (i.e. common or auxiliary verb). For a V2 pro-
jection, its head verb contains the constraints to the
effect that only one of its arguments can be fronted
immediately before the verb itself. To enable this,
potential discontinuity and obligatory adjacency in
part of a phrase is included in the repertoire of word
order constraints in addition to the standard LP (lin-
ear precedence) constraints.
2 The data
The V2 constructions to be dealt with in this paper
are as follows (I will use as an example the tertiary
verb gebengive or its past participle gegebengiven
throughout):
1. The ?basic? case where dependency between
the preverbal constituent and the matrix verb is
strictly local, e.g:
1
Ein Buch geben die Eltern dem Sohn.
a book give the parents the son
?A book the parents give the son?
2. The case where an argument of the lower verb
is fronted across the higher auxiliary verb:
Ein Buch haben die Eltern dem Sohn gegeben.
a book have the parents the son given
?A book the parents have given the son?
3. The long-distance dependency case:
Ein Buch, sagt ein Freund, dass er glaubt, dass die
Eltern dem Sohn geben.
?A book, a friend says that he thinks that the parents
give the son?
4. Adjunct fronting
Heimlich haben die Eltern dem Sohn ein Buch gegeben.
secretly have the parents the son a book given
?Secretly the parents have given the son a book.?
5. Partial VP fronting
Ein Buch dem Sohn gegeben haben die Eltern.
Ein Buch gegeben haben die Eltern dem Sohn.
As stated, our approach adopts a linearisation ap-
proach in which constituency does not determine the
surface realisation, which is handled instead by word
order conditions encoded in lexical heads. My con-
tention here is not so much plausibility as a grammar
as neutrality to particular phrase structures, which
linearisation promotes. Therefore I take a rather
simplified position to use an entirely uniform phrase
structure for the verb-argument structure for com-
mon verbs, namely the flat construal where all the
arguments as well as the head project onto a clause
(?VP?) as mutual sisters, although I hasten to add
our constraint enforcement could equally apply to
configurational analyses. In fact we take an auxil-
iary verb to subcategorise for a clause rather than
the complex verb analysis, and adopt the traditional
binary iteration analysis for adjunct-head phrases, to
see how our parser fares with configurational analy-
ses.
I sum up the assumed constituency of the above
examples graphically as trees (though this has little
impact on word order):
(1) Clause(=VP)      
V
geben

NP
die Eltern
DD
NP
dem Sohn
aaa
NP
ein Buch
(2)&(5)     
Aux
haben
PPP
Clause(((( hhhh
-e E. -em S. ein Buch gegeben
(3) ((((((
NP
ein Freund

V
sagt
bb
CP!!
C
dass
HH
Clause
NP
er

V
glaubt
aa
CP""
C
dass
```
C`lause    ````
-e E. -em S. ein Buch geben
(4) 
Aux
haben
PPP
Clause    
Adv
heimlich
PPP
Clause(((( hhhh
-e E. -em S. ein Buch gegeben
3 The parser
3.1 Core design
The design of the parser employed here can be
called constrained free word order parsing. First,
it allows for completely free word order at default.
The core algorithm for the parse engine is what
Reape (1991) presents as a generalised permutation-
complete parser, which in turn is based on the pre-
ceding proposal of Johnson (1985). Details apart,
while using context-free production rules (no multi-
ple left-hand side non-terminal symbols), this algo-
rithm only checks for the presence of all the right-
hand side constituents, wherever in the string they
occur, potentially discontinuously,1 effectively li-
censing all the permutations of the given terminal
symbols (e.g. 3! = 6 permutations for the string
consisting of ring, up and John including up John
ring etc.). This ?directionless? parsing is rendered
possible by Johnson?s ?bitvector? representation of
partial string coverage. In the above up John ring
string, the coverage of the ring and up combina-
1More precisely, it searches for non-overlapping combina-
tions, excluding the same word being counted more than once
or more than one word counting towards the same rule in the
same search path.
2
tion, which materially constitutes a complex verb,
is represented as [1,0,1]. This is then then merged
with the bitvector of John, [0,1,0] into [1,1,1]. Sec-
ond, however, this rather promiscuous (and expen-
sive) parsing is dynamically restricted by word or-
der constraints that obtain in individual languages.
With sufficient constraints applied during the parse,
the above combinations with ring, up and John are
restricted to ring up John and ring John up.
I do not claim for originality in this basic design.
Daniels (2005) for example describes an implemen-
tation of an algorithm that falls precisely in such
style of parsing.2 The main points of the proposal
lie in lexicalisation and localisation, which contrast
with the general trend to introduce phrasal and non-
local constraint processing for German processing,
of which Daniels? work is an example. All the word
order constraints are stored in lexicon, more specifi-
cally in lexical heads.
To adapt this design to a practical lexically driven
parsing, the author implemented a rendering of
head-corner chart parsing. It is head-corner in the
sense described e.g. in van Noord (1991), where
the parsing of a production rule always starts from
its head. This is necessary for our design because
the parser first retrieves the word order information
from the head. Furthermore, it requires the words
to be processed first by preterminal rules since with-
out processing lexical heads the whole recognition
process does not come off the ground. Therefore, a
chart parsing algorithm that invokes lexical initiali-
sation is utilised (as described in Gazdar & Mellish
(1989) rather than the classical top-down parsing of
Earley (1970)).
3.2 Constraint checking and propagation
Since no non-local word order constraints are intro-
duced in our parsing, they can be fully enforced at
each application of a production rule. More specif-
ically, the checking of constraint compliance is car-
ried out at the completer operation of chart pars-
ing.3 The data structure of an edge is suitably mod-
ified. In addition to the dotted production rule, it
needs to carry the constraint set relevant to the corre-
2A foregoing implementation by Mu?ller (2004) also em-
ploys bitvector-based linearisation approach.
3The equivalent operation is called the ?fundamental rule? in
Gazdar & Mellish (1989).
sponding production rule, retrievable from the head,
which is always processed first in our head-corner
algorithm.4 Also, as we are adopting the bitvector
representation of coverage, an edge contains its cor-
responding bitvector. The completer operation in-
volves merger of two bitvectors, so the check can be
conducted at this stage:
Completer in constrained parsing
Let A and B be symbols, ?, ? and ? be arbi-
trary strings, V1 and V2 be bitvectors and V m
be their merge, then:
If the chart contains an active edge ?V1, A? ?
? B ?? and a passive edge ?V2, B? ? ? ?, run
the CHECK-ORDER procedure. If it succeeds,
add edge ?V m, A? ?B ? ?? to the chart if V1
and V2 are mergeable. If it fails, do nothing.
The CHECK-ORDER procedure consists in a bit-
wise comparison of bitvectors. It picks out the
bitvectors of the categories in question and checks
the compliance of the newly found category with re-
spect to the relevant constraints. If for example A, B
and C had been found at [0,1,0,0,0], [0,0,1,0,1] and
[1,0,0,1,0] respectively, this would validate A ? B
but not A ? C. Thus the edges for string combina-
tions that violate the word order constraints would
not be created, eliminating wasteful search paths.
As we will shortly see, the constraint type that
checks continuity of a phrase is also introduced.
Therefore the phrase (dis)continuity can also be as-
certained locally, which is a major advantage over a
parsing that relies largely on concatenation. Thus,
the cost of constraint checking remains very small
despite the capability of processing discontinuity.5
Note however that by locality is meant subcat-
egorisation locality (or ?selection? locality as de-
scribed in Sag (2007)): whatever is in the same
subcategorisation frame of a lexical head is consid-
ered local. Depending on the adopted analysis, con-
stituents ?local? in this sense may of course occur
in different trees. Constraints on such ?non-local?
?in the tree sense but not in the subcategorisation
sense? constituents are still enforceable in the im-
plemented parser. The unused constraints at a node,
4This retrieval of word order information is carried out at the
predictor stage of chart parsing.
5It is worth mentioning that the bitvector checking is con-
ducted over the whole string, the effect of applied constraints
will be never lost.
3
for example some constraint applicable to the verb
and its subject at the VP node in the configurational
(subjectless-VP) analysis, is made to propagate up
to the upper node. Thus it is no problem to enforce
a constraint over ?different trees?, as long as it is ap-
plied to ?local? constituents in our sense.6
4 Possible constraints and subtyping
It is crucial, if the computational properties of the
parser is to be transparent in constrained free word
order parsing, to identify the kind of word order con-
straints admitted into lexical heads. We will remain
relatively conservative, in introducing only two op-
erators for constraint encoding. We first invoke the
binary LP operator (?) in a conventional sense: the
whole (or, equivalently, right-periphery) of a string
for category A needs to precede the whole (or left-
periphery) of a string for category B to satisfy A ?
B (I will use the shorthand A ? (B,C) to express
(A ? B) ? (A ? C). Crucially, the contiguity op-
erator () is added. It takes a set of constituents as its
operand and requires the constituents in it to be con-
tiguous, regardless of their order. Thus, {A,B,C}
encodes the requirement for A, B and C as a whole
forming a contiguous string. For example, the string
I ring John up does not satisfy {ring, up} but does
satisfy {ring, John, up}.
Also important is how to succinctly generalise
on the word order patterns now encoded in lexical
items, as one would certainly want to avoid a te-
dious task of writing them all individually, if they
allow for broader classification. For example the En-
glish transitive verb generally follows its subject ar-
gument and precedes its object argument, and one
would naturally want to lump these verbs under one
umbrella. For such a cluster of lexical heads, we will
introduce a word order (sub)type. More pertinently,
the German verbs may be classified into v1-verb, v2-
verb and vf-verb according to the positions of their
arguments in their projection. We will also allow
multiple inheritance that becomes standard in the
typed feature system (cf. Pollard and Sag (1987)).
6See Sato (2006) for details.
5 Constraints for V2
5.1 General setup
To enforce the V2 word order pattern lexically, I pro-
pose to use a combination of two word order sub-
types: dislocating-verb (disl-v) and matrix-v2-verb
(mtrx-v2-v). The former type represents a verb one
of whose arguments is to be ?dislocated?. A verb of
this type can thus be characterised as ?contributing?
the dislocated (preverbal) element. The latter, on the
other hand, is the type that is projected onto a ma-
trix sentence. This type should be constrained such
that one dislocated constituent must ?and only one
may? precede and be adjacent to the verb itself. It
may be characterised as a verb that provides a locus
?immediately before itself? of, or ?receives? the
dislocated element.
Dislocation is handled by a constraint percola-
tion mechanism. I assume the dislocated constituent
is pushed into a storage that then participates in a
slash style percolation, although the storage content
would still need to be ordered by lexicalised con-
straints rather than by the percolation mechanism it-
self, as they are the sole resource for word order.7
Thus the checking as regards the dislocated con-
stituent is conducted at each projection in the per-
colation path, hence locally, while the percolation
mechanism gives some ?global? control over disloca-
tion. Not just the positioning of the dislocated con-
stituent at the left-periphery of the whole sentence,
but the assurance of a global singularity restriction
of dislocation ?not just one constituent per clause
in multiple embeddings? becomes thus possible.
Let args be the set of the arguments of a disl-v,
disl be that of the dislocated one and situ be that of
the remaining arguments, i.e. disl ? args where
|disl| = 1 and situ = {x|x ? args ? x /? disl}.
Then the type disl-v can be characterised as having
the following constraint:
disl-v: disl ? situ (disl ? dislst)
Simply put, this says that the arguments are divided
into two parts, the dislocated and in-situ parts, the
former of which precedes the latter. We assume, as
7The adopted mechanism is close to Penn (1999), though
he invokes potentially non-local topology-based constraints and
removes the filler and gapped head entirely.
4
in the standard treatment, there is only one dislo-
cated constituent, until we consider the VP fronting.
The notation with an arrow on the right indicates this
singleton set is pushed into the storage that is prop-
agated upwards.
The mtrx-v2-v type is then characterised as fol-
lows:
mtrx-v2-v: dislst ? verb, {dislst, verb}
This simply says the dislocated constituent (stored
in a lower node and percolated) immediately pre-
cedes the matrix verb. (For the following presen-
tation, the storage-related notations will be omitted
and implicitly assumed unless necessary. Also, the
set variables disl and args will be used with the same
meaning.)
Thus the combination of the two types gives, for
example where args = {A,B,C}, disl = {A} and
the matrix verb is V , the following constraint set:
{A ? (B,C), A ? V, {A, V }}
which essentially says that the dislocated A immedi-
ately precedes the matrix verb V and precedes (not
necessarily immediately) the in-situ B and C.
5.2 Local case
To begin with, let us see a case where dependency
between the preverbal constituent and the matrix
verb is strictly local, taking (1) as an example. Note
first that there are six possible variants:
(1)
a. Die Eltern geben dem Sohn ein Buch.
b. Die Eltern geben ein Buch dem Sohn.
c. Dem Sohn geben die Eltern ein Buch.
d. Dem Sohn geben ein Buch die Eltern.
e. Ein Buch geben die Eltern dem Sohn.
f. Ein Buch geben dem Sohn die Eltern.
In this case, geben is both a matrix (argument-
receiving) and dislocating (argument-contributing)
verb. This means that the two subtypes should be
overloaded. Let us call this overloaded sub-species
disl-mtrx-v2-v: which is given the following specifi-
cation:
disl-mtrx-v2-v:
disl ? situ, disl ? verb, {disl, verb}
To adapt this type to our verb, geben, where we rep-
resent its arguments as sNP (subject NP), ioNP (in-
direct object NP) and doNP (direct object NP), we
obtain, for the case where sNP is preposed:
{sNP ? (ioNP, doNP),
sNP ? geben, (sNP, geben)}
where the constraints on the first line is inher-
ited from disloc-v while those on the second from
matrix-v2-v. This corresponds to the sentences (a)
and (b) above. The followings are the cases where
ioNP and doNP are preposed, corresponding to (c,d)
and (e,f), respectively.
{ioNP ? (sNP, doNP), ioNP ? geben, (ioNP, geben)}
{doNP ? (sNP, ioNP), doNP ? geben, (doNP, geben)}
These possible sets are enforced in the manner of
exclusive disjunction, that is, only one of the above
three sets actually obtains. This does not mean, how-
ever, each set must be explicitly stated in the verb
and processed blindly. Only the abstract form of
the constraint, as described under the type specifi-
cation above, is written in the lexicon. During pars-
ing, then, one of the sets, as dynamically found to
match the input string, is computed and applied. In
the subsequent discussion, therefore, only the direct-
object fronting case is considered as a representative
example for each construction.
5.3 Argument fronting across auxiliary
We now consider the cases where the dependency is
not local, starting with an auxiliary-involving case.
The dependency between an auxiliary and an ar-
gument of its lower verb is, according to the Aux-
Clause construal adopted here, is not local. We can
however succinctly specify such non-local V2 ren-
derings as a case where the above two types are in-
stantiated separately in two verbs. The example is
reproduced below:
(2) Ein Buch haben die Eltern dem Sohn gegeben.
The argument-contributing gegebengiven is, as
before, assigned the disl-v type, but is further sub-
typed and inherits the constraints also from vf-v (v-
final verb), reflecting the fact that it occurs head-
finally.
gegeben (type disl-vf-v):
{doNP ? (sNP, ioNP),
5
(sNP, doNP, ioNP) ? gegeben}
The dislocated doNP climbs up the tree ((2) in
Section 2) in the storage, which is then subject to
the constraints of matrix haben at the top node. This
argument-receiving auxiliary haben is, as before,
given the mtrx-v2-v status.8.
haben (type mtrx-v2-v):
{doNPst ? haben, (doNPst, haben)}
Thus the dislocated ein Buch is duly placed at the
left-periphery in a manner that forbids intervention
between itself and the matrix verb.
5.4 Long-Distance Dependency
Having dealt with an argument fronting of the auxil-
iary construction as a non-local case, we could now
extend the same treatment to long-distance depen-
dency. Our example is:
(3) Ein Buch, sagt ein Freund, dass er glaubt, dass
die Eltern dem Sohn geben.
(?A book, a friend says that he thinks that the
parents give the son?)
In fact, it suffices to endow exactly the same type
as gegeben, i.e. disl-vf-v, to the occurrence of geben
in a subordinate clause.9
geben (in subord. clause, type disl-vf-v):
{doNP ? (sNP, ioNP),
(sNP, doNP, ioNP) ? geben}
This ensures that the dislocated argument goes
progressively up towards the top node. To prevent
this argument from being ?dropped? the half way
through, however, the non-matrix CP-taking verbs
?in the middle? that should be bypassed, in our case
glaubt, needs to possess the constraint that pushes
the dislocated element to the left of itself:
glaubt (in subord. clause, type ?middle-v?):10
{doNPst ? glaubt}
8More precisely this also involves haben? VP(gapped)
9This means that, given the identical morphological form,
gegeben is type-ambiguous between the matrix and subordinate
occurrences. This does not add too much to parsing complexity,
however, as this ?ambiguity? is quickly resolved when one of its
argument is encountered.
10The constraints applicable to the usual finite verb is omit-
ted, i.e. sNP ? glaubt and glaubt ? CP(gapped).
Finally, a mtrx-v2-v, in our case sagt, takes care of
placing the dislocated constituent immediately be-
fore itself.
sagt (type mtrx-v2-v):11
{doNPst ? sagt, (doNPst, sagt)}
5.5 Adjunct fronting
I declared at the beginning to use the traditional bi-
nary adjunction analysis for adjunct-head phrases.12
In order to achieve this, I first propose a fundamental
conceptual shift, given the iterability and optionality
of adjuncts. In the traditional concept of adjunct-
head phrases, it is the adjunct that selects for the
head it modifies rather than the other way round.
Also semantically, the adjunct is considered the ?se-
mantic head? that works as a functor. In light of
this background, it is not implausible to take the
adjunct as the ?parsing head? equipped with word
order constraints. In fact, the opposite option ?
equipping the syntactic head with its relative word
order with adjuncts? is not as feasible in our lexi-
cal head-corner parsing. The iterability of adjuncts
means that the head would have to be equipped with
an infinite number of adjuncts as its ?arguments?,
which would lead to various uninstantiation prob-
lems. Therefore, I swap the statuses and treat, in
terms of parsing, the adjunct as a functor with word
order constraints incorporated relative to its modi-
fiee.
Thus, the word order constraints are now given
to the lexical adjuncts also. I will take as an ex-
ample adverbs.13 Adverbs are now the potential lo-
cus of word order patterns relative to its modifiee
(clause/VP), but are not given any specific constraint
in German generally, because one can appear either
after or inside a clause. Our focus is solely on the
possibility of putting one before the clause it modi-
fies, when it is subject to the V2 constraint. This is
handled simply by saying, for such a type, which we
call disl-adverb, it dislocates itself, in the manner of
11Likewise: sagt ? CP(gapped) omitted.
12That is against the temptation for a constituency change
that renders adjuncts sisters on par with arguments (cf. Bouma
et al(2001)), in which case V2 would simply fall out from the
foregoing word order types.
13The same treatment can be extended to prepositional ad-
juncts (remember the unused constraints will percolate up to
the maximal projection).
6
?head movement? which is widely used in German
syntax (Kiss and Wesche, 1991; Netter, 1992).
disl-adverb: adv (adv? dislst)
This specification ensures the adverb itself goes
onto the extraction path, to be placed at the left-
periphery, triggered by the mtrx-v2-v type. The sin-
gularity of the adverbials at the prerverbal position
is ensured by means of percolation storage control.
6 Verbal Fronting
Our last challenge concerns fronting of verb or ver-
bal projections. From the preceding discussion, an
option that suggests itself is to treat the verb fronting
as the case of verb dislocating itself. I will in-
deed propose a strategy along this line, but this av-
enue proves more difficult due to complications spe-
cific to verb-related fronting. Firstly, generally such
fronting is limited to the environment of a lower VP
governed by a higher verb such as an auxiliary, as
can be seen from the following contrast:
(4)
a. Gegeben haben die Eltern dem Sohn ein Buch.
b. *Geben, sagt ein Freund, dass die Eltern dem Sohn ein
Buch.
Second, the type we used for gegeben in Section
5.3, namely disl-vf-v, clearly does not work, as the
verb does not occur phrase-finally (but in fact ini-
tially) relative to its sisters in (4a). Some relaxation
of LP constraints seem to be in order.
Thirdly, German displays a variety of ways to
front part of a VP:
(5)
Gegeben haben die Eltern dem Sohn ein Buch.
Dem Sohn gegeben haben die Eltern ein Buch.
Ein Buch gegeben haben die Eltern dem Sohn.
Dem Sohn ein Buch gegeben haben die Eltern.
This raises the question of whether this fits in the V2
pattern at all, coupled with the ongoing debate on the
status of the preverbal string. Quite apart from the
theoretical debate, however, how best to adequately
generate these patterns is an acute parsing issue. We
are assuming the flat clause=VP anaylsis, so relax-
ing the singularity condition seems unavoidable.
Fourthly, to make the matter worse, allowing mul-
tiple frontings and dropping LP requirements does
not solve the problem, as ordering of the preverbal
constituents is constrained, as shown in the follow-
ing data:
(6)
*Gegeben dem Sohn haben die Eltern ein Buch.
*Dem Sohn gegeben ein Buch haben die Eltern.
It is a great challenge for any syntactician to pro-
vide a unified account for such complex behaviour,
and I confine myself here to offering the ?solution?
sets of constraints that adequately generate the de-
sired string. What I offer is this: allowing multiple
dislocations only for the verbal fronting cases via a
new word order subtype, while retaining the verb-
final LP conditions for these dislocated constituents.
For this new type we first relax the singularity
condition for dislocation. To allow multiple dislo-
cations, it would suffice to drop the |disl| = 1 condi-
tion, but an unrestricted application of disl ? args
would lead to overgeneration, due to two further
constraints applicable: (1) not all arguments can and
(2) the subject argument cannot be fronted along
with the verb (as in (a) and (b) below, respectively):
(7)
a. *Die Eltern dem Sohn ein Buch gegeben haben.
b. *Die Eltern gegeben haben dem Sohn ein Buch.
*Die Eltern ein Buch gegeben haben dem Sohn.
Therefore we add the conditions to exlude the above,
along with the the verb-final constraint applicable
the dislocated constituents to exclude (6). Let us call
this type frontable-v. The constraint specification is
as follows:
gegeben (frontable-v):
disl = {gegeben} ? ptargs, ptargs ? gegeben
where ptargs ? args and sNP /? ptargs
The proposed constraint set might strike as rather
ad hoc. It would clearly be better to treat both the
fronted and non-fronted occurrences of gegeben as
sharing some common word order type, and what is
meant by ?applying the constraints amongst the dis-
located constituents? needs to be fleshed out. Thus
this may not be an elegant solution, but nevertheless
is an generatively adequate solution. More impor-
tantly it serves as a good example for the flexibility
7
and adaptability of constrained free word order pars-
ing, because it handles a rather complex word order
pattern in a way neutral to grammatical construal,
i.e. without invoking constituency manipulation.
7 Concluding Remarks
I conclude this paper by responding to a natural ob-
jection: why would one have to go through this con-
voluted route of lexical word order control, when
the ?natural? way to constrain V2 ?or V1 and VF,
for that matter? would be to have some ?global?
patterns pertinent to clause types? My responses
are primarily engineering-oriented. First, lexicalised
encoding gives the parser, through locality restric-
tion, a certain control over computational complex-
ity, as the search space for constraint enforcement is
restricted.14 However this not an entirely unique, if
more amenable, feature to lexicalised parsing, as one
could impose such a control in non-lexicalised pars-
ing. The advantage truly unique to lexicalising word
order lies in rendering the parser and grammar in-
dependent of surface realisation and hence re-usable
across languages. In short, it promotes modularity.
As we have seen, though the parser needs to con-
form to a certain strategy, the word order component
is fairly independent, as a separate procedure which
can be modified if for example more types of word
order operators are needed. The grammar could also
be kept more compact and cross-linguistically appli-
cable, because word order is abstracted away from
constituency. Therefore, paradoxically, an advan-
tage of lexicalising German parsing is to enable the
same parser/grammar to be used in other languages
too, even if it is not naturally suited to the language.
References
Gosse Bouma, Robert Malouf, and Ivan Sag. 2001. Sat-
isfying constraints on extraction and adjunction. Nat-
ural Language and Linguistic Theory, 19(1).
Mike Daniels. 2005. Generalized ID/LP Grammar.
Ph.D. thesis, Ohio State University.
Jay Earley. 1970. An efficient context free parsing algo-
rithm. Communications of ACM, 13:94?102.
Gerald Gazdar and Chris Mellish. 1989. Natural Lan-
guage Processing in Prolog. Addison Wesley.
14For a complexity analysis of such grammar, see Sato (2008)
and Suhre (1999).
Mark Johnson. 1985. Parsing with discontinuous con-
stituents. In Proceedings of the 23rd Annual Meeting
of the ACL, pages 127?132.
Andreas Kathol. 2000. Linear Syntax. OUP.
Tibor Kiss and B Wesche. 1991. Verb order and head
movement. In O Herzog, editor, Text Understanding
in LILOG, pages 216?40. Springer.
Stefan Mu?ller. 2004. Continuous or discontinuous con-
stituents? a comparison between syntactic analyses for
constituent order and their processing systems. Re-
search on Language and Computation 2(2).
Klaus Netter. 1992. On non-head non-movement. An
HPSG treatment of finite verb position in German.
In G. Go?rz, editor, Proceedings of KONVENS 92.
Springer.
Gerald Penn. 1999. Linearization and Wh-extraction in
HPSG: Evidence from Serbo-Croatian. In R. Borsely
and A. Przepiorkowski, editors, Slavic in HPSG.
CSLI.
Carl Pollard and Ivan Sag. 1987. Information-Based
Syntax and Semantics. CSLI.
Mike Reape. 1991. Parsing bounded discontinuous con-
stituents: Generalisation of some common algorithms.
DIANA Report, Edinburgh University.
Mike Reape. 1993. A Formal Theory of Word Order.
Ph.D. thesis, Edinburgh University.
Ivan Sag. 2007. Remarks on locality. In Stefan Mu?ller,
editor, Proceedings of HPSG07. CSLI.
Yo Sato. 2006. A proposed lexicalised linearisation
grammar: a monostratal alternative. In Stefan Mu?ller,
editor, Proceedings of HPSG06. CSLI.
Yo Sato. 2008. Implementing Head-Driven Linearisa-
tion Grammar. Ph.D. thesis, King?s College London.
Oliver Suhre. 1999. Computational Aspects of a Gram-
mar Formalism for Languages with Freer Word Order.
Diplomarbeit, Eberhard-Karls-Universita?t Tu?bingen.
Gertjan van Noord. 1991. Head corner parsing for dis-
continuous constituency. In Proceedings of the 29th
annual meeting on ACL, pages 114?121.
8
