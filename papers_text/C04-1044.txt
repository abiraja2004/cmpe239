Polarization and abstraction of grammatical formalisms as
methods for lexical disambiguation
Guillaume Bonfante and Bruno Guillaume and Guy Perrier
LORIA - UMR 7503,
Campus Scientifique, B.P. 239,
F-54506 Vand?uvre le`s Nancy CEDEX
{Guillaume.Bonfante, Bruno.Guillaume, Guy.Perrier}@loria.fr
Abstract
In the context of lexicalized grammars, we
propose general methods for lexical disam-
biguation based on polarization and ab-
straction of grammatical formalisms. Polar-
ization makes their resource sensitivity ex-
plicit and abstraction aims at keeping essen-
tially the mechanism of neutralization be-
tween polarities. Parsing with the simpli-
fied grammar in the abstract formalism can
be used efficiently for filtering lexical selec-
tions.
Introduction
There is a complexity issue if one consider ex-
act parsing with large scale lexicalized gram-
mars. Indeed, the number of way of associating
to each word of a sentence a corresponding ele-
mentary structure?a tagging of the sentence?
is the product of the number of lexical entries for
each word. The procedure may have an expo-
nential complexity in the length of the sentence.
In order to filter taggings, we can use proba-
bilistic methods (Joshi and Srinivas, 1994) and
keep only the most probable ones; but if we
want to keep all successful taggings, we must
use exact methods. Among these, one consists
in abstracting information that is relevant for
the filtering process, from the formalism F used
for representing the concerned grammar G. In
this way, we obtain a new formalism Fabs which
is a simplification of F and the grammar G is
translated into a grammar abs(G) in the ab-
stract framework Fabs. From this, disambiguat-
ing with G consists in parsing with abs(G). The
abstraction is relevant if parsing eliminates a
maximum of bad taggings at a minimal cost.
(Boullier, 2003) uses such a method for Lexical-
ized Tree Adjoining Grammars (LTAG) by ab-
stracting a tree adjoining grammar into a con-
text free grammar and further abstracting that
one into a regular grammar. We also propose
to apply abstraction but after a preprocessing
polarization step.
The notion of polarity comes from Categorial
Grammars (Moortgat, 1996) which ground syn-
tactic composition on the resource sensitivity of
natural languages and it is highlighted in Inter-
action Grammars (Perrier, 2003), which result
from refining and making Categorial Grammars
more flexible.
Polarization of a grammatical formalism F
consists in adding polarities to its syntactic
structures to obtain a polarized formalism Fpol
in which neutralization of polarities is used for
controlling syntactic composition. In this way,
the resource sensitivity of syntactic composition
is made explicit. (Kahane, 2004) shows that
many grammatical formalisms can be polarized
by generalizing the system of polarities used in
Interaction Grammars.
To abstract a grammatical formalism, it is in-
teresting to polarize it before because polarities
allow original methods of abstraction.
The validity of our method is based on a con-
cept of morphism (two instances of which being
polarization and abstraction) which character-
izes how one should transport a formalism into
another.
In sections 1 and 2, we present the conceptual
tools of grammatical formalism and morphism
which are used in the following.
In section 3, we define the operation of polar-
izing grammatical formalisms and in section 4,
we describe how polarization is used then for
abstracting these formalisms.
In section 5, we show how abstraction of
grammatical formalisms grounds methods of
lexical disambiguation, which reduce to pars-
ing in simplified formalisms. We illustrate our
purpose with an incremental and a bottom-up
method.
In section 6, we present some experimental
results which illustrate the flexibility of the ap-
proach.
1 Characterization of a grammatical
formalism
Taking a slightly modified characterization of
polarized unification grammars introduced by
(Kahane, 2004) we define a grammatical formal-
ism F (not necessarily polarized) as a quadruple
?StructF ,SatF ,PhonF ,RulesF ?:
1. StructF is a set of syntactic structures
which are graphs1 in which each edge
and vertex may be associated with a la-
bel representing morpho-syntactic informa-
tion; we assume that the set of labels asso-
ciated with F is equipped with subsump-
tion, a partial order denoted v, and with
unification, an operation denoted unionsq, such
that, for any labels l and l?, either l unionsq l? is
not defined, which is denoted l unionsq l? = ?, or
l unionsq l? is the least upper bound of l and l?2;
2. SatF is a subset of StructF , which repre-
sents the saturated syntactic structures of
grammatical sentences;
3. PhonF is a function that projects every
element of SatF in the sentence that has
this element as its syntactic structure.
4. RulesF is a set of composition rules be-
tween syntactic structures. Every element
of RulesF is a specific method for super-
posing parts of syntactic structures; this
method defines the characteristics of the
parts to be superposed and the unification
operation between their labels. Notice that
we do not ask rules to be deterministic.
The composition rules of syntactic structures,
viewed as superposition rules, have the funda-
mental property of monotonicity: they add in-
formation without removing it. Hence, the defi-
nition above applies only to formalisms that can
be expressed as constraint systems in opposition
to transformational systems.
Let us give some examples of grammatical for-
malisms that comply with the definition above
by examining how they do it.
? In LTAG, StructLTAG represents the set
of derived trees, SatLTAG the set of de-
rived trees with a root in the category
sentence and without non terminal leaves.
1Usually trees or directed acyclic graphs.
2The least upper bound of l and l? can exist and, at
the same time, l unionsq l? be not defined; if the operation of
unification is defined everywhere, the set of labels is a
semi-lattice.
The projection PhonLTAG is the canoni-
cal projection of a locally ordered tree on
its leaves. Finally, RulesLTAG is made
up of two rules: substitution and adjunc-
tion. To view adjunction as a superposition
rule, we resort to the monotone presenta-
tion of LTAG with quasi-trees introduced
by (Vijay-Shanker, 1992).
? In Lambek Grammars (LG), StructLG
is the set of partial proofs and these
proofs can be represented in the form
of incomplete Lambek proof nets labelled
with phonological terms (de Groote, 1999).
SatLG represents the set of complete proof
nets with the category sentence as their
conclusion and with syntactic categories
labelled with words as their hypotheses.
The projection PhonLG returns the label
of the conclusion of complete proof nets.
RulesLG is made up of two rules: a binary
rule that consists in identifying two dual
atomic formulas of two partial proof nets
by means of an axiom link and a unary rule
that consists in the same operation but in-
side the same partial proof net.
Now, inside a formalism defined as above, we
can consider particular grammars:
A grammar G of a formalism F is a
subset G ? StructF of its elementary
syntactic structures.
A grammar is lexicalized if every element of G
is anchored by a word in a lexicon. In LTAG, G
is constituted of its initial and auxiliary trees.
In LG, G is constituted of the syntactic trees of
the formulas representing syntactic categories of
words as hypotheses plus a partial proof net an-
chored by the period and including a conclusion
in the category sentence.
From a grammar G defined in a formalism
F , we build the set D(G) of its derived syntac-
tic structures by applying the rules of RulesF
recursively from the elements of G. The lan-
guage generated by the grammar is the projec-
tion L(G) = PhonF (SatF ? D(G)).
2 Morphisms between grammatical
formalisms
Polarization and abstraction can be defined
from a more general notion of morphism be-
tween grammatical formalisms. A morphism
from a grammatical formalism C to a grammat-
ical formalism A is a function f from StructC
to StructA with the following properties3:
(i) f(SatC) ? SatA;
(ii) ?S ? SatC ,PhonA(f(S)) = PhonC(S);
(iii) if S1, . . . , Sn are composed into a struc-
ture S in C by means of rules of RulesC ,
then f(S1), . . . , f(Sn) can be composed
into the structure f(S) by means of rules
of RulesA.
Given such a morphism f and a grammar G
in C, the image of G by f denoted f(G) is
the grammar?in A?induced by the morphism.
The three properties of morphism guarantee
that the language generated by any grammar
G of C is a subset of the language generated by
f(G). In other words, L(G) ? L(f(G)).
We propose to use the notion of morphism in
two ways:
? for polarizing grammatical formalisms and
in this case, morphisms are isomorphisms;
grammars are transposed from a formalism
to another formalism with the same gener-
ative power; in other words, with the pre-
vious notations: L(G) = L(f(G));
? for abstracting grammatical formalisms
and this case, the transposition of gram-
mars by morphisms entails simplification of
grammars and extension of the generated
languages; we have only: L(G) ? L(f(G)).
An example of the use of abstraction for lex-
ical disambiguation may be found in (Boul-
lier, 2003)4. We propose to link polarization
with abstraction because polarities allow origi-
nal methods of abstraction. Polarization is used
as a preprocessing step before the application of
these methods.
3 Polarization of grammatical
formalisms
The goal of polarizing a grammatical formal-
ism is to make explicit the resource sensitiv-
ity that is hidden in syntactic composition, by
adding polarities to the labels of its structures.
When morpho-syntactic labels become polar-
ized in syntactic structures, they get the status
3An elegant definition of morphism could be given
in a category-theoretical framework but we have chosen
here a more elementary definition.
4Our definition of morphism must be slightly ex-
tended for embedding the proposal of (Boullier, 2003).
of consumable resources: a label that is asso-
ciated with the polarity + becomes an avail-
able resource whereas a label that is associated
with the polarity ? becomes an expected re-
source; both combine for producing a saturated
resource associated with the polarity $; labels
associated with the polarity = are neutral in
this process. In a polarized formalism, the sat-
urated structures are those that have all labels
associated with the polarity = or $. We call
them neutral structures. The composition of
structures is guided by a principle of neutraliza-
tion: every positive (negative) label must unify
with a negative (positive) label.
The polarization of a formalism must pre-
serve its generative power: the language that
is generated by a polarized grammar must be
the same as that generated by the initial non-
polarized grammar. This property of (weak and
even strong) equivalence is guaranteed if the
polarized formalism is isomorphic to the non-
polarized formalism from which it stems. For-
mally, given a grammatical formalism F , any
formalism Fpol with a morphism pol : F ? Fpol
is a polarization of F if:
(i) For any structure S ? StructF , pol(S)
results from associating each label of S
with one of the polarities: +, ?, =, $;
in others words, labels of Fpol are pairs
(p, l) with p a polarity and l a label of
F . The set of polarities {+, ?, =, $} is
equipped with the operation of unification
and the subsumption order defined by
Figure 1. The operations of subsumption
and unification on pairs are the pointwise
operations. That is, for any pairs (p, l)
and (p?, l?),
(p, l)v(p?, l?) iff pvp? and lvl?
(p, l)unionsq(p?, l?) = (punionsqp?, lunionsql?)
(ii) SatFpol is constituted of the neutral struc-
tures of StructFpol .
(iii) pol is an isomorphism whose inverse mor-
phism is the function that ignores polar-
ities and keeps invariant the rest of the
structure.
Let us illustrate our purpose by taking again
our two examples of formalisms.
? For LTAG (see figure 2), pol consists in
labelling the root of elementary syntactic
trees with the polarity + and their non ter-
minal leaves (substitution and foot nodes)
? + = $
? $ ?
+ $ +
= ? + = $
$ $
=
? ?
+ ?
? ?
$
Figure 1: unification and subsumption between
polarities
pol destr
N
N*Adj
red
N?
N+
N+
Adj N?
red
 N+, N+, N?, N? 
 red , Adj
Figure 2: Syntactic structures associated
with the adjective red in LTAG, LTAGpol,
(LTAGpol)destr
with the polarity ?. In every pair of quasi-
nodes, the top quasi-node is labelled with
the polarity ? and the bottom quasi-node
is labelled with the polarity +. With re-
spect to the classical presentation of LTAG,
initial trees must be completed by an axiom
with two nodes of the type sentence: a root
with the polarity = and its unique daugh-
ter with the polarity ?. In this way, pol
establishes a perfect bijection between the
saturated structures of LTAG and the neu-
tral structures of LTAGpol. The rules of ad-
junction and substitution of RulesLTAGpol
mimic the corresponding rules in LTAG,
taking into account polarities. We add a
third composition rule, a unary rule which
identifies the two quasi-nodes of a same
pair. It is routine to check that pol is a
polarisation.
? In LG(see figure 3), polarization is already
present explicitly in the formalism: nega-
tive formulas and sub-formulas are input
formulas, hypotheses whereas positive for-
mulas and sub-formulas are output formu-
las, conclusions.
4 Abstraction of polarized
grammatical formalisms
The originality of abstracting polarized for-
malisms is to keep a mechanism of neutraliza-
tion between opposite polarities at the heart of
the abstract formalism. Furthermore, we can
choose different levels of abstraction by keeping
more or less information from the initial formal-
S+ NP?
eats
NP?(NP \ S ) / NP
eats
pol S+, NP?, NP?
eatsdestr
Figure 3: Syntactic structures associated
with the transitive verb eats in LG, LGpol,
(LGpol)destr
ism.
As an example, we propose a high degree ab-
straction, destructuring. Destructuring a polar-
ized formalism consists in ignoring the struc-
ture from the initial syntactic objects to keep
merely the multisets of polarized labels. For-
mally, given a polarized formalism P , we define
the formalism Pdestr as follows:
? Any element M of StructPdestr is a multi-
set of labels. All elements of M are labels
of P , except one exactly, the anchor, which
is a neutral string.
? SatPdestr is made up of multisets containing
only neutral and saturated labels;
? The projection PhonPdestr returns the la-
bel of the anchor.
? RulesPdestr has two neutralization rules. A
binary rule takes two multisets M1 and M2
from StructPdestr as inputs; two unifiable
labels +l1 ? M1(M2) and ?l2 ? M2(M1)
are selected. The rule returns the union of
M1 and M2 in which +l1 and ?l2 are uni-
fied and the two anchors are concatenated.
The only change with the unary rule is that
this operates inside the same multiset.
A morphism destr is associated to Pdestr (see
figure 2 and 3): it takes any structure S from
StructP as input and returns the multiset of its
labels with an additionnal anchor. This anchor
is the neutral string PhonP (S) if this one is
defined.
An important property of Pdestr is that it is
not sensitive to word order: if a sentence is gen-
erated by a particular grammar of Pdestr, by
permuting the words of the sentence, we ob-
tain another sentence generated by the gram-
mar. Destructuring is an abstraction that ap-
plies to any polarized formalism but we can de-
sign abstractions with lower degree which are
specific to particular formalisms (see Section 6).
5 Application to lexical
disambiguation
Abstraction is the basis for a general method
of lexical disambiguation. Given a lexicalized
grammar G in a concrete formalism C, we con-
sider a sentence w1 . . . wn. For each 1 ? i ? n,
let the word wi have the following entries in the
lexicon of G: Si,1, Si,2 . . . Si,mi . A tagging of
the sentence is a sequence S1,k1 , S2,k2 . . . Sn,kn .
We suppose now that we have given an abstrac-
tion morphism abs : C ? Cabs. As L(G) ?
L(abs(G)), any tagging in abs(G) which has no
solutions comes from a bad tagging in G. As
a consequence, the methods we develop try to
eliminate such bad taggings by parsing the sen-
tence w1w2 . . . wn within the grammar abs(G).
We propose two procedures for parsing in the
abstract formalism:
? an incremental procedure which is specific
to the destructuring abstraction,
? a bottom-up procedure which can apply to
various formalisms and abstractions.
5.1 Incremental procedure
We choose polarization followed by destructur-
ing as abstraction. In other words: abs =
destr ?pol. Let us start with the particular case
where unification of labels in C reduces to iden-
tity. In this case, parsing inside the formalism
Cabs is greatly simplified because composition
rules reduce to the neutralization of two labels
+l and ?l. As a consequence, parsing reduces
to a counting of positive and negative polarities
present in the selected tagging for every label
l: every positive label counts for +1 and ev-
ery negative label for ?1, the sum must be 0;
since this counting must be done for every pos-
sible tagging and for every possible label, it is
crucial to factorize counting. For this, we use
automata, which drastically decrease the space
(and also the time) complexity.
For every label l of C that appears with a
polarity + or ? in the possible taggings of the
sentence w1w2 . . . wn, we build the automaton
Al as follows. The set of states of Al is [0..n]?Z.
For any state (i, c), i represents the position at
the beginning of the word wi+1 in the sentence
and c represents a positive or negative count of
labels l. The initial state is (0, 0), and the final
state is (n, 0). Transitions are labeled by lexicon
entries Si,j . Given any Si,j , there is a transition
(i? 1, x)
Si,j
?? (i, y) if y is the sum of x and the
count of labels l in the multi-set destr(Si,j).
Reaching state (i, c) from the initial state
(0, 0) means that
(a) the path taken is of the form
S1,j1 , S2,j2 , . . . , Si,ji , that is a tagging
of the first i words,
(b) c is the count of labels l present
in the union of the multi-sets
abs(S1,j1), abs(S2,j2), . . . , abs(Si,ji).
As a consequence, any path that leads to the fi-
nal state corresponds to a neutral choice of tag-
ging for this label l.
The algorithm is now simply to construct for
each label l the automaton Al and to make the
intersection A =
?
l?LabelsAl of all these au-
tomata. The result of the disambiguation is
the set of paths from the initial state to the fi-
nal state described by this intersection automa-
ton. Notice that at each step of the construction
of the intersection, one should prune automata
from their blind states to ensure the efficiency
of the procedure.
Now, in the general case, unification of labels
in F does not reduce to identification, which in-
troduces nondeterminism in the application of
the neutralization rule. Parsing continues to re-
duce to counting polarities but now the counting
of different labels is nondeterministic and inter-
dependent. For instance, consider the multiset
{+a, +b, ?aunionsq+b} of three different elements.
If we count the number of a, we find 0 if we
consider that +a is neutralized by ?aunionsqb and
+1 otherwise; in the first case, we find +1 for
the count of b and in the second case, we find 0.
Interdependency between the counts of different
labels is very costly to be taken into account and
in the following we ignore this property; there-
fore, in the previous exemple, we consider that
the count of a is 0 or +1 and the count of b is
also 0 or +1 independently from the first one.
For expressing this, given a label l of F and a
positive or negative label l? of Fpol, we define
Pl(l?) as a segment of integers, which represents
the possible counts of l found in l?, as follows:
? if l? is positive, then Pl(l?) =?
?
?
J1, 1K if lvl?
J0, 0K if lunionsql? = ?
J0, 1K otherwise
? if l? is negative, then Pl(l?) =?
?
?
J?1,?1K if lvl?
J0, 0K if lunionsql? = ?
J?1, 0K otherwise
We generalize the function Pl to count the num-
ber ol labels l present in a multi-set abs(S):
Pl(S) = Jinf, supKwith:
inf =
?
l??abs(S) min(Pl(l
?))
sup =
?
l??abs(S) max(Pl(l
?))
The method of disambiguation using au-
tomata presented above is still valid in the gen-
eral case with the following change in the defini-
tion of a transition in the automaton Al: given
any Si,j , there is a transition (i?1, x)
Si,j
?? (i, y)
if y is the sum of x and some element of Pl(Si,j).
With this change, the automaton Al becomes
nondeterministic.
The interest of the incremental procedure is
that it is global to the sentence and that it ig-
nores word order. This feature is interesting for
generation where the question of disambigua-
tion is crucial. This advantage is at the same
time its drawback when we need to take word
order and locality into account. Under this an-
gle, the bottom-up procedure, which will be pre-
sented below, is a good complement to the in-
cremental procedure.
5.2 Bottom-up procedure
We propose here another procedure adapted to
a formalism C with the property of projectiv-
ity. Because of this property, it is possible to
use a CKY-like algorithm in the abstract for-
malism Cabs. To parse a sentence w1w2 ? ? ?wn,
we construct items of the form (i, j, S) with S
an element of StructCabs and i and j such that
wi+1 . . . wj represents the phonological form of
S. We assume that Rules(Cabs) has only unary
and binary rules. Then, three rules are used for
filling the chart:
initialization: the chart is initialized with
items in the form (i, i+ 1, abs(Si+1,k));
reduction: if the chart contains an item
(i, j, S), we add the item (i, j, S?) such that
S? is obtained by application of a unary
composition rule to S;
concatenation: if the chart contains two item
(i, j, S) and (j, k, S?), we add the item
(i, k, S??) such that S?? is obtained by ap-
plication of a binary composition rule to S
and S?.
Parsing succeeds if the chart contains an item
in the form (0, n, S0) such that S0 is an element
of SatCabs . From such an item, we can recover
all taggings that are at its source if, for every
application of a rule, we keep a pointer from the
conclusion to the corresponding premisses. The
other taggings are eliminated.
6 Experiments
In order to validate our methodology, we have
written two toy English grammars for the LG
and the LTAG formalisms. The point of the
tests we have done is to observe the performance
of the lexical disambiguation on highly ambigu-
ous sentences. Hence, we have chosen the three
following sentences which have exactly one cor-
rect reading:
(a) the saw cut the butter.
(b) the butter that the present saw cut
cooked well.
(c) the present saw that the man thinks that
the butter was cut with cut well.
For each test below, we give the execution
time in ms (obtained with a PC Pentium III,
600Mhz) and the performance (number of se-
lected taggings / number of possible taggings).
6.1 Incremental procedure
The incremental procedure (IP) results are
given in Figure 4:
LG LTAG
ms perf. ms perf.
(a) 1 3/36 3 3/96
(b) 42 126/12 960 40 126/48 384
(c) 318 761/248 832 133 104/1 548 288
Figure 4: IP with destr ? pol
One may notice that the number of selected
taggings/total taggings decrease with the length
of the sentence. This is a general phenomenon
explained in (Bonfante et al, 2003).
6.2 Bottom-up procedure
The execution time for the bottom-up proce-
dure (BUP) grows quickly with the ambiguity
of the sentence. So this procedure is not very
relevant if it is used alone. But, if it is used as
a second step after the incremental procedure,
it gives interesting results. In Figure 5, we give
the results obtained with the destr abstraction.
Some other experiments show that we can im-
LG LTAG
ms perf. ms perf.
(a) 2 3/36 9 3/96
(b) 154 104/12 960 339 82/48 384
(c) 2 260 266/248 832 1 821 58/1 548 288
Figure 5: IP + BUP with destr ? pol
prove performance or execution time with spe-
cific methods for each formalism which are less
abstract than destr.
6.2.1 Tailor-made abstraction for LG
For the formalism LG, instead of complete de-
structuring, we keep some partial structural in-
formation to the polarized label. As the for-
malism is projective, we record some constraints
about the continuous segment associated with a
polarity. In this way, some neutralizations pos-
sible in the destr abstraction are not possible
anymore if the two polarities have incompatible
constraints (i.e. lie in different segments). This
new morphism is called proj. The execution
time is problematic but it might be controlled
with a bound on the number of polarities in ev-
ery multiset5 (see Figure 6)
LG
sentence Time(ms) Perf.
(a) 2 1/36
(b) 168 5/12 960
(c) with bound 6 2 364 3/248 832
Figure 6: IP + BUP with proj ? pol
Without bound for sentence (c), the running
time is over 1 min.
6.2.2 Tailor-made abstraction for LTAG
For LTAG: a possible weaker abstraction (called
ltag) consists in keeping, with each polarity,
some information of the LTAG tree it comes
from. Rather than bags where all polarized la-
bels are brought together, we have four kind
of polarized pieces: (1) a positive label coming
from the root of an initial tree, (2) a negative
label coming from a substitution node, (3) a
couple of dual label coming from the root and
the foot of an auxiliary tree or (4) a couple of
dual label coming from the two parts of a quasi-
node. Rules in this formalism reflect the two
operations of LTAG; they do not mix polarities
relative to adjunction with polarities relative to
substitution. Figure 7 shows that the execution
time is improved (wrt. Figure 5).
Conclusion
The examples we have presented above should
not be used for a definitive evaluation of partic-
ular methods, but more as a presentation of the
flexibility of our program: polarizing grammati-
cal formalisms for abstracting them and parsing
5This bound expresses the maximum number of syn-
tactic dependencies between a constituent and the others
in a sentence.
LTAG
ms perf.
(a) 6 3/96
(b) 89 58/48 384
(c) 272 54/1 548 288
Figure 7: IP + BUP with ltag ? pol
in the resulting abstract frameworks for disam-
biguating lexical selections. We have presented
one general tool (the destructuring abstraction)
that may apply to various grammatical frame-
work. But we think that abstractions should be
considered for specific frameworks to be really
efficient. One of our purpose is now to try the
various tools we have developped to some large
covering lexicons.
So far, we have not taken into account the tra-
ditional techniques based on probabilities. Our
point is that these should be seen as an other
way of abstracting grammars. Our hope is that
our program is a good way to mix different
methods, probabilistic or exact.
References
G. Bonfante, B. Guillaume, and G Perrier.
2003. Analyse syntaxique e?lectrostatique.
Traitement Automatique des Langues. To ap-
pear.
P. Boullier. 2003. Supertagging: a Non-
Statistical Parsing-Based Approach. In 8th
International Workshop on Parsing Tech-
nologies (IWPT?03), Nancy, France, 2003,
pages 55?66.
P. de Groote. 1999. An algebraic correct-
ness criterion for intuitionistic multiplica-
tive proofnets. Theoretical Computer Sci-
ence, 224:115?134.
A. Joshi and B. Srinivas. 1994. Disambiguation
of super parts of speech (or supertags) : Al-
most parsing. In COLING?94, Kyoto.
S. Kahane. 2004. Grammaires d?unification po-
larise?es. In TALN?2004, Fe`s, Maroc.
M. Moortgat. 1996. Categorial Type Logics. In
J. van Benthem and A. ter Meulen, editors,
Handbook of Logic and Language, chapter 2.
Elsevier.
G. Perrier. 2003. Les grammaires d?interaction.
Habilitation a` diriger des recherches, Univer-
site? Nancy2.
K. Vijay-Shanker. 1992. Using description of
trees in a tree adjoining grammar. Computa-
tional Linguistics, 18(4):481?517.
