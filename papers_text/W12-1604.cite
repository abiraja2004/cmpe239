Paul Allopenna, James Magnuson, and Michael Tanen-
haus. 1998. Tracking the Time Course of Spoken
Word Recognition Using Eye Movements: Evidence
for Continuous Mapping Models. Journal of Memory
and Language, 38:419?439.
R.H. Baayen, D.J. Davidson, and D.M. Bates. 2008.
Mixed-effects modeling with crossed random effects
for subjects and items. Journal of Memory and Lan-
guage, 59:390?412.
Okko Buss and David Schlangen. 2010. Modelling
sub-utterance phenomena in spoken dialogue systems.
In Aspects of Semantics and Pragmatics of Dialogue.
SemDial 2010, 14th Workshop on the Semantics and
Pragmatics of Dialogue, pages 33?41.
Alexandre Denis. 2010. Generating referring expres-
sions with reference domain theory. In Proceedings
of the 6th International Natural Language Generation
Conference.
Nina Dethlefs, Heriberto Cuayahuitl, Kai-Florian
Richter, Elena Andonova, and John Bateman. 2010.
Evaluating task success in a dialogue system for
indoor navigation. In Aspects of Semantics and Prag-
matics of Dialogue. SemDial 2010, 14th Workshop
on the Semantics and Pragmatics of Dialogue, pages
143?146.
Daniel Dionne, Salvador de la Puente, Carlos Leo?n,
Pablo Gerva?s, and Raquel Herva?s. 2009. A model
for human readable instruction generation using level-
based discourse planning and dynamic inference of at-
tributes. In Proceedings of the 12th European Work-
shop on Natural Language Generation.
Mary Ellen Foster. 2007. Enhancing human-computer
interaction with embodied conversational agents. In
Proceedings of HCI International 2007.
Andrew Gargett, Konstantina Garoufi, Alexander Koller,
and Kristina Striegnitz. 2010. The GIVE-2 Corpus of
Giving Instructions in Virtual Environments. In Pro-
ceedings of the 7th Conference on International Lan-
guage Resources and Evaluation.
Konstantina Garoufi and Alexander Koller. 2011. The
Potsdam NLG systems at the GIVE-2.5 Challenge. In
Proceedings of the Generation Challenges Session at
the 13th European Workshop on Natural Language
Generation.
Graeme Hirst, Susan McRoy, Peter Heeman, Philip Ed-
monds, and Diane Horton. 1994. Repairing conver-
sational misunderstandings and non-understandings.
Speech Communications, 15:213?229.
Ryu Iida, Masaaki Yasuhara, and Takenobu Tokunaga.
2011. Multi-modal reference resolution in situated
dialogue by integrating linguistic and extra-linguistic
clues. In Proceedings of 5th International Joint Con-
ference on Natural Language Processing.
K. Jokinen, H. Furukawa, M. Nishida, and S. Yamamoto.
in press. Gaze and turn-taking behaviour in casual
conversational interactions. ACM Trans. Interactive
Intelligent Systems. Special Issue on Eye Gaze in In-
telligent Human-Machine Interaction.
Alexander Koller, Kristina Striegnitz, Donna Byron, Jus-
tine Cassell, Robert Dale, Johanna Moore, and Jon
Oberlander. 2010. The First Challenge on Generating
Instructions in Virtual Environments. In Emiel Krah-
mer and Mariet Theune, editors, Empirical Methods in
Natural Language Generation, number 5790 in LNCS,
pages 337?361. Springer.
Tim Paek and Eric Horvitz. 1999. Uncertainty, utility,
and misunderstanding: A decision-theoretic perspec-
tive on grounding in conversational systems. In AAAI
Fall Symposium on Psychological Models of Commu-
nication in Collaborative Systems.
David Nicola?s Racca, Luciana Benotti, and Pablo
Duboue. 2011. The GIVE-2.5 C Generation System.
In Proceedings of the Generation Challenges Session
at the 13th European Workshop on Natural Language
Generation.
Marc Schro?der and J. Trouvain. 2003. The German
Text-to-Speech Synthesis System MARY: A Tool for
Research, Development and Teaching. International
Journal of Speech Technology, 6:365?377.
Gabriel Skantze and David Schlangen. 2009. Incre-
mental dialogue processing in a micro-domain. In
Proceedings of the 12th Conference of the European
Chapter of the Association for Computational Linguis-
tics.
Maria Staudte and Matthew W. Crocker. 2011. Inves-
tigating joint attention mechanisms through human-
robot interaction. Cognition, 120(2):268?291.
Maria Staudte, Alexander Koller, Konstantina Garoufi,
and Matthew W. Crocker. 2012. Using listener gaze
to augment speech generation in a virtual 3D environ-
ment. In Proceedings of the 34th Annual Conference
of the Cognitive Science Society. To appear.
Kristina Striegnitz, Alexandre Denis, Andrew Gargett,
Konstantina Garoufi, Alexander Koller, and Mariet
Theune. 2011. Report on the Second Second Chal-
lenge on Generating Instructions in Virtual Environ-
ments (GIVE-2.5). In Proceedings of the Generation
Challenges Session at the 13th European Workshop on
Natural Language Generation.
Michael K. Tanenhaus, Michael J. Spivey-Knowlton,
Kathleen M. Eberhard, and Julie C. Sedivy. 1995. In-
tegration of visual and linguistic information in spoken
language comprehension. Science, 268:1632?1634.
David Traum. 1994. A computational theory of ground-
ing in natural language conversation. Ph.D. thesis,
University of Rochester.
Michael Young, Johanna Moore, and Martha Pollack.
1994. Towards a principled representation for dis-
course plans. In Proceedings of the Sixteenth Annual
Meeting of the Cognitive Science Society.
A Example interactions
The following interactions between a user (U) and
each of the three systems (S) were recorded during
the systems? attempts to instruct the user to press the
rightmost blue button shown in Fig. 1.
A.1 Eyetracking system
(1) S: Push the right button to the right of the green
button.
U: (approaches the pair of blue and green but-
ton and inspects one of them)
S: No, not that one!
. . . (U inspects other buttons in the scene, while
S provides appropriate feedback)
U: (inspects the correct target)
S: Yes, that one!
U: (presses the correct button)
A.2 Movement system
(2) S: Push the right button to the right of the green
button.
U: (approaches the pair of blue and green but-
tons; once the user is very close to the blue but-
ton, it happens to become the only button visi-
ble on screen)
U: (continues moving closer to the blue button)
S: No, not that one!
U: (has no time to react to the system?s feed-
back and presses the wrong blue button)
A.3 No-feedback system
(3) S: Push the right button to the right of the green
button.
U: (presses the wrong blue button)
B The experimental setup