Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010), pages 465?473,
Beijing, August 2010
Normal-form parsing for Combinatory Categorial Grammars
with generalized composition and type-raising
Julia Hockenmaier Yonatan Bisk
University of Illinois at Urbana-Champaign
{juliahmr, bisk1}@illinois.edu
Abstract
We propose and implement a modifica-
tion of the Eisner (1996) normal form to
account for generalized composition of
bounded degree, and an extension to deal
with grammatical type-raising.
1 Introduction
Combinatory Categorial Grammar (Steedman,
2000) is a linguistically expressive grammar for-
malism that has been used for many NLP appli-
cations, including wide-coverage parsing (Clark
and Curran, 2007; Hockenmaier, 2003) and se-
mantic interpretation (Curran et al, 2007), se-
mantic role-labeling (Gildea and Hockenmaier,
2003; Boxwell et al, 2009), semantic parsing
(Zettlemoyer and Collins, 2005) and natural lan-
guage generation (Espinosa et al, 2008).
An essential feature of CCG is its flexible
constituent structure, licensed by type-raising
and composition rules which can create ?non-
standard? constituents such as ?John saw?, or
?Mary talked to?, required in constructions in-
volving non-local dependencies, such as wh-
extraction (Fig. 1) or right-node raising. Since
?John saw? can now also be a constituent in
?John saw Mary?, this leads to a combinato-
rial explosion of spurious ambiguities, i.e. mul-
tiple syntactic derivations of the same seman-
tic interpretation (Wittenburg, 1986). This can
create problems for applications based on CCG,
e.g. for the induction of stochastic CCGs from
text annotated with logical forms (Zettlemoyer
and Collins, 2007), where spreading probabil-
ity mass over equivalent derivations should be
avoided. A number of normal-form (NF) parsing
algorithms that aim to produce only one deriva-
tion per interpretation have been proposed (Wit-
tenburg, 1986; Niv, 1994; Pareschi and Steed-
man, 1987; Hepple and Morrill, 1989; Eis-
ner, 1996). Computationally, such algorithms
are very attractive since they do not require
costly semantic equivalence checks (Karttunen,
1989; Komagata, 2004) during parsing. Eis-
ner?s (1996) normal form is the most devel-
oped and well-known of these approaches, but
is only defined for a variant of CCG where
type-raising is a lexical operation and where the
degree of composition is unbounded. There-
fore, it and its equivalent reformulation by Hoyt
and Baldridge (2008) in a multimodal variant of
CCG are not safe (preserve all interpretations)
and complete (remove all spurious ambiguities)
for more commonly used variants of CCG. In
particular, this NF is not safe when the degree
of composition is bounded,1 and not complete
when type-raising is a grammatical operation.
This paper defines a NF for CCG with bounded
composition and grammatical type-raising.
2 Combinatory Categorial Grammar
In CCG, every constituent (?John saw?) has a
syntactic category (S/NP) and a semantic in-
terpretation (?x.saw(john?, x)).2 Constituents
combine according to a small set of language-
1Although Eisner (1996, section 5) also provides a safe
and complete parsing algorithm which can return non-NF
derivations when necessary to preseve an interpretation if
composition is bounded or the grammar is restricted in
other (arbitrary) ways.
2More complex representations than simple predicate-
argument structures are equally possible.
the man that John saw
NP (NP\NP)/(S/NP) NP (S\NP)/NP
>T
S/(S\NP)
>B1
S/NP
>B0
NP\NP
<B0NP
Figure 1: CCG derivations for wh-extraction
465
Application (>) X/Y : ?x.f(x) Y : a ? X : f(a)
(<) Y : a X\Y : ?x.f(x) ? X : f(a)
Composition (>B1) X/Y : ?x.f(x) Y/Z : ?y.g(y) ? X/Y : ?z.f(g(z))
(<B1) Y\Z : ?y.g(y) X\Y : ?x.f(x) ? X\Y : ?z.f(g(z))
(>B 1?) X/Y : ?x.f(x) Y\Z : ?y.g(y) ? X\Y : ?z.f(g(z))
(<B 1?) Y/Z : ?y.g(y) X\Y : ?x.f(x) ? X/Y : ?z.f(g(z))
(>Bn) X/Y : ?x.f(x) Y|Z1|...|Zn : ?zn..z1.g(z1...zn) ? X|Z1|...|Zn : ?zn...z1.f(g(z1...zn))
(<Bn) Y|Z1|...|Zn : ?zn..z1.g(z1...zn) X\Y : ?x.f(x) ? X|Z1|...|Zn : ?zn...z1.f(g(z1...zn))
Typeraising (>T ) For X ? Carg : X : a ? T/i(T\iX) : ?f.f(a)
(<T ) For X ? Carg : X : a ? T\i(T/iX) : ?f.f(a)
Figure 2: CCG?s combinatory rules.
independent combinatory rules (Fig. 2). The lex-
icon pairs words with categories and interpreta-
tions and is language-specific.
Syntax We distinguish atomic (S, NP, PP,
etc.) from complex categories ((S\NP)/NP,
N/N, etc.). A complex category of the form X/Y
(or X\Y) represents a function which returns a
result of type X when applied to an argument
of type Y, which, in the case of a forward slash
(/) has to follow the functor, and in the case of
a backslash (\) has to preceed it. X and Y can
themselves be complex again. We will use cat-
egories with vertical slashes when the direction
of the slash does not matter, and may omit un-
necessary parentheses (so X|Y|Z will represent
(X\Y)/Z, (X\Y)\Z, ...). We will also use the
shorthand X|Y1..n (or X|?) to refer to a category
with (possibly complex) result X and arguments
Y1...Yn (or an unspecified, possibly empty, list
of arguments ? = Y0...n, where |?| = n) that
can each appear with either type of slash.
Semantics If the category of a constituent is
atomic (NP; S), its interpretation will also be
atomic (kim?; sleeps?(kim?)), and if the category
is a functor of arity n (X|Y1..n), the interpretation
is a ?-expression ?yn..?y1?(y1...yn) of arity n.
The lexicon Each language defines a finite set
of lexical category types Clex (e.g. (S\NP)/NP
is in the English lexicon, but (S\NP)\NP is not)
with maximal arity NL. This defines a set of
lexical argument category types Carg , consist-
ing of all categories Y that are the argument
of some lexical category (X|Y)|? ? Clex (with
|?| ? 0). Since Clex is finite, Carg is strictly
smaller than Clex (and usually consists of basic
categories such as NP, S, S\NP).
Combinatory Rules In addition to function
application (>,<), CCG has three kinds of com-
binatory rules (Fig. 2): harmonic function com-
position (>B(1), <B(1)), crossing function com-
position (>B ?,<B ?) and type-raising (>T ,
<T ). All rules take one or two input categories
and yield one output category, and consist of a
syntactic and a corresponding semantic opera-
tion. Composition also has generalized variants
>Bn, <Bn up to a fixed degree NB .3 Compo-
sition of unbounded degree increases the genera-
tive capacity of CCG (Weir, 1988), and should be
disallowed. Application (>,<) can be seen as a
special case of composition (>B0,<B0). When
composing X|Y with Y|Z to X|Z, we call X|Y
the primary input and Y|Z the secondary in-
put. Harmonic composition allows associativ-
ity: the string A/B B/C C now has an alter-
native derivation where A/B and B/C compose
into A/C, whereas crossing composition enables
novel permutations, such as C A/B B\C.
Type-raising swaps the functor-argument rela-
tion. Although it is often assumed to take place
in the lexicon, we will distinguish lexical cate-
gories (e.g. for quantifiers) that have the syn-
tactic type of type-raised categories, but seman-
tics that could not be obtained by type-raising a
simple category from grammatically type-raised
categories. We follow the common definition
of CCG (Steedman, 2000) and allow only cat-
egories X ? Carg to be type-raised.4 Instantia-
3In X|Y1..n or X|?=X|Y1...|?|, we do not assume the
slash variable | ? {/, \} to be instantiated the same way for
all Yi. We will therefore only distinguish between forward
and backward generalized composition Bn>1.
4We stipulate that it may be further necessary to only
allow those argument categories to type-raise that are not
used to project unbounded dependencies, such as S/NP in
466
tions of the variable T should also be restricted
to categories of finite arity NT in oder to pre-
vent an increase in generative capacity (Hoff-
man, 1995; Komagata, 1997). We refer to the
arity of T as the degree of any particular instan-
tation of T . We follow Steedman (2000) and
assume NT = NB .
Coordination requires a ternary rule (?) which
can be binarized (?>, ?<) to simplify parsing:5
(?) X conj X ? X
(?>) X X[conj] ? X
(?<) conj X ? X[conj]
Uses of type-raising and composition In En-
glish, type-raising and composition are required
for wh-extraction and right node raising of argu-
ments as well as so-called argument cluster co-
ordination. In other languages, they are needed
for scrambling and cross-serial dependencies.
It is important to note that when type-raising is
required, it always occurs in tandem with com-
position. Since type-raising an argument Y to
X/(X\Y) and applying it to the functor X\Y is
semantically equivalent to applying X\Y directly
to Y, type-raising is never required when func-
tion application can be used instead. That is, in
all cases, a type-raised argument must be com-
posed with another constituent, usually the orig-
inal functor (head). Only in argument-cluster co-
ordination will the type-raised element be com-
posed with a non-head constituent. In the lat-
ter case, coordination will be required before
the argument cluster can be combined with the
head. Composition without type-raising may oc-
cur, e.g. for adjuncts, which have categories X|X,
but may modify a constituent with category X|?.
Restrictions on type-raising and composition
In order to prevent overgenerations of the form
?John speaks because Chinese, he enjoys Bei-
jing.?, we assume a variant of CCG in which
forward crossing composition >B 1? (e.g. of be-
cause:(S/S)/S) into the result of backward type-
raising <T (e.g. Chinese:S\(S/NP), and, simi-
larly, <Bx into the result of >T , are disallowed.
(NP\NP)/(S/NP) for English object relative pronouns.
5Here, X needs to be restricted to a finite set of cate-
gories (Weir, 1988). In multimodal CCG, conjunction have
categories of the form (X?\?X)/?X, i.e. must apply to their
argument
Punctuation and Type-changing rules CCG-
bank (Hockenmaier and Steedman, 2007) uses
special punctuation rules such as S . ? S or
, NP\NP ? NP\NP, and a small number of
(non-recursive) type-changing rules (with id-
iosyncratic semantics) such as N ? NP (for
determiner-less NPs) or S[pss]\NP ? NP\NP
(for complex adjuncts, here passive VPs being
used as NP postmodifiers):
Punctuation (>P) X:? [., ; ] ? X:?
(<P) [., ; ] X:? ? X:?
TypeChanging (TCR) X:? ? Y:?(?)
CCG parsing CCG can be parsed with a
bottom-up CKY-like algorithm (Shieber et al,
1995; Steedman, 2000), which differs from stan-
dard CKY in that it requires one (or two) unary
completion steps in each cell to deal with type-
raising (and type changing).6 Chart items are of
the form ?X, i, j?, where X is a category, and the
indices i and j represent the span of the item.
Interpretations need only to be constructed for
complete derivations when unpacking the chart.
3 The Eisner normal form
The Eisner normal form Eisner (1996)
presents a normal-form parsing algorithm for
CCG without grammatical type raising (where
the lexicon may still contain categories like
S/(S\NP), but there is no combinatory rule
that changes a complex (derived) NP to e.g.
S/(S\NP)). He proves that his algorithm finds
only one canonical derivation for each semantic
interpretation of an input string consisting of a
sequence of words and their lexical categories.
Since the presence of both pre- and postmodi-
fiers (as in ?intentionally knock twice?7) intro-
duces a genuine ambiguity, Eisner proves that
the only kind of spurious ambiguity that can
arise in his variant of CCG is due to associative
chains of composition such as A/B B/C C/D or
A/B B/C C\D, which can be derived as either
6Since composition allows the arity of derived (? non-
terminal) CCG categories to grow with the length of the
input string, worst-case complexity of this naive algorithm
is exponential. (Vijay-Shanker and Weir, 1993)?s O(n6)
algorithm has a more compact representation of categories.
7This can mean ?x.intentionally ?(twice ?(knock ?(x)))
or ?x.twice ?(intentionally ?(knock ?(x))).
467
Eisner NF Not Eisner NF
(A|B1..b)/C (C|D1..d)/E (E|F1..f)/G G|H1..h
>Bh
(E|F1..f)|H1..h
>Bf+h
((C|D1..d)|F1..f)|H1..h
>Bd+f+h
(((A|B1..b)|D1..d)|F1..f)|H1..h
(A|B1..b)/C (C|D1..d)/E (E|F1..f)/G G|H1..h
>Bd+1
((A|B1..b)|D1..d)/E
>Bf+1
(((A|B1..b)|D1..d)|F1..f)|G
>Bh
(((A|B1..b)|D1..d)|F1..f)|H1..h
Figure 3: Eisner NF and generalized composition Bn>1
Left branching Right branching
>B0(>Bm+1,...)?>Bm?0(...,>B0) A/B (B|D0..m)/C C m ? 0
>B1(>Bm?1,...)?>Bm?1(...,>B1) A/B (B|C1...m?1)/D D/E m ? 1
>Bn?1(>B1,...) ?>Bn(...,>Bm=n) A/B B/C C/D1..n m = n ? 1
? :>Bn>1(...,>Bm>n) A/(B|D1..k) B/C ((C|D1..k)|E1..n m > n > 1
>Bm(>Bk,...) ?>Bn>1(...,>B1<m<n) A/B (B|C1..k?1)/D D|E1..m n > m > 1
Figure 4: Associative composition chains: our NF disallows the grayed-out derivations.
>B (..., >B ) or >B (>B , ). This is eliminated
by the following constraint:
Eisner NF Constraint 1. The output X|? of
forward composition >Bn>0 cannot be the pri-
mary input to forward application or composi-
tion >Bm?0. The output of <Bn>0 cannot be
the primary input to <Bm?0.
This can be implemented by a ternary feature
HE ? {>Bn, <Bn, ?} and chart items of the
form ?X, HE, i, j? where HE =>Bn (or <Bn)
if X was produced by the corresponding compo-
sition rule (for any n > 0) and ? otherwise.
4 A new normal form for CCG
4.1 Generalized composition
Eisner NF and generalized composition Un-
boundedly long sequences of generalized com-
position are required e.g. for Dutch verb clus-
ters that give rise to cross-serial dependen-
cies (N1...NnV1...Vn with Ni the argument of
Vi). These can be obtained through standard
bounded-degree compositions, but the Eisner NF
produces a derivation that requires compositions
of unbounded degree (Fig. 3). Although this is
allowed in the variant of CCG Eisner considers,
compositions of unbounded degree are usually
disallowed because they increase the generative
capacity of CCG (Weir, 1988). We stipulate that
the NF of any derivation ? should not require
composition rules of higher degree than ? itself.
Note that the output of function application (B0)
always has lower arity than its functor; the output
of regular composition (B1) has the same arity as
its primary functor, but the output of generalized
composition (Bn>1) has an arity that is n ? 1
higher than that of the primary functor. Bn>1
therefore requires a different treatment.
Our reformulation of the Eisner NF As-
sociative composition chains for constituents
A B C can lead to spurious ambiguity if both a
left-branching >Bn(>Bm(A B) C) and a right-
branching >Bn?(A >Bm?(B C)) are possible and
lead to the same interpretation. Figure 4 il-
lustrates all possible cases consisting of three
constituents. In most cases, the right-branching
(Eisner NF) derivation is to be preferred. For
generalized composition >Bn>1, >Bm>1, left-
branching >Bn>1(>Bm>1, ...) is always al-
lowed, but right-branching >Bn(..., >Bm) is
only allowed if m ? n.
NF Constraint 1 (B0 and Bn?1). The output of
>Bn?1 (resp. <Bn?1) cannot be primary func-
tor for >Bn?1 (resp. <Bn?1).
NF Constraint 2 (B1 and Bn?1). The output of
>B1 (resp. <B1) cannot be primary functor for
>Bn?1 (resp. <Bn?1).
NF Constraint 3 (Bn>1 and Bm>1). The out-
put of >Bm (resp. <Bm) cannot be secondary
functor for >Bn>m (resp. <Bn>m).
4.2 Grammatical type-raising
Eisner NF and type-raising Figure 5 illus-
trates a spurious ambiguity arising through type-
468
which Sue ate happily
NP : (S\NP)/NP : S\S :
s? ?y.?x.ate?(x, y) ?z.happily?(z)
>T
S/(S\NP) :
?f.f(s?)
>B1
S/NP : ?y.ate?(s?, y)
<B1?
S/NP : ?y.happily?(ate?(s?, y))
which Sue ate happily
NP : (S\NP)/NP : S\S :
s? ?y.?x.ate?(x, y) ?z.happily?(z)
>T
S/(S\NP) :
?f.f(s?)
<B2?
(S\NP)/NP :
?y.?x.happily?(ate?(x, y))
>B1
S/NP : ?y.happily?(ate?(s?, y))
Figure 5: The Eisner NF allows spurious ambiguity arising due to type-raising
raising that the Eisner NF does not exclude.8
Here two derivations can be obtained because
the result of combining the adverb with the
subject-verb cluster is no longer the output of
a forward composition, and can therefore ap-
ply to the object. The derivations are semanti-
cally equivalent: although type-raising reverses
the syntactic functor-argument relation, a type-
raised argument applied to a predicate returns
the same interpretation as when the predicate
is applied directly to the original. But Eis-
ner treats S/(S\NP) as a category with se-
mantics ?x.?(x), in which case the derivations
yield indeed different scope relations. Eis-
ner?s analyis is correct for certain classes of
words which have lexical categories that ap-
pear like type-raised categories, but have a dif-
ferent interpretation from that of categories ob-
tained by type-raising. These are usually scope-
bearing elements, such as the universal quantifer
every ((S/(S\NP))/N : ?P?Q?xP(x) ? Q(x)),
and there may not be a single derivation which
captures all semantic interpretations. Lexical-
ized pseudo-type-raising therefore needs to be
distinguished from grammatical type-raising.
Our extension of the (modified) Eisner NF
In Fig. 5, Eisner NF licenses two derivations.
Both contain an instance of composition in
which the type-raised argument is the primary
component. In the analysis in which this is the
second derivation step, the canceled part of this
<B2 composition (boxed) contains a category
(\NP) that was part of the argument output of
the first >B1 composition (bold-faced):
8We have chosen a slighly unusual adverb category to
illustrate a general problem.
which Sue ate happily
S/ (S\NP) (S\NP)/NP S\S
<B2?
S\NP /NP
>B1
S/NP
Our NF will eliminate derivations of this type
and prefer the other, lower-degree derivation.
We stipulate that the spurious ambiguities that
arise through type-raising and composition can
be eliminated through the following rule:
NF Constraint 4 (T and Bn>0). The output of
>T cannot be primary input to >Bn>0 if the
secondary input is the output of <Bm>n. The
output of <T cannot be primary input in <Bn>0
if the secondary input is the output of >Bm>n.
We also stipulate that a type-raised T/(T\X)
cannot be used as a functor in application (since
T\X could always apply directly to X).
NF Constraint 5 (T and B0). The output of for-
ward (or backward) type-raising >T (resp. <T )
cannot be the functor in application > (resp. <).
Additional spurious ambiguities arise through
the interaction of type-raising and coordination:
Since any category can be coordinated, we can
either coordinate X and then type-raise the co-
ordinated X to T/(T\X), or we can first type-
raise each conjunct to T/(T\X) and then con-
join. Since nonsymmetric coordinations of an
argument-adjunct cluster and a single argument
(as in eats ((pizza for lunch) and pasta)) require
type-raising before coordination, we formulate
the following rule to eliminate interactions be-
tween type-raising and coordination:
NF Constraint 6 (T and ?). The result of coor-
dination ? cannot be type-raised.
469
NF Derivation A NF Derivation B
A B C
X/X : (X|?a)|?b : (X|?a)\(X|?a) :
?Pa(P ) ?xbxab(xaxb) ?Q?zac(Q(za))
<Bb
(X|?a)|?b : ?xbxac(b(xaxb))
>Ba+b?
(X|?a)|?b : ?xbxaa(c(b(xaxb)))
A B C
X/X : (X|?a)|?b : (X|?a)\(X|?a) :
?Pa(P ) ?xbxab(xaxb) ?Q?zac(Q(za))
>Ba+b?
(X|?a)|?b : ?xbxaa(b(xaxb))
<Bb?
(X|?a)|?b : ?xbxac(a(b(xaxb)))
Figure 6: Constituents with pre- and postmodifiers have two semantically distinct derivations
Punctuation and Type-changing rules Punc-
tuation results in spurious ambiguities, either
when a constituent X has both an initial and a fi-
nal punctuation mark (e.g. a comma), or when it
has an initial (final) punctuation mark and a final
(initial) modifier. The first case is easy to fix by
disallowing the output of , X ? X to be the in-
put of X ,? X. The latter could be eliminated by
disallowing the output X of right-recursive (left-
recursive) punctuation rule to be secondary input
to any left-recursive (right-recursive) application
or composition rule (e.g. X X\X ? X).9
Implementation Our normal-form constraints
can be implemented in a bottom-up parser with
items of the form ?X, C, i, j?, with
C ? {>, >B 1, >B 2, ..., >Bn; <, <B 1, <B 2, ..., <Bn;
>T , <T , >Pct,<Pct, ?>, ?<, TCR}
4.3 Is our normal form safe and complete?
Here we sketch the beginnings of a proof that
our algorithm allows one and only one syntac-
tic derivation per semantic interpretation for the
version of CCG we consider. We first examine
all cases of two adjacent constituents A, B which
must combine into a category C:
Functor X/Y and argument Y combine to X
The functor must apply to the argument. The ar-
gument could type-raise, but then cannot apply.
Functor X/Y|? and argument Y combine to
X|? The functor cannot apply to the argument.
The argument must type-raise to X\(X/Y), and
can then backward-compose into the functor.
Functor X/X and X\X can combine to X/X or
X\X This is not a spurious ambiguity, since the
output categories are different.
9If punctuation can be used both with X and Y, it also
interacts with type-changing rules X ? Y. Our current
implementation does not deal with this case.
Functor X|Y and Y|Z combine to X|Z Our re-
formulation of Eisner?s NF eliminates spurious
ambiguities that are due to such associative com-
position chains. This covers not only argument
clusters (which must compose), but also ambigu-
ous cases where one constituent (e.g. Y/Z with
? = ) is the argument of the first (X/Y), and ei-
ther takes the third (Z) as its own argument or is
modified by the third Y\Y (there are, of course,
other arrangements of such categories which are
not ambiguous, e.g. X/Y Z Y\Z.
We now focus our attention on the ternary
cases in which one of the constituents is a head
(predicate), and the other two are either its argu-
ments or modifiers. The counterexample to Eis-
ner?s normal-form algorithm shows that there is
at least one additional kind of spurious ambigu-
ity that arises when there are three adjacent con-
stituents A, B, C and both A and C can compose
into B. There are three cases: 1) A and C are
both modifiers of B, 2) one of A or C is a mod-
ifier of B, the other is an argument of B, and 3)
A and C are both arguments of B. Only 1) is a
real ambiguity, but the other cases are instances
of spurious ambiguity which our NF eliminates.
Argument Y, head (X\Y)/Z and argument Z
combine to X In the NF derivation, the head
applies first to the Z, than to Y. All other deriva-
tions are blocked, either because type-raised cat-
egories cannot apply, or because the output of
composition cannot apply.
Modifier X/X, head (X|?)|? and modifier
(X|?)\(X|?) combine to (X|?)|? (Fig. 4.2).
This is the ?intentionally knock twice? example.
The derivations have different semantics.
Argument Y, head ((X|?)\Y)|?, and modifier
X\X combine to (X|?)|? (Fig. 7). If there is
an ambiguity, B must have a category of the form
470
Normal form Not normal form
A B C
Y ((X|?a)\Y)|?b : X\X
a ?xbxixab(xaxixb) ?Q?zac(Q(za))
>T
(X|?a)/((X|?a)\Y) :
?P?yaP (aya)
>Bb?
(X|?a)|?b : ?xbxab(xaaxb)
<Ba+b?
(X|?a)|?b : ?xbxac(b(xaaxb))
A B C
Y ((X|?a)\Y)|?b : X\X
a ?xbxixab(xaxixb) ?Q?zac(Q(za))
>T <Ba+b+1?
(X|?a)/((X|?a)\Y) : ((X|?a)\Y)|?b :
?P?yaP (aya) ?xbxixac(b(xaxixb))
>Bb?
(X|?a)|?b : ?xbxac(b(xaaxb))
Figure 7: Argument Y, head ((X|?a)\Y)|?b, and modifier X\X combine to (X|?a)|?b
Normal form Not normal form
A B C
Y (((X\Y)|?a)/Z)|?b Z
a ?xbxjxaxib(xixaxjxb) c
>T <T
X/(X\Y) ((X\Y)|?a)\(((X\Y)|?a)/Z)
?P?yaP (aya) ?Q?zazizaQ(czaziza)
<Bb?
((X\Y)|?a)|?b : ?xbxaxib(xixacxb)
>Ba+b?
(X|?a)|?b : ?xbxab(axacxb)
A B C
Y (((X\Y)|?a)/Z)|?b : Z
a ?xbxjxaxib(xixaxjxb) c
>T <T
X/(X\Y) (X|?a)\((X|?a)/Z)
?P?yaP (aya) ?Q?zaQ(cza)
>Ba+b+1?
((X|?a)/Z)|?b : ?xbxjxab(axaxjxb)
<Bb?
(X|?a)|?b : ?xbxab(axacxb)
Figure 8: Argument Y, head (((X\Y)|?)/Z)|? and argument Z combine to (X|?)|?
((X|?)\Yi)|? (with X possibly complex and ?, ?
possibly empty), and C must have a category of
the form X\X. We obtain the NF derivation by
first combining head and argument, followed by
the modifier. The other derivation violates the
NF constraints.
Argument Y, head (((X\Y)|?)/Z)|? and ar-
gument Z combine to (X|?)|? (Fig. 8) The
derivation in which Z composes first is in NF.
The derivation in which the Y combines first
with the head is blocked.
Arguments YA, YB, head (((X\Y1)|?)\Y2)|?
combine to (X|?)|? There are two readings:
standard (YA:=Y1, YB:=Y2), and scrambled
(YA:=Y2, YB:=Y1). If ? and ? are empty, func-
tion application is sufficient for the standard
reading, and our NF constraint 1 excludes the
?argument cluster? derivation in which both YA
and YB type-raise, compose and then apply to the
head. Otherwise, at least one of the arguments
has to type-raise and compose into the head. If
both ? and ? are non-empty, each interpretation
has only one derivation in which the type-raised
YA composes into the output of the composition
of the type-raised YB with the head. Since the
degree of the second composition is lower than
the first, this is allowed by our NF constraint 2.
Argument YA and heads (((X\Y1)|?)/Z and
((Z|?)\Y2)|? combine to (((X|?)|?)\Y2)|? or
to (((X|\Y1?)|?)|? There are two readings:
standard (YA:=Y1) or scrambled (YA:=Y2). De-
pending on the maximal degree n of Bn allowed
by the grammar, the standard reading one can ei-
ther be obtained by type-raising YA and compos-
ing into the first head (allowed by our NF) or by
first composing the two heads and then compos-
ing the type-raised YA into the cluster (allowed
by Eisner, but not by us). The second reading
requires the heads to compose and then YA to
apply or compose (depending on the arity of ?),
which is allowed by our NF constraint 2 because
the degree of this second composition is lower
than that of the first.
Our NF and the bound NT on type-raising
If X\X in Fig. 7 is replaced with a (non-type-
raised) category Z\X (for Z 
= X), the non-NF
derivation requires T|Z|+a, whereas the NF-
derivation requires T|X|+a. If we stipulate a fi-
nite bound NT on the degree of type-raising,
and if |X| > |Z| and |X| + a > NT , our
NF cannot be derived anymore. If such Z\X
(with X ? Carg ) can be derived from the lexi-
con, our NF requires therefore a potentially un-
bounded degree of type-raising. The T-degree
471
Sentence length l=15...30
15 20 25 30
No NF (total #derivs) 4.13E6 5.66E8 3.06E11 1.59E14
Eisner B 18.92% 9.05% 3.63% 2.14%
Our B 18.38% 8.97% 3.60% 2.02%
Our B , T 2.92% 1.22% 0.37% 0.10%
Our full NF 2.60% 0.93% 0.33% 0.09%
(a) Median % of allowed derivations
Sentence length l= 30
Min Mean Median Max
No NF 5.99E9 8.19E15 1.59E14 2.61E17
Eisner B 1.60% 2.68% 2.14% 2.76%
Our B 1.57% 2.49% 2.02% 2.69%
Our B ,T 0.64% 0.07% 0.10% 0.05%
Our full NF 0.53% 0.06% 0.09% 0.05%
(b) Statistics on the % of allowed derivations
Figure 9: Experimental results: the effect of different normal forms on the number of derivations
of the non-NF derivation in Fig. 8 is also one less
than that of the NF derivation, but its B-degree is
increased by one, so for NT = NB either both
derivations are possible or neither.
What remains to be proven is that we have
considered all cases of spurious ambiguity in-
volving three constituents, and that all cases of
spurious ambiguity that arise for more than three
constituents reduce to these cases.
5 The effects of normal form parsing
We now illustrate the impact of the different nor-
mal form variants on a small, restricted, gram-
mar. We define a set of atomic categories, a set of
lexical categories (up to a fixed arity NLex), and
compile out all possible rule instantiations (in-
cluding compositions up to a fixed degree N|B)
that generate categories up to a fixed arity Ncat10
The effect of different normal forms This
experiment is intended to examine how nor-
mal form parsing might reduce spurious ambi-
guity for actual grammars, e.g. for unsuper-
vised estimation of stochastic CCGs. We cre-
ated a small English grammar with atomic cat-
egories S,NP,N, conj, ., , ; and 47 lexical cate-
gories using NLex = 3, NB = 3, NCat = 15.
There are two type-changing rules (N ? NP
and S/NP ? NP\NP ). We accept deriva-
tions of S, NP and S\NP. The T|X in T has
to be a lexical category. Our lexical categories
are divided into disjoint sets of adjuncts of the
form X|X and (X|X)|Y, head (both atomic and
complex), and punctuation and conjunction cat-
egories. The comma can act as a conjunction or
to set off modifiers (requiring punctuation rules
10The restriction of categories to a fixed arity
means that we could generate cross-serial dependencies
N1...NnV1...Vn only up to n = Acat .
of the form X|X , ? X|X and , X|X ? X|X).
We furthermore define coarse-grained parts of
speech (noun, verb, function word, conj, other)
and decide for each part of speech which lexical
categories it can take. We compare different NF
settings for sentences of lengths 15?30 from Eu-
roparl (Koehn, 2005). At each length, we com-
pare 100 sentences that our grammar can parse.
All NFs can parse all sentences the full grammar
can parse. Results (Fig. 9(a)) show that our NF
reduces the number of derivations significantly
over Eisner?s NF, even though our (full) gram-
mar only allows a restricted set of type-raising
rules. Fig. 9(b) illustrates the combinatorial ex-
plosion of spurious derivations as the sentence
length increases.
6 Conclusions
We have proposed a modification and extension
of Eisner (1996)?s normal form that is more ap-
propriate for commonly used variants of CCG
with grammatical type-raising and generalized
composition of bounded degree, as well as some
non-combinatory extensions to CCG. Our exper-
iments indicate that incorporating normal form
constraints to deal with grammatical type-raising
drastically reduces the number of derivations.
We have sketched the outline of a proof that our
normal form is safe and complete for the variant
of CCG we consider, althoug we have seen that
under certain circumstances, type-raising of un-
bounded degree may be required. Future work
will investigate this issue further, and will also
aim to turn our informal arguments about the ad-
equacy of our approach into a full proof, and pro-
vide more experiments on a wider range of gram-
mars and languages.
472
References
Boxwell, Stephen, Dennis Mehay, and Chris Brew.
2009. Brutus: A semantic role labeling system in-
corporating CCG, CFG, and dependency features.
In Proceedings of the 47th ACL/4th IJCNLP, pages
37?45.
Clark, Stephen and James R. Curran. 2007. Wide-
coverage efficient statistical parsing with CCG
and log-linear models. Computational Linguistics,
33(4):493?552.
Curran, James, Stephen Clark, and Johan Bos.
2007. Linguistically motivated large-scale NLP
with C&C and boxer. In Proceedings of the 45th
ACL Companion Volume (Demo and Poster Ses-
sions), pages 33?36, Prague, Czech Republic.
Eisner, Jason. 1996. Efficient normal-form pars-
ing for Combinatory Categorial Grammar. In Pro-
ceedings of the 34th ACL, pages 79?86, Santa
Cruz, CA.
Espinosa, Dominic, Michael White, and Dennis
Mehay. 2008. Hypertagging: Supertagging for
surface realization with CCG. In Proceedings of
ACL-08: HLT, pages 183?191, Columbus, Ohio.
Gildea, Daniel and Julia Hockenmaier. 2003. Iden-
tifying semantic roles using Combinatory Catego-
rial Grammar. In Proceedings of EMNLP, Sap-
poro, Japan.
Hepple, Mark and Glyn Morrill. 1989. Parsing and
derivational equivalence. In Proceedings of the
Fourth EACL, pages 10?18, Manchester, UK.
Hockenmaier, Julia and Mark Steedman. 2007.
CCGbank: A corpus of CCG derivations and de-
pendency structures extracted from the penn tree-
bank. Computational Linguistics, 33(3):355?396.
Hockenmaier, Julia. 2003. Data and models for
statistical parsing with Combinatory Categorial
Grammar. Ph.D. thesis, School of Informatics,
University of Edinburgh.
Hoffman, Beryl. 1995. Computational Analysis of
the Syntax and Interpretation of ?Free? Word-order
in Turkish. Ph.D. thesis, University of Pennsylva-
nia. IRCS Report 95-17.
Hoyt, Frederick and Jason Baldridge. 2008. A log-
ical basis for the D combinator and normal form
in CCG. In Proceedings of ACL-08: HLT, pages
326?334, Columbus, Ohio.
Karttunen, Lauri. 1989. Radical lexicalism. In
Baltin, M.R. and A.S. Kroch, editors, Alternative
Conceptions of Phrase Structure. Chicago Univer-
sity Press, Chicago.
Koehn, Philipp. 2005. Europarl: A parallel cor-
pus for statistical machine translation. In 10th MT
Summit, pages 79?86, Phuket, Thailand.
Komagata, Nobo. 1997. Generative power of
CCGs with generalized type-raised categories. In
ACL35/EACL8 (Student Session), pages 513?515.
Komagata, Nobo. 2004. A solution to the spurious
ambiguity problem for practical combinatory cate-
gorial grammar parsers. Computer Speech & Lan-
guage, 18(1):91 ? 103.
Niv, Michael. 1994. A psycholinguistically moti-
vated parser for CCG. In Proceedings of The 32nd
ACL, Las Cruces, NM, pages 125?132.
Pareschi, Remo and Mark Steedman. 1987. A lazy
way to chart parse with categorial grammars. In
Proceedings of the 25th ACL, pages 81?88, Stan-
ford, CA.
Shieber, Stuart M., Yves Schabes, and Fernando
C. N. Pereira. 1995. Principles and implemen-
tation of deductive parsing. Journal of Logic Pro-
gramming, 24(1?2):3?36, July?August.
Steedman, Mark. 2000. The Syntactic Process. MIT
Press, Cambridge, MA.
Vijay-Shanker, K and David J Weir. 1993. Parsing
some constrained grammar formalisms. Compu-
tational Linguistics, 19(4):591?636.
Weir, David. 1988. Characterising Mildly Context-
sensitive Grammar Formalisms. Ph.D. thesis, Uni-
versity of Pennsylvania. Tech. Report CIS-88-74.
Wittenburg, Kent B. 1986. Natural Language Pars-
ing with Combinatory Categorial Grammar in a
Graph-Unification Based Formalism. Ph.D. the-
sis, University of Texas at Austin.
Zettlemoyer, Luke S. and Michael Collins. 2005.
Learning to map sentences to logical form: Struc-
tured classification with probabilistic categorial
grammars. In Proceedings of the 21st UAI, pages
658?666, Edinburgh, UK.
Zettlemoyer, Luke and Michael Collins. 2007. On-
line learning of relaxed CCG grammars for pars-
ing to logical form. In Proceedings of EMNLP-
CoNLL, pages 678?687, Prague, Czech Republic.
Acknowledgements
We would like to thank Mark Steedman for help-
ful discussions, and Jason Eisner for his very
generous feedback which helped to greatly im-
prove this paper. All remaining errors and omis-
sions are our own responsibility. J.H is supported
by NSF grant IIS 08- 03603 INT2-Medium.
473
