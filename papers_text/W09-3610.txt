Proceedings of the 2009 Workshop on Text and Citation Analysis for Scholarly Digital Libraries, ACL-IJCNLP 2009, pages 80?87,
Suntec, Singapore, 7 August 2009. c?2009 ACL and AFNLP
Citations in the Digital Library of Classics: Extracting Canonical
References by Using Conditional Random Fields
Matteo Romanello, Federico Boschetti, Gregory Crane
The Perseus Project
Medford, MA, USA
matteo.romanello, federico.boschetti, gregory.crane{@tufts.edu}
Abstract
Scholars of Classics cite ancient texts by
using abridged citations called canonical
references. In the scholarly digital library,
canonical references create a complex tex-
tile of links between ancient and modern
sources reflecting the deep hypertextual
nature of texts in this field. This paper
aims to demonstrate the suitability of Con-
ditional Random Fields (CRF) for extract-
ing this particular kind of reference from
unstructured texts in order to enhance the
capabilities of navigating and aggregating
scholarly electronic resources. In partic-
ular, we developed a parser which recog-
nizes word level n-grams of a text as be-
ing canonical references by using a CRF
model trained with both positive and neg-
ative examples.
1 Introduction
In the field of Classics, canonical references are
the traditional way established by scholars to cite
primary sources within secondary sources. By
primary sources we mean essentially the ancient
texts that are the specific research object of Philol-
ogy, whereas by secondary sources we indicate all
the modern publications containing scholarly in-
terpretations about those ancient texts. This spe-
cific characteristic strongly differentiates canoni-
cal references from the typical references we usu-
ally find within research papers.
Canonical references are used to shortly refer to
the research object itself (in this case ancient texts)
rather than to the existing literature about a cer-
tain topic, as happens with references to other sec-
ondary sources. Given this distinction, canonical
references assume a role of primary importance as
the main entry point to the information contained
in scholarly digital libraries of Classics. To find a
parallel with other research fields, the role played
by those references is somewhat analogous with
that played by protein names in the medical liter-
ature or by notations of chemical compounds in
the field of Chemistry. As was recently shown by
Doms and Schroeder (2005) protein names can be
used to semantically index documents and thus to
enhance the information retrieval from a digital li-
brary of texts, provided that they are properly or-
ganized by using an ontology or a controlled vo-
cabulary. Moreover, by analyzing and indexing
such references as if they were backlinks (Lester,
2007) from a secondary to a primary source, it is
possible to provide quantitative data about the im-
pact of an ancient author for research in a particu-
lar disciplinary field, or in relation to a limited cor-
pus of texts (e.g., the papers published by schol-
arly journals in a given time interval).
In addition to serving as entry points to infor-
mation, canonical references can also be thought
of as a navigation apparatus that allows scholars
to browse seamlessly through ancient texts and
modern interpretations about them (Crane, 1987).
For every scholar working on the ancient histo-
riographer Herodotus, for instance, it would be
extremely useful to be able to easily access all
the secondary sources containing references to
Herodotus? works.
Therefore, the ability to automatically identify
canonical references within unstructured texts is a
first and necessary step to provide the users of dig-
ital libraries of Classics with a more sophisticated
way to access information and to navigate through
the texts that are already available to scholars of
other fields.
The volume of publicly available digitized
books constituting what has been called the Mil-
lion Book Library (Crane, 2006) has made it es-
sential to develop automatic and scalable tools
to automate the process of information extraction
from electronic resources. Furthermore, the obso-
80
lescence time for publications is far longer in Clas-
sics than in other disciplines, meaning that typi-
cally the value of a publication does not decrease
drastically after a certain time. As a result, schol-
ars in Classics may be the most potential benefi-
ciaries of the recent mass digitization initiatives,
since they have already started with many materi-
als out of copyright.
In this paper we describe how Conditional Ran-
dom Fields (Lafferty et al, 2001), the state of the
art model in automatic classification, can be suit-
ably applied to provide a scalable solution to this
problem.
2 Related work
Canonical references to primary sources can be
explored from at least three different angles: 1)
identification and extraction; 2) hypertextual nav-
igation; 3) semantics.
The identification and extraction of biblio-
graphic references from what we called secondary
sources (i.e. monographs, commentaries, journal
papers, etc.) is a well explored task for which ef-
fective tools already exist. Although the biggest
efforts in this direction have been made in the
scientific fields, those tools can also be suitably
adapted to the field of Classics, since they are es-
sentially based on machine learning techniques.
Several researchers recently focused on apply-
ing computational linguistics methods to automat-
ically extract information from both Classical texts
and modern texts about them, in order to support
the above described needs of scalability. Gerlach
and Crane (2008), and Kolak and Schilit (2008)
considered the identification of citations within
primary sources by analyzing the syntactic and
morphological features of texts, while (Smith and
Crane, 2001) dealt with the disambiguation of ge-
ographical names.
Looking at the problem of canonical references
from the user point of view, a digital library of
Classical texts such as the Perseus Digital Li-
brary1. already offers to the reader the ability to
navigate from secondary sources to the primary
sources they refer to, a process called reference
linking. The identification of references and the
attribution of semantics to them, however, was
done manually, and the navigation is limited to re-
sources contained in the same text collection. An
analogous reference linking system was proposed
1http://www.perseus.tufts.edu/hopper/
by Romanello (2008) as a value added service that
could be provided to readers of electronic journals
by leveraging semantic encoded canonical refer-
ences.
(Smith, 2009) provided an essential contribu-
tion to the research concerning the semantics of
canonical references. The Canonical Text Services
(CTS) protocol2 was developed by Smith for Har-
vard?s Center for Hellenic Studies; it is based on
URNs and is aimed at providing a machine action-
able equivalent to printed canonical references.
This protocol allows us to translate those refer-
ences into machine actionable URNs that can then
be resolved through resolution services against a
distributed digital library of texts. The innovative
aspect of the CTS protocol consists of a loose cou-
pling system by which the linking between pri-
mary and secondary sources can be realized. In-
stead of hard linking a canonical reference to just
one electronic edition of a primary source, by em-
bedding the CTS URNs inside (X)HTML pages, it
becomes possible to link it to an open ended num-
ber of resources as shown by (Romanello, 2007).
3 Canonical Text References
Canonical references present unique characteris-
tics when compared to bibliographic references to
modern publications. First of all, they do not re-
fer to physical facts of the referred work (such as
publication date or page number), but refer rather
to its logical and hierarchical structure. In addi-
tion, canonical references often provide additional
information needed by the reader to resolve the
reference. For example ?Archestr. fr. 30.1 Olson-
Sens? means line 1 of fragment 30 of the comic
poet Archestratus in the edition published by S. D.
Olson and A. Sens in 1994.
The specification of the edition according to
which a source is cited is an important piece of in-
formation to be considered. Indeed, since the aim
of Philology is to reconstruct for ancient works a
text that is as close as possible to the original one
(given that the original text may have been cor-
rupted over centuries of manuscript tradition), ed-
itors and scholars often disagree substantially as to
what readings and conjectures have to be included
in the established text.
Although some well established sets of abbre-
viations exist, scholars? practice of citing primary
2http://chs75.harvard.edu/projects/
diginc/techpub/cts
81
sources may noticeably differ according to style
preferences and the typographical needs of pub-
lishers, journals or research groups. Aeschylus?
name might appear in the abridged forms ?A.,
Aesch., Aeschyl.?, and similarly a collection of
fragments like Jacoby?s Die Fragmente der Gri-
eschischen Historiker may be abbreviated either
as FrGrHist or FGrHist.
Moreover, some highly specialized branches of
research exist within the field of Classics, such as
those dedicated to Epic poetry or Tragedy, or even
to a single author like Aeschylus or Homer. In
those specialized branches a common tendency to
use shorter references with a higher semantic den-
sity for the most cited authors can be observed.
For example, in publications containing thousands
of references to Homer?s Iliad and Odyssey, refer-
ences to these texts are often expressed with Greek
letters indicating the book number along with the
verse number (e.g., ?? 1? stands for the first verse
of the first book of Homer?s Odyssey). Lowercase
letters are used to refer to books of the Odyssey,
whereas uppercase letters refer to the books of the
Iliad, according to a practice developed in the IV
century B.C. by scholars of the library at Alexan-
dria.
In the actual practice of scholarly writing,
canonical references can appear with slightly dif-
ferent figures according to the needs of narrative.
Along with complete canonical references to a sin-
gle text passage, expressed as either a single value
or a range of values, other references can often be
found that are missing one or more components
that are normally present within canonical refer-
ences, such as an indication of the author name, of
the work title or of the editor name (e.g., ?Hom.
Od. 9.1, 9.2-3; Il 1.100?). This happens partic-
ularly in subsequent references to passages of the
same work.
Those differences that can be observed about
the appearance of canonical references require us
to apply different processing strategies to each
case. We focus on the task of automatically iden-
tifying complete references to primary sources.
Once those references have been identified in the
input document, we can find other anaphoric refer-
ences by applying some scope-based parsing. In-
deed, a canonical reference in the text constitutes
the reference scope for subsequent text passage in-
dications referring to the same work.
4 Methodology
Provided that scholars may use canonical refer-
ences with different abbreviation or citation styles,
it is nevertheless possible to identify within canon-
ical references common patterns in terms of token
features.
CRF is used to classify a token depending on
its features and is suitable to identify those feature
patterns (Culotta et al, 2006). During the training
phase, the CRF model learns what features make
it more likely for a token to belong to a given cat-
egory.
Our starting assumption is that it is possible
to determine if a sequence of tokens constitute a
canonical reference by evaluating (looking at) the
features of its tokens. Each token of a sequence is
assigned a category on the basis of a fixed num-
ber of features. Those token categories are in turn
used as features to classify the token sequence.
Starting from a dataset of canonical references
and applying the above described criteria to assign
features to the tokens, we obtain a training dataset
where each canonical reference is reduced to a to-
ken by removing whitespaces, and it is a assigned
as many as features as the category assigned to its
tokens.
Finally, in order to classify token sequences as
?references? or ?non-references? each canonical
reference is assigned a convenient label. The ob-
tained set of labelled references is used to train a
CRF model to identify canonical references within
unstructured texts.
4.1 Feature Extraction and Token
Categorization
For feature extraction phase, it was important to
identify both inclusive and exclusive token fea-
tures. Indeed, to extract canonical references with
a high level of precision, we need to identify not
only the characteristic features of tokens occurring
within actual references but also those characteris-
tic features for tokens occurring in sequences that
we want to be classified as non-references.
Even though the features are quite similar to
those used to identify modern bibliographic refer-
ences (Isaac Councill and Kan, 2008), they were
tuned to fit the specific needs of canonical refer-
ences to primary sources. We decided to record a
total of 9 features for each token, concerning the
following aspects:
82
1. Punctuation: information about the punctu-
ation concerning the presence of a final dot,
hyphen, quotation marks and brackets (either
single or paired), and marks used to divide
and structure sequences (i.e. comma, colon
and semicolon), which are particularly im-
portant for sequences of text passages.
2. Orthographic Case: the orthographic case
of a token is an essential piece of informa-
tion to be tracked. Author names when ab-
breviated still keep the initial as an upper-
case letter, whereas collections of texts (such
as collections of fragments) often present all
uppercase or mixed case letters (e.g., ?Tr-
GrFr?,?CGF?, ?FHG?, etc.).
3. Stopwords: given that the main language of
the input document is passed as a parame-
ter to the parser, we record in a separate fea-
ture information regarding whether a token is
a stopword in the input document language.
This feature is particularly important in deter-
mining more precisely the actual boundaries
of a canonical reference within the text.
4. Greek Words: since we deal with Unicode
UTF-8 text, we distinguish Greek letters and
words. This allows us to identify more pre-
cisely those references that contain Greek
text such as the above mentioned Homeric
references or references to the ancient lexica
(e.g., Harpocr., Lex. s.v. ??????????) since
they contain the lemma of the Greek word re-
ferred to, usually preceded by the abbrevia-
tion ?s.v.? (i.e. sub voce).
5. Number: Roman and Arabic numerals com-
bined in several figures are frequently used
to indicate the scope of a reference. Arabic
numerals that are used to represent modern
dates, however, are distinguished by using
a heuristic (for example, consider the prob-
lem of a footnote mark which gets appended
to a date). Nevertheless, sequences of both
numbers and punctuation marks are assigned
a specific value for this feature, since the
scope of a reference is commonly expressed
by dot and hyphen separated sequences such
as ?9.235-255?.
6. Dictionary matching: two features are as-
signed if a token matches a dictionary entry.
Three different dictionaries are used to ver-
ify if a token corresponds to a known canon-
ical abbreviation (e.g. ?Hom.? for Homer or
?Od.? for Odyssey) or to another kind of ab-
breviation, namely the abbreviations used by
philologists to shortly refer to pages, lines,
verses, etc. (?p?, ?pp.?, ?v.?, ?vv.?, ?cfr?, etc.)
or to abbreviations used for modern journals.
Abbreviations pertaining to the latter kind are
likely to introduce some noise during the n-
gram classification phase and thus are prop-
erly distinguished through a specific feature.
During preliminary analysis we particularly
observed that journal abbreviations were of-
ten confused with abbreviations for text col-
lections since - as we noted above - they share
the feature of having uppercase or mixed case
letters.
7. Fragment indication: canonical references to
fragments usually contain the indication ?fr.?
(and ?frr.? for more than one). Therefore
we expect tokens bearing this feature to occur
almost exclusively within references to frag-
mentary texts.
We extract from the training dataset those
unique patterns of these 9 token features that are
likely to be found within canonical references. In
order to ensure both the scalability and the ex-
tensibility of the suggested method to disciplinary
fields other than Classics, we did not assign an
identity feature to tokens or - in other words - the
actual string content is not considered as a token
feature. However, since this decision might de-
crease the overall precision of the system, we in-
troduced some features to record whether the to-
ken string occurs in one or more controlled dictio-
naries (e.g., list of widely adopted abbreviations).
An analogous consideration is valid also for
the dependency of the system from a specific lan-
guage. Even though the approach is substantially
language independent, the performances of our
system in terms of precision were improved by
using language specific lists of stopwords in or-
der to identify the actual boundaries of a canoni-
cal reference within the text. Currently we support
the most commonly used languages in the field of
Classics (English, French, German, Italian, Span-
ish).
Finally, it is worth noting that the use of italics is
a distinctive feature in particular for those tokens
83
that represent abbreviations of work titles. Since
we are dealing with plain text input documents,
however, and wish to keep the adopted approach
as generalizable as possible, this feature has not
been taken into account.
Token Features Cat.
F1 F2 F3 F4 F5 F6 F7 F8 F9
Od. ICP FDT NOD OTH OTH OTH CAB OTH OTH 1 c50
9.216-535. OTH FDT DSN OTH OTH OTH OTH OTH OTH 2 c6
Table 1: Categorization of tokens of the reference
?Od. 9.216-535? on the basis of their features.
Token Features Cat.
F1 F2
Od. 9.216-535 1 c50 2 c6 ref
Table 2: Categorization of the reference of Tab. 1
by using token categories as its features.
Feature Label
F1 Case
F2 Punctuation Mark
F3 Number
F4 Greek Sequence
F5 Stop Word
F6 Paired Brackets
F7 Contained in the 1st Dict.
F8 Contained in the 2nd Dict.
F9 Fragment Indication
Feature Value
CAB Canonical Abbreviation
DSN Dot Separated Number Plus Range
FDT Final Dot
ICP Initial Cap
NOD No Digit Sequence
OTH Other
Table 3: List of abbreviations used in Tab. 1, 2.
4.2 Positive and Negative Training
Since the main goal of our parser is to identify
canonical references by isolating them from the
surrounding context, both positive and negative
training examples are needed. Indeed, provided
two token sequences where the first contains just
a canonical reference (e.g., ?Od. 9.216-535?) and
the second additionally includes some tokens from
the context phrase (e.g.,?Od. 9.216-535, cfr. p.
29.?), without a negative training phrase both to-
ken sequences would have the same degree of sim-
ilarity. When weighted by the CRF model the
result would be that both sequences would share
the same number of features with one of the refer-
ences of the positive training. But since other se-
quences presenting features from both the positive
and negative training were included in the training,
and since such sequences were labelled as ?non-
references?, the end result is that a token sequence
with some tokens from a context phrase will be
less similar to a pure canonical reference.
The first step of the training phase is the ex-
traction of token features and the identification of
unique patterns of token features. At this stage
the processing units are the tokens of a reference.
Given a dataset of canonical references, each ref-
erence is firstly tokenized and each token is then
assigned 9 labels containing the values for the
above described features (see Section 4.1). Note
that in Tab. 1, 2 the labels and values of features
are indicated by the abbreviations given in Tab. 3.
The observed combinations of feature values
are then deduplicated and rearranged into unique
categories that are used to classify each token (see
Tab 1). These categories correspond to the uniques
combinations of features assigned to tokens of ref-
erences in the training dataset. Each category is
defined by a name such as ?c6? or ?c50?, where
?c? simply stands for ?category?? and ?6? or ?50?
are unique numeric identifiers. Besides, a numer-
ical prefix corresponding to the position of the to-
ken inside the canonical reference is then added to
the category name to form the identifier. Indeed,
the position of each token in the sequence is in
itself meaningful information, provided that indi-
cations of the reference scope (and other reference
components as well) tend to occur at the end of
the token sequence. What we obtain are category
identifiers such as ?1 c50? or ?2 c6?.
The second step is building the training dataset.
At this stage each canonical reference is reduced
to a single token which is assigned the label ?ref?
(i.e. reference) and which has as distinctive fea-
tures the category identifiers assigned to its tokens
(see Tab 2).
Finally, a such obtained dataset of labelled in-
stances is used to train our CRF model by us-
ing the Java CRF implementation provided by the
Mallet toolkit (McCallum, 2002).
84
4.3 Sequence Classification Process
The system we propose to identify canonical ref-
erences in unstructured texts is basically a binary
classifier. Indeed, it classifies as ?reference? or
?non-reference? a sequence of word level n-grams
depending on the features of its tokens. However,
in the training dataset the positive examples are
manually grouped by typology and different labels
(such as ?ref1?, ?ref2? etc.) are assigned to canon-
ical references pertaining to different types. This
is done in order to avoid associating too many fea-
tures to a single class and thus to maximize the
difference in terms of features between sequence
being references and non-references.
Since every token is assigned a certain number
of features and finally a category, the likelihood
for a token sequence to be a canonical reference
can be determined on the basis of its similarity, in
terms of token features, to the labelled references
of a training set.
Once the input document is tokenized into sin-
gle words, the n-grams are created by using a
window of variable dimensions ranging from the
minimum to the maximum length in terms of to-
kens that was observed for all the references in the
training dataset. For example, provided that the
shortest canonical reference in the training dataset
is 2 tokens long and the longest is 7 tokens long,
for each token are created 6 word level n-grams.
For the sake of performance, however, the num-
ber of n-grams to be created is determined for
each token at parsing time. First of all a threshold
value is passed to the parser as an option value.
The threshold is compared to the weight value as-
signed by the CRF model to the probability of a
token to be classified with a label, in our case
?ref? or ?noref?. For each token, if the first n-
gram is classified as not being a canonical refer-
ence the processing shifts to the next token, since
we observed that if the first n-gram is classified as
a non-reference the following n-grams of increas-
ing width never contain a reference. If the exam-
ined n-gram is classified as reference, another of
dimension n+1 is created: the parser passes on to
process the next token only if the current n-gram
is classified as a canonical reference with a like-
lihood value greater that that of the previous n-
gram.
5 Training and Evaluation Criteria
The system is based on both a positive and a neg-
ative training.
The dataset for the positive training is built by
labeling with the above explained criteria a start-
ing set of approximatively 50 canonical references
selected by an expert. The classifier trained with
those positive examples is then applied to a ran-
dom set of documents. Extracted candidate canon-
ical references are scored by the CRF model by as-
signing to each sequence of n-grams a value rep-
resenting the probability for the sequence to be a
canonical reference.
The first one hundred errors with the highest
score, due to the sharing of several features with
the actual canonical references, are marked as
non-references and added to the set of sequences
to use for the negative training. The negative
training is needed in order to precisely segment
a canonical reference and to correctly classify
those sequences that are most likely to be con-
fused with actual canonical references, such as se-
quences only partially containing a canonical ref-
erence or bibliographic references. In particular,
bibliographic references are misleading sequences
since they have several features in common with
canonical references, such as capitalized titles and
page numbers.
The overall performances of the system on
a random sample of 24 pages can be summa-
rized by: precision=81.01%, recall=94.11%, ac-
curacy=77.11%, F-score=0.8707. Analytical data
are provided in Tab. 4. Although the evaluation
was performed on pages drawn from a publica-
tion written in Italian, we expect to have analogous
performances on texts written in each of the cur-
rently supported languages (English, French, Ger-
man, Italian, Spanish) for the reasons described in
Section 4.1.
The results are encouraging, however, and some
further improvements could concern the recovery
of tokens wrongly included in or excluded from
the sequence identified by the parser.
6 Conclusion and Future Work
This paper has illustrated how the CRF model can
be suitably applied to the task of extracting canoni-
cal references from unstructured texts by correctly
classifying word level n-grams as references or
non-references.
85
Document # Precision Recall Accuracy F-Score
40 100.00% 100.00% 100.00% 1.0000
41 100.00% 100.00% 100.00% 1.0000
55 100.00% 100.00% 100.00% 1.0000
57 100.00% 100.00% 100.00% 1.0000
62 100.00% 100.00% 100.00% 1.0000
64 100.00% 100.00% 100.00% 1.0000
67 25.00% 25.00% 25.00% 0.2500
74 88.00% 87.50% 77.78% 0.8800
77 45.00% 90.00% 42.86% 0.6000
82 100.00% 100.00% 100.00% 1.0000
85 100.00% 90.00% 90.00% 0.9474
88 100.00% 100.00% 100.00% 1.0000
90 92.31% 92.31% 85.71% 0.4286
100 100.00% 100.00% 100.00% 1.0000
113 60.00% 100.00% 60.00% 0.7500
117 100.00% 100.00% 100.00% 1.0000
134 100.00% 75.00% 75.00% 0.8571
137 75.00% 100.00% 75.00% 0.8571
144 67.00% 100.00% 67.00% 0.8024
146 33.00% 100.00% 33.00% 0.4511
150 57.14% 100.00% 57.00% 0.7273
162 100.00% 100.00% 100.00% 1.0000
169 50.00% 75.00% 43.00% 0.6000
Overall 81.01% 94.11% 77.11% 0.8707
Table 4: Performance evaluation of the system.
Once automatically identified, canonical refer-
ences can have further semantic information added
to them. By combining and then applying tech-
niques of syntactic and semantic parsing to the
identified references, it is possible to extract infor-
mation such as the precise author name and work
title, the text passage referred to, and the reference
edition (either when implicitly assumed or explic-
itly declared).
The first important outcome of our work is that
such an automatic system allows us to elicit the
hidden tangle of references which links together
the primary and secondary sources of a digital li-
brary. Another important outcome is that unstruc-
tured texts could be analyzed on the basis of the
canonical references they contain, for example by
clustering techniques. Given a consistent corpus
of texts it would be possible to cluster it on the
basis of the distribution of canonical references
within documents in order to obtain a first topic
classification.
Among the benefits of the proposed approach
there is the possibility of applying it to texts per-
taining to specific branches of Classics, like Pa-
pyrology or Epigraphy. Indeed in those disci-
plines papyri and epigraphs are also often cited by
abridged references that are very similar in their
structure and features to the canonical text ref-
erences. In a similar way, a canonical reference
parser can be trained on a particular citation style
in order to tailor it to a consistent corpus of texts
with consequent improvements on the overall per-
formances.
Finally, since the task of automatic extraction
of canonical references has never been explored
before, we hope that in the future more resources
will be available for this task (such as training
datasets, golden standards, performance measure
to be compared, etc.), analogous to those already
existing for other more common tasks, like named
entity recognition or the extraction and labeling of
modern bibliographic references.
References
Gregory Crane. 1987. From the old to the new: in-
tergrating hypertext into traditional scholarship. In
Proceedings of the ACM conference on Hypertext,
pages 51?55, Chapel Hill, North Carolina, United
States. ACM.
Gregory Crane. 2006. What do you do with a million
books. D-Lib Magazine, 12(3).
Aron Culotta, Andrew Mccallum, and Jonathan Betz.
2006. Integrating probabilistic extraction models
and data mining to discover relations and patterns in
text. In Proceedings of the main conference on Hu-
man Language Technology Conference of the North
American Chapter of the Association of Computa-
tional Linguistics, pages 296?303, Morristown, NJ,
USA. Association for Computational Linguistics.
Andreas Doms and Michael Schroeder. 2005. GoP-
ubMed: exploring PubMed with the gene ontology.
Nucl. Acids Res., 33(suppl 2):783?786, July.
Andrea Ernst-Gerlach and Gregory Crane, 2008. Iden-
tifying Quotations in Reference Works and Primary
Materials, pages 78?87.
C. Lee Giles Isaac Councill and Min-Yen Kan. 2008.
Parscit: an open-source crf reference string pars-
ing package. In Bente Maegaard Joseph Mari-
ani Jan Odjik Stelios Piperidis Daniel Tapias Nico-
letta Calzolari (Conference Chair), Khalid Choukri,
editor, Proceedings of the Sixth International
Language Resources and Evaluation (LREC?08),
Marrakech, Morocco. European Language Re-
sources Association (ELRA). http://www.lrec-
conf.org/proceedings/lrec2008/.
86
Okan Kolak and Bill N. Schilit. 2008. Generating links
by mining quotations. In Proceedings of the nine-
teenth ACM conference on Hypertext and hyperme-
dia, pages 117?126, Pittsburgh, PA, USA. ACM.
John Lafferty, Andrew Mccallum, and Fernando
Pereira. 2001. Conditional random fields: Prob-
abilistic models for segmenting and labeling se-
quence data. In Proc. 18th International Conf. on
Machine Learning, pages 289, 282. Morgan Kauf-
mann, San Francisco, CA.
Frank Lester. 2007. Backlinks: Alternatives to the
citation index for determining impact. Journal of
Electronic Publishing, 10(2).
Andrew Kachites McCallum. 2002. MAL-
LET: a machine learning for language toolkit.
http://mallet.cs.umass.edu.
Matteo Romanello. 2007. A semantic linking sys-
tem for canonical references to electronic corpora.
Prague. to be next published in the proceedings of
the ECAL 2007 Electronic Corpora of Ancient Lan-
guages, held in Prague November 2007.
Matteo Romanello. 2008. A semantic linking frame-
work to provide critical value-added services for e-
journals on classics. In Susanna Mornati and Leslie
Chan, editors, ELPUB2008. Open Scholarship: Au-
thority, Community, and Sustainability in the Age of
Web 2.0 - Proceedings of the 12th International Con-
ference on Electronic Publishing held in Toronto,
Canada 25-27 June 2008 / Edited by: Leslie Chan
and Susanna Mornati.
David A. Smith and Gregory Crane. 2001. Disam-
biguating geographic names in a historical digital li-
brary. In ECDL ?01: Proceedings of the 5th Euro-
pean Conference on Research and Advanced Tech-
nology for Digital Libraries, pages 127?136, Lon-
don, UK. Springer-Verlag.
Neel Smith. 2009. Citation in classical studies. Digital
Humanities Quarterly, 3(1).
87
