m 
m 
m 
m 
mm 
m 
m 
n 
\[\] 
WordNet  2 - A Morpho log ica l ly  and Semant ica l ly  Enhanced 
Resource  
Sanda M. Harabagiu George A. Miller Dan I. Moldovan 
Depar tment  of Computer  Cogmt~ve Scmnce Laboratory  Depar tment  of Computer  
Scmnce and Engineer ing Pr inceton  Umvermty  Scmnce and Eng~eneermg 
Southern  Method is t  Umvermty  221 Nassau St reet  Southern  Methodist  Umvers~ty 
Dallas, TX  75275-0122 Pr inceton,  NJ  08542 Dallas, TX  75275-0122 
sanda@seas  smu edu geo@clarz ty  prznceton  edu moldovan@seas mu edu 
Abst ract  
Th~s paper presents an on-going project m- 
tended to enhance WordNet molpholog~- 
cally and semanttcally The mottvatmn for 
th~s work steams from the current hm~ta- 
t~ons of WordNet when used as a hngmst~c 
knowledge base We enwmon a software 
tool that automatically parses the concep- 
tual defining glosses, attributing part-of- 
speech tags and phrasal brackets The 
nouns, verbs, adjectives and adverbs from 
every defimtmn are then d~samb~guated 
and hnked to the corresponding synsets 
Th~s increases the connectlv~ty between 
synsets allowing the ~etneval of topically 
~elated concepts Furthermore, the tool 
t~ansforms the glosses, first into logical 
forms and then into semantm fo~ms Us- 
mg der~vatmnal morphology new hnks are 
added between the synsets 
1 Mot ivat ion  
WordNet has already been ~ecogmzed as a valu- 
able ~esource m the human language technol- 
og> and know, ledge processing commumtms Its 
apphcabfl~ty has been c~ted m mo~e than 200 
papers and s~stems have been m~plemented us- 
mg WordNet A Wo~dNet bkbhog~aph~ ~s 
mamtamed at the Umve~mt) of Penns:~l~ama 
( http //www c~s upenn edu/~oseph~ /wn- 
btblw html) In Europe, WordNet ~s being u~ed to 
develop a multflmgual database w~th basic semantic 
relatmns between words for several European lan- 
guages (the EuroWordNet project) 
Capabiht ies  WordNet was conceived as a 
machine-readable dmtlonary, followmg psychohn- 
gmstm principles Unhke standard alphabetmal dm- 
t~onaHes ~hmh o~gamze vocabula~ms u ing mo~pho- 
logmal mmllm ltms, WordNet structures lex~cal refor- 
mation m terms of word meanings WordNet maps 
word forms m ~ord senses usmg the s)ntact~c at- 
egory as a parametel Although it covers onl~ fouI 
paits of speech nouns verbs, adjectives and ad- 
verbs, it encompasses a large majont) of Enghsh 
words ( http //www cogscz pmnceton edu/~..wn) 
Wolds of the same syntactm catego~) that 
can be used to express the same meamng are 
grouped into a smgle synonym set, called synset 
Words wlth multiple meanings (polysemous) be- 
long to multiple synsets An ~mportant part 
of the 99 643 synsets encoded m WordNet 1 6 
contain word collocatmns, thus representing com- 
plex nominals (e g the synset {manufacturer, 
maker, manufacturing business} , (omplex vel- 
bals (eg the synset {leave o f f i ce ,  quit ,  step 
down}, complex adjectlvals (e g the ~ynset {true, 
dead on target}  or complex adverbmls (e g the 
synset {out of hand, beyond control} The iep- 
~esentatmn of collocatmns as synset entries p~ov~des 
for their semantm mterp~etatmn 
Wolds and concepts are furthei connected 
through a small set of lexmo-semantm relatmns 
The dominant semantm relatmn is the hypernymy, 
xvh~ch structures the noun concepts m 11 hmr- 
aichms and the verb concepts into 512 )he, at- 
chins Thlee melonym Ielatlons are encoded be- 
tween noun concepts the ha~_member, the ha~_~tu\]f 
and the has_part ~elatlons Loglcal opelatlon~ be- 
tx~een events or entltms ale modeled through entazl- 
ment and cause_to ~elatmns between verb concepts 
or antonymy relatmns among nouns, veibs ad)ec- 
t~ves or adverb words The~e are only a few mo~- 
phologmally motivated connectmns between x~ords 
known as perta~mym relatmns 
L lml tatmns The mare ~eaknesses of \Vo~dNet 
c~ted m the hte~ature ale 
1 The lack oi connections between oun and verb 
hmrarctnes 
2 Limited number of connectmns between topi- 
cally related words 
3 The lack of morpholog!cat relations 
4 The absence of thema61c relatmns/ selectmnal 
restnctmns 
5 Some concepts (word senses) and relatmns are 
mmsmg " 
6 Since glosses were written manually, sometimes 
the2e m a lack of umform~ty and consmtency 2n 
the defimtmns 
The key idea m our project is to put to wo, k 
the rich sourse of mformauon contained m glosses 
that now can be used only by humans to Iead 
the deflmtmn of synsets For example, Wo, d- 
Net 1 6 hsts the concept {cat, t rue cat)  with 
the gloss (fellne mammal usually havlng thlck 
soft fur and belng unable to roar, 
domestxc cats, wxldcats) Currently, from a 
concept like thin, only a few other concepts could be 
reached In Extended Wo2dNet, the concept {cat, 
true cat} will be ,elated to 215othel concepts (I0 
from its own gloss, 38 flom the glosses of its hyper- 
n>ms, 25 concepts that use ~t m the*r glosses as a 
defining concept plus other 142 concepts with which 
the concept mteracts in these 25 glosses) Thin level 
of mformatmn ,s rich enough to presume that the 
Extended WordNet will work well as a knowledge 
base for common-sense r asoning 
2 Re la ted  work  
Machine Readable DmUonanes (MRDs) have long 
been ,ecogmzed as ~aluable resources m computa- 
uonal hngmstlcs In their paper, Ide and Veto- 
ms (Ide and Veloms, 1993) plojected a rather pes- 
~lmmuc outlook for the uuhty of MRDs as knowl- 
edge sources, a view that has impeded the enthus2- 
asm of some researchers (Wfiks et al1996) make a 
strong argument m favor of using MRDs and shine 
thel, posluve experience w~th using some dlcuonar- 
ms The MmdNet project at Mmrosoft alms at fully 
automatmg the development of a vel} large lexl- 
cal knowledge base using t~o MRDs the Long- 
man DicUonary of ContemporaD Enghsh (LDOCE) 
and the American Heritage Third EdlUon (AHD3) 
Man:y techmcal aspects of thin project are rooted m 
the works of Vanderwende (Vanderwende 1996) and 
Richardson (R2chardson 1997) 
3 Word  sense  d i sambiguat ion  o f  
g loss  concepts  
There are se~e, al dlffe~ences bet~een gloss dlsam- 
blguauon and text dlsamb~guatmn A n-la\]oi differ- 
ence is that m our project we know the meaning of 
each gloss, namely the synset o whmh a gloss ap- 
phes Second, the glosses contain a defimUon, com- 
ments, and one or more examples 
We address the word sense dmamblguaUon prob- 
lem by using three complementary methods (a) 
heunstms, (b) conceptual dens,ty, and (c) staus- 
tins on large corpora The first two methods rely 
enurely on the mfolmaUon contained m WordNet, 
while the th,rd one uses other corpora Specffically, 
the sources of knowledge available to us me (1) lex- 
lcal mformauon that includes part of speech, posl- 
uon of ~ords (1 e head word), and lexmal elauons 
(2) collocauons and s)ntacuc patterns, (3) s}nset 
to which a gloss belongs, (4) hypernyms of s)nset 
and their glosses (5) synsets of pobsemouns x~o2ds 
and their glosses, (6) hypernyms of synsets of poly- 
semous words, and their glosses, and so on 
Method  1 Classes of heur,st,cs for word 
sense dmarnblguatmn 
A statable techmque for dmamblguatmg dmuonarms 
is to rely on heu!mucs able to cope with d~ffe2ent 
sources of mformauon Work m tins alea w~ doue 
by Ravin (Rax m 1990) in a similar project at IBM, 
(Klavans et al1990), and others We present no~ 
some of the heunsUcs used by us 
1. Class- Hypernyms 
A way of explaining a concept m to speclahze a more 
general concept (, e a hypernym) It m hkely that 
an explanatmn begins with a phrase whose head is 
one of ~ts hypernyms, and the features are expressed 
either as attributes m the same phrase o2 as phrases 
attached to the first phrase 
Example The gloss of synset {xntrusxon} is 
(entrance by force  or without permxsslon or 
welcome) 
? entrance#3,  the head of the fiist phrase, is a 
hype~n)m of zntruszon, thus we pick sense 3 of 
noun entrance (The senses in Wo2dNet a2e ,anked 
acco, dmg to then frequency ot occmrence m the 
Brown corpus, ent rance#3 means sense 3 of wo, d 
entrance ) 
2 Class Lmgmst lc  Paral lehsm 
It 2s hkel? that the s} ntacuc pal allehsm of t~ o xx ord~ 
uanslates into semantic parallelmm and the ~xo2ds 
may have a common hypernym, or one m a hyper- 
nym of the other Fo~ adjectives, the hypein) m) is 
replaced by the similarity relation Other heuristics 
in this class check ~hether or not two pol)semous 
words belong to the same synset, or one is a hy- 
pern} m of the other, or if they belong to the same 
the2 arch:y 
Example The gloss of { interact ion} is (a 
mutual or. reczprocal actlon) 
? Adjective rec iproca l  has only one sense ,n Word- 
Net 1 6, whereas mutua l  has two senses But we 
find that between sense 2 of mutua l  and rec iproca l  
there is a szmdar l ink m WordNet 1 6, thus pick 
mutual#2 
3. Class. Gloss Comments .  
In glosses, comments and examples are meant to 
provide supplemental information It ts possible to 
find the specmhzatlon o, typical relation hnkmg the 
comment o the preceding head phrase m one of the 
synsets (or gloss) of the head phrase 
E~ample The gloss of the synset {scuf f ,  
scuffing} IS (the act of scufflng (scraplng 
or dragging the feet)) 
? In %?ordNet 1 6 there is a synset {scuff#l, drag}, 
thus verb scuff Is dlsamblguated 
4 Class. Gloss Examples  
Examples in WordNet prov,de collocatmnal reforma- 
tion of the words m synsets The intrinsic semanuc 
tag of the word from the synset which is used in 
the example can occur in the same lexical relation 
in some other gloss, carrymg the semantic tag w,th 
~t 
Example Synset {penet ra t ion}  has the gloss 
(the act of forcing a way Into something) 
? \[wlrw2\] ---- \[force way\] The gloss of {way#9} 
contains the example (2 'I had xt my way' '), pro- 
vldmg the lexlcal relation \[w3rw2\] = \[have way\] 
? Noun way is dxsamblguated (sense 9), and verbs 
have#7 and fo rce#9 have a common hypernym, 
therefore verb fo rce  ~s also dlsambiguated 
5 C lass  Co l locat ions  
Nouns representing actions ate nommahzatmns of
some verbs If a verbal collocation contains a noun, 
and is also a s~ nonym of some mo, phologmally re- 
lated verb, then ,t is likely to be the nommahza- 
tlon source The verb from the gloss of a synonym 
describing an actmn, ff not the source of the noml- 
nahzaUon is hkely to belong to the same hmtarchy 
as the true nommahzatlon source, since they must 
share some properties 
Ezample Let s = {escape ,  f l ight} ,  with the 
gloss ( the ac t  of escap ing  phys ica l ly )  
? The ~erb escape Is morphological ly identical to 
the noun escape  from synset s 
? Sense 1 of verb escape  has a hypernym collocation 
usmg noun f lxght  from s, thus is selected 
6 C lass  Lex~cal Re la t ,ons  
%. lexlcal relatmn using a ~ ord w both in the gloss of 
a s} nsct s and m some other gloss s~gnals a prope~D, 
of w associated u~th s In other cases x~hen ~wo ie- 
latmns \[w,r w~\] and \[w,~ w~.\] are ~ound m txvo glosses 
of %%bldNet, and the~e are senses of w~ and w~ that 
have a common hypernym, it is hkely that the cor- 
relatmn between w, and the common hypeInym is 
projected m both collocatlons 
Example The gloss of the synset {Underground 
Rallroad} Is (abolltlonlsts secret al to 
escaping slaves) 
? We have \[wlrw2\] - \[ald to slave\] 
? The gloss of {ald#4} is (ald to someone) 
? The pronoun someone can tefel to {slave#l} 
thus sense 4 of noun ald IS picked 
Method  2 Conceptual  dens,ty method  
We have ,mplemented a WSD system for free text 
that disamb,guates multiple wolds mmultaneousl3 
(Mlhalcea and Moldovan, 1999) The method is 
based on measuring the number of common nouns 
shared by the verb and noun hmrarchms, and thus 
gets around the lack of connections problem As 
an example, consider a verb - noun pair of uotds 
Denote w~th < vl,v2, ,Vh > and < nl,n2, ,nt > 
the senses of the verb and the noun m WoidNet Fo~ 
each possible pelt v, - n j ,  the conceptual density m 
computed as follows 
1 Extract  all the glosses from the sub-hmrmch~ 
of v, and determine the nouns from these glosses 
This constitutes the noun-context of verb v, Each 
such noun is stored together with a weight w that 
indicates the level m the sub-hmrarchy of the velb 
concept m whose gloss the noun was found 
2 Determine the glosses of the noun sub-hmtatchy 
of nj and determine the nouns m them 
3 Compute the conceptual denszty C u of the com- 
mon concepts between the nouns obtained at (1) and 
the nouns obtained at (2) using the metl lc 
Icd,j I 
& 
C~3 = lo9(descendentsj) (1) 
where 
? \[~d,~l is the number of common concepts be- 
tween the tnelarch,es of v~ attd nj 
? w~ are the levels of the nouus m the lueiaich~ 
of verb v, 
? descendentsj *s the total number of uotd~ 
w,thm the hmra, chy of noun nj 
4 C u tanks each pa,r v, - nj ,  fol all ~ and j Van- 
ants of th,s method work for other parts of speech 
pairs such as noun-noun, noun-verb, verb-verb, 
verb-noun, adje.cUve-noun and verb-adverb Th,s 
,s a powerful method that v, orks surprisingly x~ell 
even for free text We ha~e tested the method on 
SemCor, the pint of the Brown coipus tagged x~ltlt 
WotdNet seltses \V,th tlns technique it is possible 
to ,ank the senses and \[o keep not only the h~st 
lanked sense, but the second ol th,td ~anked senses 
3 
especmlly when the tankmg is sufficiently close and 
there ~s another wa~ to check the vahd,ty of the d~s- 
amb~guaUon 
Method  3 Statistics on large corpora  
As a last resort, we can use a staustmal approach 
to d,samblguate hose words that can not be done 
with any of the methods described so fal Consider 
a collocating word-word pmr wl - w2 m whmh we 
conslde, that Wl has been dtsambtguated already 
The dlsambtguatmn of w2 proceeds as follows 
(1) Foi each sense w~, form a slmdanty hst with 
w) and all other words that may be m that synset 
{w.~, w', (1) " ,(2)~ ' _ , w 2 ) } 
(2) Form pans of wz and all the %xords m each 
~Izmlarzty hst foI all z 
(3) Search a lalge empus for the occurrences o\[ any 
of the pans m the hst above 
,. , KI). . K2)~,, { wtw~" OR ~1~ OR wzw 2 ) } 
We have searched the Internet using the AltaV~sta 
search engine The number of hits for each similarity 
hst measmes the ,elatedness of w~ wtth each sense 
w~ and thus provtdes a ranking of the senses 
Overal l  P rocedure  and Resu l ts  
The followmg procedure was used to dlsamb~guate 
12,762 words from 1000 randomly selected glosses 
Step 1 Identify and separate the monosemous 
words - that have only one sense m WordNet (m 
out experiment 6468 words were found) 
Step 2 Apply Method 1 - HeurlsUcs - to the re- 
roaming 6294 polysemous words Method 1 provides 
correct d~samblguatmn for 5475 words, thus an ac- 
cmac~ of 87% Out of the remammg 13% of the 
words, 3% were dlsamb~guated erroneously and 10% 
could not be done with the heuristics used The 
correct sense for each word was determined manu- 
ally by a team of three students We ha~e found a 
fe~ s) n~ets uch as {commemorate, r member} that 
have no hnks to an~ other synsets, m no h3 pern3 ms 
and no hypom}ms 
Step 3 Apply Method 2 - Conceptual Denszty - to 
the 6294 polysemous words, staitmg hesh 
Step 4 Apply Method 3 - StaUstlcs - to the 6294 
words using Alta?~sta on the Internet 
Step 5 The results obtained wtth Method 1 and 
Method 2 are combined, that is, take all the wo, ds 
that were d~sambzguated, and m the case of conflict 
g~ve prmnty to Method 1 
Step 6 The results from Step 5 are combmed wtth 
the results g~ven by Method 3 and m the case of 
conflmt gtve priority to results obtained m Step 5 
Table 1 indicates the accuracy obtamed at each 
step An overall accmacy of 94% x~as achmved Out 
goal ,s to improve the techmque to be able to dls- 
amb~guate all words automatmally 
These results must be seen agamst the background 
average rate of 59 39% correct sense asstgnment 
achmved when the first WordNet sense is assigned to 
each polysemous word This is considered the base- 
hne performance l vel for word-sense dlsamblguat,on 
programs (Gale et al1992) and is consistent ~uth out 
own measurements 
4 Log ica l  fo rm t rans format ion  
Our extenszon of WordNet Intends to serve as a 
lexlco-semantic Iesource for a variety of NLP ap- 
phcations, many of them requiring pragmauc and 
common-sense knowledge (Harabagm and Moldovan 
1998) It is beneficial to transform the conceptual 
glosses m logical foimulae 
Approach  to implement Logical Form Trans- 
format ,ons (LFTs) 
(1) Traditional lexmographm principles deteIImne 
the d,scnmmatlon ofany conceptual defimtlons into 
a genus and the dzfferentza Our LFTs Implement 
the same dlstlncUon by always plaong the genus 
predicate on the first position of the LFT, and the 
rest of the LFT viewed as the definition differentia 
(2) A predmate is generated for every noun, verb, 
adjective or adverb encountered In any gloss The 
name of the predicate is a concatenatmn of the mor- 
pheme's base form, the pat t-of-speech and the Word- 
Net semanuc sense, thus capturing the full lem- 
cal and semantm disamblguaUon For example, the 
LFT of the gloss of {student, pupzl, educatee} 
contains the predmates learner n#l,  enroll v#l  and 
educabonaIJnstJtutlon n#l  
(3) In the sprat of the Davidsoman tzeatment oi 
the acUon predicates, all verb predmates (as ~ell 
as the nommahzaUons zeptesentmg acuons, e~ents 
or states) haxe thlee arguments actlon/state/event- 
predlcate(e,,~\[,x~), where 
? e, zeptesents he eventuahty of the acUon state ot 
exent ~ stated b> the xetb to take place, 
? 3.~ ~epresents he syntactLc sub3ect of the acUon 
event ot state, and 
? ~ lepresents the syntactic object o~ the acuon 
event or state 
In the case when the subject or the object are present 
m the gloss, they share the correspondmg arguments 
wtth the actmn/state/event predmate For example, 
the LFT  of (a person who backs a polltlclan) 
the gloss of {supporter, protagonlst, 
champion, admlrer, booster, friend} zs 
LFT = \[person #l(:ci) ~z back v#l(el,xl,x2) & 
pohtloan n#2(x~) \] 
\[ I Method 1 Method 2 Method 3 (M1) U M2 \[ ((M1) U M2) U M3 
I (Step 2). (Step 3) (Step 4) (Step 5) \[ (Step 6) 
\[ Accuracy \[ 87 80 68 92 I 94 
Table 1 Summary of results m % for the d~samb~guatmn of 1000 glosses 
(4) The role of complements wmthm a phrase ~s 
rephcated m the LFTs Predicates generated from 
modffiers hare the same arguments w~th the predi- 
cates corresponding to the phrase heads Adjective 
p~ed~cates share the same argument as the predicate 
corresponding to the noun they modify An exem- 
phficatlon ~s the LFT of the gloss of {ar t~fact ,  
a r te fac t} ,  whmh maps (a man-made object)  into 
\[ object n~l(x~) ~ man-made a#l(x~)\] S~mllarly, 
the argument of adverbml predmate ~s the argument 
marking the eventuahty of the event/state/actmn 
they modify For example, the gloss of the verb 
synset {hare} is (run quickly) ,  producing the 
LFT = \[run(e~,:~,x~) & qu~ckly(e~)\] 
(5) Conflunctmns a~e transformed m predicates, 
whmh enable the aggregatmn of several predicates 
under the same syntactic role (e g subject, object or 
preposmonal object) By conventmn, conjunction- 
predmates have a variable number of arguments, 
since they cover a varmble number of predicates 
The first argument represents the "result" of the 
logmal operation induced by the conjunctmn (e g 
a logical and m the case of the and conjunctmn, or 
a loggcal or m the case of the or con\]unctmn) The 
rest of the a~guments mdmate the predicates covered 
by the conjunctmn, as they are a~guments of those 
predmates as well 
(6) We also generate p~edmates for every prepo- 
sition encountered ,n the gloss The prepos~tmn 
predicates always have two arguments the first ar- 
gument corresponding to the predicate of the head 
of the phrase to which prepos~tmnal phlase ~s at- 
tached, whereas the second argument corresponds 
to the prepos~tmnal object 
Sources of  mformatmn.  The ~mplementatlon f 
LFTs rehes on mformatmn provided b3 
(a) Lexmal and semantm d~samb~guatmn p~oduced 
m the p~eprocessmg and semantm d~samb~guatmn 
phases Th,s mformatmn contributes to the creatmn 
of predicate names 
(b) Phrasal parsing, enabl,ng the recogmtmn ofbasic 
and complex phrases Th~s determines all comple- 
ments to share the same predmate argument w~th 
the phrase head 
(c) Syntactm t~ansformatmn rules, d~scnmmatmg 
the syntactm subject and object of every verb (m 
nommahzatmn) based on the local syntactic ontext 
(d) Preposlt,onal attachment resolutmn, indicating 
the arguments of the prepos~tmn p~ed~cates 
Table 2 lllustiates the tlansfolmatlons fo~ the 
gloss of {tennis ,  lawn tennis} 
5 Semant ic  fo rm t rans format ion  
Many NLP problems lely on the recogmuon of 
the tyDcal exmo-semantm I elatlonshlps between hn- 
gulstm concepts The LFT codfficatlon meiely ac- 
knowledges the foUowmg syntax-based relatlonsh~ps 
(1) syntactic subjects, (2) s)ntactm objects (3) 
prepositional attachments (4) complex nominals 
and (5) adjecuval/adverblal adjuncts Semanuc m- 
terpretat,ons of utterances, as ~ell as d~scou~e p~o- 
cessmg require knowledge about he semantic or the- 
mat~c relatmnsh~ps between concepts The ~emant~c 
form trans.formatwns prov,de with constraint-based 
mappings of the syntax-based relatmns covered m 
the LFTs into binary thematic relatmns or semantLc 
relations (We dlstmgmsh between thematic ~ela- 
tmns such as agent, expenencer, etc, and semantic 
relatmns uch as a-kind-of, part-of, etc ) 
Approach to ~mplement Semant,c Form 
Trans formatmns  (SFTs) 
1 The syntactic sublect relations lecogmzed m the 
LFTs by the predmatlve formula 
subjeCt(xl )&:verb(e, ~ l, ~.~) can be mapped into a x a- 
Ilet:y of thematic relations The defimtlon of the 
thematm relations is enurely based on mfo~matmn 
internal to the WordNet database, explessed as con- 
straints Fol example, all the subjects of verbs that 
are hyponyms of the verb cause or have thts concept 
as the genus of then glosses are defined to represent 
the Iole of agents 
(2) The syntactzc obTect ~elatmns a~e tec- 
ogmzed m the LFTs b) the predmauve founula 
verb(em,xi,x2) & aoua(~2) The defimtmn of tim 
thematic relatmns m whmh syntactm objects can be 
mapped is expressed m terms of verb synsets The 
constraining verb synsets ~epresent the upper-most 
hypernyms of all verbs that (z) have syntactic ob- 
jects m the WordNet glosses and (~z) belong to the 
same hmrarchy or a~e defined by gloss gem from the 
same h~el arch:y 
(3) The preposztzonal predzcates ale tlansfolmed 
into thematm ol semantm relations When a IVo~d- 
Gloss (a game played w~th rackets by two or four players who hxt a ball back and forth over a net ~hat 
LFT 
SFT  
d~v~des  a tenn is  cour t )  
game n#2(x2) & play v~2(e~,z~,x2) & w~th(et,z3) & racket n~4(z3) & by(el,z~) & or(xl,Z3,z4) gz two n#l(z3) 
&: four n#1(x4) & player n~l(z~) &: hit v#l(e~,x~,z~) ~z ball n#l(zs) &: back_and_forth r@l(e~) & over(e2,~) & 
net n~5(z~) gz d~wde v#5(e3,x~,z,z) ,~ tenms_court n~l(xT) 
gloss(tenms n~l,game n#2) object(game n#2,play v~2) agen~(pla~er n#l,play v#2) 
attribute(or(two n~l,four n#l),player n#l)  agent(player n#l,h~t v~l)  object(ball n#l,h~t v#l) 
locatmn(net n#5,h,t v#l)  agent(net n#5,d,wde v#5) object(tenms_court n#l,d~v,de v#5) 
Table 2 T~ans~rmatlons a sociated with the gloss of synset {tennxs, lawn tennxs} (a game played 
wxth rackets by two or four players who h~t a bal l  back and forth over a net that d~v~des 
a tennis court) 
Net semantm relauon holds between the arguments 
of a pteposmonal p~edmate, that specffic ~elatmn 
becomes the semantic transformauon of the predi- 
cate Fol example, the PP attachment \[sacrament 
of penance\] derived from the gloss of {confession} 
indicates a semantic kind-o\[ relauon due to the 
fact that m WordNet penance is a hyponym of 
sacrament 
(4) The transformation of complex nominal pred- 
zcates into thematic or semanUc onstraints m done 
by first seeking a WordNet relatmn (or a combma- 
Uon of such relatmns) between the components of 
the predicate If such a (chain of) relation(s) m 
found, predicate nn is transformed into the domi- 
nant WordNet semantic relation Otherwise, the no 
predicate is transformed into a thematic relation 
(5) The Uansformatlon of ad3ectwal and adver- 
bzal adjuncts, lepresented m the LFTs as p~edmates 
sharing the same argument with the concepts they 
modify shall be connected to their modifiers through 
attribute lelauons 
6 Inc lude  more  der ivat iona l  
morpho logy  
Smce the oIgamzaUon of WordNet dlwdes the En- 
ghsh vocabulary into four sepmate domains-nouns, 
velbs, ad\]ecuves, and adverbs- closely related con- 
cepts are often entered in more than one of these 
domains Many (probably most) of these relatmns 
can be ~dentffied m terms of denvatlonal morphol- 
ogy, e ~, the noun executzon is derived from the 
verb execute and so is an example of a deverbal 
noun WordNet aleady contmns ome of th~s kind 
of denvatmnal morphology dead\]ecUval nouns are 
hnked to their root adjecuves ( length m derived 
\[tom long), deadjectival adverbs are hnked to then 
loot adjecu~es ( rap id ly  Is derived from rapid),  and 
some denommal ad\]ecUves are hnked to then ~oot 
nouns (ce l lu la r  m derived from ce l l )  
In o~del to mcrease the connecUwty of WordNet 
it would be desirable to include more such deIlva- 
Uonal morphology Fol example, denvauonal le- 
latmns betxxeen ouns and verbs should be palUc- 
ularly useful (Hull and Gomez 1996) both de= 
veIbal nouns (avowal from avow) and denommal 
verbs (sammarlze from summary) Such connecuons 
would facilitate the recogmtmn that the same idea 
can be expressed m different ways, e g,  that "He 
summarized the book" and "He gave a summary 
of the book" are effecUvel~ eqmvalent m mean- 
mg Sometimes these morphological relations can 
be picked up from glosses, as when {disagreement} 
is defined as (the speech act of dlsagreexng or 
arguing or d isput ing) ,  but these are generally re- 
garded as unmformaUve definitions, and the leveIse 
relation may not happen to occur 
Since many of the words ale polysemous, mox- 
phologmal relatmns should not link words, but 
synsets that have related meanings Fot exam- 
ple, {execute} meaning (to put to death) should 
be hnked to {execut ion} meaning (the act  of 
puttxng a condemned person to death),  
and {execute} meanmg (to carry out a task)  
should be hnked to {execution} meaning (the act  
of doing sometMng success fu l ly ) ,  etc And m 
cases where the concepts of the noun and verb a~e 
dlffeIent-e g,  {womanize} floin {woman}-no seman- 
Uc link ~ould need to be cleated 
References  
H Alsha~xl Analysm the dlcUonaly deflmuons In 
B Boguraev and T Bnscoe, editors, Compata- 
tzonal Lexzcography for Natural Language Process- 
rag, pages 153-170 Longman, London, 1989 
R Bruce and L Guthne Genus dlsamblguatmn a 
study m weighted preference In Proceedings of 
COLING92, COLING92, pp 1187-1191 
W Gale, K W Chinch and D Yarowsky Estimat- 
ing uppel and lowel bounds on the peflolmance 
of ~old-sense dmamblguaUon programs In Pro- 
ceed,ngs of the 30th Annual Meetzng of the A~so- 
cmtzon for Computatzonal Lmguzst~cs, New, ark , 
Delaware, 1992 
S M Harabagm and D I Moldovan A Parallel In- 
ierence System In IEEE Transactzon on Parallel 
and Dzstmbuted System, Aug 1998, pp 729-747 
R D Hull and F Gomez Semantm mterpretatlon 
of nommahzatlons In Proceedings of the 13th Na- 
tzonal Conference on Artzficzal Intelhgence AAAI- 
96, Portland, OR, 1996 
N Ide and J Veroms Extracting knowledge 
bases from machine-readable dictionaries have we 
wasted our t~me ~ In KB ~4 KS, Tokyo, Japan, 
Dec 1993 
J Klavans, M Chodorow amd N Wacholder From 
dmtlonaly to knowledge base via taxonomy In 
Electronzc Text Research, Umverslty of Waterloo, 
Cente~ for the New OED and Text Research, Wa- 
terloo, Canada, pages-110-132, 1990 
R Mlhalcea and D I Moldovan A Method for Word 
Sense Dlsamb~guatlon of Unrestrmted Text In 
Proceedings o/ the 37th Annual Meeting of the 
ACL, June 1999 
S Montemagm and L Vanderwende Structural Pat- 
terns vs stnng patterns for extracting semantic 
reformation from dictionaries In Proceedings of 
COLING92, COLING '92, pp 546-552 
Y Ravin Dlsamblguatmg and interpreting verb def- 
mltmns In Proceedings o/ the 28th Annual Meet- 
mg o/the Assoczatzon /or Computatwnal L~nguz~- 
tzcs, Pittsburgh, PA, pages 260-267, 1990 
S Rmhardson Determining slmfiar~ty and mferimg 
~elatmns m a lexmal knowledge base In PhD 
dzssertatwn, City Umverslty of New Yolk, 1997 
L Vander~ende The Analysis of Noun Sequences 
using Semantm Informatmn Extracted from On- 
Line Dlctmnarms In Ph D dzssertatzon, George 
\Vastungton Umverslty, Washington D C, 1996 
Y A Wllks, B M Slator, and L M Guthrm Elec- 
tric words d~ctlona~ms, computers and meamng 
In MIT Press, 1996 

