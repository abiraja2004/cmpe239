General ized Augmented  Transi t ion Network  Grammars  
For Generat ion From Semant ic  Networks  1 
Stuar t  C. Shap i ro  
Department of Computer Science 
State University of New York at Buffalo 
Amherst,  New York 14226 
The augmented transition network (ATN) is a formalism for writing parsing grammars 
that has been much used in Artificial Intelligence and Computational Linguistics. A few 
researchers have also used ATNs for writing grammars for generating sentences. Previous- 
ly, however, either generation ATNs did not have the same semantics as parsing ATNs, or 
they required an auxiliary mechanism to determine the syntactic structure of the sentence 
to be generated. This paper reports a generalization of the ATN formalism that allows 
ATN grammars to be written to parse labelled directed graphs. Specifically, an ATN 
grammar can be written to parse a semantic network and generate a surface string as its 
analysis. An example is given of a combined parsing-generating rammar that parses 
surface sentences, builds and queries a semantic network knowledge representation, and 
generates urface sentences in response. 
1. Introduction 
Augmented transition network (ATN) grammars 
have, since their development by Woods 1970,1973, 
become the most used method of describing grammars 
for natural language understanding and question an- 
swering systems. The advantages of the ATN notation 
have been summarized as "1) perspicuity, 2) genera- 
tive power, 3) eff iciency of representation, 4) the 
ability to capture linguistic regularities and generali- 
ties, and 5) efficiency of operat ion" \[Bates 1978, p. 
191\]. 
The usual method of utilizing an ATN grammar in 
a natural language system is to provide an interpreter 
that can take any ATN grammar, a lexicon, and a 
sentence-as data, and produce either a parse of a sen- 
tence or a message that the sentence does not conform 
to the grammar. The input sentence is assumed to be 
a linear sequence of symbols, while the parse is usually 
a tree (often represented by a LISP S-expression) or 
some "knowledge representation" such as a semantic 
network. Compilers have been written \[Burton 1976; 
Burton and Woods 1976\] that take an ATN grammar 
1 This paper is a revised and expanded version of one given 
at the 17th Annual Meeting of the Association for Computational 
Linguistics. The work reported here was supported in part by the 
National Science Foundation under Grants MCS78-02274 and 
MCS80-06314. 
as input and produce a specialized parser for that 
grammar, but in this paper we assume that an inter- 
preter is being used. 
Several methods have been described for using 
ATN grammars for sentence generation. One method 
\[Bates 1978, p. 235\] is to replace the usual interpreter 
by a generation interpreter that can take an ATN 
grammar written for parsing and use it to produce 
random sentences conforming to the grammar. This is 
useful for testing and debugging the grammar. 
Simmons 1973 uses a standard ATN interpreter to 
generate sentences from a semantic network. In this 
method, an ATN register is initialized to hold a node 
of the semantic network and the input to the grammar 
is a linear string of symbols providing a pattern of the 
sentence to be generated. For example, the input 
string might be (CA1-LOCUS VACT THEME) ,  
where CA1-LOCUS and THEME are labels of arcs 
emanating from the semantic node, and VACT stands 
for "act ive verb."  This pattern means that the sen- 
tence to be generated is to begin with a string denot- 
ing the CA1-LOCUS,  then have the active form of the 
verb, and end with a string denoting the THEME.  
The method also assumes that semantic nodes have 
such syntactic information stored with them as number 
and definiteness of nominals, and tense, aspect, mood, 
and voice of propositions. 
Copyright 1982 by the Association for Computational Linguistics. Permission to copy without fee all or part of this material is granted 
provided that the copies are not made for direct commercial advantage and the Journal reference and this copyright notice are included on 
the first page. To copy otherwise, or to republish, requires a fee and/or  specific permission. 
0362-613X/82/010012-14501.00 
12 American Journal of Computational Linguistics, Volume 8, Number 1, January-March 1982 
Stuart C. Shapiro Generalized Augmented Transition Network Grammars 
Shapiro 1979 also generates entences from a se- 
mantic network. In this method, input to the grammar 
is the semantic network itself (starting at some node). 
That is, instead of successive symbols of a linear sen- 
tence pattern being scanned as the ATN grammar is 
traversed by the interpreter, different nodes of the 
semantic network are scanned. The grammar controls 
the syntax of the generated sentence, but bases specif- 
ic decisions on the structural properties of the seman- 
tic network and on the information contained therein. 
The original goal in Shapiro 1975 was that a single 
ATN interpreter could be used both for standard ATN 
parsing and for generation. However, a special inter- 
preter was written for generation grammars; indeed, 
the semantics of the ATN formalism given in that 
paper, though based on the standard ATN formalism, 
were inconsistent enough with the standard notation 
that a single interpreter could not be used. For exam- 
ple, standard ATNs use a register named "*"  to hold 
the input symbol (word) currently being scanned. Un- 
like other registers, whose values are set explicitly by 
actions on the ATN arcs, the * register is manipulated 
directly by the ATN interpreter. In Shapiro 1975 the * 
register was used to hold the string being generated 
rather than the input symbol being scanned. The in- 
terpreter written for Shapiro 1975 also manipulated 
the * register directly, but in a manner inconsistent 
with standard ATN interpreters. 
This paper reports the results of work carried out 
to remove the inconsistencies mentioned above. A 
generalization of the ATN formalism has now been 
derived that supplies consistent semantics (and so 
allows a single interpreter to be used) for both parsing 
and generating rammars. In fact, one grammar can 
include both parsing and generating sub-networks that 
can call each other. For example, an ATN grammar 
can be constructed so that the "parse"  of a natural 
language question is the natural language statement 
that answers it, interaction with representat ion and 
inference routines being done on arcs along the way. 
The new formalism is a strict generalization in the 
sense that it interprets all old ATN grammars as hav- 
ing the same semantics (carrying out the same actions 
and producing the same parses) as before. 
The generalized ATN formalism can be used to 
write grammars for parsing labelled directed graphs. 
In this paper, however, we only discuss its use in pars- 
ing two particular kinds of labelled di-graphs. One is 
the kind that is generally called a semantic network. 
We consider parsing a semantic network, as viewed 
from some node, into a particular linear symbol struc- 
ture that constitutes a surface string of English. The 
other kind of labelled di-graph is a linear graph all of 
whose arcs have the same label and whose nodes are 
successive words in a surface sentence. This kind of 
di-graph is so special that a subset of the generalized 
ATN formalism, namely the original formalism, has 
built-in facilities for traversing its arcs. 
Since many people have implemented their own 
ATN interpreters, this paper is written to describe the 
extension to be made to any ATN interpreter to allow 
it to interpret generation grammars as well as parsing 
grammars. A key ingredient in such an extension is a 
systematic treatment of the input buffer and the * 
register. This is explained in Section 4, which is essen- 
tially a description of a set of program assertions for 
ATN interpreters. 
2. Generat ion  f rom a Semant ic  Network  - Br ief  Over-  
v iew 
In our view, each node of a semantic network rep- 
resents a concept. The goal of the generator is, given 
a node, to express the concept represented by that 
node in a natural language surface string. The syntac- 
tic category of the surface string is determined by the 
grammar, which can analyze the structure of the se- 
mantic network connected to the node. In order to 
express the concept, it is often necessary to include in 
the string substrings that express the concepts repre- 
sented by adjacent nodes. For example, if a node 
represents a proposit ion to be expressed as a state- 
ment, part of the statement may be a noun phrase 
expressing the concept represented by the node con- 
nected to the original node by an AGENT case arc. 
This can be done by a recursive call to a section of the 
grammar in charge of building noun phrases. This 
section will be passed the adjacent node. When it 
finishes, the original statement section of the grammar 
will continue adding additional substrings to the grow- 
ing statement. 
In ATN grammars written for parsing, a recursive 
push does not change the input symbol being exam- 
ined, but when the original level continues, parsing 
normally continues at a different symbol. In the gen- 
eration approach we use, a recursive push normally 
involves a change in the semantic node being exam- 
ined, and the original level continues with the original 
node. This difference is a major motivation of some 
of the generalizations to the ATN formalism discussed 
below. The other major motivation is that, in parsing 
a string of symbols, the "next"  symbol is defined by 
the system, but in "parsing" a network, "next"  must 
be specified in the grammar. 
3. The  Genera l i zat ion  
The following sub-sections how the generalized 
syntax of the ATN formalism, and assume a knowl- 
edge of the standard formalism (Bates 1978 is an ex- 
cellent introduction). Syntactic structures already 
familiar to ATN users but not discussed here remain 
unchanged. Parentheses and terms in upper case let- 
ters are terminal symbols. Lower case terms in angle 
American Journal of Computational Linguistics, Volume 8, Number 1, January-March 1982 13 
Stuart  C. Shapiro Generalized Augmented Transition Network Grammars 
brackets are non-terminals. Terms enclosed in square 
brackets are optional. Terms followed by "..." may 
occur zero or more times in succession. 
3.1 Termina l  Act ions  
Successful traversal of an ATN arc might or might 
not consume an input symbol. When parsing, such 
consumption ormally occurs; when generating it nor- 
mally does not, but if it does, the next symbol 
(semantic node) must be specified. To allow for these 
choices, we have returned to the technique of Woods 
1970 of having two terminal actions, TO and JUMP, 
and have added an optional second argument o TO. 
The syntax is: 
(TO <state> \[<form>\]) 
(JUMP <state>) 
Both cause the parser to enter the given state. JUMP 
never consumes the input symbol; TO always does. If 
the <form> is absent in the TO action, the next sym- 
bol to be scanned will be the next one in the input 
buffer. If < form> is present, its value will be the 
next symbol to be scanned. All traditional ATN arcs 
except JUMP and POP end with a terminal action. 
The explanation given in Burton 1976 for the re- 
placement of the JUMP terminal action by the JUMP 
arc was that, "since POP, PUSH and VIR arcs never 
advance the input, to decide whether or not an arc 
advanced the input required knowledge of both the arc 
type and termination action. The introduction of the 
JUMP arc ... means that the input advancement is a 
function of the arc type alone." That our reintroduc- 
tion of the JUMP terminal action does not bring back 
the confusion is explained in Section 4. 
3.2 Arcs 
We retain a JUMP arc as well as a JUMP terminal 
action. The JUMP arc provides a place to make an 
arbitrary test and perform some actions without con- 
suming an input symbol. For symmetry, we introduce 
a TO arc: 
(TO (<state> \[<form>\]) <test> 
<action>.. .  ) 
If <test> is successful, the <act ion>s are performed 
and transfer is made to <state>. The input symbol is 
consumed. The next symbol to be scanned is the val- 
ue of <form> if it is present, or the next symbol in 
the input buffer if <form> is missing. 
Neither the JUMP arc nor the TO arc are really 
required if the TST arc is retained (Bates 1978, how- 
ever, does not mention it), since they are equivalent to 
the TST arc with the JUMP or TO terminal action, 
respectively. However, they require less typing and 
provide clearer documentation. They are used in the 
example in Section 6. 
The PUSH arc makes two assumptions: 1) the first 
symbol to be scanned in the subnetwork is the current 
contents of the * register; 2) the current input symbol 
will be consumed by the subnetwork, so the contents 
of * can be replaced by the value returned by the sub- 
network. We need an arc that causes a recursive call 
to a subnetwork, but makes neither of these two as- 
sumptions, so we introduce the CALL  arc: 
(CALL <state> <form> <test> 
<preact ion or act ion>.. .  
<register> <act ion>.. .  
<terminal  act ion> ) 
where <preact ion or act ion> is <preact ion> or 
<act ion>.  If the <test> is successful, all the 
<act ion>s of <preact ion or act ion> are performed 
and a recursive push is made to the state <state> 
where the next symbol to be scanned is the value of 
<form> and registers are initialized by the 
<preact ion>s. If the subnetwork succeeds, its value is 
placed into <register> and the <act ion>s and 
<terminal action> are performed. 
Just as the normal TO terminal action is the gener- 
alized TO terminal action without the optional form, 
the PUSH arc (which we retain) is equivalent o the 
following CALL arc: 
(CALL <state> * <test> <preact ion>.. .  
? <act ion>.. .  <terminal  act ion> ) 
3.3 Forms 
The generalized TO terminal action, the generalized 
TO arc, and the CALL  arc all include a form whose 
value is to be the next symbol to be scanned. If this 
next symbol is a semantic network node, the primary 
way of identifying it is as the node at the end of a 
directed arc with a given label from a given node. This 
identification mechanism requires a new form: 
(GETA <arc> \[<node form>\]) 
where <node form> is a form that evaluates to a se- 
mantic node. If absent, <node form> defaults to * 
The value of GETA is the node at the end of the arc 
labelled <arc> from the specified node, or a list of 
such nodes if there are more than one. 
3.4 Tests,  Preact ions,  and Act ions  
The generalization of the ATN formalism to one 
that allows for writing grammars which generate sur- 
face strings from semantic networks, yet can be inter- 
preted by the same interpreter which handles parsing 
grammars, requires no changes other than the ones 
described above. Specifically, no new tests, preac- 
tions, or actions are required. Of course each imple- 
mentation of an ATN interpreter contains slight differ- 
ences in the set of tests and actions implemented be- 
yond the basic ones. 
14 Amer ican Journal  of Computational Linguistics, Volume 8, Number  1, January-March 1982 
Stuart  C. Shapiro Generalized Augmented Transition Network Grammars 
4. The Input Buffer 
Input to the ATN parser can be thought of as being 
the contents of a stack, called the input buffer. If the 
input is a string of words, the first word will be at the 
top of the input buffer and successive words will be in 
successively deeper positions of the input buffer. If 
the input is a graph, the input buffer might contain 
only a single node of the graph. 
Adequate treatment of the * register is crucial for 
the correct operation of a grammar interpreter that 
does both parsing and generation. This is dealt with in 
the present section. 
On entering an arc, the * register is set to the top 
element of the input buffer, which must not be empty. 
The only exceptions to this are the CAT, VIR, and 
POP arcs. On a CAT arc, * is the root form of the 
top element of the input buffer. (Since the CAT arc is 
treated as a "bundle" of arcs, one for each sense of 
the word being scanned, and is the only arc so treated, 
it is the only arc on which (GETF <feature> *) is 
guaranteed to be well-defined.) VIR sets * to an ele- 
ment of the HOLD register. POP leaves * undefined 
since * is always the element o be accounted for by 
the current arc, and a POP arc is not trying to account 
for any element. The input buffer is not changed be- 
tween the time a PUSH arc is entered and the time an 
arc emanating from the state pushed to is entered, so 
the contents of * on the latter arc will be the same as 
on the former. A CALL arc is allowed to specify the 
contents of * on the arcs of the called state. This is 
accomplished by replacing the top element of the input 
buffer by that value before transfer to the called state. 
If the value is a list of elements, we push each element 
individually onto the input buffer. This makes it par- 
ticularly easy to loop through a set of nodes, each of 
which will contribute the same syntactic form to the 
growing sentence (such as a string of adjectives). 
While on an arc (except for POP), i.e. during eval- 
uation of the test and the acts, the contents of * and 
the top element of the input buffer remain the same. 
This requires special processing for VIR, PUSH, and 
CALL arcs. Since a VIR arc gets the value of * from 
HOLD, rather than from the input buffer, after setting 
? the VIR arc pushes the contents of * onto the input 
buffer. The net effect is to replace the held constitu- 
ent in a new position in the string. When a PUSH arc 
resumes, and the lower level has successfully returned 
a value, the value is placed into * and also pushed 
onto the input buffer. The net effect of this is to re- 
place a sub-string by its analysis. When a CALL re- 
sumes, and the lower level has successfully returned a 
value, the value is placed into the specified register, 
and the contents of * is pushed onto the input buffer. 
(Recall that it was replaced before the transfer. See 
the previous paragraph.) The specified register might 
or might not be *. In either case the contents of * and 
the top of the input buffer are the same. 
There are two possible terminal acts, JUMP and 
TO. JUMP does not affect the input buffer, so the 
contents of * will be the same on the successor arcs 
(except for POP and VIR) as at the end of the current 
arc. TO pops the input buffer, but if provided with an 
optional form, also pushes the value of that form onto 
the input buffer. 
POPping from the top level is only legal if the in- 
put buffer is empty. POPping from any level should 
mean that a constituent has been accounted for. Ac- 
counting for a constituent should entail removing it 
from the input buffer. From this we conclude that 
every path within a level from an initial state to a POP 
arc must contain at least one TO transfer, and in most 
cases, it is proper to transfer TO rather than to JUMP 
to a state that has a POP arc emanating from it. TO 
will be the terminal act for most VIR and PUSH arcs. 
In any ATN interpreter having the operational 
characteristics given in this section, advancement of 
the input is a function of the terminal action alone, in 
the sense that, at any state JUMPed to, the top of the 
input buffer will be the last value of *, and, at any 
state jumped TO, it will not be. 
5. The Lexicon 
Parsing and generating require a lexicon - a file of 
words giving their syntactic ategories and lexical fea- 
tures, as well as the inflectional forms of irregularly 
inflected words. Parsing and generating require differ- 
ent information, yet we wish to avoid duplication as 
much as possible. This section discusses how a lexicon 
might be organized when it is to be used both for 
parsing and for generation. Figure 1 shows the lexi- 
con used for the example in Section 6. 
During parsing, morphological analysis is per- 
formed. The analyzer is given an inflected form and 
must segment it, find the root in the lexicon, and mod- 
ify the lexical entry of the root according to its analy- 
sis of the original form. Irregularly inflected forms, 
such as "seen" in Figure 1, must have their own en- 
tries in the lexicon. An entry in the lexicon may be 
lexically ambiguous, such as "saw" in Figure 1, so 
each entry must be associated with a list of one or 
more lexical feature lists. Each such list, whether 
stored in the lexicon or constructed by the morpholog- 
ical analyzer, must include a syntactic category and a 
root, as well as other features needed by the grammar. 
The lexical routines we use supply certain default fea- 
tures if they are not supplied explicitly. These are as 
follows: the root is the lexeme itself; nouns have 
(NUM.  SING); verbs have (TENSE . PRES). In 
Figure 1, BE and DOG get default features, while the 
entries for SAW override several of them. 
American Journal of Computational Linguistics, Volume 8, Number 1, January-March 1982 15 
Stuart  C. Shapiro Generalized Augmented Transition Network Grammars 
(A 
(BE 
(DOG 
(IS 
LUCY 
SAW 
SAWI  
SEE  
SEEN 
SWEET 
(WAS 
(YOUNG 
CTGY 
CTGY 
CTGY 
CTGY 
CTGY 
CTGY 
CTGY 
CTGY 
CTGY 
CTGY 
CTGY 
CTGY 
CTGY 
DET 
v)) 
N)) 
v) 
NPR 
N) 
V) 
N) 
V) 
V) 
im J  
v) 
ADJ  
)) 
ROOT . BE) 
)) 
ROOT . SAWI ) )  
ROOT . SEE)  (TENSE . PAST)  
ROOT . SAW)) )  
PAST  . SAW) (PASTP  . SEEN)  
ROOT . SEE)  (TENSE . PASTP  
)) 
ROOT . BE) 
)) 
(NUM.  S ING)  (TENSE . PRES) ) )  
) 
) 
(PPRT . T))) 
(NUM.  SING) (TENSE . PAST))) 
Figure 1. Example Lexicon. 
In the semantic network, some nodes are associated 
with lexical entries. In Figure 3, nodes SWEET, 
YOUNG,  LUCY,  BE, SEE, and SAWl are. During 
generation, these entries, along with other information 
from the semantic network, are used by a morphologi- 
cal synthesizer to construct an inflected word. We 
assume that all such entries are unambiguous roots, 
and so contain only a single lexical feature list. This 
feature list must contain any irregularly inflected 
forms. For example, the feature list for "see"  in Fig- 
ure 1 lists "saw" as its past tense and "seen"  as its 
past participle. SAW1 represents the unambiguous 
sense of "saw" as a noun. It is used in that way in 
Figure 3. In Figure 1, SAW1 is given as the ROOT of 
the noun sense of SAW, but for purposes of morpho- 
logical synthesis, the ROOT of SAW1 is given as 
SAW. 
In summary, a single lexicon may be used for both 
parsing and generating under the following conditions. 
The entry of an unambiguous root can be used for 
both parsing and generating if its one lexical feature 
list contains features required for both operations. An 
ambiguous lexical entry (such as SAW) will only be 
used during parsing. Each of its lexical feature lists 
must contain a unique but arbitrary " root"  (SEE and 
SAW1) for connection to the semantic network and 
for holding the lexical information required for genera- 
tion. Every lexical feature list used for generating 
must contain the proper natural language spelling of its 
root (SAW for SAW1) as well as any irregularly in- 
flected forms. Lexical entries for irregularly inflected 
forms will only be used during parsing. In the lexicon 
of Figure 1, the entries for A, DOG,  LUCY,  SEE, 
SWEET, and YOUNG are used during both parsing 
and generation. Those for BE, IS, SAW, SEEN, and 
WAS are only used during parsing. The entry for 
SAW1 is only used during generation. Our morpho- 
logical synthesizer ecognizes "be"  as a special case, 
and computes its inflected forms without referring to 
the lexicon. 
For the purposes of this paper, it should be irrele- 
vant whether the " root"  connected to the semantic 
network is an actual surface word like "give",  a deep- 
er sememe such as that underlying both "g ive"  and 
" take" ,  or a primitive such as "ATRANS" .  
6. Example 
In this section, we discuss an example of natural 
language interaction (in a small fragment of English) 
using an ATN parsing-generating grammar and SNePS, 
the Semantic Network Processing System \[Shapiro 
1979\]. The purpose of the example is to demonstrate 
the use of the generalized ATN formalism for writing 
a parsing-generating grammar for which the "parse"  of 
an input sentence is a generated sentence response, 
using a knowledge representation and reasoning sys- 
tem as the sentence is processed. Both the fragment 
of English and the semantic network representat ion 
technique have been kept simple to avoid obscuring 
the use of the generalized ATN formalism. 
Figure 2 shows an example interaction using SNeP- 
SUL, the SNePS User Language. The numbers in the 
left margin are for reference in this section. The 
string "**"  is the SNePSUL prompt. The rest of each 
line so marked is the user's input. The following line 
is the result returned by SNePSUL. The last line of 
each interaction is the CPU time in milliseconds taken 
by the interaction. (The system is running as compiled 
LISP on a CDC CYBER 170/730. The ATN gram- 
mar is interpreted.) Figure 3 shows the semantic net- 
work built as a result of the sentences in Figure 2. 
The first interaction creates a new semantic net- 
work node, shown as B1 in Figure 3, to represent he 
instant of time "now".  The symbol "#"  represents a
SNePSUL function to create this node and make it the 
value of the variable NOW. From then on, the ex- 
16 Amer ican Journal  of Computational Linguistics, Volume 8, Number  1, January-March 1982 
Stuart C. Shapiro Generalized Augmented Transition Network Grammars 
(1) 
(2) 
(3) 
(4) 
** #NOW 
(BI) 
4 MSECS 
** (: YOUNG LUCY SAW A SAW) 
(I UNDERSTAND THAT YOUNG LUCY SAW A SAW) 
2481MSECS 
** (: WHO SAW A SAW) 
(YOUNG LUCY SAW A SAW) 
875 MSECS 
** (: LUCY IS SWEET)  
(I UNDERSTAND THAT YOUNG LUCY IS SWEET)  
397 MSECS 
** (: WHAT WAS SEEN BY LUCY) 
(A SAW WAS SEEN BY SWEET YOUNG LUCY) 
862 MSECS 
Figure 2. Example interaction. 
BEFORE 
ETM 
I 
BEFORE 
NOW 
I 
14 
x 
Figure 3. The semantic network built by the example interaction. 
pression *NOW evaluates to B1. We will see *NOW 
used on some arcs of the grammar. 
The rest of the user inputs are calls to the SNeP-  
SUL funct ion ":". This funct ion passes its argument 
list to the parser as the input buffer. The parser starts 
in state S. The form popped by the top level ATN 
grammar is returned as the value of the call to :, and is 
then printed as ment ioned above.  Thus, the line fol-  
lowing the call to : may be v iewed as the "parse"  of 
the sentence passed to :. 
American Journal of Computational Linguistics, Volume 8, Number 1, January-March 1982 17 
Stuart C. Shapiro Generalized Augmented Transition Network Grammars 
We will trace the first example sentence through 
the ATN grammar, referring to the other example 
sentences at various points. The parse starts in state S 
(Figure 4) with the input buffer being (YOUNG 
LUCY SAW A SAW). The one arc out of state S 
pushes to state SP, which is the beginning of a net- 
work that parses a sentence. The first arc out of state 
SP recognizes that inputs (2) and (4) are questions. 
In these cases the register TYPE is set to Q both on 
this level (by the SETR action) and on the top level 
(by the L IFTR action). The register SUBJ is also set 
to %X, which is a free variable in SNePSUL. In the 
cases of sentences (1) and (3), however, the second 
arc from SP is taken. This is a PUSH to the network 
beginning at state NPP, which will parse a noun 
phrase. Register TYPE is initialized to D (for 
"declarative") at the lower level by SENDR. When 
the noun phrase is parsed, the TYPE register is set to 
D at this and the top level, and the SUBJ register is 
set to the parse of the noun phrase. 
At state NPP (Figure 5) the JUMP arc is followed 
since the * register is YOUNG rather than A. At state 
NPDET, the CAT ADJ arc is followed and a semantic 
node representing the concept of YOUNG is put in 
the HOLD register for later use. The SNePSUL form 
(F INDORBUILD LEX (^(GETR *))) finds in the 
network a node with a LEX arc to YOUNG (the con- 
tents of the * register) or builds such a node if one 
does not exist, and returns that node as the value of 
the form. In this case, node M1 of Figure 3 is built 
and placed in HOLD. The parser then loops TO 
NPDET with the input buffer being (LUCY SAW A 
SAW). This time, the * register contains LUCY, so 
the fourth arc is followed. This time the SNePSUL 
form builds nodes M2, M3, and M4 of Figure 3, and 
places M4 in the register NH. Node M4 represents 
someone named LUCY. Node M3 represents the prop- 
osition that this person is named LUCY. Node M2 
represents the name LUCY. (When this arc is taken 
while parsing LUCY in sentences (3) and (4), these 
semantic nodes will be found.) The parser then trans- 
fers TO state NPA at which the modifying properties 
are removed from the HOLD register and asserted to 
hold of the concept stored in NH. In this case, there 
is only one property, and node M5 is built. Node M4, 
representing someone who is named LUCY and is 
YOUNG is popped to the PUSH arc emanating from 
state SP, and is placed in the SUBJ register as men- 
tioned earlier. The parser then transfers TO state V 
with an input buffer of (SAW A SAW). 
The CAT arc from state V (Figure 6) wants a word 
of category V. The first word in the input buffer is 
SAW, which is two-ways lexically ambiguous (see 
Figure 1), so we can think of the CAT arc as being 
two arcs, on one of which * contains the singular of 
the Noun SAW1, and on the other of which * contains 
the past tense of the Verb SEE. The second of these 
arcs can be followed, setting the register VB to node 
M6, and the register TNS to PAST. The parser than 
goes TO state COMPL with input buffer (A SAW). 
At COMPL, neither CAT arc can be followed, so the 
parser JUMPs to state SV. The first CAT arc is fol- 
lowed in sentence 4, while the second CAT arc is fol- 
lowed in sentence 3. 
At state SV (Figure 7), a semantic network tempo- 
ral structure is built for events. Each event is given a 
starting time and an ending time. Present tense is 
interpreted to mean that the present ime, the value of 
? NOW, is after the starting time and before the ending 
time. Past tense is interpreted to mean that the ending 
time is before *NOW. In this case, the tense is past, 
so the third arc is taken and builds nodes M7 and M8. 
M7 is made the SNePSUL value of *ETM, and M8 is 
placed in the ATN register STM. For simplicity in this 
example, the first arc ignores the tense of questions. 
Control then passes to state O. 
The first arc of state O (Figure 8) recognizes the 
beginning of a "by"  prepositional phrase in a passive 
sentence. This arc will be followed in the case of 
sentence 4 to the state PAG where the object of BY 
will replace the previous contents of the SUBJ register. 
In the case of sentence (1), the second arc will be 
taken, which is a PUSH to state NPP with input buff- 
er, (A SAW). 
(S ; Parse  a sentence  and generate  a response.  
(PUSH SP T (JUMP RESPOND)) )  
(SP ; Parse  a sentence.  
(WRD (WHO WHAT) 
; If it s tar ts  w i th  "Who" or "What",  i t 's a quest ion .  
T (SETR TYPE 'Q) (L IFTR TYPE) (SETR SUBJ  ZX) (TO V)) 
(PUSH NPP ; A s ta tement  s tar ts  w i th  a Noun Phrase  -- its sub ject .  
T (SENDR TYPE 'm) (SETR TYPE 'D) (L IFTR TYPE) (SETR SUBJ  *) 
(TO V))) 
Figure 4. ATN Grammar .  
18 American Journal of Computational Linguistics, Volume 8, Number 1, January-March 1982 
Stuart C. Shapiro Generalized Augmented Transition Network Grammars 
At state NPP (Figure 5), the first arc is taken, set- 
ting register INDEF to T, and transferring TO state 
NPDET with input buffer (SAW). The second arc is 
taken from NPDET interpreting SAW as a noun, the 
singular form of SAW1. A semantic node is found or 
built (in this case M9 is built) to represent the class of 
SAWls ,  M l l  is built to represent a new SAW1, and 
M10 is built to assert that M l l  is a SAW1. In the case 
of a question, such as sentence (2), the third arc finds 
all known SAWls  using the SNePSUL function DE- 
DUCE,  so that whatever can be inferred to be a 
SAW1 is found. In either case the SAWI(s)  are 
(NPP ; Parse a noun phrase. 
(WRD A T (SETR INDEF T) 
(JUMP NPDET T)) 
(TO NPDET 
(NPDET ; Parse a NP after the determiner.  
(CAT ADJ T ; Hold adject ives for later. 
(HOLD 'ADJ (FINDORBUILD LEX (A(GETR *)))) (TO NPDET)) 
(CAT N (AND (GETR INDEF) (EQ (GETR TYPE) 'D)) 
; "a N" means some member of the class Noun, 
(SETR NH ; but not necessar i ly  any one already known. 
(BUILD MEMBER- 
(BUILD CLASS (FINDORBUILD LEX (A(GETR *)))))) 
(TO mPi)) 
(CAT m (AND (GETR INDEE) (EQ (GETR TYPE) 'Q)) 
; "a N" in a quest ion refers to an a lready known Noun. 
(SETR NH 
(FIND MEMBER- 
(DEDUCE MEMBER ZY CLASS (TBUILD LEX (A(GETR *)))))) 
(TO NPA)) 
(CAT NPR T ; A proper noun is someone's name. 
(SETR NH (FINDORBUILD NAMED- 
(FINDORBUILD NAME (FINDORBUILD LEX (A(GETR *)))))) 
(TO NPA)) 
(NPA ; Remove all held adject ives and bui ld WHICH-ADJ  proposit ions.  
(VIR ADJ T 
(FINDORBUILD WHICH (A (GETR NH)) ADJ (A (GETR *))) 
(TO mmi)) 
(POP NH T)) 
Figure 5. ATN Grammar (continued). 
(V (CAT V T ; The next word must be a verb. 
(SETR VB (FINDORBUILD LEX (A(GETR *)))) 
(TO COMPL))) 
(SETR TNS (GETF TENSE)) 
(COMPL ; Consider the word after the verb. 
(CAT V (AND (GETF PPRT) (OVERLAP (GETR VB) (GETA LEX- 'BE))) 
; It must be a pass ive sentence. 
(SETR OBJ (GETR SUBJ)) (SETR SUBJ NIL) (SETR VC 'PASS) 
(SETR VB (FINDORBUILD LEX (A(GETR *)))) (TO SV)) 
(CAT ADJ (OVERLAP (GETR VB) (GETA LEX- 'BE)) 
; a predicate adjective. 
(SETR ADJ (FINDORBUILD LEX (A (GETR *)))) (TO SVC)) 
(JUMP SV T)) 
Figure 6. ATN Grammar (continued). 
American Journal of Computational Linguistics, Volume 8, Number 1, January-March 1982 19 
Stuart C. Shapiro Generalized Augmented Transition Network Grammars 
placed in register NH,  and the parser transfers TO 
state NPA with an empty input buffer, and the value 
of NH is popped back to the PUSH arc from state O 
or PAG where it becomes the value of the * register 
and the first (and only) item on the input buffer. Af-  
ter setting the SUBJ or OBJ register, these PUSH arcs 
LIFTR the proper voice to the VC register on the top 
ATN level and transfer TO state SVO (Figure 9). 
When dealing with sentence (1), the first POP arc 
at state SVO builds node M12 and pops it to the top 
level. The second POP arc finds M12 for both sen- 
tences (2) and (4). In the case of sentence (3), the 
CAT ADJ arc is fo l lowed from state COMPL to state 
SVC, on the first arc of which node M15 is built. The 
second arc from SVC is not used in these examples. 
The pop from state SVO or SVC returns to the 
PUSH arc from state S which JUMPs to the state RE- 
SPOND with the input buffer containing either the 
node built to represent an input statement or the node 
that represents the answer to an input question. In 
our example, this is node M12 for inputs (1), (2), and 
(4), and node M15 for input (3). Remember  that 
nodes M14 and M15 do not exist until sentence (3) is 
analyzed. 
The state RESPOND (Figure 10) is the initial state 
of the generation network. In this network the regis- 
ter STRING is used to col lect the surface sentence 
being built. The only difference between the two arcs 
in state RESPOND is that the first, responding to 
input statements, starts the output sentence with the 
(SV ; Start bu i ld ing the temporal  structure. 
JUMP O (EQ (GETR TYPE) 'Q)) ; Ignore the tense of a question. 
JUMP O (EQ (GETR TNS) 'PRES) 
; Present means start ing before and ending after now. 
(SETR STM (BUILD BEFORE *NOW BEFORE (BUILD AFTER *NOW) : ETM))) 
JUMP O (EQ (GETR TNS) 'PAST) 
; Past means start ing and ending before now. 
(SETR STM (BUILD BEFORE (BUILD BEFORE *NOW) = ETM)))) 
Figure 7. ATN Grammar (continued). 
(O ; Parse what fol lows the verb group. 
(WRD BY (EQ (GETR VC) 'PASS) ; Passive sentences have 
(TO PAG)) 
(PUSH NPP T ; A<tive sentences have an object NP. 
(SENDR TYPE) (SETR OBJ *) (LIFTR VC) (TO SVO))) 
"by NP". 
(PAG (PUSH NPP T ; Parse the subject NP of a pass ive sentence. 
(SENDR TYPE) (SETR SUBJ *) (LIFTR VC) (TO SVO))) 
Figure 8. ATN Grammar (continued). 
(SVO ; Return a semantic node. 
(POP (BUILD AGENT (^(GETR SUBJ)) VERB (A(GETR VB)) 
OBJECT (^(GETR OBJ)) STIME (A(GETR STM)) ETIME *ETM) 
(EQ (GETR TYPE) 'D)) ; An Agent -Verb-Object  statement. 
(POP (DEDUCE AGENT (A(GETR SUBJ)) VERB (^(GETR VB)) 
OBJECT (^(GETR OBJ))) 
(EQ (GETR TYPE) 'Q))) ; An Agent -Verb-Object  question. 
(SVC (POP (EVAL (BUILDQ (FINDORBUILD WHICH + ADJ +) SUBJ ADJ)) 
(EQ (GETR TYPE) 'D)) ; A Noun-be-Adj  statement. 
(POP (DEDUCE WHICH (A(GETR SUBJ)) ADJ (A(GETR ADJ))) 
(EQ (GETR TYPE) 'Q))) ; A Noun-be-Adj  question. 
Figure 9. ATN Grammar (continued). 
20 American Journal of Computational Linguistics, Volume 8, Number 1, January-March 1982 
Stuart C. Shapiro Generalized Augmented Transition Network Grammars 
(RESPOND 
; Generate  the response  represented  by the semant ic  node in * .  
(JUMP G (EQ (GETR TYPE) 'D) 
; The input  was a s ta tement  represented  by *. 
(SETR STRING ' (I UNDERSTAND THAT)))  
(JUMP G (EQ (GETR TYPE) 'Q))) 
; The input  was a quest ion  answered  by *. 
Figure 10. ATN Grammar (continued). 
phrase I UNDERSTAND THAT. Then both arcs 
JUMP to state G. We follow the generation process 
assuming that the input buffer is now (M12). 
In state G (Figure 11), the node representing the 
statement to be generated is analyzed to decide what 
kind of sentence will be produced. The first arc, for a 
passive version of M12, sets the SUBJ register to M11 
(the saw), the OBJ register to M4 (Lucy), and the 
PREP register to the word BY. (Note the use of 
GETA, defined in Section 3.3.) The second arc, for 
an active version of M12, sets SUBJ to M4, OBJ to 
M l l ,  and leaves PREP empty. It also makes sure VC 
is set to ACT, since active voice is the default if VC is 
empty. The third arc is for generating sentences for 
nodes such as M15. In that case it sets SUBJ to M4, 
OBJ to M14 (the property SWEET), VC to ACT, and 
leaves PREP empty. All three arcs then JUMP to 
state GS. 
The CALL  arc at state GS (Figure 12) sets the 
NUMBR register to SING or PL to determine whether 
the subject and verb of the sentence will be singular or 
plural, respectively. It does this by CALLing the net- 
work beginning at state NUMBR, sending it the con- 
tents of the SUBJ register, and placing the form re- 
turned by the lower network into the NUMBR regis- 
ter. Let us assume we are generating an active version 
of M12. In that case when state NUMBR (Figure 12) 
is reached, the input buffer will be (M4), and when 
the parser returns to the CALL  arc the input buffer 
will again be (M12). 
At state NUMBR, the semantic network attached 
to the node in the * register is examined to determine 
if it represents a (singular) individual or a (plural) 
class of individuals. The first arc decides on PL if the 
node has a SUB-, SUP-, or CLASS- are emanating 
from it. These arcs are the converses of SUB, SUP, 
and CLASS arcs, respectively. The first would occur 
if the node represented the subset of some class. The 
second would occur if the node represented the super- 
set of some class. The third would occur if the node 
represented a class with at least one member. In our 
example, the only semantic node that would be recog- 
nized by this arc as representing a class would be M9. 
The second arc from state NUMBR decides on SING 
if none of the three mentioned arcs emanate from the 
node in *, and in our case this is the successful arc. 
The decision is made by placing SING or PL in the 
NUMBR register, and transferring TO state NUMBR1. 
There the input buffer is empty and the contents of 
NUMBR is popped to the CALL arc in the state GS 
as discussed above. The last thing the CALL arc in 
state GS does is set the DONE register to the node in 
? This register is used to remember the node being 
expressed in the main clause of the sentence so that it 
is not also used to form a subordinate clause or de- 
scription. For example, we would not want to gener- 
ate "Lucy, who saw a saw, saw a saw." This is used 
(G ; Generate  a sentence  to express  the semant ic  node in * .  
(JUMP GS (AND (GETA OBJECT) (OVERLAP (GETR VC) 'PASS)) 
; A pass ive  sentence  is "OBJECT VERB by AGENT".  
(SETR SUBJ (GETA OBJECT))  (SETR OBJ (GETA AGENT)) 
(SETR PREP 'BY)) 
(JUMP GS (AND (GETA AGENT) (DIS JOINT (GETR VC) 'PASS)) 
; An act ive  sentence  is "AGENT VERB OBJECT".  
(SETR SUBJ (GETA AGENT))  (SETR OBJ (GETA OBJECT))  
(SETR VC 'ACT)) 
(JUMP GS (GETA WHICH) (SETR SUBJ  (GETA WHICH)) 
; A WHICH-ADJ  sentence  is "WHICH be ADJ".  
(SETR OBJ (GETA ADJ)) (SETR VC 'ACT))) 
Figure 1 h ATN Grammar (continued). 
American Journal of Computational Linguistics, Volume 8, Number 1, January-March 1982 21 
Stuart C. Shapiro Generalized Augmented Transition Network  Grammars 
effectively in the response to statement 3 to prevent 
the response from being "I UNDERSTAND THAT 
SWEET YOUNG LUCY IS SWEET". We will see 
where DONE is used in the ATN network shortly. 
The parser then JUMPs to state GS1, where NP is 
CALLed with input buffer (M4), DONE set to M12, 
and NUMBR set to SING. 
State NP (Figure 13) is the beginning of a network 
that generates a noun phrase to describe the concept 
represented by the semantic node in the * register (in 
this case, M4). The first arc just uses the node at the 
end of the LEX arc if one exists, as it does for nodes 
M1, M2, etc. WRDIZE is a LISP function that does 
morphological synthesis for nouns. Its first argument 
must be SING or PL, and its second argument must be 
a non-ambiguous lexeme in the lexicon. Nouns whose 
singular or plural forms are irregular must have them 
explicitly noted in the lexical feature list. The regular 
rule is to use the ROOT form as the singular, and to 
pluralize according to rules built into WRDIZE that 
operate on the ROOT form. For example, the singu- 
lar of SAW1 is its ROOT, SAW, and its plural is 
SAWS. 
The second arc in the state NP uses a proper name 
to describe *, if it has one, and if the proposition that 
this name is *'s name is not the point of the main 
(GS ; Set the NUMBR reg is ter  to the number  of the subject ,  
; and the DONE reg is ter  to the propos i t ion  of the main  c lause.  
(CALL NUMBR SUBJ  T NUMBR (SETR DONE *) (JUMP GSl)))  
(GSI (CALL NP SUBJ  T ; Generate  a NP to express  the subject .  
(SENDR DONE) (SENDR NUMBR) REG 
(ADDR STRING REG) (JUMP SVB))) 
(NUMBR 
; The proper  number  is PL for a class, S ING for an ind iv idua l .  
(TO (NUMBRI) (OR (GETA SUB-) (GETA SUP-) (GETA CLASS-))  
(SETR NUMBR 'PL)) 
(TO (NUMBRI) (NOT (OR (GETA SUB-) (GETA SUP-) (GETA CLASS-) ) )  
(SETR NUMBR 'SING))) 
(NUMBRI (POP NUMBR T)) ; Return  the number.  
Figure 12. ATN Grammar (Continued). 
(NP ; Generate  a NP to express  *. 
(TO (END) (GETA LEX) 
; Just  use the word  at the end of the LEX arc if present .  
(SETR STRING (WRDIZE (GETR NUMBR) (GETA LEX))))  
(CALL ADJS (GETA WHICH-)  ; If it has a name, 
(AND (GETA NAMED-) (DIS JOINT (GETA NAMED-) DONE)) 
(SENDR DONE) REG 
(ADDR STRING REG) ; add an ad jec t ive  str ing,  
(TO NPGA (GETA NAME (GETA NAMED-) ) ) )  ; and cons ider  its name. 
(CALL ADJS (GETA WHICH-)  ; If it has a class, 
(AND (GETA MEMBER-)  (DIS JOINT (GETA MEMBER-)  DONE)) 
(SENDR DONE) REG ; add 'A and an ad jec t ive  str ing,  
(ADDR STRING 'A REG) ; and cons ider  its class. 
(TO NPGA (GETA CLASS (GETA MEMBER- ) ) ) ) )  
(NPGA ; Generate  a noun phrase  for the name or class. 
(PUSH NP T (SENDR DONE) (ADDR STRING *) (TO END))) 
(END (POP STRING T)) ; Return  the s t r ing  that  has been bui l t .  
Figure 13. ATN Grammar (continued). 
22 American Journal of Computational Linguistics, Volume 8, Number 1, January-March 1982 
Stuart  C. Shapiro Generalized Augmented Transition Network Grammars 
clause. The third arc uses the phrase "a <c lass>"  if * 
is known to be a member of some class, and if that 
fact is not the main clause of the sentence. Both arcs 
first call ADJS to form an adjective string to be in- 
cluded in the noun phrase. 
The network starting at ADJS (Figure 14) is 
CALLed to generate a string of adjectives. For this 
purpose, it is "passed" the set of property assertion 
nodes, and its DONE register is set. Let us consider 
the four cases in which a noun phrase is being generat- 
ed to describe M4. In sentences (1) and (2), the input 
buffer at state ADJS is (M5) and DONE contains 
(M12). In sentence (3), the input buffer is (M15 M5) 
and DONE is (M15). In sentence (4), the input buff- 
er is (M15 M5) and DONE contains (M12). The 
CALL arc in state ADJS calls the NP network to gen- 
erate a description of the property at the end of the 
ADJ arc from the node in * (the first node in the in- 
put buffer) as long as the node in * is not also in 
DONE.  It adds this description to the register 
STRING and loops back TO ADJS, consuming the 
node in * from the input buffer. We have already 
seen how the NP network will generate SWEET for 
M14 and YOUNG for M1. The second arc in state 
ADJS consumes the first node in the input buffer 
without generating a description for its property. The 
third arc POPs back to the CALLing arc, returning the 
constructed adjective string in STRING. If we view 
the ATN as a non-deterministic machine, the result of 
the ADJS network is a string of zero or more of the 
adjectives that describe the individual of the noun 
phrase, but not the adjective, if any, in the predicate 
of the higher clause. Viewed deterministically, since 
most ATN interpreters try arcs in strict order, the 
network will generate a string of all appropriate adjec- 
tives. 
Returning to our main example of sentence (1), the 
string YOUNG is POPped into the REG register on 
the first CALL  arc in state NP, where it is added to 
the end of the register STRING (previously empty). 
The parser then jumps TO state NPGA,  and, because 
of the form in the terminal action, the input buffer is 
changed from (M4) to (M2). At state NPGA,  the 
parser PUSHes to state NP where, as we have seen, 
LUCY will be generated and POPped back into the * 
register. This is added to STRING, forming (YOUNG 
LUCY),  and the parser goes TO state END, emptying 
the input buffer. At END, the contents of STRING, 
(YOUNG LUCY)  is POPped to the register REG in 
the CALL  arc of state GS1 (Figure 12), and added to 
the top level of STRING, which is now (I UNDER-  
STAND THAT YOUNG LUCY) .  The parser then 
JUMPs to state SVB with the input buffer restored to 
(M12). 
At state SVB (Figure 15), the network beginning at 
state PRED is CALLed. At that level the input buffer 
is (M12), * contains M12, NUMBR contains SING, 
VC contains ACT (PASS in the case of sentence 4), 
and VB contains SEE. Notice that if the main propo- 
sition node has no VERB arc, BE is placed in VB. 
This is the situation in the case of sentence (3), re- 
flecting the theory that in copulative sentences BE is 
only a dummy verb used to carry tense, mood, and 
aspect. 
The arcs at state PRED (Figure 15) determine and 
place in the TENSE register the tense of the sentence 
being generated. For simplicity in this example, we 
only consider simple present, past, and future. This is 
one of the most interesting sections of this generation 
grammar, because it is a grammar that analyzes 
(parses) a piece of the semantic network. The first 
CALL  arc of state PRED calls a network that recog- 
nizes the temporal structure indicating past tense. The 
second CALL arc calls a network that recognizes the 
temporal structure indicating future tense. The third, 
TO, arc chooses present tense as the default. The 
CALL arcs pass to the lower network the appropriate 
semantic temporal nodes. Since past tense is indicated 
by the action ending before *NOW, the first arc pas- 
ses the node at the end of the ET IME arc from the 
proposition node. Since future tense is indicated by 
the action starting after *NOW, the second arc passes 
the node at the end of the STIME arc. In our case, 
the tense will be past, so we turn to the PAST sub- 
network (Figure 16). 
The first are in state PAST transfers TO state PAS- 
TEND, which simply POPs the atom PAST if the con- 
tents of * OVERLAPs  the value of *NOW, that is, if 
the * register contains the semantic node representing 
now. If it doesn't,  the second arc in PRED replaces 
the first node in the input buffer by the node(s) repre- 
senting times known to be after it, and loops back to 
PRED. This sub-network can only succeed, returning 
(ADJS 
; Generate  a s t r ing  of ad ject ives ,  one for each WHICH-ADJ  node in *. 
(CALL NP (GETA ADJ) (DISJOINT * DONE) (SENDR DONE) * 
(ADDR STRING *) (TO ADJS)) 
(TO (ADJS) T) 
(POP STRING T)) 
Figure 14. ATN Grammar (continued). 
American Journal of Computational Linguistics, Volume 8, Number 1, January-March 1982 23 
Stuart C. Shapiro Generalized Augmented Transition Network Grammars 
(SVB (CALL PRED * T 
; Generate a verb group. Use "be" if no other verb. 
(SENDR NUMBR) (SENDR VC) 
(SENDR VB (OR (GETA LEX (GETA VERB)) 'BE)) 
REG (ADDR STRING REG) (JUMP SUROBJ))) 
(SUROBJ (CALL NP OBJ OBJ 
; Generate a NP to express the OBJ if there is one. 
(SENDR DONE) * (ADDR STRING PREP *) (TO END)) 
(TO (END) T)) 
(PRED ; F igure out the proper  tense. 
(CALL PAST (GETA ETIME) T TENSE (TO GENVB)) 
; Past tense depends on ending time. 
(CALL FUTR (GETA STIME) T TENSE (TO GENVB)) 
; Future tense depends on start ing time. 
(TO (GENVB) T (SETR TENSE 'PRES))) ; Present tense is the default.  
(GENVB ; Return the verb group. 
(POP (VERBIZE (GETR NUMBR) (GETR TENSE) (GETR VC) (GETR VB)) T)) 
Figure 15. ATN Grammar (continued). 
(PAST ; If we can get to *NOW by BEFORE arcs, 
(TO (PASTEND) (OVERLAP * *NOW)) 
(TO (PAST (GETA BEFORE)) T)) 
(PASTEND (POP 'PAST T)) 
it is past tense. 
(FUTR ; If we can get to *NOW by AFTER arcs, 
(TO (FUTREND) (OVERLAP * *NOW)) 
(TO (FUTR (GETA AFTER)) T)) 
(FUTREND (POP 'FUTR T)) 
it is future tense. 
Figure 16. ATN Grammar (continued). 
PAST, if there is a path of BEFORE arcs from the 
node representing the ending time of the action to 
*NOW. If there isn't, the sub-network will eventually 
block, causing the CALL  PAST arc in state PRED to 
fail. The FUTR sub-network works in a similar fash- 
ion. Similar sub-networks can easily be written to 
recognize the temporal structure of future perfect 
("Lucy will have seen a saw."), which is a path of 
BEFORE arcs followed by a path of AFTER arcs 
from the ending time to now, and the temporal struc- 
tures of other tenses. 
In our example, the CALL  PAST arc succeeds, 
TENSE is set to PAST, and the parser transfers TO 
state GENVB (Figure 15), where the appropriate verb 
group is generated and POPped to the CALL  arc in 
state SVB. The verb group is constructed by VER- 
BIZE, which is a LISP function that does morphologi- 
cal synthesis on verbs. Its arguments are the number, 
tense, voice, and verb to be used. 
Back on the CALL  arc in state SVB (Figure 15), 
the verb group POPped into the register REG is added 
to the STRING, which is now (I UNDERSTAND 
THAT YOUNG LUCY SAW), and the parser JUMPs 
to state SUROBJ. There, the NP sub-network (Figure 
13) is CALLed to generate a noun phrase for the con- 
tents of OBJ (M l l ) .  Since M l l  has neither a LEX 
arc nor a name, but does have a class, the third arc is 
used, and (A SAW) is generated and POPped. This 
noun phrase is added to STRING preceded by the 
contents of PRED, which is empty in sentences (1), 
(2), and (3), but which contains BY in sentence (4). 
The CALL  arc then transfers TO state END, emptying 
the input buffer at the top level. The POP arc at state 
END POPs the contents of STRING, which is finally 
printed by the system, and the interaction is complete. 
24 American Journal of Computational Linguistics, Volume 8, Number 1, January-March 1982 
Stuart C. Shapiro Generalized Augmented Transition Network Grammars 
7. Conclusions 
A generalization of the ATN formalism has been 
presented which allows grammars to be written for 
generating surface sentences from semantic networks. 
The generalization has involved: adding an optional 
argument o the TO terminal act; reintroducing the 
JUMP terminal act; introducing a TO arc similar to 
the JUMP arc; introducing a CALL arc that is a gen- 
eralization of the PUSH arc; introducing a GETA 
form; clarifying the management of the input buffer. 
The benefits of these few changes are that parsing and 
generating rammars may be written in the same fa- 
miliar notation, may be interpreted (or compiled) by a 
single program, and may use each other in the same 
parser-generator network grammar. 
Acknowledgments  
The help provided by the following people with the 
ATN parsing and generating interpreters and compiler, 
the morphological analyzer and synthesizer, and mov- 
ing the software across several LISP dialects is greatly 
appreciated: Stan Kwasny, John Lowrance, Darrel 
Joy, Don McKay, Chuck Arnold, Ritch Fritzson, Ger- 
ard Donlon. Associate editor Michael McCord and 
the reviewers provided valuable comments on earlier 
drafts of this paper. 
References 
Bates, M. 1978 The theory and practice of augmented transition 
network grammars. In Bole, L., Ed., Natural Language Commu- 
nication with Computers. Springer Verlag, Berlin: 191-259. 
Burton, R.R. 1976 Semantic grammar: an engineering technique 
for constructing natural anguage understanding systems. BBN 
Report No. 3453, Bolt Beranek and Newman, Inc., Cambridge, 
MA., December. 
Burton, R.R. and Woods, W.A. 1976 A compiling system for 
augmented transition etworks. Preprints of COLING 76: The 
International Conference on Computational Linguistics, Ottawa 
(June). 
Shapiro, S.C. 1975 Generation as parsing from a network into a 
linear string. AJCL Microfiche 33, 45-62. 
Shapiro, S.C. 1979 The SNePS semantic network processing 
system. In Findler, N.V., Ed., Associative Networks: Representa- 
tion and Use of Knowledge by Computers. Academic Press, New 
York, 179-203. 
Simmons, R.F. 1973 Semantic networks: their computation and 
use for understanding English sentences. In Schank, R.C. and 
Colby, K.M., Ed., Computer Models of Thought and Language. 
W. H. Freeman and Co., San Francisco: 63-113. 
Woods, W.A. 1970 Transition network grammars for natural 
language analysis. CACM 13, 10 (October) 591-606. 
Woods, W.A. 1973 An experimental parsing system for transition 
network grammars. In Rustin, R., Ed., Natural Language 
Processing. Algorithmics Press, New York: 111-154. 
Stuart C. Shapiro is an associate professor in the 
Department of Computer Science at the State University 
of New York at Buffalo. He received the Ph.D. degree 
in computer sciences f rom the University o f  Wisconsin in 
1971. 
American Journal of Computational Linguistics, Volume 8, Number 1, January-March 1982 25 
