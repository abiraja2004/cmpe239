Proceedings of the 9th SIGdial Workshop on Discourse and Dialogue, pages 148?155,
Columbus, June 2008. c?2008 Association for Computational Linguistics
Modeling Vocal Interaction for Text-Independent
Participant Characterization in Multi-Party Conversation
Kornel Laskowski
Cognitive Systems Labs
Universita?t Karlsruhe
Karlsruhe, Germany
kornel@ira.uka.de
Mari Ostendorf
Dept. of Electrical Engineering
University of Washington
Seattle WA, USA
mo@ee.washington.edu
Tanja Schultz
Cognitive Systems Labs
Universita?t Karlsruhe
Karlsruhe, Germany
tanja@ira.uka.de
Abstract
An important task in automatic conversation
understanding is the inference of social struc-
ture governing participant behavior. We ex-
plore the dependence between several social
dimensions, including assigned role, gender,
and seniority, and a set of low-level features
descriptive of talkspurt deployment in a mul-
tiparticipant context. Experiments conducted
on two large, publicly available meeting cor-
pora suggest that our features are quite useful
in predicting these dimensions, excepting gen-
der. The classification experiments we present
exhibit a relative error rate reduction of 37% to
67% compared to choosing the majority class.
1 Introduction
An important task in automatic conversation under-
standing is the inference of social structure govern-
ing participant behavior; in many conversations, the
maintenance or expression of that structure is an
implicit goal, and may be more important than the
propositional content of what is said.
There are many social dimensions along which
participants may differ (Berger, Rosenholtz and
Zelditch, 1980). Research in social psychology has
shown that such differences among participants en-
tail systematic differences in observed turn-taking
and floor-control patterns (e.g. (Bales, 1950), (Tan-
nen, 1996), (Carletta, Garrod and Fraser-Krauss,
1998)), and that participant types are not indepen-
dent of the types and sizes of conversations in which
they appear. In the present work, we consider the
dimensions of assigned role, gender, and senior-
ity level. We explore the predictability of these
dimensions from a set of low-level speech activ-
ity features, namely the probabilities of initiating
and continuing talkspurts in specific multipartici-
pant contexts, estimated from entire conversations.
For our purposes, talkspurts (Norwine and Murphy,
1938) are contiguous intervals of speech, with in-
ternal pauses no longer than 0.3 seconds. Features
derived from talkspurts are not only easier to com-
pute than higher-level lexical, prosodic, or dialogue
act features, they are also applicable to scenarios in
which only privacy-sensitive data (Wyatt et al 2007)
is available. At the current time, relatively little is
known about the predictive power of talkspurt tim-
ing in the context of large multi-party corpora.
As stated, our primary goal is to quantify the de-
pendence between specific types of speech activity
features and specific social dimensions; however,
doing so offers several additional benefits. Most
importantly, the existence of significant dependence
would suggest that multiparticipant speech activity
detectors (Laskowski, Fu?gen and Schultz, 2007) re-
lying on models conditioned on such attributes may
outperform those relying on general models. Fur-
thermore, conversational dialogue systems deployed
in multi-party scenarios may be perceived as more
human-like, by humans, if their talkspurt deploy-
ment strategies are tailored to the personalities they
are designed to embody.
Computational work which is most similar to that
presented here includes the inference of static dom-
inance (Rienks and Heylen, 2005) and influence
(Rienks et al, 2006) rankings. In that work, the au-
thors employed several speech activity features dif-
fering from ours in temporal scale and normaliza-
148
tion. Notably, their features are not probabilities
which are directly employable in a speech activity
detection system. In addition, several higher-level
features were included, such as topic changes, par-
ticipant roles, and rates of phenomena such as turns
and interruptions, and these were shown to yield the
most robust performance. Our aim is also similar
to that in (Vinciarelli, 2007) on radio shows, where
the proposed approach relies on the relatively fixed
temporal structure of production broadcasts, a prop-
erty which is absent in spontaneous conversation.
Although (Vinciarelli, 2007) also performs single-
channel speaker diarization, he does not explore be-
havior during vocalization overlap.
Aside from the above, the focus of the major-
ity of existing research characterizing participants
is the detection of dynamic rather than static roles
(i.e. (Banerjee and Rudnicky, 2004), (Zancanaro et
al, 2006), (Rienks et al, 2006)). From a mathe-
matical perspective, the research presented here is
a continuation of our earlier work on meeting types
(Laskowski, Ostendorf and Schultz, 2007), and we
rely on much of that material in the presentation
which follows.
2 Characterizing Participants
Importantly, we characterize participants in entire
groups, rather than characterizing each participant
independently. Doing so allows us to apply con-
straints on the group as a whole, eliminating the
need for hypothesis recombination (in the event that
more than one participant is assigned a role which
was meant to be unique). Additionally, treating
groups holistically allows for modeling the interac-
tions between specific pairs of participant types.
For each conversation or meeting1 of K partici-
pants, we compute a feature vector F, in which all
one-participant and two-participant speech activity
features are found in a particular order, typically im-
posed by microphone channel or seating assignment
(the specific features are described in Section 4).
The goal is to find the most likely group assignment
of participant labels that account for the observed
F. In (Laskowski, Ostendorf and Schultz, 2007), it
was shown that meeting types in a large meeting cor-
1
?Conversation? and ?meeting? will be used interchange-
ably in the current work.
pus can be successfully inferred from F using this
approach; here, we employ the same framework to
classify participant types in the K-length vector g,
for the group as a whole:
g? = arg max
g?G
P (g |F )
= arg max
g?G
P (g )
? ?? ?
MM
P (F |g )
? ?? ?
BM
, (1)
where MM and BM are the membership and behav-
ior models, respectively, and G is the set of all pos-
sible assignments of g.
In the remainder of this section, we define the
participant characteristics we explore, which include
assigned role, gender, and seniority. We treat these
as separate tasks, applying the same classification
framework. We also show how our definitions pro-
vide search space constraints on Equation 1.
2.1 Conversations with Unique Roles
Given a meeting of K participants, we consider a set
of roles R = {R1, R2, ? ? ? , RK} and assign to each
participant k, 1?k?K, exactly one role in R. An
example group assignment is the vector r1 of length
K, where r1 [k] = Rk. The set R of group assign-
ment alternatives r ? R is given by permutations
? : R 7? R, where ? ? SK , the symmetric group on
K symbols2. The number of elements in R is iden-
tically the number of unique permutations in SK , a
quantity known as its order |SK | = K!.
To identify the most likely group assignment r? =
?? (r1) given the set F of observables, we iterate
over the K! elements of SK using
?? = arg max
??SK
P (F |? (r1) ) , (2)
where we have elided the prior P (? ) assuming that
it is uniform. Following the application of Equa-
tion 2, the most likely role of participant k is given
by ?? (r1) [k].
Alternately, we may be interested in identifying
only a subset of the roles in R, namely a leader, or
a manager. In this case, participant roles are drawn
from L = {L,?L}, under the constraint that exactly
one participant is assigned the role L. The set L of
2For an overview of group theoretic notions and notation,
we refer the reader to (Rotman, 1995).
149
alternative group assignments has K indicator vec-
tor members lj , 1?j?K, where lj [k] is L for k = j
and ?L otherwise.3 We iterate over the indicator
vectors to obtain
j? = arg max
j?{1,???,K}
P (F | lj ) , (3)
assuming uniform priors P ( lj ). Following the ap-
plication of Equation 3, j? is the index of the most
likely L participant.
We note that this framework for unique role clas-
sification is applicable to classifying unique ranks,
without first having to collapse them into non-
unique rank classes as was necessary in (Rienks et
al., 2006).
2.2 Conversations with Non-Unique Roles
The second type of inference we consider is for di-
mensions in which roles are not unique, i.e. where
participants are in principle drawn independently
from a set of alternatives. This naturally includes
dimensions such as gender, seniority, age, etc.
As an example, we treat the case of gender. Par-
ticipant genders are drawn independently from H =
{~,|}. The set of group assignment alternatives h
is given by the Cartesian product HK , of 2K unique
elements. We search for the most likely group as-
signment h?, given the observables F, by iterating
over these elements using
h? = arg max
h?HK
P (h ) P (F |h ) . (4)
Once h? is found, the gender of each participant k is
available in h? [k].
A similar scenario is found for seniority, when
it is not uniquely ranked. We assume a set of
NS mutually exclusive seniority levels Si ? S =
{S1, S2, ? ? ? , SNS}, 1?i?NS . During search, each
participant?s seniority level is drawn independently
from S , leading to group assignments s ? SK , of
which there are NKS . As for gender, we iterate over
these to find
s? = arg max
s?SK
P ( s ) P (F | s ) . (5)
The seniority of participant k, following the applica-
tion of Equation 5, is s? [k].
3For completeness, we note that each lj corresponds to a
permutation ? : L 7? L of l1, and that ? ? ?? ?, the cyclic sub-
group generated by ? , where ? is the permutation (1, 2, ? ? ? ,K).
3 Data
In the current work, we use two different corpora of
multi-party meetings. The first, the scenario subset
of the AMI Meeting Corpus (Carletta, 2007), con-
sists of meetings involving K = 4 participants who
play different specialist roles in a product design
team. We have observed the recommended division
of this data into: AMITRAINSET of 98 meetings;
AMIDEVSET of 20 meetings; and AMIEVALSET,
also of 20 meetings. Although each participant takes
part in approximately 4 meetings, the 3 sets are dis-
joint in participants. We use only the provided word
alignments of these meetings. The corpus is accom-
panied by metadata which specifies the gender and
assigned role of each participant.
The second corpus consists of the Bed, Bmr,
and Bro meeting types in the ICSI Meeting Cor-
pus (Janin et al, 2003). Each meeting is identified
by one of {Bed,Bmr,Bro}, as well as a numerical
identifier d. We have divided these meetings into:
ICSITRAINSET, consisting of the 33 meetings for
which d mod 4 ? {1, 2}; ICSIDEVSET, consist-
ing of the 18 meetings for which d mod 4 ? 3;
and ICSIEVALSET, consisting of the 16 meetings for
which d mod 4 ? 0. These three sets are not dis-
joint in participants, and the number of instrumented
participants K varies from meeting to meeting, be-
tween 3 and 9. The corpus is accompanied by meta-
data specifying the gender, age, and education level
of each participant. We use only the forced align-
ments of these meetings, available in the accompa-
nying MRDA Corpus (Shriberg et al 2004).
4 Features
Our observation space is the complete K-participant
vocal interaction on-off pattern description for a
meeting C, a discretized version of which we denote
as qt ? {0, 1}K for 1?t?T , where T is the dura-
tion of C in terms of the number of 100 ms frames.
Details regarding the discretization (and subsequent
feature computation) can be found in (Laskowski,
Ostendorf and Schultz, 2007).
We compute from qt the following features4
which are the elements of F: fV Ik , the probabil-
4Feature type superscripts indicate talkspurt initiation (I) or
continuation (C), for either single-participant vocalization (V )
or vocalization overlap (O).
150
ity that participant k initiates vocalization at time t
when no-one else was speaking at t ? 1; fV Ck , the
probability that participant k continues vocalization
at time t when no-one else was speaking at t ? 1;
fOIk,j , the probability that participant k initiates vo-
calization at time t when participant j was speaking
at t ? 1; and fOCk,j the probability that participant k
continues vocalization at time t when participant j
was speaking at t? 1. Values of the features, which
are time-independent probabilities, are estimated us-
ing a variant of the Ising model (cf. (Laskowski, Os-
tendorf and Schultz, 2007)). Additionally, we com-
pute a feature fVk , the probability that participant
k vocalizes at time t, and single-participant aver-
ages of the two-participant features: ?fOIk,j ?j , ?fOIj,k ?j ,
?fOCk,j ?j , and ?fOCj,k ?j . The complete feature vector
for a conversation of K participants then consists of
7K one-participant features, and 2(K2 ? K) two-
participant features.
We note that multiple phenomena contribute to
the overlap features. The features fOIk,j are based
on counts from interruptions, backchannels, and pre-
cise floor handoffs. The features fOCk,j are based on
counts from interruptions, attempts to hold the floor,
and backchannels. Both feature types also contain
counts incurred during schism, when the conversa-
tion splits into two sub-conversations.
5 Models
Since K may change from meeting to meeting, the
size of the feature vector F must be considered vari-
able. We therefore factor the behavior model, as-
suming that all features are mutually independent
and that each is described by its own univariate
Gaussian model N
(
?, ?2
)
. These parameters are
maximum likelihood estimates from the fk and fk,j
values in a training set of conversations. In most of
these experiments, where the number of classes is
small, no parameter smoothing is needed.
For the cases where the group prior is not uniform
and participant types are not unique, the member-
ship model assumes independent participant types
and has the general form
P (g ) =
K?
k=1
P (g [k] ) , (6)
where P (g [k] ) is the probability that the k-th par-
ticipant is type g [k]. This model is used for gen-
der (P (h)) and seniority (P (s)). The probabilities
of specific types are maximum likelihood estimates
from the training data.
6 Assigned Role Classification
6.1 Classifying Unique Roles
For unique role classification, we use the AMI Meet-
ing Corpus. All meetings consist of K = 4 par-
ticipants, and each participant is assigned one of
four roles: project manager (PM), marketing expert
(ME), user interface designer (UI), or industrial de-
signer (ID).
As mentioned in Section 2.1, classifying the
unique role of all participants, jointly, involves
enumerating over the possible permutations of
{PM, ME, UI, ID}. We use AMITRAINSET to train
the behavior model, and then classify AMIDEVSET
using Equation 2, one feature type at a time, to iden-
tify the best 3 feature types for this task; develop-
ment experiments suggest that classification rates
level off after a small handful of the best perform-
ing feature types is included. Those feature types
were found to be fV Ik , ?fOIk,j ?j , and fOIk,j , capturing
the probability of initiating a talkspurt in silence, of
initiating a talkspurt when someone else is speak-
ing, and of initiating a talkspurt when a participant
in a specific other role is speaking, respectively. On
AMIEVALSET, these feature types lead to single-
feature-type 4-way classification rates of 41%, 29%,
and 53%, respectively. When all three types are used
together (3K+K2 features in total), the rate is 53%.
Accuracy when all feature types are used is 46%, in-
dicating that some feature types are detrimental to
this task.
The confusion matrix for classification using the
three best feature types is shown in Table 1. The
matrix shows that association between the reference
assignment of PM, as well as of UI, and the hypoth-
esized assignment based on the three feature types
mentioned is statistically significant. On the other
hand, assignment of ID and ME does not deviate
significantly from chance.
6.2 Finding the Manager
Using the same data as above, we explore the sim-
plified task of finding a specific participant type. We
151
HypRef
ID ME PM UI
ID 8 6 4 2
ME 5 8 4 3
PM 3 4 ++12 ? 1
UI 4 2 ?? 0 ++14
Table 1: Confusion matrix for role classification on
AMIEVALSET; reference assignment is found in the rows,
hypothesized assignment in columns. Correctly classified
roles, along the diagonal, are highlighted in bold. Statis-
tical significance of association at the p < 0.005 level
per class, using a 2?2 ?2-test, is shown using ?++? and
????, for above chance and below chance values, re-
spectively; the same is true of ?+? and ???, for signifi-
cance at the 0.005 ? p < 0.05 level.
equate the project manager role with L, and the re-
maining roles with ?L. This is justified by the AMI
meeting scenario, in which participant groups take a
product design from start to prototype, and in which
the project manager is expected to make the group
run smoothly.
The behavior model, trained on AMITRAINSET,
is applied using Equation 3 to determine the most
likely index j? of the leader L, given the observed
F, from among the K = 4 alternatives. To select
the best 3 feature types, we once again use AMIDE-
VSET; these turn out to be the same as those for role
classification, namely fV Ik , ?fOIk,j ?j , and fOIk,j . Using
these three feature types individually, we are able
to identify the leader PM in 12 of the 20 meetings
in AMIEVALSET. When all three are used together,
the identification rate is 60%. However, when all
feature types are used, the identification rate climbs
to 75%. Since all participants are equally likely to
be the leader, the baseline for comparison is random
guessing (25% accuracy).
Figure 1 shows the distribution of two of the se-
lected features, fV Ik and fOIk,j , for the data in AMI-
TRAINSET; we also show the first standard de-
viation of the single-Gaussian diagonal-covariance
models induced. We first note that fV Ik and fOIk,j
are correlated, i.e. that the probability of beginning
a talkspurt in silence is correlated with the proba-
bility of beginning a talkspurt when someone else
is speaking. L consistently begins more talkspurts,
both in silence and during other people?s speech. It
0 0.005 0.01 0.015 0.02 0.025 0.03 0.035 0.04
0
0.005
0.01
0.015
0.02
0.025
(?L,?L)
(?L,L)
(L,?L)
feature fVI
fe
at
ur
e 
fO
I
(?L,?L)
(?L,L)
(L,?L)
Figure 1: Distribution of (fV Ik , fOIk,j ) pairs for each of
(?L,?L), (?L,L), and (L,?L). Ellipses are centered
on AMITRAINSET means and encompass one standard
deviation.
is also interesting that ?L is slightly less likely to
initiate a talkspurt when L is already speaking than
when another ?L is. This suggests that ?L partic-
ipants consistently observe the L-status of the al-
ready speaking party when contemplating talkspurt
production. Finally, we note that neither the proba-
bility of continuing a talkspurt fV Ck (related to talk-
spurt duration) nor fVk (related to overall amount of
talk) are by themselves good L/?L discriminators.
7 Gender Classification
Gender classification is an example of a task with a
Cartesian search space. For these experiments, we
use the AMI Meeting Corpus and the ICSI Meet-
ing Corpus. In both corpora, gender is encoded in
the first letter of each participant?s unique identifier.
The ratio of male to female occurrences is 2 : 1
in AMITRAINSET, and 4 : 1 in ICSITRAINSET.
Choosing the majority class leads to gender classi-
fication rates of 65% and 81% on AMIEVALSET and
ICSIEVALSET, respectively.
We enumerate alternative group assignments us-
ing Equation 4. Somewhat surprisingly, no single
feature type leads to AMIEVALSET or ICSIEVALSET
classification rates higher than those obtained by hy-
pothesizing all participants to be male. On AMIDE-
VSET, one feature type (fOIk,j ) yields negligibly bet-
ter accuracy, but does not generalize to the corre-
152
sponding evaluation data. Furthermore, the associ-
ation between reference gender labels and hypothe-
sized gender labels, on both evaluation sets, does not
appear to be statistically significant at the p < 0.05
level. This finding that males and females do not
differ significantly in their deployment of talkspurts
is likely a consequence of the social structure of the
particular groups studied. The fact that AMI roles
are acted may also have an effect.
8 Seniority Classification
As a second example of non-unique roles, we at-
tempt to classify participant seniority. For these
experiments, we use the ICSI Meeting corpus, in
which each participant?s education level appears as
an optional, self-reported attribute. We have man-
ually clustered these attributes into NS = 3 mu-
tually exclusive seniority categories.5 Each partic-
ipant?s seniority is drawn independently from S =
{GRAD, PHD, PROF}; a breakdown for ICSITRAIN-
SET is shown in Table 2. Choosing the majority
class (P (PHD) = 0.444 on ICSITRAINSET) yields
a classification accuracy of 45% on ICSIEVALSET.
We note that in this data, education level is closely
correlated with age group.
Number ofSeniority
spkrs occur meets
GRAD 15 81 33
PHD 13 87 29
PROF 3 28 28
all 31 196 33
Table 2: Breakdown by seniority S in ICSITRAINSET by
the number of unique participants (spkrs), the number of
occurrences (occur), and the number of meetings (meets)
in which each seniority occurs.
8.1 Classifying Participant Types
Independently of Conversation Types
We first treat the problem of classifying participant
seniority levels independently of the type of conver-
sation being studied. We identify the most likely se-
5GRAD includes ?Grad?, as well as ?Undergrad?,
?B.A.?, and ?Finished BA in 2001?, due to their small
number of exemplars; PHD includes ?PhD? and ?Postdoc?;
and PROF includes ?Professor? only.
niority assignment for all participants using Equa-
tion 5. The best three feature types, determined
using ICSIDEVSET, are fVk , fOIk,j , and fOCk,j (repre-
senting the probability of speaking, of beginning a
talkspurt when a specific seniority participant is al-
ready speaking, and of continuing a talkspurt when
a specific seniority participant is speaking), yield-
ing single-feature-type classification rates of 52%,
59%, and 59%, respectively. When used together,
these three feature types produce the confusion ma-
trix shown in Table 3 and a rate of 61%, better than
when all feature types are used (58%). This rep-
resents a 28% relative error reduction over chance.
As can be seen in the table, association between the
reference and hypothesized seniority assignments is
statistically significant on unseen data. It is also
evident that confusion between GRAD and PROF is
lower than between more proximate seniority levels.
HypRef
GRAD PHD PROF
GRAD ++11 26 3
PHD ? 2 ++41 ? 3
PROF 0 ?? 6 ++10
Table 3: Confusion matrix for seniority classification on
ICSIEVALSET; reference assignment is found in the rows,
hypothesized assignment in columns. Highlighting and
use of ?++?, ?+?, ???, and ???? as in Table 1.
Figure 2 shows the distribution of (fVk , fOCk,j )
pairs in ICSITRAINSET, together with the first stan-
dard deviation, for each combination of the al-
ready speaking seniority participant and the senior-
ity participant initiating a new talkspurt (except for
(PROF, PROF), since there is at most one PROF in
each ICSITRAINSET meeting).
As is clear from the figure, PROF participants in
this data talk more than either of the two other se-
niority types. The figure also demonstrates a differ-
ence of behavior during speech overlap. The four
ellipses describing GRAD behavior when overlap-
ping with any of the other three classes, as well as
PHD behavior when overlapping with GRAD partic-
ipants, are relatively broad and indicate the absence
of strong tendency or preference. However, PHD
participants are more likely to continue vocalizing in
overlap with other PHD participants, and even more
likely to continue through overlap with PROF partic-
153
0 0.2 0.4
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
(GRAD,*)
(PHD,GRAD)
(PHD,PHD)
(PHD,PROF)
(PROF,GRAD)
(PROF,PHD)
feature fV
fe
at
ur
e 
fO
C
(GRAD,GRAD)
(GRAD,PHD)
(GRAD,PROF)
(PHD,GRAD)
(PHD,PHD)
(PHD,PROF)
(PROF,GRAD)
(PROF,PHD)
Figure 2: Distribution of (fVk , fOCk,j ) feature value pairs
for each of the (k, j) participant pairs (GRAD, GRAD),
(GRAD, PHD), (GRAD, PROF), (PHD, GRAD),
(PHD, PHD), (PHD, PROF), (PROF, GRAD), and
(PROF, PHD). Ellipses are centered on ICSITRAIN-
SET means and encompass one standard deviation.
ipants. A similar trend is apparent for PROF partici-
pants: the mean likelihood that they continue vocal-
izing in overlap with GRAD participants lies below
??? (bottom 17%) of their model with PHD partic-
ipants. We believe that the senior researchers in this
data are consciously minimizing their overlap with
students, who talk less, to make it easier for the lat-
ter to speak up.
8.2 Conditioning on Conversation Type
We now repeat the experiments in the previous sec-
tion, but condition the behavior and membership
models on meeting type t:
s? = arg max
s?SK
?
t?T
P ( t ) P ( s | t )
P (F | s , t ) , (7)
where t ? T = {Bed,Bmr,Bro}.
Performance using maximum likelihood esti-
mates for the behavior model P (F | s , t ) results
in a seniority classification rate on ICSIEVALSET of
61%, i.e. no improvement over conversation-type-
independent classification. We suspect this is due
to the smaller amounts of training material. To ver-
ify this assumption, we smooth the maximum like-
lihood estimates, ?Si,t, ?2Si,t, towards the maximum
likelihood conversation-type-independent estimates,
?Si , ?Si , using
??Si,t = ??Si,t + (1 ? ?)?Si , (8)
??2Si,t = ??Si,t + (1 ? ?) ?
2
Si , (9)
where the value of ? = 0.7 was selected using
ICSIDEVSET. This leads to a rate of 63% on IC-
SIEVALSET. Furthermore, if instead of estimating
the prior on conversation type P (t) from the train-
ing data, we use our meeting type estimates from
(Laskowski, Ostendorf and Schultz, 2007), the clas-
sification rate increases to 67%. A control experi-
ment in which the true type ttest of each test meeting
is known, i.e. P (t) = 1 if ttest = t and 0 otherwise,
shows that the maximum accuracy achievable under
optimal P (t) estimation is 73%.
9 Conclusions
We have explored several socially meaningful parti-
tions of participant populations in two large multi-
party meeting corpora. These include assigned role,
leadership (embodied by a manager position), gen-
der, and seniority. Our proposed classifier, which
can represent participants in groups rather than in-
dependently, is able to leverage the observed differ-
ences between specific pairs of participant classes.
Using only low-level features capturing when partic-
ipants choose to vocalize relative to one another, it
attains relative error rate reductions on unseen data
of 37%, 67%, and 40% over chance on classifying
role, leadership, and seniority, respectively. We have
also shown that the same classifier, using the same
features, cannot discriminate between genders in ei-
ther corpus.
A comparison of the proposed feature types and
their performance on the tasks we have explored is
shown in Table 4. Consistently, the most useful fea-
ture types appear to be the probability of initiating
a talkspurt in silence, and the probability of initiat-
ing a talkspurt when a participant of a specific type
is already speaking. Additionally, on the ICSI Meet-
ing Corpus, the probability of speaking appears to be
dependent on seniority, and the probability of con-
tinuing to vocalize in overlap with another partici-
pant appears to depend on the seniority of the lat-
ter. Finally, we note that, for seniority classification
on the unseen ICSIEVALSET, the top 3 feature types
outperform the best single feature type, indicating a
154
degree of feature type complementarity; this is also
true for L-detection on AMIEVALSET when all fea-
ture types, as opposed to the single best feature type,
are used.
Feature AMI ICSI
Type R L H H S S|t?
fVk 44 ? ? ? *52 *57
fV Ik *41 *60 ? ? 52 56
fV Ck 34 ? ? ? ? 62
?fOIj,k ?j 44 ? ? ? 47 56
?fOIk,j ?j *29 *60 ? ? 49 59
fOIk,j *53 *60 64 ? *59 *59
?fOCj,k ?j 24 ? ? ? ? 57
?fOCk,j ?j ? ? ? ? 54 59
fOCk,j ? ? ? ? *59 *63
top 3* 53 60 ? ? 61 67
all 46 75 43 47 58 57
priors 25 25 65 81 45 45
Table 4: Comparative classification performance for 3
experiments on AMIEVALSET and 3 experiments on IC-
SIEVALSET, per feature type; R, L, H, and S as defined
in Section 2. Also shown is performance on the best three
feature types (selected using development data) and all
feature types, as well as that when choosing the major-
ity class (?prior?), informed by training data priors; for
R and L classification, ?prior? performance is equal to
random guessing. ??? indicates that a feature type, by
itself, did not perform above the corresponding ?prior?
rate; top-3 feature type selection indicated by ?*?.
Our results not only suggest new, easy-to-
compute, low-level features for the automatic clas-
sification of participants into socially meaningful
types, but also offer scope for informing turn-taking
or talkspurt-deployment policies in conversational
agents deployed in multi-party settings. Addition-
ally, they suggest that implicit models of certain
equivalence classes may lead to improved perfor-
mance on other tasks, such as multi-participant vo-
cal activity detection.
Acknowledgments
We would like to thank Jean Carletta for help-
ful comments during the final preparation of this
manuscript, and Liz Shriberg for access to the ICSI
MRDA Corpus.
References
R. Bales. 1950. Interaction Process Analysis. Addison-
Wesley Press, Inc.
S. Banerjee and A. Rudnicky. 2004. Using simple speech
based features to detect the state of a meeting and
the roles of the meeting participants. Proc. INTER-
SPEECH, pp.2189-2192.
J. Berger, S. Rosenholtz, M. Zelditch Jr. 1980. Status
Organizing Processes. Annual Review of Sociology,
6:479-508.
J. Carletta, S. Garrod, and H. Fraser-Krauss. 1998. Com-
munication and placement of authority in workplace
groups ? The consequences for innovation. Small
Group Research, 29(5):531-559.
J. Carletta. 2007. Unleashing the killer corpus: Expe-
riences in creating the multi-everything AMI Meeting
Corpus. Language Resources and Evaluation Journal,
41(2):181?190.
A. Janin, D. Baron, J. Edwards, D. Ellis, D. Gelbart, N.
Morgan, B. Peskin, T. Pfau, E. Shriberg, A. Stolcke,
and C. Wooters. 2003. The ICSI Meeting Corpus.
Proc. ICASSP, pp.364?367.
K. Laskowski, M. Ostendorf, and T. Schultz. 2007. Mod-
eling vocal interaction for text-independent classifica-
tion of conversation type. Proc. SIGdial, pp.194-201.
K. Laskowski, C. Fu?gen, and T. Schultz. 2007. Simulta-
neous multispeaker segmentation for automatic meet-
ing recognition. Proc. EUSIPCO, pp.1294-1298.
A. Norwine and O. Murphy. 1938. Characteristic time
intervals in telephonic conversation. Bell System Tech-
nical Journal, 17:281-291.
R. Rienks and D. Heylen. 2005. Dominance detection
in meetings using easily obtainable features. Proc.
MLMI.
R. Rienks, D. Zhang, D. Gatica-Perez, and W. Post.
2006. Detection and application of influence rankings
in small-group meetings. Proc. ICMI.
J. Rotman. 1995. An Introduction to the Theory of
Groups. Springer-Verlag New York, Inc.
E. Shriberg, R. Dhillon, S. Bhagat, J. Ang, and H. Car-
vey. 2004. The ICSI Meeting Recorder Dialog Act
(MRDA) Corpus. Proc. SIGdial, pp.97?100.
D. Tannen. 1996. Gender & Discourse. Oxford Univer-
sity Press, USA.
A. Vinciarelli. 2007. Speakers role recognition in mul-
tiparty audio recordings using social network analysis
and duration distribution modeling. IEEE Trans. Mul-
timedia, 9(6):1215-1226.
D. Wyatt, J. Bilmes, T. Choudhury, and H. Kautz.
2007. A privacy-sensitive approach to modeling
multi-person conversations. Proc. IJCAI, pp.1769?
1775.
M. Zancanaro, B. Lepri, and F. Pianesi. 2006. Automatic
detection of group functional roles in face to face in-
teractions. Proc. ICMI.
155
