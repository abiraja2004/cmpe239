ON THE EXISTENCE OF PRIMITIVE MEANING UNITS 
Sharon C. Salveter 
Computer Science Department 
SUNY Stony Brook 
Stony Brook, N.Y. 11794 
ABSTRACT 
Knowledge representation schemes are either based on 
a set of primitives or not. The decision of whether 
or not to have a primitive-based scheme is crucial 
since it affects the knowledge that is stored and how 
that knowledge may be processed. We suggest that a 
knowledge representation scheme may not initially have 
primitives, but may evolve into a prlmltive-based 
scheme by inferring a set of primitive meaning units 
based on previous experience. We describe a program 
that infers its own primitive set and discuss how the 
inferred primitives may affect the organization of 
existing information and the subsequent incorporation 
of new information. 
i. DECIDING HOW TO REPRESENT KNOWLEDGE 
A crucial decision in the design of a knowledge repre- 
sentation is whether to base it on primitives. A prim- 
itive-based scheme postulates a pre-defined set of mean- 
ing structures, combination rules and procedures. The 
primitives may combine according to the rules into more 
complex representational structures, the procedures 
interpret what those structures mean. A primltive-free 
scheme, on the other hand, does not build complex struc- 
tures from standard building blocks; instead, informa- 
tion is gathered from any available source, such as 
input and information in previously built meaning 
structures. 
A hybrid approach postulates a small set of pro-defined 
meaning units that may be used if applicable and con- 
venient, but is not limited to those units. Such a 
representation scheme is not truly prlmitive-based 
since the word "primitive" implies a complete set of 
pre-deflned meaning units that are the onl 7 ones avail- 
able for construction. However, we will call this hy- 
brid approach a primitive-based scheme, since it does 
postulate some pro-defined meaning units that are used 
in the same manner as primitives. 
2. WHAT IS A PRIMITIVE? 
All representation systems must have primitives of some 
sort, and we can see different types of primitives at 
different levels. Some primitives are purely structural 
and have little inherent associated semantics. That is, 
the primitives are at such a low level that there are 
no semantics pre-deflned for the primitives other than 
how they may combine. We call these primitives struc- 
tural primitives. On the other hand, semantic primi- 
tives have both structural and semantic components. 
The structures are defined on a higher level and come 
with pre-attached procedures (their semantics) that 
indicate what they "mean," that is, how they are to be 
meaningfully processed. What makes primitives semantic 
is this association of procedures with structures, since 
the procedures operating on the structures give them 
meaning. In a primitive-based scheme, we design both 
a set of structures and their semantics to describe a 
specific environment. 
There are two problems with pre-defining primitives. 
First, the choice of primitives may be structurally 
inadequate. That is, they may limit what can be repre- 
sented. For example, if we have a set of rectilinear 
primitives, it is difficult to represent objects in a 
sphere world. The second problem may arise even if we 
have a structurally adequate set of primitives. I_n this 
case the primitives may be defined on too low a level 
to be useful. For example, we may define atoms as our 
primitives and specify how atoms interact as their 
semantics. Now we may adequately describe a rubber ball 
structurally, hut we will have great difficulty describ- 
ing the action of a rolling ball. We would like a set 
of semantic primitives at a level both structurally and 
semantically appropriate to the world we are describing. 
3. INFERRING AN APPROPRIATE PRIMITIVE SET 
Schank \[1972\] has proposed a powerful primitive-based 
knowledge representation scheme called conceptual 
dependency. Several natural language understanding 
programs have been written that use conceptual depend- 
ency as their underlying method of knowledge represen- 
tation. These programs are among the most successful 
at natural language understanding. Although Schank 
does not claim that his primitives constitute the only 
possible set, he does claim that some set of primitives 
is necessary in a general knowledge representation 
scheme. 
Our claim is that any advanced, sophisticated or rich 
memory is likely to be decomposable into primitives, 
since they seem to be a reasonable and efficient method 
for storing knowledge. However, this set of after-the- 
fact primitives need not be pre-defined or innate to 
a representation scheme; the primitives may be learned 
and therefore vary depending on early experiences. 
We really have two problems: inferring from early 
experiences a set of structural primitives at an appro- 
priate descriptive level and learning the semantics to 
associate with these structural primitives. In this 
paper we shall only address the first problem. Even 
though we will not address the semantics attachment 
task, we will describe a method that yields the minimal 
structural units with which we will want to associate 
semantics. We feel that since the inferred structural 
primitives will be appropriate for describing a par- 
titular environment, they will have appropriate seman- 
tics and that unlike pro-defined primitives, these 
learned primitives are guaranteed to be at the appro- 
priate level for a given descriptive task. Identify- 
ing the structural primitives is the first step (prob- 
ably a parallel step) in identifylng semantic primi- 
tives, which are composed of structural units and 
associated procedures that 81ve the structures meaning. 
This thesis developed while investigating learning 
strategies. Moran \[Salveter 1979\] is a program that 
learns frame-like structures that represent verb mean- 
ings. We chose a simple representative frame-like 
knowledge representation for Moran to learn. We chose 
a primitive-free scheme in order not to determine the 
level of detail at which the world must be described. 
As Moran learned, its knowledge base, the verb world, 
evolved from nothing to a rich interconnection of frame 
structures that represent various senses of different 
root verbs. When the verb world was "rich enough" (a 
heuristic decision), Moran detected substructures, 
which we call building blocks, that were frequently 
used in the representations of many verb senses across 
root verb boundaries. These building blocks can be 
used as after-the-fact primitives. The knowledge 
representation scheme thus evolves from a primitive- 
free state to a hybrid state. Importantly, the build- 
ing blocks are at the level of description appropriate 
13 
Co how the world was described to Moran. Now Mor~ may 
reorganize the interconnected frames that  make up the 
verb world with respect  co the bui ld ing blocks. This 
reorganizaclon renulcs in a uniform identification of the 
co - -a l le les  and differences of  the various meanings 
of different root: verbs. As l enrning continues the new 
knowledge incorporated into the verb world will also be 
scored, as ,-~ch as possible, with respect to the build- 
ins blocks; when processing subsequent input, Moran 
first tries to use a on~inat lon of the building blocks 
to represent the meaning of each new situation iC 
encoiJ~Cer8 ? 
A sac of bui lding blocks, once in fer red ,  need noc be 
f ixed forever;  the search for more bui ld ing blocks may 
continue as the knowledge base becomes r icher .  A 
different, "better," set of bui ld ing blocks may be in- 
ferred later from the richer knowledge and all knowledge 
reorganized with respect to them. If we can assume that 
initial inputs are representaClve of future inputs, 
subsequent processing will approach that of primitive- 
based systems. 
4. AN OVERVIEW OF MORAN 
Moran is able to "view" a world that is a room; the 
room Contains people and objects ,  Moran has pre-def ined 
knowledge of the contents of the room. For exan~le, i t  
knows chac lamps, cables and chairs are all types of 
furniture, Figaro is a male, Ristin is a female, Eistin 
and Figaro are human. As input to a learning crlal, 
Moran is presented with: 
i) a snapshot of the room Just before an action 
oct%tEn 
2) a snapshot o f  tbe room Just  a f te r  the ac t ion  is  
completed end 
3) a parsed sentence thac descr ibes the action thac 
occured in the two-snapshot sequence. 
The learning task is to associate a frame-like structure, 
cal led a Conceptual Meaning Structure (CMS), with each 
root verb it enco,mcers. A CMS is a directed acyclic 
graph that represents the types of entities chat partic- 
ipate in an action and the changes the entities undergo 
during the action. 
The ~s  are organized so thac the similarities among 
various senses of a given root verb are expllcicly rep- 
resented b 7 sharing nodes in a graph. A CMS is organ- 
i zed  into two par~s: an ar~,-~-cs graph and an effects 
graph. The arguments graph stores cases and case slot 
restrictions, the effects graph stores a description of 
what happens co the entities described in the arg,,m~,~Cs 
graph when an action "takes place." 
A sin~llfled example of a possible ~S for the verb 
"throw" is shown in Figure i. Sense i, composed of argu- 
ment and e f fec t  nodes label led A, W and X can represent  
'~kr 7 throws the ba l l . "  Ic show thac during sense 1 of 
the actlan "throw," a human agent remains at a location 
while a physical object changes location from where the 
Agent is to another location. The Agent changes from 
being in a stare of physical contact with the Object co 
not being in physical contact with ic. Sense 2 is com- 
posed of nodes labelled A, B, W and Y; It might repre- 
sent "Figaro throws the ball co E-Istin." Sense 3, com- 
posed of nodes label led A, B, C, W, X and Z, could rep-  
resent  "Sharon threw the terminal  at Raphael." 
Mor~- infers a CMS for each root verb it encotmters. 
Although similarlt~'es among different senses of the 
same root verb are recognized, similarities are noC 
recognized across C~S boundaries; true synonyms might 
have id~- t l ca l  graphs, but Moran would have no knowledge 
arguments 
~ 1,2,3 
.TECT PhysobJ 
A: Location 
|C2 Location 
2,3 
B: ! PREP  Prespos i t i~  
I~O~ ~,,m. | 
c: Ic3 Locat ion  J 
W: 
X: \[ AGENT PHYSCONT OBJECT - ->  null I 
ef fec ts  
1,2,3 
I AGENT AT Cl - ->  AGENT AT C1 I 
OBJECT AT Cl ~> OBJECT AT C2 
I i ,3  ,~ 2 
I I~DOBJ AT C2 - - ->  INDO~ AT C2 
Y: AGENT PHYSCONT OBJECT - - ->  INDOBJ PHYSCONT OBJECT 
Figure 1. 
14 
of the similarity. Similarities among verbs that are 
close in meaning, but not synonyms, are not represented; 
the fact that "move" and "throw" are related is not ob- 
vious to Moran. 
5. PRELIMINARY RESULTS 
A primitive meaning unit, or building block, should be 
useful for describing a large number of different mean- 
ings. Moran attempts to identify those structures that 
have been useful descriptors. At a certain point in the 
learning process, currently arbitrarily chosen by the 
h.m;un trainer, Moran looks for building blocks that have 
been used to describe a number of different root verbs. 
This search for building blocks crosses CMS boundaries 
and occurs only when memory is rich enough for some 
global decisions to be made. 
Moran was presented with twenty senses of four root 
verbs: move, throw, carry and buy. Moran chose the 
following effects as building blocks: 
i) Agent (h,,~--) AT Casel (location) 
Agent (human) AT Casel (location) 
* a human agent remains at a location * 
2) Agent (human) AT Casel (location) 
$ 
Agent (human) AT Case2 (location) 
* a human agent changes location * 
3) Object (physicalobj) AT Casel (location) 
1, 
Object (physicalobj) AT Case2 (location) 
* a physical object changes location * 
4) Agent (human) PHYSICALCONTACT Object (physlcalobJ) 
Agent (human) PHYSICALCONTACT Object (physicalobJ) 
* a human agent remains in physical con=at= 
with a physical object * 
Since Moran has only been presented with a small number 
of verbs of movement, it is not surprising that the 
building blocks it chooses describe Agents and Objects 
moving about the environmen= and their interaction with 
each other. A possible criticism is that the chosen 
building blocks are artifacts of the particular descrlp- 
tions that were given to Moran. We feel this is an 
advantage rather than a drawback, since Moran must as- 
sume that the world is described to it on a level that 
will be appropriate for subsequent processing. 
In Schank's conceptual dependency scheme, verbs of move- 
ment are often described with PTRANS and PROPEL. ~t is 
interesting that some of the building blocks Moran in- 
ferred seem to be subparts of the structures of PTRANS 
and PROPEL. For example, the conceptual dependency for 
"X throw Z at Y" is: 
) Y | D X~--) PROPEL +.S- Z ( J 
! (X 
where X and Y are b,,m"ns and Z is a physical object. 
see the object, Z, changing from the location of X to 
that of Y. Thus, the conceptual dependency subpart: 
We 
) <o z <D J 
appears to be approximated by building block ~3 where 
the Object changes location. Moran would recoEnize 
that the location change is from the location of the 
Agent to the location of the indirect object by the 
interaction of building block #3 with other buildlng 
blocks and effects that participate in the action 
description. 
Similarly, the conceptual dependency for "X move Z to 
W" is : 
z<~)ioc(w) 
where X and Z have the same restrictions as above and 
W is a location. Again we see an object changing loca- 
tion; a co,~-on occuzence in movement and a building 
block Moran identified. 
6. CONCLUDING REMARKS 
We are currently modifying Moran so that the identified 
building blocks are used to process subsequent input. 
That is, as new situations are encountered, Moran will 
try to describe them as much as possible in terms of 
the building blocks. It will be interesting to see 
how these descriptions differ from the ones Moran would 
have constructed if the building blocks had not been 
available. We shall also investigate how the existence 
of the building blocks affects processing time. 
As a cognitive model, inferred primitives may account 
for the effects of "bad teaching," that is, an unfor- 
tunate sequence of examples of a new concept. If ex- 
amples are so disparate that few building blocks exist, 
or so unrepresentative that the derived building blocks 
are useless for future inputs, then the after-the-fact 
primitives will impede efficient representation. The 
knowledge organization will not tie together what we 
have experienced in the past or predict that we will 
experience in the future. Although the learning pro- 
gram could infer more useful building blocks at a later 
timeg that process is expensive, time-consuming and may 
be unable to replace information lost because of poor 
building blocks chosen earlier. In general, however, 
we must assume that our world is described at a level 
appropriate to how we must process it. If that is the 
case, then inferring a set of primitives is an advanta- 
geous strateEy. 
REFERENCES 
\[Salveter 1979\] Inferring conceptual graphs. Co~nltive 
Science, 1979, 3_, 141-166. 
\[Schank 1972\] Conceptual Dependency: a theory of 
natural language understanding. Cobnitive 
Psychology, 1972, ~, 552-631. 
15 

