Allen, M., Fritzsche, P., 2011, Reinforcement Learn-
ing with Adaptive Kanerva Encoding for Xpilot
Game AI, Annual Congress on Evolutionary Com-
putation, pp 1521?1528.
Atkeson, C.G., Santamaria, J.C., 1997, A comparison
of direct and model-based reinforcement learning,
IEEE Robotics and Automation, pp 3557?3564.
Bagnell, J., Schneider, J., 2003, Covariant pol-
icy search, Proceedings of the Eighteenth Interna-
tional Joint Conference on Artificial Intelligence, pp
1019?1024.
Bertsekas D.P., 2007, Dynamic Programming and
Optimal Control, Athena Scientific, vol 2, 3rd edi-
tion.
Bhatnagar, S, Sutton, R.S., Ghavamzadeh, M., Lee,
M. 2007, Incremental Natural Actor-Critic Algo-
rithms, Neural Information Processing Systems, pp
105?112.
Bohus, D., Rudnicky, A.I., 2009, The RavenClaw di-
alog management framework: Architecture and sys-
tems, Computer Speech & Language, vol 23:3, pp
332-361.
Boidin, C., Rieser, V., Van Der Plas, L., Lemon, O.,
and Chevelu, J. 2009, Predicting how it sounds:
Re-ranking dialogue prompts based on TTS qual-
ity for adaptive Spoken Dialogue Systems, Pro-
ceedings of the Interspeech Special Session Ma-
chine Learning for Adaptivity in Spoken Dialogue,
pp 2487?2490.
Chen, S-L., Wei, Y-M. 2008, Least-Squares
SARSA(Lambda) Algorithms for Reinforcement
Learning, Natural Computation, 2008. ICNC ?08,
vol.2, pp 632?636.
Cuaya?huitl, H., Renals, S., Lemon, O., Shimodaira,
H. 2010, Evaluation of a hierarchical reinforce-
ment learning spoken dialogue system, Computer
Speech & Language, Academic Press Ltd., vol 24:2,
pp 395?429.
Gas?ic?, M., Jurc???c?ek, F., Keizer, S., Mairesse, F.
and Thomson, B., Yu, K. and Young, S, 2010,
Gaussian processes for fast policy optimisation of
POMDP-based dialogue managers, Proceedings
of the 11th Annual Meeting of the Special Interest
Group on Discourse and Dialogue, pp 201?204.
Geist, M., Pietquin, O., 2010, Kalman temporal
differences, Journal of Artificial Intelligence Re-
search, vol 39:1, pp 483?532.
Janarthanam, S., Lemon, O. 2009, A Two-Tier User
Simulation Model for Reinforcement Learning of
Adaptive Referring Expression Generation Policies,
SIGDIAL Conference?09, pp 120?123.
Jurc???c?ek, F., Thomson, B., Keizer, S., Mairesse, F.,
Gas?ic?, M., Yu, K., Young, S 2010, Natural Belief-
Critic: A Reinforcement Algorithm for Parameter
Estimation in Statistical Spoken Dialogue Systems,
International Speech Communication Association,
vol 7, pp 1?26.
Konda, V.R., Tsitsiklis, J.N., 2001, Actor-Critic Al-
gorithms, SIAM Journal on Control and Optimiza-
tion, MIT Press, pp 1008?1014.
Konstantopoulos S., 2010, An Embodied Dialogue
System with Personality and Emotions, Proceedings
of the 2010 Workshop on Companionable Dialogue
Systems, ACL 2010, pp 3136.
Papangelis, A., Karkaletsis, V., Makedon, F., 2012,
Evaluation of Online Dialogue Policy Learning
Techniques, Proceedings of the 8th Conference on
Language Resources and Evaluation (LREC) 2012,
to appear.
Peng, J., Williams, R., 1996, Incremental multi-step
Q-Learning, Machine Learning pp 283?290.
Peters, J., Vijayakumar, S., Schaal, S. 2005, Natural
actor-critic , Machine Learning: ECML 2005, pp
280?291.
Pietquin, O., Hastie H. 2011, A survey on metrics for
the evaluation of user simulations, The Knowledge
Engineering Review, Cambridge University Press
(to appear).
Rieser, V., Lemon, O. 2009, Natural Language Gen-
eration as Planning Under Uncertainty for Spoken
Dialogue Systems, Proceedings of the 12th Confer-
ence of the European Chapter of the ACL (EACL
2009), pp 683?691.
Ross, S., Pineau, J., Paquet, S., Chaib-draa, B., 2008,
Online planning algorithms for POMDPs, Journal
of Artificial Intelligence Research, pp 663?704.
Sutton R.S., Barto, A.G., 1998, Reinforcement Learn-
ing: An Introduction, The MIT Press, Cambridge,
MA.
Sutton, R.S.,Mcallester, D., Singh, S., Mansour, Y.
2000, Policy gradient methods for reinforcement
learning with function approximation, In Advances
in Neural Information Processing Systems 12, pp
1057?1063.
Szepesva?ri, C., 2010, Algorithms for Reinforcement
Learning, Morgan & Claypool Publishers, Synthe-
sis Lectures on Artificial Intelligence and Machine
Learning, vol 4:1, pp 1?103.
Watkins C.J.C.H., 1989, Learning from delayed re-
wards, PhD Thesis, University of Cambridge, Eng-
land.
Wiering, M. A, Van Hasselt, H. 2009, The QV
family compared to other reinforcement learning
algorithms, IEEE Symposium on Adaptive Dy-
namic Programming and Reinforcement Learning,
pp 101?108.
Young S., Gas?ic?, M., Keizer S., Mairesse, F., Schatz-
mann J., Thomson, B., Yu, K., 2010, The Hid-
den Information State model: A practical frame-
work for POMDP-based spoken dialogue manage-
ment, Computer Speech & Language, vol 24:2, pp
150?174.