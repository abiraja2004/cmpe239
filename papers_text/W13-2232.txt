Proceedings of the Eighth Workshop on Statistical Machine Translation, pages 252?261,
Sofia, Bulgaria, August 8-9, 2013 c?2013 Association for Computational Linguistics
Online Polylingual Topic Models for Fast Document Translation Detection
Kriste Krstovski
School of Computer Science
University of Massachusetts Amherst
Amherst, MA, 01003
kriste@cs.umass.edu
David A. Smith
School of Computer Science
University of Massachusetts Amherst
Amherst, MA, 01003
dasmith@cs.umass.edu
Abstract
Many tasks in NLP and IR require ef-
ficient document similarity computations.
Beyond their common application to ex-
ploratory data analysis, latent variable
topic models have been used to represent
text in a low-dimensional space, indepen-
dent of vocabulary, where documents may
be compared. This paper focuses on the
task of searching a large multilingual col-
lection for pairs of documents that are
translations of each other. We present
(1) efficient, online inference for repre-
senting documents in several languages in
a common topic space and (2) fast ap-
proximations for finding near neighbors in
the probability simplex. Empirical evalu-
ations show that these methods are as ac-
curate as?and significantly faster than?
Gibbs sampling and brute-force all-pairs
search.
1 Introduction
Statistical topic models, such as latent Dirich-
let alocation (LDA) (Blei et al, 2003), have
proven to be highly effective at discovering hid-
den structure in document collections (Hall et al,
2008, e.g.). Often, these models facilitate ex-
ploratory data analysis, by revealing which col-
locations of terms are favored in different kinds
of documents or which terms and topics rise and
fall over time (Blei and Lafferty, 2006; Wang and
McCallum, 2006). One of the greatest advan-
tages in using topic models to analyze and process
large document collections is their ability to rep-
resent documents as probability distributions over
a small number of topics, thereby mapping doc-
uments into a low-dimensional latent space?the
T -dimensional probability simplex, where T is the
number of topics. A document, represented by
some point in this simplex, is said to have a par-
ticular ?topic distribution?.
Representing documents as points in a low-
dimensional shared latent space abstracts away
from the specific words used in each document,
thereby facilitating the analysis of relationships
between documents written using different vocab-
ularies. For instance, topic models have been used
to identify scientific communities working on re-
lated problems in different disciplines, e.g., work
on cancer funded by multiple Institutes within the
NIH (Talley et al, 2011). While vocabulary mis-
match occurs within the realm of one language,
naturally this mismatch occurs across different
languages. Therefore, mapping documents in dif-
ferent languages into a common latent topic space
can be of great benefit when detecting document
translation pairs (Mimno et al, 2009; Platt et al,
2010). Aside from the benefits that it offers in the
task of detecting document translation pairs, topic
models offer potential benefits to the task of creat-
ing translation lexica, aligning passages, etc.
The process of discovering relationship be-
tween documents using topic models involves: (1)
representing documents in the latent space by in-
ferring their topic distributions and (2) comparing
pairs of topic distributions to find close matches.
Many widely used techniques do not scale ef-
ficiently, however, as the size of the document
collection grows. Posterior inference by Gibbs
sampling, for instance, may make thousands of
passes through the data. For the task of comparing
topic distributions, recent work has also resorted
to comparing all pairs of documents (Talley et al,
2011).
This paper presents efficient methods for both
252
of these steps and performs empirical evaluations
on the task of detected translated document pairs
embedded in a large multilingual corpus. Unlike
some more exploratory applications of topic mod-
els, translation detection is easy to evaluate. The
need for bilingual training data in many language
pairs and domains also makes it attractive to mit-
igate the quadratic runtime of brute force transla-
tion detection. We begin in ?2 by extending the
online variational Bayes approach of Hoffman et
al. (2010) to polylingual topic models (Mimno et
al., 2009). Then, in ?3, we build on prior work
on efficient approximations to the nearest neighbor
problem by presenting theoretical and empirical
evidence for applicability to topic distributions in
the probability simplex and in ?4, we evaluate the
combination of online variational Bayes and ap-
proximate nearest neighbor methods on the trans-
lation detection task.
2 Online Variational Bayes for
Polylingual Topic Models
Hierarchical generative Bayesian models, such as
topic models, have proven to be very effective
for modeling document collections and discover-
ing underlying latent semantic structures. Most
current topic models are based on Latent Dirich-
let Allocation (LDA) (Blei et al, 2003). In some
early work on the subject, Blei and Jordan (2003)
showed the usefulness of LDA on the task of auto-
matic annotation of images. Hall et al (2008) used
LDA to analyze historical trends in the scientific
literature; Wei and Croft (2006) showed improve-
ments on an information retrieval task. More re-
cently Eisenstein et al (2010) modeled geographic
linguistic variation using Twitter data.
Aside from their widespread use on monolin-
gual text, topic models have also been used to
model multilingual data (Boyd-Graber and Blei,
2009; Platt et al, 2010; Jagarlamudi and Daume?,
2010; Fukumasu et al, 2012), to name a few.
In this paper, we focus on the Polylingual Topic
Model, introduced by Mimno et al (2009). Given
a multilingual set of aligned documents, the PLTM
assumes that across an aligned multilingual doc-
ument tuple, there exists a single, tuple-specific,
distribution across topics. In addition, PLTM as-
sumes that for each language?topic pair, there ex-
ists a distribution over words in that language ?l.
As such, PLTM assumes that the multilingual cor-
pus is created through a generative process where
D T
T
...
D
wz
N1
wz
NL
...
1E
LE
1K
LK
Figure 1: Polylingual topic model (PLTM)
first a document tuple is generated by drawing a
tuple-specific distribution over topics ?1 which, as
it is the case with LDA, is drawn from a Dirich-
let prior ? ? Dir (?) . For each of the languages
l in the tuple and for each of the N words wln in
the document the generative process: first chooses
a topic assignment zln ?Multinomial (?) which
is then followed by choosing a word wln from a
multinomial distribution conditioned on the topic
assignment and the language specific topics distri-
bution over words ?l?Dir (?l). Both? and ?1,...,L
are symmetric priors, i.e. the priors are exchange-
able Dirichlet distributions. Finally, each word
is generated from a language- and topic-specific
multinomial distribution ?lt as selected by the topic
assignment variable zln:
wln ? p
(
wln | zln, ?ln
)
(1)
Figure 1 shows a graphical representation of
the PLTM using plate notation. In their original
work Mimno et al (2009) used the Gibbs sam-
pling approach as a posterior inference algorithm
to assign topics distributions over their test collec-
tion. While more straightforward to implement,
this sampling approach is inherently slow when
applied to large collections which makes the orig-
inal PLTM work practically infeasible to be used
on real-world data sets.
In general, performing posterior inference over
the latent variables of a Bayesian model is usu-
ally done with two of the three approximate ap-
proaches, Gibbs sampling, variational Bayes (VB)
and expectation-propagation. While Gibbs Sam-
pling is a variation of Markov Chain Monte Carlo
method (MCMC) which generates a sample from
the true posterior after converging to a stationary
1In the traditional LDA model ? is used to specify the
document specific distribution over topics.
253
distribution; in VB, a set of free variational param-
eters characterizes a simpler family of probabil-
ity distributions. These variational parameters are
then optimized by finding the minimum Kullback-
Leibler (KL) divergence between the variational
distribution q (?, z, ?|?, ?, ?) and the true pos-
terior P (?, z, ?|w,?, ?). From an algorithmic
perspective, the variational Bayes approach fol-
lows the Expectation-Maximization (EM) proce-
dure where for a given document, the E-step up-
dates the per document variational parameters ?d
and ?d while holding the per words-topic distribu-
tion parameter ? fixed. It then updates the vari-
ational parameter ? using the sufficient statistics
computed in the E step. In order to converge to
a stationary point, both approaches require going
over the whole collection multiple times which
makes their time complexity to grown linearly
with the size of the data collection. The mere fact
that they require continuous access to the whole
collection makes both inference approaches im-
practicable to use on very large or streaming col-
lections. To alleviate this problem, several algo-
rithms have been proposed that draws from belief
propagation (Zeng et al, 2012), the Gibbs sam-
pling approach such as (Canini et al, 2009), vari-
ational Bayes (Hoffman et al, 2010) as well as
a combination of the latter two (Hoffman et al,
2012) to name a few. In this paper we use Hoff-
man et al (2010) approach. Hoffman et al (2010)
proposed a new inference approach called Online
LDA which relies on the stochastic gradient de-
scent to optimize the variational parameters. This
approach can produce good estimates of LDA pos-
teriors in a single pass over the whole collection.
2.1 Algorithmic Implementation
We now derive an online variational Bayes algo-
rithm for PLTM to infer topic distributions over
multilingual collections. Figure 2 shows the vari-
ational model and free parameters used in our ap-
proach. As in the case of Hoffman et al (2010),
our algorithm updates the variational parameters
?ld and ?ld on each batch of documents while the
variational parameter ? is computed as a weighted
average of the value on the previous batch and its
approximate version ??. Averaging is performed
using a decay function whose parameters control
the rate at which old values of ?l are forgotten.
Within the E step of the VB approach, we com-
pute the updates over the variational parameter ?l
T
. . .
D
T z
N1
z
NL
. . .
J 1I LI
1E LE
1O LO
Figure 2: Graphical model representation of the
free variational parameters for the online varia-
tional Bayes approximation of the PLTM posterior
for each language L present in our document tuple
while the update on the ? parameter accumulates
the language specific sufficient statistics:
?mk = ?+
?
l
?
w
?mlwk nmlw (2)
We detail these steps in Algorithm 1.
2.2 Performance Analysis
To demonstrate the efficacy of online PLTM, we
ran topic inference on a subset of the English-
Spanish Europarl collection consisting of ?64k
parallel speeches and compared the accuracy re-
sults vs. the training and inference speed against
the original PLTM model using topic sets of
T=50,100, 200 and 500. We explain in details
the evaluation task and the performance metric
used in ?4. Shown in Figure 3 are the results of
these comparisons. Our speed measurements were
performed on Xeon quad processors with a clock
speed of 2.66GHz and a total of 16GB of memory.
As we increase the number of topics we gain in
accuracy over the evaluation task across both in-
ference approaches. When we increase the num-
ber of topics from 50 to 500 the speed improve-
ment obtained by Online VB PLTM drops by a
factor of 2.9 within the training step and by a
factor of 4.45 in the test step. Our total running
time for the Online VB PLTM with T=500 ap-
proaches the running time of the Gibbs sampling
approach with T=50. The gradual drop in speed
improvement with the increase of the number top-
ics is mostly attributed to the commutation of the
254
Algorithm 1 Online variational Bayes for PLTM
initialize ?l randomly
obtain the tth mini-batch of tuples Mt
for t = 1 to ? do
?t ?
(
1
t0+t
)?
E step:
initialize ?t randomly
for each document tuple in mini-batch t
for m in Mt do
repeat
for l ? 1, . . . ,L do
?mlwk ?
exp {Eq [log ?mk ]} ?
exp
{
Eq
[
log ?mlkw
]}
end for
?mk = ?+
?
l
?
w ?mlwk nmlwuntil convergence
end for
M step:
for l ? 1, . . . ,L do
??lkw = ? +D
?
m ?mlwknmlw
?ltkw ? (1? ?t)?
l(t?1)
kw + ?t??lkwend for
end for
0 2000 4000 6000 8000 10000 12000
0
10
20
30
40
50
60
70
80
90
100
A
cc
ur
ac
y 
[%
 @
 R
an
k 1
.]
Running time [sec]
Accuracy vs. Running time
 
 
Gibbs sampling
Online VB
T=50
T=100
T=200 T=500 T=500T=200T=100
T=50
Figure 3: Speed vs. accuracy comparison between
Online VB PLTM and Gibbs Sampling PLTM at
T=50,100, 200 and 500. We used a Python imple-
mentation of Online VB and Mallet?s Java imple-
mentation of PLTM with in-memory Gibbs Sam-
pling using 1000 iterations.
0 50 100 250 500 750 1,000
0
20,000
40,000
60,000
80,000
100,000
120,000
140,000
160,000
180,000
200,000
Collection size [k]
Tr
ai
ni
ng
 ti
m
e 
[se
c]
Collection size vs. training time
 
 
Gibbs sampling T=50
Online VB T=50
Gibbs sampling T=500
Online VB T=500
Figure 4: Collection size vs. training time compar-
ison between Online VB PLTM and Gibbs Sam-
pling PLTM using multilingual collections of 50k,
100k, 250k, 500k, 750k and 1M speech pairs.
digamma function (Asuncion et al, 2009) whose
time complexity increases linearly with the num-
ber of topics.
While a multilingual collection of ?64k docu-
ment pairs is considered relatively big, our goal
of deriving the Online VB PLTM approach was to
be able to utilize PLTM on very large multilingual
collections. To analyze the potential of using On-
line VB PLTM on such collections we ran speed
comparisons within the training step by creating
multilingual collections of different lengths multi-
plying the original English-Spanish Europarl col-
lection. Speed comparisons using collections of
length 50K, 100K, 250K, 500K, 750K and 1M are
shown in Figure 4. Training was performed with
the number of topics T set to T=50 and T=500.
As we increase the collection size we observe
the real benefit of using Online VB compared to
Gibbs sampling. This is mostly attributed to the
fact that the Gibbs sampling approach requires
multiple iterations over the whole collection in or-
der to achieve a convergence point. For collec-
tion sizes of 50k and 100k the training time for
the Online VB PLTM with T=500 approaches the
training time of Gibbs sampling with T=50 and as
we increase the collection size this proximity dis-
sipates.
In Figure 5 we show a sample set of the aligned
topics extracted using Online VB PLTM with
T=400 on the English-Spanish Europarl collec-
tion. For a given topic tuple words are ordered
based on probability of occurrence within the
given topic.
255
	




	



	

	

	


 
 

	

	
	
	
	

!

	

	



	

"
	#


"	#
	





	


	$

%
	 
	






"




	 %

	 	
&
 
	


 	#
	



&
	#
	#
	 
	




&




 



	 
	
	

$










$



 








 
%
	




	!


	




	

			






'
(

	
%
	)	
"
%


	 


 
	







	










%




	

 



	

	#



		

 !

	#
		
	

!




(

 !
	

		



(

(
!

	








&
	#

"#


*












&



"






%	
	

Figure 5: Sample set of topics extracted from Europarl English-Spanish collection of 64k speeches using
Online PLTM with T=400 ordered based on their probability of occurrence within the topic.
3 Approximate NN Search in the
Probability Simplex
One of the most attractive applications for topic
models has involved using the latent variables as
a low-dimensional representation for document
similarity computations (Hall et al, 2008; Boyd-
Graber and Resnik, 2010; Talley et al, 2011). Af-
ter computing topic distributions for documents,
however, researchers in this line of work have al-
most always resorted to brute-force all-pairs simi-
larity comparisons between topic distributions.
In this section, we present efficient methods for
approximate near neighbor search in the proba-
bility simplex in which topic distributions live.
Measurements for similarity between two proba-
bility distributions are information-theoretic, and
distance metrics, typical for the metric space, are
not appropriate (measurements such as Euclidean,
cosine, Jaccard, etc.). Divergence metrics, such as
Kullback-Leibler (KL), Jensen-Shannon (JS), and
Hellinger distance are used instead. Shown in Fig-
ure 6 are the formulas of the divergence metrics
along with the Euclidean distance. When dealing
with a large data set of N documents, the O(N2)
time complexity of all-pairs comparison makes the
task practically infeasible. With some distance
measures, however, the time complexity on near
neighbor tasks has been alleviated using approxi-
mate methods that reduce the time complexity of
each query to a sub-linear number of comparisons.
For example, Euclidean distance (3) has been effi-
ciently used on all-pairs comparison tasks in large
data sets thanks to its approximate based versions
developed using locality sensitive hashing (LSH)
(Andoni et al, 2005) and k-d search trees (Fried-
man et al, 1977). In order to alleviate the all-pairs
computational complexity in the probability sim-
plex, we will use a reduction of the Hellinger di-
vergence measure (4) to Euclidean distance and
therefore utilize preexisting approximation tech-
niques for the Euclidean distance in the probability
simplex.
This reduction comes from the fact that both
measurements have similar algebraic expressions.
If we discard the square root used in the Euclidean
distance, Hellinger distance (4) becomes equiva-
lent to the Euclidean distance metric (3) between?pi and ?qi. The task of finding nearest neigh-
bors for a given point (whether in the metric space
or the probability simplex) involves ranking all
nearest points discovered and as such not com-
puting the square root function does not affect the
overall ranking and the nearest neighbor discov-
ery. Moreover, depending on its functional form,
the Hellinger distance is often defined as square
root over the whole summation. Aside from the
Hellinger distance, we also approximate Jensen-
Shannon divergence which is a symmetric ver-
sion of the Kullback-Liebler divergence. For the
JS approximation, we will use a constant factor
relationship between the Jensen-Shannon diver-
gence an Hellinger distance previously explored
by (Tops?e, 2000). More specifically, we will be
using its more concise form (7) also presented by
256
Eu(p, q) =
????
n?
i=1
(pi ? qi)2 (3)
He(p, q) =
n?
i=1
(?
p(xi)?
?
q(xi)
)2 (4)
KL(p, q) =
n?
i=1
p(xi) log
p(xi)
q(xi)
(5)
JS(p, q) = 12KL
(
p, p+ q2
)
+
1
2KL
(
q, p+ q2
)
(6)
1
2He(p, q) ? JS(p, q) ? 2 ln(2)He(p, q) (7)
Figure 6: Distance measures and bounds
(Guha et al, 2006). The constant factor relation-
ship provides us with the theoretical guarantees
necessary for this approximation.
In practice, we can often do much better than
this theoretical bound. Figure 7 shows the empiri-
cal relation of JS and Hellinger on a translation-
detection task. As will be described in ?4, we
computed the JS and Hellinger divergences be-
tween topic distributions of English and Spanish
Europarl speeches for a total of 1 million docu-
ment pairs. Each point in the figure represents
one Spanish-English document pair that might or
might not be translations of each other. In this
figure we emphasize the lower left section of the
plot where the nearest neighbors (i.e., likely trans-
lations) reside, and the relationship between JS
and Hellinger is much tighter than the theoretical
bounds and from pratical perspective as we will
show in the next section. As a summary for the
reader, using the above approaches, we will ap-
proximate JS divergence by using the Euclidean
based representation of the Hellinger distance. As
stated earlier, the Euclidean based representation
is computed using well established approximation
approaches and in our case we will use two such
approaches: the Exact Euclidean LSH (E2LSH)
(Andoni et al, 2005) and the k-d trees implemen-
tation within the Approximate Nearest Neighbor
(ANN) library (Mount and Arya, 2010).
0 0.02 0.04 0.06 0.08 0.1
0
0.02
0.04
0.06
0.08
0.1
0.12
0.14
0.16
0.18
0.2
H
el
lin
ge
r D
is
ta
nc
e
Jensen?Shannon Divergence
Hellinger
Upper bound
Lower Bound
Figure 7: Empirical evidence of the bounds pre-
sented in Eq. 7 on 1 million document pairs?
zoomed section where nearest neighbors reside.
The lower bound is He(p, q) = 12 ln(2)JS(p, q)
while the upper bound is He(p, q) = 2JS(p, q).
4 Efficient Approximate Translation
Detection
Mapping multilingual documents into a common,
language-independent vector space for the pur-
pose of improving machine translation (MT) and
performing cross-language information retrieval
(CLIR) tasks has been explored through vari-
ous techniques. Mimno et al (2009) introduced
polylingual topic models (PLTM), an extension of
latent Dirichlet alocation (LDA), and, more re-
cently, Platt et al (2010) proposed extensions of
principal component analysis (PCA) and proba-
bilistic latent semantic indexing (PLSI). Both the
PLTM and PLSI represent bilingual documents in
the probability simplex, and thus the task of find-
ing document translation pairs is formulated as
finding similar probability distributions. While
the nature of both works was exploratory, results
shown on fairly large collections of bilingual doc-
uments (less than 20k documents) offer convinc-
ing argument of their potential. Expanding these
approaches to much large collections of multilin-
gual documents would require utilizing fast NN
search for computing similarity in the probabil-
ity simplex. While there are many other proposed
approaches to the task of finding document trans-
lation pairs that represent documents in metric
space, such as Krstovski and Smith (2011) which
utilizes LSH for cosine distance, there is no evi-
dence that they yield good results on documents
of small lengths such as paragraphs and even sen-
257
tences.
In this section, we empirically show how to uti-
lize approaches that deal with representing docu-
ments in the probability simplex without a signif-
icant loss in accuracy while significantly improv-
ing the processing time. We use PLTM represen-
tations of bilingual documents. In addition, we
show how the results as reported by Platt et al
(2010) can be obtained using the PLTM represen-
tation with a significant speed improvement.
As in (Platt et al, 2010) and (Mimno et al,
2009) the task is to find document translation pairs
in a multilingual collection of documents by rep-
resenting documents in the probability simplex
and computing similarity between their probabil-
ity distribution representation across all document
pairs. For this experimental setup, accuracy is de-
fined as the number of times (in percentage) that
the target language document was discovered at
rank 1 (i.e. % @Rank 1.) across the whole test
collection.
4.1 Experimental Setup
We use Mallet?s (McCallum, 2002) implementa-
tion of the PLTM to train and infer topics on the
same data set used in Platt et al (2010). That
paper used the Europarl (Koehn, 2005) multilin-
gual collection of English and Spanish sessions.
Their training collection consists of speeches ex-
tracted from all Europarl sessions from the years
1996 through 1999 and the year 2002 and a devel-
opment set which consists of speeches from ses-
sions in 2001. The test collection consists of Eu-
roparl speeches from the year 2000 and the first
nine months of 2003. While Platt et al (2010) do
offer absolute performance comparison between
their JPLSA approach and previous results pub-
lished by (Mimno et al, 2009), these performance
comparisons are not done on the same training and
test sets?a gap that we fill below.
We train PLTM models with number of topics T
set to 50, 100, 200, and 500. In order to compare
exactly the same topic distributions when comput-
ing speed vs. accuracy of various approximate and
exhaustive all-pairs comparisons we focus only on
one inference approach - the Gibbs sampling and
ignore the online VB approach as it yields sim-
ilar performance. For all four topic models, we
use the same settings for PLTM (hyperparame-
ter values and number of Gibbs sampling itera-
tions) as in (Mimno et al, 2009)2. Topic distribu-
tions were then inferred on the test collection us-
ing the trained topics. We then performed all-pairs
comparison using JS divergence, Hellinger dis-
tance, and approximate, LSH and kd-trees based,
Hellinger distance. We measured the total time
that it takes to perform exhaustive all-pairs com-
parison using JS divergence, the LSH and kd-
trees version on a single machine consisting of a
core 2 duo quad processors with a clock speed of
2.66GHz on each core and a total of 8GB of mem-
ory. Since the time performance of the E2LSH de-
pends on the radius R of data set points considered
for each query point (Indyk and Motwani, 1998),
we performed measurements with different values
of R. For this task, the all-pairs JS code implemen-
tation first reads both source and target sets of doc-
uments and stores them in hash tables. We then go
over each entry in the source table and compute di-
vergence against all target table entries.We refer to
this code implementation as hash map implemen-
tation.
4.2 Evaluation Task and Results
Performance of the four PLTM models and the
performance across the four different similarity
measurements was evaluated based on the percent-
age of document translation pairs (out of the whole
test set) that were discovered at rank one. This
same approach was used by (Platt et al, 2010) to
show the absolute performance comparison. As in
the case of the previous two tasks, in order to eval-
uate the approximate, LSH based, Hellinger dis-
tance we used values of R=0.4, R=0.6 and R=0.8.
Since in (Platt et al, 2010) numbers were reported
on the test speeches whose word length is greater
or equal to 100, we used the same subset (to-
tal of 14150 speeches) of the original test col-
lection. Shown in Table 1 are results across the
four different measurements for all four PLTM
models. When using regular JS divergence, our
PLTM model with 200 topics performs the best
with 99.42% of the top one ranked candidate trans-
lation documents being true translations. When
using approximate, kd-trees based, Hellinger dis-
tance, we outperform regular JS and Hellinger
divergence across all topics and for T=500 we
achieve the best overall accuracy of 99.61%. We
believe that this is due to the small amount of error
2We start off by first replicating the results as in (Mimno
et al, 2009) and thus verifying the functionality of our exper-
imental setup.
258
Divergence T=50 100 200 500
JS 94.27 98.48 99.42 99.33
He 94.30 98.45 99.40 99.31
He LSH R=0.4 93.95 97.46 98.27 98.01
He LSH R=0.6 94.30 98.46 99.40 99.31
He LSH R=0.8 94.30 98.45 99.34 99.31
He kd-trees 94.86 98.90 99.50 99.61
Table 1: Percentage of document pairs with the
correct translation discovered at rank 1: compari-
son of different divergence measurements and dif-
ferent numbers T of PLTM topics.
Divergence T=50 100 200 500
JS 7.8 4.6 2.4 1.0
He LSH R=0.4 511.5 383.6 196.7 69.7
He LSH R=0.6 142.1 105.0 59.0 18.6
He LSH R=0.8 73.8 44.7 29.5 16.3
He kd-trees 196.7 123.7 76.7 38.5
Table 2: Relative speed improvement between all-
pairs JS divergence and approximate He diver-
gence via kd-trees and LSH across different values
of radius R. The baseline is brute-force all-pairs
comparison with Jensen-Shannon and 500 topics.
in the search introduced by ANN, due to its ap-
proximate nature, which for this task yields pos-
itive results. On the same data set, (Platt et al,
2010) report accuracy of 98.9% using 50 topics, a
slightly different prior distribution, and MAP in-
stead of posterior inference.
Shown in Table 2 are the relative differences in
time between all pairs JS divergence, approximate
kd-trees and LSH based Hellinger distance with
different value of R. Rather than showing abso-
lute speed numbers, which are often influenced by
the processor configuration and available memory,
we show relative speed improvements where we
take the slowest running configuration as a refer-
ent value. In our case we assign the referent speed
value of 1 to the configuration with T=500 and all-
pairs JS computation. Results shown are based
on comparing running time of E2LSH and ANN
against the all-pairs similarity comparison imple-
mentation that uses hash tables to store all docu-
ments in the bilingual collection which is signifi-
cantly faster than the other code implementation.
For the approximate, LSH based, Hellinger dis-
tance with T=100 we obtain a speed improve-
ment of 24.2 times compared to regular all-pairs
JS divergence while maintaining the same per-
formance compared to Hellinger distance metric
and insignificant loss over all-pairs JS divergence.
From Table 2 it is evident that as we increase the
radius R we reduce the relative speed of perfor-
mance since the range of points that LSH consid-
ers for a given query point increases. Also, as the
number of topics increases, the speed benefit is re-
duced for both the LSH and k-d tree techniques.
5 Conclusion
Hierarchical Bayesian models, such as Polylin-
gual Topic Models, have been shown to offer
great potential in analyzing multilingual collec-
tions, extracting aligned topics and finding docu-
ment translation pairs when trained on sufficiently
large aligned collections. Online stochastic opti-
mization inference allows us to generate good pa-
rameter estimates. By combining these two ap-
proaches we are able to infer topic distributions
across documents in large multilingual document
collections in an efficient manner. Utilizing ap-
proximate NN search techniques in the probability
simplex, we showed that fast document translation
detection could be achieved with insignificant loss
in accuracy.
6 Acknowledgments
This work was supported in part by the Center
for Intelligent Information Retrieval and in part by
NSF grant #IIS-0910884. Any opinions, findings
and conclusions or recommendations expressed in
this material are those of the authors and do not
necessarily reflect those of the sponsor.
References
Alexandr Andoni, Mayur Datar, Nicole Immorlica, Pi-
otr Indyk, and Vahab Mirrokni. 2005. Locality-
sensitive hashing using stable distributions. In
G. Shakhnarovich, T. Darrell, and P. Indyk, editors,
Nearest Neighbor Methods in Learning and Vision:
Theory and Practice, pages 61?72. MIT Press.
Arthur Asuncion, Max Welling, Padhraic Smyth, and
Yee Whye Teh. 2009. On smoothing and inference
for topic models. In Proceedings of the Twenty-Fifth
Conference on Uncertainty in Artificial Intelligence,
UAI ?09, pages 27?34, Arlington, Virginia, United
States. AUAI Press.
David M. Blei and Michael I. Jordan. 2003. Modeling
annotated data. In Proceedings of the 26th annual
international ACM SIGIR conference on Research
259
and development in informaion retrieval, SIGIR ?03,
pages 127?134, New York, NY, USA. ACM.
David M. Blei and John D. Lafferty. 2006. Dynamic
topic models. In Proceedings of the 23rd interna-
tional conference on Machine learning, ICML ?06,
pages 113?120, New York, NY, USA. ACM.
David M. Blei, Andrew Y. Ng, and Michael I. Jordan.
2003. Latent dirichlet alocation. J. Mach. Learn.
Res., 3:993?1022, March.
Jordan Boyd-Graber and David M. Blei. 2009. Multi-
lingual topic models for unaligned text. In Proceed-
ings of the Twenty-Fifth Conference on Uncertainty
in Artificial Intelligence, UAI ?09, pages 75?82, Ar-
lington, Virginia, United States. AUAI Press.
Jordan Boyd-Graber and Philip Resnik. 2010. Holis-
tic sentiment analysis across languages: multilin-
gual supervised latent dirichlet alocation. In Pro-
ceedings of the 2010 Conference on Empirical Meth-
ods in Natural Language Processing, EMNLP ?10,
pages 45?55, Stroudsburg, PA, USA. Association
for Computational Linguistics.
Kevin R. Canini, Lei Shi, and Thomas L. Griffiths.
2009. Online inference of topics with latent dirichlet
allocation. In Proceedings of the 12th International
Conference on Artificial Intelligence and Statistics
(AISTATS).
Jacob Eisenstein, Brendan O?Connor, Noah A. Smith,
and Eric P. Xing. 2010. A latent variable model
for geographic lexical variation. In Proceedings of
the 2010 Conference on Empirical Methods in Natu-
ral Language Processing, EMNLP ?10, pages 1277?
1287, Stroudsburg, PA, USA. Association for Com-
putational Linguistics.
J. H. Friedman, J. L. Bentley, and R. A. Finkel. 1977.
An algorithm for finding best matches in logarithmic
expected time. ACM Transactions on Mathematical
Software, 3(3):209?226.
Kosuke Fukumasu, Koji Eguchi, and Eric Xing. 2012.
Symmetric correspondence topic models for multi-
lingual text analysis. In P. Bartlett, F.C.N. Pereira,
C.J.C. Burges, L. Bottou, and K.Q. Weinberger, ed-
itors, Advances in Neural Information Processing
Systems 25, pages 1295?1303.
Sudipto Guha, Andrew McGregor, and Suresh
Venkatasubramanian. 2006. Streaming and sublin-
ear approximation of entropy and information dis-
tances. In ACM-SIAM Symposium on Discrete Al-
gorithms, pages 733?742.
David Hall, Daniel Jurafsky, and Christopher D. Man-
ning. 2008. Studying the history of ideas using
topic models. In Proceedings of the Conference on
Empirical Methods in Natural Language Process-
ing, EMNLP ?08, pages 363?371, Stroudsburg, PA,
USA. Association for Computational Linguistics.
Matthew Hoffman, David Blei, and Francis Bach.
2010. Online learning for latent dirichlet alocation.
In J. Lafferty, C. K. I. Williams, J. Shawe-Taylor,
R.S. Zemel, and A. Culotta, editors, Advances in
Neural Information Processing Systems 23, pages
856?864.
Matt Hoffman, David M. Blei, and David M. Mimno.
2012. Sparse stochastic inference for latent dirichlet
allocation. In John Langford and Joelle Pineau, ed-
itors, Proceedings of the 29th International Confer-
ence on Machine Learning (ICML-12), pages 1599?
1606, New York, NY, USA. ACM.
Piotr Indyk and Rajeev Motwani. 1998. Approximate
nearest neighbors: towards removing the curse of di-
mensionality. In Proceedings of the thirtieth annual
ACM symposium on Theory of computing, STOC
?98, pages 604?613, New York, NY, USA. ACM.
Jagadeesh Jagarlamudi and Hal Daume?. 2010. Ex-
tracting multilingual topics from unaligned compa-
rable corpora. In Proceedings of the 32nd Euro-
pean conference on Advances in Information Re-
trieval, ECIR?2010, pages 444?456, Berlin, Heidel-
berg. Springer-Verlag.
Philipp Koehn. 2005. Europarl: A parallel corpus for
statistical machine translation. In MT Summit, pages
79?86.
Kriste Krstovski and David A. Smith. 2011. A mini-
mally supervised approach for detecting and ranking
document translation pairs. In Proc. Workshop on
Statistical MT, pages 207?216.
Andrew Kachites McCallum, 2002. MALLET: A Ma-
chine Learning for Language Toolkit. http://
mallet.cs.umass.edu.
David Mimno, Hanna M. Wallach, Jason Naradowsky,
David A. Smith, and Andrew McCallum. 2009.
Polylingual topic models. In Proceedings of the
2009 Conference on Empirical Methods in Nat-
ural Language Processing: Volume 2 - Volume
2, EMNLP ?09, pages 880?889, Stroudsburg, PA,
USA. Association for Computational Linguistics.
David M. Mount and Sunil Arya, 2010. ANN: A Li-
brary for Approximate Nearest Neighbor Searching.
http://www.cs.umd.edu/?mount/ANN/.
John C. Platt, Kristina Toutanova, and Wen-tau Yih.
2010. Translingual document representations from
discriminative projections. In Proceedings of the
2010 Conference on Empirical Methods in Natural
Language Processing, EMNLP ?10, pages 251?261,
Stroudsburg, PA, USA. Association for Computa-
tional Linguistics.
Edmund Talley, David Newman, David Mimno, Bruce
Herr, Hanna Wallach, Gully Burns, Miriam Leen-
ders, and Andrew McCallum. 2011. Database of
NIH grants using machine-learned categories and
graphical clustering. Nature Methods, 8:443?444.
260
Flemming Tops?e. 2000. Some inequalities for in-
formation divergence and related measures of dis-
crimination. IEEE Trans. Information Theory,
44(4):1602?1609.
Xuerui Wang and Andrew McCallum. 2006. Top-
ics over time: a non-markov continuous-time model
of topical trends. In Proceedings of the 12th ACM
SIGKDD international conference on Knowledge
discovery and data mining, KDD ?06, pages 424?
433, New York, NY, USA. ACM.
Xing Wei and W. Bruce Croft. 2006. Lda-based doc-
ument models for ad-hoc retrieval. In Proceedings
of the 29th annual international ACM SIGIR confer-
ence on Research and development in information
retrieval, SIGIR ?06, pages 178?185, New York,
NY, USA. ACM.
Jia Zeng, Xiao-Qin Cao, and Zhi-Qiang Liu. 2012.
Residual belief propagation for topic modeling.
CoRR, abs/1204.6610.
261
