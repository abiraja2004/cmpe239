Proceedings of EACL 2009 Workshop on Semantic Representation of Spoken Language - SRSL 2009, pages 34?41,
Athens, Greece, 30 March 2009. c?2009 Association for Computational Linguistics
Annotating Spoken Dialogs: from Speech Segments to Dialog Acts and
Frame Semantics
Marco Dinarelli, Silvia Quarteroni, Sara Tonelli, Alessandro Moschitti, Giuseppe Riccardi?
University of Trento
38050 Povo - Trento, Italy
{dinarelli,silviaq,moschitti,riccardi}@disi.unitn.it, satonelli@fbk.eu
Abstract
We are interested in extracting semantic
structures from spoken utterances gener-
ated within conversational systems. Cur-
rent Spoken Language Understanding sys-
tems rely either on hand-written seman-
tic grammars or on flat attribute-value se-
quence labeling. While the former ap-
proach is known to be limited in coverage
and robustness, the latter lacks detailed re-
lations amongst attribute-value pairs. In
this paper, we describe and analyze the hu-
man annotation process of rich semantic
structures in order to train semantic statis-
tical parsers. We have annotated spoken
conversations from both a human-machine
and a human-human spoken dialog cor-
pus. Given a sentence of the transcribed
corpora, domain concepts and other lin-
guistic features are annotated, ranging
from e.g. part-of-speech tagging and con-
stituent chunking, to more advanced anno-
tations, such as syntactic, dialog act and
predicate argument structure. In particu-
lar, the two latter annotation layers appear
to be promising for the design of complex
dialog systems. Statistics and mutual in-
formation estimates amongst such features
are reported and compared across corpora.
1 Introduction
Spoken language understanding (SLU) addresses
the problem of extracting and annotating the
meaning structure from spoken utterances in the
context of human dialogs (De Mori et al, 2008).
In spoken dialog systems (SDS) most used models
of SLU are based on the identification of slots (en-
?This work was partially funded by the European Com-
mission projects LUNA (contract 33549) and ADAMACH
(contract 022593).
tities) within one or more frames (frame-slot se-
mantics) that is defined by the application. While
this model is simple and clearly insufficient to
cope with interpretation and reasoning, it has sup-
ported the first generation of spoken dialog sys-
tems. Such dialog systems are thus limited by the
ability to parse semantic features such as predi-
cates and to perform logical computation in the
context of a specific dialog act (Bechet et al,
2004). This limitation is reflected in the type of
human-machine interactions which are mostly di-
rected at querying the user for specific slots (e.g.
?What is the departure city??) or implementing
simple dialog acts (e.g. confirmation). We believe
that an important step in overcoming such limita-
tion relies on the study of models of human-human
dialogs at different levels of representation: lexi-
cal, syntactic, semantic and discourse.
In this paper, we present our results in address-
ing the above issues in the context of the LUNA
research project for next-generation spoken dialog
interfaces (De Mori et al, 2008). We propose
models for different levels of annotation of the
LUNA spoken dialog corpus, including attribute-
value, predicate argument structures and dialog
acts. We describe the tools and the adaptation of
off-the-shelf resources to carry out annotation of
the predicate argument structures (PAS) of spoken
utterances. We present a quantitative analysis of
such semantic structures for both human-machine
and human-human conversations.
To the best of our knowledge this is the first
(human-machine and human-human) SDS corpus
denoting a multilayer approach to the annotation
of lexical, semantic and dialog features, which al-
lows us to investigate statistical relations between
the layers such as shallow semantic and discourse
features used by humans or machines. In the fol-
lowing sections we describe the corpus, as well as
a quantitative analysis and statistical correlations
between annotation layers.
34
2 Annotation model
Our corpus is planned to contain 1000 equally
partitioned Human-Human (HH) and Human-
Machine (HM) dialogs. These are recorded by
the customer care and technical support center of
an Italian company. While HH dialogs refer to
real conversations of users engaged in a problem
solving task in the domain of software/hardware
troubleshooting, HM dialogs are acquired with a
Wizard of Oz approach (WOZ). The human agent
(wizard) reacts to user?s spontaneous spoken re-
quests following one of ten possible dialog scenar-
ios inspired by the services provided by the com-
pany.
The above data is organized in transcrip-
tions and annotations of speech based on a new
multi-level protocol studied specifically within the
project, i.e. the annotation levels of words, turns1,
attribute-value pairs, dialog acts, predicate argu-
ment structures. The annotation at word level
is made with part-of-speech and morphosyntac-
tic information following the recommendations of
EAGLES corpora annotation (Leech and Wilson,
2006). The attribute-value annotation uses a pre-
defined domain ontology to specify concepts and
their relations. Dialog acts are used to annotate in-
tention in an utterance and can be useful to find
relations between different utterances as the next
section will show. For predicate structure annota-
tion, we followed the FrameNet model (Baker et
al., 1998) (see Section 2.2).
2.1 Dialog Act annotation
Dialog act annotation is the task of identifying
the function or goal of a given utterance (Sinclair
and Coulthard, 1975): thus, it provides a comple-
mentary information to the identification of do-
main concepts in the utterance, and a domain-
independent dialog act scheme can be applied.
For our corpus, we used a dialog act taxonomy
which follows initiatives such as DAMSL (Core
and Allen, 1997), TRAINS (Traum, 1996) and
DIT++ (Bunt, 2005). Although the level of granu-
larity and coverage varies across such taxonomies,
a careful analysis leads to identifying three main
groups of dialog acts:
1. Core acts, which represent the fundamen-
tal actions performed in the dialog, e.g. re-
1A turn is defined as the interval when a speaker is active,
between two pauses in his/her speech flow.
questing and providing information, or exe-
cuting a task. These include initiatives (often
called forward-looking acts) and responses
(backward-looking acts);
2. Conventional/Discourse management acts,
which maintain dialog cohesion and delimit
specific phases, such as opening, continua-
tion, closing, and apologizing;
3. Feedback/Grounding acts,used to elicit and
provide feedback in order to establish or re-
store a common ground in the conversation.
Our taxonomy, following the same three-fold
partition, is summarized in Table 1.
Table 1: Dialog act taxonomy
Core dialog acts
Info-request Speaker wants information from ad-
dressee
Action-request Speaker wants addressee to perform
an action
Yes-answer Affirmative answer
No-answer Negative answer
Answer Other kinds of answer
Offer Speaker offers or commits to perform
an action
ReportOnAction Speaker notifies an action is being/has
been performed
Inform Speaker provides addressee with in-
formation not explicitly required (via
an Info-request)
Conventional dialog acts
Greet Conversation opening
Quit Conversation closing
Apology Apology
Thank Thanking (and down-playing)
Feedback/turn management dialog acts
Clarif-request Speaker asks addressee for confirma-
tion/repetition of previous utterance
for clarification.
Ack Speaker expresses agreement with
previous utterance, or provides feed-
back to signal understanding of what
the addressee said
Filler Utterance whose main goal is to man-
age conversational time (i.e. dpeaker
taking time while keeping the turn)
Non-interpretable/non-classifiable dialog acts
Other Default tag for non-interpretable and
non-classifiable utterances
It can be noted that we have decided to retain
only the most frequent dialog act types from the
schemes that inspired our work. Rather than as-
piring to the full discriminative power of possible
conversational situations, we have opted for a sim-
ple taxonomy that would cover the vast majority
35
of utterances and at the same time would be able
to generalize them. Its small number of classes is
meant to allow a supervised classification method
to achieve reasonable performance with limited
data. The taxonomy is currently used by the sta-
tistical Dialogue Manager in the ADAMACH EU
project (Varges et al, 2008); the limited number
of classes allows to reduce the number of hypoth-
esized current dialogue acts, thus reducing the di-
alogue state space.
Dialog act annotation was performed manually
by a linguist on speech transcriptions previously
segmented into turns as mentioned above. The an-
notation unit for dialog acts, is the utterance; how-
ever, utterances are complex semantic entities that
do not necessarily correspond to turns. Hence, a
segmentation of the dialog transcription into ut-
terances was performed by the annotator before
dialog act labeling. Both utterance segmentation
and dialog act labeling were performed through
the MMAX tool (Mu?ller and Strube, 2003).
The annotator proceeded according to the fol-
lowing guidelines:
1. by default, a turn is also an utterance;
2. if more than one tag is applicable to an ut-
terance, choose the tag corresponding to its
main function;
3. in case of doubt among several tags, give pri-
ority to tags in core dialog acts group;
4. when needed, split the turn into several utter-
ances or merge several turns into one utter-
ance.
Utterance segmentation provides the basis not
only for dialog act labeling but also for the other
semantic annotations. See Fig. 1 for a dialog sam-
ple where each line represents an utterance anno-
tated according to the three levels.
2.2 Predicate Argument annotation
We carried out predicate argument structure an-
notation applying the FrameNet paradigm as de-
scribed in (Baker et al, 1998). This model
comprises a set of prototypical situations called
frames, the frame-evoking words or expressions
called lexical units and the roles or participants in-
volved in these situations, called frame elements.
The latter are typically the syntactic dependents of
the lexical units. All lexical units belonging to
the same frame have similar semantics and show
                                              PERSON-NAME 
Info: Buongiorno, sono   Paola.  
  
          GREETING    B._NAMED Name 
Good morning, this is Paola. 
 
Info-req: Come la posso aiutare? 
                      
                    Benefitted_party   ASSISTANCE 
How may I help you? 
 
                                                       CONCEPT         HARDWARE-COMPONENT 
Info: Buongiorno. Ho un problema con la stampante.  
 
          GREETING            PR._DESCRIPTION     Affected_device 
Good morning. I have a problem with the printer. 
 
           PART-OF-DAY   NEGAT. ACTION                ACTION 
Info: Da stamattina non   riesco pi? a  stampare 
                                       
                                    Problem 
Since this morning I can?t print. 
 
Info-req:   Mi  pu?  dire   nome e cognome per favore? 
 
              Addressee      TELLING               Message 
Can you tell me your name and surname, please? 
 
                                       PERSON-NAME  PERSON-SURNAME 
Answer: Mi chiamo  Alessandro  Manzoni. 
 
               Entity B._NAMED                   Name 
My name is Alessandro Manzoni. 
Figure 1: Annotated dialog extract. Each utterance
is preceded by dialog act annotation. Attribute-
value annotation appears above the text, PAS an-
notation below the text.
the same valence. A particular feature of the
FrameNet project both for English and for other
languages is its corpus-based nature, i.e. every el-
ement described in the resource has to be instanti-
ated in a corpus. To annotate our SDS corpus, we
adopted where possible the already existing frame
and frame element descriptions defined for the En-
glish FrameNet project, and introduced new def-
initions only in case of missing elements in the
original model.
Figure 1 shows a dialog sample with PAS an-
notation reported below the utterance. All lexi-
cal units are underlined and the frame is written in
capitals, while the other labels refer to frame el-
ements. In particular, ASSISTANCE is evoked by
the lexical unit aiutare and has one attested frame
element (Benefitted party), GREETING has no
frame element, and PROBLEM DESCRIPTION
and TELLING have two frame elements each.
Figure 2 gives a comprehensive view of the an-
notation process, from audio file transcription to
the annotation of three semantic layers. Whereas
36
Figure 2: The annotation process
Audio file 
Turn segmentation & 
Transcription 
Utterance segmentation 
POS tagging Domain attribute 
annotation 
PAS annotation 
Dialog Act 
annotation 
Syntactic parsing 
attribute-value and DA annotation are carried
out on the segmented dialogs at utterance level,
PAS annotation requires POS-tagging and syntac-
tic parsing (via Bikel?s parser trained for Italian
(Corazza et al, 2007)). Finally, a shallow manual
correction is carried out to make sure that the tree
nodes that may carry semantic information have
correct constituent boundaries. For the annotation
of frame information, we used the Salto tool (Bur-
chardt et al, 2006), that stores the dialog file in
TIGER-XML format and allows to easily intro-
duce word tags and frame flags. Frame informa-
tion is recorded on top of parse trees, with target
information pointing to terminal words and frame
elements pointing to tree nodes.
3 Quantitative comparison of the
Annotation
We evaluated the outcome of dialog act and
PAS annotation levels on both the human-human
(henceforth HH) and human-machine (HM) cor-
pora by not only analyzing frequencies and occur-
rences in the separate levels, but also their interac-
tion, as discussed in the following sections.
3.1 Dialog Act annotation
Analyzing the annotation of 50 HM and 50 HH
dialogs at the dialog act level, we note that an
HH dialog is composed in average by 48.9?17.4
(standard deviation) dialog acts, whereas a HM
dialog is composed of 18.9?4.4. The difference
between average lengths shows how HH sponta-
neous speech can be redundant, while HM dialogs
are more limited to an exchange of essential infor-
mation. The standard deviation of a conversation
in terms of dialog acts is considerably higher in
the HH corpus than in the HM one. This can be ex-
plained by the fact that the WOZ follows a unique,
previously defined task-solving strategy that does
not allow for digressions. Utterance segmentation
was also performed differently on the two corpora.
In HH we performed 167 turn mergings and 225
turn splittings; in HM dialogs, only turn splittings
(158) but no turn mergings were performed.
Tables 2 and 3 report the dialog acts occurring
in the HM and HH corpora, respectively, ranked
by their frequencies.
Table 2: Dialog acts ranked by frequency in the
human-machine (HM) corpus
human-machine (HM)
DA count rel. freq.
Info-request 249 26.3%
Answer 171 18.1%
Inform 163 17.2%
Yes-answer 70 7.4%
Quit 60 6.3%
Thank 56 5.9%
Greet 50 5.3%
Offer 49 5.2%
Clarification-request 26 2.7%
Action-request 25 2.6%
Ack 12 1.3%
Filler 6 0.6%
No-answer 5 0.5%
Other, ReportOnAction 2 0.2%
Apology 1 0.1%
TOTAL 947
From a comparative analysis, we note that:
1. info-request is by far the most common dia-
log act in HM, whereas in HH ack and info
share the top ranking position;
2. the most frequently occurring dialog act in
HH, i.e. ack, is only ranked 11th in HM;
3. the relative frequency of clarification-request
(4,7%) is considerably higher in HH than in
HM.
We also analyzed the ranking of the most fre-
quent dialog act bigrams in the two corpora. We
can summarize our comparative analysis, reported
in Table 4, to the following: in both corpora,
most bigram types contain info and info-request,
37
Table 3: Dialog acts ranked by frequency in the
human-human (HH) corpus
human-human (HH)
DA count rel. freq.
Ack 582 23.8%
Inform 562 23.0%
Info-request 303 12.4%
Answer 192 7.8%
Clarification-request 116 4.7%
Offer 114 4.7%
Yes-answer 112 4.6%
Quit 101 4.1%
ReportOnAction 91 3.7%
Other 70 2.9%
Action-request 69 2.8%
Filler 61 2.5%
Thank 33 1.3%
No-answer 26 1.1%
Greet, Apology 7 0.3%
TOTAL 2446
as expected in a troubleshooting system. How-
ever, the bigram info-request answer, which we
expected to form the core of a task-solving dia-
log, is only ranked 5th in the HH corpus, while 5
out of the top 10 bigram types contain ack. We
believe that this is because HH dialogs primarily
contain spontaneous information-providing turns
(e.g. several info info by the same speaker) and
acknowledgements for the purpose of backchan-
nel. Instead, HM dialogs, structured as sequences
of info-request answers pairs, are more minimal
and brittle, showing how users tend to avoid re-
dundancy when addressing a machine.
Table 4: The 10 most frequent dialog act bigrams
human-machine (HM) human-human (HH)
info-req answer ack info
answer info-req info ack
info info-req info info
info-req y-answer ack ack
sentence beginning greet info-req answer
greet info info info-req
info quit info-req y-answer
offer info ack info-req
thank info answer ack
y-answer thank quit sentence end
3.2 Predicate Argument annotation
We annotated 50 HM and 50 HH dialogs with
frame information. Differently from the English
FrameNet database, we didn?t annotate one frame
per sentence. On the contrary, we identified all
lexical units corresponding to ?semantically rele-
vant? verbs, nouns and adjectives with a syntac-
tic subcategorization pattern, eventually skipping
the utterances with empty semantics (e.g. dis-
fluencies). In particular, we annotated all lexical
units that imply an action, introduce the speaker?s
opinion or describe the office environment. We
introduced 20 new frames out of the 174 iden-
tified in the corpus because the original defini-
tion of frames related to hardware/software, data-
handling and customer assistance was sometimes
too coarse-grained. Few new frame elements were
introduced as well, mostly expressing syntactic re-
alizations that are typical of spoken Italian.
Table 5 shows some statistics about the cor-
pus dimension and the results of our annotation.
The human-human dialogs contain less frame in-
stances in average than the human-machine group,
meaning that speech disfluencies, not present in
turns uttered by the WOZ, negatively affect the se-
mantic density of a turn. For the same reason, the
percentage of turns in HH dialogs that were manu-
ally corrected in the pre-processing step (see Sec-
tion 2.2) is lower than for HM turns, since HH di-
alogs have more turns that are semantically empty
and that were skipped in the correction phase. Be-
sides, HH dialogs show a higher frame variabil-
ity than HM, which can be explained by the fact
that spontaneous conversation may concern mi-
nor topics, whereas HM dialogs follow a previ-
ously defined structure, designed to solve soft-
ware/hardware problems.
Tables 6 and 7 report the 10 most frequent
frames occurring in the human-machine resp.
human-human dialogs. The relative frame fre-
quency in HH dialogs is more sparse than in HM
dialogs, meaning that the task-solving strategy fol-
lowed by the WOZ limits the number of digres-
sions, whereas the semantics of HH dialogs is
richer and more variable.
As mentioned above, we had to introduce and
define new frames which were not present in the
original FrameNet database for English in order to
capture all relevant situations described in the di-
alogs. A number of these frames appear in both
tables, suggesting that the latter are indeed rel-
38
Table 5: Dialog turn and frame statistics for the
human-machine (HM) resp. human-human (HH)
corpus
HM HH
Total number of turns 662 1,997
Mean dialog length (turns) 13.2 39.9
Mean turn length (tokens) 11.4 10.8
Corrected turns (%) 50 39
Total number of annotations 923 1951
Mean number of frame annota-
tions per dialog
18.5 39.0
Mean number of frame elements
per frame annotation
1.6 1.7
evant to model the general semantics of the di-
alogs we are approaching. The most frequent
frame group comprises frames relating to infor-
mation exchange that is typical of the help-desk
activity, including Telling, Greeting, Contacting,
Statement, Recording, Communication. Another
relevant group encompasses frames related to the
operational state of a device, for example Be-
ing operational, Change operational state, Oper-
ational testing, Being in operation.
The two groups also show high variability of
lexical units. Telling, Change operational state
and Greeting have the richest lexical unit set,
with 11 verbs/nouns/adjectives each. Arriving
and Awareness are expressed by 10 different lexi-
cal units, while Statement, Being operational, Re-
moving and Undergo change of operational state
have 9 different lexical units each. The informal
nature of the spoken dialogs influences the com-
position of the lexical unit sets. In fact, they are
rich in verbs and multiwords used only in collo-
quial contexts, for which there are generally few
attestations in the English FrameNet database.
Similarly to the dialog act statistics, we also
analyzed the most frequent frame bigrams and
trigrams in HM and HH dialogs. Results are
reported in Tables 8 and 9. Both HH bigrams
and trigrams show a more sparse distribution and
lower relative frequency than HM ones, implying
that HH dialogs follow a more flexible structure
with a richer set of topics, thus the sequence of
themes is less predictable. In particular, 79%
of HH bigrams and 97% of HH trigrams occur
only once (vs. 68% HM bigrams and 82% HM
trigrams). On the contrary, HM dialogs deal with
Table 6: The 10 most frequent frames in the HM
corpus (* =newly introduced)
HM corpus
Frame count freq-%
Greeting* 146 15.8
Telling 134 14.5
Recording 83 8.9
Being named 74 8.0
Contacting 52 5.6
Usefulness 50 5.4
Being operational 28 3.0
Problem description* 24 2.6
Inspecting 24 2.6
Perception experience 21 2.3
Table 7: The 10 most frequent frames in the HH
corpus (* =newly introduced)
HH corpus
Frame count freq-%
Telling 143 7.3
Greeting* 124 6.3
Awareness 74 3.8
Contacting 63 3.2
Giving 62 3.2
Navigation* 61 3.1
Change operational state 51 2.6
Perception experience 46 2.3
Insert data* 46 2.3
Come to sight* 38 1.9
a fix sequence of topics driven by the turns uttered
by the WOZ. For instance, the most frequent
HM bigram and trigram both correspond to the
opening utterance of the WOZ:
Help desk buongiornoGREETING, sonoBEING NAMED
Paola, in cosa posso esserti utileUSEFULNESS?
(Good morning, help-desk service, Paola speaking, how can
I help you?)
3.3 Mutual information between PAS and
dialog acts
A unique feature of our corpus is the availabil-
ity of both a semantic and a dialog act annota-
tion level: it is intuitive to seek relationships in
the purpose of improving the recognition and un-
derstanding of each level by using features from
the other. We considered a subset of 20 HH and
50 HM dialogs and computed an initial analysis
39
Table 8: The 5 most frequent frame bigrams
human-machine (HM) freq-%
Greeting Being named 17.1
Being named Usefulness 15.3
Telling Recording 12.9
Recording Contacting 10.9
Contacting Greeting 10.6
human-human (HH) freq-%
Greeting Greeting 4.7
Navigation Navigation 1.2
Telling Telling 1.0
Change op. state Change op. state 0.9
Telling Problem description 0.8
Table 9: The 5 most frequent frame trigrams
human-machine (HM) freq-%
Greeting Being named Usefulness 9.5
Recording Contacting Greeting 5.7
Being named Usefulness Greeting 3.7
Telling Recording Contacting 3.5
Telling Recording Recording 2.2
human-human (HH) freq-%
Greeting Greeting Greeting 1.6
Greeting Being named Greeting 0.5
Contacting Greeting Greeting 0.3
Navigation Navigation Navigation 0.2
Working on Greeting Greeting 0.2
of the co-occurrences of dialog acts and PAS. We
noted that each PAS tended to co-occur only with a
limited subset of the available dialog act tags, and
moreover in most cases the co-occurrence hap-
pened with only one dialog act. For a more thor-
ough analysis, we computed the weighted condi-
tional entropy between PAS and dialog acts, which
yields a direct estimate of the mutual information
between the two levels of annotation2.
2Let H(yj |xi) be the weighted conditional entropy of ob-
servation yj of variable Y given observation xi of variable
X:
H(yj |xi) = ?p(xi; yj)log
p(xi; yj)
p(xi)
,
where p(xi; yj) is the probability of co-occurrence of xi and
yj , and p(xi) and p(yj) are the marginal probabilities of oc-
currence of xi resp. yj in the corpus. There is an obvious re-
lation with the weighted mutual information between xi and
yj , defined following e.g. (Bechet et al, 2004) as:
wMI(xi; yj) = p(xi; yj)log
p(xi; yj)
p(xi)p(yj)
.
(a) human-machine dialogs (filtering co-occurrences below 3)
(b) human-human dialogs (filtering co-occurrences below 5)
Figure 3: Weighted conditional entropy between
PAS and dialog acts in the HM (a) and HH corpus
(b). To lower entropies correspond higher values
of mutual information (darker color in the scale)
Our results are illustrated in Figure 3. In the
HM corpus (Fig. 3(a)), we noted some interesting
associations between dialog acts and PAS. First,
info-req has the maximal MI with PAS like Be-
ing in operation and Being attached, as requests
are typically used by the operator to get informa-
tion about the status of device. Several PAS de-
note a high MI with the info dialog act, includ-
ing Activity resume, Information, Being named,
Contacting, and Resolve problem. Contacting
refers to the description of the situation and of the
speaker?s point of view (usually the caller). Be-
ing named is primarily employed when the caller
introduces himself, while Activity resume usually
refers to the operator?s description of the sched-
Indeed, the higher is H(yj |xi), the lower is wMI(xi; yj).
We approximate all probabilities using frequency of occur-
rence.
40
uled interventions.
As for the remaining acts, clarif has the high-
est MI with Perception experience and Statement,
used to warn the addressee about understanding
problems and asking him to repeat/rephrase an ut-
terance, respectively. The two strategies can be
combined in the same utterance, as in the utter-
ance: Non ho sentito bene: per favore ripeti cer-
cando di parlare piu` forte. (I haven?t quite heard
that, please repeat trying to speak up.).
The answer tag is highly informative with Suc-
cessful action, Change operational state, Becom-
ing nonfunctional, Being detached, Read data.
These PAS refer to the exchange of infor-
mation (Read data) or to actions performed
by the user after a suggestion of the system
(Change operational state). Action requests (act-
req) seem to be correlated to Replacing as it usu-
ally occurs when the operator requests the caller
to carry out an action to solve a problem, typically
to replace a component with another. Another fre-
quent request may refer to some device that the
operator has to test.
In the HH corpus (Fig. 3(b)), most of the PAS
are highly mutually informative with info: in-
deed, as shown in Table 3, this is the most fre-
quently occurring act in HH except for ack, which
rarely contain verbs that can be annotated by a
frame. As for the remaining acts, there is an easily
explainable high MI between quit and Greeting;
moreover, info-req denote its highest MI with
Giving, as in requests to give information, while
rep-action denotes a strong co-occurrence with
Inchoative attaching: indeed, interlocutors often
report on the action of connecting a device.
These results corroborate our initial observation
that for most PAS, the mutual information tends
to be very high in correspondence of one dialog
act type: this suggests the beneficial effect of in-
cluding shallow semantic information as features
for dialog act classification. The converse is less
clear as the same dialog act can relate to a span
of words covered by multiple PAS and generally,
several PAS co-occur with the same dialog act.
4 Conclusions
In this paper we have proposed an approach to
the annotation of spoken dialogs using seman-
tic and discourse features. Such effort is crucial
to investigate the complex dependencies between
the layers of semantic processing. We have de-
signed the annotation model to incorporate fea-
tures and models developed both in the speech
and language research community and bridging
the gap between the two communities. Our multi-
layer annotation corpus allows the investigation
of cross-layer dependencies and across human-
machine and human-human dialogs as well as
training of semantic models which accounts for
predicate interpretation.
References
C. F. Baker, C. J. Fillmore, and J. B. Lowe. 1998.
The Berkeley FrameNet Project. In Proceedings of
ACL/Coling?98, pages 86?90.
F. Bechet, G. Riccardi, and D. Hakkani-Tur. 2004.
Mining spoken dialogue corpora for system evalu-
ation and modeling. In Proceedings of EMNLP?04,
pages 134?141.
H. Bunt. 2005. A framework for dialogue act specica-
tion. In Proceedings of SIGSEM WG on Represen-
tation of Multimodal Semantic Information.
A. Burchardt, K. Erk, A. Frank, A. Kowalski, S. Pado?,
and M. Pinkal. 2006. Salto - a versatile multi-
level annotation tool. In Proceedings of LREC 2006,
pages 517?520, Genoa, Italy.
A. Corazza, A. Lavelli, and G. Satta. 2007. Anal-
isi sintattica-statistica basata su costituenti. Intelli-
genza Artificiale, 4(2):38?39.
M. G. Core and J. F. Allen. 1997. Coding dialogs
with the DAMSL annotation scheme. In Proceed-
ings of the AAAI Fall Symposium on Communicative
Actions in Humans and Machines.
R. De Mori, F. Bechet, D. Hakkani-Tur, M. McTear,
G. Riccardi, and G. Tur. 2008. Spoken language
understanding: A survey. IEEE Signal Processing
magazine, 25(3):50?58.
G. Leech and A. Wilson. 2006. EAGLES recommen-
dations for the morphosyntactic annotation of cor-
pora. Technical report, ILC-CNR.
C. Mu?ller and M. Strube. 2003. Multi-level annotation
in MMAX. In Proceedings of SIGDIAL?03.
J. M. Sinclair and R. M. Coulthard. 1975. Towards an
Analysis of Discourse: The English Used by Teach-
ers and Pupils. Oxford University Press, Oxford.
D. Traum. 1996. Conversational agency: The
TRAINS-93 dialogue manager. In Proceedings of
TWLT 11: Dialogue Management in Natural Lan-
guage Systems, pages 1?11, June.
S. Varges, G. Riccardi, and S. Quarteroni. 2008. Per-
sistent information state in a data-centric architec-
ture. In Proceedings of SIGDIAL?08.
41
