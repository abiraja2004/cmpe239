Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010), pages 1137?1145,
Beijing, August 2010
Towards a Unified Approach to Simultaneous Single-Document and 
Multi-Document Summarizations 
 
Xiaojun Wan 
Institute of Compute Science and Technology 
The MOE Key Laboratory of Computational Linguistics 
Peking University 
wanxiaojun@icst.pku.edu.cn 
 
Abstract 
Single-document summarization and multi-
document summarization are very closely re-
lated tasks and they have been widely investi-
gated independently.  This paper examines 
the mutual influences between the two tasks 
and proposes a novel unified approach to si-
multaneous single-document and multi-
document summarizations. The mutual influ-
ences between the two tasks are incorporated 
into a graph model and the ranking scores of a 
sentence for the two tasks can be obtained in 
a unified ranking process. Experimental re-
sults on the benchmark DUC datasets demon-
strate the effectiveness of the proposed ap-
proach for both single-document and multi-
document summarizations.  
1 Introduction 
Single-document summarization aims to pro-
duce a concise and fluent summary for a single 
document, and multi-document summarization 
aims to produce a concise and fluent summary 
for a document set consisting of multiple related 
documents. The two tasks are very closely re-
lated in both task definition and solution method. 
Moreover, both of them are very important in 
many information systems and applications. For 
example, given a cluster of news articles, a 
multi-document summary can be used to help 
users to understand the whole cluster, and a sin-
gle summary for each article can be used to help 
users to know the content of the specified article.  
To date, single-document and multi-document 
summarizations have been investigated exten-
sively and independently in the NLP and IR 
fields. A series of special conferences or work-
shops on automatic text summarization (e.g. 
SUMMAC, DUC, NTCIR and TAC) have ad-
vanced the technology and produced a couple of 
experimental online systems. However, the two 
summarization tasks have not yet been simulta-
neously investigated in a unified framework.  
Inspired by the fact that the two tasks are very 
closely related and they can be used simultane-
ously in many applications, we believe that the 
two tasks may have mutual influences on each 
other. In this study, we propose a unified ap-
proach to simultaneous single-document and 
multi-document summarizations. The mutual 
influences between the two tasks are incorpo-
rated into a graph-based model. The ranking 
scores of sentences for single-document summa-
rization and the ranking scores of sentences for 
multi-document summarization can boost each 
other, and they can be obtained simultaneously 
in a unified graph-based ranking process. To the 
best of our knowledge, this study is the first at-
tempt for simultaneously addressing the two 
summarization tasks in a unified graph-based 
framework. Moreover, the proposed approach 
can be easily adapted for topic-focused summa-
rizations.  
Experiments have been performed on both the 
single-document and multi-document summari-
zation tasks of DUC2001 and DUC2002. The 
results demonstrate that the proposed approach 
can outperform baseline independent methods 
for both the two summarization tasks. The two 
tasks are validated to have mutual influences on 
each other.  
The rest of this paper is organized as follows: 
Section 2 introduces related work. The details of 
the proposed approach are described in Section 
3. Section 4 presents and discusses the evalua-
tion results. Lastly we conclude our paper in 
Section 5. 
1137
2 Related Work 
Document summarization methods can be either 
extraction-based or abstraction-based. In this 
section, we focus on extraction-based methods.  
Extraction-based methods for single-
document summarization usually assign a sali-
ency score to each sentence in a document and 
then rank and select the sentences. The score is 
usually computed based on a combination of 
statistical and linguistic features, such as term 
frequency, sentence position, cue words and 
stigma words (Luhn, 1969; Edmundson, 1969; 
Hovy and Lin, 1997). Machine learning tech-
niques have also been used for sentence extrac-
tion (Kupiec et al, 1995; Conroy and O?Leary, 
2001; Shen et al, 2007; Li et al, 2009). The 
mutual reinforcement principle has been ex-
ploited to iteratively extract key phrases and 
sentences from a document (Zha, 2002; Wan et 
al, 2007a). Wan et al (2007b) propose the Col-
labSum algorithm to use additional knowledge 
in a cluster of documents to improve single 
document summarization in the cluster.   
In recent years, graph-based ranking methods 
have been investigated for document summari-
zation, such as TextRank (Mihalcea and Tarau, 
2004; Mihalcea and Tarau, 2005) and LexPag-
eRank (ErKan and Radev, 2004). Similar to 
PageRank (Page et al, 1998), these methods 
first build a graph based on the similarity rela-
tionships between the sentences in a document 
and then the saliency of a sentence is determined 
by making use of the global information on the 
graph recursively. The basic idea underlying the 
graph-based ranking algorithm is that of ?vot-
ing? or ?recommendation? between sentences.  
Similar methods have been used for generic 
multi-document summarization. A typical 
method is the centroid-based method (Radev et 
al., 2004). For each sentence, the method com-
putes a score based on each single feature (e.g. 
cluster centroids, position and TFIDF) and then 
linearly combines all the scores into an overall 
sentence score. Topic signature is used as a 
novel feature for selecting important content in 
NeATS (Lin and Hovy, 2002). Various sentence 
features have been combined by using machine 
learning techniques (Wong et al, 2008). A 
popular way for removing redundancy between 
summary sentences is the MMR algorithm (Car-
bonell and Goldstein, 1998). Themes (or topics, 
clusters) in documents have been discovered and 
used for sentence selection (Harabagiu and La-
catusu, 2005). Hachey (2009) investigates the 
effect of various source document representa-
tions on the accuracy of the sentence extraction 
phase of a multi-document summarization task. 
Graph-based methods have also been used to 
rank sentences in a document set. The methods 
first construct a graph to reflect sentence rela-
tionships at different granularities, and then 
compute sentence scores based on graph-based 
learning algorithms. For example, Wan (2008) 
proposes to use only cross-document relation-
ships for graph building and sentence ranking. 
Cluster-level information has been incorporated 
in the graph model to better evaluate sentences 
(Wan and Yang, 2008).  
For topic-focused multi-document summari-
zation, many methods are extensions of generic 
summarization methods by incorporating the 
information of the given topic or query into ge-
neric summarizers. In recent years, a few novel 
methods have been proposed for topic-focused 
summarization (Daum? and Marcu, 2006; Wan 
et al, 2007c; Nastase 2008; Li et al, 2008; 
Schilder and Kondadadi, 2008; Wei et al, 2008).   
The above previous graph-based summariza-
tion methods aim to address either single-
document summarization or multi-document 
summarization, and the two summarization tasks 
have not yet been addressed in a unified graph-
based framework.  
3 The Unified Summarization Ap-
proach 
3.1 Overview 
Given a document set, in which the whole docu-
ment set and each single document in the set are 
required to be summarized, we use local sali-
ency to indicate the importance of a sentence in 
a particular document, and use global saliency 
to indicate the importance of a sentence in the 
whole document set. 
In previous work, the following two assump-
tions are widely made for graph-based summari-
zation models: 
Assumption 1: A sentence is locally impor-
tant in a particular document if it is heavily 
linked with many locally important sentences in 
the same document.  
1138
Assumption 2: A sentence is globally impor-
tant in the document set if it is heavily linked 
with many globally important sentences in the 
document set.  
   The above assumptions are the basis for Pag-
eRank-like algorithms for single document 
summarization and multi-document summariza-
tion, respectively.  In addition to the above two 
assumptions, we make the following two as-
sumptions to consider the mutual influences be-
tween the two summarization tasks: 
Assumption 3: A sentence is locally impor-
tant in a particular document, if it is heavily 
linked with many globally important sentences 
in the document set.   
The above assumption is reasonable because 
the documents in the set are relevant and the 
globally important information in the document 
set will be expressed in many single documents. 
Therefore, if a sentence is salient in the whole 
document set, the sentence may be salient in a 
particular document in the set. 
Assumption 4: A sentence is globally impor-
tant in the document set, if it is heavily linked 
with many locally important sentences.  
The above assumption is reasonable because 
the documents in the set are relevant and the 
globally important information in the whole set 
is the aggregation of the locally important in-
formation in each single document. Therefore, if 
a sentence is salient in a particular document, 
the sentence has the potential to be salient in the 
whole document set. 
In brief, the local saliency and global saliency 
of a sentence can mutually influence and boost 
each other: high local saliency will lead to high 
global saliency, and high global saliency will 
lead to high local saliency.  
Based on the above assumptions, our pro-
posed approach first builds affinity graphs (each 
graph is represented by an affinity matrix) to 
reflect the different kinds of relationships be-
tween sentences, respectively, and then itera-
tively computes the local saliency scores and the 
global saliency scores of the sentences based on 
the graphs. Finally, the algorithm converges and 
the local saliency score and global saliency 
score of each sentence are obtained. The sen-
tences with high local saliency scores in a par-
ticular document are chosen into the summary of 
the single document, and the sentences with 
high global saliency scores in the set are chosen 
into the summary of the document set.  
Note that for both summarization tasks, after 
the saliency scores of sentences have been ob-
tained, the greedy algorithm used in (Wan et al, 
2007c) is applied to remove redundancy and 
finally choose both informative and novel sen-
tences into the summary. 
3.2 Algorithm Details 
Formally, the given document set is denoted as 
D={di|1?i?m}, and the whole sentence set is 
denoted as S={si|1?i?n}.  We let Infosingle(si)  
denote the local saliency score of sentence si in a 
particular document d(si)?D, and it is used to 
select summary sentences for the single docu-
ment d(si).   And we let Infomulti(si) denote the 
global saliency score of sentence si in the whole 
document set D,  and it is used to select sum-
mary sentences for the document set D.  
The four assumptions in Section 3.1 can be 
rendered as follows: 
?? j jglejiAigle sInfoWsInfo )()()( sinsin  (1) 
?? j jmultijiBimulti sInfoWsInfo )()()(  (2) 
?? j jmultijiCigle sInfoWsInfo )()()(sin  (3) 
?? j jglejiDimulti sInfoWsInfo )()()( sin  (4) 
where WA, WB, WC, WD are n?n affinity matrices 
reflecting the different kinds of relationships 
between sentences in the document set, where n 
is the number of all sentences in the document 
set. The detailed derivation of the matrices will 
be presented later. 
After fusing the above equations, we can ob-
tain the following unified forms: 
?
?
?+
=
j jmultijiC
j jglejiAigle
sInfoW
sInfoWsInfo
)()()1(                
)()()( sinsin
?
?   (5) 
?
?
?+
=
j jglejiD
j jmultijiBimulti
sInfoW
sInfoWsInfo
)()()1(             
)()()(
sin?
?
 
 
  (6) 
However, the above summarization method 
ignores the feature of sentence position, which 
has been validated to be very important for 
document summarizations. In order to incorpo-
rate this important feature, we add one prior 
score to each computation as follows: 
)()()(
)()()(
sin
sinsin
iglej jmultijiC
j jglejiAigle
spriorsInfoW
sInfoWsInfo
?++
=
?
?
??
?   
(7) 
1139
)()()(
)()()(
sin imultij jglejiD
j jmultijiBimulti
spriorsInfoW
sInfoWsInfo
?++
=
?
?
??
?  
 
  (8) 
where ?, ?, ??[0,1] specify the relative contri-
butions to the final saliency scores from the dif-
ferent factors, and we have ?+?+?=1. pri-
orsingle(si) is the prior score for the local saliency 
of sentence si, and here priorsingle(si)  is com-
puted based on sentence position of si in the par-
ticular document d(si). priormulti(si) is the prior 
score for the global saliency of sentence si, and 
we also compute priormulti(si) based on sentence 
position of si. 
We use two column vectors 
ur =[Infosingle(si)]n?1 and vr =[Infomulti(si)]n?1 to 
denote the local and global saliency scores of all 
the sentences in the set, respectively. And the 
matrix forms of the above equations are as fol-
lows: 
gle
TT ???
CA sin
pvWuWu rrrr ++=   (9) 
multi
TT ???
DB
puWvWv rrrr ++=    (10) 
where 
1sinsin )]([ ?= niglegle spriorp
r and 
1)]([ ?= nimultimulti spriorp
r
 are the prior column vec-
tors. 
The above matrices and prior vectors are con-
structed as follows, respectively: 
WA: This affinity matrix aims to reflect the 
local relationships between sentences in each 
single document, which is defined as follows: 
   
Otherwise   0,
ji  and                                   
 )d( )d( if  ),,(
)(
cos
??
??
?
?
=
=
jijiine
ijA
sssssim
W  
  
(11) 
where d(si) refers to the document containing 
sentence si. simcosine(si,sj) is the cosine similarity 
between sentences si and sj.  
ji
ji
jiine ss
ss
sssim rr
rr
?
?
=),(cos  
 
(12) 
where is
r  and js
r are the corresponding term vec-
tors of si and sj. Note that we have (WA)ij = (WA)ji, 
and we have (WA)ii =0 to avoid self loops.  
   We can see that the matrix contains only the 
within-document relationships between sen-
tences.  
WB: This affinity matrix aims to reflect the 
global relationships between sentences in the 
document set, which is defined as follows: 
    
Otherwise   0,
 )d( )d( if  ),,(
)( cos
??
? ?
=
jijiine
ijB
sssssim
W
  
(13) 
    We can see that the matrix contains only the 
cross-document relationships between sentences. 
We do not include the within-document sen-
tence relationships in the matrix because it has 
been shown that the cross-document relation-
ships are more appropriate to reflect the global 
mutual influences between sentences than the 
within-document relationships in (Wan, 2008). 
WC: This affinity matrix aims to reflect the 
cross-document relationships between sentences 
in the document set. However, the relationships 
in this matrix are used for carrying the influ-
ences of the sentences in other documents on the 
local saliency of the sentences in a particular 
document. If we directly use Equation (13) to 
compute the matrix, the mutual influences 
would be overly used. Because other documents 
might not be sampled from the same generative 
model as the specified document, we probably 
do not want to trust them so much as the speci-
fied document. Thus a confidence value is used 
to reflect out belief that the document is sampled 
from the same underlying model as the specified 
document. Heuristically, we use the cosine simi-
larity between documents as the confidence 
value. And we use the confidence value as the 
decay factor in the matrix computation as fol-
lows: 
   
Otherwise   0,
    )d( )d( if                                     
)),(),((),(
)(
coscos
??
??
?
?
?
= ji
jiinejiine
ijc ss
sdsdsimsssim
W
  
(14) 
WD: This affinity matrix aims to reflect the 
within-document relationships between sen-
tences. Thus we have WD=WA, which means that 
the global saliency score of a sentence is influ-
enced only by the local saliency scores of the 
sentences in the same document, without con-
sidering the sentences in other documents.  
Note that the above four matrices are symmet-
ric and we can replace TAW , TBW , TCW and TDW  
by WA, WB, WC and WD in Equations (9) and 
(10), respectively. 
priorsingle(si): It is computed under the as-
sumption that the first sentences in a document 
are usually more important than other sentences.  
1)(
15.0)(sin
+
+=
i
igle sposition
sprior   
(15) 
where position(si) returns the position number of 
sentence si in its document d(si). For example, if 
1140
si is the first sentence in its document, position(si) 
is 1.  
The  prior weight is then normalized by: 
?= i igle
igle
igle sprior
sprior
sprior
)(
)(
)(
sin
sin
sin
  
(16) 
priormulti(si): We also let the prior weight re-
flect the influence of sentence position. 
)()( sin igleimulti spriorsprior =  (17) 
And then the prior weight is normalized in the 
same way. 
The above definitions are for generic docu-
ment summarizations and the above algorithm 
can be easily adapted for topic-focused summa-
rizations. Given a topic q, the only change for 
the above computation is priormulti(si). The topic 
relevance is incorporated into the prior weight as 
follows: 
),()( cos qssimsprior iineimulti =  (18) 
?= i imulti
imulti
imulti sprior
spriorsprior
)(
)()(   (19) 
In order to solve the iterative problem defined 
in Equations (9) and (10), we let TT ]  [ Tvur rrr = , 
T]  [ Tmulti
T
single ppp
rrr ??= , 
???
?
???
?
=
T
B
T
D
T
C
T
A
WW
WWW
??
??
   
   , and 
then the iterative equations correspond to the 
following linear system: 
prWr rrr +=  (20) 
prWI rr =? )(  (21) 
To guarantee the solution of the above linear 
system, W is normalized by columns. If all the 
elements of a column are zero, we replace the 
elements with 1/(2n), where 2n equals to the 
element number of the column. We then multi-
ply W by a decay factor ? (0<?<1) to scale down 
each element in W, but remain the meaning of 
W. Here, ? is empirically set to 0.61. Finally, 
Equation (21) is rewritten as follows: 
prWI rr =?? )( ?  (22) 
Thus, the matrix (I-?W) is a strictly diago-
nally dominant matrix and the solution of the 
linear system exists and we can apply the Gauss-
Seidel method used in (Li et al, 2008) to solve 
the linear system. The GS method is a well-
know method for numeric computation in 
                                                 
1  In our pilot study, we can observe good performance 
when ? is in a wide range of [0.4, 0.8]. 
mathematics and the details of the method is 
omitted here.  
4 Empirical Evaluation 
4.1 Dataset and Evaluation Metric 
Generic single-document and multi-document 
summarizations have been the fundamental tasks 
in DUC 2001 and DUC 2002 (i.e. tasks 1 and 2 
in DUC 2001 and tasks 1 and 2 in DUC 2002), 
and we used the two datasets for evaluation. 
DUC2001 provided 309 articles, which were 
grouped into 30 document sets. Generic sum-
mary of each article was required to be created 
for task 1, and generic summary of each docu-
ment set was required to be created for task 2. 
The summary length was 100 words or less. 
DUC 2002 provided 59 document sets consist-
ing of 567 articles (D088 is excluded from the 
original 60 document sets by NIST) and generic 
summaries for each article and each document 
set with a length of approximately 100 words 
were required to be created. The sentences in 
each article have been separated and the sen-
tence information has been stored into files.  The 
summary of the two datasets are shown in Table 
1.  
 DUC 2001 DUC 2002
Task Tasks 1, 2 Tasks 1, 2 
Number of documents 309 567 
Number of clusters 30 59 
Data source TREC-9 TREC-9 
summary length 100 words 100 words 
  Table 1. Summary of datasets  
We used the ROUGE toolkit2  (Lin and Hovy, 
2003) for evaluation, which has been widely 
adopted by DUC for automatic summarization 
evaluation. It measured summary quality by 
counting overlapping units such as the n-gram, 
word sequences and word pairs between the 
candidate summary and the reference summary.  
The ROUGE toolkit reported separate recall-
oriented scores for 1, 2, 3 and 4-gram, and also 
for longest common subsequence co-
occurrences. We showed three of the ROUGE 
metrics in the experimental results: ROUGE-1 
(unigram-based), ROUGE-2 (bigram-based), 
and ROUGE-W (based on weighted longest 
common subsequence, weight=1.2). In order to 
truncate summaries longer than the length limit, 
                                                 
2 We used ROUGEeval-1.4.2 in this study. 
1141
we used the ?-l 100? option in ROUGE toolkit. 
We also used the ?-m? option for word stem-
ming. 
4.2 Evaluation Results 
4.2.1 System Comparison 
In the experiments, the combination weight ? for 
the prior score is fixed at 0.15, as in the PageR-
ank algorithm. Therefore, we have ?+?=0.85. 
Here, we use ?/(?+?) to indicate the relative 
contributions of the first two parts in Equations 
(9) and (10). We empirically set ?/(?+?)=0.4 in 
the experiments.  The proposed unified approach 
(i.e. UnifiedRank) is compared with a few base-
line approaches and the top three participating 
systems.  
The graph-based baselines for single-
document summarization are described as fol-
lows: 
BasicRank: This baseline approach adopts 
the basic PageRank algorithm to rank sentences 
based on all sentence relationships in a single 
document, similar to previous work (Mihalcea 
and Tarau, 2004).  
PositionRank: This baseline approach im-
proves the basic PageRank algorithm by using 
the position weight of a sentence as the prior 
score for the sentence. The position weight of a 
sentence is computed by using Equation (15). 
CollabRank1: This baseline approach is the 
?UniformLink(Gold)? approach proposed in 
(Wan et al 2007b).  It uses a cluster of multiple 
documents to improve single document summa-
rization by constructing a global affinity graph.   
CollabRank2: This baseline approach is the  
?UnionLink(Gold)? approach proposed in (Wan 
et al 2007b).  
The graph-based baselines for multi-
document summarization are described as fol-
lows: 
BasicRank: This baseline approach adopts 
the basic PageRank algorithm to rank sentences 
based on all sentence relationships in document 
set. Both within-document and cross-document 
sentence relationships are used for constructing 
the affinity graph. 
PositionRank: Similarly, this baseline ap-
proach improves the basic PageRank algorithm 
by using the position weight of a sentence as the 
prior score for the sentence.  
TwoStageRank: This baseline approach lev-
erages the results of single document summari-
zation for multi-document summarization. It 
first computes the score of each sentence within 
each single document by using the PositionRank 
method, and then computes the final score of 
each sentence within the document set by con-
sidering the document-level sentence score as 
the prior score in the improved PageRank algo-
rithm.  
The top three systems are the systems with 
highest ROUGE scores, chosen from the partici-
pating systems on each task, respectively. Ta-
bles 2 and 3 show the comparison results for 
single-document summarization on DUC2001 
and DUC2002, respectively. Tables 4 and 5 
show the comparison results for multi-document 
summarization on DUC2001 and DUC2002, 
respectively. In the tables, SystemX (e.g. Sys-
tem28, SystemN) represents one of the top per-
forming systems. The systems are sorted by de-
creasing order of the ROUGE-1 scores.  
For single-document summarization, the pro-
posed UnifiedRank approach always outper-
forms the four graph-based baselines over all 
three metrics on both two datasets. The per-
formance differences are all statistically signifi-
cant by using t-test (p-value<0.05). The 
ROUGE-1 score of UnifiedRank is higher than 
that of the best participating systems and the 
ROUGE-2 and ROUGE-W scores of Unifie-
dRank are comparable to that of the best partici-
pating systems.  
For multi-document summarization, the pro-
posed UnifiedRank approach outperforms all the 
three graph-based baselines over all three met-
rics on the DUC2001 dataset, and it outperforms 
the three baselines over ROUGE-1 and 
ROUGE-W on the DUC2002 dataset. In particu-
lar, UnifiedRank can significantly outperform 
BasicRank and TwoStageRank over all three 
metrics on the DUC2001 dataset (t-test, p-
value<0.05). Moreover, the ROUGE-1 and 
ROUGE-W scores of UnifiedRank are higher 
than that of the best participating systems and 
the ROUGE-2 score of UnifiedRank is compa-
rable to that of the best participating systems. 
The results demonstrate that the single-
document and multi-document summarizations 
can benefit each other by making use of the mu-
tual influences between the local saliency and 
1142
global saliency of the sentences. Overall, the 
proposed unified graph-based approach is effec-
tive for both single document summarization 
and multi-document summarization. However, 
the performance improvement for single-
document summarization is more significant 
than that for multi-document summarization, 
which shows that the global information in a 
document set is very beneficial to summariza-
tion of each single document in the document 
set.  
 
System ROUGE-1 ROUGE-2 ROUGE-W
UnifiedRank 0.45377 0.17649 0.14328 
CollabRank2 0.44038 0.16229 0.13678 
CollabRank1 0.43890 0.16213 0.13676 
PositionRank 0.43596 0.15936 0.13684 
BasicRank 0.43407 0.15696 0.13629 
Table 2. Comparison results for single-document 
summarization on DUC20013 
System ROUGE-1 ROUGE-2 ROUGE-W
UnifiedRank 0.48478 0.21462 0.16877 
System28 0.48049 0.22832 0.17073 
System21 0.47754 0.22273 0.16814 
CollabRank1 0.47187 0.20102 0.16318 
CollabRank2 0.47028 0.20046 0.16260 
PositionRank 0.46618 0.19853 0.16180 
System31 0.46506 0.20392 0.16162 
BasicRank 0.46261 0.19457 0.16018 
Table 3. Comparison results for single-document 
summarization on DUC2002 
System ROUGE-1 ROUGE-2 ROUGE-W
UnifiedRank 0.36360 0.06496 0.10950 
PositionRank 0.35733 0.06092 0.10798 
BasicRank 0.35527 0.05608 0.10641 
TwoStageRank 0.35221 0.05500 0.10515 
SystemN 0.33910 0.06853 0.10240 
SystemP 0.33332 0.06651 0.10068 
SystemT 0.33029 0.07862 0.10215 
Table 4. Comparison results for multi-document 
summarization on DUC2001 
System ROUGE-1 ROUGE-2 ROUGE-W
UnifiedRank 0.38343 0.07855 0.12341 
PositionRank 0.38056 0.08238 0.12292 
TwoStageRank 0.37972 0.08166 0.12261 
BasicRank 0.37595 0.08304 0.12173 
System26 0.35151 0.07642 0.11448 
System19 0.34504 0.07936 0.11332 
System28 0.34355 0.07521 0.10956 
Table 5. Comparison results for multi-document 
summarization on DUC2002 
                                                 
3 The summarization results for participating systems on 
DUC2001 are incomplete. 
4.2.2 Influences of Combination Weight 
In the above experiments, the relative contribu-
tions from the first two parts in Equations (9) 
and (10) are empirically set as ?/(?+?)=0.4. In 
this section, we investigate how the relative con-
tributions influence the summarization perform-
ance by varying ?/(?+?) from 0 to 1. A small 
value of ?/(?+?) indicates that the contribution 
from the same kind of saliency scores of the sen-
tences is less important than the contribution 
from the different kind of saliency scores of the 
sentences, and vice versa. Figures 1-8 show the 
ROUGE-1 and ROUGE-W curves for single-
document summarization and multi-document 
summarization on DUC2001 and DUC2002, 
respectively.  
For single document summarization, very 
small value or very large value for ?/(?+?) will 
lower the summarization performance values on 
the two datasets. The results demonstrate that 
both the two kinds of contributions are impor-
tant to the final performance of single document 
summarization. 
For multi-document summarization, a rela-
tively large value (?0.4) for ?/(?+?) will lead to 
relatively high performance values on the 
DUC2001 dataset, but a very large value for 
?/(?+?) will decrease the performance values. 
On the DUC2002 dataset, a relatively small 
value (?0.4) will lead to relatively high per-
formance values, but a very small value for 
?/(?+?) will decrease the performance values. 
Though the trends of the curves on the 
DUC2001 and DUC2002 datasets are not very 
consistent with each other, the results show that 
both the two kinds of contributions are benefi-
cial to the final performance of multi-document 
summarization. 
5 Conclusion and Future Work 
In this study, we propose a novel unified ap-
proach to simultaneous single-document and 
multi-document summarization by making using 
of the mutual influences between the two tasks. 
Experimental results on the benchmark DUC 
datasets show the effectiveness of the proposed 
approach.  
In future work, we will perform comprehen-
sive experiments for topic-focused document 
1143
summarizations to show the robustness of the 
proposed approach.  
DUC2001
0.444
0.446
0.448
0.45
0.452
0.454
0.456
0.458
0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1
?/(?+?)
RO
U
G
E-
1
 
Figure 1. ROUGE-1 vs. combination weight for sin-
gle-document summarization on DUC2001 
DUC2001
0.14
0.1405
0.141
0.1415
0.142
0.1425
0.143
0.1435
0.144
0.1445
0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1
?/(?+?)
RO
U
G
E-
W
 
Figure 2. ROUGE-W vs. combination weight for 
single-document summarization on DUC2001 
DUC2002
0.474
0.476
0.478
0.48
0.482
0.484
0.486
0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1
?/(?+?)
RO
U
G
E-
1
 
Figure 3. ROUGE-1 vs. combination weight for sin-
gle-document summarization on DUC2002 
DUC2002
0.164
0.165
0.166
0.167
0.168
0.169
0.17
0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1
?/(?+?)
R
O
U
G
E-
W
 
Figure 4. ROUGE-W vs. combination weight for 
single-document summarization on DUC2002 
DUC2001
0.34
0.345
0.35
0.355
0.36
0.365
0.37
0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1
?/(?+?)
RO
U
G
E-
1
 
Figure 5. ROUGE-1 vs. combination weight for 
multi-document summarization on DUC2001 
DUC2001
0.102
0.104
0.106
0.108
0.11
0.112
0.114
0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1
?/(?+?)
RO
U
G
E-
W
 
Figure 6. ROUGE-W vs. combination weight for 
multi-document summarization on DUC2001 
DUC2002
0.374
0.376
0.378
0.38
0.382
0.384
0.386
0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1
?/(?+?)
R
O
U
G
E-
1
 
Figure 7. ROUGE-1 vs. combination weight for 
multi-document summarization on DUC2002 
DUC2002
0.12
0.121
0.122
0.123
0.124
0.125
0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1
?/(?+?)
RO
U
G
E-
W
 
Figure 8. ROUGE-W vs. combination weight for 
multi-document summarization on DUC2002 
Acknowledgments 
This work was supported by NSFC (60873155), 
Beijing Nova Program (2008B03) and NCET 
(NCET-08-0006).  
1144
References  
J. Carbonell, J. Goldstein. 1998. The Use of MMR, 
Diversity-based Reranking for Reordering Docu-
ments and Producing Summaries. In Proceedings 
of SIGIR1998, 335-336. 
J. M. Conroy, D. P. O?Leary. 2001. Text Summariza-
tion via Hidden Markov Models. In Proceedings 
of SIGIR2001, 406-407. 
H. Daum? and D. Marcu. 2006. Bayesian query-
focused summarization. In Proceedings of ACL-
06. 
H. P. Edmundson. 1969. New Methods in Automatic 
Abstracting. Journal of the Association for com-
puting Machinery, 16(2): 264-285. 
G. ErKan, D. R. Radev. 2004. LexPageRank: Pres-
tige in Multi-Document Text Summarization. In 
Proceedings of EMNLP2004. 
B. Hachey. 2009. Multi-document summarisation 
using generic relation extraction. In Proceedings 
of EMNLP2009. 
S. Harabagiu and F. Lacatusu. 2005. Topic themes 
for multi-document summarization. In Proceed-
ings of SIGIR-05. 
E. Hovy, C. Y. Lin. 1997. Automated Text Summari-
zation in SUMMARIST. In Proceeding of 
ACL?1997/EACL?1997 Worshop on Intelligent 
Scalable Text Summarization. 
J. Kupiec, J. Pedersen, F. Chen. 1995. A.Trainable 
Document Summarizer. In Proceedings of 
SIGIR1995, 68-73. 
W. Li, F. Wei, Q. Lu and Y. He. 2008. PNR2: rank-
ing sentences with positive and negative rein-
forcement for query-oriented update summariza-
tion. In Proceedings of COLING-08. 
L. Li, K. Zhou, G.-R. Xue, H. Zha, Y. Yu. 2009. 
Enhancing diversity, coverage and balance for 
summarization through structure learning. In Pro-
ceedings of WWW-09. 
C..-Y. Lin and E.. H. Hovy. 2002. From Single to 
Multi-document Summarization: A Prototype 
System and its Evaluation. In Proceedings of 
ACL-02. 
C.-Y. Lin and E.H. Hovy. 2003. Automatic Evalua-
tion of Summaries Using N-gram Co-occurrence 
Statistics. In Proceedings of HLT-NAACL -03. 
H. P. Luhn. 1969. The Automatic Creation of litera-
ture Abstracts. IBM Journal of Research and De-
velopment, 2(2). 
R. Mihalcea, P. Tarau. 2004. TextRank: Bringing 
Order into Texts. In Proceedings of EMNLP2004. 
R. Mihalcea and P. Tarau. 2005. A language inde-
pendent algorithm for single and multiple docu-
ment summarization. In Proceedings of IJCNLP-
05. 
V. Nastase. 2008. Topic-driven multi-document 
summarization with encyclopedic knowledge and 
spreading activation. In Proceedings of EMNLP-
08.  
L. Page, S. Brin, R. Motwani, and T. Winograd. 1998. 
The pagerank citation ranking: Bringing order to 
the web. Technical report, Stanford Digital Librar-
ies. 
D. R. Radev, H. Y. Jing, M. Stys and D. Tam. 2004. 
Centroid-based summarization of multiple docu-
ments. Information Processing and Management, 
40: 919-938. 
F. Schilder and R. Kondadadi. 2008. FastSum: fast 
and accurate query-based multi-document sum-
marization. In Proceedings of ACL-08: HLT. 
D. Shen, J.-T. Sun, H. Li, Q. Yang, and Z. Chen. 
2007. Document Summarization using Condi-
tional Random Fields. In Proceedings of 
IJCAI2007. 
X. Wan. 2008. Using Only Cross-Document Rela-
tionships for Both Generic and Topic-Focused 
Multi-Document Summarizations. Information 
Retrieval, 11(1): 25-49. 
X. Wan and J. Yang. 2008. Multi-document summa-
rization using cluster-based link analysis. In Pro-
ceedings of SIGIR-08. 
X. Wan, J. Yang and J. Xiao. 2007a. Towards an 
Iterative Reinforcement Approach for Simultane-
ous Document Summarization and Keyword Ex-
traction. In Proceedings of ACL2007.  
X. Wan, J. Yang and J. Xiao. 2007b. CollabSum: 
Exploiting Multiple Document Clustering for Col-
laborative Single Document Summarizations. In 
Proceedings of SIGIR2007.  
X. Wan, J. Yang and J. Xiao. 2007c. Manifold-
ranking based topic-focused multi-document 
summarization. In Proceedings of IJCAI-07.  
F. Wei, W. Li, Q. Lu and Y. He. 2008. Query-
sensitive mutual reinforcement chain and its ap-
plication in query-oriented multi-document sum-
marization. In Proceedings of SIGIR-08.  
K.-F. Wong, M. Wu and W. Li. 2008. Extractive 
summarization using supervised and semi-
supervised learning. In Proceedings of COLING-
08. 
H. Y. Zha. 2002. Generic Summarization and Key-
phrase Extraction Using Mutual Reinforcement 
Principle and Sentence Clustering. In Proceedings 
of SIGIR2002, 113-120. 
 
1145
