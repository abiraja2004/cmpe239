Proceedings of the 22nd International Conference on Computational Linguistics (Coling 2008), pages 993?1000
Manchester, August 2008
Domain Adaptation for Statistical Machine Translation with Domain 
Dictionary and Monolingual Corpora 
Hua Wu,  Haifeng Wang 
Toshiba (China) R&D Center 
Beijing, 100738, China 
 wuhua@rdc.toshiba.com.cn 
wanghaifeng@rdc.toshiba.com.cn 
Chengqing Zong 
NLPR, Institute of Automation 
Chinese Academy of Sciences 
 Beijing 100080, China 
cqzong@nlpr.ia.ac.cn 
 
Abstract tra
Statistical machine translation systems 
are usually trained on large amounts of 
bilingual text and monolingual text. In 
this paper, we propose a method to per-
form domain adaptation for statistical 
machine translation, where in-domain bi-
lingual corpora do not exist. This method 
first uses out-of-domain corpora to train a 
baseline system and then uses in-domain 
translation dictionaries and in-domain 
monolingual corpora to improve the in-
domain performance. We propose an al-
gorithm to combine these different re-
sources in a unified framework. Experi-
mental results indicate that our method 
achieves absolute improvements of 8.16 
and 3.36 BLEU scores on Chinese to 
English translation and English to French 
translation respectively, as compared 
with the baselines using only out-of-
domain corpora. 
1 Introduction 
In statistical machine translation (SMT), the 
translation process is modeled to obtain the 
translation  of the source sentence f  by 
maximizing the following posterior probability 
(Brown et al, 1993). 
beste
)()(maxarg
)(maxarg
|
|
ee
fee
fe
e
LM
best
pp
p
=
=
 (1)
State-of-the-art SMT systems are trained on 
large collections of bilingual corpora for the 
                                                 
?C 2008. Licensed under the Creative Commons Attri-
bution-Noncommercial-Share Alike 3.0 Unported 
license (http://creativecommons.org/licenses/by-nc-
sa/3.0/). Some rights reserved. 
nslation model )( | efp  and monolingual tar-
get language corpora for the language model 
(LM) )(eLMp . The trained SMT systems are 
suitable for translating texts in the same domain 
as the training corpus. However, for some spe-
cific domains, it is difficult to obtain a bilingual 
corpus. In this case, the performance of SMT 
systems will be degraded. 
Generally, it is easier to obtain in-domain 
monolingual corpora in either source or target 
language. Moreover, in some specific domains, 
although in-domain bilingual corpora do not ex-
ist, in-domain translation dictionaries, which 
usually contain domain-specific terms and their 
translations, are available. And even if such dic-
tionaries are not available, it is easier to compile 
one than to build a bilingual corpus. Thus, in this 
paper, we address the problem of domain-
specific SMT, where only domain-specific dic-
tionaries and/or monolingual corpora exist. In a 
specific domain, there are two kinds of words: 
common words, which also frequently occur in 
out-of-domain corpora, and domain-specific 
words, which only occur in the specific domain. 
Thus, we can combine the out-of-domain bilin-
gual corpus, the in-domain translation dictionary, 
and monolingual corpora for in-domain transla-
tion. 
If an in-domain translation dictionary is avail-
able, we combine it with the out-of-domain 
translation model to improve translation quality. 
If an in-domain target language corpus (TLC) is 
available, we use it to build an in-domain lan-
guage model, which can be combined with the 
out-of-domain language model to further im-
prove translation quality. Moreover, if an in-
domain source language corpus (SLC) is avail-
able, we automatically translate it and obtain a 
synthetic in-domain bilingual corpus. By adding 
this synthetic bilingual corpus to the training data, 
we rebuild the translation model to improve 
993
translation quality. We can repeatedly translate 
the in-domain source language corpus with the 
improved model until no more improvement can 
be made. This is similar to transductive learning 
described in (Ueffing et al, 2007). 
We perform domain adaptation experiments 
on two tasks: one is the Chinese to English trans-
lation, using the test set released by the Interna-
tio
inese to English translation 
an
MT sys-
tem
lation model and language model adapta-
in domain adaptation for 
del adaptation has been 
 
shared task focused on do-
main adaptation for machine translation among 
Eu
rpora. Adding the extracted bilin-
gu
the performance of a SMT system 
tra
Moses (Koehn et al, 2007). In 
babilities, reorder-
e model probabili-
nal Workshop on Spoken Language Transla-
tion 2006 (IWSLT 2006), and the other is the 
English to French translation, using the data re-
leased by the Second Workshop on Statistical 
Machine Translation (WMT 2007) (Callison-
Burch et al, 2007). 
Experimental results indicate that our method 
achieves absolute improvements of 8.16 and 3.36 
BLEU scores on Ch
d English to French translation respectively, as 
compared with the baselines only using the out-
of-domain corpora. The results on both transla-
tion tasks also show that the translation quality 
achieved by our methods is comparable to that of 
the method using both in-domain and out-of-
domain bilingual corpora. Moreover, even if in-
domain and out-of-domain bilingual corpora are 
available, adding an in-domain dictionary also 
helps to improve the translation quality. 
The remainder of the paper is organized as fol-
lows. In section 2, we describe the related work. 
Section 3 briefly introduces the baseline 
 used in our experiments. Section 4 describes 
our domain adaptation method of using in-
domain dictionary and monolingual corpora. And 
then we present the experimental results in sec-
tions 5. In the last section, we conclude this pa-
per. 
2 Related Work 
Trans
tion are usually used 
SMT. Language mo
widely used in speech recognition (Bacchiani 
and Roark, 2003). In recent years, language 
model adaptation has also been studied for SMT 
(Bulyko et al, 2007). They explored discrimina-
tive estimation of language model weights by 
directly optimizing machine translation perform-
ances such as BLEU score (Papineni et al, 2002).
Their experiments indicated about 0.4 BLEU 
score improvement. 
A shared task is organized as part of the Sec-
ond Workshop on Statistical Machine Transla-
tion. A part of this 
ropean languages. Several studies investigated 
mixture model adaptation for both translation 
model and language model in SMT (Civera and 
Juan, 2007; Foster and Kuhn, 2007). Koehn and 
Schroeder (2007) investigated different adapta-
tion methods for SMT. Their experiments indi-
cate an absolute improvement of more than 1 
BLEU score. 
To enlarge the in-domain bilingual corpus, 
Munteanu and Marcu (2005) automatically ex-
tracted in-domain bilingual sentence pairs from 
comparable co
al corpus to the training data improved the per-
formance of the MT system. In addition, Ueffing 
et al (2007) explored transductive learning for 
SMT, where source language corpora are used to 
train the models. They repeatedly translated 
source sentences from the development set and 
test set. Then the generated translations are used 
to improve the performance of the SMT system. 
This kind of transductive learning can be seen as 
a means to adapt the SMT system to a new type 
of texts. 
In this paper, we use an in-domain translation 
dictionary and/or in-domain monolingual corpora 
(in both source language and target language) to 
improve 
ined on the out-of-domain corpora. Thus, our 
method uses these resources, instead of an in-
domain bilingual corpus, to adapt a baseline sys-
tem trained on the out-of-domain corpora to in-
domain texts. 
3 Baseline MT System 
The phrase-based SMT system used in our ex-
periments is 
Moses, phrase translation pro
ing probabilities, and languag
ties are combined in the log-linear model to ob-
tain the best translation beste  of the source sen-
tence f : 
?
=
?
=
M
p | )(maxarg fee ebest
 (2)
m
mmh
1
,(maxarg f)ee ?
The weights are set by a discriminative train-
ing method using a held-out data set as describ
in (Och, 2003). The models or features which are 
employed by the decoder are (a) one or several 
ph
ed 
rases tables, (b) one or more language models 
trained with SRILM toolkit (Stolcke, 2002), (c) 
distance-based and lexicalized distortion models, 
(d) word penalty, (e) phrase penalty. 
994
Input  Out-of-domain training data OL  
ary D  In-domain translation diction  I
In-domain target language corpus IT  (optional) 
           In-d
, where  represents the general model. 
e 
f 
If  
         
e
ing step: Translate  with  to get a synthetic bilingual corpus 
Un
E
End 
Outpu l  for in-domain translation 
omain source language corpus I  (optional) S
Begin Assign translation probabilities to ID  
If IT  is available 
Training step: (L Estimate= ),, IIO TD?
Els
?
Training step: ),( IO DL Estimate=?  
End i
 S  is availableI
    ? =)0( ?,  0=i
R peat 
 
1+= ii  
Label IS
)1( ?i? IL  
Training step: ),, IIO
til no more improvement can be achieved 
()(i LDL estimate-Re=?  
)(i?  ?=
nd if 
t  Mode  ?
Figure 1.The domain adaptation algorithm 
4 The Framework 
n about the algorithm is 
 our algorithm, a phrase 
available, we train an in-domain LM, which is 
co
ilable, we use the built -linear 
m
). With the 
 order to 
 to assign prob-
nary.  
m
4.1 The Algorithm 
The detailed informatio
shown in Figure 1. In
table and a language model are first constructed 
based on the out-of-domain corpus OL . Then 
probabilities are automatically assigned to the 
entries in the in-domain translation dictionary 
ID , from which another phrase table is con-
structed. At last, the two phrase tables are com-
d. This is the procedure of the training step 
),( IO DL Estimate=? . 
If an in-domain target language corpus is 
bine
mbined with the out-of-domain LM. The built 
phrase tables and LMs are integrated in the log-
linear model as described in section 3. This is the 
procedure of ),,( IIO TDL Estimate=? . 
Moreover, if an in-domain source language 
corpus is ava log
odel to translate the in-domain source texts and 
obtain a synthetic bilingual corpus. And then we 
add the synthetic bilingual corpus into the train-
ing data to improve the current log-linear model 
improved model, we repeatedly translate the in-
domain source texts until no more improvement 
on a development set can be achieved.  
4.2 Dictionary Probabilities 
In general, there is no translation probability in a 
manually-made translation dictionary. In
( estima-Re=? ),,()( IIOi LDL te
construct a phrase table, we have
abilities to the entries in the dictio
Uniform Translation Probability: Since we 
have no parallel corpus to estimate the translation 
probabilities, we simply assign uniform prob-
abilities to the entries in the dictionary. With this 
ethod, if a source word has n  translations, then 
we assign n1  to each translation of this phrase 
for all the four scores of the phrase pair. 
Constant Translation Probability: For each 
entry in the dictionary, we as ign a fixed score. 
In this case e sum of the translation probability 
is not necessarily equal to 1. 
s
, th
anslation probabili-
ties for the entries in the dictionary. And for the 
Corpus Translation Probability: If an in-
domain monolingual source corpus exists, we 
translate it with the method as described in Fig-
ure 1, and then estimate the tr
995
en
s.  
mmonly-used 
tries whose translation probabilities are not 
estimated, we assign average probabilities that 
are calculated from the entries that have obtained 
probabilities. 
4.3 Combining Phrase Tables  
In the algorithm, there are two kinds of phrase 
tables. We need to combine them to translate the 
in-domain text
Mixture Model: The most co
method is linear interpolation.  
)()1()()( ||| fefefe oI ppp ?? ?+=  (3)
W
ion probabili-
ties. 
here )( | feIp  and )( | feop  are the in-
domain and out-of-domain translat
?  is the interpolation weight. 
Discriminative Model: An alternative is to 
two tables in the log-linea  
ranslation oses, for 
en uses them 
fo
he out-of-domain lan-
tigate two 
ation and 
two different tasks: one 
is the Chinese to English translation in IWSLT 
 the other is the English to 
n adaptation translation in the 
red task. 
airs, with about 3 mil-
lio
                                                
combine the r model.
During t with M each phrase in 
the sentence, the decoder obtains all of its trans-
lations in both phrase tables, and th
r translation expansion. 
4.4 Combining Language Models 
If an in-domain target language corpus exists, we 
use it to construct an in-domain language model, 
which is combined with t
guage model. In this paper, we inves
combination methods: linear interpol
log-linear interpolation. 
5 Experiments  
5.1 Setting 
We ran experiments on 
2006 evaluation, and
French domai
WMT 2007 sha
For the Chinese to English translation task, we 
use the Chinese-English bilingual corpus pro-
vided by the Chinese Linguistic Data Consortium 
(CLDC)2 as the out-of-domain corpus. It con-
tains 156,840 sentence p
n English words and about 5 million Chinese 
characters.  In addition, we use the Basic Travel-
ing Expression Corpus (BTEC) released by 
IWSLT 2006 (Paul, 2006) to construct an in-
domain phrase table, as a comparison with that 
one constructed with the in-domain dictionary. 
 
2  http://www.chineseldc.org/EN/index.htm. The catalog 
number is CLDC-LAC-2003-004. It is a balanced corpus 
containing sentence pairs in multiple domains. 
Corpora Sentences OOV 
CLDC 156,840 89 (6.31%) 
BTEC 39,953 179 (12.69%) 
IWSLT06-dev4 489 NA 
IWSLT06-test 500 NA 
Table 1. Ch sh cor
aries Entries 
inese-Engli pora 
Diction OOV 
LDC 82,090 228 (16.16%) 
in-domain 32  .57%) ,821 121 (8
T s 
ces 
able 2. Chinese-English dictionarie
Corpora Senten OOV 
Europarl 949,410 412 (5.90%) 
NC 43,060 599 (8.58%) 
WMT07 dev 1,057 NA 
WMT07 test 2,007 NA 
Table 3. E ch cor
I art and rt a sed 
a in m ual  ex-
p  ta rts of  CLDC and 
BTEC are used for language m  construction 
(see Tab uation, 
nglish-Fren pora 
ts source p  target p
g
a re separately u
ra in ours the in-doma
e
onolin corpo
eriments. Th rget pa  both
odel
le 1). From the IWSLT 2006 eval
we choose the devset4 as our development data. 
Evaluation was performed on IWSLT 2006 test 
set. The references for the test set contain lower-
case words and punctuations. The detailed in-
formation is shown in Table 1. 
We use two kinds of manually-made diction-
aries for comparison: one is the LDC Chinese-
English Translation Lexicon Version 3.0 
(LDC2002L27), and the other is the in-domain 
spoken language dictionary made by ourselves, 
which contains in-domain Chinese words and 
their English translations. The dictionary is ma-
nually constructed. Some entries of the diction-
ary are collected from phrase books. Some of 
them are collected from the general-domain dic-
tionaries. And then, the entries are filtered and 
modified by a Chinese native speaker specialized 
in English. The detailed information is shown in 
Table 2. If a source word has two translations, it 
is counted as two entries. The OOV rates of the 
test set uncovered by the LDC dictionary and the 
in-domain dictionary are 16.16% and 8.57%, 
respectively. 
For the English to French translation task, the 
out-of-domain corpus is the Europarl corpus dis-
tributed for the shared task of WMT 2007 (Calli-
son-Burch et al, 2007)3. We filter the sentence 
pairs whose lengths are above 40 words. For the 
                                                 
3 http://www.statmt.org/wmt07/shared-task.html 
996
in-domain corpus, we use the News Commentary 
(NC) corpus distributed in WMT 2007. We also 
use the same development set and test set in the 
domain adaptation shared task (see Table 3). We 
manually built an in-domain English-French dic-
tionary according to the in-domain bilingual cor-
pus, which includes 26,821 entries. It contains 
in-domain English words and their French trans-
lations. The OOV rate of the test set uncovered 
by this dictionary is 22.34%. 
5.2 Evaluation Measures 
To perform phrase-based SMT, we use the 
rt training scripts. 
efault settings and 
ary 
rase table. With the in-
domain translation dictionary, we construct in-
do
lts, log-linear 
tra
tionary into the training corpus. In 
th
omain 
corpus to train a phrase table. Then we use both  
Moses decoder and its suppo
We run the decoder with its d
then use Moses' implementation of minimum 
error rate training (Och, 2003) to tune the feature 
weights on the development set. Translation 
quality was evaluated using BLEU score (Pap-
ineni et al, 2002).  
5.3 Results on Chinese-English Translation 
Translation Diction
With the out-of-domain bilingual corpus, we 
train an out-of-domain ph
main phrase tables by assigning different 
translation probabilities with two different meth-
ods: uniform and constant. For the constant 
translation probability, we set the score using the 
development set. In our experiments, we set it to 
1. We use the target part of the out-of-domain 
corpus to train a language model4. 
With two phrase tables, we combine them in a 
linear or log-linear method as described in sec-
tion 4.3. In our experimental resu
nslation models outperform the linear models 
(16.38 vs. 15.12), where the entries of the dic-
tionary are assigned with the constant translation 
probabilities. Thus, we will use log-linear models 
for phrase table combination in the following 
experiments. 
Another method to combine the out-of-domain 
corpus and the translation dictionary is to add the 
in-domain dic
is case, only one phrase table is trained. 
Table 4 describes the results using the out-of-
domain corpus and the in-domain dictionary. The 
baseline method only uses the out-of-d
                                                 
4 We also used LDC English Gigaword to train a large lan-
guage model. However, this language model did not im-
prove the translation quality. 
Methods Resources Used BLEU(%)
baseline out-of-domain corpus 13.59 
+dictionary as corpus 15.52 
+uniform prob. 16.00 
+constant prob. 16.38 
baseline + 
dictionary
+corpus prob. 16.72 
Table 4. Translation results of using out-of-
d ictionary
the out-of-dom  the in-dom c-
5 . The 
 also 
im
bine it with the 
 linear inter-
polation and log-linear interpolation. The ex-
pe
oves 
th
ifference be-
tw
 
                                                
omain corpus and in-domain d  
ain corpus and ain di
tionary. The results indicate that adding an in- 
domain dictionary significantly improves the 
translation quality by 2.79 BLEU score
methods using the dictionary as a phrase table 
outperform the method adding it to the training 
corpus. And the method using constant transla-
tion probabilities significantly outperforms that 
using the uniform translation probabilities. 
For comparison, we also assign corpus prob-
abilities to the entries in the dictionary by trans-
lating the source part of the BTEC corpus with 
the method described in Section 4.2. This
proves the translation quality. 
In-Domain Monolingual Corpora 
We use the target part of the BTEC corpus to 
train an in-domain LM. We com
out-of-domain LM in two methods:
rimental results indicate that linear interpola-
tion outperforms log-linear interpolation (17.16 
vs. 16.20). Thus, we will use linear interpolation 
for LMs in all of the following experiments. 
Table 5 describes the results of using the in-
terpolated language model. As compared with 
the results in Table 4, it can be seen that adding 
the in-domain language model greatly impr
e translation quality. It achieves an absolute 
improvement of 3.57 BLEU score as compared 
with the baseline model. If the in-domain transla-
tion dictionary is used, the translation quality is 
further improved by 4 BLEU score. 
If the in-domain source language data is avail-
able, we translate it and obtain a synthetic bilin-
gual corpus. Then we perform transductive learn-
ing as described in Figure 1. The d
een our method and that in (Ueffing et al, 
2007) is that we translate a larger in-domain 
source corpus, and we use 1-best translation 
 
5 We use the method described in (Koehn and Monz, 2006) 
for significance test. In this paper, significant improvement 
means method A outperforms method B on a significance 
level of no less than 95%. 
997
Methods Models  Resources used BLEU(%)
baseline Model 1 out-of-domain corpus 13.59 
baseline + TLC  Model 2 + in-domain TLC 17.16 
Model 3 + in-domain TLC + dictionary (uniform prob.) 20.83 baseline + TLC 
 dictionary (constant prob.) + dictionary Model 4 + in-domain TLC + 21.16 
Model 5 + in-domain SLC 15.98 
Model 6 + in-domain SLC and TLC 18.19 
transductive 
learning 
nd TLC + dictionary (corpus prob.) Model 7 + in-domain SLC a 21.75 
Table 5. 
Diction  BLEU(%)
Translation results of using in-domain resources 
ary types Entries OOV
general domain LDC 228 (1 %) 82,090 6.16 19.11 
manual 121 ) 32,821 (8.57% 21.16 
in-domain 
extracted 11,765 330 (23.39%) 19.88 
LD al C + manu 106,572 45 (3.19%) 21.34 combined 
LDC + extracted 95,660 202 (14.31%) 20.49 
Table 6. Comparison of ictionar
result with full re-training.
that transductive learning 
ed, the transla-
tio
tionaries 
with concern to the translation quality. Besides 
ld as described in (Wu and 
Wang, 2007). 
 phrase table, extract the 
 their translations. 
 
us
 when an in-domain bi-
m
d  different ies 
 The results indicate 
improves translation 
? From the filtered
Chinese words and
quality in all cases. For example, Model 5 
achieves an absolute improvement of 2.39 BLEU 
score over Model 1, and Model 6 achieves 1.03 
BLEU score improvement over Model 2. Model 
7 uses the in-domain dictionary with corpus 
translation probabilities, which are obtained from 
the phrase table trained with the synthetic bilin-
gual corpus. The results indicate that Model 7 
outperforms Model 4, with a significant im-
provement of 0.59 BLEU score.  
The results also indicate that when only the in-
domain monolingual corpus is us
n quality is improved by 4.6 BLEU score 
(Model 6 vs. Model 1). By adding the in-domain 
dictionary, the translation quality is further im-
proved, achieving an absolute improvement of 
8.16 BLEU score (Model 7 vs. Model 1). 
Comparison of Different Dictionaries 
We compare the effects of different dic
the manually-made in-domain dictionary, we use 
other two dictionaries: the LDC dictionary and 
an automatically built dictionary, which is ex-
tracted from the BTEC corpus. This extracted 
dictionary only contains Chinese words and their 
translations. The extraction method is as follows:  
? Build a phrase table with the in-domain bi-
lingual corpus. 
? Filter those phrase pairs whose values are 
below a thresho
? Assign constant translation probabilities to 
the entries of the extracted dictionary. 
Table 6 shows the translation results. All of 
the methods use the out-of-domain corpus, the 
in-domain target language corpus, and the corre-
sponding translation dictionaries with constant 
translation probabilities. The results indicate that
ing the general-domain dictionary also im-
proves translation quality, achieving an im-
provement of about 2 BLEU score as compared 
with Model 2 in Table 5. It can also be seen that 
the in-domain dictionaries significantly outper-
form the LDC dictionary although the extracted 
dictionary has a higher OOV rate than the LDC 
dictionary. Further analysis shows that the LDC 
dictionary does not contain the in-domain trans-
lations of some words. Results also indicate that 
combining the two kinds of dictionaries helps to 
slightly improve translation quality since the 
OOV rates are reduced. 
Comparison with In-domain Bilingual Corpus 
The aim of this section is to investigate 
whether the in-domain dictionary helps to im-
prove translation quality
lingual corpus is available. And we will also 
compare the translation results with those of the 
ethods only using in-domain dictionaries and 
monolingual corpora. 
To train the in-domain translation model, we 
use the BTEC corpus. The translation results are 
998
13
14
15
16
17
18
19
20
21
22
23
100k 200k 300k all
In-domain sentence pairs
BL
EU
 (
%)
CLDC
BTEC
CLDC+BTEC
CLDC+BTEC+Dic
CLDC+Mono+Dic
Figure 2. Comparison of different methods using 
different resources. 
shown in Figure 2. CLDC and BTEC represent 
s linear interpolation of the 
Interpolated LM" means that 
the methods that only use the out-of-domain and 
the in-domain corpus, respectively. The method 
"CLDC+BTEC" use
phrase tables and LMs trained with CLDC and 
BTEC.   "Dic" means using the in-domain dic-
tionary, and "Mono" means using in-domain 
source and target language corpora. 
From the results, it can be seen that (a) even if 
an in-domain bilingual corpus exists, the in-
domain dictionary also helps to improve the 
translation quality, as "CLDC+BTEC+Dic" 
achieves an improvement of about 1 BLEU score 
in comparison with "CLDC+BTEC"; (b) the 
method "CLDC+Mono+Dic", which uses both 
the in-domain monolingual corpora and the in-
domain dictionary, achieves high translation 
quality. It achieves slightly higher translation 
quality than "CLDC+BTEC" that uses the in-
domain bilingual corpus (21.75 vs.  21.62)  and 
achieves slightly lower translation quality than 
"CLDC+BTEC+Dic" (21.75 vs. 22.05). But the 
differences are not significant. This indicates that 
our method using an in-domain dictionary and 
in-domain monolingual corpora is effective for 
domain adaptation. 
5.4 Results on English-French Translation 
We perform the same experiments for English to 
French translation. Table 7 describes the domain 
adaptation results. "
we use the target part of the NC corpus to train 
an in-domain LM, and then linearly interpolate it 
with the out-of-domain LM trained with the Eu-
roparl corpus. The results indicate that using an 
in-domain target corpus significantly improves 
the translation quality, achieving an improve-
ment of 2.19 BLEU score (from 25.44 to 27.63).  
Methods Out-of-domain LM 
Interpolated 
LM 
Europarl 25.44 27.63 
Europarl+Dic 26.24 28.22 
transductive 
learning - 2  8.80
Europarl+NC - 29.19 
Europarl+NC+Dic - 29.41 
T ation result f using i in 
d onolingual corpora 
Using the in-domain translation dictionary im-
used (from 
29.19 to 29.41). 
n Table 7. The results indicate 
th
28.80). Although the translation quality 
is 
This 
 an out-of-domain corpus to 
ystem, and then used an in-
ion dictionary, to improve the transla-
able 7. Transl
ictionary and m
s o n-doma
proves translation quality in all cases, even when 
the in-domain bilingual corpus is 
We also perform transductive learning with 
the source part of the NC corpus. The model 
used to translate the corpus is that one created by 
"Europarl+Dic" i
at transductive learning significantly improves 
translation quality, achieving an absolute im-
provement of 0.58 BLEU score (from 28.22 to 
28.80).  
In summary, using an in-domain dictionary 
and in-domain monolingual corpora improves the 
translation quality by 3.36 BLEU score (from 
25.44 to 
slightly lower than that method of using both 
in-domain and out-of-domain bilingual corpora, 
the difference is not statistically significant. 
6 Conclusion 
This paper proposed a domain adaptation ap-
proach for statistical machine translation. 
approach first used
build a baseline s
domain translation dictionary and in-domain 
monolingual corpora to adapt it to the in-domain 
texts. The contribution of this paper lies in the 
following points: 
? We proposed a method to integrate a do-
main-specific translation dictionary into a 
phrase-based SMT system for domain adap-
tation. 
? We investigated the way of using in-domain 
monolingual corpora in either source or tar-
get language, together with the in-domain 
translat
tion quality of a baseline system. 
999
We performed experiments on both Chinese to 
English and English to French translation. Ex-
perimental results on Chinese to English transla-
tio
-
vised Language Model Adaptation. In Proc. of the 
ational Conference on Acoustics, 
 Signal Processing (ICASSP-2003), 
Br
n. Computational Linguistics, 
Bu
f the 32nd International Confer-
Ca
 Statistical Ma-
Ci
 
, pages 177-180. 
Fo
Ko
ation of Machine Translation be-
Ko
erico, Nicola Bertoldi, 
Ko
istical Ma-
M
Oc
ranslation. In Proc. of 
Pa
2. BLEU: a Method for Auto-
Pa
ation Campaign. In Proc. of the International 
St
 Proc. of International 
Ue
rning for Statistical 
W
ics and Phrase-
n indicate that all of the in-domain resources 
are useful to improve in-domain translation qual-
ity, with an overall improvement of 8.16 BLEU 
score as compared with the baseline trained with 
out-of-domain corpora. Results on English to 
French translation also show that using in-
domain translation dictionaries and in-domain 
monolingual corpora is effective for domain ad-
aptation, achieving an absolute improvement of 
3.36 BLEU score. And the results on both trans-
lation tasks indicate that the translation quality 
achieved by our methods is comparable with that 
of the method using both in-domain and out-of-
domain bilingual corpora. Moreover, even if in-
domain and out-of-domain bilingual corpora are 
available, adding an in-domain dictionary also 
helps to improve the translation quality. 
In the future work, we will investigate to as-
sign translation probabilities to the dictionaries 
using comparable in-domain corpora and exam-
ine its effect on the MT performance. And we 
will also examine the effect of an in-domain dic-
tionary on transductive learning in more details. 
References 
Bacchiani, Michiel and Brian Roark. 2003. Unsuper
28th Intern
Speech, and
pages 224-227. 
own, Peter F., Stephen A. Della Pietra, Vincent J. 
Della Pietra, and Robert L. Mercer. 1993. The 
Mathematics of Statistical Machine Translation: 
Parameter Estimatio
19(2): 263-311. 
lyko, Ivan, Spyros Matsoukas, Richard Schwartz, 
Long Nguyen, and John Makhoul. 2007. Language 
Model Adaptation in Machine Translation from 
Speech. In Proc. o
ence on Acoustics, Speech, and Signal Processing 
(ICASSP-2007), pages 117-120. 
llison-Burch, Chris, Cameron Fordyce, Philipp 
Koehn, Christof Monz, and Josh Schroeder. 2007. 
(Meta-) Evaluation of Machine Translation. In 
Proc. of the Second Workshop on
chine Translation, pages 136-158. 
vera, Jorge and Alfons Juan. 2007. Domain Adapta-
tion in Statistical Machine Translation with Mix-
ture Modelling. In Proc. of the Second Workshop
on Statistical Machine Translation
ster, George and Roland Kuhn. 2007. Mixture-
Model Adaptation for SMT. In Proc. of the Second 
Workshop on Statistical Machine Translation, 
pages 128-135. 
ehn, Philipp and Christof Monz. 2006. Manual and 
Automatic Evalu
tween European Languages. In Proc. of the HLT-
NAACL 2006 Workshop on Statistical Machine 
Translation, pages 102-121. 
ehn, Philipp, Hieu Hoang, Alexanda Birch, Chris 
Callison-Burch, Marcello Fed
Brooke Cowan, Wade Shen, Christine Moran, 
Richard Zens, Chris Dyer, Ondrej Bojar, Alexandra 
Constantin, and Evan Herbst. 2007. Moses: Open 
Source Toolkit for Statistical Machine Translation. 
In Proc. of the 45th Annual Meeting of the Associa-
tion for Computational Linguistics (ACL-2007), 
demonstration session, pages 177-180. 
ehn, Philipp and Josh Schroeder. 2007. Experi-
ments in Domain Adaptation for Stat
chine Translation. In Proc. of the Second Workshop 
on Statistical Machine Translation, pages 224-227. 
unteanu, Dragos Stefan, and Daniel Marcu. 2005. 
Improving Machine Translation Performance by 
Exploiting Non-Parallel Corpora. Computational 
Linguistics, 31(4): 477-504. 
h, Franz Josef. 2003. Minimum Error Rate Train-
ing in Statistical Machine T
the 41st Annual Meeting of the Association for 
Computational Linguistics (ACL-2003), pages 160-
167. 
pineni, Kishore, Salim Roukos, Todd Ward, and 
Wei-Jing Zhu. 200
matic Evaluation of Machine Translation. In Proc. 
of the 40th Annual Meeting of the Association of 
Computational Linguistics (ACL-2002), pages 311-
318. 
ul, Michael. 2006. Overview of the IWSLT 2006 
Evalu
Workshop on Spoken Language Translation 
(IWSLT-2006), pages 1-15. 
olcke, Andrea. 2002. SRILM -- an Extensible Lan-
guage Modeling Toolkit. In
Conference on Spoken Language Processing 
(ICSLP-2002), pages 901-904. 
ffing, Nicola, Gholamreza Haffari, and Anoop 
Sarkar. 2007. Transductive Lea
Machine Translation. In Proc. of 45th Annual 
Meeting of the Association of Computational Lin-
guistics (ACL-2007), pages 25-32. 
u, Hua and Haifeng Wang. 2007. Comparative 
Study of Word Alignment Heurist
Based SMT. In Proc. of Machine Translation 
Summit XI, pages 507-514. 
1000
