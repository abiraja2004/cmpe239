Proceedings of NAACL HLT 2007, Companion Volume, pages 205?208,
Rochester, NY, April 2007. c?2007 Association for Computational Linguistics
Comparing Wikipedia and German Wordnet
by Evaluating Semantic Relatedness on Multiple Datasets
Torsten Zesch and Iryna Gurevych and Max M?hlh?user
Ubiquitous Knowledge Processing Group, Telecooperation Division
Darmstadt University of Technology, D-64289 Darmstadt, Germany
{zesch,gurevych,max} (at) tk.informatik.tu-darmstadt.de
Abstract
We evaluate semantic relatedness mea-
sures on different German datasets show-
ing that their performance depends on: (i)
the definition of relatedness that was un-
derlying the construction of the evalua-
tion dataset, and (ii) the knowledge source
used for computing semantic relatedness.
We analyze how the underlying knowl-
edge source influences the performance
of a measure. Finally, we investigate the
combination of wordnets andWikipedia to
improve the performance of semantic re-
latedness measures.
1 Introduction
Semantic similarity (SS) is typically defined via the
lexical relations of synonymy (automobile ? car)
and hypernymy (vehicle ? car), while semantic re-
latedness (SR) is defined to cover any kind of lexi-
cal or functional association that may exist between
two words. Many NLP applications, like sense tag-
ging or spelling correction, require knowledge about
semantic relatedness rather than just similarity (Bu-
danitsky and Hirst, 2006). For these tasks, it is not
necessary to know the exact type of semantic rela-
tion between two words, but rather if they are closely
semantically related or not. This is also true for the
work presented herein, which is part of a project
on electronic career guidance. In this domain, it
is important to conclude that the words ?baker? and
?bagel? are closely related, while the exact type of a
semantic relation does not need to be determined.
As we work on German documents, we evalu-
ate a number of SR measures on different German
datasets. We show that the performance of mea-
sures strongly depends on the underlying knowledge
source. While WordNet (Fellbaum, 1998) mod-
els SR, wordnets for other languages, such as the
German wordnet GermaNet (Kunze, 2004), contain
only few links expressing SR. Thus, they are not
well suited for estimating SR.
Therefore, we apply theWikipedia category graph
as a knowledge source for SR measures. We show
that Wikipedia based SR measures yield better cor-
relation with human judgments on SR datasets than
GermaNet measures. However, using Wikipedia
also leads to a performance drop on SS datasets,
as knowledge about classical taxonomic relations
is not explicitly modeled. Therefore, we combine
GermaNet with Wikipedia, and yield substantial im-
provements over measures operating on a single
knowledge source.
2 Datasets
Several German datasets for evaluation of SS or SR
have been created so far (see Table 1). Gurevych
(2005) conducted experiments with a German trans-
lation of an English dataset (Rubenstein and Goode-
nough, 1965), but argued that the dataset (Gur65)
is too small (it contains only 65 noun pairs), and
does not model SR. Thus, she created a German
dataset containing 350 word pairs (Gur350) con-
taining nouns, verbs and adjectives that are con-
nected by classical and non-classical relations (Mor-
ris and Hirst, 2004). However, the dataset is bi-
ased towards strong classical relations, as word
pairs were manually selected. Thus, Zesch and
Gurevych (2006) semi-automatically created word
pairs from domain-specific corpora. The resulting
ZG222 dataset contains 222 word pairs that are con-
nected by all kinds of lexical semantic relations.
Hence, it is particularly suited for analyzing the ca-
pability of a measure to estimate SR.
205
CORRELATION r
DATASET YEAR LANGUAGE # PAIRS POS TYPE SCORES # SUBJECTS INTER INTRA
Gur65 2005 German 65 N SS discrete {0,1,2,3,4} 24 .810 -
Gur350 2006 German 350 N, V, A SR discrete {0,1,2,3,4} 8 .690 -
ZG222 2006 German 222 N, V, A SR discrete {0,1,2,3,4} 21 .490 .647
Table 1: Comparison of datasets used for evaluating semantic relatedness.
3 Semantic Relatedness Measures
Semantic wordnet based measures Lesk (1986)
introduced a measure (Les) based on the number of
word overlaps in the textual definitions (or glosses)
of two terms, where higher overlap means higher
similarity. As GermaNet does not contain glosses,
this measure cannot be employed. Gurevych (2005)
proposed an alternative algorithm (PG) generating
surrogate glosses by using a concept?s relations
within the hierarchy. Following the description in
Budanitsky and Hirst (2006), we further define sev-
eral measures using the taxonomy structure.
simPL = l(c1, c2)
simLC = ? log
l(c1, c2)
2? depth
simRes = IC(ci) = ? log(p(lcs(c1, c2)))
distJC = IC(c1) + IC(c2)? 2IC(lcs(c1, c2))
simLin = 2?
IC(lcs(c1, c2))
IC(c1) + IC(c2)
PL is the taxonomic path length l(c1, c2) between
two concepts c1 and c2. LC normalizes the path
length with the depth of the taxonomy. Res com-
putes SS as the information content (IC) of the low-
est common subsumer (lcs) of two concepts, while
JC combines path based and IC features.1 Lin is
derived from information theory.
Wikipedia based measures For computing the
SR of two words w1 and w2 using Wikipedia, we
first retrieve the articles or disambiguation pages
with titles that equal w1 and w2 (see Figure 1). If
we hit a redirect page, we retrieve the correspond-
ing article or disambiguation page instead. In case
of an article, we insert it into the candidate article
set (A1 for w1, A2 for w2). In case of a disam-
biguation page, the page contains links to all en-
coded word senses, but it may also contain other
1Note that JC returns a distance value instead of a similarity
value resulting in negative correlation with human judgments.
Wo
rd w
2
Wo
rd w
1
1
Can
dida
te 
arti
cle sets
Can
dida
te 
arti
cle pair
s
3
a
Sem
ant
ic R
elat
edn
ess
Sem
ant
ic re
late
dne
ss o
f (w
1, w
2)
Ma
x
a
A 2
A 1
2
a
1
aArt
icle
Dis
am
big.
 pa
ge
Red
irec
ts
Figure 1: Steps for computing SR using Wikipedia.
links. Therefore, we only consider links conforming
to the pattern ?Title_(DisambiguationText)?2 (e.g.
?Train_(roller coaster)?). Following all such links
gives the candidate article set. If no disambiguation
links are found, we take the first link on the page, as
most important links tend to come first. We add the
corresponding articles to the candidate set. We form
pairs from each candidate article ai ? A1 and each
article aj ? A2. We then compute SR(ai, aj) for
each pair. The output of the algorithm is the maxi-
mum SR value maxai?A1,aj?A2(SR(ai, aj)).
3
As most SR measures have been developed for
taxonomic wordnets, porting them to Wikipedia re-
quires some modifications (see Figure 2). Text over-
lap measures can be computed based on the article
text, while path based measures operate on the cate-
gory graph. We compute the overlap between article
2?_(DisambiguationText)? is optional.
3Different from our approach, Strube and Ponzetto (2006)
use a disambiguation strategy that returns only a single candi-
date article pair. This unnecessarily limits a measure?s potential
to consider SR between all candidate article pairs. They also
limit the search for a lcs to a manually specified threshold of 4.
206
Wikip
edia
 
cate
gory 
grap
h
A B
A D
B B
B D
C B
C D
Cat
ego
ry pair
sA
C
B
B
D
Cat
ego
ries
 
of a
rticl
e 1
A
H
G
C
E
F
B
D
Artic
le 1 Text
1
AB
C
Text
1
Text
2
Text
2
First 
para
grap
h
Full te
xt
Artic
le 2 Text
2
BD
Text
1
LCS
(B,D
)
Cat
ego
ry gra
ph ba
sed
Text 
bas
ed
Com
bina
tion
 
stra
tegy
Avg
Best
Candidate article pair
Cat
ego
ries
 
of a
rticl
e 2
C 2
C 1
a) b)
Figure 2: SR measures adapted on Wikipedia.
texts based on (i) the first paragraph, as it usually
contains a short gloss, and (ii) the full article text.
As Wikipedia articles do not form a taxonomy, path
based measures have to be adapted to the Wikipedia
category graph (see the right part of Figure 2). We
define C1 and C2 as the set of categories assigned to
article ai and aj , respectively. We compute the SR
value for each category pair (ck, cl) with ck ? C1
and cl ? C2. We use two different strategies to com-
bine the resulting SR values: First, we choose the
best value among all pairs (ck, cl), i.e., the minimum
for path based, and the maximum for information
content based measures. As a second strategy, we
average over all category pairs.
4 Experiments & Results
Table 2 gives an overview of our experimental re-
sults on three German datasets. Best values for each
dataset and knowledge source are in bold. We use
thePGmeasure in optimal configuration as reported
by Gurevych (2005). For the Les measure, we give
the results for considering: (i) only the first para-
graph (+First) and (ii) the full text (+Full). For the
path length based measures, we give the values for
averaging over all category pairs (+Avg), or tak-
ing the best SR value computed among the pairs
(+Best). For each dataset, we report Pearson?s cor-
relation r with human judgments on pairs that are
found in both resources (BOTH). Otherwise, the re-
sults would not be comparable. We additionally use
a subset containing only noun-noun pairs (BOTH
NN). This comparison is fairer, because article titles
in Wikipedia are usually nouns. Table 2 also gives
the inter annotator agreement for each subset. It con-
stitutes an upper bound of a measure?s performance.
Our results on Gur65 using GermaNet are very
close to those published by Gurevych (2005), rang-
ing from 0.69?0.75. For Gur350, the performance
drops to 0.38?0.50, due to the lower upper bound,
and because GermaNet does not model SR well.
These findings are endorsed by an even more sig-
nificant performance drop on ZG222. The measures
based on Wikipedia behave less uniformly. Les
yields acceptable results on Gur350, but is generally
not among the best performing measures. LC +Avg
yields the best performance on Gur65, but is outper-
formed on the other datasets by PL +Best, which
performs equally good for all datasets.
If we compare GermaNet based and Wikipedia
based measures, we find that the knowledge source
has a major influence on performance. When evalu-
ated on Gur65, that contains pairs connected by SS,
GermaNet based measures perform near the upper
bound and outperformWikipedia based measures by
a wide margin. On Gur350 containing a mix of SS
and SR pairs, most measures perform comparably.
Finally, on ZG222, that contains pairs connected by
SR, the best Wikipedia based measure outperforms
all GermaNet based measures.
The impressive performance of PL on the
SR datasets cannot be explained with the struc-
tural properties of the category graph (Zesch and
Gurevych, 2007). Semantically related terms, that
would not be closely related in a taxonomic word-
net structure, are very likely to be categorized under
the same Wikipedia category, resulting in short path
lengths leading to high SR. These findings are con-
trary to that of (Strube and Ponzetto, 2006), where
LC outperformed path length. They limited the
search depth using a manually defined threshold,
and did not compute SR between all candidate ar-
ticle pairs.
Our results show that judgments on the perfor-
mance of a measure must always be made with re-
spect to the task at hand: computing SS or SR. De-
pending on this decision, we can choose the best un-
derlying knowledge source. GermaNet is better for
207
GUR65 GUR350 ZG222
BOTH NN BOTH BOTH NN BOTH BOTH NN
# Word Pairs 53 116 91 55 45
Inter Annotator Agreement 0.80 0.64 0.63 0.44 0.43
GermaNet
PG 0.69 0.38 0.42 0.23 0.21
JC -0.75 -0.52 -0.48 -0.19 -0.25
Lin 0.73 0.50 0.50 0.08 -0.12
Res 0.71 0.42 0.42 0.10 0.13
Wikipedia
Les +First 0.16 0.36 0.32 0.01 0.11
Les +Full 0.19 0.34 0.37 0.13 0.17
PL +Avg -0.32 -0.34 -0.46 -0.36 -0.43
PL +Best -0.35 -0.42 -0.53 -0.43 -0.49
LC +Avg 0.37 0.25 0.34 0.30 0.30
LC +Best 0.21 0.12 0.21 0.15 0.12
Combination
Linear 0.77 0.59 0.60 0.38 0.43
POS - 0.55 - 0.48 -
Table 2: Correlation r of human judgments with SR measures on different datasets.
estimating SS, while Wikipedia should be used to
estimate SR. Therefore, a measure based on a single
knowledge source is unlikely to perform well in all
settings. We computed a linear combination of the
best measure from GermaNet and from Wikipedia.
Results for this experiment are labeled Linear in Ta-
ble 2. POS is an alternative combination strategy,
where Wikipedia is only used for noun-noun pairs.
GermaNet is used for all other part-of-speech (POS)
combinations. For most datasets, we find a combi-
nation strategy that outperforms all single measures.
5 Conclusion
We have shown that in deciding for a specific mea-
sure and knowledge source it is important to con-
sider (i) whether the task at hand requires SS or
SR, and (ii) which POS are involved. We pointed
out that the underlying knowledge source has a ma-
jor influence on these points. GermaNet is better
used for SS, and contains nouns, verbs, and adjec-
tives, while Wikipedia is better used for SR between
nouns. Thus, GermaNet and Wikipedia can be re-
garded as complementary. We have shown that com-
bining them significantly improves the performance
of SR measures up to the level of human perfor-
mance.
Future research should focus on improving the
strategies for combining complementary knowledge
sources. We also need to evaluate a wider range of
measures to validate our findings. As the simple PL
measure performs remarkably well, we should also
consider computing SR based on the Wikipedia arti-
cle graph instead of the category graph.
Acknowledgments
This work was supported by the German Research Foundation
under grant "Semantic Information Retrieval from Texts in the
Example Domain Electronic Career Guidance", GU 798/1-2.
References
Alexander Budanitsky and Graeme Hirst. 2006. Evaluating
WordNet-based Measures of Semantic Distance. Computa-
tional Linguistics, 32(1).
Christiane Fellbaum. 1998. WordNet An Electronic Lexical
Database. MIT Press, Cambridge, MA.
Iryna Gurevych. 2005. Using the Structure of a Conceptual
Network in Computing Semantic Relatedness. In Proc. of
IJCNLP, pages 767?778.
Claudia Kunze, 2004. Lexikalisch-semantische Wortnetze,
chapter Computerlinguistik und Sprachtechnologie, pages
423?431. Spektrum Akademischer Verlag.
Michael Lesk. 1986. Automatic Sense Disambiguation Us-
ing Machine Readable Dictionaries: How to tell a pine cone
from an ice cream cone. In Proc. of the 5th Annual Interna-
tional Conference on Systems Documentation, pages 24?26.
Jane Morris and Graeme Hirst. 2004. Non-Classical Lexical
Semantic Relations. In Proc. of the Workshop on Computa-
tional Lexical Semantics, NAACL-HTL.
Herbert Rubenstein and John B. Goodenough. 1965. Contex-
tual Correlates of Synonymy. Communications of the ACM,
8(10):627?633.
Michael Strube and Simone Paolo Ponzetto. 2006. WikiRelate!
Computing Semantic Relatedness UsingWikipedia. In Proc.
of AAAI, pages 1219?1224.
Torsten Zesch and Iryna Gurevych. 2006. Automatically Creat-
ing Datasets for Measures of Semantic Relatedness. In Proc.
of the Workshop on Linguistic Distances, ACL, pages 16?24.
T. Zesch and I. Gurevych. 2007. Analysis of the Wikipedia
Category Graph for NLP Applications. In Proc. of the
TextGraphs-2 Workshop, NAACL-HLT, (to appear).
208
