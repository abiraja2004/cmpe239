L. Bahl, P. Brown, P. de Souza, and R. Mercer. 1988.
A new algorithm for the estimation of hidden Markov
model parameters. In Proceedings of ICASSP, pages
493?496.
E. Benson, A. Haghighi, and R. Barzilay. 2011. Event
discovery in social media feeds. In Proceedings of
ACL-HLT, pages 389?398.
Y. Choi, C. Cardie, E. Riloff, and S. Patwardhan. 2005.
Identifying sources of opinions with conditional ran-
dom fields and extraction patterns. In Proceedings of
HLT/EMNLP, pages 355?362.
J. Domke. 2008. Learning convex inference of
marginals. In Proceedings of UAI.
J. Domke. 2010. Implicit differentiation by perturba-
tion. In Advances in Neural Information Processing
Systems, pages 523?531.
J. Domke. 2011. Parameter learning with truncated
message-passing. In Proceedings of the IEEE Con-
ference on Computer Vision and Pattern Recognition
(CVPR).
J. Domke. 2012. Generic methods for optimization-
based modeling. In Proceedings of AISTATS.
M. Dreyer and J. Eisner. 2009. Graphical models over
multiple strings. In Proceedings of EMNLP, pages
101?110.
J. Eisner and Hal Daume? III. 2011. Learning speed-
accuracy tradeoffs in nondeterministic inference al-
gorithms. In COST: NIPS 2011 Workshop on Com-
putational Trade-offs in Statistical Learning, Sierra
Nevada, Spain, December.
A. Elisseeff and J. Weston. 2001. Kernel methods for
multi-labelled classification and categorical regression
problems. In Advances in Neural Information Pro-
cessing Systems, pages 681?687.
J.R. Finkel, T. Grenager, and C. Manning. 2005. In-
corporating non-local information into information ex-
traction systems by Gibbs sampling. In Proceedings of
ACL, pages 363?370.
T. Finley and T. Joachims. 2008. Training structural
SVMs when exact inference is intractable. In Proceed-
ings of ICML, pages 304?311.
D. Freitag. 2000. Machine learning for information
extraction in informal domains. Machine learning,
39(2).
N. Ghamrawi and A. McCallum. 2005. Collective multi-
label classification. In Proceedings of CIKM, pages
195?200.
K. Gimpel and N.A. Smith. 2010. Softmax-margin
CRFs: Training log-linear models with cost functions.
In Proceedings of ACL, pages 733?736.
P. I. Good. 2000. Permutation Tests. Springer.
A. Griewank and G. Corliss, editors. 1991. Automatic
Differentiation of Algorithms. SIAM, Philadelphia.
S. Gross, O. Russakovsky, C. Do, and S. Batzoglou.
2007. Training conditional random fields for maxi-
mum labelwise accuracy. Advances in Neural Infor-
mation Processing Systems, 19:529.
H. Ji and R. Grishman. 2011. Knowledge base popula-
tion: Successful approaches and challenges. In Pro-
ceedings of ACL-HLT, pages 1148?1158.
S. Kakade, Y.W. Teh, and S. Roweis. 2002. An alternate
objective function for Markovian fields. In Proceed-
ings of ICML, pages 275?282.
D. Koller and N. Friedman. 2009. Probabilistic Graph-
ical Models: Principles and Techniques. The MIT
Press.
A. Kulesza and F. Pereira. 2008. Structured learning
with approximate inference. In Advances in Neural
Information Processing Systems, pages 785?792.
S. Lacoste-Julien, F. Huszr, and Z. Ghahramani.
2011. Approximate inference for the loss-calibrated
Bayesian. In Proceedings of AISTATS.
J. Lafferty, A. McCallum, and F. Pereira. 2001. Con-
ditional random fields: Probabilistic models for seg-
menting and labeling sequence data. In Proceedings
of ICML, pages 282?289.
Y. LeCun, S. Chopra, R. Hadsell, M.A. Ranzato, and F.-
J. Huang. 2006. A tutorial on energy-based learning.
In G. Bakir, T. Hofman, B. Schlkopf, A. Smola, and
B. Taskar, editors, Predicting Structured Data. MIT
Press.
Z. Li and J. Eisner. 2009. First- and second-order
expectation semirings with applications to minimum-
risk training on translation forests. In Proceedings of
EMNLP, pages 40?51.
K. P. Murphy, Y. Weiss, and M. I. Jordan. 1999. Loopy
belief propagation for approximate inference: An em-
pirical study. In Proceedings of UAI.
F. Och. 2003. Minimum error rate training in statisti-
cal machine translation. In Proceedings of ACL, pages
160?167.
F. Peng and A. McCallum. 2006. Information extraction
from research papers using conditional random fields.
Information Processing & Management, 42(4):963?
979.
N.N. Schraudolph. 1999. Local gain adaptation in
stochastic gradient descent. In Proceedings of ANN,
pages 569?574.
F. Sha and F. Pereira. 2003. Shallow parsing with con-
ditional random fields. In Proceedings of ACL/HLT,
pages 134?141.
D.A. Smith and J. Eisner. 2006. Minimum risk annealing
for training log-linear models. In Proceedings of the
COLING/ACL, pages 787?794.
D. Smith and J. Eisner. 2008. Dependency parsing by
belief propagation. In Proceedings of EMNLP, pages
145?156.
V. Stoyanov and J. Eisner. 2011. Learning cost-aware,
loss-aware approximate inference policies for proba-
bilistic graphical models. In COST: NIPS 2011 Work-
shop on Computational Trade-offs in Statistical Learn-
ing, Sierra Nevada, Spain, December.
V. Stoyanov, A. Ropson, and J. Eisner. 2011. Empirical
risk minimization of graphical model parameters given
approximate inference, decoding, and model structure.
In Proceedings of AISTATS.
C. Sutton and A. McCallum. 2005. Piecewise training
of undirected models. In Proceedings of UAI, pages
568?575.
C. Sutton, A. McCallum, and K. Rohanimanesh. 2007.
Dynamic conditional random fields: Factorized proba-
bilistic models for labeling and segmenting sequence
data. The Journal of Machine Learning Research,
8:693?723.
J. Suzuki, E. McDermott, and H. Isozaki. 2006. Train-
ing conditional random fields with multivariate eval-
uation measures. In Proceedings of COLING/ACL,
pages 217?224.
B. Taskar, C. Guestrin, and D. Koller. 2003. Max-margin
Markov networks. Proceedings of NIPS, pages 25?32.
M. Thomas, B. Pang, and L. Lee. 2006. Get out the vote:
Determining support or opposition from congressional
floor-debate transcripts. In Proceedings of EMNLP,
pages 327?335.
S. Vishwanathan, N. Schraudolph, M. Schmidt, and
K. Murphy. 2006. Accelerated training of conditional
random fields with stochastic gradient methods. In
Proceedings of ICML, pages 969?976.
M. Wainwright. 2006. Estimating the ?wrong? graphi-
cal model: Benefits in the computation-limited setting.
Journal of Machine Learning Research, 7:1829?1859,
September.
R.J. Williams and D. Zipser. 1989. A learning algo-
rithm for continually running fully recurrent neural
networks. Neural Computation, 1(2):270?280.