Proceedings of the NAACL HLT 2010 First International Workshop on Formalisms and Methodology for Learning by Reading, pages 96?104,
Los Angeles, California, June 2010. c?2010 Association for Computational Linguistics
Analogical Dialogue Acts: Supporting Learning by Reading Analogies 
 
 
David Barbella 
Qualitative Reasoning Group 
Northwestern University 
2133 Sheridan Road, Evanston, IL, USA 
barbella@u.northwestern.edu 
Kenneth D. Forbus 
Qualitative Reasoning Group 
Northwestern University 
2133 Sheridan Road, Evanston, IL, 60201, USA 
forbus@northwestern.edu 
 
  
 
Abstract 
Analogy is heavily used in written explana-
tions, particularly in instructional texts.  We 
introduce the concept of analogical dialogue 
acts (ADAs) which represent the roles utter-
ances play in instructional analogies.  We de-
scribe a catalog of such acts, based on ideas 
from structure-mapping theory.  We focus on 
the operations that these acts lead to while un-
derstanding instructional texts, using the 
Structure-Mapping Engine (SME) and dynam-
ic case construction in a computational model.  
We test this model on a small corpus of in-
structional analogies, expressed in simplified 
English, which were understood via a semi-
automatic natural language system using ana-
logical dialogue acts.  The model enabled a 
system to answer questions after understand-
ing the analogies that it was not able to answer 
without them. 
1 Introduction 
People use analogy heavily in written explanations.  
Instructional texts, for example, use analogy to 
convey new concepts and systems of related ideas 
to learners.  Any learning by reading system must 
ultimately include the capability of understanding 
such analogies.  Here we combine Gentner?s 
(1983) structure-mapping theory with ideas from 
dialogue act theory (Traum, 2000) to describe a 
catalog of analogical dialogue acts (ADAs) which 
capture the functional roles that discourse elements 
play in instructional analogies.  We outline criteria 
for identifying ADAs in text and describe what 
operations they suggest for discourse processing.  
We provide evidence that this model captures im-
portant aspects of understanding instructional 
analogies via a simulation that uses knowledge 
gleaned from reading instructional analogies to 
answer questions. 
We start by reviewing the relevant aspects of 
structure-mapping theory and dialogue act theory.  
Then we describe our catalog of analogical dialo-
gue acts, based on a theoretical analysis of the 
roles structure-mapping operations can play in lan-
guage understanding.  A prototype implementation 
of these ideas is described next, followed by an 
experiment illustrating that these ideas can be used 
to understand analogies in text, based on answering 
questions.  We close with a discussion of related 
and future work. 
2 Background  
Dialogue act theories (also called speech acts 
(Allen & Perrault, 1980)) are concerned with the 
roles utterances play in discourse and the effects 
they have on the world or on understanding.  An 
utterance identified as a Requesting Information, 
for example, might take the syntactic form of a 
question that makes the information requested ex-
plicit, e.g. ?What time is it??  The surface manife-
station might instead be a statement, or an indirect 
question, e.g. ?Do you have the time??   In other 
words, its classification is based on its function in 
the dialogue and the set of operations it suggests 
for the recipient to undertake.  We claim that there 
exists a set of analogical dialogue acts that are used 
in communicating analogies.  Like other dialogue 
acts, they have criteria by which they can be rec-
96
ognized, and a set of implied commitments and 
obligations for the dialogue participants.  This pa-
per focuses on instructional analogies in texts, both 
because they are an important phenomenon and 
because it allows us to factor out follow-up ques-
tions, making it a useful starting point. 
There are a wide variety of dialogue act models, 
but all of them include some variation of acts like 
Inform (Traum, 2000), which indicate the intent to 
describe the state of the world.  The analogical di-
alogue acts we discuss here can be viewed as spe-
cializations of Inform.   
The organization of analogical dialogue acts fol-
lows directly from the concepts of structure-
mapping theory.  In structure-mapping, analogical 
matching takes as input two structured, relational 
representations, the base and target, and produces 
as output one or more mappings.  Each mapping 
consists of a set of correspondences, identifying 
how entities and statements in the base align with 
entities and statements in the target.  Mappings 
include a structural evaluation score providing an 
estimate of their overall quality.  This estimate is 
based on systematicity, i.e., the amount of nested 
relational structure in the mapping, especially 
higher-order relations that serve as inferential con-
nections between other statements.  Causal, logi-
cal, and mathematical statements are all examples 
of higher-order relations.  Systematicity thus 
serves as a local heuristic measure of the explana-
tory promise of a mapping.   
Mappings can also contain candidate inferences, 
statements in the base that are projected onto the 
target, using the correspondences of the mapping.  
The candidate inferences represent conjectures 
about the target, and constitute a source of analo-
gy?s generative power.  Whether or not the candi-
date inferences are in fact correct is evaluated 
outside of the matching process.  In discourse, 
candidate inferences are often used to convey new 
information about the target to the learner.  Candi-
date inferences can be forward, from base to target, 
or reverse, from target to base.  Candidate infe-
rences also represent differences between two re-
presentations, when they cannot be consistently 
projected from one description to the other.   
The Structure-Mapping Engine (SME, Falken-
hainer et al1989) provides a simulation of analogi-
cal matching.  SME typically produces only one 
mapping, but can produce a second or third map-
ping if they are sufficiently close to the best map-
ping.  SME can accept input about the base and 
target incrementally, updating its mappings as new 
information becomes available (Forbus et al1994), 
which can be important for modeling the incre-
mental nature of discourse.  One cost of SME?s 
greedy match algorithm and incremental operation 
is that matches can go awry.  Consequently, SME 
also supports a small set of constraints, optionally 
specified as part of the matcher?s input, which 
guide it based on task constraints.  Here the rele-
vant constraints are those concerning correspon-
dences.   That is, given a base item bi and target 
item tj, either entities or statements, the following 
constraints are defined: required(bi tj) means that bi 
must correspond to tj in every mapping, and ex-
cluded(bi tj) means that bi cannot correspond to tj in 
any mapping.  The following open constraints are 
also defined: requiredBase(bi), means that some-
thing in every mapping must correspond to bi, with 
requiredTarget(tj) defined similarly.  excluded-
Base(bi) means that bi cannot participate in any 
correspondence, with excludedTarget(tj) defined 
similarly.     
An important problem in understanding analogy 
in discourse concerns how the representations pro-
vided to SME are constructed.  As described be-
low, the representations that constitute an 
understanding of the text are produced in our mod-
el via a semi-automatic natural language under-
standing system, which reduces tailorability.  In 
understanding instructional analogies, a learner is 
expected to draw upon their existing world know-
ledge.  In some situations, whole cases 
representing a prior experience are retrieved from 
memory.  In other situations, cases seem to be con-
structed dynamically from one?s general know-
ledge of the world.  We use dynamic case 
construction methods (Mostek et al2000) to model 
this process.  In dynamic case construction, a seed 
entity or concept is provided as a starting point, 
and facts which mention it are gathered, perhaps 
filtering by some criterion.  For example, ?The 
economy of India? might have India as its seed, 
and facts filtered based on their judged relevance 
to economic matters.  When a reader is processing 
an instructional analogy, we believe that something 
like this process is used to create representations to 
be used in their understanding of the analogy.  
 
97
 3 Analogical Dialogue Acts 
Our model of analogical dialog acts is based on an 
analysis of how the functional constraints on per-
forming analogical mapping and case construction 
interact with the properties of discourse.  To carry 
out an analogy, a reader must be able to infer that 
an analogy is required.  They must understand 
what goes into the base and what goes into the tar-
get, which can be complex because what is stated 
in the text typically needs to be combined with the 
reader?s own knowledge.  Since readers often 
know quite a lot to begin with, figuring out which 
subset of what they know is relevant to the analogy 
can be complicated.  Finally, they have to under-
stand how the author intends the mapping to go, 
since there can be multiple mappings between the 
same domains.  Analogical dialogue acts, we ar-
gue, provide readers with information that they 
need to perform these tasks. 
Let us examine this process in more detail.  To car-
ry out an analogy, the contents of the base and tar-
get representations must be identified.  A 
fundamental problem is that the reader must figure 
out an appropriate construal of the base and target, 
i.e., what subset of their knowledge should be 
brought to bear in the current comparison?  A 
reader?s starting knowledge may or may not be 
sufficient to guide the mapping process correctly, 
in order to reconstruct the mapping that the author 
intended.  This is especially true in instructional 
analogies, of course.  We believe that this is why 
one commonly finds explicit information about 
intended correspondences provided as part of in-
structional analogies.  Such information provides a 
source of constraints that can be used to guide case 
construction and mapping.  Similarly, and we be-
lieve for similar reasons, the desired inferences to 
be drawn from the analogy are often highlighted.  
Since there can be multiple construals (i.e., specific 
sets of facts retrieved) for the given base and tar-
get, mentioning candidate inferences explicitly 
provides clues to the reader about how to construe 
the base and target (i.e., the given candidate infe-
rence should be derivable) as well as information 
about its validity. 
Next we describe our proposed analogy dialogue 
acts.  For each act, we give an example, some cri-
teria for identifying them, and describe what opera-
tions a reader might do when they detect such an 
act has occurred.  At this point our focus has been 
on developing the basic set and the operations they 
entail, rather than on developing a comprehensive 
set of identification criteria.  The first three acts are 
concerned with introducing the representations to 
be compared, and the rest are concerned with cor-
respondences and candidate inferences.  We use a 
greenhouse/atmosphere analogy as a source of ex-
amples. 
Introduce Comparison: Introduces a compari-
son by providing both base and target.  For exam-
ple, in ?We can understand the greenhouse effect 
by comparing it to what goes on in an actual 
greenhouse.? the base is a greenhouse, and the tar-
get is the Earth?s atmosphere. Recognizing an In-
troduce Comparison can require combining 
information across multiple sentences.  In Figure 1, 
for example, the target is described in the para-
graph above the point where the comparison is in-
troduced.  Sometimes this intent must be inferred 
from parallel sentence structure in subsequent sen-
Heat flows from one place to another because the 
temperature of the two places is different. A hot 
brick loses heat to a cool room. The temperature 
difference - the brick's temperature minus the 
room's temperature ? drives the heat from the 
brick. Heat leaks from the brick until the tempera-
ture difference is gone. No more heat flows from 
the brick when it becomes as cool as the room it is 
in. 
Similarly, a full can of water will leak volume 
from a hole in the side of the can. The depth of the 
water is higher than the depth of the hole, so the 
depth difference drives volume out through the 
hole. 
Eventually, all the volume that can leak out does 
so. When this happens, the water depth has fallen 
so that it is the same as that of the hole. There is 
no more depth difference, so no more volume 
flows out through the hole. Just as a difference in 
temperature causes heat to flow, so a difference in 
depth causes volume to flow. When there is no 
temperature difference, heat flow ceases; when 
there is no depth difference, volume flow ceases. 
 
Extend Target 
Extend Base 
Introduce Comparison 
Candidate Inference 
 
Figure 1: An analogy from our test corpus, 
hand-annotated with analogical dialogue acts. 
98
tences and other sophisticated rhetorical devices, 
while in other cases, like this example, the compar-
ison is introduced explicitly. 
What is the base and what is the target requires a 
non-local assessment about what the containing 
text is about.  (This particular example is drawn 
from a book on solar energy, and the rest of the 
chapter makes clear that heat is the domain being 
taught.)  Since we assume that candidate inferences 
can be constructed bidirectionally, an incorrect 
assessment is not catastrophic. 
Processing an Introduce Comparison act re-
quires finding appropriate construals of the base 
and target.  The target, as in this case, is con-
strained by what has already been introduced in the 
text.  The base, unless it has been used before in 
the same text and is being used in a consistent 
manner, must be constructed from the reader?s 
knowledge.  Whether this is done aggressively or 
lazily is, we suspect, a strategy that is subject to 
individual variation.  Ambiguity in linguistic cues 
can lead to the need to explore multiple construals, 
to find combinations with significant overlap.   
Extend Base, Extend Target: These acts add 
information to the base or target of a comparison, 
respectively.  Such acts are identified by relation-
ships and/or entities being mentioned in the same 
statement as an entity in the base or target, but 
which is not a statement about correspondences or 
candidate inferences.  For example, ?The glass of a 
greenhouse lets the short solar rays through.? is 
extending the base, and ?The earth?s atmosphere 
admits most of the solar radiation.? is an example 
of extending the target.  Entities that are mentioned 
in these acts are added to the construal of the case, 
if not there already, by retrieving additional know-
ledge about them, focusing on statements involv-
ing other entities in the current construal.  If the 
specific facts mentioned are not already known to 
the reader, they are provisionally accepted as being 
true about the base or target, as appropriate.   
Introduce Correspondence: These acts provide 
clues as to the author?s intended mapping.  For 
example, ?The Earth?s atmosphere is like the glass 
in the greenhouse.? indicates that ?Earth?s atmos-
phere? corresponds to ?glass in greenhouse?.  Dis-
tinguishing these acts from introducing a 
comparison can be tricky, since ?is like? is a syn-
tactic pattern common to both.  The first occur-
rence of ?is like? in such cases is typically the 
introduction of the base and target, with subse-
quent statements introducing correspondences.  
Sometimes Introduce Correspondence acts are ex-
pressed as identity statements, e.g. ?The glass is 
the atmosphere.? Sometimes these acts are sig-
naled by pairs of sentences, one expressing a fact 
about the base followed immediately by one about 
the target, with identical syntax. 
When an Introduce Correspondence act is de-
tected, the base and target are checked to see if 
they already contain the entities or relationships 
mentioned.  If they do not, then the descriptions 
are extended to include them.  The final step is in-
troducing a required constraint between them as 
part of the input to SME.  If mappings have al-
ready been generated that are not consistent with 
this constraint, they are discarded and new map-
pings are generated. 
Block Correspondence:  These acts are pro-
vided by the author to block a correspondence that 
a reader might otherwise find tempting.  An exam-
ple is ?The greenhouse door is not like the hole in 
the ozone layer.?  We believe that these acts are 
relatively rare, and especially in written text com-
pared with spoken dialogue, where there are oppor-
tunities for feedback, a matter discussed later.   
When both a base and target item are men-
tioned, an exclude constraint is introduced between 
them.  When only one of them is mentioned, the 
minimal operation is to add an open exclusion con-
straint (e.g. excludedBase or excludedTarget).  The 
reader may decide to simply remove the excluded 
item from the construal, along with all of the facts 
that mention it.  This would prevent it from being 
mapped, but it would also prevent it from appear-
ing in any candidate inferences, and hence is more 
extreme.   
Introduce Candidate Inference: These acts 
alert the reader to information that the author in-
tended to convey via the analogy.   An example is 
?Just as heat is trapped by the greenhouse roof, 
heat is trapped by the Earth?s atmosphere.?  Phras-
es such as ?just as? and ?just like?, or even ?Like 
<base statement to be projected>, <resulting can-
didate inference>.? are clues for identifying such 
acts.  If the candidate inference can be found in the 
mapping that the reader has built up so far, then 
that surmise should be given additional weight as 
being true.  (If it is already known by the reader, it 
may already be part of a mapping.  This does not 
indicate failure, only that it is uninformative for 
that reader.)  If the candidate inference cannot be 
99
found, then there are several possibilities that a 
reader should explore: Their construal of the base 
and/or target might be too different from what the 
author expects, or they should generate a different 
mapping. 
It is important to note that whether a statement 
combining information from the base and target is 
considered an intended correspondence versus an 
intended candidate inference depends to some de-
gree on the reader?s state of knowledge.  If the tar-
get information is unknown, then for that reader, a 
candidate inference is being introduced.  A very 
active reader may ponder whether it would be a 
correspondence for a more informed reader, and 
conversely, whether something an active and well-
informed reader views as a correspondence might 
have been intended as a candidate inference.  In 
both cases, considering the alternate classification 
would affect the reader?s judgment of informative-
ness, so the distinction between these two types of 
acts is useful to make.  Candidate inferences 
represent the point of the analogy, what it was set 
up to convey, and hence distinguishing them seems 
important. 
Block Candidate Inference: These acts alert 
the reader that an inference that they are likely to 
make is not in fact correct.  For example, ?Unlike 
solar radiation, radiation heat flow reacts in the 
same way to different colors.?  If the candidate 
inference is part of the reader?s mapping, then 
these acts indicate that the reader should mark 
them as incorrect.  A reader with an aggressive 
processing style who did not generate this infe-
rence might explore modifications of their base 
and/or target to see if they can generate that infe-
rence, thereby ensuring they are more in sync with 
the author?s intentions and thus better able to 
process subsequent statements. These acts are 
sometimes identifiable by terms such as ?unlike,? 
?however,? or ?you might expect? but? which 
include one clause expressing information about 
the base and one clause expressing information 
about the target. We believe that, like Block Cor-
respondence, these occur relatively infrequently. 
 
4 A prototype implementation 
To explore the utility of our analogical dialogue 
acts theory, we implemented a simple computa-
tional model which uses ADAs to learn from in-
structional texts and answer questions based on 
what it has learned, synthesized with what it al-
ready knows (Figure 1). Our model uses the FIRE 
reasoning engine, which incorporates SME. The 
knowledge base contents are extracted from Re-
searchCyc1 and extended with other knowledge, 
including an analogy ontology that lets analogy 
operations and other forms of reasoning be freely 
mixed (Forbus et al2002). In addition to the natu-
ral language lexical information built into Re-
searchCyc, we also use the COMLEX lexicon 
(Macleod et al1998) for part of speech and subcat 
information. For natural language understanding, 
we use EA NLU (Tomai & Forbus, 2009), which 
also uses FIRE and the same knowledge base.  EA 
NLU uses Allen?s (1994) parser for syntactic 
processing and construction of initial semantic re-
presentations.  It uses Discourse Representation 
Theory (Kamp & Reyle, 1993) for dealing with 
tense, quotation, logical and numerical quantifica-
tion, and counterfactuals.   
EA NLU is useful for this type of learning by 
reading experiment because it focuses on generat-
ing rich semantic representations. It does so at the 
expense of syntactic coverage: We restrict inputs 
syntactically, using QRG-CE (Kuehne & Forbus, 
2004), a form of simplified English much like CPL 
(Clark et al2005). For example, complex sen-
                                                           
1 http://research.cyc.com 
Source Text Translation* QRG-CE Text
EA NLUSemantic Representation
Discourse 
Interpretation
ADA 
Hypotheses
Recognition 
Rules
Build Base and 
Target
Build Required 
Correspondences
Required 
Correspondences
Cases
Facts from 
Memory
Dynamic Case 
Construction
SME Candidate 
Inferences
Question 
Answering
Comprehension 
Questions Translation* Queries
Answers
 
Figure 2: Architecture of the experimental prototype. Processes performed by hand are marked with an asterisk. 
100
tences are broken up into a number of shorter, 
simpler sentences.  Explicit object references (e.g. 
?the greenhouse greenhouse12? every time the 
same greenhouse is mentioned) are used to factor 
out the difficulty of anaphora resolution. EA NLU 
provides facilities for semi-automatic processing; 
In this mode, the ambiguities it cannot resolve on 
its own are presented as choices to the experimen-
ter. This keeps tailorability low, while allowing  
the system to process more complex texts.  
As noted above, we do not yet have a robust 
model of identification criteria for analogical di-
alogue acts, so we extended EA NLU?s grammar 
to have at least one naturally occurring pattern for 
every ADA. As part of the translation to QRG-CE, 
texts are rewritten to use those patterns when we 
view an analogical dialogue act as being present. 
This allows the system to automatically classify 
ADAs during processing.  Here our goal is to mod-
el the processing that must take place once such 
acts are recognized, since identifying such acts is 
irrelevant if they are not useful for reasoning. EA 
NLU?s parsing system produces semantic repre-
sentations used in its discourse interpretation 
processing.  The ADA recognition rules are used 
along with EA NLU?s standard discourse interpre-
tation rules to generate ADA hypotheses as part of 
its discourse representations (Figure 1).  
We believe that there are significant individual 
differences in processing strategies for these acts. 
For example, some people seem to be quite aggres-
sive about building up mappings, whereas others 
appear to do minimal work. Consequently, we 
have started with the simplest possible approach. 
Here is what our simulation currently does for each 
of the types of acts: 
Introduce Comparison: Builds initial con-
struals of the base and the target by retrieving rele-
vant facts from the knowledge base2. 
 Extend Base/Extend Target: The understand-
ing of the sentence is added to the base or target, as 
appropriate.  This decision is made by keeping 
track of the concepts that are mentioned by state-
ments in each domain, starting with the Introduce 
Comparison act.   
Introduce Correspondence: A required corres-
pondence constraint is introduced for the entities 
                                                           
2 We use a case constructor similar to CaseFn from Mostek 
et al2000, but including automatic expansion of rule macro 
predicates and using microtheory information for filtering.  
involved, to be used when SME is run for this 
analogy. 
Introduce Candidate Inference: The informa-
tion in these statements is simply treated as a fact 
about the target domain.  We do not currently 
change the mapping if a candidate inference in text 
is not part of the mapping computed.   
Block Correspondence/Candidate Inference: 
Not implemented currently, because examples of 
these did not show up in our initial corpus. 
Analogical dialogue acts are identified via infe-
rence rules that are run over the discourse-level 
interpretation that EA NLU produces.  Analogical 
mapping occurs only at the end of processing a 
text, rather than incrementally.  Statements about 
the base and target are accepted uncritically, rather 
than being tested for inconsistencies against back-
ground knowledge.  These simplifications 
represent one point in the possible space of strate-
gies that people seem likely to use; plans to ex-
plore other strategies are discussed below. 
Once the ADA hypotheses are used to construct 
the base and target domain and the required cor-
respondences between them, this information is 
used by SME to generate candidate inferences - 
statements that might be true on the basis of the 
analogy constructed. The base and target case are 
expanded using dynamic case construction, which 
adds knowledge from the KB to fill in information 
that the text leaves out.  For example, a text may 
not explicitly mention that rain falls from the sky 
to the earth, taking it as a given that the reader is 
aware of this.  
5 Experiment 
An essential test for a theory of analogy dialogue 
acts is whether or not it can be used to construct 
new knowledge from instructional analogies in 
text.  To test this, we extracted a small corpus of 6 
instructional analogies from a book on solar energy 
(Buckley, 1979) and a book on weather (Lehr et al
Example #O #A 
Gold mining/Collecting solar energy 8 11 
Water flow/heat flow 11 12 
depth of water in bucket/temperature of house 8 16 
Bucket with hole/house leaking heat 4 10 
Bucket/Solar collector 5 8 
Earth?s atmosphere/greenhouse 7 14 
Mean 7.2 11.8 
Table 1: Corpus Information.  #O/#A = # sen-
tences before/after translation to QRG-CE 
101
Condition # correct % 
-A, -K 0 0 
+A, -K 7 58 
-A, +K 0 0 
+A, +K 12 100 
 
Table 2: Results for Q/A.  +/- means 
with/without, A means analogy, K 
means facts retrieved from KB 
1987).  We simplified the syntax of the original 
texts into QRG-CE, using the appropriate surface 
forms for the analogy dialogue acts that we per-
ceived in the text.  One of the analogies is illu-
strated in Figure 1, with part of its translation is 
shown in Figure 3.  Table 1 summarizes properties 
of the original texts and the simplification process. 
To test the effectiveness of knowledge capture, 
12 comprehension questions similar to those found 
in middle-school science texts were generated by 
independent readers of the texts (see Figure 4 for 
an example).  All questions were designed to re-
quire understanding the analogy in order to answer 
them.  Moreover, some of the questions require 
combining information from the knowledge base 
with knowledge gleaned from the text.   
Four experimental conditions were run, based 
on a 2x2 design here the factors were whether or 
not analogy was used (+A) or not used (-A), and 
whether what was learned from the text was aug-
mented with information from the knowledge base 
(+K) or not (-K).   
Table 2 shows the results.  The system was able 
to answer all twelve questions when it understood 
the analogy and combined what it learned by read-
ing with information from the knowledge base.  
That this was due to understanding the analogy can 
be seen from the other conditions.  The informa-
tion from the text alone is insufficient to answer 
any of the questions (-A, -K), as is the information 
from the KB alone (-A, +K).  Analogy by itself 
over what was learned by reading the passages can 
handle over half the questions (+A, -K), but the 
rest require combining facts learned by reading 
with facts from the KB (+A, +K). 
6 Related Work 
There has been very little work on modeling anal-
ogies in dialogue.  One of the few efforts has been 
Lulis & Evans (2003), who examined the use of 
analogies by human tutors for potential extensions 
to their intelligent tutoring system for cardiac func-
tion.  Recently they have begun incorporating 
analogies into their tutor (Lulis, Evans, & Michael, 
2004), but they have not focused on understanding 
novel analogies presented via language. 
Because EA NLU is designed to explore issues 
of understanding, it is focused more on semantic 
coverage than on syntactic coverage.  The most 
similar system is Boeing?s BLUE (Clark & Harri-
son, 2008), which also uses simplified syntax and 
focuses on integrating language with a knowledge 
base and reasoning. 
Aside from SME, we suspect that the only other 
current widely tested model of analogy that might 
be able to handle this task is IAM (Keane & Bray-
shaw 1988).  CAB (Larkey & Love 2003) does not 
model inference, and hence could not model this 
task.  Although LISA (Hummel & Holyoak, 2003) 
can model some analogical inferences, the number 
of relations (see Table 3) in these analogies is 
beyond the number of relationships it can currently 
handle (2 or 3). 
The first simulation of analogy to use natural 
language input was Winston?s (1982, 1986), which 
used a simple domain-specific parser in modeling 
the learning of if-then rules and censors.  EA NLU 
Original: Similarly, a full can of water will leak 
volume from a hole in the side of the can. 
QRG-CE: A hot brick brick005 is like a can 
can001 of water water001. There is a hole hole001 
in can can001. The water water001 exits can 
can001 through hole hole001. 
 
Figure 3: Example of translation to QRG-CE.  
The specific individuals are added to factor out 
anaphora processing.  Cues to analogical dialo-
gue acts spread across multiple sentences in the 
original text are combined into single sentences 
during the translation process. 
Question: What disappears as the heat leaks from the 
brick? 
Predicate calculus version: 
(and 
 (inputsDestroyed ?d ?ourAnswer) 
 (after-Underspecified ?d ?leaving) 
 (objectMoving ?leaving heat005) 
 (isa ?heat ThermalEnergy) 
 (isa ?leaving LeavingAPlace) 
 (fromLocation ?leaving brick005)) 
Figure 4: A question for the analogy of Figure 
1, in English and the hand-generated predicate 
calculus generated from it. 
102
benefits from subsequent progress in natural lan-
guage research, enabling it to handle a wider range 
of phenomena. 
7 Discussion and Future Work 
Modeling the roles that analogy plays in under-
standing language is an important problem in 
learning by reading.  This paper is an initial explo-
ration of how analogy can be integrated into dialo-
gue act theories, focusing on instructional 
analogies in text.  We presented a catalog of ana-
logical dialogue acts, based on an analysis of how 
the functional constraints of analogical mapping 
and case construction interact with the properties 
of discourse.  We showed that a simulation using 
these ideas, combined with a natural language un-
derstanding system to semi-automatically produce 
input representations, can indeed learn information 
from simplified English analogies, which is en-
couraging evidence for these ideas. 
The next step is to expand the corpus substan-
tially, including more examples of all the ADAs, to 
better test our model.  We also need to implement 
the rest of the ADAs, and experiment with a wider 
range of processing strategies. 
To better model how ADAs can be identified in 
natural texts, we plan to use a large-scale web-
based corpus analysis.  We have focused on text 
here, but we believe that these ideas apply to spo-
ken dialogue as well.  We predict more opportuni-
ties for blocking in spoken dialogue, due to 
opportunities for feedback. 
Our goal is to incorporate these ideas into a 2nd 
generation learning by reading system (e.g., Forbus 
et al2007; Forbus et al2009a), along with other 
dialogue processing, to better interpret larger-scale 
texts (e.g., Lockwood & Forbus, 2009).  This will 
be built using the Companions cognitive architec-
ture (Forbus et al2009b), to more easily model a 
wider range of processing strategies, and so that 
the system can learn to improve its interpretation 
processes. 
Acknowledgments 
This research was supported by the Intelligent and 
Autonomous Systems Program of the Office of 
Naval Research.   
References  
Allen, J.F. (1994). Natural Language Understanding.  
(2nd Ed.) Redwood City, CA: Benjamin/Cummings. 
Allen, J. F. & C. R. Perrault (1980). Analyzing Intention 
in Utterances. Artificial Intelligence 15(3). 
Buckley, S. (1979). From Sun Up to Sun Down. New 
York: McGraw-Hill. 
Clark, P. & Harrison, P. (2008).  Boeing?s NLP system 
and the challenges of semantic representation 
Clark, P., Harrison, P., Jenkins, T., Thompson, J. & 
Wojcik, R. (2005). Acquiring and using world know-
ledge using a restricted subset of English.  18th In-
ternational FLAIRS Conference.   
Falkenhainer, B., Forbus, K. & Gentner, D. (1989). The 
Structure-Mapping Engine: Algorithms and Exam-
ples. Artificial Intelligence, 41, 1-63. 
Forbus, K., Ferguson, R. & Gentner, D. (1994) Incre-
mental structure-mapping.  Proceedings of CogSci94. 
Forbus, K., Lockwood, K. & Sharma, A. (2009). Steps 
towards a 2nd generation learning by reading system. 
AAAI Spring Symposium on Learning by Reading, 
Spring 2009. 
Forbus, K., Klenk, M., & Hinrichs, T. , (2009). Compa-
nion Cognitive Systems: Design Goals and Lessons 
Learned So Far. IEEE Intelligent Systems, vol. 24, 
no. 4, pp. 36-46, July/August. 
Forbus, K., Mostek, T. & Ferguson, R. (2002). An anal-
ogy ontology for integrating analogical processing 
and first-principles reasoning. Proceedings of IAAI-
02, July. 
Forbus, K. Riesbeck, C., Birnbaum, L., Livingston, K., 
Sharma, A., & Ureel, L. (2007). Integrating natural 
language, knowledge representation and reasoning, 
and analogical processing to learn by reading.  Pro-
ceedings of AAAI-07 Vancouver, BC. 
Example #S #BA #BR #TA #TR 
Gold mining/Collecting 
solar energy 
8 26 32 4 4 
Water flow/heat flow 11 14 21 13 16 
depth of water in buck-
et/temperature of house 
8 12 19 9 12 
Bucket with hole/house 
leaking heat 
4 14 20 8 6 
Bucket/Solar collector 5 13 15 4 4 
Earth?s atmos-
phere/greenhouse 
7 12 19 11 14 
Mean 7.2 15.2 21 8.2 9.3 
Table 3: Statistics of base and target domains 
produced by EA NLU.  #S = number of sen-
tences, B/T = Base, Target; A/T = 
Attributes/Relations 
103
Gentner, D. (1983). Structure-Mapping: A Theoretical 
Framework for Analogy. Cognitive Science, 7: 155-
170. 
Gentner, D., Bowdle, B., Wolff, P., & Boronat, C. 
(2001).  Metaphor is like analogy.  In Gentner, D., 
Holyoak, K., and Kokinov, B. (Eds.) The analogical 
mind: Perspective from cognitive science.  pp. 199-
253, Cambridge, MA: MIT Press. 
Hummel, J. E., & Holyoak, K. J. (2003). A symbolic-
connectionist theory of relational inference and gene-
ralization. Psychological Review, 110, 220-264. 
Kamp, H. & Reyle, U. (1993).  From Discourse to Log-
ic: Introduction to Model-theoretic Semantics of 
Natural Language.  Kluwer Academic Dordrecht: 
Boston. 
Keane, M., and Brayshaw, M. (1988).  The Incremental 
Analogy machine: A computational model of analo-
gy.  European Working Session on Learning. 
Larkey, L. & Love, B. (2003). CAB: Connectionist 
Analogy Builder.  Cognitive Science 27,781-794. 
Lehr, P. E., Burnett, R. W., & Zim, H. S. (1987). 
Weather. New York, NY: Golden Books Publishing 
Company, Inc. 
Lockwood, K. & Forbus, K. 2009. Multimodal know-
ledge capture from text and diagrams.  Proceedings 
of KCAP-2009. 
Lulis, E. & Evans, M. (2003).  The use of analogies in 
human tutoring dialogues.  AAAI Technical Report 
SS-03-06. 
Lulis, E., Evans, M. & Michael, J. (2004). Implement-
ing analogies in an electronic tutoring system.  In 
Lecture Notes in Computer Science, Vol 3220, pp. 
228-231, Springer Berlin/Heidelberg. 
Macleod, C., Grisham, R., & Meyers, A. (1998).  
COMLEX Syntax Reference Manual, Version 3.0.  
Linguistic Data Consortium, University of Pennsyl-
vania: Philadelphia, PA. 
Mostek, T., Forbus, K, & Meverden, C. (2000). Dynam-
ic case creation and expansion for analogical reason-
ing. Proceedings of AAAI-2000. Austin, TX. 
Tomai, E. & Forbus, K. (2009). EA NLU: Practical 
Language Understanding for Cognitive Modeling. 
Proceedings of the 22nd International Florida Artifi-
cial Intelligence Research Society Conference. Sani-
bel Island, Florida. 
Traum, David R. (2000). 20 Questions on Dialogue Act 
Taxonomies. Journal of Semantics, 17, 7-30. 
Winston, P.H. 1982.  Learning new principles from pre-
cedents and exercises.  Artificial Intelligence 23(12). 
Winston, P. 1986. Learning by augmenting rules and 
accumulating censors.  In Michalski, R., Carbonell, J. 
and Mitchell, T. (Eds.) Machine Learning: An Artifi-
cial Intelligence Approach, Volume 2.  Pp. 45-62. 
Morgan-Kaufman.   
 
104
