Proceedings of SPEECHGRAM 2007, pages 9?16,
Prague, Czech Republic, June 2007. c?2007 Association for Computational Linguistics
Converting Grammatical Framework to Regulus
Peter Ljungl?f
Department of Linguistics
G?teborg University
Gothenburg, Sweden
peb@ling.gu.se
Abstract
We present an algorithm for converting
Grammatical Framework grammars (Ranta,
2004) into the Regulus unification-based
framework (Rayner et al, 2006). The main
purpose is to take advantage of the Regulus-
to-Nuance compiler for generating opti-
mized speech recognition grammars. But
there is also a theoretical interest in knowing
how similar the two grammar formalisms
are.
Since Grammatical Framework is more ex-
pressive than Regulus, the resulting Regu-
lus grammars can be overgenerating. We
therefore describe a subclass of Grammati-
cal Framework for which the algorithm re-
sults in an equivalent Regulus grammar.
1 Background
In this section we describe the grammar formalism
Grammatical Framework (GF), and discuss its ex-
pressive power and the present options for creat-
ing speech recognition grammars (SRGs). The main
problem is that the size of the grammar can explode
when inflectional parameters are expanded. In this
paper we try to solve this problem by converting to
a formalism for which there is an optimized SRG
compiler. This formalism is Regulus, which is de-
scribed together with its SRG compiler.
The formal details are left out of the descriptions
in this section and can instead be found in section 2.
In section 3 the conversion algorithm is presented in
detail, and in section 4 there is a short discussion.
1.1 Grammatical Framework
Grammatical Framework (Ranta, 2004) is a gram-
mar formalism based on type theory. The main fea-
ture is the separation of abstract and concrete syn-
tax, which makes it very suitable for writing mul-
tilingual grammars. A rich module system also fa-
cilitates grammar writing as an engineering task, by
reusing common grammars.
1.1.1 Separating abstract and concrete syntax
The main idea of GF is the separation of ab-
stract and concrete syntax, a distinction which is
shared with several other grammar formalisms such
as Abstract Categorial Grammars (de Groote, 2001),
Lambda Grammar (Muskens, 2003) and Higher Or-
der Grammar (Pollard, 2004). The abstract part of
a grammar defines a set of abstract syntactic struc-
tures, called abstract terms or trees; and the concrete
part defines a relation between abstract structures
and concrete structures.
GF has a linearization perspective to grammar
writing, where the relation between abstract and
concrete is viewed as a mapping from abstract to
concrete structures, called linearization terms. In
some cases the mapping can be partial or even many-
valued.
Although not exploited in many well-known
grammar formalisms, a clear separation between ab-
stract and concrete syntax gives some advantages.
High-level language descriptions: When describ-
ing the abstract syntax, the grammar writer can
choose not to care about language specific de-
tails, such as inflection and word order.
Multilingual grammars: It is possible to define
different concrete syntaxes for one particular
9
abstract syntax. Multilingual grammars can be
used as a model for interlingua translation, but
also to simplify localization of language tech-
nology applications.
Resource grammars: The abstract syntax of one
grammar can be used as a concrete syntax of
another grammar. This makes it possible to im-
plement grammar resources to be used in sev-
eral different application domains.
These points are currently exploited in the GF Re-
source Grammar Library (Ranta et al, 2006), which
is a multilingual GF grammar with a common ab-
stract syntax for 13 languages. The grammati-
cal coverage is similar to the Core Language En-
gine (Rayner et al, 2000). The main purpose of
the Grammar Library is as a resource for writing
domain-specific grammars.
1.1.2 Abstract syntax
The abstract theory of GF is a version of Martin-
L?f?s (1984) dependent type theory. A grammar
consists of declarations of categories and functions.
Categories can depend on other categories. Func-
tion declarations can bind variables to be used in de-
pendent types, and also take functions as arguments,
thus giving rise to higher-order functions. Since the
abstract syntax also permits function definitions, the
expressive power of GF abstract syntax is Turing-
complete.
In this article we restrict ourselves to an impor-
tant subclass of GF, where there are no dependent
types and no higher-order functions. This subclass
is called context-free GF, and is an instance of Gen-
eralized Context-Free Grammar (Pollard, 1984).
The abstract syntax of a context-free GF grammar
consists of a set of function typings of the form
f : A1 ? ? ? ? ? A? ? A
This typing says that f is a function taking ? argu-
ments with categories A1 . . . A? and returning a cat-
egory A. This is equivalent to a context-free gram-
mar without terminal symbols. Note however, that
the function f would be written A ? A1 . . . A? as
an ordinary context-free rule. I.e., the left-hand side
of a context-free rule corresponds to the result of the
function, which is written to the right. The restric-
tion to a context-free backbone is not severe, since
the concrete syntax is so expressive.
1.1.3 Concrete syntax
Linearizations are written as terms in a typed
functional programming language, which is limited
to ensure decidability in generation and in parsing.
The language has records and finite-domain func-
tions (called tables); and the basic types are termi-
nal lists (called strings) and finite data types (called
parameter types). There are also local definitions,
lambda-abstractions and global function definitions.
The parameters are declared by the grammar; they
can be hierarchical but not recursive, to ensure finite-
ness.
The language of linearization terms is quite com-
plex, but it can be compiled to a normalized form
which is called canonical GF. In this paper we as-
sume that all linearizations are in canonical form.
A canonical concrete GF grammar contains declara-
tions of all parameter types, and linearization defini-
tions for all abstract functions.
1.1.4 Expressive power
The expressive power of context-free GF solely
depends on the possibility of discontinuous con-
stituents. This means that one grammatical phrase
can be split into several parts occurring in different
places in the sentence. Discontinuous constituents
permit a simple and compositional way of treating,
e.g., German compound verbs, where the particle
commonly is moved to the end of the sentence.
Ljungl?f (2004) showed that context-free GF is
equivalent to Multiple Context-Free Grammar (Seki
et al, 1991), which is known to be parseable in time
polynomial in the length of the input string. From a
converted Multiple CFG, each constituent can be ex-
tracted as a context-free rule, which will result in a
possibly overgenerating context-free grammar. This
context-free grammar can be output from the GF
system in several different speech recognition for-
mats, as described by Bringert (2007).
There is a severe problem with the conversion
from GF to Multiple CFG however ? the size of
the resulting grammar tend to explode when the in-
flectional parameters are expanded. Large gram-
mars such as many of the languages in the Resource
10
Grammar Library simply cannot be converted. One
solution would be to optimize the conversion algo-
rithm, e.g., by interleaving parameter expansion and
grammar compaction. Another solution would be
to translate into a grammar formalism which does
not have this size explosion. This is where Regulus
comes in ? if we could translate GF grammars into
Regulus grammars, we could make use of the re-
search already put into the Regulus-to-Nuance com-
piler, and would not have to reinvent the wheel.
1.2 Regulus
Regulus is an open-source toolkit for writing
grammar-based speech recognition systems (Rayner
et al, 2006).1 The central part is the Regulus gram-
mar formalism and a compiler for creating speech
recognition grammars. The toolkit has been en-
hanced with templates for developing e.g., speech
translation systems and dialogue systems. There is
also an English resource grammar, which can be
used for grammar specialization using explanation-
based learning (Rayner et al, 2006, chapters 9?10).
1.2.1 Unification of finite parameters
The Regulus formalism is a context-free gram-
mar, enhanced with unification of finite parameters.
This means that the formalism is equivalent to a
context-free grammar.
Each context-free category (e.g., Noun) has a
number of features (e.g., Number and Gender)
with a finite domain of values (e.g., Sg/Pl and
Masc/Fem/Neutr). The feature values are specified
using a record paired with the grammatical category.
Logical variables can be used for unifying features
of different constituents in the rule. It is possible to
define macros for simplifying common tasks, e.g.,
when implementing a lexicon.
Compared to Grammatical Framework, the Regu-
lus formalism is quite restricted. There is no clear
distinction between abstract and concrete syntax,
and there is no advanced module system in which to
define grammatical resources. Also, Regulus lacks
discontinuous constituents, which reduces the ex-
pressive power considerably.
1More information about Regulus, including download in-
formation, can be found on the project homepage: http:
//www.issco.unige.ch/projects/regulus/
1.2.2 Compiling Regulus to Nuance GSL
Nuance Communications (2003) has developed
a context-free grammar format for speech recogni-
tion, which has become one of the de facto stan-
dards for speech recognition. The grammar format
is called Nuance Grammar Specification Language
(GSL). The format has some special features, such
as semantic tagging and probabilistic grammar rules.
There are also restrictions in the format, most no-
tably that the grammars must not be left-recursive.
The Regulus formalism is designed to be able to
make use of the special features in Nuance GSL, and
the compiler can always create correct GSL gram-
mars without left-recursion.
2 Formal definitions
In this section we give formal definitions of rules and
linearization terms in GF, grammar rules and terms
in Regulus, and the intermediate structures we will
be using.
2.1 GF grammar rules
Since we are only interested in GF grammars with
a context-free backbone, the abstract syntax is a
context-free grammar where each rule has a unique
name. The rules are written as typings in a func-
tional language:
f : A1 ? ? ? ? ? A? ? A
Asmentioned earlier, this declaration corresponds to
the context-free rule A ? A1 . . . A?.
Linearizations are written as function definitions,
f x1 . . . x? = t, where x1 . . . x? are variables that
occur in the linearization term t. An alternative way
of writing this is to name the variables consistently
for each rule, and then the linearization term t it-
self is sufficient as a linearization definition. We
adopt this idea and use the uniform variable names
$1 . . . $? in each linearization. With this approach
we also distinguish the argument variables from the
parameter variables which get bound in tables.
2.2 GF linearization terms and substructures
A parameter type P is just a set of parameter values
{p1, . . . , pn}. Note that all parameter types must
be disjoint, i.e., each parameter should belong to
11
exactly one parameter type. Linearizations are de-
fined by association linearization terms to the ab-
stract functions. Note that the definition of terms is
slightly more general than the definition in GF, since
we want to include reduced terms in the definition.
The relation between the introduced classes are as
follows:
P ? VPar
VStr
}
? V ? T
Terms (t ? T) are defined inductively as follows:
t ::= $n argument
| ?s? string
| t ++ t? concatenation
| p pattern
| {r1 = t1; . . . ; rn = tn} record
| t.r projection
| [p1 ? t1; . . . ; pn ? tn] table
| t1!t2 selection
where n > 0 is a positive integer, p ? P is a pattern,
and r ? R is a record label. The class R of record
labels is just a finite class of atomic values. The ar-
gument reference $n denotes the nth argument of
the linearization function.
Patterns (p ? P) are pairs x@pi of variables, x,
and sets of parameters, pi = {p1 . . . pn}. The pa-
rameters p1 . . . pn all must belong to the same pa-
rameter type P, i.e., pi ? P. The meaning of the
pattern is that x is bound to one of the parameters in
pi. If pi = P we can skip that part and simply write
x. Conversely, if x is not used elsewhere in the term,
we can skip it and simply write pi.
Note that a pattern is a term in itself, but in GF
it will always occur as a single variable x or as a
single parameter p. However, after the conversion
algorithm has transformed tables into records, pat-
terns will become first class terms.
Reduced terms (v ? V) are subterms of ordinary
terms. A reduced term is a term which does not
contain a table or a selection, and where projections
only occur in the form $n.?, where ? ? R? is a se-
quence of labels:
v ::= $n.?
| ?s?
| v ++ v?
| p
| {r1 = v1; . . . ; rn = vn}
Reduced parameter terms (vp ? VPar) are sub-
terms of reduced terms, which correspond to param-
eters:
vp ::= $n.? | p
Reduced string terms (vs ? VStr) are subterms
of reduced terms, which correspond to strings:
vs ::= $n.? | ?s? | vs ++ v
?
s
Note that this is equivalent to a sequence of argu-
ment projections and string constants, which in turn
is equivalent to a right-hand side in a context-free
rule.
2.3 Regulus grammar rules and terms
A Regulus grammar is a unification-based phrase-
structure grammar. It consists of grammar rules,
which in turn is built up using Regulus terms.
Regulus rules are regular context-free grammar
rules, where each category is augmented with a Reg-
ulus term:
A:v ? ?0 A1:v1 ?1 . . . A?:v? ??
where each Ai is a context-free category, each vi is
a Regulus term, and each ?i is a (possibly empty)
sequence of terminal tokens.
Regulus terms are flat records where all values
are patterns (pi = xi@pii):2
vr ::= {r1 = p1; . . . ; rn = pn}
In this sense, Regulus terms are just subterms of re-
duced terms. However, a Regulus term can include
one of the two special labels sem and gsem, cor-
responding to return values and global slot-filling
in Nuance GSL, respectively. They can contain
complex structures, such as deeply nested lists and
records. Using these it is possible to define the syn-
tactical structure of a phrase.
2This is a slight abuse of syntax ? in Regulus the record row
ri = xi@pii is written as two separate rows ri = xi; ri = pii.
12
3 Converting GF to Regulus
In this section we describe an algorithm for convert-
ing any context-free GF rule into a set of Regulus
rules. This conversion is done in three steps:
1. Tables and table selections are removed from
the GF term, resulting in several reduced terms
and sets of constraints.
2. The results are massaged into Regulus terms
for the left-hand side and the right-hand side.
3. Finally, GF abstract syntax is used to create the
final Regulus rules.
In the final step, the abstract syntax is added as a se-
mantic value in the Regulus rules. This makes it pos-
sible to get back the GF abstract syntax tree, when
using Regulus (or Nuance) for parsing the grammar.
Example As a running example we will use a stan-
dard English GF rule for combining transitive verbs
with noun phrases:
vp : TV ? NP ? VP
= {s = [n ? $1.s!n ++ $2.s]}
The idea is that a verb phrase has a parametrical
number (n), which it inherits from the verb. When
the verb phrase is used in a sentence, the number
will depend on the inherent number of the subject.
3.1 Converting tables to unification-based
records
The main difference between GF and Regulus is that
the former has tables and the latter has unification.
The problem when converting from GF to Regulus
is therefore how to get rid of the tables and selec-
tions. We present an algorithm for removing tables
and selections, by replacing them with logical vari-
ables and equality constraints.
The basic idea is to translate each row pi ? ti
in a table into a record {p = pi;v = ti}. The
variables in ti which are bound by pi become log-
ical variables. Thus the original table gives rise to n
different records (if n is the number of table rows),
which in the end becomes n different Regulus terms.
A table selection t!t? then has to be translated into
the value t.v of the table, and a constraint is added
that the selection term t? and the pattern t.p of the
table should be unified.
Step 1: Removing tables and selections
We define a nondeterministic reduction operation
=? . The meaning of t =? v/? is that the term t ?
T is converted to the reduced term v ? V together
with the set of constraints ? ? VPar ? VPar. Each
constraint in ? is of the form vp
.
= v?p, where vp and
v?p are reduced parameter terms.
? Each row pi ? ti in a table is reduced to a
record containing the pattern pi and the reduced
value vi:
ti =? vi/?i
[. . . ; pi ? ti; . . .] =? {p = pi;v = vi}/?i
Note that this rule is nondeterministic ? the ta-
ble is reduced to n different terms, where n is
the number of table rows.
? A table selection t!t? is reduced to the value v.v,
with the added constraint that the pattern v.p
and the selection term v? should unify:
t =? v0/? t? =? v?p/?
?
t!t? =? v / ???(vp
.
= v?p)
vp = prj(v0,p)
v = prj(v0,v)
Note that since t? denotes a parameter, it will be
reduced to a parameter term, v?p ? VPar.
? A record projection t.r is reduced to a projec-
tion v.r:
t =? v/?
t.r =? vr/?
vr = prj(v, r)
? All other term constructors are reduced com-
positionally, i.e., by reducing the internal terms
recursively.
The function prj(v, r) calculates the projection of
r on the simple term v. Since there are only two
reduced term constructors that can correspond to a
record, there are only two cases in the definition:
prj({. . . ; r = vr; . . .}, r) = vr
prj($n.? , r) = $n.?r
13
Example The original linearization term of the ex-
ample contains one table and one selection. The
selection $1.s!n is reduced to $1.sv with the added
constraint $1.sp .= n. And since there is only one
row in the table, the example term is reduced to one
single term vvp with the constraints ?vp:
vvp = {s = {p = n;v = $1.sv ++ $2.s}}
?vp = $1.sp
.
= n
3.2 Building Regulus terms
The reduced term and the constraints from the first
step do not constitute a Regulus grammar rule, but
they have to be massaged into the correct form. This
is done in four small steps below.
Step 2a: Flattening the reduced term
After the conversion t =? v/?, we have a re-
duced term v ? V and a set of constraints ? ?
VPar ? VPar. Now we convert v into a set of con-
straints and add to the constraint store ?:
? For each subterm v? in v denoting a parameter,
add $0.?
.
= v? to ?. The path ? is the sequence
of labels for getting from v to v?, i.e., v? = v.?.
We also create a set of ?proto rules? ? ? R??VStr:
? For each subterm v? in v denoting a string, add
? ? v? to ?. The path ? is the same as above.
Example There is one subterm in vvp denoting a
parameter, so we add $0.sp .= n to ?vp. There is
one subterm in vvp that denotes a string, so we let
?vp contain sv ? $1.sv ++ $2.s.
Step 2b: Simplifying the constraints
Now we have two constraint stores, ? and ?, of
which the latter can be partially evaluated into a sim-
pler form.
1. For each constraint of the form $n1.?1
.
=
$n2.?2, we replace it with two new constraints
$ni.?i
.
= x, where x is a fresh variable.3
2. For each constraint of the form x1@pi1
.
=
x2@pi2 , there are two possibilities:
3Recall that x is just a shorthand for x@pi, where pi is the set
of all parameters.
? If pi1 and pi2 are disjoint, then the con-
straint is contradictive and we remove v,
? and ? from the list of results.
? Otherwise, we replace each occurrence of
xi@pii in v and in ?, by x@pi, where x is a
fresh variable and pi = pi1 ? pi2.
Example We do not have to do anything to ?vp,
since all constraints already are in simplified form.
Step 2c: Building Regulus terms
Now ? only contains constraints of the form
$n.?
.
= p where p = x@pi. We transform these
constraints into the Regulus records T0, T1, . . . , T?
in the following way:
? For each constraint $n.?
.
= p, add the record
row {? = p} to Tn.
Note that the labels in the Regulus terms are se-
quences of GF labels.
Example The constraints in ?vp now give rise to
the Regulus terms:
Tvp,0 = {sp = n}
Tvp,1 = {sp = n}
Tvp,2 = {}
3.3 Building a Regulus grammar
To be able to create Regulus grammar rules from the
Regulus terms T0 . . . T?, we need to look at the ab-
stract syntax in the GF grammar. In this section we
will assume that the typing of the linearization in
question is f : A1 ? ? ? ? ? A? ? A.
Regulus (and Nuance GSL) permits the use of ar-
bitrary nested lists in the special sem feature. We
will use the nested list for representing a GF abstract
syntax tree which then will be returned directly by
Nuance after the parsing has succeeded. This is im-
portant since the arguments to the function can be
permuted in the linearization, which then means that
the arguments in the Regulus rule are permuted as
well.
14
Step 3a: Adding GF abstract syntax to the
Regulus terms
The abstract syntax tree of the original rule is put
as a sem value in the left-hand side term T0:
? Add the row {sem=[f x1 . . . x?]} to T0.
? For each 1 ? i ? ?, add {sem=xi} to Ti.
Note that the x1 . . . x? should be fresh variables, not
used elsewhere in the terms.
Example After adding semantics, the example
terms become:
Tvp,0 = {sp = n; sem = [vp x y]}
Tvp,1 = {sp = n; sem = x}
Tvp,2 = {sem = y}
Step 3b: Building Regulus grammar rules
Finally, we can transform the proto rules in ? into
Regulus grammar rules:
? For each proto rule ?0 ? v1 ++ ? ? ? ++ vm in
?, create a new Regulus rule:
A?0 : T0 ? v
?
1 . . . v
?
m
where the terms in the right-hand side are cal-
culated as follows:
(?s?)? = ?s?
($n.?)? = An ? : Tn
Example From the single proto rule in?vp we cre-
ate the Regulus rule:
VPsv : Tvp,0 ? TVsv : Tvp,1 NPs : Tvp,2
where the terms Tvp,i are described above.
4 Discussion
We have presented an algorithm for converting
GF grammars with a context-free backbone into
unification-based Regulus grammars. The algorithm
is simple and straightforward, which is an indication
that the formalisms are more similar than one might
have guessed beforehand.
4.1 Equivalence of the grammars
The presented algorithm does not necessarily yield
an equivalent grammar. This is a consequence of the
fact that context-free GF is equivalent to Multiple
CFG, and that Multiple CFG is much more expres-
sive than context-free grammars.
However, if the original grammar does not make
use of multiple constituents, the conversion is equiv-
alent. Note that the grammar might very well con-
tain multiple constituents, but if there is no right-
hand side that refers to both constituents simultane-
ously the equivalence is still preserved.
4.2 Complexity issues
As mentioned earlier, each GF function might give
rise to several Regulus rules, so in one sense the re-
sulting grammar is bigger than the original. How-
ever, the actual size in terms of memory usage does
not differ (except maybe linear because of differ-
ences in syntax).
4.2.1 The number of rules
The number of Regulus rules for one single GF
linearization term is equal to:
|?|
?
?
|?|
where |?| is the number of discontinuous con-
stituents, and ? ranges over all tables in the lin-
earization term. This is easy to see, since it is
only tables that are reduced nondeterministically,
and each proto rule in ? gives rise to one Regulus
rule.
4.2.2 The size of the grammar
The total size of the final grammar can be larger
than the original GF grammar. This is because the
Regulus grammar will contain lots of copies of the
same structures, e.g., everything outside of a table
has to be duplicated in for each table row. The the-
oretical limit is the same as above ? the number of
constituents, times the the total product of all table
rows ? but in practice the grammar explosion is not
that extreme.
Since the increase in size is due to copying, the
Regulus grammar can be compacted by the use of
macros (Rayner et al, 2006, section 4.5). This could
15
probably be implemented in the algorithm directly,
but we have not yet investigated this idea.
4.2.3 Time complexity
The time complexity of the algorithm is approxi-
mately equivalent to the size of the resulting Regu-
lus grammar. The first step (in section 3.1), can be
implemented as a single pass through the term and
is therefore linear in the size of the resulting terms.
The post-processing steps (in section 3.2) are also
linear in the size of the terms and constraints. Fi-
nally, the steps for building grammar rules does not
depend on the term size at all. Thus, the time com-
plexity is linear in the size of the final Regulus gram-
mar.
4.3 Using Regulus as a compiler for speech
recognition grammars
By presenting an algorithm for converting GF gram-
mars into Regulus, it is possible to further use the
Regulus-to-Nuance compiler for getting an opti-
mized speech recognition grammar. The advantage
to compiling Nuance grammars directly from GF is
clear: the Regulus project has developed and imple-
mented several optimizations (Rayner et al, 2006,
chapter 8), which would have to be reimplemented
in a direct GF-to-Nuance compiler.
As previously mentioned in section 1.1.4, there is
a speech recognition grammar compiler already im-
plemented in GF (Bringert, 2007), which uses the
equivalence of GF and Multiple CFG. An interest-
ing future investigation would be to compare the two
approaches on realistic grammars.
References
Bj?rn Bringert. 2007. Speech recognition grammar com-
pilation in Grammatical Framework. Submitted to
SpeechGram 2007.
Philippe de Groote. 2001. Towards abstract categorial
grammars. In 39th Meeting of the Association for
Computational Linguistics, Toulouse, France.
Peter Ljungl?f. 2004. Expressivity and Complexity of
the Grammatical Framework. Ph.D. thesis, G?teborg
University and Chalmers University of Technology,
November.
Per Martin-L?f. 1984. Intuitionistic Type Theory. Bib-
liopolis, Napoli.
ReinhardMuskens. 2003. Language, lambdas, and logic.
In Geert-Jan Kruijff and Richard Oehrle, editors, Reo-
surce Sensitivity in Binding and Anaphora, pages 23?
54. Kluwer.
Nuance Communications, Inc., 2003. Nuance Speech
Recognition System 8.5: Grammar Developer?s
Guide, December.
Carl Pollard. 1984. Generalised Phrase Structure Gram-
mars, Head Grammars and Natural Language. Ph.D.
thesis, Stanford University.
Carl Pollard. 2004. Higher-order categorial grammar. In
Michel Moortgat, editor, International Conference on
Categorial Grammars, Montpellier, France.
Aarne Ranta, Ali El-Dada, and Janna Khegai,
2006. The GF Resource Grammar Library.
Can be downloaded from the GF homepage
http://www.cs.chalmers.se/~aarne/GF
Aarne Ranta. 2004. Grammatical Framework, a type-
theoretical grammar formalism. Journal of Functional
Programming, 14(2):145?189.
Manny Rayner, Dave Carter, Pierrette Bouillon, Vassilis
Digalakis, and Mats Wir?n. 2000. The Spoken Lan-
guage Translator. Cambridge University Press.
Manny Rayner, Beth Ann Hockey, and Pierrette Bouil-
lon. 2006. Putting Linguistics into Speech Recogni-
tion: The Regulus Grammar Compiler. CSLI Publica-
tions.
Hiroyuki Seki, Takashi Matsumara, Mamoru Fujii, and
Tadao Kasami. 1991. On multiple context-free gram-
mars. Theoretical Computer Science, 88:191?229.
16
