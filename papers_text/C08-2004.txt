Coling 2008: Companion volume ? Posters and Demonstrations, pages 15?18
Manchester, August 2008
The power of negative thinking:
Exploiting label disagreement in the min-cut classification framework
Mohit Bansal
Dept. of Computer Science & Engineering
Indian Institute of Technology Kanpur
mbansal47@gmail.com
Claire Cardie and Lillian Lee
Dept. of Computer Science
Cornell University
{cardie,llee}@cs.cornell.edu
Abstract
Treating classification as seeking minimum
cuts in the appropriate graph has proven ef-
fective in a number of applications. The
power of this approach lies in its abil-
ity to incorporate label-agreement prefer-
ences among pairs of instances in a prov-
ably tractable way. Label disagreement
preferences are another potentially rich
source of information, but prior NLP work
within the minimum-cut paradigm has not
explicitly incorporated it. Here, we re-
port on work in progress that examines
several novel heuristics for incorporating
such information. Our results, produced
within the context of a politically-oriented
sentiment-classification task, demonstrate
that these heuristics allow for the addition
of label-disagreement information in a way
that improves classification accuracy while
preserving the efficiency guarantees of the
minimum-cut framework.
1 Introduction
Classification algorithms based on formulating the
classification task as one of finding minimum s-t
cuts in edge-weighted graphs ? henceforth min-
imum cuts or min cuts ? have been successfully
employed in vision, computational biology, and
natural language processing. Within NLP, appli-
cations include sentiment-analysis problems (Pang
and Lee, 2004; Agarwal and Bhattacharyya, 2005;
Thomas et al, 2006) and content selection for text
generation (Barzilay and Lapata, 2005).
c
? 2008. Licensed under the Creative Commons
Attribution-Noncommercial-Share Alike 3.0 Unported li-
cense (http://creativecommons.org/licenses/by-nc-sa/3.0/).
Some rights reserved.
As a classification framework, the minimum-
cut approach is quite attractive. First, it provides
a principled, yet flexible mechanism for allowing
problem-specific relational information ? includ-
ing several types of both hard and soft constraints
? to influence a collection of classification deci-
sions. Second, in many important cases, such as
when all the edge weights are non-negative, find-
ing a minimum cut can be done in a provably effi-
cient manner.
To date, however, researchers have restricted the
semantics of the constraints mentioned above to
encode pair-wise ?agreement? information only.
There is a computational reason for this restriction:
?agreement? and ?disagreement? information are
arguably most naturally expressed via positive and
negative edge weights, respectively; but in general,
the inclusion of even a relatively small number of
negative edge weights makes finding a minimum
cut NP-hard (McCormick et al, 2003).
To avoid this computational issue, we propose
several heuristics that encode disagreement infor-
mation with non-negative edge weights. We in-
stantiate our approach on a sentiment-polarity clas-
sification task ? determining whether individual
conversational turns in U.S. Congressional floor
debates support or oppose some given legislation.
Our preliminary results demonstrate promising im-
provements over the prior work of Thomas et al
(2006), who considered only the use of agreement
information in this domain.
2 Method
2.1 Min-cut classification framework
Binary classification problems are usually ap-
proached by considering each classification deci-
sion in isolation. More formally, let X
test
=
15
{x
1
, x
2
, . . . , x
n
} be the test instances, drawn from
some universe X , and let C = {c
1
, c
2
} be
the two possible classes. Then, the usual ap-
proach can often be framed as labeling each x
i
according to some individual-preference function
Ind:X ? C?<, such as the signed distance to
the dividing hyperplane according to an SVM or
the posterior class probability assigned by a Naive
Bayes classifier.
But when it is difficult to accurately classify a
particular x
i
in isolation, there is a key insight
that can help: knowing that x
i
has the same la-
bel as an easily-categorized x
j
makes labeling x
i
easy. Thus, suppose we also have an association-
preference function Assoc:X ?X?< express-
ing a reward for placing two items in the same
class; an example might be the output of an agree-
ment classifier or a similarity function. Then, we
can search for a classification function c(x
i
|X
test
)
? note that all of X
test
can affect an instance?s la-
bel ? that minimizes the total ?pining? of the test
items for the class they were not assigned to due to
either their individual or associational preferences:
?
i
Ind(x
i
, c(x
i
|X
test
)) +
??
?
i,j:c(x
i
|X
test
)=c(x
j
|X
test
)
Assoc(x
i
, x
j
),
where c(x
i
|X
test
) is the class ?opposite? to
c(x
i
|X
test
), and the free parameter ? regulates
the emphasis on agreement information. Solutions
to the above minimization problem correspond to
minimum s-t cuts in a certain graph, and if both
Ind and Assoc are non-negative functions, then,
surprisingly, minimum cuts can be found in poly-
nomial time; see Kleinberg and Tardos (2006, Sec-
tion 7.10) for details. But, as mentioned above,
allowing negative values makes finding a solution
intractable in the general case.
2.2 Prior work discards some negative values
The starting point for our work is Thomas et
al. (2006) (henceforth TPL). The reason for this
choice is that TPL used minimum-cut-based classi-
fication wherein signed distances to dividing SVM
hyperplanes were employed to define Ind(x, c)
and Assoc(x, x?). It was natural to use SVMs,
since association was determined by classification
rather than similarity ? specifically, categorizing
references by one congressperson to another as re-
flecting agreement or not ? but as a result, neg-
ative association-preferences (e.g., negative dis-
tance to a hyperplane) had to be accounted for.
We formalize TPL?s approach at a high
level as follows. Let Ind?:X ? C?< and
Assoc
?
:X ?X?< be initial individual- and
association-preference functions, such as the
signed distances mentioned above. TPL create two
non-negative conversion functions f :<? [0, 1]
and g:<? [0, 1], and then define
Ind(x
i
, c) := f(Ind
?
(x
i
, c))
Assoc(x
i
, x
j
) := g(Assoc
?
(x
i
, x
j
))
so that an optimal classification can be found in
polynomial time, as discussed above. We omit the
exact definitions of f and g in order to focus on
what is important here: roughly speaking, f and
g normalize values and handle outliers1, with the
following crucial exception. While negative initial
individual preferences for one class can be trans-
lated into positive individual preferences for the
other, there is no such mechanism for negative val-
ues of Assoc?; so TPL resort to defining g to be
0 for negative arguments. They thus discard po-
tentially key information regarding the strength of
label disagreement preferences.
2.3 Encoding negative associations
Instead of discarding the potentially crucial label-
disagreement information represented by negative
Assoc
? values, we propose heuristics that seek to
incorporate this valuable information, but that keep
Ind and Assoc non-negative (by piggy-backing off
of TPL?s pre-existing conversion-function strat-
egy2) to preserve the min-cut-classification effi-
ciency guarantees.
We illustrate our heuristics with a running
example. Consider a simplified setting with only
two instances x
1
and x
2
; f(z) = z; g(z) = 0 if
z < 0, 1 otherwise; and Ind? values (numbers
labeling left or right arrows in the diagrams below,
e.g., Ind?(x
1
, c
1
) = .7) and Assoc? value (the -2
labeling the up-and-down arrow) as depicted here:
? [.7]? x
1
?[.3]?
c
1
m [?2] c
2
? [.6]? x
2
?[.4]?
Then, the resulting TPL Ind and Assoc values are
1Thus, strictly speaking, f and g also depend on Ind?,
Assoc
?
, and X
test
, but we suppress this dependence for nota-
tional compactness.
2Our approach also applies to definitions of f and g dif-
ferent from TPL?s.
16
? [.7]? x
1
?[.3]?
c
1
m [0] c
2
? [.6]? x
2
?[.4]?
Note that since the initial -2 association value is
ignored, c(x
1
|X
test
) = c(x
2
|X
test
) = c
1
appears
to be a good classification according to TPL.
The Scale all up heuristic Rather than discard
disagreement information, a simple strategy is to
just scale up all initial association preferences by a
sufficiently large positive constant N :
Ind(x
i
, c) := f(Ind
?
(x
i
, c))
Assoc(x
i
, x
j
) := g(Assoc
?
(x
i
, x
j
) + N)
For N = 3 in our example, we get
? [.7]? x
1
?[.3]?
c
1
m [1] c
2
? [.6]? x
2
?[.4]?
This heuristic ensures that the more negative the
Assoc
? value, the lower the cost of separating the
relevant item pair (whereas TPL don?t distinguish
between negative Assoc? values). The heuristic
below tries to be more proactive, forcing such
pairs to receive different labels.
The SetTo heuristic We proceed through
x
1
, x
2
, . . . in order. Each time we encounter
an x
i
where Assoc?(x
i
, x
j
) < 0 for some
j > i, we try to force x
i
and x
j
into dif-
ferent classes by altering the four relevant
individual-preferences affecting this pair of in-
stances, namely, f(Ind?(x
i
, c
1
)), f(Ind
?
(x
i
, c
2
)),
f(Ind
?
(x
j
, c
1
)), and f(Ind?(x
j
, c
2
)). Assume
without loss of generality that the largest of
these values is the first one. If we respect
that preference to put x
i
in c
1
, then according
to the association-preference information, it
follows that we should put x
j
in c
2
. We can
instantiate this chain of reasoning by setting
Ind(x
i
, c
1
) := max(?, f(Ind
?
(x
i
, c
1
)))
Ind(x
i
, c
2
) := min(1? ?, f(Ind
?
(x
i
, c
2
)))
Ind(x
j
, c
1
) := min(1? ?, f(Ind
?
(x
j
, c
1
)))
Ind(x
j
, c
2
) := max(?, f(Ind
?
(x
j
, c
2
)))
for some constant ? ? (.5, 1], and making no
change to TPL?s definition of Assoc. For ? = .8
in our example, we get
? [.8]? x
1
?[.2]?
c
1
m [0] c
2
? [.2]? x
2
?[.8]?
Note that as we proceed through x
1
, x
2
, . . . in
order, some earlier changes may be undone.
The IncBy heuristic A more conservative ver-
sion of the above heuristic is to increment and
decrement the individual-preference values so that
they are somewhat preserved, rather than com-
pletely replace them with fixed constants:
Ind(x
i
, c
1
) := min(1, f(Ind
?
(x
i
, c
1
)) + ?)
Ind(x
i
, c
2
) := max(0, f(Ind
?
(x
i
, c
2
))? ?)
Ind(x
j
, c
1
) := max(0, f(Ind
?
(x
j
, c
1
))? ?)
Ind(x
j
, c
2
) := min(1, f(Ind
?
(x
j
, c
2
)) + ?)
For ? = .1, our example becomes
? [.8]? x
1
?[.2]?
c
1
m [0] c
2
? [.5]? x
2
?[.5]?
3 Evaluation
For evaluation, we adopt the sentiment-
classification problem tackled by TPL: clas-
sifying speech segments (individual conversational
turns) in a U.S. Congressional floor debate as
to whether they support or oppose the legis-
lation under discussion. TPL describe many
reasons why this is an important problem. For
our purposes, this task is also very convenient
because all of TPL?s computed raw and converted
Ind
? and Assoc? data are publicly available at
www.cs.cornell.edu/home/llee/data/convote.html.
Thus, we used their calculated values to imple-
ment our algorithms as well as to reproduce their
original results.3
One issue of note is that TPL actually in-
ferred association preferences between speakers,
not speech segments. We do the same when ap-
plying SetTo or IncBy to a pair {x
i
, x
j
} by con-
sidering the average of f(Ind?(x
k
, c
1
)) over all
x
k
uttered by the speaker of x
i
, instead of just
f(Ind
?
(x
i
, c
1
)). The other three relevant individ-
ual values are treated similarly. We also make
appropriate modifications (according to SetTo and
IncBy) to the individual preferences of all such x
k
simultaneously, not just x
i
, and similarly for x
j
.
A related issue is that TPL assume that all
speech segments by the same speaker should have
the same label. To make experimental compar-
isons meaningful, we follow TPL in considering
two different instantiations of this assumption. In
segment-based classification, Assoc(x
i
, x
j
) is set
to an arbitrarily high positive constant if the same
speaker uttered both x
i
and x
j
. In speaker-based
classification, Ind?(x
i
, c) is produced by running
3For brevity, we omit TPL?s ?high-threshold? variants.
17
 60
 62
 64
 66
 68
 70
 72
 74
 76
 78
SetTo(.6)SVM SetTo(1) IncBy(.25)IncBy(.15)TPL IncBy(.05)Scale all up SetTo(.8)
pe
rc
en
t c
or
re
ct
ALGORITHMS
Test-set classification accuracies, using held-out parameter estimation
segment-based, test
speaker-based, test
best TPL, test
Figure 1: Experimental results. ?SVM?: classification using only individual-preference information.
Values of ? are indicated in parentheses next to the relevant algorithm names.
an SVM on the concatenation of all speeches ut-
tered by x
i
?s speaker.
Space limits preclude inclusion of further de-
tails; please see TPL for more information.
3.1 Results and future plans
The association-emphasis parameter ? was trained
on held-out data, with ties broken in favor of the
largest ? in order to emphasize association in-
formation. We used Andrew Goldberg?s HIPR
code (http://avglab.com/andrew/soft.html) to com-
pute minimum cuts. The resultant test-set classifi-
cation accuracies are presented in Figure 1.
We see that Scale all up performs worse
than TPL, but the more proactive heuristics
(SetTo, IncBy) almost always outperform TPL on
segment-based classification, sometimes substan-
tially so, and outperform TPL on speaker-based
classification for half of the variations. We there-
fore conclude that label disagreement informa-
tion is indeed valuable; and that incorporating la-
bel disagreement information on top of the (posi-
tive) label agreement information that TPL lever-
aged can be achieved using simple heuristics; and
that good performance enhancements result with-
out any concomitant significant loss of efficiency.
These results are preliminary, and the diver-
gence in behaviors between different heuristics
in different settings requires investigation. Ad-
ditional future work includes investigating more
sophisticated (but often therefore less tractable)
formalisms for joint classification; and looking
at whether approximation algorithms for finding
minimum cuts in graphs with negative edge capac-
ities can be effective.
Acknowledgments We thank Jon Kleinberg and the
reviewers for helpful comments. Portions of this work
were done while the first author was visiting Cornell Uni-
versity. This paper is based upon work supported in part
by the National Science Foundation under grant nos. IIS-
0329064, BCS-0624277, and IIS-0535099, a Cornell Univer-
sity Provost?s Award for Distinguished Scholarship, a Yahoo!
Research Alliance gift, an Alfred P. Sloan Research Fellow-
ship, and by DHS grant N0014-07-1-0152. Any opinions,
findings, and conclusions or recommendations expressed are
those of the authors and do not necessarily reflect the views
or official policies, either expressed or implied, of any spon-
soring institutions, the U.S. government, or any other entity.
References
A. Agarwal, P. Bhattacharyya. 2005. Sentiment analysis: A
new approach for effective use of linguistic knowledge and
exploiting similarities in a set of documents to be classi-
fied. ICON.
R. Barzilay, M. Lapata. 2005. Collective content selection for
concept-to-text generation. HLT/EMNLP, pp. 331?338.
J. Kleinberg, ?E. Tardos. 2006. Algorithm Design. Addison
Wesley.
S. T. McCormick, M. R. Rao, G. Rinaldi. 2003. Easy and dif-
ficult objective functions for max cut. Mathematical Pro-
gramming, Series B(94):459?466.
B. Pang, L. Lee. 2004. A sentimental education: Sentiment
analysis using subjectivity summarization based on mini-
mum cuts. ACL, pp. 271?278.
M. Thomas, B. Pang, L. Lee. 2006. Get out the vote: De-
termining support or opposition from Congressional floor-
debate transcripts. EMNLP, pp. 327?335.
18
