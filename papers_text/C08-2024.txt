Coling 2008: Companion volume ? Posters and Demonstrations, pages 95?98
Manchester, August 2008
Integrating Motion Predicate Classes with
Spatial and Temporal Annotations
James Pustejovsky
Computer Science Department
Brandeis University
jamesp@cs.brandeis.edu
Jessica L. Moszkowicz
Computer Science Department
Brandeis University
jlittman@cs.brandeis.edu
Abstract
We propose a spatio-temporal markup for
the annotation of motion predicates in text,
informed by a lexical semantic classifica-
tion of these verbs. We incorporate this
classification within a spatial event struc-
ture, based on Generative Lexicon Theory.
We discuss how the spatial event structure
suggests changes to annotation systems de-
signed solely for temporal or spatial phe-
nomena, resulting in spatio-temporal an-
notation.
1 Introduction and Motivation
The recognition of spatial entities in natural lan-
guage is an important component of understanding
a text (Mani et al, 2008). However, simply iden-
tifying fixed geospatial regions and specific ?facil-
ities? is not enough to achieve a complete repre-
sentation of all the spatial phenomena present. In
fact, this leaves out one of the most crucial aspects
of spatial information, motion. To capture motion,
we must integrate temporal and spatial information
with the lexical semantics of motion predicates and
prepositions.
The goal of this research is to further the rep-
resentational support for spatio-temporal reason-
ing from natural language text in the service of
practical applications. To create such support, we
propose to use lexical resources for motion predi-
cates to integrate two existing annotation schemes,
SpatialML and TimeML, creating a representation
that captures, in a fine-grained manner, the move-
ment of individuals through spatial and temporal
c
? 2008. Licensed under the Creative Commons
Attribution-Noncommercial-Share Alike 3.0 Unported li-
cense (http://creativecommons.org/licenses/by-nc-sa/3.0/).
Some rights reserved.
indexes. This work is part of a larger effort to au-
tomate such annotation and reasoning over natural
language documents using symbolic and machine
learning methods.
In this paper, we investigate different resources
and annotations for spatio-temporal information.
In section 2, we describe some of the resources we
employed for our investigation. Section 3 elabo-
rates on the classes we focus on as we work to-
wards developing a classification for the purpose
of annotating motion predicates, which we discuss
in section 4.
2 Previous Work on Motion
Classifications in Language
There has been considerable research on the lin-
guistic behavior of spatial predicates and preposi-
tions in language (e.g., (Jackendoff, 1983), (Her-
skovits, 1986), (Boas, 2001), (Cappelle and De-
clerck, 2005)). Within qualitative spatial reasoning
(QSR), work has recently started to focus on incor-
porating mereo-topological concepts into the cal-
culus of relations between regions. The most suc-
cessful of these is the Regional Connection Calcu-
lus, or RCC (Randell et al, 1992). RCC8 and other
systems like it do an adequate job of represent-
ing static information about space, but they cannot
help us deal with motion, since that task requires a
temporal component. Galton ((Galton, 1993; Gal-
ton, 1997)) began work on a commonsense theory
of motion, but this work did not focus on merging
temporal and spatial phenomena. Muller (Muller,
1998), however, proposes just such a system with
his qualitative theory of motion based on spatio-
temporal primitives. The result of Muller?s system
is a set of six motion classes: leave, hit, reach, ex-
ternal, internal, and cross.
Asher and Sablayrolles offer their own account
95
of motion verbs and spatial prepositional phrases
in French (Asher and Sablayrolles, 1995). They
propose ten groups of motion verbs as follows:
s?approcher (to approach), arriver (to arrive), en-
trer (to enter), se poser (to alight), s??eloigner (to
distance oneself from), partir (to leave), sortir (to
go out), d?ecoller (to take off), passer (par) (to go
through), d?evier (to deviate). This verb classifica-
tion is more fine-grained than Muller?s.
While Muller, Asher, Sablayrolles, and Vieu
among others have focused on the formal seman-
tics of motion, other work has been done to repre-
sent motion in the FrameNet (Baker et al, 1998)
and VerbNet (Kipper et al, 2006) projects. The
Motion frame is a high level frame in the FrameNet
hierarchy. It is defined as ?Some entity (Theme)
starts out in one place (Source) and ends up in
some other place (Goal), having covered some
space between the two (Path).?
To explore VerbNet?s take on motion predicates,
we mapped Asher and Sablayrolles? verbs to Verb-
Net classes. The mapping revealed that, while
many of the motion predicates we care about have
specific classes in VerbNet, it is not always clear
what these classes have in common unless we look
to FrameNet to find a higher level representation.
3 Classifying spatio-temporal predicates
Following (Muller, 1998), (Vieu, 1991), and
(Asher and Sablayrolles, 1995), we assume spatial
variables are incorporated into the representation
of motion predicates in language. For this paper,
we generally follow (Muller, 2002) by represent-
ing the individuals participating in spatial relations
as spatio-temporal regions (s?i). For modeling mo-
tion, however, we restrict our discussion to spatio-
temporal regions occupied by physical matter de-
noted by the type s ? i ? p.
For this work, we performed several map-
pings between Muller, Asher and Sablayrolles, and
FrameNet. The result of this mapping was a group
of classes based largely on Muller?s classifications
with some very slight modifications detailed in the
table below. The spatial event structures for each
of these classes will describe their formal seman-
tics (as in Figure 1 below).
In addition to these classes, we model the spatial
semantics of prepositions, following (Asher and
Sablayrolles, 1995), generally. Because of space
limitations, we will not discuss the contritbution
of prepositional semantics in this paper.
Move run, fly, drive
Move External drive around, pass
Move Internal walk around the room
Leave leave, desert
Reach arrive, enter, reach
Detach take off, disconnect, pull away
Hit land, hit
Follow follow, chase
Deviate flee, run from
Stay remain, stay
Table 1: Motion Classes
There is a complex interaction between a motion
verb class and the interpretation of its arguments.
For example, not all regions are occupied by the
extent of physical matter (see above), but there are
some objects which are properly both physical and
spatial, such as the concept building. Notice the
ambiguity inherent in the statement below, where
both Move Internal and Move External are pos-
sible interpretations.
(1) The man walked around the building.
This is due to the semantic nature of building as
both a physical object with extent, and also as a
volume/aperture.
To model the mapping of objects to specific ar-
gument and event structures, we adopt the frame-
work of Generative Lexicon Theory (GL). The no-
tion of ?polarity? in the (Muller, 1998) sense is
quite similar to the semantic effect brought about
by event headedness in (Pustejovsky, 1995). GL
provides an explicitly typed argument structure,
a typed subeventual structure, and a predicative
body, which we will use to express RCC8 rela-
tions. For example, a representation of the Spa-
tial Event Structure (SES) for the motion predicate
leave is illustrated below in Figure 1. Note that
the statement Polarity=initial is equivalent to say-
ing Head=left. The relation BT is shorthand for
boundary transition, which is composed of the fol-
lowing RCC8 relations: TPP, O, and EC.
Each motion class in Table 1 maps to a unique
predicative body (qualia structure) in the spatial
event structure for a verb. We demonstrate be-
low how these representations are then embed-
ded in the annotation of a text as RCC8 relations
in a modified SpatialML/TimeML format, called
Spatio-temporal Markup (STM).
The robustness of the mapping from the motion
classes in Table 1 to FrameNet is currently being
96
??
?
?
?
?
?
?
?
?
?
?
?
?
?
leave
ARGSTR =
[
ARG1 = x: s ? i ? p
ARG2 = y: s ? i
]
EVENTSTR =
?
?
E
1
= e
1
:process
E
2
= e
2
:state
RESTR = <
?
POLARITY = initial
?
?
QUALIA =
[
AGENTIVE = NTTP(e
1
,x,y)
? BT(e
1
,x.y)
FORMAL = DC(e
2
,x,y)
]
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
Figure 1: Spatial Event Structure
tested and evaluated.
4 Spatio-temporal Annotation
Throughout the development of the classification
described here, we have tried to focus on how
the classification will impact the task of annotat-
ing spatio-temporal information in text. There are
currently two distinct annotation schemes for spa-
tial and temporal information. If we are to suc-
cessfully capture motion phenomena in text, these
annotations must be merged just as a topological
base and a temporal calculus need to be combined
to model motion predicates.
TimeML (Pustejovsky et al, 2003) is an anno-
tation scheme for representing temporal informa-
tion in text. The basic elements of a TimeML an-
notation are temporal expressions such as dates,
times, and durations, and events that can be an-
chored or ordered to those expressions or with re-
spect to each other.
For the annotation of spatial information, Spa-
tialML (MITRE, 2007) is being developed. The
focus of SpatialML is the markup of spatial lo-
cations that can be integrated with additional re-
sources such as databases that provide informa-
tion about a given domain (e.g. physical feature
databases, gazetteers).
While SpatialML does a reasonable job of cap-
turing locations in space, it cannot model moving
objects such as people and cars, and in fact lacks a
mechanism for capturing motion since predicates
are not annotated. As we saw above, the motion
event must be captured in addition to the locations
involved in the motion. The development of our
motion classification also reveals that the partici-
pants of the event are also needed, even if they are
not spatial locations. For example, in John flew to
Boston, John must be included in the motion anno-
tation because he is a moving object.
We can enhance the spatio-temporal informa-
tion from SpatialML and TimeML with lexical se-
mantic information from a lexicon of motion pred-
icates, resulting in annotation that is rich enough
to be able to (1) infer motion of individuals in-
vovled in specific events; and (2) to compose mo-
tions to create motion sequences (cf. (Pustejovsky
and Verhagen, 2007)).
To create a spatio-temporal markup, TimeML
and SpatialML must be enriched so that they can
adequately capture the motion predicates we are
discussing. TimeML will already annotate motion
predicates as events, but to truly reveal the motion
involved, additional attributes must be added to ac-
count for the beginning, middle, and end points of
the event. The spatio-temporal annotation will re-
quire a new kind of spatial link to capture motion
paths. Essentially, the motion path will combine
the event information from TimeML with the spa-
tial information from SpatialML. This motion path
is at the core of a spatio-temporal markup or STM.
The spatial event structure described in the previ-
ous section motivates the construction of the STM.
The concept of polarity or headedness will also
motivate some aspects of the annotation. Depend-
ing on the polarity of the motion predicate or spa-
tial prepositional phrase, the annotator will know
to look for the source or goal of the event in the
text and include that in the motion path.
The exact details of the resulting spatio-
temporal markup are still under development.
However, the following examples give an idea of
how motion class information allow us to integrate
spatial and temporal annotation.
(2) John drove from Boston to NY on Thursday.
<MOVER id=0>John</MOVER>
<EVENT id=1 tense=past start=t1 end=t2>drove</EVENT>
<SIGNAL id=2 type=spatial polarity=initial>from</SIGNAL>
<PLACE id=3>Boston</PLACE>
<SIGNAL id=4 type=spatial polarity=final>to</SIGNAL>
<PLACE id=5>New York</PLACE>
<SIGNAL id=6 type=temporal>on</SIGNAL>
<TIMEX3 id=7>Thursday</TIMEX3>
<TLINK eventID=1 timeID=7 relType=INCLUDES
signalID=6 />
<MOTION eventID=1 moverID=0 source=3
sourceTime=t1 sourceSignal=2 goal=5
goalTime=t2 goalSignal=4 class=MOVE/>
(3) John left Boston for New York.
<MOVER id=0>John</MOVER>
<EVENT id=1 tense=past start=t1 end=t2
polarity=intitial>left</EVENT>
<PLACE id=2>Boston</PLACE>
<SIGNAL id=3 type=spatial
polarity=final>for</SIGNAL>
<PLACE id=4>New York</PLACE>
<MOTION eventID=1 moverID=0 source=2 sourceTime=t1
goal=4 goalTime=t2 goalSignal=3 class=LEAVE/>
97
The Motion tag in the above examples tells us
the class of the motion predicate. This provides a
link to both the spatial event structure (as in Figure
1) and a spatio-temporal markup, which embeds
the annotaton of a text as RCC8 relations in a mod-
ified SpatialML/TimeML format. The example in
4 shows the STM for leave:
(4)
?
?
?
?
?
?
?
?
?
?
motion
TYPE = leave
EVENTID = e
MOVERID = x
SOURCE = l
1
SOURCETIME = t
1
GOAL = l
2
GOALTIME = t
2
?
?
?
?
?
?
?
?
?
?
=?
[
IN(t
1
, x, l
1
)
IN(t
2
, x, l
2
)
DC(t
2
, x, l
1
)
]
This STM indicates what additional information
is needed for the spatio-temporal annotation. In
the case of example 3, three temporally anchored
SpatialML link tags are indiated for each of the
RCC8-like relations to the second part of the STM:
(5) <LINK linkType=IN source=0 target=2 time=t1/>
<LINK linkType=DC source=0 target=2 time=t2/>
<LINK linkType=IN source=0 target=4 time=t2/>
These links that can be automatically generated
at a later stage in the annotation set up the locations
of moving objects at given times. The first link in
example 5 reveals that the moving object John was
in Boston at time t1, which is the start time of the
motion given in the annotation.
5 Conclusion
In this paper, we investigate how an expressive
classification for verbs of motion can be used to
integrate spatial and temporal annotation infor-
mation, in order to represent objects in motion,
as expressed in text. We adopt a modified ver-
sion of the classifications of verbs of motion in
(Muller, 1998) and (Asher and Sablayrolles, 1995)
and demonstrated how verb classes are mapped to
RCC8+1 relations in a temporally anchored Spa-
tialML. We are currently evaluating the reliability
of the FrameNet encoding of motion predicates,
and are developing algorithms for translating lexi-
cal structures to Spatio-temporal markup.
References
Asher, N. and P. Sablayrolles. 1995. A typology and
discourse for motion verbs and spatial pps in french.
Journal of Semantics, 12:163?209.
Baker, C., C. Fillmore, and J. Lowe. 1998. The berke-
ley framennet project. In Proceedings of the COL-
ING ACL, Montreal, Canada.
Boas, H. 2001. Frame semantics as a framework for
describing polysemy and syntactic structures of en-
glish and german motion verbs in contrastive com-
putational lexicography. Rayson, P., A. Wilson, T.
McEnery, A. Hardie, and S. Khoja, eds., Corpus lin-
guistics 2001 , vol.13, Lancaster, UK.
Cappelle, B. and R. Declerck. 2005. Spatial and tem-
poral boundedness in english motion events. Journal
of Pragmatics, 37(6):889?917, June.
Galton, A. 1993. Towards an integrated logic of space,
time, and motion. IJCAI.
Galton, A. 1997. Space, time, and movement. Stock,
O., ed., Spatial and temporal reasoning. Kluwer.
Herskovits, A. 1986. Language and Spatial Cogni-
tion: an Interdisci- plinary Study of the Prepositions
in English. Cambridge University Press.
Jackendoff, R. 1983. Semantics and Cognition. MIT.
Kipper, K., A. Korhonen, N. Ryant, and M. Palmer.
2006. Extensive classifications of english verbs. In
12th EURALEX, Turin, Italy.
Mani, I., J. Hitzeman, and C. Clark. 2008. Annotating
natural language geographic references. In Work-
shop on Methodologies and Resources for Process-
ing Spatial Language. LREC?2008.
MITRE. 2007. Spatialml: Annotation scheme for
marking spatial expressions in natural language.
http://sourceforge.net/projects/spatialml/.
Muller, P.. 1998. A qualitative theory of motion
based on spatio-temporal primitives. Cohn, A., L.
Schubert, and S. Shapiro, eds., KR?98: Principles
of Knowledge Representation and Reasoning, pages
131?141. Morgan Kaufmann.
Muller, P. 2002. Topological spatio-temporal reason-
ing and representation. Computational Intelligence,
18(3):420?450.
Pustejovsky, J. and M. Verhagen. 2007. Inferring
spatio-temporal trajectories of entities from natural
language documents. Tech. report, Brandeis U.
Pustejovsky, J., J. Casta?no, R. Ingria, R. Saur??, R.
Gaizauskas, A. Setzer, and G. Katz. 2003. Timeml:
Robust specification of event and temporal expres-
sions in text. In IWCS-5, Fifth International Work-
shop on Computational Semantics.
Pustejovsky, J. 1995. The Generative Lexicon. MIT.
Randell, D. A., Z. Cui, and A. G. Cohn. 1992. A spatial
logic based on regions and connections. Kaufmann,
M., ed., 3rd International Conference on Knowledge
Representation and Reasoning.
Vieu, L. 1991. S?emantique des relations spatiales
et inf?erences spatio-temporelles: une contribution `a
l??etude des structures formelles de l?espace en lan-
gage naturel. Ph.D. thesis, Universit?e Paul Sabatier.
98
