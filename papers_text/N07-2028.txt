Proceedings of NAACL HLT 2007, Companion Volume, pages 109?112,
Rochester, NY, April 2007. c?2007 Association for Computational Linguistics
Efficient Computation of Entropy Gradient for
Semi-Supervised Conditional Random Fields
Gideon S. Mann and Andrew McCallum
Department of Computer Science
University of Massachusetts
Amherst, MA 01003
gideon.mann@gmail.com , mccallum@cs.umass.edu
Abstract
Entropy regularization is a straightforward
and successful method of semi-supervised
learning that augments the traditional con-
ditional likelihood objective function with
an additional term that aims to minimize
the predicted label entropy on unlabeled
data. It has previously been demonstrated
to provide positive results in linear-chain
CRFs, but the published method for cal-
culating the entropy gradient requires sig-
nificantly more computation than super-
vised CRF training. This paper presents
a new derivation and dynamic program
for calculating the entropy gradient that
is significantly more efficient?having the
same asymptotic time complexity as su-
pervised CRF training. We also present
efficient generalizations of this method
for calculating the label entropy of all
sub-sequences, which is useful for active
learning, among other applications.
1 Introduction
Semi-supervised learning is of growing importance
in machine learning and NLP (Zhu, 2005). Condi-
tional random fields (CRFs) (Lafferty et al, 2001)
are an appealing target for semi-supervised learning
because they achieve state-of-the-art performance
across a broad spectrum of sequence labeling tasks,
and yet, like many other machine learning methods,
training them by supervised learning typically re-
quires large annotated data sets.
Entropy regularization (ER) is a method of semi-
supervised learning first proposed for classification
tasks (Grandvalet and Bengio, 2004). In addition to
maximizing conditional likelihood of the available
labels, ER also aims to minimize the entropy of the
predicted label distribution on unlabeled data. By in-
sisting on peaked, confident predictions, ER guides
the decision boundary away from dense regions of
input space. It is simple and compelling?no pre-
clustering, no ?auxiliary functions,? tuning of only
one meta-parameter and it is discriminative.
Jiao et al (2006) apply this method to linear-
chain CRFs and demonstrate encouraging accuracy
improvements on a gene-name-tagging task. How-
ever, the method they present for calculating the
gradient of the entropy takes substantially greater
time than the traditional supervised-only gradient.
Whereas supervised training requires only classic
forward/backward, taking time O(ns2) (sequence
length times the square of the number of labels),
their training method takes O(n2s3)?a factor of
O(ns) more. This greatly reduces the practicality
of using large amounts of unlabeled data, which is
exactly the desired use-case.
This paper presents a new, more efficient entropy
gradient derivation and dynamic program that has
the same asymptotic time complexity as the gradient
for traditional CRF training, O(ns2). In order to de-
scribe this calculation, the paper introduces the con-
cept of subsequence constrained entropy?the en-
tropy of a CRF for an observed data sequence when
part of the label sequence is fixed. These meth-
ods will allow training on larger unannotated data
set sizes than previously possible and support active
109
learning.
2 Semi-Supervised CRF Training
Lafferty et al (2001) present linear-chain CRFs, a
discriminative probabilistic model over observation
sequences x and label sequences Y = ?Y1..Yn?,
where |x| = |Y | = n, and each label Yi has s differ-
ent possible discrete values. For a linear-chain CRF
of Markov order one:
p?(Y |x) =
1
Z(x)
exp
(
?
k
?kFk(x, Y )
)
,
where Fk(x, Y ) =
?
i fk(x, Yi, Yi+1, i),
and the partition function Z(x) =
?
Y exp(
?
k ?kFk(x, Y )). Given training
data D = ?d1..dn?, the model is trained by
maximizing the log-likelihood of the data
L(?;D) =
?
d log p?(Y
(d)|x(d)) by gradient
methods (e.g. Limited Memory BFGS), where the
gradient of the likelihood is:
?
??k
L(?;D) =
?
d
Fk(x
(d), Y (d))
?
?
d
?
Y
p?(Y |x
(d))Fk(x
(d), Y ).
The second term (the expected counts of the features
given the model) can be computed in a tractable
amount of time, since according to the Markov as-
sumption, the feature expectations can be rewritten:
?
Y
p?(Y |x)Fk(x, Y ) =
?
i
?
Yi,Yi+1
p?(Yi, Yi+1|x)fk(x, Yi, Yi+1).
A dynamic program (the forward/backward algo-
rithm) then computes in time O(ns2) all the needed
probabilities p?(Yi, Yi+1), where n is the sequence
length, and s is the number of labels.
For semi-supervised training by entropy regular-
ization, we change the objective function by adding
the negative entropy of the unannotated data U =
?u1..un?. (Here Gaussian prior is also shown.)
L(?;D,U) =
?
n
log p?(Y
(d)|x(d)) ?
?
k
?k
2?2
+ ?
?
u
p?(Y
(u)|x(u)) log p?(Y
(u)|x(u)).
This negative entropy term increases as the decision
boundary is moved into sparsely-populated regions
of input space.
3 An Efficient Form of the Entropy
Gradient
In order to maximize the above objective function,
the gradient for the entropy term must be computed.
Jiao et al (2006) perform this computation by:
?
??
? H(Y |x) = covp?(Y |x)[F (x, Y )]?,
where
covp?(Y |x)[Fj(x, Y ), Fk(x, Y )] =
Ep?(Y |x)[Fj(x, Y ), Fk(x, Y )]
? Ep?(Y |x)[Fj(x, Y )]Ep?(Y |x)[Fk(x, Y )].
While the second term of the covariance is easy
to compute, the first term requires calculation of
quadratic feature expectations. The algorithm they
propose to compute this term is O(n2s3) as it re-
quires an extra nested loop in forward/backward.
However, the above form of the gradient is not
the only possibility. We present here an alternative
derivation of the gradient:
?
??k
?H(Y |x) =
?
??k
X
Y
p?(Y |x) log p?(Y |x)
=
X
Y
?
?
??k
p?(Y |x)
?
log p?(Y |x)
+ p?(Y |x)
?
?
??k
log p?(Y |x)
?
=
X
Y
p?(Y |x) log p?(Y |x)
?
 
Fk(x, Y ) ?
X
Y ?
p?(Y
?|x)Fk(x, Y
?)
!
+
X
Y
p?(Y |x)
 
Fk(x, Y ) ?
X
Y ?
p?(Y
?|x)Fk(x, Y
?)
!
.
Since
?
Y p?(Y |x)
?
Y ? p?(Y
?|X)Fk(x, Y ?) =?
Y ? p?(Y
?|X)Fk(x, Y ?), the second summand can-
cels, leaving:
?
??
?H(Y |x) =
X
Y
p?(Y |x) log p?(Y |x)Fk(x, Y )
?
 
X
Y
p?(Y |x) log p?(Y |x)
! 
X
Y ?
p?(Y
?|x)Fk(x, Y
?)
!
.
Like the gradient obtained by Jiao et al (2006),
there are two terms, and the second is easily com-
putable given the feature expectations obtained by
110
forward/backward and the entropy for the sequence.
However, unlike the previous method, here the first
term can be efficiently calculated as well. First,
the term must be further factored into a form more
amenable to analysis:
?
Y
p?(Y |x) log p?(Y |x)Fk(x, Y )
=
?
Y
p?(Y |x) log p?(Y |x)
?
i
fk(x, Yi, Yi+1, i)
=
?
i
?
Yi,Yi+1
fk(x, Yi, Yi+1, i)
?
Y?(i..i+1)
p?(Y |x) log p?(Y |x).
Here, Y?(i..i+1) = ?Y1..(i?1)Y(i+2)..n?. In order
to efficiently calculate this term, it is sufficient
to calculate
?
Y?(i..i+1)
p?(Y |x) log p?(Y |x) for all
pairs yi, yi+1. The next section presents a dynamic
program which can perform these computations in
O(ns2).
4 Subsequence Constrained Entropy
We define subsequence constrained entropy as
H?(Y?(a..b)|ya..b, x) =
?
Y?(a..b)
p?(Y |x) log p?(Y |x).
The key to the efficient calculation for all subsets
is to note that the entropy can be factored given a
linear-chain CRF of Markov order 1, since Yi+2 is
independent of Yi given Yi+1.
?
Y?(a..b)
p?(Y?(a..b), ya..b|x) log p?(Y?(a..b), ya..b|x)
=
?
Y?(a..b)
p?(ya..b|x)p?(Y?(a..b)|ya..b, x)?
(
log p?(ya..b|x) + log p?(Y?(a..b)|ya..b, x)
)
=p?(ya..b|x) log p?(ya..b|x)
+ p?(ya..b|x)H
?(Y?(a..b)|ya..b, x)
=p?(ya..b|x) log p?(ya..b|x)
+ p?(ya..b|x)H
?(Y1..(a?1)|ya, x)
+ p?(ya..b|x)H
?(Y(b+1)..n|yb, x).
Given the H?(?) and H?(?) lattices, any sequence
entropy can be computed in constant time. Figure 1
H (0|y6)H (Y6|y5)H (0|y1) H (Y1|y2)
y4
y3
? ? ? ?
Figure 1: Partial lattice shown for com-
puting the subsequence constrained entropy:P
Y p(Y?(3..4), y3, y4) log p(Y?(3..4), y3, y4). Once the
complete H? and H? lattices are constructed (in the direction
of the arrows), the entropy for each label sequence can be
computed in linear time.
illustrates an example in which the constrained se-
quence is of size two, but the method applies to
arbitrary-length contiguous label sequences.
Computing the H?(?) and H?(?) lattices is easily
performed using the probabilities obtained by for-
ward/backward. First recall the decomposition for-
mulas for entropy:
H(X,Y ) = H(X) + H(Y |X)
H(Y |X) =
?
x
P (X = x)H(Y |X = x).
Using this decomposition, we can define a dynamic
program over the entropy lattices similar to for-
ward/backward:
H?(Y1..i|yi+1, x)
=H(Yi|yi+1, x) + H(Y1..(i?1)|Yi, yi+1, x)
=
?
yi
p?(yi|yi+1, x) log p?(yi|yi+1, x)
+
?
yi
p?(yi|yi+1, x)H
?(Y1..(i?1)|yi).
The base case for the dynamic program is
H?(?|y1) = p(y1) log p(y1). The backward entropy
is computed in a similar fashion. The conditional
probabilities p?(yi|yi?1, x) in each of these dynamic
programs are available by marginalizing over the
per-transition marginal probabilities obtained from
forward/backward.
The computational complexity of this calcula-
tion for one label sequence requires one run of for-
ward/backward at O(ns2), and equivalent time to
111
calculate the lattices for H? and H? . To calculate
the gradient requires one final iteration over all label
pairs at each position, which is again time O(ns2),
but no greater, as forward/backward and the en-
tropy calculations need only to be done once. The
complete asymptotic computational cost of calcu-
lating the entropy gradient is O(ns2), which is the
same time as supervised training, and a factor of
O(ns) faster than the method proposed by Jiao et
al. (2006).
Wall clock timing experiments show that this
method takes approximately 1.5 times as long as
traditional supervised training?less than the con-
stant factors would suggest.1 In practice, since the
three extra dynamic programs do not require re-
calculation of the dot-product between parameters
and input features (typically the most expensive part
of inference), they are significantly faster than cal-
culating the original forward/backward lattice.
5 Confidence Estimation
In addition to its merits for computing the entropy
gradient, subsequence constrained entropy has other
uses, including confidence estimation. Kim et al
(2006) propose using entropy as a confidence esti-
mator in active learning in CRFs, where examples
with the most uncertainty are selected for presenta-
tion to humans labelers. In practice, they approxi-
mate the entropy of the labels given the N-best la-
bels. Not only could our method quickly and ex-
actly compute the true entropy, but it could also be
used to find the subsequence that has the highest un-
certainty, which could further reduce the additional
human tagging effort.
6 Related Work
Hernando et al (2005) present a dynamic program
for calculating the entropy of a HMM, which has
some loose similarities to the forward pass of the
algorithm proposed in this paper. Notably, our algo-
rithm allows for efficient calculation of entropy for
any label subsequence.
Semi-supervised learning has been used in many
models, predominantly for classification, as opposed
to structured output models like CRFs. Zhu (2005)
1Reporting experimental results with accuracy is unneces-
sary since we duplicate the training method of Jiao et al (2006).
provides a comprehensive survey of popular semi-
supervised learning techniques.
7 Conclusion
This paper presents two algorithmic advances. First,
it introduces an efficient method for calculating
subsequence constrained entropies in linear-chain
CRFs, (useful for active learning). Second, it
demonstrates how these subsequence constrained
entropies can be used to efficiently calculate the
gradient of the CRF entropy in time O(ns2)?
the same asymptotic time complexity as the for-
ward/backward algorithm, and a O(ns) improve-
ment over previous algorithms?enabling the prac-
tical application of CRF entropy regularization to
large unlabeled data sets.
Acknowledgements
This work was supported in part by DoD contract #HM1582-
06-1-2013, in part by The Central Intelligence Agency, the Na-
tional Security Agency and National Science Foundation under
NSF grant #IIS-0427594, and in part by the Defense Advanced
Research Projects Agency (DARPA), through the Department
of the Interior, NBC, Acquisition Services Division, under con-
tract number NBCHD030010. Any opinions, findings and con-
clusions or recommendations expressed in this material belong
to the author(s) and do not necessarily reflect those of the spon-
sor.
References
Y. Grandvalet and Y. Bengio. 2004. Semi-supervised learning
by entropy minimization. In NIPS.
D. Hernando, V. Crespi, and G. Cybenko. 2005. Efficient com-
putation of the hidden markov model entropy for a given
observation sequence. IEEE Trans. on Information Theory,
51:7:2681?2685.
F. Jiao, S. Wang, C.-H. Lee, R. Greiner, and D. Schuur-
mans. 2006. Semi-supervised conditional random fields
for improved sequence segmentation and labeling. In COL-
ING/ACL.
S. Kim, Y. Song, K. Kim, J.-W. Cha, and G. G. Lee. 2006.
Mmr-based active machine learning for bio named entity
recognition. In HLT/NAACL.
J. Lafferty, A. McCallum, and F. Pereira. 2001. Conditional
random fields: Probabilistic models for segmenting and la-
beling sequence data. In Proceedings of ICML, pages 282?
289.
X. Zhu. 2005. Semi-supervised learning literature survey.
Technical Report 1530, Computer Sciences, University of
Wisconsin-Madison.
112
