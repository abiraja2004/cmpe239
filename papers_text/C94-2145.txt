ON TIIE PORTABILITY OF COMPLEX CONSTRAINT-BASED 
GRAMMARS 
C.J. Rupp* and Rod Johnson 
Formerly of IDS\[A, Corso Elvezia 36, C11900 Lugano 
1 Int roduct ion  
\]{.ec('.nt years have seen tile appearance of' a number of 
grammar  f'ormalisms 1 sharing a strong family resem- 
blance, which we have characterised elsewhere \[R,upp 
et al, 199d\] as tim property of being constraint-based. 
As well as having in common many formal proper- 
ties, these formalisms also support,  often by explicit 
de.sign, descriptions from a similarly convergent range 
o\[' l inguistic theories, which we might reasonably label 
"\[ lPSG-l ike". 
Given the considerable common ground between 
such formalisms, it is reasonable to begin to ~sk ques- 
tions about their intertranslatal)i l ity, or, ht program- 
nling language terms, the relative ease with which it 
is possible to "port" a grammar  from one such formal- 
isnl to another. Such questious are clearly of interest 
\['or tile enterprise of recovering a.s much as possible of 
the existing stock of already encoded linguistic knowl- 
edge, perhaps for reuse in a more modern theoretical 
\['ramework. They are also of relevance for any attempts  
to build in portabi l i ty from the start  in ongoing new 
grammar  writing. 
At present, the criteria for determining whether a 
particular translat ion is successful are extremely fuzzy. 
Apart from anything else, they will presumably de- 
pend to some extent on external goals, such as, for 
example, whether the results will be used in a prac- 
tical, rnnning system or just in a laboratory experi- 
ment  to show the feasibility of a particular theoretical 
approach. In our work, we have. a.ssulned that,  if the 
translation is intended ,as more than a sterile exercise, 
then the information in the source description must be 
worth conserving and hence worth translating. More- 
over, we suppose that the resulting target gramInar 
will need to be mainta ined and extendcd, and hence 
should be wel l -understood and well-behaved. Given 
these assumptions,  we can begin to impose some con- 
ditions on what constitutes a "good" translation; in 
effect, in a translat ion from grammar  A to grammar  
B: 
*Currently affiliated to the Institute for Computational 
IAnguistics, University of Stuttgart, Azenbergstr.12, 70174 
Stuttgart, Germany, cj(~ims.mfi-stuttgart.dc 
) In the interests of brevity, we shall often use the term gram- 
mar to refer to the collection of formal devices which comprise 
all aspects of a linguistic description, encomn&sslng both gram- 
maticM and lexical inforrn,~tion. This is purely a notational con- 
venience and in no way implies a commitment to the primacy 
of syntax. 
? B and A should have the same input-output be- 
haviour. 
? B should conserve as much as possible of the con- 
ceptual shape of A. 
? B should have comparable or better run-t ime per- 
formance with respect to A. 
The first condition is a consequence, if somewhat  
oversimplified, of tile assumptions we made above, 
that  the main purpose of the exercise is to preserve 
usefltl information. 
The second condit ion h~Ls to do with the relative 
expressivity of tile two formalisms involved. In ef- 
fect, tLow much of the conceptual and organisatioual 
structure of a linguistic description can pass over un-. 
changed, and to what extent do conceptual changes 
that may have to be made obscure our subsequent un- 
derstanding of the description as a whole? 
The question of performance is not l imited to the 
relative execution speed of source and target gram- 
mars, though its importance for subsequent mainte- 
nance and development cannot be overstated, l low do 
we approach the case, for example, where the source 
grammar  uns normally in its native environment but 
the translated form fails to terminate unless the de- 
scription is completely restructured? And what if the 
two systems use conflicting criteria for the apport ion- 
ment  of procedural control between the linguist and 
the implementat ion? 
Over the past year, we have been engaged on a nun> 
bet of experiments designed to investigate these porta- 
bility issues, and in particular to bring out the impli- 
cations behind the two related sets of questions about 
expressivity and performance. In some ways, our work 
is similar in spirit to the reusabil ity experiments re- 
ported in \[Arnold el al., 1993\], though these appear 
to have been l imited to translation to a single, rather 
general formalism, and to have been concerned ahnost 
entirely with questions of relative expressivity. 
The remainder of this paper discusses our own ex- 
perinrents and comlnents ou some of our more impor- 
tant findings so far. 
.900 
i 'rl 's I 
t c/31," I 
\[al,U A 
Type 
ltierarchy 
I i~xplici~ l)edicated 
l'ars~r ~_ Morphology 
yes  llO IlO 
yes _y(~ _~ yes 
(Jontol Lazy Host 
l)etermiued Evaluation Language 
globally 
globally 
locally 
locally 
yes  
yes 
yes 
no 
Common Lisp 
Common Lisp 
l'rolog 
Prolog 
Table 1: A checklist of tile signiticant properties of the sample implementations 
2 Formalisms 
In our experiments to explore the portability of com- 
plex constraint-ba.qed grammars we have considered a
sample of four imt)lemented formalisms: 
. UI) (Unillcation Device) \[Johnson and l{.osner, 
1989, lt.upp cl ql., 1992\] 2 .
? "FFS (Typed l"eature Structures) \[l,hnele and Za- 
jac, 1990\]. 
? CUI" (Comprehensive Unification i"ormalism) 
\[l)i;rre and l';isele, 199l, l)grre and l)orna, 1993\] 
? ALE (Al, tribnte l,ogic Engine) \[Carpenter, 195)2\] 
The original reason for selecting this sample was 
practical: the availability of these systems in tile put)lie 
domain at; the alqu'opriate time3; but on filrther reflec- 
tion this sample turns ()tit to be quite representative of 
the major differences which may occur in formalisms 
of this type (cf the very coarse-grained ela.ssilieation i
Tal)\[e 1)4 The consequences of these distinctions are 
explored ira more detail below. 
The nal, ure of experinmnts in portability requires 
nol, otdy tim selection of source and target tbrmalisms, 
but also of exatnl)le descriptions to be translat.ed. In 
this respect we opted for taking grammars "fronl the 
wild", i.e. native, code from one of the sample for  
malis,ns that was not designed with ally prior consid- 
eration of its potential portal)ility. To be more precise, 
we have worked with a small, lint formally represen- 
(.alive IIPSG grammar, originally provided as sample 
data with the TI"S system, and a somewhat larger and 
quite intricate gl) grammar of French, which touches 
on such thorny issues ;us clitic placement and object 
agreement. 'Fhe init, ial experiments were iu translat- 
ing the TFS grammar into (Jl), and then subsequently 
inl, o the other two formalisms. Our attempts to trails-- 
late the ul) French gramtnar into ALl", were Ilot quite 
as successful, as a substantive alteration to tit(', struco 
lure of the syntactic analysis proved necessary, The 
situation with CUF is more. promising, even though 
the delinition of an explicit parsing strategy within 
the formalism was required. 'fires(: two issues are dis-- 
cussed further in Section 4. 
2\[,'or the purposes of this paper  wc see no signif icant dif- 
ferences bel, wecn UD and its derivatiw~" El ,U, ,uee e.g. \[lgstival., 
19510\]. 
awe did toy with the idea of ent i t l ing this paper :  "OIi' the 
OUI," reread'ks on how much AI,I'; I J I) need to make  sense of ~L 
TIeS grmnmar" ,  but  thought  bet ter  of it. 
4See also \[l{upp, 1992, Johnson and l{upp, 1993\] 
3 Expressivity 
The underlying assumption that; is crncial to the na- 
ture of this work is that these formalisms have highly 
comparable expressivity, i.e. they share more than sel> 
arates them. This is central to the success of the en- 
terprise since preservation of concepts defined by the 
linguist is an essential part of grammar translation. 
Consequently, we are I)articularly concerned here with 
the main constructs of a linguistic description: types, 
relations and lists. We also consider, though to a lesser 
exl,el,t, purely notational devices like lnacros, which 
can be useful in organising the conceptual structure of 
a description. Of lesser importance in the present con- 
text. is the treatment of logical structure, in particular 
disjunction; iu any case, this topic has received a good 
deal of attention elsewhere (cf \[Trost, 1993\]). 
3.1 Types 
'Fhc role of f~at, ure structure types in constraint- 
based linguistics t1~ gained increasing importance 
as a result of the increa~slng popularity, some might 
s~y donlinance, of IIPSG \[Pollard and Sag, 1987, 
Pollard and Sag, forthcoming\]. In HPSG the type sys- 
tem, or type signature, plays a signitlcant role in deiln- 
ing the (:lass of legal linguistic objects. In fact in the 
current version of the theory only objects wlmse typ- 
ing information is fldly resolved are considered to be 
adequate models of naturally occurring linguistic con- 
structs. Each of the formalisms we consider permits 
the delinition of feature structure types, but the form 
and expressivity of these type definitions differ quite 
considerably, a~s does the significance of type defini-. 
tions in the description a.s a whole. The extreme cases 
are TFS, in which the type system is virtually all there 
is, and ol), where type dellnitions imply constrain the 
attributes which can occur on a feature structure. 
At this point we should note that a type system in 
the "true" or IIPSG sense, requires a notion of type 
inheritance which can be further subdivided into three 
COllCeDt8: 
? subtype/supertype relations 
? feature appropriateness conditions 
? closure conditions 
Type detinitions which form a type system usually en- 
code immediate subtypes and feature appropriateness 
conditions, which specify, at le~Lst, ire attributes which 
901 
head = subst  I funct, head(X):  !subst (X)  
subst = noun I verb I adj I prep. 
subst\[PKD:boolean\]. 
noun \[CASE: case\] . 
verb\[VFOKM:vform, 
AUX: boolean, 
INV: boolean\]. 
Figure h A fragmentary type system rootcd in head 
and written in TFS 
are licensed by the type and the types of their values, 
as in Figure 1. Closure is usually a derived notion, 
in that only attributes licensed by the type or one of 
its supertypes may occur, an unlicensed attr ibute in- 
curring either further subtyping or inconsistency. UD 
type definitions cannot of themselves be used to define 
a hierarchical type system. They give an entirely fiat 
system with the most absolute closure and the most 
minimal appropriateness conditions. The type defini- 
tions of the other formalisms, TFS, CUF and ALE, dif- 
fer mainly in the expressivity of their appropriateness 
conditions, in order of decremsing expressivity, cf \[Man- 
andhar, 1993\] for a more detailed comparison of these 
type systems. 
Evidently, one of the most basic hurdles to translat- 
ing any of the other formMisms into UD is the recon- 
struction of the type system. This was the problem 
posed in our initial experiment of porting an IIPSG 
grammar encoded in TFS into up. Our solution to 
this problem, cf Figure 2, consists of separating out the 
hierarchies of sub- and supertype dependencies from 
those of feature appropriateness, so that each node 
in the type hierarchy is represented by two unary ab- 
straction definitions in the UP encoding. UD types ~ are 
only utilised on the terminal nodes of the type hierar- 
chy to ensure ult imate closure. In principle the use of 
any pseudo-type definition will work its way down the 
dependency hierarchy to the terminal node and then 
back up the appropriateness hierarchy to gain more in- 
formation. While this sounds dreadfully inefficient he 
lazy evaluation strategy adopted in UD in fact avoids 
most of the computational overhead. 
3 .2  Re la t ions  
The other main constructs used for expressing linguis- 
tic concepts are relations - or more specifically def- 
inite relations since most of these formalisnls are in 
fact instantiations of the tIShfeld and Smolka notion 
of a Constraint Logic Programming language \[tI6hfcld 
and Smolka, 1988\]. While the same essential notion oc- 
curs in all thcse formalisms the terminology is quite 
5Type a~ssignmcnts i  UD have the form: Variable == type, 
head(X): !funct(X) 
subst(X): !noun(X) 
subst (X) :  !verb(X) 
subst(X): !adj(X) 
subst (X) :  !prep(X) 
Subst(X) :  <X prd> = yes /no  
noun(X) X == noun 
!Subst(X) 
!case(<X case>) 
verb(X) X = =  verb 
!Subst(X) 
<X aux> = yes/no 
<X inv> = yes/no 
!vform(<X Worm>)  
Figure 2: The head system rewritten in UD 
diverse, including, for instance, relational abstractions 
(UD) and parametric sorts (CUF). In fact in TFS rela- 
tional constructs actually take the form of types with 
features expressing their argument structure, although 
a relational notation is provided to sweeten the syn- 
tax slightly. Since definite relations occur in each of the 
formalisms, their translation does not pose any imme- 
diate problems, and many of their usages are the same, 
e.g. accounting for relational dependencies and princi- 
ples in l lPSG-style grammars, cf Figure 3. Difficulties 
do however occur where the usage of relational con- 
structs is restricted. ALE imposes the restriction that 
true definite relations may only be used in the phrasal 
domain, attached to phrase structure rules. On first 
impression, this could pose a serious problem for trans- 
lations from other formalisms where relations may be 
used freely in the lexicon. Our experience has shown 
that many such lexical relations can in fact be en- 
coded using ALE macros, as in Figure 4, which may 
be parameterised, but require a deterministic expan- 
sion. Where operations involving reeursive or disjunc- 
tive relations are required there is still the option of 
encoding the construct as a lexical rule, though with 
the risk of losing some of the conceptual structure. 
hfp(synsem: loc: cat: head: Head) := 
synsem: loc: cat: head: Head. 
Figure 3: A CUF encoding of a Head Feature Principle. 
as a unary parametric sort 
902 
r ip(Case) macro 
~nominal(Case), 
@saturated ,  
~lex(false). 
Figure 4: An ALI'\] macro definition 
3.3  Lists 
The last cbuss of constructs that we consider in detail 
arc' lists, or sequences. Our objective here is slightly 
different than in the last two c~mes, since all the for- 
malisms upport lists and most even supply the same, 
Prolog-style, notation. There is however a more sub- 
tie difference between uB and the more strongly typed 
forrnalisms, since in all the other formalisms the list 
notation is purely syntactic and masks a typed feature 
structure that is either atomic or has two attributes. 
\[n UP where lists are "real" objects, the nnitier is 
more explicitly polynlorl)hie , \])lit also admits tin; pro- 
vision of built-in functions over sequence data-types, 
whose computational behaviour is more predictable 
than that of defined constructs like relations. Ul) pro- 
rides both append and member (or perhaps better "ex-- 
tract") over lists and since strings are also a fldl 
data type concal, enation over strings. The elfects 
on perlornrance of hard-coding frequenl,ly used con 
struets can be quite dramatic. We do not pursue this 
question here since the tmsociated esign issues are 
COml)atral)le with those associated with the decision to 
incorporate dedicated modnles which are discussed ill 
the next section. 
4 Per fo rmance  
The second class of issues which affect the porting of a 
grammar frolu one forlnalisln to another is COlmeete.d 
with the relative perfornlance of the two instantia- 
tions. We consider two aspects of this topic, the provi-- 
sion of explicit modules for processing in a particular 
domaiu, such as syntactic or morllhological analysers, 
~md the complex and thorny issue of control informa- 
tion, or who gets control of control. First, though, it 
is worth emphasising wily we (:onsider performance to 
be a signilicant issue at all. We are not - yet, anyway 
particularly concerned with the real time perfor- 
mance of "end-user" allplications. Wc view all of the 
systelns that implenmnt these formalisms as develop 
ment environments, even if timy were originally devel- 
oped as "academic" protol,ypes, in several cases with 
a view to demonstrating it particular theoretical per- 
spective. Accordingly, we feel that it is more appropri- 
ate to evaluate their perfornlance with respect to the 
development loop ~ussociated with grammar writing. 
More. concretely, if either the analysis or compilation 
times exceed certain acceptable bounds (determined 
by pragmatic, external considerations like the atten- 
tion sl)an of a grammar (levelol)er or lexicographer), 
then the grammar under development should be re? 
garded as being, in a purely practical sense, no longer 
extensible. These may be rather harsh criteria, but we 
believe they reflect a more realistic sense of what these 
systems are good for% 
4.1  Dedicated  Modu les  
A further explicit distinction arises between those 
tbrmalisrns which include explicit modules for treat- 
ing either phrasal or morphological structure (UD, 
ALl';), and those which only l)rovide a theorem prover 
over linguistic constraints (TFS, CUF). In general, we 
expect that, other things being equal, a formalism 
whose implementation contains dedicated processors 
for phrase structure parsing and/or string processing 
will have better run-time performance than one which 
does not, and this is indeed borne out empirically in 
the behaviour of the systems we considered. 
The prc'senee or absence of an explicit parser also 
ha~s obvious consequences for porting experiments. If
there is a parser in the target system and not in the 
source system then seine phrase structure component 
must be supplied. This may just be a vacuous struc- 
ture or it; may he derived from existing components of 
the source description, llence we have produced three 
instantiations of the UD translatiou of the TFS-I IPSG 
gra,mnar: one inw~lving a vacuous phrase structure de- 
scription, one in which grammar rules are derived from 
the phrase structure delinitions of the TFS encoding 
and one ill which full strings are associated with a lex- 
icon of garbage tokens to awfid invoking either of UD's 
dedicated modnles lbr morphology and syntax. 
Portability in the other direction poses considerably 
greater problems, since not only must the phrase strnc- 
ture description he encoded, but some parsing strategy 
must also be detined. In translating the UD grammar 
into (J/Jl" we encoded a head coruer  parser  (cf e.g. 
\[van Noord, t994\]) directly in the CUF formalism. In 
order to obtain adequate results with this strategy it 
was necessary to make use of all the facilities offered 
for determining both global and local process control. 
This sheds a certain anionnt of doubt on the possibil- 
ity of replicating the CUI" resnlts within TFS, where 
explicit local control statements are not permitted. We 
address the more general i)roblems with the incorpo- 
ration of control information in the next section. 
While the question of translating more or less ex- 
plicit phra~se structure information is already a diificult 
one, the issue of porting morphological information is 
quite chaotic. There is even less agreement on the in.- 
formation structure of morphological regnlarities than 
there is on syntactic patterning, avd this fact is re,? 
tlected in the fact that two of tile systems we have 
been working with do not oiler any apparatus at all 
for dealing with sub-word-level phenomena. Moreover, 
the two formalisms in our sample which (to admit ex- 
plicit morphological descriptions differ so greatly ill 
6That is apart froln acquiring publication.~ (,r qualilicati(ms 
903 
the form that these components take that they are 
not directly comparable ven with each other . 
4 .2  Cont ro l  In fo rmat ion  
The final issue that wc turn to is one which is in ef- 
fect most revealing about how system developers view 
their users. In terms of our sample formalisms, we 
once again can distinguish a two-way split, which ac- 
tually cuts across all of the groupings that we have 
observed above. The crude characterisation f this dis- 
tinction is that some formalisms permit the grammar 
writer to influence the local processing strategy, either 
in the good, old-fashioned Prolog manner of ordering 
clauses, as in ALE, or by providing additional control 
information, such as delay statements in CUF. The 
other two systems eschew this kind of local tweak- 
ing of the processing strategy and rely on a global 
specification of processing behaviour. Of course, this 
apparent dichotomy is to some extent illusory. Those 
systems which retain global control usually permit the 
user to modify certain parameters of this behaviour, 
and those that permit local control information must 
also assnme a global control strategy which may bc 
less forgiving than that in an apparently more totali- 
tarian system. We have two observations in respect of 
the control strategies adopted by these systems. 
The first of these is that some form of lazy evalua- 
tion, such as that assumed as a global strategy in both 
UD and TFS, can become a requirement of a target sys- 
tem when the source system permits lazy evaluation. 
More explicitly a description may rely on a particu- 
lar evaluation strategy that cannot be emulated in the 
target system. This situation actually occurred in the 
porting of the UD French grammar to ALE. The lack of 
a lazy evaluation strategy in ALE required a change in 
the analysis of verbal structure s , so the ALE descrip- 
tion is actually different from the original UD one. In 
a very real sense the port failed, in that, even though 
in terms of the declarative formalism a compatible de- 
scription was definable, it turned out that this was not 
runnable. The class of portable descriptions between 
ALE and any of the other formalisms is therefore fur- 
ther constrained by the ALE's underlying evahlation 
strategy. 
The second point we would like to make harks 
back, in many ways, to the warnings inherent in Ka- 
plan's "procedural seduction". Kaplan \[Kaplan, 1987\] 
reports experiences with the use of ATN parsers which 
ended with both grammar writers and system devel- 
opers attempting to improve the performance of the 
same parser and effectively getting in each other's way. 
More generally, every time we think we may be mak- 
ing a smart move by some kind of local fix to the con- 
7In the case of ALE it would probably be incorrect o speak 
of a lnorphological nalyser since lexical forms are expanded at 
compile time. 
SAt the corresponding point in the CUb" translation lazy 
evaluation had to be explicitly enforced by the use of a delay 
statement 
trol strategy we also make it more difficult for a really 
smart optimising controller to do its job properly. Of 
course we have progressed considerably in the declar- 
ativity and monotonicity of our formalisms which we 
now tend to view as st)ecialiscd logics, but where we 
have not learnt so much is in our view of the kind 
of people who arc going to use the implemented sys- 
tem and what they are capable of. Where local con- 
trol information is specified in the ordering of state- 
ments in definitions, we are effectively requiring that 
the grammar writer be an accomplished logic program- 
mer. Where local control information is added to sup- 
plement an existing grammar description the implicit 
assumption is even more demanding: that there are 
individuals capable of appcudiug local control infor- 
mation to descriptions that other people have written 
--- or worse still translated - -  and of getting it right. 
Both of these approaches ult imately assume that it 
is not only possible but relatively easy to retain a de- 
tailed picture of the behaviour of a complex constraint 
solver.  
When translating to a formalism which permits lo- 
cal control from one which does not, the, issue may 
come down simply to a question of rclativc speed of 
computation, which is important enough iu itself in 
practical situations, as we have already pointed out. 
In cases where the target formalism, like ALE, requires 
local control information in order to guarantee termi- 
nation, much more is at stake. 
5 Conclusion 
We readily admit that the experiments reported here 
are still quite unscientific -- or, we would prefer to 
think, prescientific and we are still feeling our 
way towards a more rigorous approach to the ques- 
tion of comparability of implemented formalisms, even 
though the task is noticeably simplified by recent con- 
vergence of goals and methods in constraint-ba.sed 
computational linguistics. 
Nonetheless, our experience already suggests, in 
keeping with \[Arnold et al, 1993\], that from the point 
of view of relative expressivity it is possible to move 
grammars from one formalism to another, and even 
perhaps to conceive of new grammars which arc de- 
signed from the start to be portable across a range of 
related formalisms. 
As regards the set of issues which we have classed to~ 
gethcr under the heading of performance, on the other 
hand, there are still many open questions whicb need 
to be addressed before porting grammars to serious, 
extensible and maintainable applications can become 
a realistic enterprise. 
Acknowledgements 
The research reported in this paper was funded by 
the Swiss National Fund for Scientific Research, un- 
der project No. 12-32604.9l Situations and Discourse. 
904 
This work would not have been possible without the 
cooperation of the developers of the various ystems. 
We would like to t, hank Martin Emele, aochen I)5rre, 
Michael Dorna, Bob Carl)enter and Gerald Penn for 
making their systems available and for their patience 
in answering questions, even when these were either 
trivial or relatively I)izarre. Any misrepresentation of 
their work that occurs here is entirely the fault of the 
authors. We would also like to thank Mike Calcagno 
for ~sisting us in some of this work aud carrying out 
the translation ofthe TFS-tIPSG grammar into ALE. 
No thanks are due to Angelo Dalle Molle and his foun- 
dation whose antics have made completion ofthe work 
reported here more dilfieult han it need have been. 
References  
\[Arnold et al, 1993\] Doug Arnold, Toni Badia, 
Josef wm Genabith, Stella Markantonatou, Stefan 
Momma, Louisa Sadler, and Paul Schmidt. Exper- 
iments in reusability of grammatical resources. In 
Proceedings of the Sixth Conference of the European 
Chapter of the Association for Computational Lin- 
guislics, pages 12 -20, Utrecht, 1993. 
\[Carpenter, 1992\] B. Carpenter. The Attribute Logic 
Engine User's Guide. Laboratory for Con> 
putational Linguistics, Philosophy l)epartment, 
Carnegie Mellon University, Pittsburgh PA 15213, 
December 1992. 
\[Dgrre and l)orna, 1993\] J. Dgrre and M. Dorna. 
CUF - a formalism for linguistic knowledge repre- 
sentation. In J. I)5rre, editor, Computational As- 
pects of Constraint-Based Linguistic Description I, 
pages 1 22. ILI~C/l)epartment of Philosophy, Uni- 
versity of Amsterdam, 1993. DYANA-2 Deliverable 
11.1.2.A. 
\[I)6rre and 1,3isele, 1991\] J. Dgrre and A. Eisele. A 
comprehensive unification-based grammar formal- 
ism. DYANA deliverable R3.1.B, Centre for Cog- 
nitive Science, University of Edinburgh, Scotland, 
January 19!)1. 
\[Emele and Zajac, 1990\] M. Emele and R. Zajae. 
'l~yped unification grammars. In Proceedings of the 
ISth International Conference on Computational 
Linguistics, COLING 90, pages 293 298, lIelsinki, 
1990. 
\[l~,stival, 1990\] D. Estival. (Jenerat, ing french with 
a reversible uniIication grammar. In Proceedings 
of the 13th International Conference on Compu- 
tational Linguistics, COLING 90, volume 2, pages 
106-111, 1990. 
\[lIShfeld and Smolka, 1988\] M. lIghfeld and 
G. Smolka. Definite relations over constraint 
languages. LILOG-Report 53, IBM l)eutschland 
Gmbll, Stuttgart, 1988. 
\[Johnson and Rosner, 1989\] IL Johnson and 
M. Rosner. A rich environment for 
experimentation with unification grammars. In 
Proceedings of the Fourth Conference of the 
European Chapter of the Association for 
Computational Linguistics, pages 182- 189, 
Manchester, 1989. 
\[Johnson and Rupp, 1993\] R. Johnson and C. J. 
Rupp. Evaluating complex constraints iu linguistic 
tbrmalisms. In tl. 'Frost, editor, Feature 
l, brmalisms and Linguistic Ambiguity. Ellis 
llorwoood, Chiehester, 1993. 
\[Kaplan, 1987\] R. M. Kaplan. Three seductions of 
computational psyeholinguistics. In P. Whitclock, 
M. M. Wood, t1. L. Seiners, P~. Johnson, and 
P. Bennett, editors, Linguistic Theory and 
Computer Applications, pages 149-188. Academic 
Press, London, 1987. 
\[Manandhar, 1993\] Suresh Manandhar. CUF in 
context. In J. DSrre, editor, Computational 
Aspects of Constraint-Based Linguistic Description 
I, pages 43 53. ILLC/l)epartment of Philosophy, 
University of Amsterdam, 19,(t3. I)YANA-2 
Deliverable R1.2.A. 
\[Pollard and Rag, 1987\] C. Pollard and I. A. Sag. 
hfformation-Based Syntax and Semantics: Volume 
1 Fundamentals. Number 13 in CSLI Lecture 
Notes. CELl, Stanford University, 1987. 
\[Pollard and Sag, forthcoming\] C. l'ollard and I. A. 
Sag. Head-Driven Phrase Structure Grammar. 
CSLI and University of Chicago Press, Stanford 
and Chicago, forthcoming. 
\[Rupp el al., 1992\] C. J. Rupp, R.. Johnson, and 
M. l{osner. Situation schemata nd linguistic 
representation. I  M. Rosner and R,. Johnson, 
editors, Computational Linguistics and Formal 
Semantics, pages 191-221. Cambridge University 
Press, Cambridge, 1992. 
\[Rupp el al., 1994\] C. J. Rnpp, 11.. Johnson, and 
M. Rosner. Overview. In C. J. ll~upp, M. R.osner, 
and R.. Johnson, editors, Constraints, Language, 
and Computation, pages xi-xxiii. Academic Press, 
London, 1994. 
\[Rupp, 1992\] C. J. Rupp. Abstraction mechanisms in 
constraint-based linguistic formalisms. Working 
Paper 6, IDSIA, 1992. 
\[Trost, 1993\] I1. Trost. Feature Formalisms and 
Linguistic Ambiguity. Ellis Ilorwoood, Chichester, 
1993. 
\[van Noord, 1994\] G. van Noord. Head corner 
parsing. In C. J. Rupp, M. Rosner, and 
IL Johnson, editors, Constraints, Language, and 
Computation, pages 315-338. Academic Press, 
London, 1994. 
905 
