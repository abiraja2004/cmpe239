Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 302?310,
Sofia, Bulgaria, August 4-9 2013. c?2013 Association for Computational Linguistics
A Context Free TAG Variant
Ben Swanson
Brown University
Providence, RI
chonger@cs.brown.edu
Eugene Charniak
Brown University
Providence, RI
ec@cs.brown.edu
Elif Yamangil
Harvard University
Cambridge, MA
elif@eecs.harvard.edu
Stuart Shieber
Harvard University
Cambridge, MA
shieber@eecs.harvard.edu
Abstract
We propose a new variant of Tree-
Adjoining Grammar that allows adjunc-
tion of full wrapping trees but still bears
only context-free expressivity. We provide
a transformation to context-free form, and
a further reduction in probabilistic model
size through factorization and pooling of
parameters. This collapsed context-free
form is used to implement efficient gram-
mar estimation and parsing algorithms.
We perform parsing experiments the Penn
Treebank and draw comparisons to Tree-
Substitution Grammars and between dif-
ferent variations in probabilistic model de-
sign. Examination of the most probable
derivations reveals examples of the lin-
guistically relevant structure that our vari-
ant makes possible.
1 Introduction
While it is widely accepted that natural language
is not context-free, practical limitations of ex-
isting algorithms motivate Context-Free Gram-
mars (CFGs) as a good balance between model-
ing power and asymptotic performance (Charniak,
1996). In constituent-based parsing work, the pre-
vailing technique to combat this divide between
efficient models and real world data has been to
selectively strengthen the dependencies in a CFG
by increasing the grammar size through methods
such as symbol refinement (Petrov et al, 2006).
Another approach is to employ a more power-
ful grammatical formalism and devise constraints
and transformations that allow use of essential ef-
ficient algorithms such as the Inside-Outside al-
gorithm (Lari and Young, 1990) and CYK pars-
ing. Tree-Adjoining Grammar (TAG) is a natural
starting point for such methods as it is the canoni-
cal member of the mildly context-sensitive family,
falling just above CFGs in the hierarchy of for-
mal grammars. TAG has a crucial advantage over
CFGs in its ability to represent long distance in-
teractions in the face of the interposing variations
that commonly manifest in natural language (Joshi
and Schabes, 1997). Consider, for example, the
sentences
These pretzels are making me thirsty.
These pretzels are not making me thirsty.
These pretzels that I ate are making me thirsty.
Using a context-free language model with
proper phrase bracketing, the connection between
the words pretzels and thirsty must be recorded
with three separate patterns, which can lead to
poor generalizability and unreliable sparse fre-
quency estimates in probabilistic models. While
these problems can be overcome to some extent
with large amounts of data, redundant representa-
tion of patterns is particularly undesirable for sys-
tems that seek to extract coherent and concise in-
formation from text.
TAG allows a linguistically motivated treatment
of the example sentences above by generating the
last two sentences through modification of the
first, applying operations corresponding to nega-
tion and the use of a subordinate clause. Un-
fortunately, the added expressive power of TAG
comes with O(n6) time complexity for essential
algorithms on sentences of length n, as opposed to
O(n3) for the CFG (Schabes, 1990). This makes
TAG infeasible to analyze real world data in a rea-
sonable time frame.
In this paper, we define OSTAG, a new way to
constrain TAG in a conceptually simple way so
302
SNP VP NP
NP
DT
the
NN
lack
NP
NNS
computers
VP
VBP
do
RB
not
VP
NP
NP PP
NP
PRP
I
PP
IN
of
PRP
them
VP
VB
fear
Figure 1: A simple Tree-Substitution Grammar using S as its start symbol. This grammar derives the
sentences from a quote of Isaac Asimov?s - ?I do not fear computers. I fear the lack of them.?
that it can be reduced to a CFG, allowing the use of
traditional cubic-time algorithms. The reduction is
reversible, so that the original TAG derivation can
be recovered exactly from the CFG parse. We pro-
vide this reduction in detail below and highlight
the compression afforded by this TAG variant on
synthetic formal languages.
We evaluate OSTAG on the familiar task of
parsing the Penn Treebank. Using an automati-
cally induced Tree-Substitution Grammar (TSG),
we heuristically extract an OSTAG and estimate
its parameters from data using models with var-
ious reduced probabilistic models of adjunction.
We contrast these models and investigate the use
of adjunction in the most probable derivations of
the test corpus, demonstating the superior model-
ing performance of OSTAG over TSG.
2 TAG and Variants
Here we provide a short history of the relevant
work in related grammar formalisms, leading up
to a definition of OSTAG. We start with context-
free grammars, the components of which are
?N,T,R, S?, where N and T are the sets of non-
terminal and terminal symbols respectively, and S
is a distinguished nonterminal, the start symbol.
The rules R can be thought of as elementary trees
of depth 1, which are combined by substituting a
derived tree rooted at a nonterminalX at some leaf
node in an elementary tree with a frontier node
labeled with that same nonterminal. The derived
trees rooted at the start symbol S are taken to be
the trees generated by the grammar.
2.1 Tree-Substitution Grammar
By generalizing CFG to allow elementary trees in
R to be of depth greater than or equal to 1, we
get the Tree-Substitution Grammar. TSG remains
in the family of context-free grammars, as can be
easily seen by the removal of the internal nodes
in all elementary trees; what is left is a CFG that
generates the same language. As a reversible al-
ternative that preserves the internal structure, an-
notation of each internal node with a unique index
creates a large number of deterministic CFG rules
that record the structure of the original elementary
trees. A more compact CFG representation can be
obtained by marking each node in each elemen-
tary tree with a signature of its subtree. This trans-
form, presented by Goodman (2003), can rein in
the grammar constant G, as the crucial CFG algo-
rithms for a sentence of length n have complexity
O(Gn3).
A simple probabilistic model for a TSG is a set
of multinomials, one for each nonterminal in N
corresponding to its possible substitutions in R. A
more flexible model allows a potentially infinite
number of substitution rules using a Dirichlet Pro-
cess (Cohn et al, 2009; Cohn and Blunsom, 2010).
This model has proven effective for grammar in-
duction via Markov Chain Monte Carlo (MCMC),
in which TSG derivations of the training set are re-
peatedly sampled to find frequently occurring el-
ementary trees. A straightforward technique for
induction of a finite TSG is to perform this non-
parametric induction and select the set of rules that
appear in at least one sampled derivation at one or
several of the final iterations.
2.2 Tree-Adjoining Grammar
Tree-adjoining grammar (TAG) (Joshi, 1985;
Joshi, 1987; Joshi and Schabes, 1997) is an exten-
sion of TSG defined by a tuple ?N,T,R,A, S?,
and differs from TSG only in the addition of a
303
VP
always VP
VP* quickly
+ S
NP VP
runs
? S
NP VP
always VP
VP
runs
quickly
Figure 2: The adjunction operation combines the auxiliary tree (left) with the elementary tree (middle)
to form a new derivation (right). The adjunction site is circled, and the foot node of the auxiliary tree is
denoted with an asterisk. The OSTAG constraint would disallow further adjunction at the bold VP node
only, as it is along the spine of the auxiliary tree.
set of auxiliary trees A and the adjunction oper-
ation that governs their use. An auxiliary tree ?
is an elementary tree containing a single distin-
guished nonterminal leaf, the foot node, with the
same symbol as the root of ?. An auxiliary tree
with root and foot node X can be adjoined into an
internal node of an elementary tree labeled with
X by splicing the auxiliary tree in at that internal
node, as pictured in Figure 2. We refer to the path
between the root and foot nodes in an auxiliary
tree as the spine of the tree.
As mentioned above, the added power afforded
by adjunction comes at a serious price in time
complexity. As such, probabilistic modeling for
TAG in its original form is uncommon. However,
a large effort in non-probabilistic grammar induc-
tion has been performed through manual annota-
tion with the XTAG project(Doran et al, 1994).
2.3 Tree Insertion Grammar
Tree Insertion Grammars (TIGs) are a longstand-
ing compromise between the intuitive expressivity
of TAG and the algorithmic simplicity of CFGs.
Schabes and Waters (1995) showed that by re-
stricting the form of the auxiliary trees in A and
the set of auxiliary trees that may adjoin at par-
ticular nodes, a TAG generates only context-free
languages. The TIG restriction on auxiliary trees
states that the foot node must occur as either the
leftmost or rightmost leaf node. This introduces
an important distinction between left, right, and
wrapping auxiliary trees, of which only the first
two are allowed in TIG. Furthermore, TIG disal-
lows adjunction of left auxiliary trees on the spines
of right auxiliary trees, and vice versa. This is
to prevent the construction of wrapping auxiliary
trees, whose removal is essential for the simplified
complexity of TIG.
Several probabilistic models have been pro-
posed for TIG. While earlier approaches such as
Hwa (1998) and Chiang (2000) relied on hueristic
induction methods, they were nevertheless sucess-
ful at parsing. Later approaches (Shindo et al,
2011; Yamangil and Shieber, 2012) were able to
extend the non-parametric modeling of TSGs to
TIG, providing methods for both modeling and
grammar induction.
2.4 OSTAG
Our new TAG variant is extremely simple. We al-
low arbitrary initial and auxiliary trees, and place
only one restriction on adjunction: we disallow
adjunction at any node on the spine of an aux-
iliary tree below the root (though we discuss re-
laxing that constraint in Section 4.2). We refer to
this variant as Off Spine TAG (OSTAG) and note
that it allows the use of full wrapping rules, which
are forbidden in TIG. This targeted blocking of
recursion has similar motivations and benefits to
the approximation of CFGs with regular languages
(Mohri and jan Nederhof, 2000).
The following sections discuss in detail the
context-free nature of OSTAG and alternative
probabilistic models for its equivalent CFG form.
We propose a simple but empirically effective
heuristic for grammar induction for our experi-
ments on Penn Treebank data.
3 Transformation to CFG
To demonstrate that OSTAG has only context-
free power, we provide a reduction to context-free
grammar. Given an OSTAG ?N,T,R,A, S?, we
define the set N of nodes of the corresponding
CFG to be pairs of a tree inR orA together with an
304
?: S
T
x
T
y
?: T
a T* a
?: T
b T* b
S ? X Y S ? X Y
X ? x X ? x
Y ? y Y ? y
X ? A
X ? B
Y ? A?
Y ? B?
A ? a X ? a X ? a X a
A? ? a Y ? a Y ? a Y a
X ? ? X
Y ? ? Y
B ? b X ?? b X ? b X b
B? ? b Y ?? b Y ? b Y b
X ?? ? X
Y ?? ? Y
(a) (b) (c)
Figure 3: (a) OSTAG for the language wxwRvyvR where w, v ? {a|b}+ and R reverses a string. (b) A
CFG for the same language, which of necessity must distinguish between nonterminalsX and Y playing
the role of T in the OSTAG. (c) Simplified CFG, conflating nonterminals, but which must still distinguish
between X and Y .
address (Gorn number (Gorn, 1965)) in that tree.
We take the nonterminals of the target CFG gram-
mar to be nodes or pairs of nodes, elements of the
setN +N ?N . We notate the pairs of nodes with
a kind of ?applicative? notation. Given two nodes
? and ??, we notate a target nonterminal as ?(??).
Now for each tree ? and each interior node ?
in ? that is not on the spine of ? , with children
?1, . . . , ?k, we add a context-free rule to the gram-
mar
? ? ?1 ? ? ? ?k (1)
and if interior node ? is on the spine of ? with
?s the child node also on the spine of ? (that is,
dominating the foot node of ? ) and ?? is a node (in
any tree) where ? is adjoinable, we add a rule
?(??)? ?1 ? ? ? ?s(??) ? ? ? ?k . (2)
Rules of type (1) handle the expansion of a node
not on the spine of an auxiliary tree and rules of
type (2) a spinal node.
In addition, to initiate adjunction at any node ??
where a tree ? with root ? is adjoinable, we use a
rule
?? ? ?(??) (3)
and for the foot node ?f of ? , we use a rule
?f (?)? ? (4)
The OSTAG constraint follows immediately
from the structure of the rules of type (2). Any
child spine node ?s manifests as a CFG nonter-
minal ?s(??). If child spine nodes themselves al-
lowed adjunction, we would need a type (3) rule
of the form ?s(??) ? ?s(??)(???). This rule itself
would feed adjunction, requiring further stacking
of nodes, and an infinite set of CFG nonterminals
and rules. This echoes exactly the stacking found
in the LIG reduction of TAG .
To handle substitution, any frontier node ? that
allows substitution of a tree rooted with node ??
engenders a rule
? ? ?? (5)
This transformation is reversible, which is to
say that each parse tree derived with this CFG im-
plies exactly one OSTAG derivation, with substi-
tutions and adjunctions coded by rules of type (5)
and (3) respectively. Depending on the definition
of a TAG derivation, however, the converse is not
necessarily true. This arises from the spurious am-
biguity between adjunction at a substitution site
(before applying a type (5) rule) versus the same
adjunction at the root of the substituted initial tree
(after applying a type (5) rule). These choices
lead to different derivations in CFG form, but their
TAG derivations can be considered conceptually
305
identical. To avoid double-counting derivations,
which can adversely effect probabilistic modeling,
type (3) and type (4) rules in which the side with
the unapplied symbol is a nonterminal leaf can be
omitted.
3.1 Example
The grammar of Figure 3(a) can be converted to
a CFG by this method. We indicate for each CFG
rule its type as defined above the production arrow.
All types are used save type (5), as substitution
is not employed in this example. For the initial
tree ?, we have the following generated rules (with
nodes notated by the tree name and a Gorn number
subscript):
? 1?? ?1 ?2 ?1 3?? ?(?1)
?1 1?? x ?1 3?? ?(?1)
?2 1?? y ?2 3?? ?(?2)
?2 3?? ?(?2)
For the auxiliary trees ? and ? we have:
?(?1) 2?? a ?1(?1) a
?(?2) 2?? a ?1(?2) a
?1(?1) 4?? ?1
?1(?2) 4?? ?2
?(?1) 2?? b ?1(?1) b
?(?2) 2?? b ?1(?2) b
?1(?1) 4?? ?1
?1(?2) 4?? ?2
The grammar of Figure 3(b) is simply a renaming
of this grammar.
4 Applications
4.1 Compact grammars
The OSTAG framework provides some leverage in
expressing particular context-free languages more
compactly than a CFG or even a TSG can. As
an example, consider the language of bracketed
palindromes
Pal = aiw aiwR ai
1 ? i ? k
w ? {bj | 1 ? j ? m}?
containing strings like a2 b1b3 a2 b3b1 a2. Any
TSG for this language must include as substrings
some subpalindrome constituents for long enough
strings. Whatever nonterminal covers such a
string, it must be specific to the a index within
it, and must introduce at least one pair of bs as
well. Thus, there are at least m such nontermi-
nals, each introducing at least k rules, requiring at
least km rules overall. The simplest such gram-
mar, expressed as a CFG, is in Figure 4(a). The
ability to use adjunction allows expression of the
same language as an OSTAG with k +m elemen-
tary trees (Figure 4(b)). This example shows that
an OSTAG can be quadratically smaller than the
corresponding TSG or CFG.
4.2 Extensions
The technique in OSTAG can be extended to ex-
pand its expressiveness without increasing gener-
ative capacity.
First, OSTAG allows zero adjunctions on each
node on the spine below the root of an auxiliary
tree, but any non-zero finite bound on the num-
ber of adjunctions allowed on-spine would simi-
larly limit generative capacity. The tradeoff is in
the grammar constant of the effective probabilis-
tic CFG; an extension that allows k levels of on
spine adjunction has a grammar constant that is
O(|N |(k+2)).
Second, the OSTAG form of adjunction is con-
sistent with the TIG form. That is, we can extend
OSTAG by allowing on-spine adjunction of left- or
right-auxiliary trees in keeping with the TIG con-
straints without increasing generative capacity.
4.3 Probabilistic OSTAG
One major motivation for adherence to a context-
free grammar formalism is the ability to employ
algorithms designed for probabilistic CFGs such
as the CYK algorithm for parsing or the Inside-
Outside algorithm for grammar estimation. In this
section we present a probabilistic model for an OS-
TAG grammar in PCFG form that can be used in
such algorithms, and show that many parameters
of this PCFG can be pooled or set equal to one and
ignored. References to rules of types (1-5) below
refer to the CFG transformation rules defined in
Section 3. While in the preceeding discussion we
used Gorn numbers for clarity, our discussion ap-
plies equally well for the Goodman transform dis-
cussed above, in which each node is labeled with a
signature of its subtree. This simply redefines ? in
the CFG reduction described in Section 3 to be a
subtree indicator, and dramatically reduces redun-
dancy in the generated grammar.
306
S ? ai Ti ai
Ti ? bj Ti bj
Ti ? ai
?i | 1 ? i ? k: S
ai T
ai
ai
?j | 1 ? j ? m: T
bj T* bj
(a) (b)
Figure 4: A CFG (a) and more compact OSTAG (b) for the language Pal
The first practical consideration is that CFG
rules of type (2) are deterministic, and as such
we need only record the rule itself and no asso-
ciated parameter. Furthermore, these rules employ
a template in which the stored symbol appears in
the left-hand side and in exactly one symbol on
the right-hand side where the spine of the auxil-
iary tree proceeds. One deterministic rule exists
for this template applied to each ?, and so we may
record only the template. In order to perform CYK
or IO, it is not even necessary to record the index
in the right-hand side where the spine continues;
these algorithms fill a chart bottom up and we can
simply propagate the stored nonterminal up in the
chart.
CFG rules of type (4) are also deterministic and
do not require parameters. In these cases it is not
necessary to record the rules, as they all have ex-
actly the same form. All that is required is a check
that a given symbol is adjoinable, which is true for
all symbols except nonterminal leaves and applied
symbols. Rules of type (5) are necessary to cap-
ture the probability of substitution and so we will
require a parameter for each.
At first glance, it would seem that due to the
identical domain of the left-hand sides of rules of
types (1) and (3) a parameter is required for each
such rule. To avoid this we propose the follow-
ing factorization for the probabilistic expansion of
an off spine node. First, a decision is made as to
whether a type (1) or (3) rule will be used; this cor-
responds to deciding if adjunction will or will not
take place at the node. If adjunction is rejected,
then there is only one type (1) rule available, and
so parameterization of type (1) rules is unneces-
sary. If we decide on adjunction, one of the avail-
able type (3) rules is chosen from a multinomial.
By conditioning the probability of adjunction on
varying amounts of information about the node,
alternative models can easily be defined.
5 Experiments
As a proof of concept, we investigate OSTAG in
the context of the classic Penn Treebank statistical
parsing setup; training on section 2-21 and testing
on section 23. For preprocessing, words that oc-
cur only once in the training data are mapped to
the unknown categories employed in the parser of
Petrov et al (2006). We also applied the annota-
tion from Klein and Manning (2003) that appends
?-U? to each nonterminal node with a single child,
drastically reducing the presence of looping unary
chains. This allows the use of a coarse to fine
parsing strategy (Charniak et al, 2006) in which
a sentence is first parsed with the Maximum Like-
lihood PCFG and only constituents whose prob-
ability exceeds a cutoff of 10?4 are allowed in
the OSTAG chart. Designed to facilitate sister ad-
junction, we define our binarization scheme by ex-
ample in which the added nodes, indicated by @,
record both the parent and head child of the rule.
NP
@NN-NP
@NN-NP
DT @NN-NP
JJ NN
SBAR
A compact TSG can be obtained automatically
using the MCMC grammar induction technique of
Cohn and Blunsom (2010), retaining all TSG rules
that appear in at least one derivation in after 1000
iterations of sampling. We use EM to estimate the
parameters of this grammar on sections 2-21, and
use this as our baseline.
To generate a set of TAG rules, we consider
each rule in our baseline TSG and find all possi-
307
All 40 #Adj #Wrap
TSG 85.00 86.08 ? ?
TSG? 85.12 86.21 ? ?
OSTAG1 85.42 86.43 1336 52
OSTAG2 85.54 86.56 1952 44
OSTAG3 85.86 86.84 3585 41
Figure 5: Parsing F-Score for the models under
comparison for both the full test set and sentences
of length 40 or less. For the OSTAG models, we
list the number of adjunctions in the MPD of the
full test set, as well as the number of wrapping
adjunctions.
ble auxiliary root and foot node pairs it contains.
For each such root/foot pair, we include the TAG
rule implied by removal of the structure above the
root and below the foot. We also include the TSG
rule left behind when the adjunction of this auxil-
iary tree is removed. To be sure that experimental
gains are not due to this increased number of TSG
initial trees, we calculate parameters using EM for
this expanded TSG and use it as a second base-
line (TSG?). With our full set of initial and aux-
iliary trees, we use EM and the PCFG reduction
described above to estimate the parameters of an
OSTAG.
We investigate three models for the probabil-
ity of adjunction at a node. The first uses a con-
servative number of parameters, with a Bernoulli
variable for each symbol (OSTAG1). The second
employs more parameters, conditioning on both
the node?s symbol and the symbol of its leftmost
child (OSTAG2).The third is highly parameterized
but most prone to data sparsity, with a separate
Bernoulli distribution for each Goodman index ?
(OSTAG3). We report results for Most Probable
Derivation (MPD) parses of section 23 in Figure
5.
Our results show that OSTAG outperforms both
baselines. Furthermore, the various parameteri-
zations of adjunction with OSTAG indicate that,
at least in the case of the Penn Treebank, the
finer grained modeling of a full table of adjunction
probabilities for each Goodman index OSTAG3
overcomes the danger of sparse data estimates.
Not only does such a model lead to better parsing
performance, but it uses adjunction more exten-
sively than its more lightly parameterized alterna-
tives. While different representations make direct
comparison inappropriate, the OSTAG results lie
in the same range as previous work with statistical
TIG on this task, such as Chiang (2000) (86.00)
and Shindo et al (2011) (85.03).
The OSTAG constraint can be relaxed as de-
scribed in Section 4.2 to allow any finite number of
on-spine adjunctions without sacrificing context-
free form. However, the increase to the grammar
constant quickly makes parsing with such models
an arduous task. To determine the effect of such a
relaxation, we allow a single level of on-spine ad-
junction using the adjunction model of OSTAG1,
and estimate this model with EM on the training
data. We parse sentences of length 40 or less in
section 23 and observe that on-spine adjunction is
never used in the MPD parses. This suggests that
the OSTAG constraint is reasonable, at least for
the domain of English news text.
We performed further examination of the MPD
using OSTAG for each of the sentences in the test
corpus. As an artifact of the English language, the
majority have their foot node on the left spine and
would also be usable by TIG, and so we discuss
the instances of wrapping auxiliary trees in these
derivations that are uniquely available to OSTAG.
We remove binarization for clarity and denote the
foot node with an asterisk.
A frequent use of wrapping adjunction is to co-
ordinate symbols such as quotes, parentheses, and
dashes on both sides of a noun phrase. One com-
mon wrapping auxiliary tree in our experiments is
NP
? NP* ? PP
This is used frequently in the news text of
the Wall Street Journal for reported speech when
avoiding a full quotation. This sentence is an ex-
ample of the way the rule is employed, using what
Joshi and Schabes (1997) referred to as ?factoring
recursion from linguistic constraints? with TAG.
Note that replacing the quoted noun phrase and
its following prepositional phrase with the noun
phrase itself yields a valid sentence, in line with
the linguistic theory underlying TAG.
Another frequent wrapping rule, shown below,
allows direct coordination between the contents of
an appositive with the rest of the sentence.
308
NP
NP , CC
or
NP* ,
This is a valuable ability, as it is common to
use an appositive to provide context or explanation
for a proper noun. As our information on proper
nouns will most likely be very sparse, the apposi-
tive may be more reliably connected to the rest of
the sentence. An example of this from one of the
sentences in which this rule appears in the MPD is
the phrase ?since the market fell 156.83, or 8 %,
a week after Black Monday?. The wrapping rule
allows us to coordinate the verb ?fell? with the pat-
tern ?X %? instead of 156.83, which is mapped to
an unknown word category.
These rules highlight the linguistic intuitions
that back TAG; if their adjunction were undone,
the remaining derivation would be a valid sen-
tence that simply lacks the modifying structure of
the auxiliary tree. However, the MPD parses re-
veal that not all useful adjunctions conform to this
paradigm, and that left-auxiliary trees that are not
used for sister adjunction are susceptible to this
behavior. The most common such tree is used to
create noun phrases such as
P&G?s share of [the Japanese market]
the House?s repeal of [a law]
Apple?s family of [Macintosh Computers]
Canada?s output of [crude oil]
by adjoining the shared unbracketed syntax onto
the NP dominating the bracketed text. If adjunc-
tion is taken to model modification, this rule dras-
tically changes the semantics of the unmodified
sentence. Furthermore, in some cases removing
the adjunction can leave a grammatically incorrect
sentence, as in the third example where the noun
phrase changes plurality.
While our grammar induction method is a crude
(but effective) heuristic, we can still highlight the
qualities of the more important auxiliary trees
by examining aggregate statistics over the MPD
parses, shown in Figure 6. The use of left-
auxiliary trees for sister adjunction is a clear trend,
as is the predominant use of right-auxiliary trees
for the complementary set of ?regular? adjunc-
tions, which is to be expected in a right branch-
ing language such as English. The statistics also
All Wrap Right Left
Total 3585 (1374) 41 (26) 1698 (518) 1846 (830)
Sister 2851 (1180) 17 (11) 1109 (400) 1725 (769)
Lex 2244 (990) 28 (19) 894 (299) 1322 (672)
FLex 1028 (558) 7 (2) 835 (472) 186 (84)
Figure 6: Statistics for MPD auxiliary trees us-
ing OSTAG3. The columns indicate type of aux-
iliary tree and the rows correspond respectively to
the full set found in the MPD, those that perform
sister adjunction, those that are lexicalized, and
those that are fully lexicalized. Each cell shows
the number of tokens followed by the number of
types of auxiliary tree that fit its conditions.
reflect the importance of substitution in right-
auxiliary trees, as they must capture the wide va-
riety of right branching modifiers of the English
language.
6 Conclusion
The OSTAG variant of Tree-Adjoining Grammar
is a simple weakly context-free formalism that
still provides for all types of adjunction and is
a bit more concise than TSG (quadratically so).
OSTAG can be reversibly transformed into CFG
form, allowing the use of a wide range of well
studied techniques in statistical parsing.
OSTAG provides an alternative to TIG as a
context-free TAG variant that offers wrapping ad-
junction in exchange for recursive left/right spine
adjunction. It would be interesting to apply both
OSTAG and TIG to different languages to deter-
mine where the constraints of one or the other are
more or less appropriate. Another possibility is the
combination of OSTAG with TIG, which would
strictly expand the abilities of both approaches.
The most important direction of future work for
OSTAG is the development of a principled gram-
mar induction model, perhaps using the same tech-
niques that have been successfully applied to TSG
and TIG. In order to motivate this and other re-
lated research, we release our implementation of
EM and CYK parsing for OSTAG1. Our system
performs the CFG transform described above and
optionally employs coarse to fine pruning and re-
laxed (finite) limits on the number of spine adjunc-
tions. As a TSG is simply a TAG without adjunc-
tion rules, our parser can easily be used as a TSG
estimator and parser as well.
1bllip.cs.brown.edu/download/bucketparser.tar
309
References
Eugene Charniak, Mark Johnson, Micha Elsner,
Joseph L. Austerweil, David Ellis, Isaac Hax-
ton, Catherine Hill, R. Shrivaths, Jeremy Moore,
Michael Pozar, and Theresa Vu. 2006. Multilevel
coarse-to-fine PCFG parsing. In North American
Chapter of the Association for Computational Lin-
guistics: Human Language Technologies.
Eugene Charniak. 1996. Tree-bank grammars. In As-
sociation for the Advancement of Artificial Intelli-
gence, pages 1031?1036.
David Chiang. 2000. Statistical parsing with
an automatically-extracted tree adjoining grammar.
Association for Computational Linguistics.
Trevor Cohn and Phil Blunsom. 2010. Blocked infer-
ence in bayesian tree substitution grammars. pages
225?230. Association for Computational Linguis-
tics.
Trevor Cohn, Sharon Goldwater, and Phil Blun-
som. 2009. Inducing compact but accurate tree-
substitution grammars. In Proceedings of Human
Language Technologies: The 2009 Annual Confer-
ence of the North American Chapter of the Associa-
tion for Computational Linguistics, pages 548?556.
Association for Computational Linguistics.
Christy Doran, Dania Egedi, Beth Ann Hockey, Banga-
lore Srinivas, and Martin Zaidel. 1994. XTAG sys-
tem: a wide coverage grammar for English. pages
922?928. Association for Computational Linguis-
tics.
J. Goodman. 2003. Efficient parsing of DOP with
PCFG-reductions. Bod et al 2003.
Saul Gorn. 1965. Explicit definitions and linguistic
dominoes. In Systems and Computer Science, pages
77?115.
Rebecca Hwa. 1998. An empirical evaluation of prob-
abilistic lexicalized tree insertion grammars. In Pro-
ceedings of the 36th Annual Meeting of the Associ-
ation for Computational Linguistics and 17th Inter-
national Conference on Computational Linguistics,
pages 557?563. Association for Computational Lin-
guistics.
Aravind K. Joshi and Yves Schabes. 1997. Tree-
adjoining grammars. In G. Rozenberg and A. Salo-
maa, editors, Handbook of Formal Languages, vol-
ume 3, pages 69?124. Springer.
Aravind K Joshi. 1985. Tree adjoining grammars:
How much context-sensitivity is required to provide
reasonable structural descriptions? University of
Pennsylvania.
Aravind K Joshi. 1987. An introduction to tree ad-
joining grammars. Mathematics of Language, pages
87?115.
Dan Klein and Christopher D Manning. 2003. Accu-
rate unlexicalized parsing. pages 423?430. Associ-
ation for Computational Linguistics.
K. Lari and S. J. Young. 1990. The estimation of
stochastic context-free grammars using the inside-
outside algorithm. Computer Speech and Language,
pages 35?56.
Mehryar Mohri and Mark jan Nederhof. 2000. Regu-
lar approximation of context-free grammars through
transformation. In Robustness in language and
speech technology.
Slav Petrov, Leon Barrett, Romain Thibaux, and Dan
Klein. 2006. Learning accurate, compact, and
interpretable tree annotation. In Proceedings of
the 21st International Conference on Computational
Linguistics and the 44th annual meeting of the Asso-
ciation for Computational Linguistics, pages 433?
440. Association for Computational Linguistics.
Yves Schabes and Richard C. Waters. 1995. Tree
insertion grammar: a cubic-time, parsable formal-
ism that lexicalizes context-free grammar without
changing the trees produced. Computational Lin-
guistics, (4):479?513.
Yves Schabes. 1990. Mathematical and computa-
tional aspects of lexicalized grammars. Ph.D. thesis,
University of Pennsylvania, Philadelphia, PA, USA.
Hiroyuki Shindo, Akinori Fujino, and Masaaki Nagata.
2011. Insertion operator for bayesian tree substi-
tution grammars. pages 206?211. Association for
Computational Linguistics.
Elif Yamangil and Stuart M. Shieber. 2012. Estimat-
ing compact yet rich tree insertion grammars. pages
110?114. Association for Computational Linguis-
tics.
310
