Coling 2008: Companion volume ? Posters and Demonstrations, pages 115?118
Manchester, August 2008
On ?redundancy? in selecting attributes for generating referring
expressions
Philipp Spanger Kurosawa Takehiro
Department of Computer Science
Tokyo Institute of Technology
Tokyo Meguro
?
Ookayama 2-12-1, 152-8550 Japan
{philipp, kurosawa, take}@cl.cs.titech.ac.jp
Tokunaga Takenobu
Abstract
We seek to develop an efficient algorithm
selecting attributes that approximates hu-
man selection. In contrast to previous work
we sought to combine the strengths of cog-
nitive theories and simple learning algo-
rithms. We then developed a new algo-
rithm for attribute selection based on ob-
servations from a corpus, which outper-
formed a simple base algorithm by a sig-
nificant margin. We then carried out a de-
tailed comparison between our algorithm
and Reiter & Dale?s ?Incremental Algo-
rithm?. In terms of achieving a human-like
attribute selection, the overall performance
of both algorithms is fundamentally equiv-
alent, while differing in the handling of re-
dundancy in selected attributes. We further
investigated this phenomenon and draw
some conclusions for further improvement
of attribute-selection algorithms.
1 Introduction
Referring expressions are a key research area in
human-agent communication. In the generation of
referring expressions humans do not necessarily
produce the most effective (i.e. minimal) expres-
sions in a computational sense. Given evolution-
ary development of human linguistic capabilities,
we can assume that human-produced expressions
are generally optimal to identify a target for other
human subjects. Thus the generation of human-
like referring expressions is an important task as
c
? 2008. Licensed under the Creative Commons
Attribution-Noncommercial-Share Alike 3.0 Unported li-
cense (http://creativecommons.org/licenses/by-nc-sa/3.0/).
Some rights reserved.
the generation of those expressions that are most
easily understandable for humans.
The seminal work in this field is the ?Incremen-
tal algorithm? (IA) (Dale and Reiter, 1995). Their
work is based on an analysis of the overall cog-
nitive tendencies of humans in the selection of at-
tributes. In recent years, there have been a number
of important extensions to this algorithm, dealing
with very specific problems. This need for a sys-
tematic approach and unified evaluation of those
vastly differing algorithms provided the motiva-
tion for the creation of the TUNA-corpus
1
that was
developed at Aberdeen University as part of the
TUNA project (van Deemter, 2007). Work has be-
gun to use this corpus for evaluating different al-
gorithms for attribute selection.
Our research is carried out within this general
trend, seeking to take advantage of common re-
sources (e.g. TUNA-corpus). A critical question is
how to combine the generic human cognitive ten-
dencies and the dependency of attribute selection
on a specific distribution of attributes in a specific
case. In this research we tackle this question in
a corpus-based approach. Specifically, in a given
environment, we seek to develop an efficient algo-
rithm for selection of attributes that approximates
human selection.
2 The corpus
We utilized a simplified version of the TUNA-
corpus, which was also the basis for the GRE-
challenge held as part of the UCNLG+MT work-
shop in 2007 (Belz and Gatt, 2007). The corpus
consists of a collection of paired pictures of objects
and human-produced referring expressions anno-
tated with attribute sets. Figure 1 shows an image
1
TUNA-corpus: www.csd.abdn.ac.uk/research/tuna
115
green
green
greengreen
red
red blue
target
Figure 1: Image of a TUNA-corpus picture
of such a case
2
. This corpus provides information
on the attribute-value pairs of the target and the
distractors as well as of the referring expressions
humans produced. Every item in our corpus con-
sists of an input part (?case?) and an output part
(?description?). Each individual case consists of
seven case entities: one target referent and six dis-
tractors. Every entity consists of a set of attribute-
value pairs and all descriptions consist of a subset
of the attribute-value pairs of the target referent in
the same format as any entity. This corpus com-
prises two domains: a ?Furniture? and a ?Person?
- domain. We note that within the corpus there
were some cases that we judged as inappropriate
for this study and thus excluded from the overall
evaluation. This included cases where attribute-
values were unspecified and/or inconsistent.
3 The base algorithm
We developed a base algorithm as a baseline for
evaluation. We define ?discriminative power? of a
specific attribute as the number of entities in the
case that have a different value from the target for
this attribute.
We add attributes in descending order of dis-
criminative power until the target can be identified
uniquely. The generated attribute set is the output.
Every time an attribute is selected, we recalcu-
late the discriminative power of the attributes of
exclusively those distractors that could not be ex-
cluded by this stage.
4 Analysis of human-produced referring
expressions
Our hypothesis is that in human generation of re-
ferring expressions, a combination of generic cog-
2
Actual pictures in the TUNA-corpus do neither show
colour labels nor a target-marker.
nitive factors as well as case-dependent factors
have to be dealt with. In order to account for the
cognitive factor, we define a ?selection probabil-
ity? over a whole domain (i.e. independent from a
specific case) and calculate the differences of this
selection probability over the different attributes.
We define the selection probability of a specific at-
tribute a in a specific domain as equation (1).
SP (a) =
C(a)
?
x?X
C(x)
(1)
where C(x) denotes the number of occurrences of
attribute x in the corpus.
We observe that in the Furniture-domain the at-
tributes colour and type have extraordinarily high
selection probabilities and in particular the at-
tribute type is selected virtually unconditionally.
We observe the same tendency of a very high selec-
tion probability for the attribute type in the Person-
domain, even though all distractors as well as the
target are of same type ?person?. Since the at-
tribute type becomes the head of the noun phrase
in the linguistic realisation of a referring expres-
sion, it is natural to mention the type. Overall, we
can conclude that the different values for the selec-
tion probabilities reflect the cognitive load humans
assign different attributes in a given domain.
4.1 Co-occurrence of attributes
We hypothesize that the selection of attributes is
limited by co-occurence - dependencies between
attributes.
In order to measure this degree of co-
occurrence, we defined a ?degree of dependency?
between attributes as in equation (2). If the degree
of dependency approaches 1, there is practically no
dependency in the occurrence of attributes a and b.
If this factor grows above 1, the two attributes eas-
ily occur jointly in the referring expression, on the
other hand, the further it decreases below 1, the
less likely are the two attributes to occur jointly.
In the equation P(a, b) is the probability that the
two attributes will be selected together, P(x) is
the probability that the attribute x will be selected.
D(a, b) is the degree of dependency between at-
tributes
D(a, b) =
P(a, b)
P(a)? P(b)
(2)
We observed that in the Furniture-domain, size
or orientation and dimension are less likely to oc-
116
cur together in a referring expression. Further-
more, in the Person - domain, hairColour and
hasHair or hasBeard have a high degree of depen-
dency, i.e. they likely occur together.
4.2 Redundancy of attributes
Even though in many referring expressions unique
identification with few attributes is possible, hu-
mans show a tendency to add ?redundant? at-
tributes, i.e. that are in a strict sense not necessary
for identification. By adding redundancy, humans
add robustness to the expression as well as pos-
sibly reducing the cognitive load for humans in a
specific context. Within the corpus, we counted the
number of expressions containing redundancy. In
the Furniture-domain there were 220 out of all 278
expressions and in the Person-domain there were
213 out of 230.
Table 1: Number of selected redundant attributes
Furniture (278 cases) Person (230 cases)
attribute occurrences attribute occurrences
colour 110 type 201
orientation 15 x-dimension 4
size 10 hasBeard 42
type 210 hasGlasses 41
x-dimension 18 hasHair 32
This level of redundancy indicates that in or-
der to produce human-like sets of attributes for the
generation of referring expressions, it is not neces-
sary to aim for a minimal set.
5 Our proposed algorithm for effective
attribute selection
Based on our analysis of co-occurrence and redun-
dancy of attributes, we centrally implemented the
following improvements of the base algorithm.
Co-occurrence Based on the results from sec-
tion 4.1, when a certain attribute is selected, we
raise the selection probabilities of those attributes
that have a tendency to co-occur with it, on the
other hand we lower the selection probabilities of
those attributes that have a tendency not to co-
occur with this attribute.
Redundancy Based on the results in section 4.2,
having selected the attributes to uniquely deter-
mine the target, we add the next candidate in the
list of attributes as a redundant attribute .
Combination We combine both individual im-
provements. First of all, we add the type-attribute
and then score the result based on the selec-
tion probability. With each selection of a spe-
cific attribute, we change the scores based on co-
occurrence, and at the end we add a redundant at-
tribute.
6 Evaluation of proposed algorithm
We measured the proximity of the sets of attributes
by our system to the human-produced set of at-
tributes. We utilize the Dice-coefficient (DC) ?
a measure of proximity for sets. For purposes of
Table 2: Average DC for key improvements
Furniture Person
Base algorithm 0.305 0.314
Base+selection probability 0.784 0.669
Base+co-occurrence 0.254 0.314
Base+redundancy 0.401 0.341
Combination 0.811 0.703
Incremental algorithm 0.811 0.705
comparison, we implemented a version of the In-
cremental algorithm, where we calculated the or-
der of selection of attributes according to the se-
lection probabilities of attributes in the overall do-
main (Furniture or Person). It is of note that our
algorithm (combination of all individual improve-
ments) performs almost equivalent to the IA.
6.1 Comparison with Incremental Algorithm
We carried out a detailed analysis of the results of
our algorithm and those of the IA. We found that
the results of both algorithms in the Furniture - do-
main are exactly the same; however the results of
the Person - domain show significant differences.
Thus we concentrate on further analysis of the re-
sults in the Person - domain.
We divided all cases from the Person - domain
into three sets; a set of cases where our algorithm
performs better than the IA (sys-superior cases: 27
cases), a set of cases where the opposite is true (IA-
superior cases: 24 cases) and a set of tie cases. We
then compared the first two sets.
Investigating these sets, we observed that the
key difference between these two algorithms lay
in the treatment of redundancy. The IA often fails
in the case where humans use fewer attributes and
add only type as redundant attribute. On the other
hand, our algorithm fails in the case where humans
use more complex expressions, that is, more at-
tributes including several redundant ones.
We investigated the redundant attributes which
are selected by humans but not by the algorithms.
117
In the IA-superior cases, our system fails to se-
lect the hasBeard attribute compared with the IA
in 20 out of 24 cases, while in the sys-superior
cases both algorithms fail to select almost the same
redundant attributes. We investigated for both al-
gorithms, which attributes the algorithms wrongly
select; i.e. which are not selected by humans. In
the sys-superior cases, the IA wrongly selects at-
tributes in all 27 cases, with 23 out of those in-
cluding the wrongly-selected hasBeard attribute.
In the IA-superior cases, the number of cases
with wrongly selected attributes is much smaller
(9 cases for each) and they are largely equiavalent.
Thus, our detailed analysis showed an over-
all opposite tendency in one attribute; hasBeard.
While in sys-superior cases about 85% of the cases
in which the IA output wrong attributes included
hasBeard, in IA-superior cases our system failed
to select exactly hasBeard at a largely equivalent
rate (about 83%). At this moment, we do not have
any reasonable explanation for this peculiarity of
hasBeard, but suspect it might possibly be related
to the characteristics of the corpus.
However, from the overall observation that our
algorithm achieved an equivalent level of human-
likeness to the IA while being weaker in cases of
more complex redundancy, we conclude that fur-
ther improvement in selecting redundant attributes
is crucial to outperform the IA.
7 Concluding Remarks
Based on observations from the TUNA-corpus,
we developed an algorithm for attribute-selection
modeling human referring expressions. Our
corpus-based algorithm sought to combine human
generic tendencies of attribute selection in a cer-
tain domain with case-dependent variation of the
salience of specific attributes. Our improved algo-
rithm outperformed the base algorithm by a signif-
icant margin. However, we got qualitatively equiv-
alent results to our implementation of the IA.
A detailed analysis of the characteristics of our
algorithm in comparison to the IA pointed to the
importance of the phenomenon of redundancy as
possibly a central aspect that needs to be further
investigated to achieve a qualitative improvement
over the IA.
Our investigations into redundancy show that in
those cases where our algorithm outperformed the
IA, our algorithm almost exclusively added solely
the type-attribute. In contrast in more complex
cases of redundancy in referring expressions, the
IA has shown to be superior. Since we achieved
overall parity to the IA even though generally per-
forming worse than the IA in cases of more com-
plex redundancy, we can conclude that outside of
this phenomenon our algorithm performs better
than the IA in terms of human-likeness.
In previous research there has been some discus-
sion on ?redundancy? vs. ?minimality? in refer-
ring expressions (e.g. (Viethen and Dale, 2006)).
Through our research we have identified the phe-
nomenon of redundancy as a critical topic for fur-
ther research and for achieving further progress
in the generation of human-like referring expres-
sions.
Our algorithm includes some strong simplifica-
tions, e.g. our treatment of attributes did not take
account of the fact that attribute-values are also of
different type and did not explore what implica-
tions this has for the process of producing refer-
ring expressions; binary (hasHair), discrete (hair-
Colour) or graded (x-dim). In future these factors
should be integrated into attribute selection algo-
rithms.
In future work, we will seek to provide a more
detailed investigation of the phenomenon of re-
dundancy, including its variation over different do-
mains. Such an analysis should also contribute to
further our understanding of the human cognitive
process in the selection of attributes for the gener-
ation of referring expressions.
References
Belz, Anja and Albert Gatt. 2007. The attribute se-
lection for GRE challenge: Overview and evaluation
results. In Proceedings of the MT Summit XI Work-
shop Using Corpora for Natural Language Gener-
ation: Language Generation and Machine Transla-
tion (UCNLG+MT), pages 75?83.
Dale, Robert. and Ehud Reiter. 1995. Computational
interpretation of the gricean maxims in the gener-
ation of referring expressions. Cognitive Science,
19(2):233?263.
van Deemter, Kees. 2007. TUNA: To-
wards a unified algorithm for the genera-
tion of referring expressions - Final Report -.
http://www.csd.abdn.ac.uk/research/tuna/pubs/TUNA-
final-report.pdf.
Viethen, Jette and Robert Dale. 2006. Algorithms for
generating referring expressions: Do they do what
people do? In Proceedings of the Fourth Inter-
national Natural Language Generation Conference,
pages 63?70.
118
