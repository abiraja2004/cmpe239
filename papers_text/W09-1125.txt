Proceedings of the Thirteenth Conference on Computational Natural Language Learning (CoNLL), pages 201?209,
Boulder, Colorado, June 2009. c?2009 Association for Computational Linguistics
Fine-Grained Classification of Named Entities
Exploiting Latent Semantic Kernels
Claudio Giuliano
FBK-irst
I-38100, Trento, Italy
giuliano@fbk.eu
Abstract
We present a kernel-based approach for fine-
grained classification of named entities. The
only training data for our algorithm is a few
manually annotated entities for each class. We
defined kernel functions that implicitly map
entities, represented by aggregating all con-
texts in which they occur, into a latent seman-
tic space derived from Wikipedia. Our method
achieves a significant improvement over the
state of the art for the task of populating an
ontology of people, although requiring con-
siderably less training instances than previous
approaches.
1 Introduction
Populating an ontology with relevant entities ex-
tracted from unstructured textual documents is a
crucial step in Semantic Web and knowledge man-
agement systems. As the concepts in an ontology
are generally arranged in deep class/subclass hierar-
chies, the problem of populating ontologies is typi-
cally solved top-down, firstly identifying and classi-
fying entities in the most general concepts, and then
refining the classification process.
Recent advances have made supervised ap-
proaches very successful in entity identification and
classification. However, to achieve satisfactory per-
formance, supervised systems must be supplied with
a sufficiently large amount of training data, usually
consisting of hand tagged texts. As domain specific
ontologies generally contains hundreds of subcate-
gories, such approaches are not directly applicable
for a more fine-grained categorization because the
number of documents required to find sufficient pos-
itive examples for all subclasses becomes too large,
making the manual annotation very expensive.
Consequently, in the literature, supervised ap-
proaches are confined to classify entities into broad
categories, such as persons, locations, and or-
ganizations, while the fine-grained classification
has been approached with minimally supervised
(e.g., Tanev and Magnini (2006) and Giuliano and
Gliozzo (2008)) and unsupervised learning algo-
rithms (e.g., Cimiano and Vo?lker (2005) and Giu-
liano and Gliozzo (2007)).
Following this trend, we present a minimally su-
pervised approach to fine-grained categorization of
named entities previously recognized into coarse-
grained categories, e.g., by a named-entity recog-
nizer. The only training data for our algorithm is a
few manually annotated entities for each class. For
example, Niels Bohr, Albert Einstein, and Enrico
Fermi might be used as examples for the class physi-
cists. In some cases, training entities can be acquired
(semi-) automatically from existing ontologies al-
lowing us to automatically derive training entities
for use with our machine learning algorithm. For
instance, we may easily obtain tens of training en-
tities for very specific classes, such as astronomers,
materials scientists, nuclear physicists, by querying
the Yago ontology (Suchanek et al, 2008).
We represent the entities using features extracted
from the textual contexts in which they occur.
Specifically, we use a search engine to collect such
contexts from the Web. Throughout this paper, we
will refer to such a representation as multi-context
representation, in contrast to the single-context rep-
201
resentation in which an entity is categorized using
solely features extracted from the local context sur-
rounding it, usually a window of a few words around
the entity occurrence. Single-context features are
commonly used in named-entity recognition, how-
ever to assign very specific categories the local con-
text might not provide sufficient information. For
example, in the sentence ?Prof. Enrico Fermi dis-
covered a way to induce artificial radiation in heavy
elements by shooting neutrons into their atomic nu-
clei,? single-context features such as, the prefix Prof.
and the capital letters, provides enough evidence that
Enrico Fermi is a person and a professor. However,
to discover that he is a physicist we need to analyze
a wider context, or alternatively multiple ones. Re-
cently, Ganti et al (2008) has shown that exploiting
multi-context information can greatly improve the
fine-grained classification of named entities, when
compared to methods using single context only.
In order to effectively represent entities? multi-
contexts, we extend the traditional vector space
model (VSM), offering a way to integrate external
semantic information in the classification process by
means of latent semantic kernels (Shawe-Taylor and
Cristianini, 2004). As a result, we obtain a general-
ized similarity function between multi-contexts that
incorporates semantic relations between terms, auto-
matically learned from unlabeled data. In particular,
we use Wikipedia to build the latent semantic space.
The underlying idea is that similar named entities
tend to have a similar description in Wikipedia. As
Wikipedia provides reliable information and it ex-
ceeds all other encyclopedias in coverage, it should
be a valuable resource for the task of populating an
ontology. To validate this hypothesis, we compare
this model with one built from a news corpus.
Our approach achieves a significant improvement
over the state of the art for the task of populating the
People Ontology (Giuliano and Gliozzo, 2008), al-
though requiring considerably less training instances
than previous approaches. The task consists in clas-
sifying person names into a multi-level taxonomy
composed of 21 categories derived from WordNet,
making very fine-grained distinctions (e.g., physi-
cists vs. mathematicians). It provides a more real-
istic and challenging benchmark than the ones pre-
viously available (e.g., Tanev and Magnini (2006)
and Fleischman and Hovy (2002)), that consider a
smaller number of categories arranged in a one-level
taxonomy.
2 Entity Representation
The goal of our research is to determine the fine-
grained categories of named entities requiring a min-
imal amount of human supervision.
Our method is based on the common assump-
tion that named entities co-occurring with the same
(domain-specific) terms are highly probable to refer
to the same categories. For example, quantum me-
chanics, atomic physics, and Nobel Prize in physics
are all terms that bound Niels Bohr and Enrico Fermi
to the concept of physics.
To automatically derive features for the training
and testing entities we proceed as follows. We pair
each entity i with a multi-context mi obtained by
querying a search engine with the entity ?i? and
merging the first M snippets si,j returned (1 6 j 6
M ). A multi-context is therefore a fictitious doc-
ument obtained by aggregating snippets, i.e., sum-
mary texts of the search engine result. Formally,
mi = ?Mj=1si,j , where the operator ? denotes the
concatenation of strings. For example, Figure 1 (a)
and (b) show some snippets retrieved for ?Enrico
Fermi? and ?Albert Einstein,? while s1? s2? s3 and
s4 ? s5 ? s6 represent their multi-contexts, respec-
tively.
The following section describes how entities?
multi-contexts are embedded into the feature space
in order to train a kernel-based classifier.
3 Kernels for Fine-Grained Classification
of Entities
The strategy adopted by kernel methods (Shawe-
Taylor and Cristianini, 2004; Scho?lkopf and Smola,
2002) consists of splitting the learning problem in
two parts. They first embed the input data in a suit-
able feature space, and then use a linear algorithm
(e.g., the perceptron) to discover nonlinear pattern in
the input space. Typically, the mapping is performed
implicitly by a so-called kernel function. The ker-
nel function is a similarity measure between the in-
put data that depends exclusively on the specific data
type and domain. A typical similarity function is the
inner product between feature vectors. Characteriz-
ing the similarity of the inputs plays a crucial role in
202
s1: [Enrico Fermi]PER discovered that many nuclear transformations could be conducted by using neutrons.
s2: [Enrico Fermi]PER led the manhattan project?s effort to create the first man-made and self-sustaining nuclear chain.
s3: [Enrico Fermi]PER was most noted for his work on the development of the first nuclear reactor.
(a)
s4: [Albert Einstein]PER did not directly participate in the invention of the atomic bomb.
s5: [Albert Einstein]PER is one of the most recognized and well-known scientists of the century.
s6: [Albert Einstein]PER was born at Ulm, in Wu?rttemberg, Germany, on March 14, 1879.
(b)
Figure 1: Examples of snippets retrieved for Enrico Fermi (a) and Albert Einstein (b).
determining the success or failure of the learning al-
gorithm, and it is one of the central questions in the
field of machine learning.
Formally, the kernel is a function k : X?X ? R
that takes as input two data objects (e.g., vectors,
texts, parse trees) and outputs a real number charac-
terizing their similarity, with the property that the
function is symmetric and positive semi-definite.
That is, for all xi, xj ? X , it satisfies
k(xi, xj) = ??(xi), ?(xj)? (1)
where ? is an explicit mapping from X to an (inner
product) feature space F .
In the next sections, we define and combine differ-
ent kernel functions that calculate the pairwise sim-
ilarly between multi-contexts. They are the only do-
main specific element of our classification system,
while the learning algorithm is a general purpose
component. Many classifiers can be used with ker-
nels. The most popular ones are perceptron, sup-
port vector machines (SVM), and k-nearest neighbor
(KNN).
3.1 Bag-of-Words Kernel
The simplest method to estimate the similarity be-
tween two multi-contexts is to compute the inner
product of their vector representations in the VSM.
Formally, we define a space of dimensionality N in
which each dimension is associated with one word
from the dictionary, and the multi-context m is rep-
resented by a row vector
?(m) = (f(t1,m), f(t2,m), . . . , f(tN ,m)), (2)
where the function f(ti,m) records whether a par-
ticular token ti is used in m. Using this representa-
tion we define bag-of-words kernel between multi-
contexts as
KBOW (m1,m2) = ??(m1), ?(m2)? (3)
However, the bag-of-words representation does
not deal well with lexical variability. To significantly
reduce the training set size, we need to map contexts
containing semantically equivalent terms into simi-
lar feature vectors. To this aim, in the next section,
we introduce the class of semantic kernels and show
how to define an effective semantic VSM using (un-
labeled) external knowledge.
3.2 Semantic Kernels
It has been shown that semantic information is fun-
damental for improving the accuracy and reducing
the amount of training data in many natural language
tasks, including fine-grained classification of named
entities (Fleischman and Hovy, 2002), question clas-
sification (Li and Roth, 2005), text categorization
(Giozzo and Strapparava, 2005), word sense disam-
biguation (Gliozzo et al, 2005).
In the context of kernel methods, semantic infor-
mation can be integrated considering linear trans-
formations of the type ??(cj) = ?(cj)S, where S
is a N ? k matrix (Shawe-Taylor and Cristianini,
2004). The matrix S can be rewritten as S = WP,
where W is a diagonal matrix determining the word
weights, while P is the word proximity matrix cap-
turing the semantic relations between words. The
proximity matrix P can be defined by setting non-
zero entries between those words whose semantic
relation is inferred from an external source of do-
main knowledge. The semantic kernel takes the gen-
eral form
k?(mi,mj) = ?(mi)SS??(mj)? = ??(mi)??(mj)?. (4)
It follows directly from the explicit construction that
Equation 4 defines a valid kernel.
WordNet and manually constructed lists of se-
mantically related words typically provide a sim-
ple way to introduce semantic information into the
203
kernel. To define a semantic kernel from such re-
sources, we could explicitly construct the proximity
matrix P by setting its entries to reflect the semantic
proximity between the words i and j in the specific
lexical resource. However, we prefer an approach
that exploits unlabeled data to automatically build
the proximity matrix, defining a language and do-
main independent approach.
3.2.1 Latent Semantic Kernel
To define a proximity matrix, we look at co-
occurrence information in a (large) corpus. Two
words are considered semantically related if they
frequently co-occur in the same texts. We use sin-
gular valued decomposition (SVD) to automatically
derive the proximity matrix ? from a corpus, rep-
resented by its term-by-document matrix D, where
the Di,j entry gives the frequency of term ti in doc-
ument dj .1 SVD decomposes the term-by-document
matrix D into three matrixes D = U?V?, where U
and V are orthogonal matrices (i.e., U?U = I and
V?V = I) whose columns are the eigenvectors of
DD? and D?D respectively, and ? is the diagonal
matrix containing the singular values of D.
Under this setting, we define the proximity matrix
? as follows:
? = Uk?k, (5)
where Uk is the matrix containing the first k
columns of U and k is the dimensionality of the la-
tent semantic space and can be fixed in advance. By
using a small number of dimensions, we can define a
very compact representation of the proximity matrix
and, consequently, reduce the memory requirements
while preserving most of the information.
The matrix ? is used to define a linear transfor-
mation pi : RN ? Rk, that maps the vector ?(mj),
represented in the standard VSM, into the vector
??(mj) in the latent semantic space. Formally, pi is
defined as follows
pi(?(mj)) = ?(mj)(W?) = ??(mj), (6)
where ?(mj) is a row vector, W is a N ? N diag-
onal matrix determining the word weights such that
Wi,i = log(idf(wi)), where idf(wi) is the inverse
document frequency of wi.
1SVD has been first applied to perform latent semantic anal-
ysis of terms and latent semantic indexing of documents in large
corpora by Deerwester et al (1990).
Finally, the latent semantic kernel is explicitly de-
fined as follows
KLS(mi,mj) = ?pi(?(mi)), pi(?(mj))?, (7)
where ? is the mapping defined in Equation 2 and
pi is the linear transformation defined in Equation 6.
Note that we have used a series of successive map-
pings each of which adds some further improvement
to the multi-context representation.
3.3 Composite Kernel
Finally, to combine the two representations of multi-
contexts, we define the composite kernel as follows
KBOW (m1,m2) +KLS(m1,m2). (8)
It follows directly from the explicit construction of
the feature space and from closure properties of ker-
nels that it is a valid kernel.
4 Experiments
In this section, we compare performance of different
kernel setups and previous approaches on an ontol-
ogy population task.
4.1 Benchmark
Experiments were carried out on the People Ontol-
ogy (Giuliano and Gliozzo, 2008). An ontology
extracted from WordNet, containing 1,657 distinct
person instances arranged in a multi-level taxonomy
having 21 fine-grained categories (Figure 2). To pro-
vide a formal distinction between classes and in-
stances, required to assign instances to classes, the
authors followed the directives defined by Gangemi
et al (2003) for OntoWordNet, in which the infor-
mal WordNet semantics is re-engineered in terms of
a description logic.
In order to have a fair comparison, we reproduced
the same experimental settings used in Giuliano and
Gliozzo (2008). The population task is cast as a cate-
gorization problem, trying to assign person instances
to the most specific category. For each class, the in-
stances were randomly split into two equally sized
subsets. One is used for training and the other for
test, and vice versa. The reported results are the av-
erage performance over these two subsets. When an
instance is assigned to a sub-class it is also implic-
itly assigned to all its super-classes. For instance,
204
Figure 2: The People Ontology defined by Giuliano and Gliozzo (2008). Numbers in brackets are the total numbers
of person instances per category. Concepts with less than 40 instances were removed.
classifying Salvador Dali as painter we implicitly
classify him as artist and creator. The evaluation
is performed as proposed by Melamed and Resnik
(2000) for a similar hierarchical categorization task.
For instance, classifying John Lennon as painter, we
obtain a false positive for the spurious classification
painter, a false negative for missing class musician,
and two true positives for the correct assignment to
the super-classes artist and creator.
4.2 Experimental Settings
We built two proximity matrices ?W and ?NY T .
The former is derived from the 200,000 most visited
Wikipedia articles, while the latter from 200,000 ar-
ticles published by the New York Times between
June 1, 1998 and January 01, 2000. After remov-
ing terms that occur less than 5 times, the result-
ing dictionaries contain about 300,000 and 150,000
terms respectively. We used the SVDLIBC pack-
age2 to compute the SVD, truncated to 400 dimen-
sions. To derive the multi-context representation, we
collected 100 english snippets for each person in-
stance by querying GoogleTM. To classify each per-
son instance into one of the fine-grained categories,
we used a KNN classifier (K = 1). No parameter
optimization was performed.
2http://tedlab.mit.edu/?dr/svdlibc/
4.3 Results
Table 1 shows micro- and macro-averaged results
for KBOW , KW , KBOW +KW , KNY T , KBOW +
KNY T , the IBOP method (Giuliano and Gliozzo,
2008), the random baseline, and most frequent base-
line.3 Where KW and KNY T are instances of the
latent semantic kernel, KLS , using the proximity
matrices ?W and ?NY T , derived from Wikipedia
and the New York Times corpus, respectively. Ta-
ble 2 shows detailed results for each sub- and super-
category for KBOW +KW . Table 3 shows the con-
fusion matrix of KBOW + KW , in which the rows
are ground truth classes and the columns are predic-
tions. The matrix has been calculated for the finer-
grained categories and, then, grouped according to
their super-class. To be compared with the IBOP
method, all experiments were conducted using only
20 training examples per category. Finally, figure
3 shows the learning curves for KBOW + KW ob-
tained varying the number of snippets (12, 25, 50,
and 100) used to derive the multi-contexts.
4.4 Discussion
On the one hand, the results (Table 2) show that
learning the semantic model from Wikipedia gives
no significant improvement. Therefore, we reject the
hypothesis that encyclopedic knowledge can provide
3The most frequent category has been estimated on the train-
ing data.
205
 0.5
 0.55
 0.6
 0.65
 0.7
 0.75
 0.8
 2  4  6  8  10  12  14  16  18  20
Mic
ro F
1
Number of instances
12 snippets
KBOWKWKBOW+KW  0.5
 0.55
 0.6
 0.65
 0.7
 0.75
 0.8
 2  4  6  8  10  12  14  16  18  20
Mic
ro F
1
Number of instances
25 snippets
KBOWKWKBOW+KW
 0.5
 0.55
 0.6
 0.65
 0.7
 0.75
 0.8
 2  4  6  8  10  12  14  16  18  20
Mic
ro F
1
Number of instances
50 snippets
KBOWKWKBOW+KW  0.5
 0.55
 0.6
 0.65
 0.7
 0.75
 0.8
 2  4  6  8  10  12  14  16  18  20
Mic
ro F
1
Number of instances
100 snippets
KBOWKWKBOW+KW
Figure 3: Learning curves for KBOW +KW obtained varying the number of snippets used to derive the training and
test sets. From top-left to bottom right: 12, 25, 50, and 100.
Method Micro-F1 Macro-F1
KBOW 75.6 70.6
KW 78.1 73.1
KBOW +KW 80.0 75.4
KNY T 77.6 72.9
KBOW + KNY T 79.7 75.1
IBOP 70.1 62.3
Random 15.4 15.5
Most Frequent 20.7 3.3
Table 1: Comparison among the kernel-based ap-
proaches, the IBOP method (Giuliano and Gliozzo,
2008), the random baseline, and most frequent baseline.
more accurate semantic models than general pur-
pose corpora. Moreover, further experiments have
shown that even a larger number of Wikipedia ar-
ticles (600,000) does not help. On the other hand,
the latent semantic kernels outperform all the other
methods, and their composite (KBOW + KW and
KBOW + KNY T ) perform the best on every con-
figuration, demonstrating the effectiveness of la-
tent semantic kernels in fine-grained classification
of named entities. As in text categorization and
word sense disambiguation, they have proven effec-
tive tools to overcome the limitation of the VSM by
introducing semantic similarity among words.
An important characteristic of the approach is the
small number of training examples required per cat-
egory. This affects both the prediction accuracy and
the computation time (this is generally a common
property of instance-based algorithms). The learn-
ing curves (Figure 3) show that the composite ker-
nel (KBOW +KLS) obtained the same performance
of the bag-of-word kernel (KBOW ) using less than
half of the training examples per category. The
difference is much more pronounced when using
less snippets. The composite kernel KBOW + KW
reaches a plateau around 10 examples, and after 20
examples adding more examples does not signifi-
cantly improve the classification performance.
As most of entities in the People Ontol-
ogy are celebrities, all the snippets retrieved by
GoogleTMgenerally refer to them, alleviating the
problem of ambiguity of proper names. However,
person names are highly ambiguous. In a more real-
istic scenario, the result of a search engine for a per-
son name is usually a mix of contexts about different
entities sharing the same name. In this case, our ap-
proach have to be combined with a system that clus-
ters the search engine result, where each cluster is
assumed to contain all (and only those) contexts that
refer to the same entity. The WePS evaluation cam-
paign on disambiguation of person names (Artiles et
al., 2007; Artiles et al, 2009) has shown that the best
clustering systems achieve a precision of about 90%
206
Scientist Performer Creator Communicator Business Health
Phy Mat Che Bio Soc Act Mus Fil Pai Mus Poe Dra Rep man prof
Phy 118 24 10 4 2 0 0 0 0 0 0 0 0 7 2
Mat 2 33 0 0 1 0 0 0 0 0 1 0 0 3 0
Che 13 2 68 9 2 0 0 0 0 0 0 0 0 5 2
Bio 3 0 7 52 0 0 0 0 1 0 0 0 1 6 6
Soc 0 4 1 1 55 0 0 0 0 0 3 1 1 4 2
Act 0 0 0 0 0 98 5 27 0 0 2 14 0 3 0
Mus 0 0 0 0 0 17 67 0 0 32 1 0 1 2 1
Fil 0 0 0 0 0 13 0 45 0 0 1 4 0 2 0
Pai 0 0 0 1 1 2 0 1 100 0 1 0 0 1 0
Mus 0 0 0 0 0 4 29 0 0 139 0 1 0 0 0
Poe 0 2 0 0 0 0 0 0 7 3 98 26 1 2 3
Dra 0 0 0 1 1 9 0 1 0 1 12 61 1 4 1
Rep 0 0 0 0 0 1 1 0 2 0 0 0 197 22 0
Bus 1 0 1 0 1 0 0 1 0 1 0 0 1 36 0
Hea 0 0 0 8 4 0 1 0 0 0 0 1 1 2 31
Table 3: Confusion matrix of KBOW +KW for the more fine-grained categories grouped according to their top-level
concepts of the People Ontology.
Category Prec. Recall F1
Scientist 95.1 90.1 92.6
Physicist 86.1 70.7 77.6
Mathematician 50.8 82.5 62.9
Chemist 78.2 67.3 72.3
Biologist 68.4 68.4 68.4
Social scientist 82.1 76.4 79.1
Performer 75.7 69.3 72.3
Actor 68.1 65.8 66.9
Musician 65.0 55.4 59.8
Creator 78.9 82.6 80.7
Film Maker 60.0 69.2 64.3
Artist 83.6 85.4 84.5
Painter 90.9 93.5 92.2
Musician 79.0 80.3 79.7
Communicator 91.9 86.7 89.2
Representative 96.6 88.3 92.3
Writer 86.8 84.2 85.5
Poet 82.4 69.0 75.1
Dramatist 56.5 66.3 61.0
Business man 36.4 85.7 51.1
Health professional 64.6 64.6 64.6
micro 80.9 79.6 80.2
macro 75.1 76.3 75.7
Table 2: Results for each category using KBOW +KW .
and a recall of about 70% and that, in the major-
ity of the cases, the number of contexts per entity is
less than 20. This shows that latent semantic kernels
are an effective tool for fine-grained classification of
person names.
Finally, table 3 shows that misclassification er-
rors are largely distributed among categories belong-
ing to the same super-class (i.e., the blocks on the
main diagonal are more densely populated than oth-
ers). As expected, the algorithm is much more accu-
rate for the top-level concepts (i.e., Scientist, Com-
municator, etc.), where the category distinctions are
clearer, while a further fine-grained classification, in
some cases, is even difficult for human annotators.
5 Related Work
Fleischman and Hovy (2002) approach the fine-
grained classification of person instances using su-
pervised learning, where the training set is gener-
ated semi-automatically, bootstrapping from a small
training set. They compare different machine learn-
ing algorithms, providing local features as well as
global semantic information derived from topic sig-
nature and WordNet. Person instances were classi-
fied into one of eight categories.
Cimiano and Vo?lker (2005) present an approach
for the fine-grained classification of entities relying
on the Harris? distributional hypothesis and the vec-
tor space model. They assign a particular instance
to the most similar concept representing both with
lexical-syntactic features extracted from the context
of the instance and the lexicalization of the concept,
respectively. Experiments were performed using a
large ontology with 682 concepts (unfortunately not
yet available).
Tanev and Magnini (2006) proposed a weakly-
supervised method that requires as training data a
list of named entities, without context, for each cat-
egory under consideration. Given a generic syntacti-
cally parsed corpus containing at least each training
entity twice, the algorithm learns, for each category,
207
a feature vector describing the contexts where those
entities occur. Then, it compares the new (unknown)
entity with the so obtained feature vectors, assigning
it to the most similar category. Experiments are per-
formed on a benchmark of 5 sub-classes of location
and 5 sub-classes of person.
Giuliano and Gliozzo (2007) propose an unsuper-
vised approach based on lexical entailment, consist-
ing in assigning an entity to the category whose lex-
icalization can be replaced with its occurrences in
a corpus preserving the meaning. Using unsuper-
vised learning, they obtained slightly worst results
than Tanev and Magnini (2006) on the same bench-
mark.
Picca et al (2007) present an approach for on-
tology learning from open domain text collections,
based on the combination of Super Sense Tagging
and Domain Modeling techniques. The system rec-
ognizes terms pertinent to the domain and assigns
them the correct ontological type.
Giuliano and Gliozzo (2008) present an instance-
based learning algorithm for fine-grained named en-
tity classification based on syntactic features (word-
order, case-marking, agreement, verb tenses, etc.).
Their method can handle much finer distinctions
than previous methods, and it is evaluated on a hi-
erarchical taxonomy of 21 ancestors of people that
was induced from WordNet. One contribution is to
create this richer People Ontology. Another is to
make effective use of the Web 1T 5-gram corpus
(Brants and Franz, 2006) to represent syntactic in-
formation. The main difference between the two ap-
proaches lies primarily in the use of syntactic and
semantic information. Our experiments show that
semantic features do provide richer information than
syntactic ones for a more fine-grained classification
of named entities. In fact, the accuracy improve-
ment achieved by our approach is more evident for
the more specific classes. For example, the improve-
ment in accuracy is about 14% for the class scientist,
while it ranges from 25% to 46% for its sub-classes
(physicist, mathematician, etc.).
Kozareva et al (2008) propose an approach for
person name categorization based on the domain
distribution. They use the information provided by
WordNet Domains to generated lists of words rele-
vant for a given domain, by mapping and ranking the
words from the WordNet glosses to their WordNet
Domains. A named entity is then classified accord-
ing the similarity between the word-domain lists and
the global context in which the entity appears. How-
ever, the evaluation was performed only on 6 person
names using two categories.
Ganti et al (2008) present a method that considers
an entity?s context across multiple documents con-
taining it, and exploiting word n-grams and existing
large list of related entities as features. They gener-
ated training and test data using Wikipedia articles
that contain list of instances. They compare their
system with a single-context classifier, showing that
their approach based on aggregate context perform
better.
Finally, Talukdar et al (2008) propose a graph-
based semi-supervised label propagation algorithm
for acquiring open-domain labeled classes and their
instances from a combination of unstructured and
structured text.
6 Conclusions
We presented an approach to automatic fine-grained
categorization of named entities based on kernel
methods. Entities are represented by aggregating all
contexts in which they occur. We employed latent
semantic kernels to extend the bag-of-words repre-
sentation. The latent semantic models were derived
from Wikipedia and a news corpus We evaluated our
approach on the People Ontology, a multi-level on-
tology of people derived from WordNet. Although
this benchmark is still far from being ?large?, it al-
lows drawing more valid conclusions than past ones.
We significantly outperformed the previous results
on both coarse- and fine-grained classification, al-
though requiring much less training instances. From
this preliminary analysis, it appears that semantic in-
formation is much more effective that syntactic one
for this task, and deriving the semantic model from
Wikipedia gives no significant improvement, as well
as, using a larger number of Wikipedia articles.
Acknowledgments
Claudio Giuliano is supported by the X-Media project (http:
//www.x-media-project.org), sponsored by the Euro-
pean Commission as part of the Information Society Technolo-
gies (IST) programme under EC grant number IST-FP6-026978
and the ITCH project (http://itch.fbk.eu), sponsored
by the Italian Ministry of University and Research and by the
Autonomous Province of Trento.
208
References
Javier Artiles, Julio Gonzalo, and Satoshi Sekine. 2007.
The semeval-2007 weps evaluation: Establishing a
benchmark for the web people search task. In Pro-
ceedings of the Fourth International Workshop on
Semantic Evaluations (SemEval-2007), pages 64?69,
Prague, Czech Republic, June. Association for Com-
putational Linguistics.
Javier Artiles, Julio Gonzalo, and Satoshi Sekine. 2009.
Weps 2 evaluation campaign: overview of the web
people search clustering task. In 2nd Web Peo-
ple Search Evaluation Workshop (WePS 2009), 18th
WWW Conference, Madrid, Spain, April.
Thorsten Brants and Alex Franz. 2006. Web 1T 5-
gram corpus version 1, Linguistic Data Consortium,
Philadelphia.
Philipp Cimiano and Johanna Vo?lker. 2005. Towards
large-scale, open-domain and ontology-based named
entity classification. In Proceedings of RANLP?05,
pages 66? 166?172, Borovets, Bulgaria.
Scott C. Deerwester, Susan T. Dumais, Thoms K. Lan-
dauer, George W. Furnas, and Richard A. Harshman.
1990. Indexing by latent semantic analysis. Jour-
nal of the American Society of Information Science,
41(6):391?407.
Michael Fleischman and Eduard Hovy. 2002. Fine
grained classification of named entities. In Proceed-
ings of the 19th International Conference on Compu-
tational Linguistics, Taipei, Taiwan.
Aldo Gangemi, Roberto Navigli, and Paola Velardi.
2003. Axiomatizing WordNet glosses in the On-
toWordNet project. In Proocedings of the Workshop
on Human Language Technology for the Semantic
Web and Web Services at ISWC 2003, Sanibel Island,
Florida.
Venkatesh Ganti, Arnd C. Ko?nig, and Rares Vernica.
2008. Entity categorization over large document col-
lections. In KDD ?08: Proceeding of the 14th ACM
SIGKDD international conference on Knowledge dis-
covery and data mining, pages 274?282, New York,
NY, USA. ACM.
Alfio Giozzo and Carlo Strapparava. 2005. Domain ker-
nels for text categorization. In Ninth Conference on
Computational Natural Language Learning (CoNLL-
2005), pages 56?63, Ann Arbor, Michigan, June.
Claudio Giuliano and Alfio Gliozzo. 2007. Instance
based lexical entailment for ontology population. In
Proceedings of the 2007 Joint Conference on Empir-
ical Methods in Natural Language Processing and
Computational Natural Language Learning (EMNLP-
CoNLL), pages 248?256.
Claudio Giuliano and Alfio Gliozzo. 2008. Instance-
based ontology population exploiting named-entity
substitution. In Proceedings of the 22nd Interna-
tional Conference on Computational Linguistics (Col-
ing 2008), pages 265?272, Manchester, UK, August.
Alfio Massimiliano Gliozzo, Claudio Giuliano, and Carlo
Strapparava. 2005. Domain kernels for word sense
disambiguation. In Proceedings of the 43rd Annual
Meeting of the Association for Computational Linguis-
tics (ACL?05), pages 403?410, Ann Arbor, Michigan,
June.
Zornitsa Kozareva, Sonia Vazquez, and Andres Montoyo.
2008. Domain information for fine-grained person
name categorization. In 9th International Conference
on Intelligent Text Processing and Computational Lin-
guistics (CICLing 2008), pages 311?321, Haifa, Israel,
17-23 February.
Xin Li and Dan Roth. 2005. Learning question classi-
fiers: the role of semantic information. Natural Lan-
guage Engineering, 12(3):229?249.
I. Dan Melamed and Philip Resnik. 2000. Tagger eval-
uation given hierarchical tag sets. Computers and the
Humanities, pages 79?84.
Davide Picca, Alfio Gliozzo, and Massimiliano Cia-
ramita. 2007. Semantic domains and supersense tag-
ging for domain-specific ontology learning. In David
Evans, Sadaoki Furui, and Chantal Soule?-Dupuy, edi-
tors, Recherche d?Information Assiste?e par Ordinateur
(RIAO), Pittsburgh, PA, USA, May.
B. Scho?lkopf and A. Smola. 2002. Learning with Ker-
nels. MIT Press, Cambridge, Massachusetts.
J. Shawe-Taylor and N. Cristianini. 2004. Kernel Meth-
ods for Pattern Analysis. Cambridge University Press.
Fabian M. Suchanek, Gjergji Kasneci, and Gerhard
Weikum. 2008. YAGO: A large ontology from
wikipedia and wordnet. Elsevier Journal of Web Se-
mantics.
Partha Pratim Talukdar, Joseph Reisinger, Marius Pasca,
Deepak Ravichandran, Rahul Bhagat, and Fernando
Pereira. 2008. Weakly-supervised acquisition of la-
beled class instances using graph random walks. In
Proceedings of the conference on Empirical Methods
in Natural Language Processing (EMNLP), Waikiki,
Honolulu, Hawaii, October 25-27.
Hristo Tanev and Bernardo Magnini. 2006. Weakly su-
pervised approaches for ontology population. In Pro-
ceedings of the Eleventh Conference of the European
Chapter of the Association for Computational Linguis-
tics (EACL-2006), Trento, Italy.
209
