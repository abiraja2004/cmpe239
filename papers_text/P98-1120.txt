SOLVING ANALOGIES  ON WORDS:  AN ALGORITHM 
Yves  Lepage 
ATR Interpreting Telecommunications Research Labs, 
Hikaridai 2-2, Seika-tyS, SSraku-gun, KySto 619-0288, Japan 
lepage@itl, atr. co. jp 
I n t roduct ion  
To introduce the algorithm presented in this pa- 
per, we take a path that is inverse to the his- 
torical development of the idea of analogy (se e 
(Hoffman 95)). This is necessary, because a 
certain incomprehension is faced when speak- 
ing about linguistic analogy, i.e., it is generally 
given a broader and more psychological defini- 
tion. Also, with our proposal being computa- 
tional, it is impossible to ignore works about 
analogy in computer science, which has come 
to mean artificial intelligence. 
1 A Survey  of Works  on Ana logy  
This paper is not intended to be an exhaustive 
study. For a more comprehensive study on the 
subject, see (Hoffman 95). 
1.1 Metaphors ,  or Impl ic it  Analogies 
Beginning with works in psychology and arti- 
ficial intelligence, (Gentner 83) is a milestone 
study of a possible modeling of analogies uch 
as, "an atom is like the solar system" adequate 
for artificial intelligence. In these analogies, two 
domains are mapped, one onto the other, thus 
modeling of the domain becomes necessary. 
Y sun-,nucleus 
planet-~Yelectron 
In addition, properties (expressed by clauses, 
formulae, etc.) are transferred from one domain 
onto the other, and their number somehow de- 
termines the quality of the analogy. 
aZZracts(sun, J~aZZracZs(nucleus, 
planeZ) elecZron) 
moremassive(sun, -~fmoremassive(nucleus, 
planet) elecZron) 
However, Gentner's explicit description of 
sentences as "an A is like a B" as analo- 
gies is subject to criticism. Others (e.g. 
(Steinhart 94)) prefer to call these sentences 
metaphors 1, the validity of which rests on sen- 
tences of the kind, "A is to B as C is to D", for 
which the name analogy 2 is reserved. In other 
words, some metaphors are supported by analo- 
gies. For instance, the metaphor, "an atom is 
like the solar system", relies on the analogy, "an 
electron is to the nucleus, as a planet is to the 
sun"  .3 
The answer of the AI community is com- 
plex because they have headed irectly to more 
complex problems. For them, in analogies or 
metaphors (Hall 89): 
two different domains appear 
for both domains, modeling of a knowledge- 
base is necessary 
mapping of objects and transfer of proper- 
ties are different operations 
the quality of analogies has to be evalu- 
ated as a function of the strength (number, 
truth, etc.) of properties transferred. 
We must drastically simplify all this and 
enunciate a simpler problem (whose resolution 
may not necessarily be simple). This can be 
aclfieved by simphfying data types, and conse- 
quently the characteristics of the problem. 
alf the fact that properties are carried over char- 
acterises uch sentences, then etymologically they are 
metaphors: In Greek, pherein: to carry; meta-: between, 
among, with, after. "Metaphor" means to transfer, to 
carry over. 
2In Greek, logos, -logio: ratio, proportion, reason, dis- 
course; ann-: top-down, again, anew. "Analog3," means 
the same proportions, similar ratios. 
3This complies with Aristotle's definitions in the 
Poetics. 
728 
1.2 Mul t ip l ic i ty  vs Unic i ty  of Domains  
In the field of natural anguage processing, there 
have been plenty of works on pronunciation of 
English by analogy, some being very much con- 
cerned with reproducing human behavior (see 
(Damper & Eastmond 96)). Here is an illustra- 
tion of the task from (Pirelli & Federici 94): 
vane A /vejn/ 
,~ g .L h 
sane 1-~ x = /sejn/ 
Similarly to AI approaches, two domains ap- 
pear (graphemic and phonemic). Consequently, 
the functions f,  g and h are of different ypes 
because their domains and ranges are of differ- 
ent data types. 
Similarly to AI again, a common feature in 
such pronouncing systems is the use of data 
bases of written and phonetic forms. Regard- 
ing his own model, (Yvon 94) comments that: 
The \[...\] model crucially relies upon the 
existence of numerous paradigmatic rela- 
fionsh.ips in lexical data bases. 
Paradigmatic relationships being relation- 
ships in which four words intervene, they are 
in fact morphological nalogies: "reaction is to 
reactor, as faction is to factor". 
reactor/-~ reactio.n 
? Lg  l g  
factor  ~ fact ion 
Contrasting sharply with AI approaches, 
morphological nalogies apply in only one do- 
main, that of words. As a consequence, 
the number of relationships between analogical 
terms decreases from three (f, g and h) to two 
(f  and g). Moreover, because all four terms 
intervening in the analogy are from the same 
domain, the domains and ranges of f and g 
are identical. Finally, morphological nalogies 
can be regarded as simple equations indepen- 
dent of any knowledge about the language in 
which they are written. This standpoint elim- 
inates the need for any knowledge base or dic- 
tionary. 
\] 
reactor --, reaction 
~g ~g 
factor ~ x? 
1.3 Unic i ty  vs Mult ip l ic i ty  of Changes 
Solving morphological analogies remains diffi- 
cult because several simultaneous changes may 
be required to transform one word into a sec- 
ond (for instance, doer ---, undo requires the 
deletion of the suffix -er and the insertion of 
the prefix un-). This problem has yet to be 
solved satisfactorily. For example, in (Yvon 94), 
only one change at a time is allowed, and 
multiple changes are captured by successive 
applications of morphological analogies (cas- 
cade model). However, there are cases in the 
morphology of some languages where multiple 
changes at the same time are mandatory, for 
instance in semitic languages. 
"One change at a time", is also found in (Na- 
gao 84) for a translation method, called trans- 
lation by analogy, where the translation of an 
input sentence is an adaptation of translations 
of similar sentences retrieved from a data base. 
The difficulty of handling multiple changes is 
remedied by feeding the system with new exam- 
ples differing by only one word commutation at
a time. (Sadler and Vendelmans 90) proposed a
different solution with an algebra ontrees: dif- 
ferences on strings are reflected by adding or 
subtracting trees. Although this seems a more 
convincing answer, the use of data bases would 
resume, as would the multiplicity of domains. 
Our goal is a true analogy-solver, i.e., an algo- 
rithm which, on receiving three words as input, 
outputs a word, analogical to the input. For 
that, we thus have to answer the hard problem 
of: (1) performing multiple changes (2) using 
a unique data-type (words) (3) without dictio- 
nary nor any external knowledge. 
1.4 Analogies on Words 
We have finished our review of the problem and 
ended up with what was the starting point of 
our work. In linguistic works, analogy is de- 
fined by Saussure, after Humboldt and Baudoin 
de Courtenay, as the operation by which, given 
two forms of a given word, and only one form 
of a second word, the missing form is coined 4, 
"honor is to hon6rem as 6r6tor is to 6rSt6rem" 
noted 6r~t6rem : 6rdtor = hon6rem : honor. 
This is the same definition as the one given by 
Aristotle himself, "A is to B as C is to D", pos- 
tulating identity of types for A, B, C, and D. 
4Latin: 6rdtor (orator, speaker) and honor (honour) 
nominative singular, 5rat6rern and honfrem accusative 
singular. 
729 
However, while analogy has been mentioned 
and used, algorithmic ways to solve analogies 
seem to have never been proposed, maybe be- 
cause the operation, is so "intuitive". We (Lep- 
age & Ando 96) recently gave a tentative com- 
putational explanation which was not always 
valid because false analogies were captured. It 
did not constitute an algorithm either. 
The only work on solving analogies on words 
seems to be Copycat ((Hofstadter et al 94) 
and (Hoffman 95)), which solves such puzzles 
as: abc : abbccc = ijk : x. Unfortunately it
does not seem to use a truly dedicated algo- 
rithm, rather, following the AI approach, it uses 
a forlnalisation of the domain with such func- 
tions as, "previous in aZphabe'c", "rank in 
aZphabel:", etc. 
2 Foundat ions  of  the  A lgor i thm 
2.1 The  First Term as an Axis 
(Itkonen and Haukioja 97) give a program in 
Prolog to solve analogies in sentences, asa refu- 
tation of Chomsky, according to whom analogy 
would not be operational in syntax, because it
dehvers non-gralnmatical sentences. That anal- 
ogy would apply also to syntax, was advocated 
decades ago by Hermann Paul and Bloomfield. 
Chomsky's claim is unfair, because it supposes 
that analogy applies only on the symbol evel. 
Itkonen and Haukioja show that analogy, when 
controlled by some structural level, does deliver 
perfectly grammatical sentences. What is of 
interest o us, is the essence of their method, 
which is the seed for our algorithm: 
Sentence D is formed by going through 
sentences B and C one element at a time 
and inspecting the relations of each ele- 
ment to the structure of sentence A (plus 
the part of sentence D that is ready). 
Hence, sentence A is the axis against which sen- 
tences B and C are compared, and by opposition 
to which output sentence D is built. 
rextder : u_~nreadoble = d"-oer : x ~ x = un~ab le  
The method will thus be: (a) look for those 
parts which are not common to A and B on one 
hand, and not common to A and C on the other 
and (b) put them together in the right order. 
2.2 Common Subsequenees 
Looking for common subsequences of A and B 
(resp. A and C) solves problem (a) by comple- 
mentation. (Wagner & Fischer 74) is a method 
to find longest common subsequences by com- 
puting edit distance matrices, yielding the min- 
imal number of edit operations (insertion, dele- 
tion, substitution) necessary to transform one 
string into another. 
For instance, the following matrices give the 
distance between like and unlike on one hand, 
and between like and known on the other hand, 
in their right bottom cells: dist(l ike, unlike) = 2 
and dist( Iike, known) = 5 
u n l i k e k n o w n 
! 1 2 2 3 4 5 l 1 2 3 4 5 
i 2 2 3 2 3 4 i 2 2 3 4 5 
k 3 3 3 3 2 3 k 2 3 3 4 5 
e 4 4 4 4 3 2 e 3 3 4 4 5 
2.3 Simi l i tude between Words 
We call simi l i tude between A and B the length 
of their longest common subsequence. It is also 
equal to the length of A, minus the number of 
its characters deleted or replaced to produce B. 
This number we caU pdist(A,B), because it is 
a pseudo-distance, which can be computed ex- 
actly as the edit distances, except that inser- 
tions cost 0. 
sire(A, B) = I A \[ - pdist(A, B) 
For instance, pdist(unl ike,  like) = 2, while 
pdist (  like, unlike) = O. 
l i k e 
u 1 1 1 1 u n l i k e 
n 2 2 2 2 
l 2 2 2 2 I 1 1 0 0 0 0 
i 3 2 2 2 i 2 2 1 0 0 0 
k 4 3 2 2 k 3 3 2 1 0 0 
e 5 4 3 2 e 4 4 3 2 1 0 
Characters inserted into B or C may be left 
aside, precisely because they are those charac- 
ters of B and C, absent from A, that we want 
to assemble into the solution, D. 
As A is the axis in the resolution of analogy, 
graphically we make it the vertical axis around 
which the computation of pseudo-distances 
takes place. For instance, for l i ke :un l i ke  = 
k,'r~OW~ : X, 
n w o n k u n 1 i k e 
1 I I I i I 1 I 0 0 0 0 
2 2 2 2 2 i 2 2 1 0 0 0 
2 2 2 2 2 k 3 3 2 1 0 0 
3 3 3 3 3 e 4 4 3 2 i 0 
730 
2.4 The  Coverage  Const ra in t  
It is easy to verify that there is no solution to an 
analogy if some characters of A appear neither 
in B nor in C. The contrapositive says that, 
for an analogy to hold, any character of A has 
to appear in either B or C. Hence, the sum 
of the similitudes of A with B and C must be 
greater than or equal to its length: sim(A, B) + 
sire(A, C) >_ I A I, or, equivalently, 
I d I ~ pdist(d, B) + pdist(d, C) 
When the length of A is greater than the sum 
of the pseudo-distances, some subsequences of 
A are common to all strings in the same order. 
Such subsequences have to be copied into the 
solution D. We call com(A, B, C, D) the sum 
of the length of such subsequences. The del- 
icate point is that this sum depends precisely 
on the solution D being currently built by the 
algorithnL 
To summarise, for analogy A : B = C : D to 
hold, the following constraint must be verified: 
I A I = pdist(A, B)+pdist(A, C)+com(A, B, C, D) 
3 The  A lgor i thm 
3.1 Computat ion  of  Mat r i ces  
Our method relies on the computation of two 
pseudo-distance matrices between the three first 
terms of the analogy. A result by (Ukkonen 85) 
says that it is sufficient o compute a diagonal 
band plus two extra bands on each of its sides in 
the edit distance matrix, in order to get the ex- 
act distance, if the value of the overall distance 
is known to be less than some given thresh- 
old. This result applies to pseudo-distances, 
and is used to reduce the computation of the 
two pseudo-distance matrices. The width of the 
extra bands is obtained by trying to satisfy the 
coverage constraint with the value of the current 
pseudo-distance in the other matrix. 
proc compute_matrices(A, B, C, pdAB,pdAc) 
compute pseudo-distances matrices with 
extra bands of pdAB/2 and pdAc/2 
i f  \ [d l>_  pd is t (d ,B)+ pdist(A,C) 
main component 
else 
compute.anatrices(A, B, C, 
max(\[ A I - pdist(d, C),pdAB + 1), 
xnax(I A I - pdist(A, B),pdac + x)) 
end if 
end proc COlnpute_matrices 
3.2 Ma in  Component  
Once enough in the matrices has been com- 
puted, the principle of the algorithm is to follow 
the paths along which longest common subse- 
quences are found, simultaneously in both ma- 
trices, copying characters into the solution ac- 
cordingly. At each time, the positions in both 
matrices must be on the same horizontal line, 
i.e. at a same position in A, in order to ensure 
a right order while building the solution, D. 
Determining the paths is done by compar- 
ing the current cell in the matrix with its three 
previous ones (horizontal, vertical or diagonal), 
according to the technique in (Wagner & Fis- 
cher 74). As a consequence, paths are followed 
from the end of words down to their begin- 
ning. The nine possible combinations (three di- 
rections in two matrices) can be divided into 
two groups: either the directions are the same 
in both matrices, or they are different. 
The following sketches the al- 
gorithm, corn(A, B,C, D) has been initialised 
to: I AI - (pdist(d,B)  + pdist(d,C)) ,  iA, is 
and ic are the current positions in A, B and 
C. dirAB (resp. dirAc) is the direction of the 
path in matrix A x B (resp. A ? C) from the 
current position. "copy" means to copy a char- 
acter from a word at the beginning of D and to 
move to the previous character in that word. 
i f  constraint(iA, iB, ic, corn(A, B, C, D)) 
case:  dirAB = dirAc = diagonal 
i f  A\[iA\] = B\[iB\] = C\[ic\] 
decrement corn(A, B, C, D) 
end if 
copy B\[iB\] + C\[ic\] - A\[iA\] ~
case:  dirAB = dirAC = horizontal 
copy charb/min(pdist(A\[1..iA\], B\[1..iB\]), 
pdist( A\[1..iA\], C\[1..ic\]) ) 
case:  dirAB = dirAc = vertical 
move only in A (change horizontal line) 
case: dirAB # dirAc 
i f  dirAB = horizontal 
copy B\[iB\] 
aIn this case, we move in tile three words at the 
same time. Also, the character arithmetics factors, 
in view of generalisations, different operations: if the 
three current characters inA, B and C are equal, copy 
this character, otherwise copy that character f om B 
or C that is different from the one in A. If all current 
characters are different, his is a failure. 
bThe word with less similitude with A is chosen, so 
as to make up for its delay. 
731 
e\].se ?f  d i rAB = vertical 
move in A and C 
e1$? same thing by exchanging B and C 
end ?f 
end if 
3.3 Ear ly  Terminat ion  in Case o f  
Failure 
Complete computation of both matrices is not 
necessary to detect a failure. It is obvious when 
a letter in A does not appear in B or C. This 
may already be detected before any matrix com- 
putation. 
Also, checking the coverage constraint allows 
the algorithm to stop as soon as non-satisfying 
moves have been performed. 
3.4 An  Example  
We will show how the analogy l ike : unl ike = 
known : x is solved by the algorithm. 
The algorithm first verifies that all letters 
of l ike are present either in unl ike or known.  
Then, the minimum computation is done for the 
pseudo-distances matrices, i.e. only the mini- 
mal diagonal band is computed. 
e k i l n u k n o w n 
0 1 1 1 1 1 
0 1 2 i 2 2 
0 1 2 k 3 3 
0 1 2 e 4 4 
As the coverage constraint is verified, the 
main component is called. It follows the paths 
noted by values in circles in the matrices. 
e k i 1 n u k n o w n 
? ? i ?? 
1 2 i 2 ~) 
The succession of moves triggers the following 
copies into the solution: 
dirAB 
diagonal 
diagonal 
diagonal 
diagonal 
horizontal 
horizontal 
horizontal 
d i rAc  copy 
diagonal n 
diagonal w 
diagonal o 
diagonal n 
horizontal k 
diagonal n 
diagonal u 
At each step, the coverage constraint being veri- 
fied, finally, the solution x = unknown is ouptut. 
4 P roper t ies  and  Coverage  
4.1 Trivial Cases, Mir ror ing  
Trivial cases of analogies are, of course, solved 
by the algorithm, like: A :A=A:x  =~ x= 
A or A:A  = C :x  ~ x = C. Also, by 
construction, A :B= C:x  and A: C=B:x  
deliver the same solution. 
With this construction, mirroring poses no 
problem. If we note A the mirror of word A, 
then A:B=C:D ?~ A :B=C:D.  
4.2 Pref ix ing,  Suffixing, Paral lel 
Inf ix ing 
Appendix A lists a number of examples, actu- 
ally solved by the algorithm, from simple to 
complex, which illustrate the algorithm's per- 
formance. 
4.3 Redup l i ca t ion  and Permutat ion  
The previous form of the algorithm does not 
produce redupl ication. This would be neces- 
sary if we wanted to obtain, for example, plu- 
rals in IndonesianS: orang:  orang-orang = 
burung : x =v x = burung-burung . In this 
case, our algorithm delivers, x = orang-burung,  
because preference is given to leave prefixes un- 
changed. However, the algorithm may be easily 
modified so that it applies repeatedly so as to 
obtain the desired solution 6. 
Permutation is not captured by the algo- 
rithm. An example (q with a and u) in Proto- 
semitic is: yaqti lu : yuqtiIu = qatal : qutaI. 
4.4 Language- independence/Code-  
dependence  
Because the present algorithm performs compu- 
ration only on a symbol evel, it may be applied 
to any language. It is thus language indepen- 
dent. This is fortunate, as analogy in linguistics 
certainly derives from a more general psycho- 
logical operation ((Gentner 83), (Itkonen 94)), 
which seems to be universal among human be- 
ings. Examples in Section A illustrate the lan- 
guage independence of the algorithm. 
Conversely, the symbols determine the granu- 
larity of the analogies computed. Consequently, 
a commutation not reflected in the coding sys- 
tem will not be captured. This may be illus- 
trated by a Japanese xample in three different 
Sorang (human being) singular, orang-orang plural, 
burung (bird). 
SSi,nilarly, it is easy to apply the algorithm in a 
transducer-like way so that it modifies, by analogy, parts 
of an input string. 
732 
codings: the native writing system, the Hep- 
burn transcription and the official, strict rec- 
omlnendation (kunrei). 
Kanji/Kana: ~-9 : ~#~ ~-9- = ~ < : x 
Hepburn: matsu  : maeh imasu  = hataraku  : x 
Kunrei: matu : mat imasu  = hataraku  : x 
x = hatarak imasu  
The algorithm does not solve the first two analo- 
gies (solutions: ~-~ $ #,  hatarok imasu)  be- 
cause it does not solve the elementary analogies, 
-9 :~ = < : ~ and t su :ch i=ku:k i ,  which 
are beyond the symbol evel r. 
More generally speaking, the interaction of 
analogy with coding seems the basis of a fre- 
quent reasoning principle: 
f (A )  : f (B )  = f (C)  : x ~ A : B==_ C : f - t  (x )  
Only the first analogy holds on the symbol evel 
and, as is, is solved by our algorithm, f is an 
encoding function for which an inverse exists. 
A striking application of this principle is the 
resolution of some Copycat puzzles, like: 
abc : abd = i jk  : x => x= ij I 
Using a binary ASCII representation, which re- 
flects sequence in the alphabet, our algorithm 
produces: 
011000010110001001100011 : 011000010110001001100100 
---~ 011010010110101001101011 : X 
=:~ X ~ 011010010110101001101100 ~ ijl 
Set in this way, even analogies of geometrical 
type can be solved under a convenient represen- 
tation. 
An adequate description (or coding), with no 
reduplication, is: 
ob j (b ia )& . ob j (~maU)C ob j (b ig )_  ob j (b ig )~ :x 
ob j=c i rc le"  ~:ob j=c i rc le  - ob j=square  
This is actually solved by our algorithm: 
obj( , .U)c obj(bia) 
x = &ob j=square  
~One could imagine extending the algorithm by 
parametrising it with such predefined analogical 
relations. 
In other words, coding is the key to many 
analogies. More generally we follow (Itkonen 
and Haukioja 97) when they claim that analogy 
is an operation against which formal represen- 
tations should also be assessed. But for that, of 
course, we needed an automatic analogy-solver. 
Conc lus ion  
We have proposed an algorithm which solves 
analogies on words, i .e. when possible it coins 
a fourth word when given three words. It re- 
lies on the computation of pseudo-distances be- 
tween strings. The verification of a constraint, 
relevant for analogy, limits the computation of 
matrix cells, and permits early termination in 
case of failure. 
This algorithm has been proved to handle 
many different cases in many different lan- 
guages. In particular, it handles parallel infix- 
ing, a property necessary for the morphological 
description of semitic languages. Reduplication 
is an easy extension. 
This algorithm is independent of any lan- 
guage, but not coding-independent: it consti- 
tutes a trial at inspecting how much can be 
achieved using only pure computation on sym- 
bols, without any external knowledge. We are 
inclined to advocate that much in the matter of 
usual analogies, is a question of symbolic rep- 
resentation, i .e. a question of encoding into a 
form solvable by a purely symbolic algorithm 
like the one we proposed. 
A Examples 
The following examples how actual resolution 
of analogies by the algorithm. They illustrate 
what the algorithm achieves on real linguistic 
examples. 
A.1 Inser t ion  or de let ion of  pref ixes or 
suffixes 
Latin: oratorem : o ra tor  = honorem : x 
x = honor  
French: rdpress ion  : rdp . ress ionna i re  = rdact ion  : x 
x = rdact ionna i re  
Malay: t ingga l  : ke t ingga lan  = d~tduk : x 
x = kedudukan 
Chinese: ~:4~ : ~$~ = ~ :x 
x = ~ 
733 
A.2 Exchange o f  prefixes or suffixes 
English: wolf: wolves = leaf: x 
x = leaves 
Malay: kawan : mengawani = keliting : x 
x = mengelil ingi 
Malay: keras : mengeraskan = kena : x 
X ---- 17zengef la \ ]za l~ 
Polish: wyszedteg : wyszIa.4 = poszedted : x 
x = posztad 
A.3 Infixing and umlaut 
Japanese: ~ :~@Y~ =~7o :x 
x= ,~@~ 
German: lang : Idngste = scharf : x 
x = schdrfste 
German: f l iehen : er floh = schlie~en : x 
x - er sehlofl 
Polish: zgubiony : zgubieni = zmartwiony : x 
x = zmartwieni 
Akkadian: uka~.~ad : uktanaggad = ugak.~ad : x 
x = u.?tanakgad 
A.4 Parallel infixing 
Proto-semitic: yasriqu : sariq = yanqinm : x 
x = naqim 
Arabic: huziht : huzdI= sudi'a : x 
x = sud(~' 
Arabic: arsaIa : mursitun = asIama : x 
x = m.usIimun 
References 
Robert I. Damper & John E.G. Eastman 
Pronouncing Text by Analogy 
Proceedings of COLING-96, Copenhagen, 
August 1996, pp. 268-269. 
Dedre Gentner 
Structure Mapping: A Theoretical Model for 
Analogy 
Cognitive Science, 1983, vol. 7, no 2, pp. 155- 
170. 
Rogers P. Hall 
Computational Approaches to Analogical 
Reasoning: A Comparative Analysis 
Artif icial Intelligence, Vol. 39, No. 1, May 
1989, pp. 39-120. 
Douglas Hofstadter and the Fluid Analogies Re- 
search Group 
Fluid Cbncepts and Crexttive Analogies 
Basic Books, New-York, 1994. 
Robert R. Hoffman 
Monster Analogies 
AI  Magazinc, Fall 1995, vol. 11, pp 11-35. 
Esa Itkonen 
Iconicity, analogy, and universal grammar 
Journal of Pragmatics, 1994, vol. 22, pp. 37- 
53. 
Esa Itkonen and Jussi Haukioja 
A rehabilitation of analogy in syntax (and 
elsewhere) 
in AndrOs Kert~sz (ed.) Metalinguistik im 
Wandeh die kognitive Wende in Wis- 
senschaflstheorie und Linguistik Frankfurt 
a/M, Peter Lang, 1997, pp. 131-177. 
Yves Lepage & Ando Shin-Ichi 
Saussurian analogy: a theoretical account 
and its application 
Precedings of COLING-96, Copenhagen, 
August 1996, pp. 717-722. 
Nagao Makoto 
A Framework of a Mechanical Translation be- 
tween Japanese and English by Analogy Prin- 
ciple 
in Artificial ~ Human Intelligence, Alick 
Elithorn and Ranan Banerji eds., Elsevier 
Science Publishers, NATO 1984. 
Vito Pirelli & Stefano Federici 
"Derivational" paradigms in morphonology 
Proceedings of COLING-94, Kyoto, August 
1994, Vol. I, pp 234-240. 
Victor Sadler and Ronald Vendelmans 
Pilot implementation of a bilingual knowl- 
edge bank 
Proceedings of COLING-90, Helsinki, 1990, 
vol 3, pp. 449-451. 
Eric Steinhart 
Analogical Truth Conditions for Metaphors 
Metaphor and Symbolic Activity, 1994, 9(3), 
pp 161-178. 
Esko Ukkonen 
Algorithms for Approximate String Matching 
h~formation and Control, 64, 1985, pp. 100- 
118. 
Robert A. Wagner and Michael J. Fischer 
The String-to-String Correction Problem 
Journal for the Association of Computing 
Machinery, Vol. 21, No. 1, January 1974, pp. 
168-173. 
Frangois Yvon 
Paradigmatic Cascades: a Linguistically 
Sound Model of Pronunciation by Analogy 
Proceedings of A CL-EACL-97, Madrid, 1994, 
pp 428-435. 
734 
