Proceedings of the 2010 Named Entities Workshop, ACL 2010, pages 48?52,
Uppsala, Sweden, 16 July 2010. c?2010 Association for Computational Linguistics
Abstract
The system presented in this paper uses a 
combination of two techniques to directly 
transliterate from grapheme to grapheme. The 
technique makes no language specific as-
sumptions, uses no dictionaries or explicit 
phonetic information; the process transforms 
sequences of tokens in the source language 
directly into to sequences of tokens in the 
target.  All the language pairs in our experi-
ments were transliterated by applying this 
technique in a single unified manner. The 
approach we take is that of hypothesis re-
scoring to integrate the models of two state-
of-the-art techniques: phrase-based statistical 
machine translation (SMT), and a joint multi-
gram model. The joint multigram model was 
used to generate an n-best list of translitera-
tion hypotheses that were re-scored using the 
models of the phrase-based SMT system. The 
both of the models? scores for each hypothesis 
were linearly interpolated to produce a final 
hypothesis score that was used to re-rank the 
hypotheses. In our experiments on develop-
ment data,  the combined system was able to 
outperform both of its component systems 
substantially.  
1 Introduction
In statistical machine translation the re-scoring 
of hypotheses produced by a system with addi-
tional models that  incorporate information not 
available to the original system has been shown 
to be an effective technique to improve system 
performance (Paul et al, 2006). Our approach 
uses a re-scoring technique to integrate the 
models of two transliteration systems that are 
each capable in their own right: a phrase-based 
statistical machine translation system (Koehn et 
al., 2003), and a joint  multigram model (Deligne 
and Bimbot, 1995; Bisani and Ney, 2008). 
In this work we treat the process of translit-
eration as a process of direct  transduction from 
sequences of tokens in the source language to 
sequences of tokens in the target language with 
no modeling of the phonetics of either source or 
target  language (Knight and Graehl, 1997). Tak-
ing this approach allows for a very general 
transliteration system to be built  that does not 
require any language specific knowledge to be 
incorporated into the system (for some language 
pairs this may not be the best strategy since lin-
guistic information can be used to overcome 
issues of data sparseness on smaller datasets).  
2 Component Systems
For this shared task we chose to combine two 
systems through a process of re-scoring. The 
systems were selected because of their expected 
strong level of performance (SMT systems have 
been used successfully in the field, and joint 
multigram models have performed well both in 
grapheme to phoneme conversion and Arabic-
English transliteration). Secondly, the joint mul-
tigram model relies on key features not present 
in the SMT system, that is the history of bilin-
gual phrase pairs used to derive the target. For 
this reason we felt the systems would comple-
ment each other well. We now briefly describe 
the component systems.
2.1 Joint Multigram Model
The joint  multigram approach proposed by (De-
ligne and Bimbot, 1995) has arisen as an exten-
sion of the use of variable-length n-grams (mul-
tigrams) in language modeling. In a joint  multi-
gram, the units in the model consist of multiple 
input  and output symbols. (Bisani and Ney, 
2008) refined the approach and applied to it 
grapheme-to-phoneme conversion, where its 
performance was shown to be comparable to 
state-of-the-art systems. The approach was later 
applied to Arabic-English transliteration (Dese-
laers et al, 2009) again with promising results.
Joint multigram models have the following 
characteristics:
?
The symbols in the source and target are 
co-segmented
Transliteration using a Phrase-based Statistical Machine Translation 
System to Re-score the Output of a Joint Multigram Model 
Andrew Finch
NICT
3-5 Hikaridai
Keihanna Science City
619-0289 JAPAN
andrew.finch@nict.go.jp
Eiichiro Sumita
NICT
3-5 Hikaridai
Keihanna Science City
619-0289 JAPAN
eiichiro.sumita@nict.go.jp
48
-Maximum likelihood training using an 
EM algorithm (Deligne and Bimbot, 
1995)
?
The probability of sequences of joint mul-
tigrams is modeled using an n-gram 
model
In these respects the model can be viewed as 
a close relative of the joint source channel 
model proposed by (Li et  al., 2004) for translit-
eration.
2.2 Phrase-based SMT
It  is possible to view the process of translitera-
tion as a process of translation at the character 
level, without  re-ordering. From this perspective 
it is possible to directly employ a phrase-based 
SMT  system in the task of transliteration (Finch 
and Sumita, 2008; Rama and Gali, 2009). A 
phrase-based SMT system has the following 
characteristics:
?
The symbols in the source and target are 
aligned one to many in both directions. 
Joint sequences of source and target sym-
bols are heuristically extracted given 
these alignments
?
Transliteration is performed using a log-
linear model with weights tuned on de-
velopment data
?
The models include: a translation model 
(with 5 sub-models), and a target lan-
guage model
The bilingual phrase-pairs are analogous to 
the joint  multigrams, however the translation 
model of the SMT system doesn?t use the con-
text of previously translated phrase-pairs, in-
stead relying on a target language model.
3 Experimental Conditions
3.1 SMT Decoder
In our experiments we used an in-house phrase-
based statistical machine translation decoder 
called CleopATRa. This decoder operates on 
exactly the same principles as the publicly 
available MOSES decoder (Koehn et al, 2003). 
Our decoder was modified to be able to decode 
source sequences with reference to a target se-
quence; the decoding process being forced to 
generate the target. The decoder was also con-
figured to combine scores of multiple deriva-
tions yielding the same target  sequence. In this 
way the models in the decoder were used to de-
rive scores used to re-score the n-best (we used 
n=20 for our experiments) hypotheses generated 
by the joint  multigram model. The phrase-
extraction process was symmetrized with re-
spect  to token order using the technique pro-
posed in (Finch and Sumita, 2010). In order to 
adapt  the SMT system to the task of translitera-
tion, the decoder was constrained decode in a 
monotone manner, and furthermore during train-
ing, the phrase extraction process was con-
strained such that  only phrases with monotone 
order were extracted in order to minimize the 
effects of errors in the word alignment process.
In a final step the scores from both systems 
were linearly interpolated to produce a single 
integrated hypothesis score. The hypotheses 
were then re-ranked according to this integrated 
score for the final submission.
3.2 Joint Multigram model
For the joint  multigram system we used the pub-
licly available Sequitur G2P  grapheme-to-
phoneme converter (Bisani and Ney, 2008). The 
system was used with its default settings, and 
pilot experiments were run on development  data 
to determine appropriate settings for the maxi-
mum size of the multigrams. The results for the 
English-to-Japanese task are shown in Figure 1. 
As can be seen in the figure, the system rapidly 
improves to a near-optimal value with a maxi-
mum multigram size of 4. No improvement  at 
all was observed for sizes over 7. We therefore 
chose a maximum multigram size of 8 for the 
experiments presented in this paper, and for the 
systems entered in the shared task.
3.3 Pre-processing
In order to reduce data sparseness we took the 
decision to work with data in only its lowercase 
form.
We  chose not  to perform any tokenization or 
phonetic mapping for any of the language pairs 
Figure 1: The effect on F-score by tuning with 
respect to joint multigram size
0.3
0.4
0.6
0.7
0.9
1 2 3 4 5 6 7 8 9 10
F
-
S
c
o
r
e
Joint Multigram Size
49
in the shared task. We adopted this approach 
because:
?
It  allowed us to have a single unified 
approach for all language pairs
?
It  was in the spirit  of the shared task, as 
it did not  require extra knowledge out-
side of the supplied corpora
3.4 Handling Multi-Word Sequences
The data for some languages contained some 
multi-word sequences. To handle these we had 
to consider the following strategies:
?
Introduce a <space> token into the se-
quence, and treat  it  as one long charac-
ter sequence to transliterate; or
?
Segment the word sequences into indi-
vidual words and transliterate these in-
dependently, combining the n-best hy-
pothesis lists for all the individual words 
in the sequence into a single output se-
quence.
 We adopted both approaches: for those multi-
word sequences where the number of words in 
the source and target matched, the latter ap-
proach was taken; for those where the numbers 
of source and target words differed, the former 
approach was taken. The decoding process for 
multi-word sequences is shown in Figure 2. 
During recombination, the score for the target 
word sequence was calculated as the product of 
the scores of each hypothesis for each word. 
Therefore a search over all combinations of hy-
potheses is required. In almost all cases we were 
able to perform a full search. For the rare long 
word sequences in the data, a beam search strat-
egy was adopted.
3.5 Building the Models
For the final submissions, all systems were 
trained on the union of the training data and de-
velopment data. It was felt that the training set 
was sufficiently small that  the inclusion of the 
development  data into the training set  would 
yield a reasonable boost  in performance by in-
creasing the coverage of the systems. All tunable 
parameters were tuned on development data us-
ing systems built  using only the training data. 
Under the assumption that  these parameters 
would perform well in the systems trained on 
the combined development/training corpora, 
these tuned parameters were transferred directly 
to the systems trained on all available data.
3.6 Parameter Tuning
The SMT  systems were tuned using the mini-
mum error rate training procedure introduced in 
(Och, 2003). For convenience, we used BLEU 
as a proxy for the various metrics used in the 
shared task evaluation. The BLEU score is 
commonly used to evaluate the performance of 
Figure 2: The transliteration process for multi-word sequences
Word 1 Word 2 Word m
Segment into individual words and transliterate each word independently
T
r
a
n
s
l
i
t
e
r
a
t
e
T
r
a
n
s
l
i
t
e
r
a
t
e
T
r
a
n
s
l
i
t
e
r
a
t
e
n-best
hypothesis 1
hypothesis 2
...
hypothesis n
n-best
hypothesis 1
hypothesis 2
...
hypothesis n
n-best
hypothesis 1
hypothesis 2
...
hypothesis n
Search for the best path
Figure 3: The effect on the F-score of the integrated 
system by tuning with respect to the SMT system?s 
interpolation weight
0.83
0.84
0.85
0 0.2 0.4 0.6 0.8 1.0
F
-
S
c
o
r
e
SMT System Interpolation Weight
50
machine translation systems and is a function of 
the geometric mean of n-gram precision. The 
use of BLEU score as a proxy has been shown 
to be a reasonable strategy for the metrics used 
in these experiments (Finch and Sumita, 2009). 
Nonetheless, it is reasonable to assume that  one 
would be able to improve the performance in a 
particular evaluation metric by doing minimum 
error rate training specifically for that metric. 
The interpolation weight  was tuned by a grid 
search to find the value that gave the maximal f-
score (according to the official f-score evalua-
tion metric for the shared task) on the develop-
ment data, the process for English-Japanese is 
shown in Figure 3.
4 Results
The results of our experiments are shown in Ta-
ble 1. These results are the official shared task 
evaluation results on the test  data, and the scores 
for all of the evaluation metrics are shown in the 
table. The reader is referred to the workshop 
white paper (Li et al, 2010) for details of the 
evaluation metrics. The system achieved a high 
level of performance on most of the language 
pairs. Comparing the individual systems to each 
other, and to the integrated system, the joint 
multigram system outperformed the phrase-
based SMT  system. In experiments run on the 
English-to-Japanese katakana task, the joint 
multigram system in isolation achieved an F-
score of 0.837 on development data, whereas the 
SMT  system in isolation achieved an F-score of 
0.824. When integrated the models of the sys-
tems complemented each other well, and on the 
same English-Japanese task the integrated sys-
tem achieved an F-score of 0.843.
We feel that for some language pairs, most 
notably Arabic-English where a large difference 
existed between our system and the top-ranked 
system, there is much room for improvement. 
One of the strengths in terms of the utility of our 
approach is that it  is free from dependence on 
the linguistic characteristics of the languages 
being processed. This property makes it  gener-
ally applicable, but due to the limited amounts 
of data available for the shared task, we believe 
that in order to progress, a language-dependent 
approach will be required.
5 Conclusion
We applied a system that  integrated two state-of-
the-art  systems through a process of re-scoring, 
to the NEWS 2010 Workshop shared task on 
transliteration generation. Our systems gave a 
strong performance on the shared task test  set, 
and our experiments show the integrated system 
was able to outperform both of its component 
systems. In future work we would like to depart 
from the direct grapheme-to-grapheme approach 
taken here and address the problem of how best 
to represent  the source and target  sequences by 
either analyzing their symbols further, or ag-
glomerating them. We would also like to inves-
tigate the use of co-segmentation schemes that 
do not rely on maximum likelihood training to 
overcome the issues inherent in this technique. 
Acknowledgements
The results presented in this paper draw on the 
following data sets. For English-Japanese and 
Arabic-English, the reader is referred to the CJK 
website: http://www.cjk.org. For English-Hindi, 
English-Tamil, and English-Kannada, and 
English-Bangla the data sets originated from the 
work of Kumaran and Kellner, 2007.
Language Pair
Accuracy in 
top-1
Mean 
F-score
MRR MAP
ref
English ? Thai 0.412 0.883 0.550 0.412
Thai ? English 0.397 0.873 0.525 0.397
English ? Hindi 0.445 0.884 0.574 0.445
English ? Tamil 0.390 0.887 0.522 0.390
English ? Kannada 0.371 0.871 0.506 0.371
English ? Japanese 0.378 0.783 0.510 0.378
Arabic ? English 0.403 0.891 0.512 0.327
English ? Bangla 0.412 0.883 0.550 0.412
Table 1: The results of our system in the official evaluation on the test data on all performance metrics. 
51
References
Peter Brown, Stephen Della Pietra, Vincent Della 
Pietra, and Robert Mercer, 1991. The mathematics 
of statistical machine translation: parameter esti-
mation. Computational Linguistics,  19(2), 263-
311. 
Sabine Deligne, and Fr?d?ric Bimbot, 1995.  Lan-
guage modeling by variable length sequences: 
theoretical formulation and evaluation of multi-
grams. In: Proc. IEEE Internat. Conf. on Acous-
tics, Speech and Signal Processing, Vol. 1, Detroit, 
MI, USA, pp. 169?172.
Maximilian Bisani and Hermann Ney, 2008. Joint-
Sequence Models for Grapheme-to-Phoneme 
Conversion. Speech Communication, Volume 50, 
Issue 5, Pages 434-451.
Thomas Deselaers, Sasa Hasan, Oliver Bender, and 
Hermann Ney, 2009.  A Deep Learning Approach 
to Machine Transliteration.  In Proceedings of the 
EACL 2009 Workshop on Statistical Machine 
Translation (WMT09), Athens, Greece.
Andrew Finch and Eiichiro Sumita, 2008. Phrase-
based machine transliteration.  In Proceedings of 
WTCAST'08, pages 13-18.
Andrew Finch and Eiichiro Sumita,  2009. Translit-
eration by Bidirectional Statistical Machine Trans-
lation, Proceedings of the 2009 Named Entities 
Workshop: Shared Task on Transliteration, Singa-
pore.
Andrew Finch and Eiichiro Sumita, 2010.  Exploiting 
Directional Asymmetry in Phrase-table Generation 
for Statistical Machine Translation,  In Proceed-
ings of NLP2010, Tokyo, Japan.
Kevin Knight and Jonathan Graehl, 1997. Machine 
Transliteration.  Proceedings of the Thirty-Fifth 
Annual Meeting of the Association for Computa-
tional Linguistics and Eighth Conference of the 
European Chapter of the Association for Compu-
tational Linguistics, pp. 128-135, Somerset,  New 
Jersey. 
Philipp Koehn, Franz Josef Och, and Daniel Marcu, 
2003. Statistical Phrase-Based Translation. In Pro-
ceedings of the Human Language Technology 
Conference 2003 (HLT-NAACL 2003), Edmonton, 
Canada.
Franz Josef Och, 2003. Minimum error rate training 
for statistical machine translation, Proceedings of 
the ACL.
A Kumaran and Tobias Kellner, 2007. A generic 
framework for machine transliteration, Proc. of 
the 30th SIGIR.
Haizhou Li, Min Zhang, Jian Su, 2004.  A joint source 
channel model for machine transliteration, Proc. 
of the 42nd ACL.
Haizhou Li, A Kumaran, Min Zhang and Vladimir 
Pervouchine, 2010. Whitepaper of NEWS 2010 
Shared Task on Transliteration Generation. In 
Proc. of ACL2010 Named Entities Workshop.
Michael Paul, Eiichiro Sumita and Seiichi Yama-
moto,  2006, Multiple Translation-Engine-based 
Hypotheses and Edit-Distance-based Rescoring 
for a Greedy Decoder for Statistical Machine 
Translation, Information and Media Technologies, 
Vol. 1, No. 1, pp.446-460 .
Taraka Rama and Karthik Gali, 2009. Modeling ma-
chine transliteration as a phrase based statistical 
machine translation problem, Proceedings of the 
2009 Named Entities Workshop: Shared Task on 
Transliteration, Singapore.
52
