Ame6~tU1 Journal of Computationd Lu~gUitti~ Hi ~icr~fi che 32 
P R O C E E D l N G S  
1 3 T H  A N N U A L  M E E T I N G  
ASSOCIATION FOR COMPUTATIONK LINGUI ST1 CS 
Timothy C. Diller, Editor 
Sperry-Univac 
S-t. Paul, Minnesota 56101 
Copyright @ 1975 by the Association for romputational Lf nguf $tic@ 
PREFACE 
The 13th annual ACL meeting was held at Boston. Massa- 
chusetts, October 30 - November 1, 1975, in conjunction with 
the 38th meeting of the American Society for Information 
Science. The ACL thanks the ASIS  for i t s  assistance in pub- 
licizing the conference and in handling registration. 
This and the fallowing four microfiehe8 contain 27 of 
the 30 papers presented at the meeting. The breadth o f  the 
oonference is evident in (a) the modes of communication in- 
vestFgated (speech, sign language, and written text), (b) the 
styles of communication (monologues, dialogues, and note  
making) , and (c) the uses envisioned for @he processing of 
language data ( e . g . ,  theoretical modeling, data collection and 
retrieval, game playing, story generation, idiolect charac- 
terization, and automatic indexing). 
Topics considered include the development of language 
understanding systems, the integration and utilization of 
specific components of language, specifically syntax and 
semantics, the representation and use of discourse structure 
and general world knowledge, and the construction of text 
processing eystems. 
The program committee was so le ly  responsible for select- 
ing the t a l k s  to be given, and hence the papers to be pub- 
lished hereln. (Reg~etfully, nearly half of those submitted 
could not be accepted for lack of program t i m e  . )  Members of  
the program committee w e r e  Jonathan Allen, Joyce Friedman, 
.. 
Bonnie Nash-Webber, and Chuck Rieger. A special  word of ap- 
preciation is due Jonathan Allen, who a l so  served as Local 
Arrangements Chairman. Working with h i m  were B e t t y  Brociner 
and Skip McAfee of the M I S .  Aravind Joshi, president of 
ACL, provided guidance in all areas of preparation. 
The AJCL kindly provided advance publication of the 
accepted abstracts and now makes possible the publication of 
the entire proceedings. David Hays, e d i t o r  of AJCL, provided 
guidance in publication format and each author provided final 
copy in accordance with requested s p e c i f i c a t i o n s .  The Center 
for Appl ied  Ltnguistics (in p a r t i c u l a r ,  David Hoffman and 
Nancy J~kovich with guidance from Hood Roberts)  contributed 
in a variety of ways, most notab ly  in the preparation of 
meeting handbooks. 
Tkis microfiche contains the papers as submitted by 
their authors for ffve of the s ix  talkb touching on Language 
Understanding Systems. The paper detailing "Conceptua1 
Grammartt by William Mattin was too long f o r  inclusion in 
&baa microfiche and will appear elsewhere. My thanks to 
Yorick Wilks for chairing the session.  
--Timothy C. Diller 
Program Committee Chairman 
TABLE O f ,  CONTENTS 
Program Schedule 
PEDAGLDT and Unlderstanding Natural Language Processing 
. . . . . . . . . . . . . . . . . . . . . .  William Fa.bens 9 
A General System f o r  Semantic Analysis of English and 
ilta Use in Drawing Maps from Directions ~ e r r y , ~ .  H Q ~ S  . 21 
Arl Adaptive Natural Language Parser P a r r y  L. Miller . , . 42 
Conceptual Gramar (abstract only) W i l l i a m  A .  Martin . , 57 
Semantic-based Parsing and a Natural-language In ter face  
f o r  Iaterac tive Data Management Ja'm F ,  Burger ,  Antonio 
Leal, and Arie Shoshani . . . . . . . . . . . . . . . . .  58 
PHLIQA 1: Multilevel Semantics in Question Answering 
P. Medema, W ,  J. Bromenberg, H. C .  Bunt, S. P. J ,  Landsbergen, 
R .  J. H I  ScM, W. J. Schoenmakers, and E l  P. C. van Utteren . . .  72 
THIRTEENTH ANNUAL MEETING 
THE AS$OCIATtON FOR COMPUTATIONAL UNGUISTICS 
Sheraton Boston Hotel 
Boston, Massachusef t s  
October $0-November 1, 1975 
Thursday, October 30, 197.5 
S&SSION 1: i,AhrCUAGE C/IVn ERSTAArDlllFG SYSTElhf S 
Session Chairman: Yorick Wdks - h r v e r s l t y  of Edtnburgh 
990 A.M. Greetings and Irrtroductory Rernarks 
9: 15 A.M. PE'DfiGI,OT and Underrl art d i n g  Natural 1,nnguagr Procr t sing 
Willtarn Fabens - Rutgers University 
9:40 AM A Syrtcm /or Gencral Scmankc Analysis And l t , q  Use 
I n  Drawirt g A l  apa from Dircctiotts 
Jerry R. t.lobbs - The C ~ t y  College of CUNY 
tO:OS A.M An Adaprivo Nutural Lartguago Parser 
Ferry t. M~ller - M I T. 
1030 AM. COFFEE & D O N U S  
t 1 :30 A.M. Semantic-Based Parsing Arzd A Natural-Langun /ar, Irttr,r farr, 
Far Intcrraciittc! Data Af artngctnrrlt 
John F. Burger, Antonio Leal, and A r ~ e  Shoshanl - 
System Development Carporation 
L2a0 NOaN Pl iL lQA I :  Mulrilrucl Srrmaniic~ i n  Qrrrlrtiort Ancu:crina 
P. hkderna, st. a1 - Phil~ps Research Laboratorres, 
The Netheviand$ 
1290 P.M. LUNCHEON BREAK 
S E S S I O N  2: LANGUAGE G E N E R A T I O N  S Y S T E h I S  
Sess~on Chairman: Martin K a y  - Xerox Corporation 
2:OO P.M. A Framework for W r i t i f t g  Ga~~erat io tr  Crurnrnnrs 
for Ints tact ivc  Cornputr?t Progrnrnn 
Dav~d McDonald - M I T. 
2:30 P.M. 
3:OO P.M, 
3:30 P.M. 
4:OO P.M. 
4:30 P.M. 
5:30 P.M. 
8:00 P.M. 
Incrarn~ntnl Sonlenco P r o c ~ s ~ i ~ t g  
Rodger Knaus - Bureau of the Census 
A IJoricnl Proces~ Model of IVomit~crl Compounding 
In English 
J.R. Rhyne - University of Houston 
COFFEE & OONUTS 
Gsnerat in~r ns Parsing horn A Natzrtork irtto a 
Idheat Str ing 
Stuart C Shap~ro - Indiana University 
Speech Gcnrrntior~ frdm Scmnr~i ir Nctr 
Jonathan Slocum - Stanford Research lnst i lute 
Using Plnrming Structurra to C~rzcratc Stories 
Jim Meehan - Yale University 
DINNER BREAK 
WINE, CHEESE & COMPUTER DEMONSTRATIONS 
SESSION 3 :  P A R S I N G ,  S Y N T A X ,  flND SEhl  ANTICS 
Session Chairman: Joyce Friedrnan - Stanford Research Institute 
9:00 AM. Synrucric Procanrirta in tho B R N  Spcaclr Urtdcrstnrtdi~tjy 
System 
Madeline Bates- Bolt, Beranek & Newman, lnc 
9:30 A.M. Sygtnrn latonration and Coi~iml for $prcr  h Uttdrrrrnrzdin/r 
Wllimrn H, Paxtoln and Ann E. Robinson 
Stanford Research I ~ s t i t u t e  
10a0 A.M. A Tuneahlo Porfarrnancc Grnrnmnr 
Jane J'. P~binson - Stanford Rosearch Institute 
10:30 A.M. COFFEE & DONUTS 
lla0 A.M. Scmdrriic Processing f ~ r  Speech Underxianding 
Gary G Hendrix - Stanford Research inst i tute  
11:30 A.M.. SPS: A Fortnalim f o r *  Scmani ic  Itrterlrrr~ation artd 
Its Use irr Processing P r c p s s i t i o n ~  that Rcj'rrettcc Spacc 
Norman K Sondhetrner - Ohro State University 
12:OO  NOON Tho Nature and Computational Use of n f i lcnning 
Reproscrrlntion Tor Pard Conccprz 
Nick Cercone - University of Alberta 
1 2:30 P.M LUNCHEON BREAK 
SESSION 4: MODELING DISCOURSB A M  EBOR1,D KN111171,1CIIGE I 
Session Chairman: Carl H e w ~ t t  - MIT 
2a0 P.M. Ertabliahirrg Conrcxt irt  Task-Oricnicd Dinlogs 
Barbara G, Oeutsch - Stanford Research Institute 
290 P.M. Dircoursc Modclx and Language Cotnpr~lzerl cion 
Bertram C Bruce - Bolt, Bersnek & Newman, Inc 
300 P.M. Judging ihc Coherertcy o/ Disrourse (and Some 
Observations About Frtzrnc?s/Scrip t s) 
Brian Ph~il~ps - University of Illinois at 
Chicago Circle 
3:30 P.M. COFFEE & DONUTS 
4f i0 P.M. Art Approach to r hc Orgariizatiort of Murtdnrtc 117orZd 
K r t o ~ l e d ~ a :  tho Carterarioir and fifariaacrrterrt of Scripts  
R.E. Cuflingford - Yale University 
490 P.M. Tho &ncaptuaZ II~h;cTi~t  on of P hysicnl Ar l i . t i i t i~s  
Norman Badler - University of Pennsylvan~a 
5:OO P.M. f i  Frarno Artalysit 01 Arn~rican S i g n  l,nr~gunae 
h d y  Keg1 (MIT) and Nancy Ch~ncho r  (U. of Mass ) 
5:30 P.M. ACL BUSINESS MEETING AND ELECTION OF OFFICERS 
DlNNER: ACL BANQUET 
Saturday, November 1, 1975 
S E S S I O N  $A: AIOl)Ef,liVG DISCOURSE & WORI,D KNOlVI,ItIIGlI: / I  
Session Chairman: Georgette Silva - System Development Corporation 
9:00 A.M. Cross-Sct~t~tztinE R ~ f i r ~ n r c  Rr~olutiorz 
David Klappholz and Abe Lockman - Colutnbia Uhiversity 
9:30 A.M. Ilaia Doc$ a Systcrn Knou~ TVhclz to Stop l ~ t f ~ r c r ~ r i n g ?  
Stan Rosensche~n - University of Pennsylvahla 
10:00 A.M. COFFEE Rt DONUTS 
S E S S I O N  5i?: TI5XT AiYflLYSIS 
1 1 :00 A.M. 
1 1 :30 A.M. 
D;c?ucZoping n Cornputcr Syatrm for Ilanrlling Iltizcrclrttly 
Vtzrinhlc I , i i ~ ~ u i s ~ i c  Data 
D a v ~ d  8eckles, Lawrence Carrrngton, and 
Gemma Warner - The unrversity of the West lndies 
A Nururul I1a~tguagc Proecs.sirtg Pnckrcgc, 
David Brill and Beairlee T Oshika - 
Speech Communications Reseatch Laboratory 
On the K o l c  of W o r d s  and Phrases irt Autornntir T e r t  
Analy,& and Cornru~niiort 
Gerard Salton - Cornell University 
12:OQ NOON Crnmrnnlicul Comprrssiolz in  N o t ~ s  and Rcrards: 
A~talysib and Cornl~v tntiolt 
Barbara Anderson (University of New Brunswick), 
Irwin Bross (Roswell Park Memorial Institute), 
a ~ d  Naomi Sager (New 'fork University) 
American Journal of Computational Linguistics H i c r o f i c h e  32 : 9 
CGmputer Scf ence Department 
R u t g e r s  Uni versi ty 
Few B r m i c k ,  New Jersey 08903 
ABSTRACT 
PEDAGLOT is a programmable parser, a 'meta-parser . '  To program i t ,  one 
describes not  j u s t  syntax and some semantics, but also-- independent ly-- i ts  
modes of behavior.  The PEDAGLOT formulation of  such modes o f  behavior follows 
a ca tegor iza t ion  of pars ing processes  i n t o  a t t e n t i o n - c o n t r o l ,  d iscovery,  pre- 
d i c t i o n  and cons t ruc t ion .  Within these  o v e r a l l  types o f  - a c t i v i t i e s ,  cont ro l  
can be s p e c i f l e d  covering a number of  syntax-processing and semantics-process- 
ing operat ions .  While it i s  not t h e  only p o s s i b l e  way of programing a meta- 
parse r ,  t h e  PEDAGLOT mode-specification technique i s  suggest ive i n  i t s e l f  of  
var ious  new approaches t o  modeling and understanding same language processing 
a c t i v i t i e s  besides parsing, such as generation and inference ,  
7% i s  wotk was sponsored by through NIH Grant #RR643. 
I t  i s  well  known t h a t  t o  process n a t u r a l  language, one needs both a 
syntactic desc r ip t ion  of poss ib le  sentences,  blended i n  some way with a semantic 
desc r ip t ion  bf a c e r t a i n  domain of discourse,  and a r a t h e r  d e t a i l e d  desc r ip t ion  
of t h e  ac tua l  processes used i n  hearing o r  producing sentences.  
An augmented t r a n s i t i o n  network (Woods, 1970) i s  qn example of t h e  blending 
of s y n t a c t i c  and quasi-semantic desc r ip t ions ,  Here r e g i s t e r s  would be repos i -  
tor ies  o f ,  o r  po in te r s  t o ,  semantics. When used i n  conjunction with a semantic 
nqtwork, an ATN can be used 60 parse  o r  t o  generate (Simmons and Slocum, 1912) 
sentences.  The i s s u e  o f  changing the  des'cription of t h e  actual  processes used 
i n  such systems has been touched on by Woods ( i n  using a 'generation modet), t o  
some extent  by Gimmons and Slo~um (usi~g decis ion  funct ions t o  control  s t y l e  of 
generat ion) ,  and t o  a l a r g e r  ex tent  by Kaplari (19751, i n  h i s  General Syntac t ic  
Procdssor, GSP. GSP indeed is  one example of  a system i n  which syntax, semantics 
and t o  some extent  processes can each be u s e f u l l y  defined. 
If we look at syntax, semantics and processes a s  t h r e e  descr ibable  components, 
these  systems j u s t  mentioned i l l u s t r a t e  how thoroughly intertwined they can become-- 
t o  the  extent  t h a t  t h e o r i s t s  from time t o  time deny the  exis tence o r  a t  l e a s t  t h e  
importance of some one of  them. Ignoring t h a t  d ispute ,  I would- l ike  t o  concentrate 
on the quest ion of  being a b l e  t o  comprehensively descr ibe one ' s  theory of language 
i n  terms of its syntax, semantics and processes i n  a way t h a t  allows fo r  t h e i r  
necessary and extensive in ter twining  connections, bu t  a t  t h e  sane time allows one 
t o  describe them independently. 
I came t a  t h e  need for  doing t h i s  while designing a Tre laxa t ion  p a r s e r , '  a 
parser which can make grammatical r e l axa t ions  i f  i t  i s  given an Ill-formed s t r i n g ,  
so as t o  arrive a t  a k l o s e s t t  poss ib le  parse  f o r  the' s t r i n g .  This probl-em involved 
descr ib ing  a k o r r e c t t  grammar and then (in some way) descr ibing a space of  deviat ions 
az 
that night be allowed by the paxser. Thus the syntax would be fixed and the way 
the  parser uses it would separately have to  be described. I t  was soon noticed 
that efficiency could be greatly enhanced i f  some rudimentary notion of semantic 
p laus ib i l i ty  could also be used. I t  would have t o  be described i n  a way related 
t o  the cbrrect syntax but st i l l  be usable by the parser. Thus, for  my purposes, 
the descriptions had t o  be independent of one another. 
One feature of a relaxation parser i s  tha t  it can ' f i l l  i n  the gaps' of a 
string tha t  is missing various words. If one could, which my re laxat ion parser 
did not, specify the semantic context of a sentence, the  generated sentence might 
be semantically rather plausible. In any case, the relaxation parser operates i n  
various respects l ike  an actual parser or like a generator, and it was t h i s  re la -  
tionship between parsing and generating that became of in teres t ,  
Out of  the design of the relaxation parser,  the  notation (independent of syn- 
tax) which t o  some extent describes various processes and choices of  al ternate ways 
of processing was developed. Thus, one may take a s e t  of syntax and semantic de- 
scriptions and then through describing the processing 'modest involved, define a 
processor which uses the par t icular  algorithm t h a t  the  individual processes together 
define, One may c a l l  the parser that  i s  programmabLe i n  i t s  processes a meta-parser, 
of which various existing qarse r s  and generators appear t o  be special  cases, 
A closer examination of the  parser I have developed (called PEDAGLOT*) may show 
some such aspects of meta-parsing, especially as regards the  relat ionship between 
parsing and generating. I will describe the syntactic and semantic parts o f  t h e  
parser first: by noting i t s  resemblances to  t h e  parser of J .  Earley (1970) and the 
ATN system of Woods. Then I w i l l  describe t he  process-type specifications t h a t  are 
available, and the  use of meta-parsers as a basis f o r  defining general language be- 
haviors. Purther detail can be found in the PEDAGMT manual (Fabens, 1972 and 1973) .  
*for pe&~ogic polyglot 
1. The Core of the Parqer 
-1 
The fundamental operation of t h e  parser  i s  very s imi lar  t o  the  operation 
of Earleyvs parser ,  with augmentations f o r  recording t h e  r e s u l t s  of parses 
(e ,g , ,  their t re  s t ruc tu re ,  and various of t h e i r  a t t r i b u t e s ,  which I c a l l  
ftags').  It is given a grammar a s  a s e t  of context-free rules with various 
extensions, most i m p ~ r t a n t  of which a r e  t h a t  LISP functions may be used as 
predicates instead of terminals, and thay each rule may be followed by opera- 
t ions t h a t  are defined i n  tbnns of t h e  syntac t ic  elements a f  the  r u l e  i n  question, 
An example of t h i s  notation i s  as follows: 
S -+ NP VP 
=> [AGREE [REF NP] [VB VP] ] 
[SUM = [REF NP] ] [OW = [REF VP] [VB = [VB VP] ] 
S -* NP [BE] [VPASS] BY NP 
=> [AGREE [REF NP] [VB [BE] ]I 
[SUM = [REF NP I ]  ] [OBJ = REF NP] ] [VB = [VB [VPASS] ] ] 
NP -+ [DET] [N] 
=> [REF = [N]] 
W + [VINP 
=> [VB = [V]] [REF = [REF NP]] 
Here, each bracketed symbol i s  the name of a recognition predicate ( e  .g., 
IN] recognizes nouns, [BE] recognizes f o n s  o f  h t o  b e 1 ) ,  Following t h e  => are 
the  post -recognit ion functions. For instance [AGREE [REF NP] [VB VP] ] specifies 
a ca l l  t o  the  AGREE function which i s  given, as arguments, the  REF a t t r i b u t e  (tag) 
of the sub-parse involved in tha t  rule and the  VB a t t r i b u t e  of t he  VP part of 
t h e  rule. 
Following i s  a parse tree fo r  'The Man Bites t h e D o g l  and values o f  tags 
after the parse. 
The Dog 
The general flow of the  parser is from top-down, and as  the  lowest compo- 
nents (symbols i n  the s t r ing)  are found, the post-recognition functions tha t  are 
associated with t h e  ru le  tha t  recognized them a r e  applied. Tags become associated 
with sub-parses when the post-recognition operation uses the  form [x = y ]  ( i n  which 
the value referenced by y i s  stored as the x t ag  of t h e  sub-parse). In the  example, 
[DET] and [N] recognize 'The Manf and 'Manf i s  used as  the REF a t t r i b u t e  ofi t h e  
first NP. In t h e  second S ru le ,  t h e  operation of [SUM = [REF NP']] would be t o  
retrieve the REF tag of  the second NP (thus the  prime), and t o  s tore  t h a t  as t h e  
SUM tag  of the  final p a n e .  
As i n  most top-down parses, t h i s  parser begins with S and i ts two ru les ,  
s ince S i s  non-terminal. S is expanded into t h e  two sequences of matches it should 
perform. This expansion r e s u l t s  i n  various (in t h i s  case, two) predict isns  of what 
t o  f ind next, When t h e  i n i t i a l  symbol i n  some r u l e  i s  a terminal o r  a predicate, 
a discovery is  cal led fo r  (in which a match is pexformed, possibly involving the  
known values of the  tags). When some complete sequence of elements is found (here, 
for instance, when NP -+ [DET] IN] has matched t h e  [N] ) . Construction invokes the 
post-reoognit ion operat ions and then usual lyt completes some e a r l i e r  part of a r u l e  
(here, the 'NPi ~f S + NP VP) So fur ther  predictions (involving VP) or discoveries 
are then specified. 
1 have broken up the parsing process into t\he$e three parts so as to  simi4arly 
catalpg t he  'parsing modes,' turn ing  this parser into a meta-parser. Before doing 
so, f should note tbat th i s  parser stores each zesult under construction in a 
'chart' as is done by Kaplan i n  his GSP, so that, for instance, the NP ' testt  
w i l l  only have to  be evaluated once for each place one i s  wanted i n  the string. 
[ N l  [;I 1 [ N l  
5 The T Man Bites The $ Dog 
I1 lustrat ion of PEDAGLOT ' s Parsing Chart 
Simple Arrows indicate 'Predictions.' 
Double Head Arrows indicate iDiscoveries, 
Dotted Arrows indicate tlConstruction. 
Also, for various well known reasons of efficiency, Earley's concept of 
independent processing of syntactic events i s  used (combined conceptually with 
the chart), SO that a main controller can evaluate the individual syntactic ' t e s t s 1  
i n  almost any order, and not just in a backtracking sense (cf.  Woods, 1975). Thb 
efficiency i s  realized here since many 'partial parses (partially recognized forns) 
15 
are effectively abandoned if other results can complete t h e  parse, o r  a sub- 
parse, first . 
2 .  Meta-Parsing Modes 
One can see that, except f o r  the nota t iona l  i ne f f i c i enc i e s  o f  the  context,  
free formalism (as opposed to the augmented t r a n s i t i o n  network form), t h i s  parser 
is very much like other standard parsers (especially ATN s) . I t  differs i n  t h a t  
there is a waytof specifying how t o  proceed. Currently, this system has approxi- 
mately a dozen toodesr and I will present some of them here. Each mode spec i f i e s  
how t o  handle a certain part of the parsing process. They can be classified i n t o  
four categories: attention control, prediction, discovery and construct ion.  
a, Attention Control W e s :  
Since the parser operates on a chart of independent events ( 'parsing 
questions1), one must give t h e  parse r  a method of sequencing through them. 
Thus, one may specify 'breadth-first1 or 'depth-first1 and the  appropriate 
~echanism will be invoked {this merely involves t h e  way the processor stacks 
i t s  jobs). A 'best-first ' option i s  -under development, which, when given an 
evaluation function to be applied to the set of currently a c t i v e  part ial  
parses, allows the system to operate  on the 'best1 problem next ,  Experi- 
Bents with this mode have so far been inconclusive. 
One also can speci fy  when t o  stop (i.e., at the first complete parse,  
or t o  wait  until a l l  other ambiguous parses have been discovered).  The d i s -  
it~gbiguation routine (which i s  described as a part o f  t h e  construct ion modes) 
defines which parse is %est l ,  Further, one may specify a left-to-right or 
right-to-left mode of how to progress along the  s t r i n g .  
b. Discovery Modes: 
The starting point of building a relaxation parser is to specify what 
t o  do when an exact match i s  not made. If the parser i s  expecting one word 
and finds another it can look arowd the indicated place in the s t r i n g  t o  f ind  
what- it i s  looking f o r ,  o r  it can i n  c e r t a i n  other  circumstances simply 
i n s e r t  t h e  expected word i n t o  t'he s t r i n g .  Thus, under discovery.modes, 
there are vaxious options:  e i t h e r  t h e  parser  i s  allowed t o  attempt matches 
in out-of-sequence p a r t s  of t he  string, or n a t ,  And i f  not ,  or  i f  no such 
match i s  found, t h e  parser  may or may not be allowed to make an inser t ion .  
So i n  PEDAGLOT, t h e r e  i s  an INSERT mode (and various r e s t r i c t e d  versions 
o f  f t )  and a  'where t o  look1 mode which i s  used t o  control  t h e  degree t o  which 
the  parser can t r y  t o  f i n d  out-of-place matches, There a re  tags  associated 
wi th- these  two spec i f ica t ions ,  t he  INSERT t a g  and t h e  OMIT t a g ,  which a r e  
associated with the parses involving inser t ions  and omissions t b a t  contain 
the number of insertions made and the number of input  symbols omitted i n  
building t h e  parse. 
There i s  also a rearrangenient mode. mus, given ce r t a in  cons t ra in ts ,  
the parser could be givep 'The Bites M a n  Dogt and produce a parse f o r  *The 
Man Bites t h e  Dogt s ince  it would have found 'Man,' by temporarily omitting 
'Bites,' but then it looks f o r  and finds 'Bitest and f i n a l l y ,  f inding no se- 
cond lthe,fthe,l i n s e r t s  one [or some other  determiner because of t h e  [DET] func- 
tion]) and f inds 'Dog. In  a similar way it would t r y  t o  produce a passive 
form [i.e., the Man Is Bitten By the Dog) but since t h i s  involves more inser-  
t i o n s ,  etc .  it would not be chosen. 
These h e u r i s t i c s  a r e  control led by recording numerical summary t a g s  
with each sub-parse that p a r t i c i p a t e  in ,  and are  judged1 by the  disambiguatic;~~ 
rout ines .  Similar ideas are used by Lyon (1974). 
c. Predict ion Modes: 
As Woods (1975) has pointed out ,  t he  extent t o  which a parser ' s  prediction 
increases efficiency varies with the quality of the expected input. This f a c t  
affects greatly our discavBry procedures, since, if inser t ions  are to be made, 
one aught t o  be rather s u m  of  one's p ~ e d i c t i o n s ,  o r  risk a combinatorial ex- 
plosion.  In PEDAGLOT, t h e r e  i s  a programmable choice ' funct ion tha t -  con- 
t r o l s  predlc t ions .  Spec i f i ca l ly ,  when the  parser encounters a non-terminal 
symbol, t h a t  symbol is t h e  left-hand s i d e  of various r u l e s .  An uncontrolled 
pkediction (used by a canonical top-down parser )  i s  t o  s e l e c t  each such r u l e  
as the expansion. I n t u i t i v e l y ,  however, people do n o t  seem t o  do t h i s .  In- 
stead, as i n  an A'I??, they t r y  one and only i f  t h a t  f a i l s ,  go In to  the  next .  
In  PEDAGLOT, t h e  choice of which r u l e  t o  t r y  can be defined as  the  r e s u l t  of 
the c a l l  t o  a 'choosef funct ion (or it can be l e f t  uncontrolled] , We have 
des&ned various approaches t o  such predic t ions  (e.g., a l imi ted  key-word 
scan of the incoming s t r i n g ,  and the use of 'language s t a t i s t i c s  such as the  
s e t  of rules which can generate the next symbol i n  the  s t r i n g  as t h e i r  l e f t  
most symbol). 
The predic t ion  is cur ren t ly  made once f o r  any given choice poin t ;  its 
outcomes are expected t o  be an ordered s e t  of r u l e s  t o  t r y  next.  
d . Construct ion Modes : 
The phase of parsing i n  which t h e  p a r t s  of t h e  parse  t r e e  and associated 
tag values are formed, is  a p lace  where most of t h e  non-syntactic information 
(tags] about the s t r i n g  being parsed can come i n t o  play. 
In t h e  first place,  new t a g s  can be formed as funct ions of lower l eve l  
parse tags tbough a process called melding, Thus, 'nonsense1 can be discovered 
d pronoun references can sometimes be t i e d  down, In t h e  second place,  it i s  
a r e s u l t  of construct ion t h a t  ambiguity i s  discovered and dea l t  w i t h ,  
Since these fea tures  of parsing deal  pr imari ly  with semantics (and s ince ,  
i f  anyrcthere, sttsntantic representa t ions  of the s t r i n g  r e s i d e  i n  the  t a g s ) ,  most 
of t b  PEDAGLOT construct ion modes involve tags .  
One play e x p l i c i t l y  meld t a g  values by using post-recognit ion operators ,  o r  
one nay def ine  an 'implicit' melding rou t ine  that i s  associated with t h e  tag 
names themselves ins tead  of with indiv idual  rules.  I n  our example we use 
this device t o  i m p l i c i t l y  form a simple l i s t  of  t h e  two REF t a g s  t h a t  be- 
come associa ted  with t h e  S ru le .  This implicit melding operat ion can a l s o  
include a blocking function, o r  some reference t o  a d a t a  base. The t ags  
t h a t  contain INSERT and OMIT information are used i n  t h i s  way t o  keep running 
t o t a l s  o f ,  and t o  minimize the  munber o f  such h e u r i s t i c s  i n  t h e  r e l axa t ion  
pars ing  modes. One may a l s o  a s s o c i a t e  a LIFT funct ion which, when t h e  par- 
t i a l  parse becomes complete, s p e c i f i e s  a transformation of t h a t  t a g  t o  be 
used as The tag of  the next higher  level  parse.  
Ambiguity i s  discovered when two parses from the same symbol, cbvering 
t he  same s t r i ng  segment axe found. For t h i s  case,  an AMBIG funct ion i s  asso- 
c i a t e d  with t ag  names, and it makes a 'value judgement1 of  which t a g  i s  ' b e t t e r ,  
hence which i n t e r p r e t a t i o n  t o  use. (Other types of  c r i t e r i a  can a l s o  come i n t o  
p l a y  here such as u s e r  in te rac t ion ,  (cf. Kay, 1973). 
3. The Uses of Meta-Parsers 
I ha-re just catalogued some of  t h e  parsing modes ava i l ab le  i n  PEDAGLOT. Others, 
such as Bottom-Up ( instead of Top-Down) o r  Inside-Out ( ins tead  of  Left-to-Right, e tc . ) ,  
are envisionedlbut not  implemented. Since PEDAGLOT is an i n t e r a c t i v e  program, the  
u s e r  can change modes a t  w i l l ,  j u s t  a s  he can change syntax o r  introduce new t ags ,  
Thus, the obvious first use a f  meta-parsers i s  t ha t  one may use them t o  des isn  
language processors without having t o  t i e  oneself  down from t h e  s t a r t  t o  say, a 
d e p t h - f i r s t  pa r se r ,  
Meta-parsers a l s o  have a c e r t a i n  amount of t r a c t i b i l i t y  t h a t  parsers t h a t  
blend a l l  . a c t i v i t i e s  i n t o  one huge network may not .  Ono may sea a t  a r a the r  high l eve l  
what is  going t o  be happening ( i . e , ,  a l l  t a g s  of a c e r t a i n  name w i l l  meld together  
i n  a c e r t a i n  way, unless  t h e  grammar s p e c i f i e s  otherwise) ,  If one, however, wants 
c e r t a i n  foms of local behavior, one may use predica tes  o r  funct ions on individuaQ 
r u l e s .  Further,  i f  one wants t o  change t h e  order  i n  which predict ions a r e  evaluated, 
one can program a tchoosel function which w i l l  make t h a t  global change. To a 
large extent, the language designer may specify mch of t h e  processor in broad 
ternas and s t i l l  be able t o  cont ro l  local events where necessary. 
In a more general sense, a meta-parser allows one t o  understand and build 
higher order theories about how people might represent and process language. 
For instance, while it may be true that  generating is  t h e  inverse of  parsing, 
there is more than one way t o  do such inve r t i ng .  One could s tart  from a senantic 
network, using the choose function along with t h e  INSERT mode t o  restrict means o f  
expression consistent with the intendea message, and using AMBIG functions to weed 
out a l l  but reasonable messages from m n g  the many the parser may produce o r  one 
might simply t a k e  from the  semantic network a simple str ing o f  meaningful words, 
and then we a less t i g h t l y  programmed 'relaxation parser' t o  rearrange these words 
to be syntactically correct. We are now considering using a crude 'backwardsT mode 
which begins with the operati~n part of a ru l e  and, by using predicates (e .g . ,  AGREE) 
to yield inverses, specifies what the context-free pat tern must produce. Thus there 
are many variations of how t o  generate using a meta-parser. 
In the area of language inference, t o  take another example of language processing, 
PEDAGLOT suggests various differing ways of approaching the  problem. First, ofie may 
use it a5 a 'relaxation-parser, the 'parse t ree1  can be pattern-matched aga ins t  
the new sentence, and hypotheses can be famed. Or, one could place a more rudimentary 
inference systw on the 'prediction' part of the processor i t se l f ,  and using other 
controls, the predictions that  are successful could be rewritten as a new gramar. 
These two learning paradigms could each be strengthened by way of  t h e  use of  tags 
t o  contain (in a sense) t h e  meaning of t h e  sentelzces t o  be learned, Each of these 
paradips can be modeled using a meta-parser like PEDAGLM. Thus, a meta-parser can 
raise [and be prepared to answer) a nlrmbor of interesting questions. 
References 
Earley, J. (1970), llAn Efficient Context-Free Parsing Algorithm,I1 Comm. ACM 13, 
number 2, (February 1970)) pp, 94-102. 
Fabens, W, (1972), PEDAGLOT Users Manual, Rutgers University CBM-TR-12, 
kt. 19722, 
Fabens, W. (1973), PEDAGLOT Users Manual : Part 11, Rutgers University CBM-TR-23, 
Nov. 1973. 
Kaplan, R.M. (1973), "A General Syntactic Proce~sor,~~ in R .  Rustin (ed.) 
Natural Language Processing, New York: Algorithmics Press, (1973), pp. 193-242. 
Kay, M. (1973), llThe MIND Systemjfl in R. Rustin (ed.) Natural Language Processing, 
New York: Algorithmics Press, (1973). pp. 155-188. 
Lyon, G. (1974)) "Syntax-Directed Least-Errors Analysis for Context-Free 
Languages: A Practical Approach.lr Comm. ACM 17, number 1, (January 1974), 
pp. 3-13. 
Simmons, R. and Slocum, J. (1972), "Generating English Discourse from Semantic 
Networks,''l Comm. ACM 15, number 10, (October 1972), pp. 891-905, 
Woods, W.A. (1970), "Transition Network Grammars for Natural Language Analysis," 
Comm, ACkl 13, number 10, (October 1970)) pp. 591-606, 
Woods, W.A., [1975), Syntax, Semantics, and Speech, BBN Report No. 3067, A.I .  
Report No, 27. Bolt Beranek and Newman Inc , , t o  appear in D, R Reddy (ed ,) 
- - 
~ S e c h  Recognition, Academic Press (1975) . 
American Journal of Compatationd Linguistics Microfiche 32 : 2 1  
Department of Computer Science 
The C i t y  College of the 
C i t y  University of New York 
Convent Avenue at 140th Street 
Hew York, N e w  York 10031 
ABSTRACT 
We describe a semantic processor we are constructing which is 
i n t e n d e d  to be of general applicability. It is designed around 
semantic operations which work on a s t r u c t u r e d  data base of world 
knowledge to draw the appropriate i n f e r e n c e s  and to identify the 
same entities i n  d i f f e r e n t  parts of t h e  t e x t .  The semantic oper- 
ations capitalize on the high degree of redundancy e x h i b i t e d  by 
all texts. Described are the operations for interpreting higher 
predicates, f o r  de t ec t ing  some intersententialqrelations, and in 
particular detail, for f i n d i n g  the  an tece6en t s  of definite noun 
phrases. The processor is applied to the problem of drawing maps 
from direct ions .  We describe a l a t t i c e - l i k e  representation 
intermediate between the linguistic representation of directions 
and the visual representation of maps. 
OVERVIEW 1,2 
We are trying to cons t ruc t  a semantic processor of some 
7 
A This research was supported by the Research Foundation of the 
City University of New York under  F a c u l t y  G r a n t  No. 11233. 
The author would like to express h i s  indebtedness to Harry  Elam 
for  many insights i n t o  the problems discussed here. 
2 2  
generality. We are using as our data base a set of f a c t s  involv- 
i n g  spat ia l  terms i n  English. To test the  processor and to s t u d y  
the interfacing of semantic and task components, we are building 
a system which takes as i n p u t  directions in E n g l i s h  of how to get 
from one place to another and outputs a map, a map such as one 
might sketch for an unfamiliar region, hearing the directions 
over the phone. 
A typical input might be the text 
"Upon leaving thi,s building, turn right and follow 
Washington Street three blocks. Make a left, The 
l ib ra ry  is an t h e  r i g h t  side of the s t ree t  before 
the next coxner." 
The ou tpu t  would be t h e  map 
I 
L i b r a r y  
I 
To bypass syntactic problems, we are us ing  a s  our input the 
o u t p u t  of t h e  Linguistic String Project's transformational pro- 
A I 
Washington Street 
gram (Grishman et al 1973, Hobbs & Grishman), which is very 
. 
close to a predicate-like natation. The semantic component is 
. 1 
This Building 
designed around general semantic operations which work on a 
r 
s t r u c t u r e d  data base of world knowledge to draw the appropriate 
N 
inferences and to identify phrases in different p a r t s  of the t e x t  
which refer to t h e  same e p t i t y .  The text, augmented and i n t e r -  
related in t h i s  way, is then passed over to the task component, 
which makes arbitrary decisions when the map requires information 
not given by the directions and produces the map. 
ORGANIZATION OF TEXT AND WORLD KNOWLEDGE 
The kwp problems of semantic analysis are to f i n d ,  o u t  of a 
p o t e n t i a l l y  enormous collection of inferences, the appropriate 
i n f e r ences ,  and t o  f i n d  them quickly .  Our s o l u t i o n  t o  t h e  first 
is i n  our semantic o p e r a t i o n s  described below. Our approach t o  
the second problem is in the organization of the data base. 
The d a t a  i n  the semantic coptponent is of two sorts: 
1. The Text: the information which is explicitly in t h e  
t e x t ,  I n  the course of  semantic processing t h i s  is augmented by 
i n fo rma t ion  which is only implicit i n  the text. The text con- 
sists of the set of entities X1,X2, ..., e x p l i c i t l y  and i m p l i c i t l y  
referred to in the text, and s t r u c t u r e s  of $he form p (X1,X2) rep- 
resenting the statements m#de or implied about t h e s e  e n t i t i e s , e . g .  
walk (XI) = X1 walks, 
building (XZ) = X is a building, 2 
door ( X 3 ,  X2) = X is a &or of X2. 3 
2 .  The World Knowledge or the Lexicon: the system's knowl- 
edge of words and the world. Words are the boundary between the 
Text and the LexPcon. A word is viewed as  a key indexing a large  
body of facts (Holzman, 1 9 7 1 ) .  
Associated with each word are a number of facts  or i n f e r e n c e s  
which can be drawn from the occurrknce of p(X1, ..., X,) in the 
Text. The facts are expressed in terms of p ' s  s e t  of parameters 
Y l f  ,Ykt and a s e t  of other l ex ica l  variables z l , . .  , , z  m' 
stanaing for entities whose existence i s  also implied. A fact 
consists of enabling c o n d i t i o n s  and conclusions. When p ( X 1 ,  ... X,) 
occurs i n  t h e  Text and the semantic operations determine a 
24 
particular inference appropriate, its enabling conditions are 
checked. If they hold, the conclusions are instantiated by 
c r e a t i n g  a copy of them in t he  Text with the lexical variables 
rep laced  by Text entities. 
Clusters. One way td state the "frames" problem (Minsky 
1974) is "How should the data base be organized to guide, confine, 
and make e f f i c i e n t  t h e  searches which the semantic opera t ions  
require?" W e  approach this by dividing the sets of inferences 
i n t o  clusters according to topic and salience in the particular 
application. In the searches, the clusters are probed in order 
of their salience. In our application, the top-level cluster 
concerns the one-dimensional aspects of objects and actions. For 
example, the fact about a block that it is the distance between 
two intersections i s  in the cluster. If "around the block" is 
encountered, less salient clusters will have to be accessed to 
f i n d  i n fo rma t io ,~  about  the two-dimensional nature of blocks, The 
mast important fact about an apartment building is that it is a 
building, to be represented by a square on the map. But if the 
d i r e c t i o n s  take us inside the building, up the elevator, and 
along the hallway, the cluster of facts about the interiors of 
buildings must be accessed, 
A self-organizing list (Knath 1973) of the clusters is main- 
tained--when a fact in a cluster i s  used,  it becqmes t h e  top- 
level cluster--on the ,assumption that t h e  t e x t  will continue to 
talk about the same thing. 
The ''<Truth Status"  of Inferences. In natural language, 
unlike mathematics, one is no t  always free to draw cer ta in  
inferehces. We t a g  our i n f e r e n c e s  always, normally,  o r  sometimes. 
These notions are d e f i n e d  o p e r a t i o n a l l y .  An a lways  i n f e r e n c e  i s  
one we are always f r e e  t o  draw, such as that a street i s  a p a t h  
through space. A normal ly  i n f e r e n c e  i s  one w e  c an  draw if it is 
not explicitly c o n t r a d i c t e d  e l sewhere ,  such  as that b u i l d i n g s  
have windows. A sometimes inference may be drawn i f  r e i n f o r c e d  
elsewhere, such as the f a c t  used below t h a t  a b u i l d i n g  i s  by a 
street. This  c l a s s i f i c a t i o n  of i n f e r e n c e s c u t s  across t h e  cluster 
structure of the Lexicon. 
Lattices. A large number of statements i n  any natural lan- 
guage t e x t ,  especially t h e  texts this system analyzes, involve a 
transitive relation, or e q u i v a l e n t l y ,  say something about an 
underlying scale. For example, the word "walk" i n d i c a t e s  a 
change of location along a p a t h  through space, o r  a distance 
scale; " tu rn"  indicates a change along a scale of a n g u l a r  orie,n-- 
t a t i o n .  
I n  any p a r t i c u l a r  t y p e  of t e x t  there are scales o r  t r a n s i t i v e  
relations which are important enough t o  deserve a more economical 
r e p r e d e n t a t i o n  than predicate n o t a t i o n .  I n  this particulak task, 
the impor tan t  scales are a distance scale, a s u b s c a l e  of t h b i s  
indicating the path "you" $ill travel, and a scale representing 
angular orientation. This is the principal information used in 
constructing the map. For these scales w e  t r a n s l a t e  i n t o  a 
directed graph or  l a t t i c e - l i k e  representation (Hobbs 1 9 7 4 ) .  
Some of the things which can be said about t h e  structure of 
a scale are mat some p o i n t  i s  on t h e  scale, t h a t  of t w o  p o i n t s  
-
on the scale one is closer t o  t h e  positive end tHan the  o t h e r ,  
26 
and t h a t  a scale i s  a part of another s c a l e .  If a point  B i s  
closer to the  positive end of the s c a l e  than point  A ,  this *fact 
is  represented by 
A-B 
If po in t  C l i e s  i n  t h e  interval  from A t o  B the representat ion  i s  
The  diagram 
mean& the scale from C to D is part of the scale from A to B, It 
is possible to represent incompleteness of information. For exam- 
ple, if it i s  known that points  A and B both lie in a region R 
of a scale bu t  their re la t ive  positions are n o t  known and if it 
is known about C only  thati,tprecedes B t h i s  i s  represented by 
The lattice for  the distance  scale for t e x t  (1) is as follows: 
Washington St. The Second St. 
the 
cross 
st. 
Library  
The lattices are intermediate between the linguistic repre- 
s e n t a t i o n  of the directions and t h e  v i s u a l  representation of the 
maps. They are used at several po in t s  in the semantic and t a s k  
27 
processes. They can be constructed f o r  any transitive relation, 
and could be very u s e f u l ,  f o r  example, in representing causal and 
enabling r e l a t i o n s  in a system translating descriptions of algo- 
rithms into flowcharts OE programs. 
SEMANTIC OPERATIONS 
Basic Principle of Semantic Analysis. We bedieve the key to 
t=he first problem of semantic a n a l y s i s ,  that of finding which 
inferences are appropriate, is  Joos '  Semantic A x i o m  N u m b e r  One 
(Joos 1972), or what I w i l l  call the Principle of  knitting. 
Restated, this is, "The important facts in a text w i l l  be repeat- 
ed, explicitly or implicity." That is, we capitalize on the very 
high degree of redundancy that characterizes a11 texts. Consi i fer ,  
for example, the simple sentenced "Walk out the door of this 
building." "Walk" implies motion from one pLace to another. 
"Out" implies motion from inside something to the ou t s ide .  "Door" 
i s  something which permits motion from inside something to the 
outside or from the outside to the inside, or if closed, prevents 
this motion. "Building" is something whose, purpose is for people 
to be in. Thus, all four c o n t e n t  words of t h e  sen tence  repeated- 
ly key the same facts. Those inferences  which should be drawn 
are those which are keyed by more than one element in t h e  text. 
This p r i n c i p l e  i s  used both formally and informally by the 
semantic operations. It is used formally in the interpretation. 
of higher predicates and in finding antecedents. It is used more 
informally for deciding among competing p l a u s i b l e  an t eceden t s ,  
resolving ambiguities, d e t e c t i n g  intersentential relations, and 
knitting the text together in some minimal way. Here it isd 
p r i m a r i l y  the  formal  uses that w i l l  be desc r ibed .  
X n t e r p r e t a t i o n . o f  Higher P r e d i c a t e s .  I n  "walk o u t " ,  "walk 
s lwoly" ,  and "pleasant walk" ,  t h e  h i g h e r  p r e d i c a t e s  "out", " s l o w "  
and ' ' p leasant"  a11 apply  t o  "walk", b u t  t hey  narrow i n  on d i f f e r -  
e n t  aspects of  walking. That  is ,  each demands t h a t  a  d i f f e r e n t  
inference be drawn from t h e  s t a t e m e n t  t h a t  "X walks".  "Out" and 
"slow" demand t h e i r  arguments be motion from one place t o  
another., f o r c i n g  us t o  infe ' r  f r o m  " X  walks'' t h a t  "X  goes from A 
t o  B " .  "Out" then adds in format ion  about  t h e  l o c a t i o n s  s f  A and 
B, whi le  "slow" says something abou t  t h e  speed of t h i s  motion. 
"Pleasant", on the other hand, r e q u i r e s  i t s  argument t o  be an 
awareness,  so we must i n f e r  from "X walks" t h a t  "X engages i n  a 
b o d i l y  a c t i v i t y  he i s  aware of" .  
Stored i n  t h e  Lexicon w i t h  each h i g h e r  predicate is t h e  
i n f e r e n c e  which must be drawn from i t s  argument and t h e  informa- 
11 t i o n  it adds t o  t h i s  i n f e r e n c e .  For  example, go (z l , z2 , z3 )"  must 
be inferred from t h e  argument of "out" .  When t h e  s ta tement  
"out(waDk(X1))" i s  encountered i n  t h e  Text, t h e  higher predicate 
o p e r a t i o n  makes e f f o r t s  t o  f i n d  a proof of 1 1 g o ( z l , ~ 1 , ~ 3 )  I1 from 
" w a l k ( X L ) " .  The search for t h i s  i n f e r e n c e  is s i m i l a r  t d  t h e  
search procedure  described below f o r  f i n d i n g  antecefienes. T h e  
f a c t s  in the  resulting c h a i n  of  inference are i n s t a n t i a t e d  
t o g e t h e r  w i t h  the  in fo rma t ion  added by the h ighe r  p r e d i c a t e ,  and 
t h e y  are subsequent ly  treated as though p a r t  of- the e x p l i c i t  Text .  
I t  i s  u s u a l  for them t o  be u s e f u l  in f u r t h e r  p rocess ing ,  u n l e s s  
the  mod i f i e r  i s  simply g r a t u i t o u s  in format ion .  
Note t h a t  t h i s  o p e r a t i o n  a l lows  c o n s i d e r a b l e  compression i n  
29 
the number of senses that must be s tored  for each word* It 
ellows us, f o r  example, to define "slow" a s  something like "Find 
the most salient associated motion. Find t h e  most specific speed 
Scale for the object X of this motion. X ' s  speed i s  on t h e  lower 
end of t h i s  scale". This definition is adequate for such  phrases 
as "walk slowlyn (the most salient motion is the forward motion 
of the walk ing ) ,  "slow race" [the forward motion of the competi- 
tors), "slow horsew (its running at f u l l  speed, usually in a 
race), and "slow personw. This last case is highly dependent on 
context, and could mean the person's physical acts in general, 
h i s  mental processes, o r  the  act h e  is engaged in at the moment. 
This operation has a default f e a tu r e ,  If a proof of t h e  
required inference can't be found, it is assumed anyway. This 
allows a t e x t  to be understood even if all the words aren't 
known. Suppose, for example, "veer rightw is encountered, and 
the word "veern isn't known, i . e .  no inferences can be drawn f r o m  
it. Since "rightn requires a change i n  angular o r i e n t a t i o n  a s  
its argument, it is assumed this is w h a t  "veer" means. Only the 
information that the change is  small is lost. 
FIND ANTECEDENTS OF DEFINITE NOUN PHRASES 
~ n t i t i e s  referred to in a text may be arranged in a hierarchy 
according to t h e i r  degree of specification: 
1. proper names, including "you" and "I" 
2 .  other noun phrases,  inc luding  those w i t h  definite, 
indefinite, and demofistrative articles 
3 .  khird person pronouns 
4 .  zeroed arguments am5 implied entities. 
3 0  
So far  our work has  concerned p r i m a r i l y  definite noun phrases ,  
but it is expected that many f e a t u r e s  of t h e  d e f i n i t e  noun phrase 
algorithm w i l l  carry over t o  other cases, 
The d e f i n i t e  noun phrase a lgor i thm consists of fou r  steps. 
First, "uniquent2~s cond i t i onsn  are checked t o  determine whether 
an antecedent i s  requ i red .  If so, t h e  Text and Lexicon are 
searched for p l a u s i b l e  anteceaents .  Third, cons i s t ency  checks 
are made on these. F i n a l l y  i f  more than  one p l a u s i b l e  antecedent  
remains the  Principle of Kn i t t i ng  is  app l i ed  t o  decide between 
them. 
Vniqueness Condi t ions ,  I n  t h e  phrase "the end of the block", 
we know we must look back i n  the t e x t  for an e x p l i c i t l y  o r  impl i -  
citly mentioned "block" ( the  search case), b u t  we do fiat neqes- 
s a r i l y  look for a previously meptioned "end" (the no-search case) . 
Given a d e f i n i t e  noun phrase t he  a lgor i thm first tries t o  deter- 
mine whether it b e l o n g s t o t h e  search or no-search case. This i s  
done by checking two broad cr i ter ia .  (These criteria were moti- 
vated by a large number of examples no t  only  from s e t s  of direc- 
tions but a l s o  from t e c h n i c a l  and news ar t ic les , )  
These criteria are checked by sea rch ing  t h e  Lexicon for 
c e r t a i n  f e a t u r e s .  However these searches are generally very 
shallow, i n  c o n t r a s t  t o  the p o t e n t i a l l y  much deeper searches in 
the riext s t e p  of the algorithm. S i n c s  by far the majority of 
d e f i n i t e  noun phrases  are i n  t h e  no-search case, checking unique- 
nes s  cond i t i ons  can r e s u l t  i n  g r e a t  savings .  
A caveat is in order. W e  state the  c r i t e r i a  at a very high 
level of abstraction, We feel i n  f a c t  t h a t  t h e  a lgor i thm can 
work at that level of abstraction if the   ex icon is proper ly  
constructed. But how to construct a large  exi icon properly is 
a problem we have not yet tackled in detail. In any event, we 
give examples f o r  each case, and the  examples themselves form a 
reasonably exhaustive classification. 
1. A d e f i n i t e  entity is in the no-search case i f  it can be 
located precisely w i t h  respect to some framework. n his includes 
me following conditions. 
a. Objects which are located with r e s p e c t  to some identi- 
f i e d  point  in space: "the building on the corner". 
b, Plurals and mass nouns which are restricted to some 
identified region sf space: "the trees in the park", " the  water 
in the swimming pool". Here "the" indicates a l l  such objects or 
substance. 
c.. Points and intervals in time khich are fixed with 
respect to some identified event: "the minute you arrive", "the 
hour since you left". 
d. Events in which at least some of the participants are 
identified and which can be recognized as occurring at a specific 
time: nthe ride you took through the park yesterday1'; 
e, P o i n t s  or intervqls on more abstract scales: "the end  
of the block", "the size of  t h e  bui ld ing".  The end is a specific 
poin t  on the distance scale defined by the block. The size of 
the building is a specific point on the general s i z e  scale for  
objects , i . e.  the volume scale. 
f. Superlatives, ordinals, and related terms: " the  largest 
house on the block", "the second house on the block", " the  only 
house on the block". If the set of comparison is identified, 
the superlative or ordinal indicates the scale oE comparison and 
the place on that scale of t h e  e n t i t y  it describes. This is a 
subcase of (e) . 
A l l  of these c o n d i t i o n s  can  be checked in one operation if 
the facts in the Lexicon are expressed in terms of suitably 
abstract operators relating entities t o  scales. We simply ask if 
the definite entity is on or part of a scale or  a t  a p o i n t  on or 
- -
along an +interval of a scale, where the scale can be identified. 
However this r e q u i r e s  that w e  t a k e  very seriously m y  suggestion 
in Hobbs (1974) t h a t  the lexicon for the entire language be built, 
insofar as possible, along the lines of a spa t i a l  metaphor. We 
have no t  yet had to f a c e  these problems since our only scales are 
physica l  -- our " a t "  and "on" are the locative " a t "  and "on". 
Also checking this c r i t e r i o n  presupposes a very sophisticated 
s y n t a c t i c  and semantic analysis. For example, [d) assumes that 
the times of events mentioned in tenseless constructions can be 
recovered. 
2. A definite entity is in the no-search case i f  it i s  the 
dominant entity of t h a t  description. This d i v i d e s  i n t o  two sub- 
cr i t e r i a :  
a ,  Those e n t i t i e s  which are unique  or dominant by virtue 
of the properties which describe them: " t h e  sun1',  "the wind".  If 
t h e  p roper t ies  p1 (X) ,pZ (X), ..., are known about the d e f i n i t e  
entity X, the definitions o f  p1,p2, ..., are probed f o r  the f ac t  
that the entity does not normally occur in the plural. Included 
under this heading are proper names beginning with "the", like 
"the Empire State Buildingff, and appositives, like "the city of 
Bos tonr' . 
b. Those entities which are unique by virtue of t h e  prop- 
erties of an entity with which they are grammatically related:  
"the door of the building", "the Hudson River valley". "The door 
of the buildingn is represented in t h e  Text a s  "xl 1  door'(^^,^^ 1 
building{X2))' i.e. "the  Xl such that  XI i s  t h e  door of X2 which 
is a building". The uniqueness or dominance of XI is not a prop- 
e r t y  of "door" but  of "building". Stored w i t h  "building" is the 
fact  that  a building has in its front surface a main door which 
does not normally occur i n  t h e  p l u r a l .  "The door of t h e  bu i ld ing r '  
is interpreted as this dominant dosr. 
If the tvliqueness conditions succeed, a poin te r  is s e t  from 
t h e  dominant lexical  variable to the corresponding e n t i t y .  If 
subsequently the same definite noun phrase occurs, the uniqueness 
check will discover t h i s  pointer  and correctly identify the ante-  
cedent. Thus, we can handle the example 
"Walk up to the door of t h e  building. Go through 
the door of the building." 
Here the uniqueness check gives us a s h o r t c u t  around the n e x t  
step in the algorithm. 
The Search for Plausible Antecedents. To illustrate the 
search for an antecedent, consider 
"Walk out the door of this bu i l8 ing .  Turn right. 
Walk to the end of the block. " 
What block? From "block" W e  follow a back p o i n t e r t o  the f a c t  
stored with "streetn *that "streets consist of blocks", and from 
34 
"street1' the fact with "buildingt' that "Buildings are by streets" 
Since a building is mentioned, we assume it is "the block of the 
street the b u i l d i n g  is on". T h e  facts in the chain of inference 
leading to this are instantiated, An entity is introduced i n t o  
the t e x t  fo r  t h e  "street" and the Text is augmented by the state- 
ments that "the bu i ld ing  is  on the street" and "the block is part 
of the street". This information turns out to be required for 
the map. Note that t he  Eact that a building is on a street is a 
sometimes f a c t  and that we are free to d'raw it only because "the 
blockn occurs* 
To conduct the search of the Lexicon, ideally we would like 
to send out a pulse from the word "block" which travels faster 
over more salient paths, and look for the first entity which the 
ptXlse reaches. The saliency is simulated by the cluster 
structure descrihea above, The parallel process of the spreading 
signal is simulated by interleafing deeper pfobes from salient 
clusters with shallower probes from less salient clusters. For 
example, i f  "streets consist of blocks" is  a c l u s t e r  1 fac t ,  t h e n  
we might probe for a cluster 1 fac t  involving syreets and a 
cluster 2 Eact involving blocks at roughly the same time, After 
one plaus ib le  antecedent is found in this way, t h e  search is 
continued for possible antecedents which are n e a r l y  as plausible. 
If after a time no plausible antecedents are found, the search 
is discontinued. 
Searches for  antecedents are conducted not only for entities 
but also for definite noun phrases that the nominalization trans- 
formations of t h e  syntactic component have turned into statements 
3 5  
- -e .g .  "The walk was t i r i n g " .  Here we look back for a statement 
whose predicate is "walk" or from which a statement involving 
"walkn can be i n f e r r e d .  There are  cases in which the required 
inference  is in f a c t  a summary o f  an entire paragraph--e.g. 
"These actions surprised. , . "--although of course we cannot 
handle these cases. 
Consistencv. Each of the plausible antecedents is checked 
for consistency. Suppose X1 is the definite entity which prompt- 
ed the search and its properties are 
and X2 is the proposed antecedent with properties 
We must cycle through the q ' s  and the r ' s  to ensure they are con- 
sistent properties. Of course, to prove t w o  properties q(X) and 
r(X) inconsistent can be an indefinitely long process with no 
assurance of termination. One admittedly ad hoc way we get 
around this is by placing into a special cluster  those f a c t s  we 
feel are likely to lead quickly to a contradiction. The second 
tool we use for  deriving inconsistencies may t u r n  out to be 
qui te  significant. 
In the course of processing, the lattice described abave is 
constructed for several predicates. They c o n t a i n  in fo rma t ion  
which can be useful i n  deriving a n  inconsistency. Suppose we 
have a t ex t  in which "the block" occurs explicitly several times. 
Toward the end of it, we encounter  
"Turn right on to  Adarnii Street. The library 
fs at the end of t h e  block" .  
The search algorithm looks first for explicit mentions of "blockl" 
and finds them. Yet none of these entities is the one we want. 
Intuitively, the reason we know this is our almost visual feeling 
that we are already beyond those points. 
The lattice consistency check corresponds precisely to this 
feeling. If a definite entity X1 is a point or interval in a 
lattice or at a point or along an interval, we ask if the propos- 
ed antecedent X2 is or can be related to a portion of the lattice. 
If so, then s i n c e  the lattice represents a transitive relation, 
we need only ask i f  there is a path in the lattice from X2 to XI. 
If there is, they cannot be the same entity. 
Many cases which pass for applications of the supposed 
recency principle--"Pick the most recent plausible antecedentn-- 
are in reality examples of this consistency check. The earlier 
plausible antecedent is rejected because of lattice considera- 
tions. 
As the text is processed, the whole structure of the 
discourse is built up. When a definite noun phrase is encounter- 
ed, this discourse structure is known and it is this knowledge 
that is used to determine the antecedent rather than the linear 
ordering of the words on the page. 
Competition among Remaining Plausible Antecedents. Even 
after the consistency checks, several plausible antecedents may 
remain, forcing us to decide among them on less certain criteria. 
To do this, we appeal to the Principle of Knitting again and make 
the choice that will maximize the redundancy in the simplest 
possible way. 
A probe is s e n t  out f r o m  the definite entity and from each 
plausible antecedent.  Each plausible antecedent i s  searched for 
properties it has in comon with the definite entity. Common 
properties Count most if they are already in the Text, an8 with- 
in the Lexicon, comon properties count more if they are within 
more salient clusters or they result from shorter chains of 
inference. 
Default. Like the higher predicate algorithm, the definite 
noun phrase algorithm has a default feature. If the uniqueness 
conditions fail and the search turns up no antecedent, we simply 
introduce a new e n t i t y .  In fact, in the direct ians  texts there 
are a disproportionately large number of default cases, for "the 
object" may simply be the object you will see when you reach 
that point in following the directions. 
Other Anaphora. We have not y e t  implemented rou t ines  for 
handling other anaphora. However, we believe they a re  very 
similar to the definite noun phrase rou t ine ,  w i t h  c e r t a i n  d i f f e r -  
ences. For entities tagged with demonstrative a r t i c l e s ,  we  do 
not check uniqueness conditions, and the search will be narrower 
since the antecedent must be an entity or statement actually 
occurr ing  in t he  text. For pronouns also, no uniqueness cond i -  
t i o n s  are checked. The search will turn up more consistent 
plausible  antecedents, and a correspondingly greater burden  will 
be placed on the competition routine. 
INTERSENTENTIAL CONNECTIVES 
We de tec t  unstated inter-sentence connectives by matching two 
successive sentences S1 S2 with a small number of common 
38 
patterns. In the directions texts the patterns are usually few 
and simple. The most common are 
1. S1 asserts a change whose final state is asserted or 
presupposed by S 2 .  
2. S1 asserts or presupposes a state which is the initial 
state of a change asserted by S2. 
(These are likely very common patterns in all narratives ,)  For 
example, in the text 
"Walk out the door of this building. Turn right. 
Walk to the end of the black",  
pattern(1) j o i n s  the first two sentences, where the state is 
"You at X", Pattern(2') joins the last two sentences, where 
again the state is "You at X-". Note moreover that the sentences 
axe interlocked by n second application of the two pa t te rns :  The 
first sentence assumes an angular orientation which is the 
initial state of the change asserted in the second sentence. 
The final state of this change is assumed by the third sentence. 
In addition to providing the discourse with structure, this 
operation i s  one of t h e - p r i n c l i p a l  means by which implied entities 
in one sentence, like X above, are identified with those in 
another. 
When pqttern (2) is applied, we delete the independent occur- 
rence of the s t a t e  in the Text, so that subsequently it ex i s t s  
only as one intermediate state ih a la rger  event. Changes across 
time are handled in this way. 
TASK PERF-ORMANCE COMPONENT 
Arbitrary Decisians, The semantic operations are quite 
39 
g e n e r a l  and can be used for any application. The augmented and 
i n t e r r e l a t e d  Text i s  t h e n  handed aver to the task performance 
component, which of course is specific to the a p p l i c a t i o n .  
Our task component first makes arbitrary decisions r e q u i r e d  
by the map but not given in the text. Both natural language 
d i r e c t i o n s  and ske tched  maps allow information to be incomplete 
and imprecise, but in different ways. Far example, in 
nTurn right at the third street or the second stoplight". 
we must decide whether to put the first stoplight at the first 
or second street, 
The l a t t i ce  representing the p a t h  "your' take must be complete 
i n  the sense t h a t  it i s  continuous, begins at the initial loca- 
tion, and ends at the desired goal, and that the relative loca- 
tions of all points on the path are known. The lattide is 
complete if and only if there is a directed path passing through 
every point in the lattice at least once. If it is not complete, 
it is completed by supplying t h e  fewest possible new links. 
Gsometr-izing the Lattices. The second task operation is to 
c o n v e r t  the topological lattice representation into the geometric 
r e p r e s e n t a t i o n  required by the maps. First we assign d i r e c t i o n s  
to all t h e  points in the angular orientation lattice. In the 
simplest case we may have something like 
where "a - b" means direction b results from a clockwise 
rotation of d i r e c t i o n  a. If no explicit directional information 
4 (0 
is present, we simply assume a, c, and e are the same direction, 
and b and d are the same, and then assume the two directions are 
at right angles, Then in the distance lattice, contiguous or 
overlapping paths which share the same orientation are assumed 
to be parts of the same path and are mapped into a straight line. 
Information about names is accessed and assigned to the streets 
and buildings and the map is drawn, 
Specific Systems with a General Semantic Component. We are 
aiming not so much at the construction o f  a general natural 
language processing system, which still seems reasonably f a r  o f f  
b u t  a t  an easier way of constructing specific systems. The case 
of syntax is instructive. It would be foolish for one who is 
building a natural language processing system to build his 
syntactic component from scratch. Large general grammars and 
parsers for them exist (e.g. Grishman et al 1973, Sager & 
Grishrnan 1975). It is easier by several orders of magnitude to 
begin with a genera l  grammar and specialize it, by weeding out 
the rules for constructions that don't occur in the texts one is 
dealing with, and by adding a few rules f o r  constructions and 
constraints peculiar to orre's application. 
We are trying to make a similar facility available for the 
most common kinds of semantic processing. Specializing the 
general semantic component would consist of several relatively 
easy steps. First the Lexicon would be organized into a 
cluster structure appropriate to the task. At worst, this would 
mean specifying the necessary knowledge in a fairly simple format. 
If a very large Lexicon were available, this could mean no more 
than designating for each fact the cluster it should appear i n .  
Cer ta in  inferences could be made obligatory while others which 
are irrelevant t o  the task  could be l e f t  out of the special  Lexi- 
con altogether. Second a Task Component would be built which 
would take, as ours does, the semantically processed Text, and 
use it t o  perform t h e  task. W e  are demonstrating the usefulness 
of this approach in performing a task involv ing  a v i s u a l  repre- 
sentation. It is likely to be useful in other sorts of tasks also. 
BIBLIOGRAPHY 
Grishman, R., Sager, N., Raze, C., & Bookchin,B.,"~he ~inguistic 
String Parser," Proc. NCC, M I P S  Press, Montvale, N . J .  1973. 
Hobbs, J e t  "A Model for Natural Language Semantics, Part I: The 
Model," Yale Univ. Dept. Comp. Sci. Res. Rep. 36, Nov. 1 9 7 4 .  
Hobbs, J., and Grishman, R., "The Automatic Transformational 
Analysis of Engl jsh Sentences: An Implementation," 
Submitted to International Journal of Computer Mathematics. 
-- - 
Holzman, M., "Ellipsis in Discourse: Implications for Linguistic 
Analysis by Computer, The C h i l d ' s  Acquisition of Language, and 
Semantic ~heory," Language and Speech (1971, 86-98. 
Joos, M., "Semantic Axiom Number One," Language (1972) 257-265 .  
Hnuth, D. The Art of Computer Programming, - 3 ,  Addison-Wesley, 
Reading, Mass., 1973. 
Minsky, M., "A Framework for  Representing Knowledge," MIT A1 Memo 
306, June 1974. 
Sager, N., and Grishman-, R., "The Restriction Language for Compu- 
ter Grammars of Natural Language," CACM 18, 7 (7/75) 390-400, 
- 
American Journal of Computational Linguistics Microfiche 32: 42 
PERRY t. MILLER 
Massachusetts Inst i tute of Technology 
Cambridge,  Massachusetts 02139 
ABSTRACT 
\Jheh a user interacts w i t h  a natural language system, he may well 
use words and expressions which were not anticipated by the system 
designers. This paper describes a system which can play TIC-TAC-TOE, and 
discuss  the game while it is in progress. I f  the system encounters new 
words, new expressions, or inadvertent  ungrammaticalities, it attempts to  
understand what was meant, through contextual inference, and by asking 
i h t e l i i g e n t  c larifying questions of the user.  The system then records 
the meaning of any ne9 words or expressions, thus augmenting its 
1inguist;lic knowledge i n  the course of user interaction, 
A number of  systems tire being developed which communicate with 
users i n  a natural  language such as  English. The u l t imate  purpose of 
such systems is t o  provide easy computer access to a technically 
Onsophisticated pepon.  When such a person interacts with a natural 
language systemr, however, he is quite l ikely  t o  use words and expressions 
which were not  anticipated. To provide truly natural interaction, the 
system should be able t o  respond intell igently when this happens. 
Most current systems, such as those of Winograd [ l o ]  and Woods 
I l l ] ,  are not designed t o  ;ope wi th  such "l i igu is t i c  i n p u t  uncertainty." 
Their parsers f a i l  completely i f  an i n p u t  sentence does not use a 
s p e c i f i c ,  b u i l t - i n  syntax and vocabulary. A t  the other extreme, systems 
l i k e  ELIZB [93 and PARRY [ Z ]  allow the user to type anything, but make no 
attempt t o  fully understand the sentence. The present work explores the 
tnlddle ground between these extremes: developing a sys.t;em which has a 
great deal of knowledge about a particular subject area, and which can  
use this knowledge to  make language interaction a flexible, adaptive, 
learning medium. 
In pursuing t h i s  goal, the present work is  most closely related 
t o  work being dona i n  the various speech recognition efforts [5 ,  7, 8, 
121 which ara studying how l ingu i s t i c  and semantic constraints can h e l p  
deal w i t h  the ACOUSTIC error and uncertainty of speech. The adaptive 
system, however, is designed t o  deal with a much mors LINGUISTIC type of 
uncertainty. 
When people use unfamiliar words or expressions in conversation, 
we can usually deduce from context what is meant, and i f  not, we can a t  
least ask inte l l igent  clarifying q u ~ s t i o n s .  To allow the machine to  do 
the same, there must be a very flexible interaction of syntax and 
$emantics i n  the parsing/understanding process, There must be a 
dif ferent  parser organization, and a more f l e x i b l e  use oP l i n g u i s t i c  and 
semantic constraints ,  than i s  p f e s e n  t in current natural language 
sys tern . 
The adaptive system is a step towards t h i s  goal  Tha cu r ren t  
implementation i s  a prototype, design'ed to  i l l u s t r a t e  many o f  these 
ideas, and t o  t i e  them together in a restricted system t h a t  is complete 
but not t o o  complex. The system's domain o f  discourse is TIC-TAC-TOE: it. 
plays a game and discusses the game in progress. It has a ( c u r r e n t l y  
limited) se t  o f  semantic concepts, and attempts t o  interpret the u s e r ' s  
sentences ih terms of these. The set of semantic concepts is FIXED. The 
system does not attempt t o  learn new concepts, merely new ways of 
describing concepts that  are already famil iar.  
When t h e  system encounters a new word or a new phrasing, it uses 
contextual information t o  detername the p o s s i b l e  meaning, and to ask 
clarifying questions which a re  as i n t e l l i g e n t  as p o s s i b l e .  It then 
remembers the meaning of the new e&pressfon, and w i l l  use it i tse lF *en 
it talks. 
2. SAHPLE SESSION 
The best way t o  introduce the system is t o  show i t  in o p e r a t i a n .  
In the sample session that follows, user input is pteced~rd by 'U:", 
machine output  by and comments added by the author arg in small 
type, enclosed in brackets, 
(HACHINE: I PLACE AM X IN TClE TOP LEFT SQUARE) 
[The machine makes its opening move. ] 
(USER: PLAY A ZERO IN THE CENTER WARE) 
(H: 1s ZERO A NOW HEANING 0 )  
(U: YES) 
(H: OK) 
[The new word *zeroa is added t o  the machine's vocabu1ary.l 
(R: I PLACE AN X IN THE BOTTOM RIGHT WARE) 
(O: SLAP Ab4 0 IN THE BOTTOV! LEFT CORNER) 
(PI: IS (TO SLAP SOMETHING SOREWHERE) A WAY OF SAYING (70  PLACE SOMEmING 
SOMEWHERE)) 
(U: YES) 
(19: OK) 
[ A  new surface framer (as described in section 4 )  I s  added to the set  sf 
surface b r a e s  which express the concept of making a move.] 
( m :  1 SLAP AN X IN TWE TOP RIGHT SQUARE) 
f n t h i s  sample sass ion ,  the machine uses i t s  newly acquired vocabulary 
a t  every opportunity.) 
HOU CORE YOU PLACED AN X IN THE TOP RIGHT SQUARE) 
(H: IS (HOW CQHE MMEONE DOES SOHETHING) AN EXPRESSION ISEANIMG ( l!lOES 
SOMEONE 00 SQMETHING)) 
(U: YES) 
(M: OR) 
(H: TO-BEAT YOU) 
[ A  new surface frme i s  added t o  those sxpssssing the concept ' I 
Syntactic featuras are associated w i t h  each such frauge i n d i c a t i n g  such 
things as Wether subject-verb invsrsion is ds be DerBomed.1 
(U: CAN YOU CURRENTLY BEAT M E )  
m: 1s CURRENTLY AN ADVERB REFERRING TO THE TInE OF A RWE) 
[These are the only  adverbs the system knows abou t .  In f ac t ,  a t  present,  
the system ignores adverbs in its sewantic processing.  I %  asks the 
question because it wants t o  account for all t h e  words in the sentence.  
(U: YES) 
'(M: OK) 
(11: YES) 
( M : r s WEST AN ADJECTIVE ~ E A N I N G  
EITHER 
(1: CORNER) 
( 2 :  LEFT) 
(U: 2) (n:  or;^ 
(H: NO) 
[Notice that t w o  top squares contain an x .  However, only the l e f t  onel 
was played while the bottom r ight  square was Free. Therefore the systcszn 
concluded t h a t  the top l e f t  square was being described. This example 
i l lustrates  how contextual information can be used t o  ask as intelligent 
a cBarifying question as p a s s i b l a . ]  
(U: *yOW COME YOU PLACED AJ4 X IN THE TOP EAST SQUARE) 
(!I: IS EAST AN l@JECTLVE NEAWXNG) 
EITHER 
(1: RIGHT) 
(2: WEST) 
( 0 :  l p  
(U: on) 

M IS (TO LAY SONETHING SOHEWHERE) A WAY OF SAYING (TO SLAP SOflETHING 
S0UEWERE) ) 
(U: Y E S )  
(M: OK) 
(H: IS (TO POLISH SOMEONE OFF) A WAY OF SAYING) 
E I THER 
( 1 : ( TO BEAT SOMEONE) ) 
(2: (TO LOSE TO SOMEONE)) 
( 3 :  (TO TIE SOMEONE)) 
(U: I )  
(?'?: OK) 
(R: BY LAYING AN X ON WE TOP CENTER CELL) 
[ I f  t h i s  same session were subsequently repeated,  sf course, the system 
would not  need t o  ask any questions of t h e  ushJr. 1 
2.1 Comments on C u r r e n t  Lirnitatians 
There are a number of l i m r t a t i o n s  to the a d a p t i v e  system as it 
now s tands .  Some of these may be apparent in the smple session, bud an 
in t roduc t ian  t o  the system is not complete without discuss ing  them 
explicitly. 
(1) The number of concepts ava i lab le  t o  the system a t  present is very 
small. T h i s ,  in fact, is why the system's first guess is usually the 
correct one. I f  the sentence is at a l l  with in  the systea's 
comprehension, t h e  options as to its meaning a re  currently q u i t e  limited. 
( 2 )  The range of expressive devices  presently recognized is q u i t s  
limited as well. For instance, the  system does n o t  recognaze relative 
clauses, con junctions, o r  pronouns (except f o r  1 and you).  
( 3 )  The system currently d e a l s  only  wi th  TOTALLY U N F M I L I A R  words and 
expressions in this adaptive fashion, It w i l l  not correctly handle  
familiar words which are used in new ways (such as a noun used eas a varb, 
as i n  wzero the center  squaren) .  
( 4 )  The system tr ies  to map the meaning o f  new wards and expressiuns 
into i t s  speci f ied  s e t  of underlying concepts. It then displays its 
hypotheses t o  the user, g iv ing  h i m  only the option of saying yas or nu. 
The user cann-ot say "no, not qui te ,  it meahs . . .". (Thus concepts like 
V h e  'northeast1 square" o r  "the 'topmost' squarew would ba confusing and 
not correctly understood.) 
The present simple system h a s  been developed w i t h  two goals in 
mind: (1) to explore the techniques required t o  achieve adaptive 
behavior,  and ( 2 )  t o  h e l p  fornulate the issues which will have t o  be 
faced when incorporating these techniques in to  a much broader natural 
language system. 
3 .  OVERVIEW 
Fig. 1 shows ths various stages that  the Adaptive System gees 
through in understanding a sentence. In this sectian, we s h a l l  watch 
while t h e  system processes the sentence "Mow came you placed an x in the 
top right ~ q u a r e . ~  
( 1 )  Local Syntact ic  Processing: 
In this f i r s t  stage, the system scans the entire sentence look ing  f o r  
local  cons t i tuents .  These i n c l u d e  Hsimplem noun phrases (NPs) and 
prepositional phrases (PPs), ("simplen meaning 'up to the head noun but 
not including any modifying clauses or phrases"),  and verb groups (VGs) 
consisting o f  verbs together with any adjoining rnodals, auxilliaries, and 
adverbs. In t h i s  instance, the  system Finds the t w o  N P s ,  "youe and "an 
xm,  the PP "in the top r ight  squarem, and the VG nplacedw. 
( 2 )  Semantic Clustering: 
A t  t h i s  s tage ,  the c lause- leve l  processing s tar t s .  U n l i k e  most systems, 
this clause- level  processing is driven by SEMANTIC r s la t i onsh ig s ,  rath-er 
than by syntactic form. It uses a semantics-first kclustssinsg*, with a 
sscondary use of syntax for cormnents and confirmation+ In t h i s  example, 
a l l  t h e  l o c a l  constituents found can be clustered i n t o  s description of e 
single concept: t h a t  o f  making a nave, Section 4 describes the mechanics 
of this stage in more detail. 
( 3 )  Cluster Expansion and Connection: 
During t h i s  stage an attempt I s  mada t o  account Psr each word in t h e  
sentence by expanding the concept c lus ters ,  and i f  there i s  more thaw 
one, by j o i n i n g  them together t o  form an e n t i r e  multicXausa1 sentence- 
In t h i s  case, ths concept c luster  rnlght b s  axpanded I n  two ways. 
a )  One possiblllty night  be t h a t  I t  i s  a "MOW" type q u e s t i o n ,  and t h a t  
wcornc.tn is some sort of adverb,  However this possibility v io la t s f  a 
semantic constraiet, since the system is not s e t  up t o  answer haw a move 
is made; only how t o  win,  how t o  prevent sorneons From winning, e t c .  
There fore  this possibility is ignored. 
b) The other p o s s i b i l i t y  f r; t h a t  "how come" i s  a new way of  describing 
soma other clause f u n e t t o n .  
(4) Contextual Inference; Clarification; and Response: 
During t h i s  f i n a l  staga, any c o n t e x t u a l  inf~rrnatfsn avai lable  is brought 
t o  bear on araas of  uncertainty, any necessary clarifying questions are  
asked, and the system responds t o  the sentencs. In this example, the  
only uncertainty is the meaning of "how comew. Since t h i s  i s  the main 
sentence 
1 
Xocal constituents 
concept 
clusters 
complete 
sentence 
hypothesf s 
system responds 
t o  sentence 
Fig. 1: Adaptive System Overview 
clause of the sentence, the possibility of  its b e i n g  an Wn or *aftsra 
clause are discarded.  The remaining p o s s i b i l i t i e s  are n i m p e r a t i v s w ,  
"hown, m ~ h y n ,  and "canw. The system does n o t  answer %own and "canw 
quest ions i n  relation t o  making moves. Similarly, "imperativen does n o t  
make sense since the action described is  a previously made move. 
Therefore the system asks i f  "How come someone does somethingw means Vhy 
does someone do somethingn. The user answers "yesn, so  the system stores 
t h i s  new way of asking "whyn, and proceeds t o  answer the question. 
4 .  SEMANTICS-FIRST CLAUSE-LEVEL PROCESSING 
One of  the major differences between t h i s  approach t o  parsing and 
tha t  of a top-down, syntax-driven system (such a s  Moods' or Winograd's) 
is the order i n  which s y n t a c t i c  and semantic processing is done a t  the 
clause level. 
In  a top-dom system, a sentence must exactly match t h e  b u i l t - i n  
syntax before semantics can even be cal led and given the various 
const i tuents  o f  a clause, T h i s  IS clearly undesirable when one i s  
dealing with  i n p u t  uncertainty, since one cannot be sure exact ly  how the  
user will phrase his sentence. One would prefer to Bet semantics opera%@ 
First on any local consituents present, so that i t  can make a reasonable 
grgss as to what is being discussed. 
As semantically-rslated clusters of local constf  tuents are found, 
syntax can be consulted and asked to comment. on the rslative 
grmmaticality of the various c lus ters .  If there are two competing 
semantlc inte~pretations of one part of  a sentence, and syntax l i k e s  one 
much better than the other ,  then the "syntactically pleasing" 
interpretation can be pursued f i r s t .  Later, i f  this does not pan out, 
the syntactically irregular possibility can be looked at  as wsP1. In 
t h i s  way, syntax can he lp  guide the system, but is not placed in a 
totally controlling p o s i t i o n .  
A by-product advantage o f  t h i s  s e m a n t i c s - f i r s t  approach i s  that 
the system can handle mildly ungrammatical input without any ex t ra  work,  
In addit ion,  t h e  semantics-first  c lus tar ing  approach lends i t s e l f  q u i t e  
naturally t o  handling sentence fragments. 
I n  the remainder of t h k s  s e c t i o n ,  we describe how the adaptive 
system organizes i d s  linguistic knowledge t o  implement this semantics- 
f i r s t  approach. As we s h a l l  s e e ,  there are three componeflts o f  this 
knowledge. 
( a )  Ths local racognizars which initially find local constituents. 
recognizers are represented t n  Augmented Transition Network [ I l l  f o m ,  
are q u i t s  s i m p l e ,  and are not described further i n  t h i s  paper .  
(b) Clause-level knowledge sf how actions and clause-functions are 
described.  This  knowledge is expressed i n  a descriptiva fash ion  which 
makes it msily manipulabla, and easy to add to. 
( c )  Clause-level syntac t ic  knowladge which is sxprssred ira a domain- 
indebpendent fom. 
4 . 1  Knowledge of how A c t i o n s  are Described 
Figure 2 i l l u s t r a t e s  how t h e  system s t o r e s  i t s  knowledge sf how 
act ions  ( o r  events) are described. This knowledge is stored a t  two 
l eve l s  : the conceptual  l e v e l ,  and t h e  surface (or expressive) l e v e l  
As shown in F i g .  2, the  concept PLACE represents  the a c t  o f  
making a TIC-TAC-TOE wove. 
( a )  On the  CONCEPTUAL l e v e l ,  there are three "conceptual s lo t s '  
i n d i c a t i n g  the  actors which are involved  in the ac t l on :  a player, a @ark, 
and a square. 
(b) On the SURFACE, or expressive, level there is a list sf surface 
frames each indicating one poss ib l e  way t h a t  t h e  concept  can be 
expressed. Each surface frame conslsts  o f  a verb p l u s  a set  of s y n t a c t i s  
case frames to be f i l l e d  by t h e  ac tors .  
(Notice that neither the conceptual slots nar  the sur face  frames i n d i c a t e  
explicitly t h e  order in which the varlous constituents are to appear Fw a 
sentence.) 
When the system processes a sentence, it fills t h e  concsp tua l  
shots w i t h  local  constituents found rn the sentence I f  i t  h a s  f o u n d  a 
f m i l i a r  verb, then i t  a l s o  gets  any surface e ( s )  associated w i t h  
that  verb. A t  this p o i n t  i t  c a l l s  syntax,  a s k i n g  for c s m e n t s .  
For instance,  i f  the input sentence is "1  place an x in the 
corner", t h e n  all the conceptual slots of #PLACE would be f i l l e d ,  and the 
system would pass the following string to syntax wagen% verb o b j  ppw . As 
a result, clause-level syntax does not see t h e  a c t u a l  constituents of  the 
sentence, only t h e  l a b e l s  specifled I n  the surface case frame, plus 
information indicating number, tense, etc . 
An interest ing aspect o f  this approach is t h a t  t h e  clause-level 
syntax is entirely domain-independent. I t  knows no thing about TIC-TAC- 
TOE, o r  even about the words used t o  talk about TIC-TAC-TOE. Tke surface 
frames allow semantics t o  t a l k  t o  syntax purely in t e rms  o f  syntact ic  
labels.  As a result, one could write a single syntact ic  module, and t h a n  
insert i t  unchanged in to  many domains. 
4.1 .1  Using t h i s  Information 
In t h i s  s e c t i o n ,  we descr ibe i n  more d e t a i l  how this  knowledge 
can be used when processing a sentence.  
(1) I f  the verb and constituents a re  familiar: 
I f  t h e r e  i s  no uncertainty i n  a c lause ,  then each const i tuent  can 
be put  into one of Ghe conceptual s lots ,  and any surface frames 
associated w i t h  the verb can be examined The frame ~ n d i c a t e s  the csse  
(agent, object, etc. ) associated with each c o n s t i t u e n t  whon that  verb is 
used. The frame is used t a  create a string of case l a b e l s  t h a t  a r e  s e n t  
t o  syntax for  coments .  
For instance, iF the sentence is "1 place an x i n  the center 
CONCEPT: PLACE 
CONCEPTUAL SLOTS: 
P: player 
H: mark 
S: square 
SURFACE FRAMES: 
VERB: place (as in: 
AGENT: P m I  place an x i n  the centera) 
OW: PI 
in: S 
VERB: play (as in: 
AGENT: P sf play an x in the centers) 
ow: H 
In:  S 
VERB: play (as in: 
AGENT: P w X  play the center") 
00J: S 
FLg . 2 : Linguis t i c  KnowleMge about Actions 
square", the string passed to syntax is "agent verb obj  pp". Syntax 
replies t h a t  t h e  sentence follows normal order. Had the  string been 
"verb obj  pp" syntax would reply t h a t  the subjec t  had been deleted .  I f  
the s t r i n g  was @'do agent verb obj ppn, syntax would reply that subject-  
verb inversion had taken p l a c e .  Given "gent obj verb ppn,  syntax would 
reply that  t h e  object was out of position. 
Thus syntax i s  se t  up  to notice both g~irnmcatical and 
u n g r m a t f  cal permutations i n  constituent order, and t o  comment 
appropriately. The system must then decide how t o  interpret these 
comments. 
For instance, if syntax repl ies  t h a t  the object is out of 
position i n  the clause,  or t h a t  there is incorrect agreement in number 
between subject and verb, the  system may decide that t h e  user has made a 
minor grammatical error, and allow the sentence t o  be processed anyway, 
especially if there i s  no better  interpretation of the sentence.  In this 
way, clause-level syntax plays an a s s i s t i n g  role rather than a 
castrolling r o l e  i n  t h e  analysis of  a sentence. 
( 2 )  If a constituent is unknown: 
If an unknown constituent is p r e s e n t ,  then both the frame and 
slot information can be used to h e l p  resolve its meaning. For ins tance ,  
suppose the sentence is " I  place a c r o s s  in the  canter squarew, and the, 
word ~ c r o s s u  is unfamiliar, 
Here, during t h e  semantic clustering, t h e  conceptual s l o t s  for a 
player and a square can bs f i l l e d  by "Iu and "in the center square", b u t  
the slot for a mark is u n f i l l e d .  I n  a d d i t i q ,  there is the unknown 
constituent "a crossg.  
A natural hypothesis,  therefore, is t h a t  the unknown constituent 
refers t o  a type of  mark. Since the verb is familia~, a surface frme is  
avaflable. Next, assumtag the unknown constituent is a mark, the s t r ing  
"agent verb ob j  ppw can be passed to syntax. Men syntax approves, this 
offers addi t iona l  confirmation t h a t  the hypothesis is probably right.  
Subsequent evaluation of this hypothesis indicates t h a t  the 
sentence makes sense only if the mark referred to is Etn x ,  so the system 
asks i f  "crossu is a noun meaning 
( 3 )  I f  the verb is unknown: 
I f  an unfamiliar verb is used, then  there i s  no sur face  fsme 
availabls t o  h e l p  guide the analysis. Instead, syntax must ba used in a 
different mode t o  propose what the surface frame should be. 
Suppose the sentence is "I  p lunk an x in the center squareM. 
Here, a l l  the constituants can be clustered into the concept #PLACE, but  
t b r e  is an unknown word, and no verb. Ths loglcrrl hypothasis is t h a t  
t h e  new word i s  a verb. A special syntactic module i s  therefore passad 
t h e  followfag s t r i n g  "NP(P) verb(p1unk) NP(M) PP(in,S)# This module 
examines the  string and produces tn new Frame: 
VERB: plunk 
AGENT: P 
OW: R 
in: 8 
The system can then ask if "to plunk something somewherew means 
" t o  place something somewheren, and upon getting an affirmative reply, 
can add t h e  new frame to those associated w i t h  the concept PLACE. 
Since the system uses the surface frames to generate its o m  
replies, it can now-use this new frame i t se l f  when it talks. When the 
system wants to generate a c lause ,  it passes a selected frame, the 
constituents, and a list of syntactic features to a clause generator 
which o u t p u t s  the specified form. (Thus, c l aus s - l eve l  syntax can be used 
by the  system i n  three different  modes: (1) to comment on the 
g r m a t i c a l i t y  of a s t r i n g  of case markers, (2) t o  constrbct  a new 
surface frame, and ( 3 )  t o  generate clauscas when t h a  system itself 
replies .  ) 
4.2 Knowledge of' how Clause-Functions are Described 
As i l lustrated i n  Fig. 3,  knowledge of  how clause-function 
concepts are described i s  also expressed as two Lexals. 
CONCEPT: #WHY 
CONCEPTUAL SLOTS: 
ACTION: #PLACE 
SURFACE F 
Why ACTIQN(SV1NV) ( a s  in: 
*Why does someone do somsthkng") 
flow come ACTION() ( as  i n :  
"Now come someone does something") 
Fig. 3 : Linguist ic  h o w l  edge about Clause Functions 
Each clause function has a conceptual s l o t  indicat ing what types 
of action can be used w i t h  t ha t  clause type ( i n  t h i s  case, the  ac t ion  
#PLACE), and a list of surface frames ind ica t ing  di f ferent  ways i n  which 
t h e  cancspt can be expressed. 
A clause-type frame currently includes any special  words which 
introduce the c lause  ( i e .  "whyn or "how comen),  together w i t h  a list sf 
syntactic proparties which should be present in the clauss. This list of 
syntactic properties might include SVIMV, nsubjec$-verb inversionw (as in 
"why does someone do something"), ar 9 u b  ject  deletionH, 'ING fomm, and 
"use of a particular preposition* (as  i n  "from doing somethingw). 
These syntactic features, however, need not bs inflexible rules. 
Sentence understanding can still psocaed wen  i f  tha  syntact ic features 
found by syntax do not exactly match those spec i f ied  by the clause- 
function frame. Thus, an inadvertent ungrammaticality cam readily be 
recognized as such, and processing can cont inue .  
4.2 .1  Using the Clause Function Knowledge 
In this section we examine how this clause function knowledge can 
be used. 
(1) With no uncertainty: 
I f  the i n p u t  sentence is "Why d l d  you place an x in the center 
squarew, then during the semantic clustering the s tr ing  Rdo agent verb 
obj ppu i s  passed t o  syntax, which repl ies  t h a t  subject-verb inversion 
has taken place. 
When exarninlng t h e  whole clause, the system sees t h a t  it e x a c t l y  
matches one of the surface frames for  a #WHY-type question, since it 
starts  with the word n ~ h y V i n d  contams subject-verb inverslbon, 
Suppose, however, the sentence had been "Why you place an x IR 
the center squaren, or "How come d i d  you place an x i n  the center 
square*. Each o f  these sentences matches a surface frame for  a MY-type 
question, except that i n  both cases subject-verb inversion i s  incorrect.  
In such a case, the system can, if it chooses, decide t h a t  the user has  
made a minor error, and allow the sentence t o  be processed anway. The 
locally-driven semantics-first approach Lets this happen i n  a natural 
way. 
( 2 )  A new surface frame: 
Another problem arises  when a new clause introducer is 
encountered, as i n :  "Wherefore d i d  you place an x i n  the center squareM. 
Here, as described i n  section 3 ,  the system hypothesizes that  this may be 
a new way of  asking a #WHY-type question. Since syntax reports that 
subject-verb inversion has taken place,  the system can therefore create a 
new surface frame: 
Wherefore ACTIOM(SV1NV) 
t o  be added t o  the frames associated w i t h  #WHY. 
B In summary, the adaptive -5ys tern stores i t s  l inguis t i c  knowledge 
i n  a very accessible form. I t  is not embedded in the parsing l o g i c .  
howledge of how actions and clause-functions are described is 
represented i n  a descriptive,  manipulable format. Syntax is domain 
independent, and is used only t o  make cornants, with semantics playing 
the guiding role. This organization allows the parsinglunderstanding 
process t o  proceed kn a f lexible  fashion, 
5 .  CONCLUSION 
Language communication is an i n h e r e n t l y  a d a p t i v e  medium. One 
sees t h i s  c l ea r ly  ~f one takes  a problem t o  a lawyer and spends time 
trying t o  assimilate t h e  r e l a t e d  " l e g a l e s e n .  One a l s o  sees i t  i n  any 
conversation where a persron is t r y i n g  t o  convey a complicated idea ,  
expressed i n  his own mental te rms,  t o  someone else. The l i s t e n e r  must 
t r y  t o  r e l a t e  t h e  words he Rears  to h i s  own set of concepts .  Language 
has ,  presumably, evolved t o  f a c i l i t a t e  t h i s  s o r t  of i n t e r a c t i o n .  
Therefore it is reasonable t o  expect  t h a t  a good deal  of the  structure of  
language is i n  some s e n s e  s e t  u p  t o  assist i n  this adap t ive  process. By 
t h e  same t o k e n ,  studying language from an adap t ive  standpoint shou ld  
p r o v i d e  a f resh p e r s p e c t i v e  on how t h e  va r ious  levsls of l i n g u i s t i c  
structure i n t e r a c t .  
REFERENCES 
[ l ]  D a v i e s ,  Q.J.M., and Isard, S.D., 'Ut terances as Programs, "resented 
a t  t h e  7 t h  I n t e r n a t i o n a l  Machine I n t e l l i g e n c e  Workshop, Edinburg, J u n e  
1972. 
[2] Enea, H . ,  and Colby, K , M . ,  ' Ideolectic Language Analysis f o r  
Understanding Doctor -Pa t i en t  D i a l o g s ' ,  Proceedings o f  t h e  3rd IJCAI, 
Stanford, August 1973. 
[3 ]  Fillmore, C.J. ,  'The Case for Case' ,  i n  'Universals i n  L i n g u i s t i c  
Theory', Bach and Warms (Eds.  ), Wolt, Rinehar t ,  and Winston, I n c . ,  
Chicago 1968. 
[ 4 ]  Joshi, A . K . ,  and Weischedel,  R.M., 'Some F r i l l s  far  the Hodaf TIC-  
TAC-TOE of Isard and Davies: Semantics of Predicate Complement 
Constructions,' Proceedings  of  t h e  3 rd  IJCAI, Stanford, August 1973. 
5 ] e ,  P .L., 'A Locally Organized P a r s e r  f o r  Spoken I n p u t ' ,  Corn. 
ACM 17, 11 -(Nov, 19741, 621-63@. 
163 Miller, P.L., 'An Adaptive  System: f o r  Natura l  Language Understanding 
and Assimilation', RLE Na tu ra l  Language memo No. 25, H I T ,  February  1974. 
[ 7 ]  Reddy, D . R . ,  Erman, L . D . ,  Fenne l l ,  R.B., and Nealey, R . B . ,  'The 
HEARSAY Speech Understanding Systemt, Proceedings of' the 3rd HJCAZ, 
Stanford, August 1973. [ a ]  Walker, D.E., 'Speech Understanding through Syntactic and Semantic 
Analysis', Proceed ings  of t h e  3 rd  IJCAI, Stanford, August 1973. 
[ 9 3  Weizenbaum, J . ,  'Eliza- a Computer Program f o r  the  S tudy  of Natural 
Comunicatian between Man and Machine', CACM 9 ,  1972. 
[ l o ]  Winograd, T.  Procedures  as a Representation of Knowledge Fw a 
Computer Program Tqr Understanding Natural Language, MAC-TR-84, P r o j e c t  
MAC, MIT, Cambridge, Mass., February 1971. 
[ l l ]  Woods, W.A., and Kaplan, R . N . ,  'The Lunar  Sciences Natural Language 
Information System" BBN Report No. 2265, Bol t ,  Beranek, and Neman Xnc. 
September 1971, 
[12] Woods-, W.A.,  and MakhsuP, J . ,  'Ovlechanical In fe rence  Problems i n  
Continuous Speech Understanding , Proceedings of t h e  3rd HJCAB, Stanford,  
1973. 
1575 ACL Mcetlng 
CONCEPTUAL GRAMMAR 
W I L L I A M  A ,  M A R T I N  
Kassachusetts Insti t u t e  of Tech~ology 
In OWL, an implementation o f  conceptual  grammar, t h e  two 
types o f  data items are symbols and concepts and the  two bas ic  
data composition operat ions  are specialization and restriction. 
A symbol is an alphanumeric s t r i n g  headed by ".  Symbols 
correspond to words, suffixes, pre f ixe s ,  and word stens in 
Znglish and the programer can introduce them a t  willm 
OWL concepts correspond t o  t h e  meanings of EEglish words 
and phrases. They are constructed using the  specialization ope- 
ration, comparable t o  CONS i n  LISP* (A B) is t he  specialization 
of A ,  a concept, by B, a concept o r  symbol. OWL f o r m  a branch- 
ing tree under specialization, with SOMETHING a t  the  t o p .  
Concepts are given properties by restriction, which puts a 
concept on the reference list of another  concept (compare proper ty  
l ists and S-expressions in LISP). A / B  is the r e s t r i c t i on  of  A 
by B. 
The categories in the specialization tree are semantic, but  
we use them also f o r  the purposes usually assigned to syntact ic  
dategories. 
A predication is a double specification of 2 model such as 
present tense or can. Examples are 
The pool is full of  water. ((PRES-TNS (BE (FULL 94TER)) J POOL/THE) 
The cookie can be in t h e  j a f .  ( (CAN (BE (IN JAR/TIIE))) COOKIE/THE) 
aob is the fa ther  o f  Sam. ( (PRES -TKS (BE (FATHE: SAM) ITHE) ) BOB) 
3ob hits the b a l l .  ((PRES-TNS (HIT BALLITHE)) Boa) 
Bob is hitting the b a l l .  ((PRES-TNS (BE (-ING (HIT BALL/THE))))BOB) 
Starting from t h i s  base we will discuss a number of issues 
buch as n~minalization incorporat ion,  and deep vs surface cases. 
American Journal of Computational Linguistics ~ i c r o f f c h e  32 : 58 
JOHN F.  BURGER, ANTONIO LEAL, AND A R I E  SHOSHANI 
System Development Corporation 
Santa Monica, California 90406 
m c T  
We describe a natural-language recognition system having both applied and 
theoretical relevance. A t  the applications level, the prwram w i l l  give a 
natural ccmmunications interface facility to users of existing interact ive  
data management systems. A t  the theoretical  level,  our work shows that  the 
useful infoxmation i n  a natural-language expression (its "meaning") can be 
obtained by an algorithm tha t  uses no formal description of synt-. The 
construction of the parsing tree is cont ro l led  primarily by semantics i n  the 
form of an abstraction of the nmicxo-world" of the DMS's func t iona l  capabil- 
ities and the organizat~on and semantic relations of the  data base content 
material. A prototype is current ly  implemented in LTSP 1.5 on tho IBM 
370/145 computsr at System Development Corporation. 
In a recent article in Scient i f ic ,  American, Dr. Alphonse Chapanis says, "Tf 
t r u l y  interactive computer ( ; y s t m  are ever to be created, they will ~omehow 
have to cope w i t h  the... errors and vio la t ions  of format tha t  are  the rule 
rather than the exception in normal human ccmmunication" [1] . An example 
dialogue produced by t w a  persons interacting w i t h  each other by teletype- 
writer to solve a problem as~igned to them by experimenters showed that :not 
one grernaaatfcally correct sentence appears in the  entire protocol. tl 
Many existing language pmcessors (woods ,  Kellogg , Thcmpson , etc.  ) [ 2,3,4) 
are limited to what Chapanis calls "Irmnaculate prose," that i s ,  "the sen- 
tences that are fed into the computer are parsed in one way or another so 
that the m e a n i n g  of the ensemble can be inferred frm conventional rules of 
syntax," which are a ?0- descr ip t ion  of the language. In effect, users 
are required to in teract  w i t h  these s y s t e m  in sme  formal language, or at 
least  i n  a language that has a formal representation i n  the computer system 
that  a user's expression must conform to (we are t h i n k i n g ,  in t he  latter 
instance, of Vhampsonls REL, which has an extensible formal representation 
facility). In addi t ion ,  most natural-language question-answering systems, 
including all referenced above, require that a user's data be restruct-wedl 
and reorganized acwraing t o  the pa r t i cu la r  data base requirements of the 
natural-language system to be used. 
A t  the level of a r t i f i c i a l  in te l l igence research [ti ,6 ,?'I , Mere is same 
interest in systems that recognize meaning i n  natural-language expressions 
by methods that dd not m i r e  compiler-like syntactic analysi~ of an 
expression prior to asmantic interpretation. We believe it is possible, 
practical, and feasible, using new lingufstic processing strategies, to 
design a natural-language interface system that will permit flexible, intu- 
itive coaansmicatiba w i t h  information management systems and other computer 
programs already in existence. This interface is open-ended in that it has 
no prejudice about t h e  user's system funckians and can be joined to almost 
any such system with relatively l i t t l e  effort. I t  i s ,  i n  addition, able to 
infer t h e  meaning of free-form English expressions, as they pertain to the 
host system, without  requiring any formal description or representation of 
English. 
THE SEMANTIC INTEREACE ALTERNATIVE 
The syntactic inflexibiiity of existing natural-language processors limits 
their usefulness i n  interactive man-madine tasks. O u r  approach does not 
use a collection of syntax rules or equations as they are normally defined. 
Instead, we  construct a dictionary in which w e  define words in terms of their 
possible meanings with respect to the particular data base and data manage- 
ment system (DMS) we want to use and according to the possible relations 
tha t  can exist between data-base and I3MS elements ( e . g . ,  an averaging func- 
t i o n  on a group CKE numbers) i n  the limited "micro-world" of this precisely 
organized data collection. Words appearing in a user's expression t ha t  are  
not explicitly defined are ignored by the system i n  processing the expres- 
sion; an example would be the  word "the," which is usually not meaningful in 
a data management environment. Wa thus avoid the expressive rigidity that 
formal syntactic methods hposa on tha user and the excesaivcs time and 
resource consumption tha t  results from the catibinatorial explosions usually 
produced by such rnethade. 
We distinguish in their def ini t ions  beween two types of words: content 
words m d  function w o r b  (or "operatore"). Content words are wads whoae 
'meaningsw are the objects, events, and concepts that make up the subjects 
being referred t o  by users, More precise ly ,  for data axetnagernent systems, 
these meanings (or "concepts") are the f i e l d  names and entz'y i d e n t i f i e r s  f o r  
*e data b-e and the names for available IHS operations such as averaging, 
s d n g ,  sorting,  comparing, etc. Function words serve as connectors of 
content words. Their use i n  natural language i s  to indicate khe manner in 
which neighboring conltent words ar'e intended to relate to one another. In 
the example "the salary of the secretary ," used belaw, "salary" and 
"secretary," are content  words, and "of" is a function word used to connect 
theta. 
Many cmntent wor& are context sensitive, In a particular data base, fo r  
btmcm, the ward "salary" may refer t o  the data-base f i e l d  name SECSAL if 
the saXW frs "of a secretary," but may also  indicate the f i e l d  name CLKSAL 
if it is a *salary of a clerk." In recpgnition of this we therefore def ine  
eaah aontent word by a set of one or more pairs of the form 
( ( X I  Y l )  (X2 Y2) . . . (Xn Yn)) 
where the Xi a d  Y i  are " o o n c e p ~ "  (that is, f i e l d  names, etc.) as described 
above. This expression may be interpreted as, "if the word so defined i r j t  
contactually related in a sehtance to Xl, its particular meaning in this 
centact  is Y1,  if it i s r  eo related b X2, it meme Y 2 ,  m d  ao forth." This 
particular oontextual mnaranfng af the word is callad its sense. Two content  
warm are consrid=& to  bls artmantically related i f  the in te rsec t ion  of  the 
X i ' a  fmtn the definition of one wort! w i t h  the Yi's from the d e f i n i t i o n  of 
U1Q other ira not empty. 
To get a more i n t u i t i v e  understanding of this process, suppose, again, t ha t  
a data base contains ent r ies  for both secretaries and clerks w i t h  salaries 
fox each. Suppose "Suzi&' is an instance of a secretary and  om" is an 
instance of a clerk. We then have three words defined as follms: 
Suzie ( (SUZIE SECY) ) 
Torn ( (TOM C-LK) ) 
Salary ( ( sECY SECSAL) (CLK CLKSAL) ) 
Processing me phrase "Suzie ' s salary" would i n t e r s e c t  the Y i  ( "  (SECY) " ) 
from t h e  def in i t ion  of "Suzie" w i t h  t h e  Xi's ("SECY" and "CLK") from t h e  
definition of "salary." The intersection is nan-empty ("(SECY)") , and, i n  
discovering the semantic relationship the sense "SECSALI-' is assigned t o  the 
word "salary." Similarly, "Tan's salary" assigns the sense "CLKSAL" t o  
"salary. !I 
A particular bplmentation of the natural-language interface processor 
operates for a par t i cu la r  DMS/data-base t a r g e t  system. It contains a 
particular &&ion- created for t h a t  t a r g e t  system. For a par t icu lar  dic- 
tionary, the s e t  of a21 l is ts  05 pa i r s  as described above, therefore, 
consti tutes the equivalent of a ~ a n c c p t  q ~ a p h  ox network for the part icular  
data b a a  malogous to those U R Q ~  hy many of the  more conventj-onall, parsers 
Pox semantic analysis folluwing (or during) the syntactic phase of parsing. 
In the analysis of a particular input by our system, two words i n  context 
are t e ~ t e d  using t h e  "intersection" method described abave and, if they are 
found to be semantically r e l a t e d ,  they are considered candidates fo r  
"connection" as descrrLbed below. Two words so connected ? o m  a phrase. 
Function words are defined as operators or processors t h a t  perform this 
semantic test .  The defini t ion of one function word  dif fers  fm that of 
another according to its slope (see belaw) and also in that  t h e  operational 
definition of a function word can reject a connection even though t h e  two 
words may be samntically related. In the operational def in i t ion  of t h e  
function word may be a list of acceptable concepts or a rejection list of 
unacceptable concepts. In most conceivable data bases, the phrase "salary 
in the secretary" would be thus rejected by the  function word "in. n 
As the analysis of an input  expression proceeds, a "clumpifig" of word and 
phr as e meanings more and more explicitly normally, 
processing of the entire sentence r e s u l t s  in a tree structure  made up of the 
connected senses of a l l  the content words fran the sentence. This  result we 
term the sentence qraph even though the input expression may not be a 
grammatically cmplete sentence. This sentence graph will be t ransla ted 
in to  statement. 
We recognize t ha t  the linear ordering of the words in an input expression 
is not entirely randm and t h a t  certain aspects of me function of syntax 
must be taken into accorunt. This is done by means of a new and pwerful  
azgorithm b k d  on what we cal l  the syntactic-semantic slope. Linguists 
generally recognize that whenever two units of meaning are combined, one is 
semantically domfnant and t h e  other subordinate, as a modifier is sub- 
ordinate to the modified word. A f t e r  coenbinatfon, the d d n a n t  word may be 
wed in m o s t  cases to refar to the canjoined pair. Thus, a "red herring" 
18 a "herring" (not a "red") , and the "salary of  t h e  secretary" is a 
"salary." If this relationship of dominance i s  represented vertically on a 
ltrectangular graph (i.e., dominance on the Y-axis),  and if t&e l i n e a r  order- 
ing of the words in the expression is represented on the X-axis in n o w 1  
left---right: order, then the connection of an adjacent pair of content 
words or phrases will describe a linear slope on the graph. The slope is 
positive eir negative as the dominating sub-unit is, respectively, to t h e  
right or to the left  of the subordinate sub-unit. For example, the phrase 
"red herring" makes a positive slope, thus: 
HERRING 
/ 
RED 
and "the salary of the secre=" makes a negative slope: 
S;71LARY 
Thus, the ~ p e r a ~ o n a l  meanings of fqnctian words operate on the meanings of 
nearby content words. Dominance is assigned, semantic relationships are 
verified, and the relationships so discovered are accepted or rejected. If 
accepted, the two word-meanings are connected, and the acceptable sense is 
assigned to the  dumllnant word. 
Eunction words may connect content words in "positive," "negative ," or 
"peak" connections. me follming are examples of each mannax of connection: 
1. "Of" is a negative operator, as in " the  salary of the 
SALARY 
2. " ' 8 "  is a positive operator, as in "the secretary 's  salary": 
3.  "And" is a peak operator, as in "Atlantic and Pacific.  " In 
contrast w i t h  positive and negative operators, peak operators add 
a representation of their m semantics i n t o  the structures they 
build ; 
AND 
\ 
A-IC PACIFIC 
4. Between any two adjacent content words there is an implicit "empty" 
operator t h a t  is a positive operator, as in "red herring": 
RED 
In general, all prepositions are defined as negative operators. This is 
equivalent Go the rule 
used by syntactic processors. The positive empty operator is equivalent to 
the rule 
N P + A x x r P 3 P  
and athew, while vexbe and conjunctions are  defined as peak operators, 
giving our atatemcnt o f  rules such errs 
s+NPvE'NP 
MP + NP CONJ NP. 
Each operator has the faci l i ty  to accept or reject  any semantic rejlation 
accordin9 to the precise def in i t ion  of the function word for the host  data 
management system.  
Progressive connection of word meanings and previously connected groups or 
"phrase meanings" results in a tree graph t h a t  we ca l l  the sentence qraph. 
For example, the question "What is ;t;he surface displacement of U S .  diesel 
submarines?" could, f o r  a particular data base, produce from the dictionary 
a string of content-word and funeion-word definitions that might be rep- 
resented typographically l i k e  this: 
( (SUB SURE-DISC) ) <OF> ( (U . S. LOC) ( (DIESEL TYPE) ) ( (LOC SUBS) 
(TYPE SUBS) 
As a xesult of processing, these will assemble into a tree structured (using 
the senseg of the words) l i k e  this: 
WHAT 
/ sUm-D=sP  
LOC AsuBs TYPE 
U , S .  DIESEL 
Even though this tree,  or  sentence graph, i s  created as a result o f  semantic 
relationships instead of Eonnal r u l e s  of grammar, it still. closely resembles 
the "parse t ree"  produced by m o ~ t  conventional syntactic language processors. 
With respect t o  the user's target data management system, t h e  sentence graph 
is preci~e and unambiguous and contains enough information for a 
straightforward translation into the formal query language of the EMS. In 
SDCrs DS/3 lanwage, f o r  example, the above question would be expressed as 
PRINT SURF-DISP WHERE TYPE EQ DIESEL AND lXXl EQ U.S. 
The response to the usex's question will thus be the response frclrn h i s  DMS 
t o  the formal query statement. 
The user's input in this hypothetical example i s  proper i n  fom and grammar. 
However ,  it need not have been. The request 
OBTAIN SURFACE DISP FOR US SUBS SUCH AS HAS TYPE EQ DIE=. 
would produce exactly the same sentence graph and thexefore, exactly t h e  
same f o m l  query statement with the same response f r o m  the DMS. 
It is not l ike ly  t ha t  a syntax-based parser would have anticipated the  odd 
laxxguage-use and grammar of this last request. Without a syntax rule t h a t  
would alluw for the phrase "such as has" such a parser would not look at the 
semantics involved and would be unable t o  interpret the request.  Our syntax 
algorithm gets the same results that would be expected f m m  the application 
of syntax rules without the need t o  anticipate each grammatical construct 
expected from the user. 
In overview, the  parsing algorithm makes a series of positive, negative, and 
peak connections based on the operational meanings of the function wards 
(including the "empty" aperator) and on the relations between meanings of the 
content wort%?. The algoridt-Xlm adheres to the following rules: 
e 1 Connections between content words are possible only if 
the result of the intez'sectfon t e s t  described & m e  is non-empty 
and i f  this result i s  not rejected by the operation of the function 
word p e r f o d n g  t h e  test. The function word d e f i n i t i o n  also deter- 
m i n e s  which w o r d  supplies its X ' s  and which its Y's for the t e s t ,  
It  thus controls which w o r d  has its sense d e t e d n e d  if t h e  t e s t  
ia successful. Most of ten (though there are exceptions) , posit ive 
operators use the X's f r o m  the  w o r d  to the r i g h t  and the  Y ' s  from 
the word to the left of . b e  operator. Positive operators, these- 
fore, determine the sense of the word t o  the  right. This is 
i l lustrated using, again, the secretaxy and her salary, Consider 
the defini t ion of "Suzie" and "salary" as shown on page 5 ,  The 
phrase "Suzie's salazy" has two content w o r d s ,  "Suzie" and 
"salary, " separated by the function word , " s , " This function 
word is  a positive operator and, hence, applies the  intersection 
t e s t  t o  the X i  from the definition of "salary" w i t h  the  Yi from 
the definition of " ~ u z i e . "  These values are, xespactively, 
'I (SECY CLK) " and " (km) . " The intersection yields " (SECY) , " 
which is acceptable to the " ' s "  operator, and the connection is 
made with "salary" as the dominant word. The sense of "salary" 
is the Y i  associated with "SECY" in t h e  def in i t ion  of "salary," 
hence, "SECSAL." T h i s  selection process is reversed f o r  negative 
aperators, while peak operators employ both kinds of t e s t s ,  one 
on each s i d e  of the peak. 
Rule 2: N o  node i n  a sentence graph may have m o r e  .than one dominating 
node. That is to say, a l l  connections m u s t  r e s u l t  i n  trees, This 
I s  a canmon asswnptLon consistent with conventional syntax-driven 
parsers. 
Rule 3: Given a subtree, a const i tuent  on its left has the poss ib i l i ty  
of conneation only to nodes of the subtree's positive adjacent 
slope, and a const i tuent  on the r i g h t  can connect onLy t o  the nodes 
i n  the adjacent negative slope. In tu i t ive ly ,  this means that if 
the nodes of a subtree are connected by "lines" that are "opaque 
b a r i e r s r n  then a constituent on either side of t h e  subtree  may 
connect to it only on those nodes that it can rlsee.r' I t  may not 
connect t o  nodes on the "inside" or the "fax s ide" of the subtree. 
This i s  a powerful h e u r i s t i c  rule that eliminates t h e  need t o  t ry  
connections to many syntactically impossible portions of the  sub- 
tree. In effect this one rule, together w i t h  the definitions of 
the function words, replaces all the syntax rules used by most 
conventional parsers. 
Rule  4: In  order t o  minimize disconnection of existing subtree 
structures (badcup) and s t i l l  consider a l l  possible connections, 
the system should, whenever possible, constrztct,subtrees s t a r t i n g  
from the top and make new connections from belaw. This rule leads 
to the following algorithm: Scan the consUtuents from left t o  
right making negative connections, then scan from right to left 
making positive connections. S c a n  thus back and forth unti l  no 
more connections can be made. Then make any poasible peak aonnec- 
t ions  and repeat the algorithm. Continue t h i s  process u n t i l  a l l  
const i tuents  have been connected i n t o  a single tree, 
We have observed t h a t  if ambiguities exist under these conditions, they w i l l  
be semantic and, in all probability. not resolvable by any further processing 
or analysis of the expression. Therefore. there is no need to carry along 
temporary multiple construction poss ibi l i t ies ,  The algorithm may eirher 
query the  user at this point for disambiguation or W d w t  the pxocesging and 
inf o m  reason, 
I. Chapanis, Alphonse. Interactive human cammunlcation, Scientific 
American, May, 1975. 
2. Woods, W. A, Trahsition network gr-ars for natural language analysis. 
Cozmnunications of the ACM, October 13, 1970, 
3. Kellogg, C. H,, et al,  The CONVEXGE natural language data management 
system: current status and plans. ACM Sym~osium on Information Storaqe 
and Ratrieval, University of Maryland, 1971. 
4, Thompson, F, B . ;  'Lockman, P. C.; Dostert, B.; Deverill, R, S. REL: 
a rapidly extensible language. Proceedings of 24th National Conference, 
ACM, New York, 1969, 399-417, 
-
Riesbeck, C, K. Computational understanding. Theoretical Issues i n  
Natural Langu~ge Processinq: Proceedinqs of an Interdisciplinary 
Workshop in Canputat icmal ~inguist&cs, Psychology, Linguistics and 
Artificial Intelligence. Cambridge, Massachuastts, June 10-13, l975. 
6, Waltz, D. L. On understanding poetry, Theoretical Issues i n  Natural 
Langtmgs Processing, Proceedings of an Interdisciplinary Workshop in 
Camputational Linguistics, Psychology, Limuistics and ~rtificial 
Intelligence. Cambridge, Massachuset-, June 10-13, 1975, 
7 .  Sdhank, Roger, and Tesler, L. G. A Conceptual Parser for N a t u r a l .  
Language. Stanford Artificial InteUigence Project. Memo No. AI-76, 
Januaq, 1969. 
American Journal of Computational Linguis ties Microfiche 32 : 7 2 
P. MEDEMA, W .  J. BRONNENBERG, H. C. BUNT. 5. P.  J.  LANDSBERGEN, 
R ,  J. H. SCHA, W .  J. SCHOENMAKERS, AND E .  P .  c. V A N  UTTEREN 
Philips Research  L a b o r a t o r i e s  
E indhoven ,  The Netherlands 
ABSTRACT 
This paper outlinee a recently implemented que~tion answering system , called 
PHLIQA 1 , which answers English questions about a data base . 
Unlike other existing aysteme , that directly tramlate a syntactic deep structure 
into a program to be executed, PHLIQA 1 leads a question through several 
intermediate etages of semantic analysis . In every stage the question is repre- 
sented a0 an expression of a formal language, The paper describes aome features 
of the Languages that are &uc~essivelg used during the analyeis process : the 
English-oriented Formal Language , the World Model Language and the Data Base 
Language . Next ,  we ahow the separate conversion steps that can be distinguished 
in the process. We indicate the problems that are handled by these conversions , 
and that are often neglected in other systems.  
1. Introduction 
PHLIQA 1 is an experimental ~ y e t e m  for answering isolated English questions 
about a data base . We have singled this out as the central problem of queation 
anawerlng , and therefore postponed the treatment of declaratives and imperrt 
tives , as well aa the analyak of discourse untll a later vereion of the system . 
The data baee is about computer installations in Europe and their users . At 
the moment, it is small and resides in core- but its structure and content 
are those of a realistic Codagyl format data base on disk ( CODASYL Data 
Base Task Group [ 1971 'J ) 
Only one module of the system , the wevaluation componenVT , would have to be 
chmqpd in order to handle a lha l t f  data base . 
2, PELIQA 1 ' e top level design 
Like other recent QA systems ( e,g, Petrick 1 1973 ] , Plath 1 1973 ] , 
Winograd 1 1972 ] , Woo& [ 1972 ] ) , the PHLIQA 1 system can , on the 
most global level , be divided into 3 parts ( aee fig. 1 ) : 
-- Underetandtng the question : Translating the question into a formal expree- 
sion which represents its meaning with respect to the world model of the 
- Computing the answer : Elaborating this expreseion , thereby finding the 
answer, it is repreeented in the system' s internal formalism. 
-- Formulating the answer : Translating this answer into a form that can be 
more readily under8 toad . 
questlon in English 
I 
formal expression , representing 
the meaning of the question 
I 
Answer 
Computation 
I 
answer In internal format 
Answer 
Formulation 
answer in external format 
Fig . 1. Global subdivision of PHLIQA 1, 
The interface between the Question understanding component and the Answer 
Computation component 1s a formal language , called the World Model Language 
( WML) . Expressions of this language represent the meaning of questions with 
respect to the world model of th@ system. Its conrrtants correspond to the concepts 
that canstitute the universe of discourse . The language is independent of the input 
language that ie udled ( in this case English) , and also independent of the storage 
structure of the data base. 
If we now look at a further subdivierion of the component& , the difference between 
PHLIQA 1 and other systems becornea apparent . Both above and below the World 
Model level, there is an intermediate stage of analysis , characterized by a 
formal language , resp r 
- The Engliaboriented Formal Language ( EFL) , which containa  constant^ that 
correspond to the terms of English, This language is wed to represent the 
semantic deep structure of the question , That divides the Question U n d e ~  
standing component into two succes~ive subcomponents I 
a. Constructing an EFL expression . using only linguistic knowledge . 
b, Translating the EFL expression into a WML expression, by taking 
knowledge about the structuf.e of the world into account. 
- The Data Base Language ( DBL ) , which contains conatants that correspond 
to data base primitives . ( The World Model constants do not correspond to 
daW base primitives , because we want to handle a realfs tic " data base : 
one that was designed to be stored efficiently , rather than to reflect neatly the 
structure of the world . ) 
This splits the Answer Computation component into two successive subcomp* 
nenta : 
a. Translating a WML expression into a DBL expression taking knowledge 
abut  the data base structure into account, 
b. Evaluating the DBL expre~sion . 
The aebup of the system that one arrives at in this way,  is shown in fig, 2. 
In section 3 , we gay eamething more about PHLIQAq s formal languagqs in 
general . How the three succeesive translation modules are further divided into 
smaller modules , c a U d  ftconvertorsw , is dfscu~sed fn the sections 4 , 5 and 6, 
Section 7 treats the evaluation component . The Answer Formulation component 
is very primitive , and will not be considered further . 
question in English 
I 
Question 
Under0 tanding 
Answer 
Computation 
expreabion of Englisboriented Formal Langua$te 
I ( Semantic Deep Structure ) 
EFL- WML - - -  - - owledge of 
tsanslation - - - - -  World Structure 
expre $ sion of World Model Language 
I 
- WML- DBL - - t - -  
translation f - - - 
[ expredsion of Data Base Language 1 
I 
answer in internal format 
Formulation 
anrswer in external format 
Fie 2, PHLIQA 1 main components . 
3. PHLIQA 1' B formal laxlguages 
3. 1, sylitax 
The three PHLIQA languages ( the English-oriented Formal Language , the 
World Model Language and the Data Base Language) have largely identfcal 
syntactic definitions . A s  pointed out already, their moat important difference 
is in the constants they contain . T h y  share most , but not all , syntactic 
COIlJ3 t~C!tf~Ils  , 
PHLIQA expresgions are rt trees TT that conaists of terminal nodes ( conetants 
and variables) and syntactic constructions . A syntact'ic construction is an 
unordered collection of labeled branches , departing from one node . 
The branches of a PHLIQA fl tree " can converge to a common subtree . 
Using a system of semantic types , the syntax of a PHLIQA language defines 
how expressions c m  be combined to form a larger expressfan. For every 
syntactic conetruetion, there ie a rule which specffies : 
- What the semantic types of it8 Immediate sub-expressions are allowed to be . 
( There is never a restriction on the syntactic form of the sub-expressions , ) 
- How the semantic type of the remitting expression is derived from the 
semantic types of the immediate sub-expressions . 
Given the types of the elementary expressions ( the constants and variables ) , 
this def'lnes the language, ( Sources of inspiration f o r  the syntax of our formal 
languages were the Vienna Definition Language- ( Wegner [ 1972 ] ) , and a 
formulation of Higher - Order Lo@c by J.A. Robinson [ 1969 ] 
. ) 
Some ~imple xamples of semantic types are the foXlowing : 
A comtant reprersenting a single object has a simple type . E.g, , 6 has 
the type " integer " , A c6nstant representing a collection of objedta of type oc 
has a type of the form <d> . E,g. , companies has the type "(company) 
" intagera has the type "(integer) . 
A constant representing a function that can have arguments of type and 
values of type ('3 has the type + . E.g. , the function 
Tt IL-cornpany-sites TI has the type ?? company* &il%y: the function &sum " 
has the type t v  (integer) integerw. 
The syntactic rule for the construction function - application t' could state 
that the emreasion 
is well -- formed if T is a well-formed expre~lsion of type and T i s  a 2 1 
well - formed expression of type 6 -+ /3 , where oC and may be 
any type ; the whole expression then has the type P 
The PHLIQA languages contaln a wide variety of syntactic constructions , e,g. 
constructions for different kinds of quantification , for selecting elements from 
a list, for reordering a list, etc , 
3. 2, Semantics 
The PaIQA language8 have a formal semantics which recursively defines the 
values of the expressions, This definition assumes as primitive nations the 
denotatian~ of the conetants of the language : function - constants denote 
procedures , and the other canstants denoh value - expressions , This means 
that if we know the denotations of the constants occurring in an expreesion , the 
value of the expression fs defined by the semantic rules of the language , For 
t b  Data Base Language , we indeed know the denotations of the constants ; what 
we call the data base is nothing but the implementation of the " primitive 
procedure8 ", t e. : the procedures corresponding to DBL functions , and 
the procedures for finding the value - expres~ions of the other DBL constants . 
Therefore , the DBL expressione are actually evaluable . 
For  the World Model Language and the English-orientad Formal Language , such 
a data base does not exiat , but one could be imagined . We express thls by saying 
t4&t the WML and EFL expressions are * evaluable with respect to a virtual data 
base 
4, Constraction of the semantic deep structure of a question. 
A s  we have seen, the EnglfsMriented Formal L m a g e  differ8 from the other 
tfttu, languagee in two respect8 : 
1, It has different constants , of'whieh the most important are t 
a names of sets corresponding to noune ( e.g. * computers ") , to verbs 
( " buy - sitrtatiane * ) and to ssme of the prepoeitions 
( in - place - situations ) . 
b. grammatical functions t subject, object, etc . 
2, It Borne different constructione . Here the most striking difference is that 
EFL conekuctinns contain eemantic and syntactic featurea . The semantic 
features influence the formal semagtfca of the constructlorn ( e,g, the definite- 
nees or indefiniteness of a noun phrase influences the choice of the kfnd of 
quantification for that noun phrase ) . The syntactic features only play a role 
during the tranaiormatian process from English to EFL . 
T t  should be noted that Ln general two eynonymoue eenteqes need not be represented 
by tho same semantic deep structure in EFL . For example , the synonymy of 
A buys B from C and C sells B to A is not accounted for at tbia level . 
Hwever ,at the level of the World Model Language synonymous sentences are 
mapped onto equivalent ( not necesaarilg identical ) WML emrerssr iom . 
The construction of the semantic deep structure in EFL consists of three main 
phanes r 
phase 1: a lexicon , providing for each word one o r  more interpretations , 
represented by pairs ( CATi, SEM \ , where CAT I s  a syntactic category i i 
and SEM an EFL expression . i 
phase 2: a set of rules that enables to combine the sequence of pairs ( CAT SEM1) , i t  
corresponding to the original sequence of words , into higher level categories and 
more complex structures , until we have ultimately the pair ( SENTENCE , SEM ) , 
S 
where SEM is the EFL expression for the bomplete sentence . 
S 
A rule of phase 2 is a combination of a context free rule and a set of rules on EFL 
expressions , that show when and how a sequence of pairs 
can be reduced fo a pair ( CAT , SEMR) . R 
The  general  format of theae rules i s  : 
- context free reduction rule : 
........ CATl +. + CATk -> CAT R 
- EFL rules : 
The C O N D ~ ' s  are conditions on the EFL expressions SEM . . , , , 1' SEMk . 
The ACTION ' s ahow how a new EFL expression SEM can be constructed with the i R 
helpofSEM ..... I' SEMk . The rule i s  applicable if at least one of the 
conditions COND is true . Then SEM ia constructed according to ACTION and I a i 
the aequence of pairs i s  reduced to ( CAT SEM ) . If more than one of the 
R' R 
COND is true , we have a local ambiguity. i 
phase 3: transformation rules that transform the semantic surface structure into 
an EFL expression that I s  called the semantic deep structure . ~ h e e e  t r & m f ~ r  
mation rules handle aspecte of meaning that could not be resolved locally , during 
phase 2. This applies for Instance to anaphoric references and elllptic clauses 
in comparative cons-ctlons . 
A ~impler example is the specification of the subject in a clauae like ' to uee a 
computer ', The eemantic surface structure of this clause means: there is a 
usesituation , with ~ a m e  computer as its object , and an unspecified subject . 
Phase 2 can be said to ' disambiguate ' thi@ expression in a context like 
' when did Shell start to q e  a computer 3 . 
A transformation specifies the subject of the use-situation as Shell '. This 
transformation would not apply if we had the verb propose instead of start ' . 
The condition8 of phase 2 and phase 3 contain a rkhortcuV' to the world model1 
the semantic types of the world model interpretations of the EFL congtants are 
inspected in order to avoid the construction of semantic deep e tructures that 
have no interpretation in the world model . This blocks many unfruitful parsing 
paths. 
5 . Translation from semantic deep structure to unambiguous World Model 
Language expression 
The translation from a semantic deep structure ( EFL expraseion ) into an un- 
arnbiguoua World Model Language expmsarion proceeds in 3 phases1 
phase 1s Translation from EFL expression Into ambiguous WML expression. 
b tbls phase , traneformations are applied which replace expressions containing 
EFL conetants by expreiseiolu containing WML canatants . Their most conspip 
uow effect is the elimination of "situations" and rTgrarnrnatical functionst1. It is 
important to note that the resulting expreseion often contains several "ambig- 
uous constantsW, These ariae from polyeemous brms in English r words that 
have a "range1? of posaible meanings . Such terms lead now to expressions with 
ambiguous constants8 constants that stand for a whole class of possible "insta* 
cesT' . An expression containing such constants , stands for the class of wellr 
formed expressions that can be generated by 'Ymtantlating" the ambiguous c o w  
stants . 
phase 2% Disambiguation of  quantification^ . 
Many sentences are ambiguous with respect to quantification , 
E .g . Were the largest 3 computers bought by 2 French companies ? can either 
ask whether there are 2 French companies such that they both bought each of 
these computers , o r ,  perhaps more plausibly , it can ask whether there are 2 
French companies such that together they bought these computers . 
Until thie stage in the process , the representation of such questions contains 
constructions which stand for both interpretatiow at once . But now that the 
system' 8 assumptions about the structure s f  the world are reflected In the ex- 
pression, some such interpretations may be ruled out as implausible , because 
they would lead to the same answer , independent of what the atate of affairs in 
the world is  . E ,g ., the first interpretation of the above example question 
has the value 'YalseW , independently of the values of the constants in the ex- 
preaeion . ( Because the assumption that a computer can only be bought by one 
company wapJ Introduced by a previous traneformatfon ) . Therefore , the second 
interpretation is chosen, 
phase 32 Di~arnbiguation of WML conestants . 
The ambiguous WML constants can be instantiated in a very efficient manner by 
using the semantic type system: The possible interpretations of an ambiguous 
comtant are severely restricted by the semantic types of the other constants 
that appear in it8 context, 
6. Tramlation from World Model L a n w g e  expression to Data Base 
Laqpage expression 
- 
In the World Model Language , constants correspond to the concepts of the universe 
of discourse, In the Data Base Language, conatants correspond to primitive 
logical and arithmetical procedures and to primitives of the data base . The choice 
of these primitives was governed by coneiderations of efficiency, rather than by 
the wish to represent neatly the structure of the univeree of discourse. Therefore , 
WML and DB conb fn different conatants . 
The translation from a WML expression to the DBL expression that will be evalu- 
ated, proceeb in three stages : 
1, Paraphrase of the WML expression, in order to eliminate * infinite notions ". 
WML contains conrrtanb representing infinite sets or infinite continua , like 
integer8 * , * moaey~amounts and ?' time ' l .  Such comtants can not be 
directly or hidirectly represented in the data base , and hence have no D B b  
tramlation. By paraphrasing the expression, the infinite notions can of*n 
be elirntnated . 
2, Translation of expressions conklning WML constants into expressions con- 
&ining DBL cow tanh , 
This tranalatlon is required by phenomena like the following : 
- it Ls poasible that a class of objects is not represented explicitly in the data 
baee , while propertlee of ib elementa are represented indirectly,  as 
properties of other , related objects , ( E.g. , cities do not occur in the 
PHLIC&Il data base , but their names are represented as the ciwnarnes 
of sites . ) 
A special case of this phenomenon ie the representation of a continuum by a 
class of diacrete objects ( E.g. , core ie represented by rr core 
memories ") t 
-- objects may be represented more than once in the data base. E.g. , in the 
PHLIQA 1 database, the flle of computer users and the file of manufacturers 
can contain records that represent one and the same f i rm.  
-- the data baee is more limited than the world model . Some questions that 
can be expreased in WML can be answered only partially or  not a t  all r 
the WML expresrition has no DBL translation. The present convertor detects 
such expressions and can generate a message which specifies what informa- 
tion ia lacking . 
Examples of this caae are r the se t  '' integers '* ( if the attempt of the previous 
convertor to eliminate it has been umuccesr~ful ) , and the date-ottaking- 
o u t - - o w e  ?* of a computer ( which happens to be not in the data base ) . 
3. Paraphrase of the DBL exprenr~ion , in order to improve the efficiency of its 
evaluation . 
The DBL expression produced by the previous convertor can already be evalu- 
ated, but i t  may be possible to paraphrase it in such a way, that the evaluaii~n 
of the paraphrase expression is more efficient, This conversion is worthwhile 
because , even with our small data base , the evaluation is often the most 
time-consuming part of the whole process ; compared to thie , the time that 
transformations take is negligible . 
7. The evaluation of a Data Base Language expression 
The value of a Data Base Language expression is completely defined by the sernaxl- 
tic rules of the Data Base Language ( see section 3 . 2 . ) , and one could cohceive 
of an algorithm that corresponds exactly to these rules . For reasons of efficiency, 
the actual algorithm differs from such an qlgorithm in some major respects r 
- in evaluating quantlficatiom over sets , it does not evaluate more element0 of 
the sat than ie necessary for determining the value of the quantification . 
- if ( e-g. during the evaluation of a quantification) , a variable assumes a new 
value , this doe8 not cause the, re-evaluation of any subexpressions that don* t 
contain this variable . 
Currently , evaluation occurs with respeet to a small data base in Core , To handle 
a real data base on dierk , only the evaluation of constantn would have to change . 
8, PELIQA I ' s Control Smckrrc3 
The sections 4 thmugh 7 sketched what the basic modulea of the system ( the 
convertors ") do . W e  shall now make some very general rernarh about the 
way they were implemented . These r e m a r k  apply to all convertors except the 
parser, whioh is described in some detail by Medema [ 1975 ] . 
The convertors can be viewed as functiong which map an input expression into a set 
of zero or more output expressions . Such a function fa defined by a collection, of 
transformations , acting on subexpresslons of the input expression . Each tr&aa- 
formation wnrrists of a condition and an action , The action ie applied to a sub- 
expression if the condition holde for it . The action can either be a procedure 
transformfngra subexpression to its * lower level equivalent '' or it can be the 
decbian this subexpressfon cannot be translated to the next lower level '' , 
"I1 convertore are implemented as procedures which operate on the tree that 
repregents the whole f~uestion . The procedures cooperate in a " deptb-first ?' 
m m r  : a conversion procedure finds suc~es s ive ly  all interpretations that the input 
expression haa on the next lower level . Far each of theae Interpretations , as soon 
as it is found, the next convertbr ie called. If no interpretation can be found, a 
message Bving the reason for this dead end is buffered , and control fe returned 
to the calling convertor , 
If the answer fs found, it is displayed. If requested, the ayatem can continue its 
search for more interpretatlorn . If the answer level is not reached , it displays 
the buffered message from the " lowest " convertor that was reached , 
Colophon 
The PHLIQA 1 program was written in SPL ( a PL/1 dialect) , and runs under the 
MDS time sharing system on the Philips Pl.400 computer of the Philips Research 
Laboratories a t  Eindhoven . 
The quantfflcatio~i~lambiguation ghaae of the EFG-WML translation, the effi- 
ciency-conVersion ( step 3 ) in the WML-DBL translation , as well a s  some parts 
of the grammar , are  not yet part  of the running system , though the convertors 
are complekly coded and the grammar is elaborately specified. 
During the design of PHLIQA 1 , the PHLIQA project was coordinated by Piet 
Medema . He and Eric van Utteren deaigned the algorithmic structure of the aye- 
tern and made decisions about many general aspectxi of implsrnentatlon . 
The formal languages and related transformation rules were designed by Harry 
Bunt . Jan Landabergen and Remko Scha . Wijnand Schoenmakera deaigned the evalu- 
ation component. Jan Landsbergen wrote a grammar for an extensive subset of English 
A l l  author6 were involved in the implementation of the system . 
During the design of PHLIQA 1 , exteneiva discussione with members of the SRI 
Speech Understanding team have helped us in making our ideasl more explicit, 
References 
CODASYL Data Base Task Group 
April 71 report. A C M ,  New York, 1971 . 
P. Medema A control structure for a question answering sys  tern . 
Proceedings of the 4th Inte~national Joint C~nferen~ce on
Artificial Intelligence . Tbilisi , USSR , 1975. Vol. 2 . 
S,RPetrick SemanticInterpretaticmintheREQUESTsystem. 
Proceedings of the International Conference on Computational 
Linguistice , VoL 1 , Pisa , 1973 . 
W, J. Plath Transformational Grammar and Transformational Pars fng in 
the REQUEST system, 
Proceedings of the International. Conference on Computational 
Linguistics , Vol. 2 , Pisa , 1973 . 
J. A. Robinson Mechanizing HighexLQrdelr Logic , 
In : B, Meltzer and D. Michie ( eds. ) , 
Machine Intelligence 4 , Edinburgh University Pres~l , 1969. 
P. Wegner The Vienna Definition Language . 
Computing Surveys , Vol, 4 , no. 1 , 1972 . 
T, Winograd Understanding Natural Language . 
Cognitive Psychology , VoL 3 , no. 1 , 1972 , 
W. A, Woode , R. M. Kaplan and B. Nash-Webber 
The Lunar Sciences Natural Language Information System : 
Final Report . BBN , Cambridge , Masa, 1972 . 

