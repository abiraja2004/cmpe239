INCORPORATING INHERITANCE AND FEATURE STRUCTURES 
INTO A LOGIC  GRAMMAR FORMALISM 
Harry H. Porter, III 
Oregon Graduate Center 
19600 N.W. Von Neumann Dr. 
Beaverton Oregon 97008-1999 
ABSTRACT 
Hassan Ait-Kaci introduced the #/-term, 
an informational structure resembling feature- 
based functional structures but which also 
includes taxonomic inheritance (Ait-Kaci, 1984). 
We describe e-terms and how they have been 
incorporated into the Logic Grammar formal- 
ism. The result, which we call Inheritance 
Grammar, is a proper superset of DCG and 
includes many features of PATR-II. Its taxo- 
nomic reasoning facilitates semantic type-class 
reasoning during grammatical analysis. 
INTRODUCTION 
The Inheritance Grammar (IG) formalism 
is an extension of Hassan Ait-Kaci's work on #/- 
terms (Ait-Kaci, 1984; Ait-Kaci and Nasr, 
1986). A e-term is an informational structure 
similar to both the feature structure of PATR-II 
(Shieber, 1985; Shieber, et al 1986) and the 
first-order term of logic, e-terms are ordered by 
subsumption and form a lattice in which 
unification of #/-terms amounts to greatest lower 
bounds (GLB, \[-'\]). In Inheritance Grammar, #/- 
terms are incorporated into a computational 
paradigm similar to the Definite Clause Gram- 
mar (DCG) formalism (Pereira and Warren, 
1980). Unlike feature structures and first-order 
terms, the atomic symbols of #/-terms are 
ordered in an IS-A taxonomy, a distinction that 
is useful in performing semantic type-class rea- 
soning during grammatical analysis. We begin 
by discussing this ordering. 
THE IS-A RELAT ION AMONG 
FEATURE VALUES 
Like other grammar formalisms using 
feature-based functional structures, we will 
assume a fixed set of symbol8 called the signa- 
ture. These symbols are atomic values used to 
represent lexical, syntactic and semantic 
categories and other feature values. In many 
formalisms (e.g. DCG and PATR-II), equality is 
the only operation for symbols; in IG symbols 
are related in an IS-A hierarchy. These rela- 
tionships are indicated in the grammar using 
statements such as1: 
boy < mascul ineObject .  
girl < feminineObject.  
man < mascul ineObject .  
woman < feminineObJect.  
{boy, girl} < child. 
{man, woman} < adult. 
{child, adult} < human. 
The symbol < can be read as "is a" and the 
notation {a , , . . .  ,an}<b is an abbreviation for 
al<b, ? ? ? ,an<b. The grammar writer need not 
distinguish between instances and classes, or 
between syntactic and semantic categories when 
the hierarchy is specified. Such distinctions are 
only determined by how the symbols are used in 
the grammar. Note that  this example ordering 
exhibits multiple inheritance: femin ineOb-  
jeers are  not  necessar i l y  humans and 
humans are not necessarily femin ine0b-  
J eers ,  yet a g i r l  is both a human and a 
feminineObj ect. 
Computation of LUB (t_ J) and GLB (\['7) 
in arbitrary partial orders is problematic. In 
IG, the grammar writer specifies an arbitrary 
ordering which the rule execution system 
automatically embeds in a lattice by the addi- 
tion of newly created symbols (Maier, 1980). 
Symbols may be thought of as standing 
for conceptual sets or semantic types and the 
IS-A relationship can be thought of as set 
I Symbols appearing in the grammar but not in the 
228 
inclusion. Finding the GLB-i .e.  unification of 
symbols-then amounts to set intersection. For 
the partial order specified above, two new sym- 
bols are automatically added, representing 
semantic categories implied by the IS-A state- 
ments, i.e. human females and human males. 
The first new category (human females) can be 
thought of as the intersection of human and 
femin lneObJect  or as the union of girl and 
woman 2, and similarly for human males. The 
signature resulting from the IS-A statements is 
shown in Figure 1. 
C-TERMS AS FEATURE STRUCTURES 
Much work in computational linguistics is 
focussed around the application of unification to 
an informational structure that maps attr ibute 
names (also called feature names, slot names, or 
labels) to values (Kay, 1984a; Kay, 1984b; 
Shieber, 1985; Shieber, et al 1986). A value is 
either atomic or (recursively) another such map- 
ping. These mappings are called by various 
names: feature structures, functional structures, 
f-structures, and feature matrices. The feature 
structures of PATR-II are most easily under- 
stood by viewing them as directed, acyclic 
graphs (DAGs) whose arcs are annotated with 
feature labels and whose leaves are annotated 
with atomic feature values (Shieber, 1985). 
IS-A s tatements  are taken to be unrelated. 
2 Or anything in between. One is the most liberal in- 
terpretation, the other the most conservative. The signs- 
ture could be extended by adding both classes, and any 
number in between. 
IGs use C-terms, an informational struc- 
ture that is best described as a rooted, possibly 
cyclic, directed graph. Each node (both leaf 
and interior) is annotated with a symbol from 
the signature. Each arc of the graph is labelled 
with a feature label (an attribute). The set of 
feature labels is unordered and is distinct from 
the signature. The formal definition of C-terms, 
given in set theoretic terms, is complicated in 
several ways beyond the scope of this 
presentation-see the definition of well-formed 
types in (Ait-Kaci, 1984). We give several 
examples to give the flavor of C-terms. 
Feature structures are often represented 
using a bracketed matrix notation, in addition 
to the DAG notation. C-terms, on the other 
hand, are represented using a textual notation 
similar to that of first-order terms. The syntax 
of the textual representation is given by the fol- 
lowing extended BNF grammar 3.
term ::= 
featureList ::= 
feature ::= 
symbol \[ featureList \] 
\[ featureList 
( feature , feature ,
... , feature )
label => term 
\[ label ~ variable \[ : term \] 
Our first example contains the symbols 
np, s ingu lar ,  and th i rd .  The label of 
3 The vertical bar separates alternate constituents, 
brackets enclose optional constituents,  and ellipses are used 
(loosely) to indicate repetition. The characters ( ) ->  , and 
z are terminals. 
femin ineObject  human mascu l ineOb ject  
adu  i t humanF ema i e humanMa i e ch i  i d 
woman man g i r  I boy  
Figure 1. A signature. 
229 
the root node, np, is called the head symbol. 
This C-term contains two features, labelled by 
number and person. 
np ( number ~ singular, 
person ~ th i rd )  
The next example includes a subterm at 
agreement:=>: 
(cat ~ np, 
agreement ~ (number ~ singular, 
person ~ third)) 
In this C-term the head symbol is missing, as is 
the head symbol of the subterm. When a sym- 
bol is missing, the most general symbol of the 
signature (T )  is implied. 
In traditional first-order terms, a variable 
serves two purposes. First, as a wild card, it 
serves as a place holder which will match any 
term. Second, as a tag, one variable can con- 
strain several positions in the term to be filled 
by the same structure. In C-terms, the wild 
card function is filled by the maximal symbol of 
the signature (T )  which will match any C-term 
during unification. Variables are used 
exclusively for the tagging function to  indicate 
C-term eore/erence. By convention, variables 
always begin with an uppercase letter while 
symbols and labels begin with lowercase letters 
and digits. 
In the following ~b-term, representing The 
man want8 to dance with Mary, X is a variable 
used to identify the subject of wants with the 
subject of dance. 
sentence ( 
subject ~ X: man, 
predicate ~ wants, 
verbComp ~ clause ( 
subject ~ X, 
predicate ~ dance, 
object ~ mary )) 
If a variable X appears in a term tagging 
a subterm t, then all subterms tagged by other 
occurrences of X must be consistent with (i.e. 
unify with) t 4. If a variable appears without a 
subterm following it, the term consisting of sim- 
ply the top symbol (T )  is assumed. The con- 
straint implied by variable coreference is not 
just equality of structure but equality of refer- 
ence. Further unifications that  add information 
to one sub-structure will necessarily add it to 
the other. Thus, in this example, X constrains 
the terms appearing at the paths subject=> 
and verbComp~sub ject~ to be the same 
term. 
In the ~b-term representation of the sen- 
tence The man with the toupee sneezed, shown 
below, the np filling the sub jec t  role, X, has 
two attributes. One is a qua l i f ie r  filled by 
a relativeClause whose subject is X 
itself. 
sentence ( 
subject ~ X: np ( 
head ~ man, 
qualifier ~ relativeClause 
subject ~ X, 
predicate ~ wear, 
object ~ toupee)), 
predicate ~ sneezed) 
As the graphical representation (in Figure 2) of 
this term clearly shows, this C-term is cyclic. 
UNIF ICAT ION OF ~b-TERMS 
The unification of two ~b-terms is similar 
to the unification of two feature structures in 
PATR-II or two first-order terms in logic. 
Unification of two terms t I and t 2 proceeds as 
follows. First, the head symbols of tl and t2"are 
unified. That  is, the GLB of the two symbols in 
the signature lattice becomes the head symbol 
of the result. Second, the subterms of t I and t, 
are unified. When t I and t 2 both contain the 
feature f, the corresponding subterms are unified 
and added as feature f of the result. If one 
term, say h, contains feature f and the other 
term does not, then the result will contain 
feature f with the value from h. This is the 
same result that  would obtain if t2 contained 
feature f with value T .  Finally, the subterm 
4 Normally, the subterm at X will be written follow- 
ing the first occurrence of X and all other occurrences of X 
will not include subterms. 
230 
coreference constraints implied by the variables 
in t 1 and t 2 are respected. That  is, the result is 
the least constrained ~b-term such that if two 
paths (addresses) in t 1 (or t2) are tagged by the 
same variable (i.e. they core/%r) then they will 
corefer in the result. 
For example, when the C-term 
(agreement @ X: (number@singular), 
subject => (agreement@X)) 
is unified with 
( sub jec t@ 
(agreement@ 
(person@third))) 
the result is 
(agreement @ X: (number@singular, 
person@third) , 
subject @ (agreement@X)) 
INHERITANCE GRAMMARS 
An IG consists of several IS-A statements 
and several grammar rul?~. A grammar rule is 
a definite clause which uses C-terms in place of 
the first-order literals used in first-order logic 
programming s. Much of the notation of Pro\]og 
and DCGs is used. In particular, the : -  sym- 
bol separates a rule head from the C-terms 
comprising the rule body. Analogously to Pro- 
log, l ist-notation (using \[, I, and \])  can be 
used as a shorthand for C-terms representing 
lists and containing head and ta i l  features. 
When the - ->  symbol is used instead of "-,  
the rule is treated as a context-free grammar 
rule and the interpreter automatically appends 
two additional arguments (start and end) to 
facilitate parsing. The final syntactic sugar 
allows feature labels to be elided; sequentially 
numbered numeric labels are automatically sup- 
plied. 
Our first simple Inheritance Grammar 
consists of the rules: 
sent  - ->  noun (Num) ,verb  (Num) . 
noun  (p lu ra l )  - ->  \ [cats \ ]  . 
verb  (p lu ra l )  - -> \ [meow\]  . 
The sentence to be parsed is supplied as a goal 
6 This is to be contrasted with LOGIN, in which ?- 
Figure 2. Graphical representation f a C-term. 
231 
clause, as in: 
: -  sent  ( \ [ ca ts ,meow\ ]  , \[\]) . 
The interpreter first translates these clauses 
into the following equivalent IG clauses, 
expanding away the notational sugar, before 
execution begins. 
sent  ( s ta r t~P l ,end~P3)  : - 
noun  ( l~Num,  s tar t~P l ,  end~P2)  , 
verb  ( l~Num,  s tar t~P2,  end~P3)  . 
noun  ( l~p lura l ,  
s ta r t~ l i s t  (head ,  cats,  ta i l~L)  , 
end~L)  . 
verb  ( l~p lura l ,  
s ta r t~ l i s t  (head ,meow,  ta i l~L)  , 
end~L)  . 
: -  sent  ( s ta r t~ l i s t  ( 
head ,cats ,  
ta i l~ l i s t  ( 
head ,meow,  
ta i l~n i l ) )  , 
end~ni l  ) . 
As this example indicates, every DCG is an 
Inheritance Grammar. However, since the argu- 
ments may be arbitrary C-terms, IG can also 
accomodate f ature structure manipulation. 
TYPE-CLASS REASONING IN PARSING 
Several logic-based grammars have used 
semantic categorization of verb arguments to 
disambiguate word senses and fill case slots (e.g. 
Dahl, 1979; Dahl, 1981; McCord, 1980). The 
primary motivation for using !b-terms for gram- 
matical analysis is to facilitate such semantic 
type-class reasoning during the parsing stage. 
As an example, the DCG presented in 
(McCord, 1980) uses unification to do taxonomic 
reasoning. Two types unify iff one is a subtype 
of the other; the result is the most specific type. 
For example, if the first-order term smi th :_  
representing an untyped individual 6, is unified 
with the type expression X :person:  student ,  
representing the student subtype of person, the 
result is smi th  :person  : s tudent .  
terms replace first-order terms rather than predications. 
e Here the colon is used as a right-associative infix 
operator meaning subtype. 
While .this grammar achieves extensive 
coverage, we perceive two shortcomings to the 
approach. (1) The semantic hierarchy is some- 
what inflexible because it is distributed 
throughout the lexicon, rather than being main- 
tained separately. (2) Multiple Inheritance is 
not accommodated (although see McCord, 
1985). In IG, the ?-term s tudent  can act as a 
typed variable and unifies with the C-term 
smi th  (yielding smith)  assuming the presence 
of IS-A statements such as: 
s tudent  < person .  
{smith ,  Jones,  b rown} < s tudent .  
The taxonomy is specified separately-even with 
the potential of dynamic modification-and mul- 
tiple inheritance is accommodated naturally. 
OTHER GRAMMATICAL APPLICATIONS 
OF TAXONOMIC REASONING 
The taxonomic reasoning mechanism of IG 
has applications in lexical and syntactic 
categorization as well as in semantic type-class 
reasoning. As an illustration which uses C-term 
predications, consider the problem of writing a 
grammar that accepts a prepositional phrase or 
a relative clause after a noun phrase but only 
accepts a prepositional phrase after the verb 
phrase. So The flower under the tree wilted, The 
flower that was under the tree wilted, and John 
ate under the tree should be accepted but not 
*John ate that was under the tree. The taxon- 
omy 8peeifie~ that prepos i t iona lPhrase  
and re la t iveC lause  are npMod i f ie rs  but 
only a prepos i t iona lPhrase  is a vpMo- 
d i f ie r  The following highly abbreviated IG 
shows one simple solution: 
{prepos i t iona lPhrase ,  
re la t iveC lause}  < npMod i f ie r .  
p repos i t iona lPhrase  < vpMod i f ie r .  
sent ( . . . )  - ->  r ip ( . . . ) ,  
vp ( . . . ) ,  
vpMod i f ie r  (...) . 
np(. . . )  --> np( . . . ) ,  
npModi f ie r  (...) . 
np( . . . )  --> . . . 
vp(. . . )  --> . . .  
prepos i t iona lPhrase( . . . )  --> . . ? 
232 
re la t iveC lause( . . . )  - ->  ... 
IMPLEMENTATION 
We have implemented an IG development 
environment in Smalltalk on the Tektronix 
4406. The IS-A statements are handled by an 
ordering package which dynamically performs 
the lattice extension and which allows interac- 
tive display of the ordering. Many of the tech- 
niques used in standard depth-first Prolog exe- 
cution have been carried over to IG execution. 
To speed grammar execution, our system 
precompiles the grammar ules. To speed gram- 
mar development, incremental compilation 
allows individual rules to be compiled when 
modified. We are currently developing a large 
grammar using this environment. 
As in Prolog, top-down evaluation is not 
complete. Earley Deduction (Pereira and War- 
ren, 1980; Porter, 1986), a sound and complete 
evaluation strategy for Logic programs, frees 
the writer of DCGs from the worry of infinite 
left-recursion. Earley Deduction is essentially a
generalized form of chart parsing (Kaplan, 1973; 
Winograd, 1983), applicable to DCGs. We are 
investigating the application of alternative xe- 
cution strategies, uch as Earley Deduction and 
Extension Tables (Dietrich and Warren, 1986) 
to the execution of IGs. 
ACKNOWLEDGEMENTS 
Valuable interactions with the following people 
are gratefully acknowledged: Hassan A.it-Kaci, 
David Maier, David S. Warren, Fernando 
Pereira, and Lauri Karttunen. 
REFERENCES 
AJt-Kaci, Hassan. 1984. A Lattice 
Theoretic Approach to Computation Based on a 
Calculus of Partially Ordered Type Structures, 
Ph.D. Dissertation, University of Pennsylvannia, 
Philadelphia, PA. 
A.it~-Kaci, Hassan and Nasr, Roger. 1986. 
LOGIN: A Logic Programming Language with 
Built-in Inheritance, Journal of Logic Program, 
ruing, 3(3):185-216. 
Dahl, Veronica. 1979. Logical Design of 
Deductive NL Consultable Data Bases, Proc. 
5th Intl. Conf. on Very Large Data Bascn, Rio de 
Janeiro. 
Dahl, Veronica. 1981. Translating Span- 
ish into Logic through Logic, Am. Journal of 
Comp. Linguistics, 7(3):149-164. 
Dietrich, Susan Wagner and Warren, 
David S. 1986. Extension Tables: Memo Rela- 
tions in Logic Programming, Technical Report 
86/18, C.S. Dept., SUNY, Stony Brook, New 
York. 
Kaplan, Ronald. 1973. A General Syn- 
tactic Processor, in: Randall Rustin, Ed., 
Natural Language ProcesMng, A_lgorithmics 
Press, New York, NY. 
Kay, Martin. 1984a. Functional 
Unification Grammar: A "Formalism for Machine 
Translation, Proc. 2Znd Ann. Meeting of the 
Assoc. for Computational Linguistics (COLING), 
Stanford University, Palo Alto, CA. 
Kay, Martin. 1984b. Unification in 
Grammar, Natural Lang. Understanding and 
Logic Programming Conf. Proceedings, IRISA- 
INRIA, Rennes, France. 
Maier, David. 1980. DAGs as Lattices: 
Extended Abstract, Unpublished manuscript. 
MeCord, Michael C. 1980. Using Slots 
and Modifiers in Logic Grammars for Natural 
Language, Artificial Intelligence, 18(3):327-368. 
McCord, Michael C. 1985. Modular Logic 
Grammars, Proc. of the eSrd ACL Conference, 
Chicago, IL. 
Pereira, F.C.N. and Warren, D.H.D. 1980. 
Definite Clause Grammars for Language 
Analysis - A Survey of the Formalism and a 
Comparison with Augmented Transition Net- 
works, Artificial Intelligence, 13:231-278. 
Pereira, F.C.N. and Warren, D.H.D. 1983. 
Parsing as Deduction, elst Annual Meeting of 
the Assoc. for Computational Linguistics, Bos- 
ton, MA. 
Porter, Harry H. 1986. Earley Deduction, 
Technical Report CS/E-86-002, Oregon Gradu- 
ate Center, Beaverton, OR. 
Shieber, Stuart M. 1985. An Introduction 
to Unification-Based Approaches to Grammar, 
Tutorial Session Notes, ?3rd Annual Meeting of 
the A~oc. for Computational Linguistics, Chi- 
cago, IL. 
233 
Shieber, S.M., Pereira, F.C.N., Karttunen, 
L. and Kay, M. 1986. A Compilation of Papers 
on Unification-Based Grammar Formalisms, 
Parts I and II, Center for the Study of Language 
and Information, Stanford. 
Winograd, Terry. 1983. Language aa a 
Cognitive Process, Vol. Z: Syntax, Addison- 
Wesley, Reading, MA. 
234 
