P A N E L 
P~Lra l le l  P~ocess ing  in  Computat iona l  L ingu is  t i cs  
Helmut Schnelle 
Ruhr-Univers i t~t  Bochum 
Sprachwissenschaft l iches Inst itut 
Postfach 102148, D-4630 Bochum 1 
Pane l i s ts :  
Garry COTTRELL 
Univers i ty  of California, Dept. of 
Computer Science, San Diego, 
Mail  Code C-O14, La Jolla, CA 92093 
U.S.A. 
Paradip DEY 
The Univers i ty  of Alabama at Birmingham 
Dept. of Computer & Information Science 
Birmingham, AL 35294 
U.S.A.  
Peter A. REICH 
Dept. of Linguistics, Univers i ty of 
Toronto, Toronto, Ontario MBS IAI 
CANADA 
Lokendra SHASTRI 
Univers i ty  of Pennsylvania 
School of Engineer ing and Appl ied 
Science, 200 South 33rd Street 
Phi ladelphia, PA 19104-6389 
U.S.A. 
Joachim DIEDERICH 
Internat ional  Computer Science Inst i tute 
1947 Center Street, Berkeley, CA 94704 
U.S.A. 
Akinori  YONEZAWA 
Tokyo Inst itute of Technology 
Dept. of Information Science 
Ookayama, Meguru-ku, Tokyo 152 
JAPAN 
Introduct ion 
The topic to be discussed by the panel 
is new and at present very much under debate. 
Paralleli~im is developed in a large var iety 
of approaches. The panel wil l  make an attempt 
to c lar i fy the under ly ing concepts, the dif-  
ferences <~f approach, the perspect ives and 
general tt!ndencies, and the di f f icul t ies to 
be expected. Some di f ferences of approach 
wil l  be iAlustrated with examples from the 
work of the panelists. 
The ~ommon context of our approaches is 
the fo l lowing:Standard computat ional  
l inguist ics tries to solve its problems by 
programmiltg a yon Neumann computer. The 
execut ion of the programs is inherent ly 
sequenti~l. This is impl ied by the fact that 
there is only one central processing unit  
(CPU) executing the program. In contrast to 
this, pal~allel process ing def ines the solu- 
t ion of p~oblems in terms of sets of computa- 
t ional units which operate concurrent ly  and 
interactively, unless sequent ia l ized for si- 
mulat ion ~urposes. 
Various approaches to paral le l ism dif fer  
in the computat ional  power they assume for 
the concurrent ly  active units. The di f feren-  
ces may be out l ined as follows: 
Massively paral le l  systems are usual ly 
systems whose units are, intuit ively 
speaking, purely reactive units, i.e. mathe- 
mat ical ly  def ined by a specif ic function re- 
lat ing the state and output of a unit  to its 
inputs. They could also be cal led connect io-  
nist systems in the wide sense; connect ionist  
systems in the narrow sense are those whose 
function~ are based on weighted sums of input 
activit ies. 
In contrast to these systems, the units may 
be themselves compl icated systems which com- 
pute their states and outputs depending on 
the messages and control s ignals which they 
receive. The units cooperate in solving the 
problem. In typical cases, each unit may be a 
central processor unit  or even a complete 
computer. Systems with cooperative processors 
(computing "agents") are usual ly considered 
to be non-massively  parallel. 
These dist inct ions suggest di f ferent meta- 
phors used in informal talk about the sy- 
stems: the neural  net metaphor on the one 
hand and the society of minds (demons) meta~ 
phor on the other. 
Given this context the panel ists have 
answered the fol lowing questions: 
I. How is the dynamics of your system 
def ined? 
- I.(A) I. What is the computat ional  power 
of a single unit in your approach 
- I.(A) 2. How is the interact ion or the 
interdependency between concurrent 
units def ined? 
- I.(B} How do you implement your system? 
- I (C) Which methods are used for ~o-  
uramminu? 
II. What is the representat ional  status of 
your system? 
- II.(A) Which parts of grammar or dict ionary 
do you model with your system? 
- II.(B) Which parts of grammar or dict ionary 
do you model by a concurrent unit of 
your system? 
- II.(C} Is there a general  method such that 
a grammar determines uniquely a 
paral le l  implementat ion or is this 
imp3ementat ion an art? 
The answers given seem to be part icu lar ly  
appropriate as an introduct ion to the topic 
and wil l  thus be presented in the subsequent 
passages.{The answers of the di f ferent 
panel ists and the organizer are pref ixed by 
their initials) 
595 
I. How is the dynamics of your system 
defined? 
I.{A) i. What is the computat ional  power 
of a single unit in your approach (a Boolean 
function, a specif ic  numerical  function, a 
mapping of vectors, a mapping of strings or 
files, a mapping of trees or conf igurat ions 
of other types, or the power of a CPU or a 
complete computer)? 
G.C.:There are no formal l imitat ions on the 
power of a unit  in my system; the power is a 
matter of taste, and is expected to be re- 
str icted to simple functions. For example a 
numerical  approximat ion to Boolean functions 
of the inputs, where the inputs are further 
broken down into functions of input sites. My 
implemented system has several hundred units. 
P.D.:Each unit  has the power of a VAX- 
11/750.The units share their memories. I 'm 
thus current ly working in a shared memory 
mult iprocess ing environment. Specif ical ly, my 
algorithms run on a 30 processor {=unit} Se- 
quent Balance 21000 machine. This is large 
grain paral lel ism. I prefer the environment 
of large grained shared memory mult iproces-  
sots, because they are the most popular gene- 
ral purpose paral lel  computers avai lable 
today. Earlier, I developed some algorithms 
for a medium grained tree machine, namely the 
DADO paral lel  machine. 
J.D.: Each unit implements a simple numerical  
function, sometimes a simple combinat ion of 
several funct ions computing input from seve- 
ral sites of incoming activation. 
P.A.R.: Each unit  has the power of a f inite 
state device {under 32 di f ferent sta- 
tes).There are 16 di f ferent types of units 
which di f fer  in their f inite state def ini -  
tion. They implement (sometimes only 
slightly} di f ferent logical functions over 
their input activations. The more impor tant  
ones are: concatenat ion (logical fol lowed 
by), conjunct ion (logical and), d is junct ion 
(exclusive or}, precedence dis junct ion {if 
both poss ib i l i t ies  are realizable, one takes 
precedence over the other), random dis junc-  
tion (pick a choice at random}, inter junct ion 
{inclusive or}, intercatenat ion {inclusive 
or; if both: concatenation),  zero (network 
dead ends producing nothing), bottom edge 
(network outputs something), top edge, feed- 
back barrier. Units operate independent ly  of 
one another and asynchronously.  
H.S.: There are two descr ipt ive levels: large 
gra ined and small grained. On the former each 
unit is a {special purpose) Tur ing machine 
(not a universal  one}. On the small grained 
level, each unit implements either a s imple 
Boolean funct ion or a simple numerical  {addi- 
tive, f ixed length} function. The large grai-  
ned net is a part i t ion ing of the small grai-  
ned net; its Tur ing machines are similar to 
von Neumann's growing cel lular automata. 
L.S.: Each unit  implements a numerical  func- 
t ion  - the  most compl icated ones have the 
form: If input aa > 0, then take the product 
of inputs bt,bs .... b~, else take the product 
of inputs cl ;cz, . . .cm. 
A.Y.: Each unit  is a single CPU with memory. 
My approach involves thousands of units. 
I.(A} 2. How is the interact ion or the 
interdependency between concurrent units de- 
f ined? Is it str ict ly  connect ionist  and thus 
also def ined by a function? Or is it coopera- 
tive and thus def ined by the messages sent, 
encoded and decoded by the units? Is there a 
d ist inct ion between data messages and con- 
trol-s ignal  messages or is it a data-f iow sy- 
stem? 
G.C.: Units pass values in a str ict ly  connec- 
t ionist way. 
P.D.:The system is a shared memory system. 
All units have in pr inciple access to the 
same information. Actual interact ion is def i -  
ned by shared variables. That is, processes 
communicate with each other through shared 
variables. 
J.D.: The system is str ict ly  connectionist,  
i.e. there are no symbol ic messages. Each 
unit  computes the weighted sum of inputs. 
P.A.R. :Each unit  is connected to at most 
three other units in the network. The connec- 
tions are active or not. According to their 
function, three di f ferent signals may be di- 
st inguished: product ion signal and posit ive 
feedback, negative feedback, and antic ipa- 
tory. 
H.S.: On the small grained level the system 
is connectionlst,  but not strictly, since not 
only weighted sums of inputs are al lowed but 
also other simple functions. 
L.S.: The system is str ict ly  connectionist.  
A.Y.: The interact ion between units involves 
message passing. Messages carry either con- 
trol information or data or both. 
I.{B} How do you implement your system? 
By s imulat ion on a yon Neumann computer or by 
programming on a universal  paral le l  machine 
(like the connect ion machine} or by designing 
hardware (e.g. a specia l -purpose information 
process ing network}? If the first, do you 
plan to implement it eventual ly  by a paral le l  
system? 
G.C.: The system is s imulated on a VAX. 
P.D.:The system is being implemented on a 30- 
processor Sequent Balance 21000 machine. It 
is current ly being implemented in paral le l -C 
running under Unix. When a paral le l  LISP be- 
comes available, it wil l  be implemented in 
paral le l  LISP. 
J.D.: We use the Rochester  Connsct ionist  Si- 
mulator  on a SUN-3 with Graphics Interface. 
Implementat ions on a Sequent (Parallel Unix 
Machine} are planned. 
P .A,R. :S imulat ion on a personal  computer 
using standard programming language. 
H.S.: The connect ionist  net is def ined on a 
spread-sheet such as LOTUS 1-2-3. Some cells 
of the spread-sheet are ident i f ied with the 
units of the net to be programmed. In each of 
these cells a formula for a funct ion is ente- 
red; it determines the react iv i ty of this 
cell to the states of those neighbour ing 
cells whose addresses are arguments of the 
function. Thus, the addresses of the formulas 
on the spread-sheet implement the connect iv i -  
ties between the formulas. We run the 
spreadsheet in the computat ion-mode: itera- 
t ive,columnwise, which def ines the sequential  
simulation. By def in i t ion the di f ferent cel ls 
of the spread-sheet could operate concur- 
rent ly in each i terat ive step; their opera- 
t ion is sequent ia l ized (and thus adapted to 
the s imulat ion on PC} only through columnwise 
computation. 
L .S. :By s imulat ion on a yon Neumann computer. 
A.Y. :By s imulat ion of a yon Neumann computer, 
and also paral le l  computers 
596 
I (C) Which methods are used for pro- 
~ ?  Paral le l iz ing of exist ing non-par-  
allel programs or independent programming? 
Methods of hardware design? 
GoC.: A network is constructed from a high- 
level speci f icat ion such as a grammar. This 
is g iven to a network construct ion routine 
that specif ies the model based on the gram- 
mar. 
P.D.:The computat ional  model is MIMD (multi- 
ple inst,'uction mult ip le data stream). Paral-  
lel programs are developed pr imari ly  by data 
partitio,~ing, although function part i t ioning 
is also itsed. 
J.D.: Independent programu~ing. Networks are 
constructed by writ ing a C program and use of 
l ibrary funct ion of the simulator. 
P.A.R.: The system is programmed by construc- 
ting the gra~maar in network form. There is an 
algorithl4 for represent ing the network in 
terms of algebraic formulas. Nodes are defi-  
ned by a series of state transit ion rules. 
The gran~aar is tested by insert ing init ial 
input sionals and running the simulation. 
H.So: There is a compiler which produces au- 
tomatical ly for any given CF-grammar a corre- 
sponding network. The processes on the net- 
work cor~:espond to the processes def ined by 
an Earley chart parser but, in contrast to 
the latter, all processes are executed con- 
current ly whenever this is possible. In par- 
ticular, all pars ing paths are fol lowed up in 
parallel.  Hardware design of networks is 
planned~ 
L.S.: A "compiler" is provided that transla- 
tes a high level speci f icat ion of a concep- 
tual structure (semantic network} into a 
connect ionist  network. It is proved, that the 
network ~enerated by the compiler solves an 
interset ing lass of inheritance and reco ngn!~ 
tiol, problems extremely fast - in time pro- 
port ional  to the depth of the conceptual 
hierarchy. 
A.Y. :We designed an object -or iented concur- 
rent language cal led ABCL/I  and program par- 
sers in this language. 
I.(D} Is your system fixed or does it 
learn ? If the latter, which learning functi-  
ons or learning algorithms are used? 
J.D.:Lea:cning is the most important topic. 
Natural  language descr ipt ions of structured 
objects are learned. These objects are also 
present in a restr icted visual environment. 
The interact ion between language and vision 
in learning is investigated. Various forms of 
weight changes are used: Hebbian learning 
with slow weight change, fast weight change 
for temporary binding, modi f ied Hebbian lear- 
ning with restr ict ion on the increase of 
weights. 
P.A.E.: A substantial  number of learning ru- 
les have been developed but not yet implemen- 
ted on computer. Learning involves "inge- 
stion" and "digestion". Ingest ion consists of 
co-occurrence rules. If two signals pre- 
v iously unconnected co-occur, they are 
connected together. Digest ion makes use of 
equivalence relat ionships to s impl i fy the 
network. Equivalence re lat ionships include: 
associat ivity,  commutativity,  distr ibutivity,  
and a number of other re lat ionships which 
have no name in standard algebra. Ingest ion 
and digest ion operate more or less alterna- 
rely. First a piece of new information is 
connected to the network, then equivalence 
relat ions are tried in a search for s impli f i -  
cation. 
L.S.: Structure is f ixed but weights on l inks 
can be learned using a Hebbian weight change 
rule. 
G.C. ,P.D. ,H.S. ,A.Y. :  Our systems do not le- 
arn. 
If. What is the representat ional  status of 
your system? 
II. (A) Which parts of grammar or dic- 
t ionary do you model with your system? 
G.C.: I  have separate systems designed to work 
together to handle lexical access, case-gram- 
mar semantics, and f ixed- length context free 
grammar .  
P .D . :Lex icon ,  g rammar  and  semant ics .  The  le -  
x icon  has words with their categories, subca- 
tegories, and lexical meaning. 
J .D. :F ixed- length context- free grammar. 
P.A.R.: IR theory the entire system from a re-- 
presentat ion of general cognit ive information 
through language specif ic "deep" or "functio- 
nal" structure, through a syntax-morphology 
structure, and then through a phonological  
structure. In actuality, the syntax-morpho- 
logy and phonology sections have been worked 
out in greatest detail, and the functional 
structure in bits and pieces. 
H.S. :Syntax and phonology as a part of a le- 
xical  access system. 
L.S.: Domain knowledge in terms of a hierar- 
chy of concepts/ frames - where each concept 
is a col lect ion of attr ibute-value (or 
slot/f i l ler) pairs. Such information structu- 
res are var iably referred to as frame-based 
languages, semantic networks, inheritance 
hierarchies, etc. 
A.Y. :Syntax and some semantics. 
II.(B) Which parts of grammar or dic- 
t ionary do you model by a concurrent unit of 
your system? 
G.C.: I use a local ist approach: One unit 
stands for a word, a meaning, a syntactic 
class, and a binding between meanings and ro- 
les, syntact ic and semantic. 
P.D.: Parts of syntax; lexical search is also 
paral lel  
J.D.: Local ist  representation, i.e. one syn- 
tactic category - one unit 
P.A.R. :Each category (such as noun phrase) is 
d istr ibut ive ly  represented by many units. 
H.S.:(Local ist ;  on small grained level:) Each 
occurrence of a category- in-ru le-context  (a 
dotted rule in Earley's parser definition) is 
represented by a unit. (On the large grain le- 
vel:) The set of possible small grain units 
of each category corresponds to a Turing ma- 
chine, such that one of its units represents 
the current state of the "head" of the TM and 
the others its "tape". 
L.S.:(Local ist:)  A unit may "represent" a 
concept, an attribute, a value, a binder bet- 
ween (concept,attr ibute,value) triples, or 
control  nodes that mediate and control the 
spreading of act ivat ion among these units. 
A.Y.:(Local ist:} Each grammatical  category is 
represented as a unit, actual ly each occur- 
fence of each category in a grammar descr ip-  
tion is a unit. 
597 
'%i:.(C) Is there a genera l  method such 
that a ~ra~,~ar determines  un ique ly  a para l le l  
imp lementat ion  or is this imp lementat ion  an 
art? 
G~.Co~Given a ~rammar,  X have an a lgor t ihm to 
generate  the network  for that grammar.  
P,,D.:Parsing a lgor i thms are deve loped for 
Tree Ad jo in ino  Grammars?  
J oDo:  Imp lementat ion  is st i l l  an art. 
PoA,~Ro~ N?o a cer ta in  extent  it is an art, at 
this point,  but  the comprehens ion-acqu is i t ion  
r~les~ if ~ccess fu l ly  implemented,  shou ld  
p~ov ide  the ~enera l  method~ 
H~So~ ~r i t ing  grammars  as h igh- leve l  spec i f i  --~ 
cat io~s is au art. F rom there on there is a 
genera l  method (same answer  as L.S.) 
l, oZo:The networks  are  const ructed  f rom a 
h igh=leve l  spec i f i ca t ion  of the conceptua l  
k~o~ledoe  to be encoded.  The mapp ing  between 
the knowledge level  and the network  level  is 
p rec i se ly  spec i f ied.  Th is  mapp ing  is per fo r -  
med automat ica l ly  by a network  compi ler .  
AoYo: G iven  a gra~muar, we have an a lgor i thm 
to make a network  of units.  
I I IoA  short  l is t  of papers  re la ted  to 
your  research?  
GoCo: -Cot t re l l ,  Go, Small ,  S.: V iewing  
Pars ing  as a Word  Sense D isc r iminat ion :  
A Connect ion is t  Approach?  In B.Bara, 
G ,Gn ida  (eds.), Computat iona l  Mode ls  of 
Natura l  Language Process ing,  Amsterdam~ 
Nor th  Ho l land  1984 
--Cottrell, Go : A Connect ion is t  Approach  
to Nord  Sense D isambiguat ion .  (Techn. 
Repo 154) Rochester :  The Un ivers i ty  of 
Rochester ,  Dept  of Computer  Sc ience~ 
Rev ised  vers ion  to be p~bl i shed  by 
P i tman in the Research  Notes  in 
Ar t i f i c ia l  ~nte l l iuence  Ser ies  
PoDo~-Dey,  P?, Iyengar,  S.S., Byoun, J .S .  : 
Para l le l  p rocess ing  of Tree Ad jo in ing  
Grammars .  Dept.  of Computer  Sc ience,  
Un ivers i ty  of A labama at B i rmingham~ 
Repor t  1987 
- Joshi~ A.K.,  Levy~ L.S., Takahash i ,  M.: 
Tree Ad jo in ing  ~rammars .  Journa l  of the 
Computer  and System Sciences,  Vol.  i0~ 
pp. 136 - 163, March  1975 
V i jay -Shankar ,  K~, Joshi,  A?K. : Some 
Computat iona l  P roper t ies  of T ree  
Ad jo in ing  Grammars .P roc .23rd  Ann. 
Meet ing  Ass?CompiL ing . ,  pp. 82-93, 1985 
,}oDo:~Cottrell ,  G.W? Para l le l i sm in 
Inher i tance  H ierach ies  w i th  Except ions?  
XJCAI -85,  194-202,  Los Angeles,  1985o 
-Fanty,  M. Context -F ree  Pars ing  in 
Connect ion is t  Networks .  TR 174, 
Un ivers i ty  of Rochester ,  Depar tment  of 
Computer  Sc ience,  November  1985. 
-Fanty,  M~ Learn ing  in S t ructured  
Connect ion is t  Networks?  Ph.D. Thesis~ 
CS Depar tment ,  Univ~ of Rochester ,1988.  
~Feldman,  J .A.,  Fanty, M.A.,  & Goddard,  
No Comput ing  w i th  S t ructured  Neura l  
Networks~ IEEE Computer  1988; in press? 
-Shastr i ,  Lo & Feldman,  JoA. Semant ic  
Networks  and Neura l  Nets .  TR 131, 
Un ivers i ty  of Rochester ,  Depar tment  of 
Computer  Sc ience~ June 1984. 
-Shastr i~ L,, Ev ident ia l  reason ing  in 
semant ic  networks :  a formal  theory  and 
its para l le l  . imp lementat ion , ,  P:::~\]:~,, 
Thes is  and TR 166~ ComD~ ScJi , DG:pL, ~ 
Univ.  of Rochester~ Se~temb~}: ~ 1985o 
P oAoR. :L i te ra ture  f rom sys temic  li~E~uistJ.c:~ 
and para l le l  d i s t~ ib~ted  D:~oce~tsin~, 
HoS. : -Schne i le~ H~ ~ Element~; Of theo~'eticai!. 
net - l ingu is t i cs  t Pax't 1:  Syntactica~. 
and morpho log ica l  nets -- ~euro -  
l ingu is t i c  in terpretat ions  o 'J~heox'etic.~. 
Linguistic..so Ber l in:  D'a l te r  ~\[e Gz~u~te:~: 
& Coo, 8, 1981~ ppo &7-100. 
.. Schnel le ,  I~., Job, D~MoZ )9~\].em<~nt~ u l  
theoret i ca l  net- l in~l~ist ics ~. ~?a~'t ~ 
Phono log ica l  nets? ~:~h~o~:~tical 
! , inuu is t i c~ I0,. ~.9S3~ }?pc 3~79-203o 
.. Schnel le ,  }~o : Ar ray  ~_o~ic for ~l~ntact:{.< 
product ion  processors  ~ Xn Mey~ J~ (r:-~,d~) ~. 
~,an~uaue and D iscourse  : Test  
and }~rotest (Sgall--Festseh~ift} 
Amsterdam.  ~ John Ben jamins  D~,V... 
198~, ppo 477-511o 
-McCle l land,  JoLo~ ~Iman~ JoL.~ 
In teract ive  p~'ocessien speech  pe~ .. 
ce~)::io::~ The '~AC~ model,  p~.. 5S--:~:~) 
in: McCle l land~ JoL., R~e lhar t ,  l .~o~ 
and the PDP-oGroup~ Para.ilel Di~t~' : ' ib ' tV ted  
Process in~ --- Exp lorat io~ in the l~iic~:'o-,- 
structux;e of Cogni t ion ,  VOlo 2~ 1986o 
Aho, AoVo~ Ul lman,  J~noz ~z'inciples of 
Compi le :  Des ign  ~- Read ing  Mass?~ ~ d o2:4 
'rile Pars ing  Method  of Er:t@~'z A(\]dison '~ 
Wesley,  1979o 
L~S. z-Fahlman, S~.  NETI,: A System foz ? 
Represent ing  and Us ing  Rea\].-.~k~'Id 
Knowledge,  '}:he MIT Press, Cm.~b~ide3~ 
MA, 1979. 
-Hinton,  G.Eo Imp lement ing  Sema~t~:  
Networks  in Para l le l  Hardware?  In 
Para l le l  Mode ls  of Assoc ia t ive  Memo~yo 
pp. 161- 187 in: G.~;oHinton and 3gAg 
Anderson  (EdSo)~o La~rence  ~rlbau~,~ 
Assoc iates ,  H i l l sda le~ N~Jo~ 198~.o 
~.Derthik, M~ A Conneet ion is t  Arch i  ~ 
tecture  for Represent ing  and Reasoni~.~.i 
about  S t ructured  Knowled~eo Pz-oceed ~o 
ings of the n in th  annual  confe~'ence 
of the Cogn i t ive  Sc ience  Society? 
Seatt le~ July, 1987o I, awre~ce 
Er lbaum Assoc ia tes ,  H i l l sda le  ~oJo 
-Shast r i ,Lo :  A Connect ion is t  Ap~)roach t<~ 
Knowledge Representat ion  and :l.im~ted 
in ference.  To appeal" in Cogn i t ive  
Science:  12,3 (1988) 
-Shastr i ,  Lo: Se~ant ic  Net~: An Ev.~.de:<~-- 
t ia l  Formal i za t ion  and its Connectgo  . 
mis t  Rea l i za t ion .  Los Altos~ ~o:?'~as 
Kauf fman~ London:  P i tman P~bl .Compo 
A.Y .  : -Kaplan R.  : A Mul t i -P rocessor  Approach  
to Natura l  Language,  PrOCo Nat iona l  
Computer  Conference,  1973, ppo 435-440.  
,-Small S., R ieger  C. : Pars ing  and Com- 
prehend ing  w i th  Word  Experts~ in Stra -~ 
teg ies  for Natura l  Language P~oces~in~ 
(~Ds. M.D. R ing le  and Wo Lenher) 
Lawrence  Er lba~m Assoc iates ,  1988.. 
~Matsumoto  Y. : A Para l le l  Pars in~ S~ste~ 
fo~ Natura l  Langua~e~ Spr in~er  Lect~'~re 
Notes  in Computer  Science, No~ 225~ 
1986, ppo 396-409.  
-Yonezawa A, Ohsawa ~o : A New App~oach 
to Par~l le l  Pars ing  for  Context--Free 
Grammars ,  Research  Repor t  on Info:?'~ o~ 
at ion  Sc iences  C-87, Dew, to of ~nf~ ScJo 
Tokyo  Ins t l tn te  of Techno lo~y~ ~987. 
