Memoisation for Glue Language Deduction and Categorial Parsing 
Mark  Hepp le  
Department of Computer Science 
University of Sheffield 
Regent Court, 211 Portobello Street 
Sheffield S1 4DP, UK 
hepple@dcs, he f .  ac.  uk 
Abst rac t  
The multiplicative fragment of linear logic has 
found a number of applications in computa- 
tional linguistics: in the "glue language" ap- 
proach to LFG semantics, and in the formu- 
lation and parsing of various categorial gram- 
mars. These applications call for efficient de- 
duction methods. Although a number of de- 
duction methods for multiplicative linear logic 
are known, none of them are tabular meth- 
ods, which bring a substantial efficiency gain 
by avoiding redundant computation (c.f. chart 
methods in CFG parsing): this paper presents 
such a method, and discusses its use in relation 
to the above applications. 
1 In t roduct ion  
The multiplicative fragment of linear logic, 
which includes just the linear implication (o-) 
and multiplicative (?) operators, has found a 
number of applications within linguistics and 
computational linguistics. Firstly, it can be 
used in combination with some system of la- 
belling (after the 'labelled deduction' method- 
ology of (Gabbay, 1996)) as a general method 
for formulating various categorial grammar sys- 
tems. Linear deduction methods provide a com- 
mon basis for parsing categorial systems formu- 
lated in this way. Secondly, the multiplicative 
fragment forms the core of the system used in 
work by Dalrymple and colleagues for handling 
the semantics of LFG derivations, providing a 
'glue language' for assembling the meanings of 
sentences from those of words and phrases. 
Although there are a number of deduction 
methods for multiplicative linear logic, there is a 
notable absence of tabular methods, which, like 
chart parsing for CFGs, avoid redundant com- 
putation. Hepple (1996) presents a compilation 
method which allows for tabular deduction for 
implicational linear logic (i.e. the fragment with 
only o--). This paper develops that method to 
cover the fragment hat includes the multiplic- 
ative. The use of this method for the applica- 
tions mentioned above is discussed. 
2 Multiplicative Linear Logic 
Linear logic is a 'resource-sensitive' logic: in any 
deduction, each assumption ('resource') is used 
precisely once? The formulae of the multiplicat- 
ive fragment of (intuitionistic) linear logic are 
defined by ~" ::= A I ~'o-~" J 9 v ? ~ (A a 
nonempty set of atomic types). The following 
rules provide a natural deduction formulation: 
Ao--B : a B :b  
o-E 
A:  (ab) 
\[B : v\] 
A:a  
o--I 
Ao -B  : ),v.a 
\[B: x\],\[C : y\] B?C:  b 
A :a  A :a  B :b  
?E ?I 
A" @ ? E.,~(b, a) A?B:  (a ? b) 
The elimination (E) and introduction (I) rules 
for o-- correspond to steps of functional ap- 
plication and abstraction, respectively, as the 
term labelling reveals. The o--I rule dis- 
charges precisely one assumption (B) within 
the proof to which it applies. The ?I rule 
pairs together the premise terms, whereas ?E 
has a substitution like meaning. 1 Proofs 
that Wo--(Xo--Z), Xo--Y, Yo--Z =~ W and that 
Xo-Yo-Z, Y@Z =v X follow: 
Wo-(Xo-Z)  : w Xo-Y :x  Yo -Z :y  \[Z:z\]  
Y:  (yz) 
x: 
Xo--Z : Az.x(yz) 
w: 
1The meaning is more obvious in the notat ion of 
(Benton et al, 1992): ( let  b be  x~y in a). 
538 
Xo-Yo-Z  : x \[Z: z\] \[Y: y\] Y?Z:w 
Xo-Y: (zz) 
X: (zzu) 
x E~,,(w, (=z~)) 
The differential status of the assumptions and 
goal of a deduction (i.e. between F and A in 
F =v A) is addressed in terms of polarity: as- 
sumptions are deemed to have positive polar- 
ity, and goals negative polarity. Each Sub- 
formula also has a polarity, which is determ- 
ined by the polarity of the immediately con- 
taining (sub)formula, ccording to the following 
schemata (where 15 is the opposite polarity to p): 
(i) (X  p o--Y~)P (ii) (X  p?Yp)p  
For example, the leftmost assumption of the 
first proof above has the polarity pattern 
( W + o- (X- o- Z + )- )+. The proofs illustrate 
the phenomenon of 'hypothetical reasoning', 
where additional assumptions (called 'hypothet- 
icals') are used, which are later discharged. The 
need for hypothetical reasoning in a proof is 
driven by the types of the assumptions and goal: 
the hypotheticals correspond to positive polar- 
ity subformulae of the assumptions/goal that 
occur in the following subformula contexts: 
i) (X- o--Y+)- (giving hypothetical Y) 
ii) (X + ?Y+)+ (giving hypo's X and Y) 
The subformula (Xo-Z) of Wo--(Xo-Z) in the 
proof above is an instance of context (i), so a 
hypothetical Z results. Subformulae that are in- 
stances of patterns (i,ii) may nest within other 
such instances (e.g. in ((A?B)?C)o-D, both 
((A?B)@C) and (A?B) are instances of (ii)). 
In such cases, we can focus on the maximal pat- 
tern instances (i.e. not contained within any 
other), and then examine the hypotheticals pro- 
duced for whether they in turn license hypothet- 
ical reasoning. This approach makes explicit 
the patterns of dependency amongst hypothet- 
ical elements. 
3 F i r s t -o rder  Compi la t ion  for 
Imp l i ca t iona l  L inear  Logic  
Hepple (1996) shows how deductions in implic- 
ational linear logic can be recast as deductions 
involving only first-order formulae, using only 
a single inference rule (a variant of o-E). The 
method involves compiling the original formulae 
to indexed first-order formulae, where a higher- 
order 2 initial formula yields multiple compiled 
formulae, e.g. (omitting indices) Xo--(Yo--Z) 
would yield Xo--Y and Z, i.e. with the sub- 
formula Z, relevant o hypothetical reasoning, 
being excised to be treated as a separate as- 
sumption, leaving a first-order esidue. 3 Index- 
ing is used to ensure general inear use of re- 
sources, but also notably to ensure proper use 
of excised subformulae, i.e. so that Z, in our ex- 
ample, must be used in deriving the argument 
of Xo-Y, or otherwise invalid deductions would 
result). Simplifying Xo--(Yo--Z) to Xo--Y re- 
moves the need for an o--I inference, but the 
effect of such a step is not lost, since it is com- 
piled into the semantics of the formula. 
The approach is best explained by example. 
In proving Xo--(Yo--Z), Yo-W, Wo--Z =v X, 
the premise formulae compile to the indexed for- 
mulae (1-4) shown in the proof below. Each 
of these formulae (1-4) is associated with a 
set containing a single index, which serves as 
a unique identifier for that assumption. 
1. 
2. {j}:Z:z 
2. {k}:Yo--(W:0):Au.yu 
4. 
5. {j, 1} :W:wz  
6. {j,k, l} :Y:y(wz) 
7. {i,j, k,l}: X:x( z.y(wz)) 
\[2+4\] 
\[3+5\] 
\[1+6\] 
The formulae (5-7) arise under combination, al- 
lowed by the single rule below. The index sets 
of these formulae identify precisely the assump- 
tions from which they are derived, with appro- 
priate indexation being ensured by the condi- 
tion 7r = ?~? of the rule (where t2 stands for 
disjoint union, which enforces linear usage). 
?:Ao--(B:a):)~v.a ?:B :b  7r = ?~? 
rr: A: a\[b//v\] 
2The key division here is between higher-order formu- 
lae, which are are functors that seek at least one argu- 
ment that bears a a functional type (e.g. Wo--(Xo--Z)), 
and first-order formulae, which seek no such argument. 
3This 'excision' step has parallels to the 'emit' step 
used in the chart-parsing approaches for the associative 
Lambek calculus of (KSnig, 1994) and (Hepple, 1992), 
although the latters differs in that there is no removal 
of the relevant subformula, i.e. the 'emitting formula' is 
not simplified, remaining higher-order. 
539 
Assumptions (1) and (4) both come from 
Xo-(Yo--Z): note how (1)'s argument is marked 
with (4)'s index (j). The condition c~ C ? of the 
rule ensures that (4) must contribute to the de- 
rivation of (1)'s argument. Finally, observe that 
the rule's semantics involves not simple applic- 
ation, but rather by direct substitution for the 
variable of a lambda expression, employing a
special variant of substitution, notated _\[_//_\], 
which specifically does not act to avoid acci- 
dental binding. Hence, in the final inference of 
the proof, the variable z falls within the scope of 
an abstraction over z, becoming bound. The ab- 
straction over z corresponds to an o-I  step that 
is compiled into the semantics, o that an expli- 
cit inference is no longer required. See (Hepple, 
1996) for more details, including a precise state- 
ment of the compilation procedure. 
4 F i r s t -o rder  Compi la t ion  for  
Mu l t ip l i ca t ive  L inear  Log ic  
In extending the above approach to the multi- 
plicative, we will address the ?I and @E rules 
as separate problems. The need for an ?I use 
within a proof is driven by the type of either 
some assumption or the proof's overall goal, 
e.g. to build the argument of an assumption 
such as Ao-(B@C). For this specific example, 
we might try to avoid the need for an expli- 
cit @I use by transforming the assumption to 
the form Ao-Bc -C  (note that the two formu- 
lae are interderivable). This line of explora- 
tion, however, leads to incompleteness, ince the 
manoeuvre results in proof structures that lack 
a node corresponding to the result of the ?I in- 
ference (which is present in the natural deduc- 
tion proof), and this node may be needed as the 
locus of some other inference. 4 This problem 
can be overcome by the use of goal atoms, which 
are unique pseudo-type atoms, that are intro- 
duced into types by compilation (in the par- 
lance of lisp, they are 'gensymmed' atoms). An 
assumption Ao-(B@C) would compile to Ao--G 
plus Go-Bo-C, where G is the unique goal atom 
(gl, perhaps). A proof using these types does 
contain a node corresponding to (what would 
be) the result of the @ inference in the natural 
4Specifically, the node must be present o allow 
for steps corresponding to @E inferences. The ex- 
pert reader should be able to convince themselves 
of this fact by considering an example such as 
Xo- ( (Y?U)~- (Z?U)) ,  Yo -Z  ~ X. 
deduction proof, namely that bearing type G, 
the result of combining Go--Bo-C with its ar- 
guments. 
This method can be used in combination with 
the existing compilation approach. For ex- 
ample, an initial assumption Ao-((B?C)o--D) 
would yield a hypothetical D, leaving the 
residue Ao-(B@C), which would become Ac~-G 
plus Go--Bo-C, as just discussed. This method 
of uniquely-generated 'goal atoms' can also be 
used in dealing with deductions having complex 
types for their intended overall result (which 
may license hypotheticals, by virtue of real- 
ising the polarity contexts discussed in section 
2). Thus, we can replace an initial deduction 
F =~ A with Co--A, F ~ G, making the goal A 
part of the left hand side. The new premise 
Go---A can be compiled just like any other. Since 
the new goal formula G is atomic, it requires no 
compilation. For example, a goal type Xo-Y 
would become an extra premise Go--(Xo--Y), 
which would compile to formulae Go-X plus Y. 
Turning next to ?E, the rule involves hypo- 
thetical reasoning, so compilation of a maximal 
positive polarity subformula B?C will add hy- 
potheticals B,C. No further compilation of B?C 
itself is then required: whatever is needed for 
hypothetical reasoning with respect to the in- 
ternal structure of its subformulae will arise 
elsewhere by compilation of the hypotheticals 
B,C. Assume that these latter hypotheticals 
have identifying indices i, j and semantic vari- 
ables x, y respectively. A rule for ?E might 
combine B?C (with term t, say) with any other 
formula A (with term s, say) provided that the 
latter has a disjoint index set that includes i, j, 
to give a result that is also of type A, that is as- 
signed semantics E~y(t, s). To be able to con- 
struct this semantics, the rule would need to 
be able to access the identities of the variables 
x, y. The need to explicitly annotate this iden- 
tity information might be avoided by 'raising' 
the semantics of the multiplicative formula at 
compilation time to be a function over the other 
term, e.g. t might be raised to Au.E~y(t,u). A 
usable inference rule might then take the follow- 
ing form (where the identifying indices of the 
hypotheticals have been marked on the product 
type): 
(?,A,s) {?,(B?C): {i,j},Au.t) i , j ? ?  
~r = ?w? 
Gr, A, t\[sllu\]) 
540 
Note that we can safely restrict the rule to re- 
quire that the type A of the minor premise 
is atomic. This is possible since firstly, the 
first-order compilation context ensures that the 
arguments required by a functor to yield an 
atomic result are always present (with respect o 
completing a valid deduction), and secondly, the 
alternatives of combining a functor with a mul- 
tiplicative under the rule either before or after 
supplying its arguments are equivalent. 5 
In fact, we do not need the rule above, as 
we can instead achieve the same effects us- 
ing only the single (o--) inference rule that we 
already have, by allowing a very restricted use 
of type polymorphism. Thus, since the above 
rule's conclusion and minor premise are the 
same atomic type, we can in the compilation 
simply replace a formula XNY, with an implic- 
ation .Ao---(.A: {i,j}), where ,4 is a variable over 
atomic types (and i , j  the identifying indices 
of the two hypotheticals generated by compil- 
ation). The semantics provided for this functor 
is of the 'raised' kind discussed above. However, 
this approach to handling ?E inferences within 
the compiled system has an undesirable charac- 
teristic (which would also arise using the infer- 
ence rule discussed above), which is that it will 
allow multiple derivations that assign equival- 
ent proof terms for a given type combination. 
This is due to non-determinism for the stage 
at which a type such as Ao---(A: {i,j}) particip- 
ates in the proof. A proof might contain sev- 
eral nodes bearing atomic types which contain 
the required hypotheticals, and Ao-(al: {i, j}) 
might combine in at any of these nodes, giving 
equivalent results. 6
The above ideas for handling the multiplicat- 
ive are combined with the methods developed 
5This follows from the proof term equivalence 
E~,y(f,(ga)) = (E~,~(f,9) a) where x,y  E freevars(g). 
The move of requiring the minor premise to be atomic 
effects a partial normalisation which involves not only 
the relative ordering of ?E and o--E steps, but also that 
between interdependent ?E steps (as might arise for an 
assumption such as ((ANB)?C)). It is straightforward 
to demonstrate that the restriction results in no loss of 
readings. See (Benton et al, 1992) regarding term as- 
signment and proof normalisation for linear logic. 
6It is anticipated that this problem can be solved by 
using normalisation results as a basis for discarding par- 
tial analyses during processing, but further work is re- 
quired in developing this idea. 
for the implicational fragment to give the com- 
pilation procedure (~-), stated in Figure 1. This 
takes a sequent F => A as input (case T1), where 
A is a type and each assumption in F takes 
the form Type:Sere (Sere minimally just some 
unique variable), and it returns a structure 
(~, ?, A}, where ~ is a goal atom, ? the set of 
all identifying indices, and A a set of indexed 
first order formulae (with associated semantics). 
Let A* denote the result of closing A under the 
single inference rule. The sequent is proven iff 
(?, ~, t) E A* for some term t, which is a com- 
plete proof term for the implicit deduction. The 
statement of the compilation procedure here is 
somewhat different to that given in (Hepple, 
1996), which is based on polar translation func- 
tions. In the version here, the formula related 
cases address only positive formulae. T 
As an example, consider the deduction 
Xo--Y, Y?Z => XNZ. Compilation returns the 
goal atom gO, the full index set {g, h, i, j, k, l}, 
)lus the formulae show in (1-6) below. 
1. ({9},gOo-(gl: {h}),At.t) 
2. ({h},glo-(X:O)o-(Z:O),AvAw.(w ?v)) 
3. ({i},Xo-(Y:O),kx.(ax)) 
4. ({j},A~-(A: {k, 0), ~.E~z(b, u)> 
5. {{k},Y,y} 
6. ({/},Z,z) 
7. ({i, k}, X, (ay)) \[3+5\] 
8. <{h,l},glo---(X:O),Aw.(w?z)) \[2+6\] 
9. {{h,i, k,l}, gl, ((ay) ? z)) \[7+8\] 
10. ({h,i,j,k,l},gl, E~z(b,((ay)?z))) \[4+9\] 
11. ({g,h,i,j,k,l},gO, E~(b,((ay)?z))) \[1+11\] 
12. {{g, h,i, k, l}, gO, ((ay) ? z)) \[1+9\] 
13. ({9, h,i,j,k,l},gO, E~(b,((ay) Nz))) \[4+12\] 
The formulae (7-13) arise under combination. 
Formulae (11) and (13) correspond to success- 
ful overall analyses (i.e. have type gO, and are 
labelled with the full index set). The proof il- 
lustrates the possibility of multiple derivations 
7Note that the complexity of the compilation is linear 
in the 'size' of the initial deduction, as measured by a 
count of type atoms. For applications where the formulae 
that may participate are preset (e.g. they are drawn 
from lexicon), formulae can be precompiled, although the 
results of precompilation would need to be parametised 
with respect o the variables/indices appearing, with a 
sufficient supply 'fresh' symbols being generated at time 
of lexical access, to ensure uniqueness. 
541 
(T1) T(X I :X l , . . . ,Xn :x  n =:~ Xo)  -- (~,4, i )  
where i0 , . . . , in  fresh indices; ~ a fresh goal atom; ? = indices(A) 
A = 7-(<i0, Go-Xo,  y.y>)u 7-(<il, Xl,  xl>) u . . .  u 7-(<in, xn,  
(7-2) 7"((4, X, 8)) : (4, X, s) where X atomic 
(7-3) 7-((?,Xo-Y,s)) = 7-((4, Xo-(Y:O),s)) where Y has no (inclusion) index set 
(7-4) T((4, X lo- (Y :?) ,s ) )  = (4, X2o--(Y:?),;~x.t) UF 
where Y is atomic; x a fresh variable; 7-((4, X1, (sx))) = (4, X2, t) +ttJF 
(T5) 7-((4, Xo-( (Yo-Z) :  ?), s)) = 7-((?, Xo-(Y:  ~r), Ay.s()~z.y))) U 7-((i, Z, z)) 
where i a fresh index; y, z fresh variables; 7r = i U ? 
(7-6) 7-((4, Xo- ( (Y  ? Z): ?), s)) = 7-((4, Xo-(G: ~), s)) u 7-((i, ~o-Yo-Z,  ~z~y.(y ? z))) 
where i a fresh index; G a fresh goal atom; y, z fresh variables; 7r = i U 
(77) T((4, X ? Y,s)) = (4, Ao---(A: {i, j}),At.(E~(s,t)))  UT-((i,X,x)) U T((j,Y,y)) 
where i, j fresh indices; x, y, t fresh variables; .4 a fresh variable over atomic types 
Figure 1: The Compilation Procedure 
assigning equivalent readings, i.e. (11) and (13) 
have identical proof terms, that arise by non- 
determinism for involvement of formula (4). 
5 Comput ing  Exc lus ion  Const ra in ts  
The use of inclusion constraints (i.e. require- 
ments that some formula must be used in de- 
riving a given functor's argument) within the 
approach allows us to ensure that hypotheticals 
are appropriately used in any overall deduction 
and hence that deductions are valid. However, 
the approach allows that deduction can generate 
some intermediate r sults that cannot be part of 
an overall deduction. For example, compiling a
formula Xo--(Yo--(Zo--W))o--(Vo-W) gives the 
first-order esidue Xo-Yo--V, plus hypothetic- 
als Zo-W and W. A partial deduction in which 
the hypothetical Zo-W is used in deriving the 
argument V of Xo--Yo-V cannot be extended 
to a successfull overall deduction, since its use 
again for the functor's second argument Y (as 
an inclusion constraint will require) would viol- 
ate linear usage. For the same reason, a direct 
combination of the hypotheticals Zo-W and W 
is likewise a deductive dead end. 
This problem can be addressed via exclusion 
constraints, i.e. annotations to forbid stated 
formulae having been used in deriving a given 
funtor's argument, as proposed in (Hepple, 
1998). Thus, a functor might have the form 
Xo---(Y:{i}:{j}) to indicate that i must appear 
in its argument's index set, and that j must not. 
Such exclusions can be straightforwardly com- 
puted over the set of compiled formulae that de- 
rive from each initial assumption, using simple 
(set-theoretic) patterns of reasoning. For ex- 
ample, for the case above, since W must be 
used in deriving the argument V of the main 
residue formula, it can be excluded from the ar- 
gument Y of that formula (which follows from 
the disjointness condition on the single inference 
rule). Given that the argument Y must include 
Zo--W, but excludes W, we can infer that W 
cannot contribute to the argument of Zo--W, 
giving an exclusion constraint hat (amongst 
other things) blocks the direct combination of 
Zo--W and W. See (Hepple, 1998) for more de- 
tails (although a slightly different version of the 
first-order formalism is used there). 
6 Tabu lar  Deduct ion  
A simple algorithm for use with the above ap- 
proach, which avoids much redundant compu- 
tation, is as follows. Given a possible theorem 
to prove, the results of compilation (i.e. in- 
dexed types plus semantics) are gathered on an 
agenda. Then, a loop is followed in which an 
item is taken from the agenda nd added to the 
database (which is initially empty), and then 
the next triple is taken from the agenda and 
542 
so on until the agenda is empty. Whenever an 
entry is added to the database, a check is made 
to see if it can combine with any that are already 
there, in which case new agenda items are gen- 
erated. When the agenda is empty, a check is 
made for any successful overall analyses. Since 
the result of a combination always bears an in- 
dex set larger than either parent, and since the 
maximal index set is fixed at compilation time, 
the above process must terminate. 
However, there is clearly more redundancy 
to be eliminated here. Where two items dif- 
fer only in their semantics, their subsequent 
involvement in any further deductions will be 
precisely parallel, and so they can be collapsed 
together. For this purpose, the semantic om- 
ponent of database ntries is replaced with a 
unique identifer, which serves as a 'hook' for 
semantic alternatives. Agenda items, on the 
other hand, instead record the way that the 
agenda item was produced, which is either 'pre- 
supplied' (by compilation) or 'by combination', 
in which case the entries combined are recorded 
by their identifiers. When an agenda item is 
added to the database, a check is made for an 
entry with the same indexed type. If there is 
none, a new entry is created and a check made 
for possible combinations (giving rise to new 
agenda items). However, if an appropriate x- 
isting entry is found, a record is made for that 
entry of an additional way to produce it, but 
no check made for possible combinations. If at 
the end there is a successful overall analsysis, 
its unique identifier, plus the records of what 
combined to produce what, can be used to enu- 
merate directly the proof terms for successful 
analyses. 
7 App l i ca t ion  ~1:  Categor ia l  
Parsing 
The associative Lambek calculus (Lambek, 
1958) is perhaps the most familiar representat- 
ive of the class of categorial formalisms that fall 
within the 'type-logical' tradition. Recent work 
has seen proposals for a range of such systems, 
differing in their resource sensitivity (and hence, 
implicitly, their underlying notion of 'linguistic 
structure'), in some cases combining differing 
resource sensitivities in one system, s Many of 
SSee, for example, the formalisms developed in 
(Moortgat et al, 1994), (Morrill, 1994), (Hepple, 1995). 
these proposals employ a 'labelled deductive 
system' methodology (Gabbay, 1996), whereby 
types in proofs are associated with labels which 
record proof information for use in ensuring cor- 
rect inferencing. A natural 'base logic' on which 
to construct such systems is the multiplicat- 
ive fragment of linear logic, since (i) it stands 
above the various categorial systems in the hier- 
archy of substructural logics, and (ii) its oper- 
ators correspond to precisely those appearing in 
any standard categorial logic. The key require- 
ment for parsing categorial systems formulated 
in this way is some theorem proving method 
that is sufficient for the fragment of linear logic 
employed (although some additional work will 
be required for managing labels), and a num- 
ber of different approaches have been used, e.g. 
proof nets (Moortgat, 1992), and SLD resolu- 
tion (Morrill, 1995). Hepple (1996) introduces 
first-order compilation for implicational linear 
logic, and shows how that method can be used 
with labelling as a basis parsing implicational 
categorial systems. No further complications 
arise for combining the extended compilation 
approach described in this paper with labelling 
systems as a basis for efficient, non-redundant 
parsing of categorial formalisms in the core mul- 
tiplicative fragment. See (Hepple, 1996) for a 
worked example. 
8 App l i ca t ion  ~2:  G lue  Language 
Deduct ion  
In a line of research beginning with Dalrymple 
et al (1993), a fragment of linear logic is used as 
a 'glue language' for assembling sentence mean- 
ings for LFG analyses in a 'deductive' fashion 
(enabling, for example, an direct treatment of 
quantifier scoping, without need of additional 
mechanisms). Some sample expressions: 
hates:  
VX, Y.(s ~t  hates(X, Y) )o-( (f .,., eX) ? (g"-% Y) ) 
everyone:  VH, S.(H-,-*t every(person, S)) 
o-(Vx.(H x)) 
The operator ~ serves to pair together a 'role' 
with a meaning expression (whose semantic 
type is shown by a subscript), where a 'role' 
is essentially a node in a LFG f-structure. For 
our purposes roles can be treated as if they were 
just atomic symbols. For theorem proving pur- 
poses, the universal quantifiers above can be de- 
leted: the uppercase variables can be treated 
543 
as Prolog-like variables, which become instanti- 
ated under matching during proof construction; 
the lowercase variables can be replaced by arbit- 
rary constants. Such deletion leaves a residue 
that can be treated as just expressions of mul- 
tiplicative linear logic, with role/meaning pairs 
serving as 'basic formulae'. 9 
An observation contrasting the categorial and 
glue language approaches is that in the cat- 
egorial case, all that is required of a deduction 
is the proof term it returns, which (for 'lin- 
guistic derivations') provides a 'semantic recipe' 
for combining the lexical meanings of initial for- 
mulae directly. However, for the glue language 
case, given the way that meanings are folded 
into the logical expressions, the lexical terms 
themselves must participate in a proof for the 
semantics of a LFG derivation to be produced. 
Here is one way that the first-order compila- 
tion approach might be used for glue language 
deduction (other ways are possible). Firstly, 
we can take each (quantifier-free) glue term, re- 
place each role/meaning pair with just the role 
component, and associate the resulting formula 
with a unique semantic variable. The set of for- 
mulae so produced can then undergo the first- 
order compilation procedure. Crucially for com- 
pilation, although some of the role expressions 
in the formulae may be ('Prolog-like') variables, 
they correspond to atomic formulae (so there is 
no 'hidden structure' that compilation cannot 
address). A complication here is that occur- 
rences of a single role variable may end up in 
different first-order formulae. In any overall de- 
duction, the binding of these multiple variable 
instances must be consistent, but we cannot rely 
on a global binding context, since alternative 
proofs will typically induce distinct (but intern- 
ally consistent) bindings. Hence, bindings must 
be handled locally (i.e. relative to each database 
formula) and combinations will involve merging 
of local binding contexts. Each proof term that 
tabular deduction returns corresponds to a nat- 
ural deduction proof over the precompilation 
formulae. If we mechanically mirror this pat- 
tern of proof over the original glue terms (with 
meanings, but quantifier-free), a role/meaning 
9See (Fry, 1997), who uses a proof net method for glue 
language deduction, for relevant discussion. This paper 
also provides examples of glue language uses that require 
a full deductive system for the multiplicative fragment. 
pair that provides a reading of the original LFG 
derivation will result. 
References 
Nick Benton, Gavin Bierman, Valeria de Paiva 
& Martin Hyland. 1992. 'Term Assignment 
for Intuitionistic Linear Logic.' Tech. Report 
262, Cambridge University Computer Lab. 
Mary Dalrymple, John Lamping & Vijay 
Saraswat. 1993. 'LFG semantics via con- 
straints.' Proc. EACL-6, Utrecht. 
John Fry 1997. 'Negative Polarity Licensing 
at the Syntax-Semantics Interface.' Proc. 
A CL/EA CL-97 Joint Con\]erence, Madrid. 
Dov M. Gabbay. 1996. Labelled deductive sys- 
tems. Volume 1. Oxford University Press. 
Mark Hepple. 1992. 'Chart Parsing Lambek 
Grammars: Modal Extensions and Incre- 
mentality', Proc. COLING-92. 
Mark Hepple. 1995. 'Mixing Modes of Lin- 
guistic Description in Categorial Grammar.' 
Proc. EA CL-7, Dublin. 
Mark Hepple. 1996. 'A Compilation-Chart 
Method for Linear Categorial Deduction.' 
Proc. COLING-96, Copenhagen. 
Mark Hepple. 1998. 'Linear Deduction via 
First-order Compilation.' Proc. First Work- 
shop on Tabulation in Parsing and Deduc- 
tion. 
Esther KSnig. 1994. 'A Hypothetical Reasoning 
Algorithm for Linguistic Analysis.' Journal 
of Logic and Computation, Vol. 4, No 1. 
Joachim Lambek. 1958. 'The mathematics of
sentence structure.' American Mathematical 
Monthly, 65, pp154-170. 
Michael Moortgat. 1992. 'Labelled deduct- 
ive systems for categorial theorem proving.' 
Proc. o/Eighth Amsterdam Colloquium, ILLI, 
University of Amsterdam. 
Michael Moortgat & Richard T. Oehrle. 1994. 
'Adjacency, dependency and order.' Proc. of 
Ninth Amsterdam Colloquium. 
Glyn Morrill. 1994. Type Logical Grammar: 
Categorial Logic of Signs. Kluwer Academic 
Publishers, Dordrecht. 
Glyn Morrill. 1995. 'Higher-order Linear Lo- 
gic Programming of Categorial Deduction.' 
Proc. of EACL-7, Dublin. 
544 
