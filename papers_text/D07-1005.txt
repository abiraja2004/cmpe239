Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational
Natural Language Learning, pp. 42?50, Prague, June 2007. c?2007 Association for Computational Linguistics
Improving Word Alignment with Bridge Languages
Shankar Kumar and Franz Och and Wolfgang Macherey
Google Inc.
1600 Amphitheatre Parkway
Mountain View, CA 94043, U.S.A.
{shankarkumar,och,wmach}@google.com
Abstract
We describe an approach to improve
Statistical Machine Translation (SMT)
performance using multi-lingual, parallel,
sentence-aligned corpora in several bridge
languages. Our approach consists of a sim-
ple method for utilizing a bridge language to
create a word alignment system and a proce-
dure for combining word alignment systems
from multiple bridge languages. The final
translation is obtained by consensus de-
coding that combines hypotheses obtained
using all bridge language word alignments.
We present experiments showing that mul-
tilingual, parallel text in Spanish, French,
Russian, and Chinese can be utilized in
this framework to improve translation
performance on an Arabic-to-English task.
1 Introduction
Word Alignment of parallel texts forms a cru-
cial component of phrase-based statistical machine
translation systems. High quality word alignments
can yield more accurate phrase-pairs which improve
quality of a phrase-based SMT system (Och and
Ney, 2003; Fraser and Marcu, 2006b).
Much of the recent work in word alignment has
focussed on improving the word alignment quality
through better modeling (Och and Ney, 2003; Deng
and Byrne, 2005; Martin et al, 2005) or alternative
approaches to training (Fraser and Marcu, 2006b;
Moore, 2005; Ittycheriah and Roukos, 2005). In
this paper we explore a complementary approach to
improve word alignments using multi-lingual, par-
allel (or multi-parallel) corpora. Two works in the
literature are very relevant to our approach. Borin
(2000) describes a non-statistical approach where a
pivot alignment is used to combine direct translation
and indirect translation via a third language. Filali
and Bilmes (2005) present a multi-lingual extension
to the IBM/HMMmodels. Our current approach dif-
fers from this latter work in that we propose a sim-
ple framework to combine word alignments from
any underlying statistical alignment model without
the need for changing the structure of the model.
While both of the above papers focus on improv-
ing word alignment quality, we demonstrate that
our approach can yield improvements in transla-
tion performance. In particular, we aim to improve
an Arabic-to-English (Ar-En) system using multi-
parallel data from Spanish (Es), French (Fr), Rus-
sian (Ru) and Chinese (Zh). The parallel data in
these languages X ? {Es, Fr,Ru, Zh} is used to
generate word alignments between Arabic-X and
X-English. These alignments are then combined to
obtain multiple word alignments for Arabic-English
and the final translation systems.
The motivation for this approach is two-fold.
First, we believe that parallel corpora available
in several languages provide a better training ma-
terial for SMT systems relative to bilingual cor-
pora. Such multi-lingual parallel corpora are be-
coming widely available; examples include proceed-
ings of the United Nations in six languages (UN,
2006), European Parliament (EU, 2005; Koehn,
2003), JRC Acquis corpus (EU, 2007) and religious
texts (Resnik et al, 1997). Word alignment systems
42
trained on different language-pairs (e.g. French-
English versus Russian-English) make errors which
are somewhat orthogonal. In such cases, incorrect
alignment links between a sentence-pair can be cor-
rected when a translation in a third language is avail-
able. Thus it can help resolve errors in word align-
ment. We combine word alignments using several
bridge languages with the aim of correcting some
of the alignment errors. The second advantage of
this approach is that the word alignment from each
bridge language can be utilized to build a phrase-
based SMT system. This provides a diverse collec-
tion of translation hypotheses for MT system com-
bination (Bangalore et al, 2002; Sim et al, 2007;
Matusov et al, 2006; Macherey and Och, 2007). Fi-
nally, a side benefit of this paper is that it provides a
study that compares alignment qualities and BLEU
scores for models in different languages trained on
parallel text which is held identical across all lan-
guages.
We show that parallel corpora in multiple lan-
guages can be exploited to improve the translation
performance of a phrase-based translation system.
This paper gives specific recipes for using a bridge
language to construct a word alignment and for com-
bining word alignments produced by multiple statis-
tical alignment models.
The rest of this paper is organized as follows: Sec-
tion 2 gives an overview of our framework for gen-
erating word alignments in a single language-pair.
In Section 3, we describe how a bridge language
may be used for producing word alignments. In Sec-
tion 4, we describe a scheme to combine word align-
ments from several bridge languages. Section 5 de-
scribes our experimental setup and reports the align-
ment and translation performance. A final discus-
sion is presented in Section 6.
2 Word Alignment Framework
A statistical translation model (Brown et al, 1993;
Och and Ney, 2003) describes the relationship be-
tween a pair of sentences in the source and target
languages (f = fJ1 , e = e
I
1) using a translation
probability P (f |e). Alignment models introduce a
hidden alignment variable a = aJ1 to specify a map-
ping between source and target words; aj = i in-
dicates that the jth source word is linked to the ith
target word. Alignment models assign a probabil-
ity P (f ,a|e) to the source sentence and alignment
conditioned on the target sentence. The transla-
tion probability is related to the alignment model as:
P (f |e) =
?
a P?(f ,a|e), where ? is a set of param-
eters.
Given a sentence-pair (f , e), the most likely
(Viterbi) word alignment is found as (Brown et al,
1993): a? = argmaxa P (f ,a|e). An alternate cri-
terion is the Maximum A-Posteriori (MAP) frame-
work (Ge, 2004; Matusov et al, 2004). We use a
refinement of this technique.
Given any word alignment model, posterior prob-
abilities can be computed as (Brown et al, 1993)
P (aj = i|e, f) =
?
a
P (a|f , e)?(i, aj), (1)
where i ? {0, 1, ..., I}. The assignment aj = 0
corresponds to the NULL (empty) alignment. These
posterior probabilities form a matrix of size (I+1)?
J , where entries along each column sum to one.
The MAP alignment for each source position j ?
{1, 2, ..., J} is then computed as
aMAP (j) = argmax
i
P (aj = i|e, f). (2)
We note that these posterior probabilities can be
computed efficiently for some alignment models
such as the HMM (Vogel et al, 1996; Och and Ney,
2003), Models 1 and 2 (Brown et al, 1993).
In the next two sections, we describe how poste-
rior probabilities can be used to a) construct align-
ment systems from a bridge language, and b) merge
several alignment systems.
3 Constructing Word Alignment Using a
Bridge Language
We assume here that we have triples of sentences
that are translations of each other in languages F, E,
and the bridge language G: f = fJ1 , e = e
I
1,g =
gK1 . Our goal is to obtain posterior probability es-
timates for the sentence-pair in FE: (f , e) using the
posterior probability estimates for the sentence pairs
in FG: (f ,g) and GE: (g, e). The word alignments
between the above sentence-pairs are referred to as
aFE , aFG, and aGE respectively; the notation aFE
indicates that the alignment maps a position in F to
a position in E.
43
We first express the posterior probability as a sum
over all possible translations g in G and hidden
alignments aFG.
P (aFEj = i|e, f)
=
?
g
P (aFEj = i,g|e, f)
=
?
g,k
P (aFEj = i,g, a
FG
j = k|e, f)
=
?
g,k
{
P (g|e, f)P (aFGj = k|g, e, f)
?P (aFEj = i|a
FG
j = k,g, e, f)
}
(3)
We now make some assumptions to simplify the
above expression. First, there is exactly one trans-
lation g in bridge language G corresponding to the
sentence-pair f , e. Since aGE
aFGj
= i = aFEj , we can
express
P (aFEj = i|a
FG
j = k,g, f , e) = P (a
GE
k = i|g, e).
Finally, alignments in FG do not depend on E.
Under these assumptions, we arrive at the final ex-
pression for the posterior probability FE in terms of
posterior probabilities for GF and EG
P (aFEj = i|e, f) = (4)
K?
k=0
P (aFGj = k|g, f)P (a
GE
k = i|g, e)
The above expression states that the posterior prob-
ability matrix for FE can be obtained using a simple
matrix multiplication of posterior probability ma-
trices for GE and FG. In this multiplication, we
prepend a column to the GE matrix corresponding
to k = 0. This probability P (aGEk = i) when k = 0
is not assigned by the alignment model; we set it as
follows
P (aGEk = i|k = 0) =
{
 i = 0
1?
I i ? {1, 2, ..., I}
The parameter  controls the number of empty align-
ments; a higher value favors more empty alignments
and vice versa. In our experiments, we set  = 0.5.
4 Word Alignment Combination Using
Posterior Probabilities
We next show how Word Alignment Posterior Prob-
abilities can be used for combining multiple word
alignment systems. In our context, we use this pro-
cedure to combine word alignments produced using
multiple bridge languages.
Suppose we have translations in bridge languages
G1, G2, ..., GN , we can generate a posterior prob-
ability matrix for FE using each of the bridge lan-
guages. In addition, we can always generate a poste-
rior probability matrix for FE with the FE alignment
model directly without using any bridge language.
These N + 1 posterior matrices can be combined as
follows. Here, the variable B indicates the bridge
language. B ? {G0, G1, ..., GN}; G0 indicates the
case when no bridge language is used.
P (aFEj = i|e, f) (5)
=
N?
l=0
P (B = Gl, a
FE
j = i|e, f)
=
N?
l=0
P (B = Gl)P (a
FE
j = i|Gl, e, f),
where P (aFEj = i|Gl, j, e, f) is the posterior proba-
bility when bridge language B = Gl. The probabili-
ties P (B = Gl) sum to one over l ? {0, 1, 2, ..., N}
and represent the prior probability of bridge lan-
guage l. In our experiments, we use a uniform prior
P (B = Gl) = 1N+1 . Equation 5 provides us a way
to combine word alignment posterior probabilites
from multiple bridge languages. In our alignment
framework (Section 2), we first interpolate the pos-
terior probability matrices (Equation 5) and then ex-
tract the MAP word alignment (Equation 2) from the
resulting matrix.
5 Experiments
We now present experiments to demonstrate the ad-
vantages of using bridge languages. Our experi-
ments are performed in the open data track of the
NIST Arabic-to-English (A-E) machine translation
task 1.
5.1 Training and Test Data
Our approach to word alignment (Section 3) requires
aligned sentences in multiple languages. For train-
ing alignment models, we use the ODS United Na-
1http://www.nist.gov/speech/tests/mt/
44
Set # of Ar words (K) # of sentences
dev1 48.6 2007
dev2 11.4 498
test 37.8 1610
blind 36.5 1797
Table 1: Statistics for the test data.
tions parallel data (UN, 2006) which contains par-
liamentary documents from 1993 onwards in all six
official languages of the UN: Arabic (Ar), Chinese
(Zh), English (En), French (Fr), Russian (Ru), and
Spanish (Es).
We merge the NIST 2001-2005 Arabic-English
evaluation sets into a pool and randomly sam-
ple this collection to create two development sets
(dev1,dev2) and a test set (test) with 2007, 498, and
1610 sentences respectively. Our blind test (blind)
set is the NIST part of the NIST 06 evaluation set
consisting of 1797 sentences. The GALE portion of
the 06 evaluation set is not used in this paper. We re-
port results on the test and blind sets. Some statistics
computed on the test data are shown in Table 1.
5.2 Alignment Model Training
For training Arabic-English alignment models, we
use Chinese, French, Russian and Spanish as bridge
languages. We train a model for Ar-En and 4 mod-
els each for Ar-X and X-En, where X is the bridge
language. To obtain aligned sentences in these lan-
guage pairs, we train 9 sentence aligners. We then
train alignment models for all 9 language-pairs us-
ing a recipe consisting of 6 Model-1 iterations and
6 HMM iterations. Finally, Word Alignment Poste-
rior Probabilities are generated over the bitext. In
Table 2, we report the perplexities of the alignment
models for the translation directions where either
Arabic or English is predicted. There are 55M Ara-
bic tokens and 58M English tokens. We observe
that the alignment model using Spanish achieves the
lowest perplexity; this value is even lower than the
perplexity of the direct Arabic-English model. Per-
plexity is related to the hardness of the word align-
ment; the results suggest that bridge languages such
as Spanish make alignment task easier while others
do not. We stress that perplexity is not related to the
alignment or the translation performance.
Bridge Perplexity
Lang ? Ar ?En
None 113.8 26.1
Es 99.0 22.9
Fr 138.6 30.2
Ru 128.3 27.5
Zh 126.1 34.6
Table 2: Perplexities of the alignment models.
5.3 Bridge Language Word Alignments
Each of the 4 bridge languages is utilized for con-
structing a word alignment for Arabic-English. Us-
ing each bridge language X, we obtain Arabic-
English word alignments in both translation direc-
tions (AE and EA). The posterior matrix for AE is
obtained using AX and XE matrices while the EA
matrix is obtained from EX and XA matrices (Equa-
tion 4). The AE (EA) matrices from the bridge
languages are then interpolated with the AE (EA)
matrix obtained from the alignment model trained
directly on Arabic-English (Section 4). The MAP
word alignment for AE (EA) direction is computed
from the AE (EA) matrix. We next outline how these
word alignments are utilized in building a phrase-
based SMT system.
5.4 Phrase-based SMT system
Our phrase-based SMT system is similar to the
alignment template system described in Och and
Ney (2004). We first extract an inventory of phrase-
pairs up to length 7 from the union of AE and EA
word alignments. Various feature functions (Och
and Ney, 2004) are then computed over the entries
in the phrase table. 5-gram word language models
in English are trained on a variety of monolingual
corpora (Brants et al, 2007). Minimum Error Rate
Training (MERT) (Och, 2003) under BLEU crite-
rion is used to estimate 20 feature function weights
over the larger development set (dev1).
Translation is performed using a standard dy-
namic programming beam-search decoder (Och and
Ney, 2004). Decoding is done in two passes. An ini-
tial list of 1000-best hypotheses is generated by the
decoder. This list is then rescored using Minimum
Bayes-Risk (MBR) decoding (Kumar and Byrne,
2004). The MBR scaling parameter is tuned on the
smaller development set (dev2).
45
Bridge Metrics(%)
Language AE EA
Prec Rec AER Prec Rec AER
None 74.1 73.9 26.0 67.3 57.7 37.9
Es 61.7 56.3 41.1 50.0 40.2 55.4
Fr 52.9 48.0 49.7 42.3 33.6 62.5
Ru 57.4 50.8 46.1 40.2 31.6 64.6
Zh 44.3 39.3 58.3 39.7 29.9 65.9
AC1 70.0 65.0 32.6 56.8 46.4 48.9
Table 3: Alignment Performance with Bridge Lan-
guages
5.5 Alignment Results
We first report alignment performance (Table 3) of
the alignment models obtained using the bridge lan-
guages. Alignment results are reported in terms
of Precision (Prec), Recall (Rec) and Alignment
Error Rate (AER). We report these numbers on
a 94-sentence test set with translations in all six
languages and human word alignments in Arabic-
English. Our human word alignments do not dis-
tinguish between Sure and Probable links (Och and
Ney, 2003).
In these experiments, we first identify the com-
mon subset of sentences which have translations in
all six languages. Each of the 9 alignment models
is then trained on this subset. We report Alignment
performance in both translation directions: Arabic-
to-English (AE) and English-to-Arabic (EA). The
first row (None) gives the results when no bridge
language is used.
Among the bridge languages, Spanish gives the
best alignment for Arabic-English while Chinese re-
sults in the worst. This might be related to how dif-
ferent the bridge language is relative to either En-
glish or Arabic. The last row (AC1) shows the per-
formance of the alignment obtained by combining
None/Es/Fr/Ru/Zh alignments. This alignment out-
performs all bridge alignments but is weaker than
the alignment without any bridge language. Our
hypothesis is that a good choice of interpolation
weights (Equation 5) would reduce AER of the AC1
combination. However, we did not investigate these
choices in this paper. We report alignment error rates
here to give the readers an idea of the vastly differ-
ent alignment performance using each of the bridge
languages.
5.6 Translation Results
We now report translation performance of our tech-
niques. We measure performance using the NIST
implementation of case sensitive BLEU-4 on true-
cased translations. We observed in experiments
not reported here that results are almost identical
with/without Minimum Error Rate Training ; we
therefore report the results without the training. We
note that the blind set is the NIST subset of the 2006
NIST evaluation set. The systems reported here are
for the Unlimited Data Track in Arabic-to-English
and obtain competitive performance relative to the
results reported on the NIST official results page 2
We present three sets of experiments. In Table 4,
we describe the first set where all 9 alignment mod-
els are trained on nearly the same set of sentences
(1.9M sentences, 57.5M words in English). This
makes the alignment models in all bridge languages
comparable. In the first rowmarked None, we do not
use a bridge language. Instead, an Ar-En alignment
model is trained directly on the set of sentence pairs.
The next four rows give the performance of align-
ment models trained using the bridge languages Es,
Fr, Ru and Zh respectively. For each language, we
use the procedure (Section 3) to obtain the posterior
probability matrix for Arabic-English from Arabic-
X and X-English matrices. The row AC1 refers to
alignment combination using interpolation of poste-
rior probabilities described in Section 4. We com-
bine posterior probability matrices from the systems
in the first four rows: None, Es, Ru and Zh. We
exclude the Zh system from the AC1 combination
because it is found to degrade the translation perfor-
mance by 0.2 points on the test set.
In the final six rows of Table 4, we show the per-
formance of a consensus decoding technique that
produces a single output hypothesis by combin-
ing translation hypotheses from multiple systems;
this is an MBR-like candidate selection procedure
based on BLEU correlation matrices and is de-
scribed in Macherey and Och (2007). We first report
performance of the consensus output by combining
None systems with/without MERT. Each of the fol-
lowing rows provides the results from consensus de-
coding for adding an extra system both with/without
MERT. Thus, the final row (TC1) combines transla-
2
http://www.nist.gov/speech/tests/mt/mt06eval official results.html
46
tions from 12 systems: None, Es, Fr, Ru, Zh, AC1
with/without MERT. All entries marked with an as-
terisk are better than the None baseline with 95%
statistical significance computed using paired boot-
strap resampling (Koehn, 2004).
35 40 45 50 55 60 65 7037
37.5
38
38.5
39
39.5
40
40.5
None
Es
Fr
Ru
Zh
AC1
100?AER(%)
BLE
U(%
)
Figure 1: 100-AER (%) vs. BLEU(%) on the blind
set for 6 systems from Table 3.
Figure 1 shows the plot between 100-AER% (av-
erage of EA/AE directions) and BLEU for the six
systems in Table 3. We observe that AER is loosely
correlated to BLEU (? = 0.81) though the re-
lation is weak, as observed earlier by Fraser and
Marcu (2006a). Among the bridge languages, Span-
ish gives the lowest AER/highest BLEU while Chi-
nese results in highest AER/lowest BLEU. We can
conclude that Spanish is closest to Arabic/English
while Chinese is the farthest. All the bridge lan-
guages yield lower BLEU/higher AER relative to the
No-Bridge baseline. Therefore, our estimate of the
posterior probability (Equation 4) is always worse
than the posterior probability obtained using a di-
rect model. The alignment combination (AC1) be-
haves differently from other bridge systems in that it
gives a higher AER and a higher BLEU relative to
None baseline. We hypothesize that AC1 is differ-
ent from the bridge language systems since it arises
from a different process: interpolation with the di-
rect model (None).
Both system combination techniques give im-
provements relative to None baseline: alignment
combination AC1 gives a small gain (0.2 points)
while the consensus translation TC1 results in a
larger improvement (0.8 points). The last 4 rows
of the table show that the performance of the hy-
pothesis consensus steadily increases as systems get
added to the None baseline. This shows that while
bridge language systems are weaker than the di-
rect model, they can provide complementary sources
of evidence. To further validate this hypothesis,
we compute inter-system BLEU scores between
None/es and all the systems in Table 5. We observe
that the baseline (None) is very dissimilar from the
rest of the systems. We hypothesize that the baseline
system has an alignment derived from a real align-
ment model while the rest of the bridge systems are
derived using matrix multiplication. The low inter-
system BLEU scores show that the bridge systems
provide diverse hypotheses relative to the baseline
and therefore contribute to gains in consensus de-
coding.
Bridge Lang # Msents BLEU (%)
test blind
None 1.9 52.1 40.1
Es 1.9 51.7 39.8
Fr 1.9 51.2 39.5
Ru 1.9 50.4 38.7
Zh 1.9 48.4 37.1
AC1 1.9 52.1 40.3
Hypothesis Consensus
None 1.9 51.9 39.8
+Es 1.9 52.2 40.0
+Fr 1.9 52.4? 40.5?
+Ru 1.9 52.8? 40.7?
+Zh 1.9 52.6? 40.6?
+AC1 = TC1 1.9 53.0? 40.9?
Table 4: Translation Experiments for Set 1; Results
are reported on the test and blind set: (NIST portion
of 2006 NIST eval set).
Ref None es fr ru zh AC1
None 100.0 60.0 59.8 59.7 59.5 58.7
es 59.6 100.0 79.9 69.3 67.4 70.5
Table 5: Inter-system BLEU scores (%) between
None/es and all systems in Table 3.
To gain some insight about how the bridge sys-
tems help in Table 4, we present an example in Ta-
ble 6. The example shows the consensus Transla-
tions and the 12 input translations for the consensus
decoding. The example suggests that the inputs to
the consensus decoding exhibit diversity.
Table 7 reports the second and third sets of ex-
periments. For both sets, we first train each bridge
language system X using all aligned sentences avail-
47
System MERT Hypothesis
None N The President of the National Conference Visit Iraqi Kurdistan Iraqi
None Y President of the Iraqi National Conference of Iraqi Kurdistan Visit
Es N President of the Iraqi National Congress to Visit Iraqi Kurdistan
Es Y President of the Iraqi National Congress to Visit Iraqi Kurdistan
Fr N President of the Iraqi National Conference Visits Iraqi Kurdistan
Fr Y Chairman of the Iraqi National Conference Visits Iraqi Kurdistan
Ru N The Chairman of the Iraqi National Conference Visits Iraqi Kurdistan
Ru Y Chairman of the Iraqi National Conference Visit the Iraqi Kurdistan
Zh N The Chairman of the Iraqi National Conference Visits Iraqi Kurdistan
Zh Y The Chairman of the Iraqi National Conference Visit Iraqi Kurdistan
AC1 N President of the Iraqi National Congress to Visit Iraqi Kurdistan
AC1 Y Chairman of the Iraqi National Congress to Visit Iraqi Kurdistan
TC1 - The Chairman of the Iraqi National Conference Visits Iraqi Kurdistan
Ref - Head of Iraqi National Congress Visits Iraqi Kurdistan
Table 6: An example showing the Consensus Translation (TC1) and the 12 inputs for consensus decoding.
The final row shows the reference translation.
able in Ar, En and X. In Set 2, the first row (Union)
is an alignment model trained on all sentence-pairs
in Ar-En which are available in at least one bridge
language X. AC2 refers to alignment combination
using bridge languages Es/Fr/Ru and Union. TC2
refers to the translation combination from 12 sys-
tems: Es/Fr/Ru/Zh/Union/AC2 with/without Mini-
mum Error Rate training. Finally, the goal in Set 3
(last 3 rows) is to improve the best Arabic-English
system that can be built using all available sen-
tence pairs from the UN corpus. The first row
(Direct) gives the performance of this Ar-En sys-
tem; AC3 refers to alignment combination using
Es/Fr/Ru and Direct. TC3 merges translations from
Es/Fr/Ru/Zh/Direct/AC3. All entries marked with
an asterisk (plus) are better than the Union (Direct)
baseline with 95% statistical significance computed
using paired bootstrap resampling (Koehn, 2004).
The motivation behind Sets 2 and 3 is to train all
bridge language systems on as much bitext as possi-
ble. As a consequence, these systems give better re-
sults than the corresponding systems in Table 4. The
Union system outperforms None by 1.7/1.4 BLEU
points and provides a better baseline. We show un-
der this scenario that system combination techniques
AC2 and TC2 can still give smaller improvements
(0.3/0.5 and 1.0/0.7 points) relative to this baseline.
As mentioned earlier, our approach requires
sentence-aligned corpora. In our experiments, we
use a single sentence aligner for each language pair
(total of 9 aligners). Since these aligners make inde-
pendent decisions on sentence boundaries, we end
up with a smaller pool of sentences (1.9M) that is
common across all language pairs. In contrast, a
sentence aligner that makes simultaneous decisions
in multiple languages would result in a larger set of
common sentence pairs (close to 7M sentence pairs).
Simard (1999) describes a sentence aligner of this
type that improves alignment on a trilingual paral-
lel text. Since we do not currently have access to
such an aligner, we simulate that situation with Sets
2 and 3: AC2/AC3 do not insist that a sentence-pair
be present in all input word alignments. We note that
Set 2 is a data scenario that falls between Sets 1 and
3.
Set 3 provides the best baseline for Arabic-
English based on the UN data by training on
all parallel sentence-pairs. In this situation, sys-
tem combination with bridge languages (AC3/TC3)
gives reasonable improvements in BLEU on the test
set (0.4/1.0 points) but only modest improvements
(0.1/0.4 points) on the blind set. However, this does
show that the bridge systems continue to provide or-
thogonal evidence at different operating points.
6 Discussion
We have described a simple approach to improve
word alignments using bridge languages. This in-
cludes two components: a matrix multiplication to
assemble a posterior probability matrix for the de-
sired language-pair FE using a pair of posterior
probability matrices FG and GE relative to a bridge
language G. The second component is a recipe for
combining word alignment systems by linearly in-
48
Bridge Lang # Msents BLEU (%)
test blind
Es 4.7 53.7 40.9
Fr 4.7 53.2 40.7
Ru 4.5 52.4 39.9
Zh 3.4 49.7 37.9
Set 2
Union 7.2 53.8 41.5
AC2 7.2 54.1 42.0?
TC2 - 54.8? 42.2?
Set 3
Direct 7.0 53.9 42.2
AC3 9.0 54.3+ 42.3
TC3 - 54.9+ 42.6+
Table 7: Translation performance for Sets 2 and 3 on
test and blind:NIST portion of 2006 NIST eval set.
terpolating posterior probability matrices from dif-
ferent sources. In our case, these sources are multi-
ple bridge languages. However, this method is more
generally applicable for combining posterior matri-
ces from different alignment models such as HMM
and Model-4. Such an approach contrasts with the
log-linear HMM/Model-4 combination proposed by
Och and Ney (2003).
There has been recent work by Ayan and Dorr
(2006) on combining word alignments from differ-
ent alignment systems; this paper describes a maxi-
mum entropy framework for this combination. Their
approach operates at the level of the alignment links
and uses maximum entropy to decide whether or
not to include an alignment link in the final out-
put. In contrast, we use posterior probabilities as the
interface between different alignment models. An-
other difference is that this maxent framework re-
quires human word aligned data for training feature
weights. We do not require any human word aligned
data to train our combiner.
Another advantage of our approach is that it is
based on word alignment posterior probability ma-
trices that can be generated by any underlying align-
ment model. Therefore, this method can be used to
combine word alignments generated by fairly dis-
similar word alignment systems as long as the sys-
tems can produce posterior probabilities.
Bridge languages have been used by NLP re-
searchers as a means to induce translation lexicons
between distant languages without the need for par-
allel corpora (Schafer and Yarowsky, 2002; Mann
and Yarowsky, 2001). Our current approach differs
from these efforts in that we use bridge languages to
improve word alignment quality between sentence
pairs. Furthermore, we do not use linguistic insight
to identify bridge languages. In our framework, a
good bridge language is one that provides the best
translation performance using the posterior matrix
multiplication. Our experiments show that Spanish
is a better bridge language relative to Chinese for
Arabic-to-English translation. We speculate that if
our approach was carried out on a data set with hun-
dreds of languages, we might be able to automati-
cally identify language families.
A downside of our approach is the requirement
for exact sentence-aligned parallel data. Except for
a few corpora such as UN, European Parliament etc,
such a resource is hard to find. One solution is to cre-
ate such parallel data by automatic translation and
then retaining reliable translations by using confi-
dence metrics (Ueffing and Ney, 2005).
Our approach to using bridge languages is ex-
tremely simple. Despite its simplicity, the system
combination gives improvements in alignment and
translation performance. In future work, we will
consider several extensions to this framework that
lead to more powerful system combination strategies
using multiple bridge languages. We recall that the
present approach trains bridge systems (e.g. Arabic-
to-French, French-to-English) until the alignment
stage and then uses these for constructing Arabic-
to-English word alignment. An alternate scenario
would be to build phrase-based SMT systems for
Arabic-to-Spanish and Spanish-to-English, and then
obtain Arabic-to-English translation by first trans-
lating from Arabic into Spanish and then Spanish
into English. Such end-to-end bridge systems may
lead to an even more diverse pool of hypotheses that
could further improve system combination.
References
N. Ayan and B. Dorr. 2006. A maximum entropy
approach to combining word alignments. In HLT-
NAACL, New York, New York.
S. Bangalore, V. Murdock, and G. Riccardi. 2002. Boot-
strapping bilingual data using consensus translation
for a multilingual instant messaging system. In COL-
ING, Taipei, Taiwan.
L. Borin. 2000. You?ll take the high road and I?ll take the
49
low road: Using a third language to improve bilingual
word alignment. In COLING, pages 97?103, Saar-
brucken, Germany.
T. Brants, A. Popat, P. Xu, F. Och, and J. Dean. 2007.
Large language models in machine translation. In
EMNLP, Prague, Czech Republic.
P. F. Brown, S. A. Della Pietra, V. J. Della Pietra, and
R. L. Mercer. 1993. The mathematics of statistical
machine translation: Parameter estimation. Computa-
tional Linguistics, 19(2):263?311.
Y. Deng and W. Byrne. 2005. HMM word and
phrase alignment for statistical machine translation. In
EMNLP, Vancouver, Canada.
EU, 2005. European Parliament Proceedings.
http://www.europarl.europa.eu.
EU, 2007. JRC Acquis Corpus. http://langtech.jrc.it/JRC-
Acquis.html.
K. Filali and J. Bilmes. 2005. Leveraging multiple lan-
guages to improve statistical mt word alignments. In
IEEE Workshop on Automatic Speech Recognition and
Understanding, San Juan, Puerto Rico.
A. Fraser and D. Marcu. 2006a. Measuring word align-
ment quality for statistical machine translation. Tech-
nical Report ISI-TR-616, ISI/University of Southern
California.
A. Fraser and D. Marcu. 2006b. Semi-supervised train-
ing for statistical word alignment. In ACL, pages 769?
776, Sydney, Australia.
N. Ge. 2004. Improvements in word alignments. In
Presentation given at DARPA/TIDES workshop.
A. Ittycheriah and S. Roukos. 2005. A maximum en-
tropy word aligner for arabic-english machine transla-
tion. In EMNLP, Vancouver, Canada.
P. Koehn, 2003. European Parlia-
ment Proceedings, Sentence Aligned.
http://people.csail.mit.edu/koehn/publications/europarl/.
P. Koehn. 2004. Statistical significance tests for machine
translation evaluation. In EMNLP, Barcelona, Spain.
S. Kumar and W. Byrne. 2004. Minimum Bayes-risk
decoding for statistical machine translation. In HLT-
NAACL, pages 169?176, Boston, MA, USA.
W. Macherey and F. Och. 2007. An empirical study on
computing consensus translations from multiple ma-
chine translation systems. In EMNLP, Prague, Czech
Republic.
G. Mann and D. Yarowsky. 2001. Multipath translation
lexicon induction via bridge languages. In NAACL,
Pittsburgh, PA, USA.
J. Martin, R. Mihalcea, and T. Pedersen. 2005. Word
alignment for languages with scarce resources. In ACL
Workshop on Building and Using Parallel Texts, pages
65?74, Ann Arbor, MI, USA.
E. Matusov, R. Zens, and H. Ney. 2004. Symmetric word
alignments for statistical machine translation. InCOL-
ING, Geneva, Switzerland.
E. Matusov, N. Ueffing, and H. Ney. 2006. Computing
consensus translation from multiple machine transla-
tion systems using enhanced hypotheses alignment. In
EACL, Trento, Italy.
R. C. Moore. 2005. A discriminative framework for
bilingual word alignment. In EMNLP, Vancouver,
Canada.
F. Och and H. Ney. 2003. A systematic comparison of
various statistical alignment models. Computational
Linguistics, 29(1):19 ? 51.
F. Och and H. Ney. 2004. The alignment template ap-
proach to statistical machine translation. Computa-
tional Linguistics, 30(4):417 ? 449.
F. Och. 2003. Minimum error rate training in statistical
machine translation. In ACL, Sapporo, Japan.
P. Resnik, M. Olsen, and M. Diab. 1997. Creating a
parallel corpus from the book of 2000 tongues. In
Text Encoding Initiative 10th Anniversary User Con-
ference, Providence, RI, USA.
C. Schafer and D. Yarowsky. 2002. Inducing translation
lexicons via diverse similarity measures and bridge
languages. In CoNLL, Taipei, Taiwan.
K. C. Sim, W. J. Byrne, M. J. F. Gales, H. Sahbi, and P. C.
Woodland. 2007. Consensus network decoding for
statistical machine translation system combination. In
IEEE International Conference on Acoustics, Speech,
and Signal Processing, Honolulu, HI, USA.
M. Simard. 1999. Text translation alignment: Three lan-
guages are better than two. In EMNLP-VLC, College
Park, MD, USA.
N. Ueffing and H. Ney. 2005. Word-level confidence
estimation for machine translation using phrase-based
translation models. In EMNLP, pages 763 ? 770, Van-
couver, Canada.
UN, 2006. ODS UN Parallel Corpus. http://ods.un.org/.
S. Vogel, H. Ney, and C. Tillmann. 1996. HMM based
word alignment in statistical translation. In COLING,
pages 836?841, Copenhagen, Denmark.
50
