Proceedings of the Second ACL Workshop on Syntax and Structure in Statistical Translation (SSST-2), pages 1?9,
ACL-08: HLT, Columbus, Ohio, USA, June 2008. c?2008 Association for Computational Linguistics
Imposing Constraints from the Source Tree on ITG Constraints for SMT
Hirofumi Yamamoto?,??,??? Hideo Okuma?,??
?National Institute of Information and Communications Technology
/ 2-2-2 Hikaridai Seika-cho Soraku-gun Kyoto Japan
??ATR Spoken Language Communication Research Labs.
???Kinki University School of Sience and Engineering Department of Information
{hirofumi.yamamoto,hideo.okuma,eichiro.sumita}@nict.go.jp
Eiichiro Sumita?,??
Abstract
In current statistical machine translation
(SMT), erroneous word reordering is one of
the most serious problems. To resolve this
problem, many word-reordering constraint
techniques have been proposed. The inver-
sion transduction grammar (ITG) is one of
these constraints. In ITG constraints, target-
side word order is obtained by rotating nodes
of the source-side binary tree. In these node
rotations, the source binary tree instance is
not considered. Therefore, stronger con-
straints for word reordering can be obtained
by imposing further constraints derived from
the source tree on the ITG constraints. For
example, for the source word sequence { a
b c d }, ITG constraints allow a total of
twenty-two target word orderings. How-
ever, when the source binary tree instance ((a
b) (c d)) is given, our proposed ?imposing
source tree on ITG? (IST-ITG) constraints
allow only eight word orderings. The re-
duction in the number of word-order permu-
tations by our proposed stronger constraints
efficiently suppresses erroneous word order-
ings. In our experiments with IST-ITG using
the NIST MT08 English-to-Chinese transla-
tion track?s data, the proposed method re-
sulted in a 1.8-points improvement in char-
acter BLEU-4 (35.2 to 37.0) and a 6.2%
lower CER (74.1 to 67.9%) compared with
our baseline condition.
1 Introduction
Statistical methods are widely used for machine
translation. One of the popular statistical machine
translation paradigms is the phrase-based model
(PBSMT) (Marcu et al, 2002; Koehn et al, 2003;
Och et al, 2004). In PBSMT, errors in word re-
ordering, especially in global reordering, are one of
the most serious problems. Approaches used to re-
solve this problem are categorized into two types.
The first type is linguistically syntax-based. In this
approach, source (Quirk et al, 2005; Liu et al, 2006;
Huang et al, 2006), target (Yamada et al, 2000; Gal-
ley et al, 2006; Marcu et al, 2006), or both side
(Melamed 2004; Ding et al, 2005) tree structures
are used for model training. The second type is for-
mal constraints on word permutations. IBM con-
straints (Berger et al, 1996), lexical word reordering
model (Tillmann, 2004), and inversion transduction
grammar (ITG) constraints (Wu, 1995; Wu, 1997)
belong to this type of approach. Our approach is an
extension of ITG constraints and is a hybrid of the
first and second type of approach.
We propose ?imposing source tree on ITG? (IST-
ITG) constraints for directly introducing source sen-
tence structure into our set of constraints. In IST-
ITG, ITG constraints under the given source sen-
tence tree structure are used as stronger constraints
than the original ITG. For example, IST-ITG allows
only eight word orderings for a four-word sentence,
even though twenty-two word orderings are possible
with respect of in the original ITG constraints.
In Section 2, we present the proposed IST-ITG
for word-based translation. In Section 3, the pro-
posed method is extended to phrase-based transla-
tion. In Section 4, we present a real-time decoding
algorithm for IST-ITG constraints. In Section 5, we
give details of the experiments and present the re-
sults. Finally, in Section 6, we offer a summary and
some concluding remarks.
1
2 Imposing the Source Tree on ITG
Constraints
First, we introduce three previous studies on word
reordering constraints: IBM constraints; lexical re-
ordering model; and ITG constraints. Here, we con-
sider one-to-one word-aligned source and target lan-
guage sentence pairs as the simplest cases.
2.1 IBM constraints
In this constraint, a distortion penalty is given in ac-
cordance with the gap between the previously and
the currently translated words, which is represented
as the following equation.
pD = exp(?
?
i
di) (1)
where di for each i is defined as:
di = abs(position(ei?1) + 1 ? position(ei)) (2)
where ei represents the translated word from the ith
source word fi, position(w) represents the position
of the word w. Sometimes, a limit is set for di
for similar language pairs such as French and En-
glish. However, for dissimilar language pairs, such
as Japanese and English or Chinese and English,
limiting di is not beneficial.
2.2 Lexical Reordering Model
In the lexical reordering model, reordering proba-
bilities are assigned to each word pair {fi, ei}. Re-
ordering positions are categorized into three types,
monotone, swap, and discontinuous. The probabil-
ity is assigned to left and right sides as ps(t|fi, ei),
where, s is left (l) or right (r), t is monotone (m),
swap (s), or discontinuous (d). Therefore, a total of
six probabilities are assigned to each word pair. For
the source word sub-sequence fi?1, fi, probabilities
of target sub-sequences are calculated as follows:
? p(ei?1, ei) = pr(m|fi?1, ei?1)pl(m|fi, ei)
? p(ei, ei?1) = pr(s|fi?1, ei?1)pl(s|fi, ei)
? p(otherwise) = pr(d|fi?1, ei?1)pl(d|fi, ei)
2.3 ITG Constraints
In one-to-one word-alignment, the source word fi is
translated into the target word ei. The source sen-
tence [f1, f2, ..., fN ] is translated into a reordered
sequence of word [e1, e2, ..., eN ]. The number of re-
orderings is N !. When ITG is introduced, this com-
bination N ! can be reduced in accordance with the
following constraints.
? All possible binary tree structures are generated
from the source word sequence.
? The target sentence is obtained by rotating any
node of the binary trees.
When N = 4, the ITG constraints can re-
duce the number of combinations from 4! =
24 to 22 by rejecting combinations [e3, e1, e4, e2]
and [e2, e4, e1, e3]. For a 4-word sentence,
the search space is reduced to 92%(22/24), but
for 10-word sentence, the search space is only
6%(206,098/3,628,800) of the original full space.
2.4 Imposing Source Tree Constraints
In ITG constraints, the source-side binary tree
instance is not considered. Therefore, if the
source sentence binary tree is utilized, stronger
constraints than the original ITG can be created.
By parsing the source sentence, a parse tree is
obtained. After parsing, a bracketed sentence is
obtained by removing the node labels, and this
bracketed sentence can be converted to a binary
tree. For example, the parse tree, (S1 (S (NP (DT
This)) (VP (AUX is) (NP (DT a) (NN pen))))),
is obtained from the source sentence ?This is a
pen?. By removing the node labels, a bracketed
sentence ((This) ((is) ((a) (pen)))) is obtained. Such
a bracketed sentence (equivalent to a binary tree)
can be used to produce constraints. If IST-ITG is
applied, the number of word orderings in N = 4 is
reduced to 8, down from 22 with ITG. For example,
for the source-side bracketed tree ((f1 f2)(f3 f4)),
eight target sequences [e1, e2, e3, e4], [e2, e1, e3, e4],
[e1, e2, e4, e3], [e2, e1, e4, e3], [e3, e4, e1, e2],
[e3, e4, e2, e1], [e4, e3, e1, e2], and [e4, e3, e2, e1]
are accepted. For the source-side bracketed tree
(((f1 f2)f3)f4), eight sequences [e1, e2, e3, e4],
[e2, e1, e3, e4], [e3, e1, e2, e4], [e3, e1, e2, e4],
[e4, e1, e2, e3], [e4, e2, e1, e3], [e4, e3, e1, e2], and
2
[e4, e3, e2, e1] are accepted. Generally, the number
of word orderings is reduced to 2N?1. Table 1
shows the number of word orderings in a target
word sequence for each N with ITG, IST-ITG, and
no constraints.
Table 1: Number of word orderings in each type of
constraint
N IST-ITG ITG No Constraint
1 1 1 1
2 2 2 2
3 4 6 6
4 8 22 24
5 16 90 120
6 32 394 720
7 64 1806 5040
8 128 8558 40320
9 256 41586 362880
10 512 206098 3628800
15 16384 745387038 1307674368000
2.5 Extension to Non-binary Tree
In the above subsection, a source binary tree was as-
sumed in order to perform IST-ITG. However, pars-
ing results sometimes are not binary trees. In this
case, some tree nodes have more than two branches.
For a non-binary node, any reordering of branches is
allowed. In a non-binary tree (f1(f2 f3 f4)), twelve
target-side sequences [e1, e2, e3, e4], [e1, e2, e4, e3],
[e1, e3, e2, e4], [e1, e3, e4, e2], [e1, e4, e2, e3],
[e1, e4, e3, e2], [e2, e3, e4, e1], [e2, e4, e3, e1],
[e3, e2, e4, e1], [e3, e4, e2, e1], [e4, e2, e3, e1], and
[e4, e3, e2, e1] are allowed. For nodes that have more
than three branches, the original ITG constraints
are locally applied. Therefore, for a non-binary tree
(f1(f2 f3 f4 f5)), 22 ? 2 = 44 word orderings are
allowed in the target-side and represented by the
following formula.
n
?
i=1
(SBi) (3)
where Sk represents the number of combinations
from the original ITG constraints for N = k and Bi
represents the number of branches at the ith node.
3 IST-ITG in Phrase-based SMT
In the above section, we described each constraint
in the case of a one-to-one word-alignment. In this
section, we consider phrase-based models. When
a phrase-based model is used, each constraint must
be extended. For IBM constraints, equation (2) is
rewritten using phrase Pen instead of word en as
follows:
di = abs(last position(Pei?1) + 1
?first position(Pei)) (4)
where last position(Pen) represents the posi-
tion of the last word in nth phrase, and
first position(Pen) represents the position of the
first word in nth phrase. The lexical reordering
model and ITG constraints can be extended by
changing the model (or constraint) unit from ?word?
to ?phrase?. However, in IST-ITG, ?word? must be
used for the constraint unit since the parse (brack-
eted tree) unit is in ?words?. To absorb different
units between translation models and IST-ITG con-
straints, we investigated a new limitation for word
ordering as follows.
? Word ordering that destroys a phrase is not al-
lowed.
When this limitation is applied, the translated word
ordering is obtained from the bracketed source sen-
tence tree by reordering the nodes in the tree, the
same as for one-to-one word-alignment. According
to this limitation, the following nodes cannot be re-
ordered. If a sub-tree with root node X includes part
of a phrase ph, node X cannot be reordered. Con-
sider the source bracketed source tree ( ( ea eb ec )
( ( ed ee ) ( ef eg ) ) ), in which eb ec, and ed form
a phrase eph as in Figure 1. Node 1 cannot be re-
ordered since part of the phrase eb ec is included in
node 1?s sub-tree. For the same reason, node 2 and 4
cannot be reordered. Node 3 can be reordered since
the sub-tree does not include the phrase (target se-
quence [fafphfefgff ] is obtained by rotating node
3). Node 5 also can be reordered since it includes
the whole phrase (target sequence [fgfffefphfa] is
obtained by rotating node 5). If node 2 is reordered,
phrase ph is split into two parts, and translated in
two parts in the target sentence. It is inconsistent
3
with the condition that phrase-to-phrase alignment
is one-to-one. As a result, only the target sequences
[fafphfefffg], [fafphfefgff ], [fgfffefphfa], and
[fffgfefphfa] are allowed. Here, fph represents an
equivalent phrase in the translation for eph.
e e ee
1 2 3
5
e
e e
4
e
a ph e f g
b c d
Figure 1: Example sentence tree with a phrase
4 Decoding with IST-ITG Constraints
In this section, we describe a one-pass decoding
algorithm that uses IST-ITG constraints in the de-
coder. The translation target sentence is sequen-
tially generated from left (sentence head) to right
(sentence tail). To introduce the IST-ITG constraints
into a decoder, the target candidate must be checked
whether it satisfies the IST-ITG constraints or not
whenever a new phrase is selected to extend a target
candidate.
To explain this checking algorithm, we catego-
rized source sub-trees into four types UNTRANS-
LATED, TRANSLATED, TRANSLATING, and
NG (no good) as follows:
? If a sub-tree consists of only leaf word nodes,
and all leaf words are not yet translated, this
sub-tree is defined as UNTRANSLATED.
? If a sub-tree consists of only UNTRANS-
LATED sub-trees, this sub-tree is also UN-
TRANSLATED.
? If a sub-tree consists of only leaf word nodes,
and all leaf words are already translated, this
sub-tree is defined as TRANSLATED.
? If a sub-tree consists of only TRANSLATED
sub-trees, this sub-tree is also TRANSLATED.
? If a sub-tree consists of only leaf word nodes
with both translated and untranslated words,
this sub-tree is defined as TRANSLATING.
? If a sub-tree consists of both TRANSLATED
and UNTRANSLATED sub-trees, this sub-
tree is TRANSLATING.
? If a sub-tree includes only one TRANSLAT-
ING sub-tree and any number (including zero)
of TRANSLATED and UNTRANSLATED
sub-trees, this sub-tree is TRANSLATING.
? If a sub-tree includes more than one TRANS-
LATING sub-tree, this sub-tree is NG.
? If a sub-tree includes NG sub-tree, this sub-tree
is also NG.
If a translation candidate includes TRANSLAT-
ING sub-tree t, t must become TRANSLATED
before anything else can happen. Given sub-tree
((ab)c), a is translated, b and c are not yet trans-
lated. In this case, b must be translated before c.
If c is translated before b, the target word order be-
comes ACB. This word order does not satisfy the
IST-ITG constraints. For the same reason, a can-
didate that includes an NG sub-tree does not satisfy
the IST-ITG constraints. The checking algorithm for
IST-ITG constraints is as follows.
1. For old translation candidates, the smallest
TRANSLATING sub-tree t and its untrans-
lated part u are calculated.
2. When a new target phrase fph is generated, the
source phrase eph and untranslated part u cal-
culated in above step are compared. If eph does
not include and is not included in u, the new
candidate is rejected. For example, in Figure
1, only source word ea is already translated.
The smallest TRANSLATING sub-tree is 1
and its untranslated part u is [ebec]. In this case,
phrases containing [eb], [ec], or [ebec] are ac-
cepted since these are included in u. Phrases
[ebeced] or [ebecedee] are also accepted since
these include u.
3. If a new candidate includes NG sub-trees, this
candidate is rejected.
4
5 Experiments
5.1 Evaluation Measures
We evaluated the proposed method using four eval-
uation measures, BLEU (Papineni et al, 2002),
NIST (Doddington 2002), WER(word error rate),
and PER(position independent word error rate). Be-
fore discussing the evaluation, the characteristics of
each one are analyzed.
? BLEU: This evaluation measure takes
into account middle range word order,
but does not take into account global
word order. When the translation result is
[w1, w2, ..., wj?1, X,wj+1, ..., wn] for refer-
ence translation [w1, w2, ..., wn], both WER
and BLEU scores will be high. For a transla-
tion result [wj+1, ..., wn, X,w1, w2, ..., wj?1],
the BLEU score will be the same as the
previous result since BLEU only takes into
account 4grams. However, the WER score will
be zero since global word positions are taken
into account. Therefore, the effectiveness of
the proposed method using BLEU is less than
that of using WER.
? NIST: This evaluation measure only takes into
account n-grams like BLEU. However, impor-
tance of higher order n-grams are less than
BLEU. Therefore, the effectiveness of the pro-
posed method using NIST will be less than that
of using BLEU.
? WER: This evaluation measure takes into ac-
count not only local but also global word or-
der, and is the most suitable for evaluating our
method.
? PER: With this evaluation measure, we are
almost incapable of considering word order.
Therefore, our proposed method would seem to
offer no improvement in this evaluation mea-
sure.
5.2 English and Japanese Patent Corpus
Experiments
First, we conducted experiments on English and
Japanese patent translations. Details of the experi-
mental corpus are shown in Table 2. This corpus is
created by automatic sentence alignment (Uchiyama
2003). The first nine hundred sentence pairs with the
best alignment scores were used as the evaluation
data (single reference) and the next thousand sen-
tence pairs were used as the development data. This
corpus is a subset of the training corpus that will be
used in the NTCIR-7 Workshop patent translation
track.
Table 2: E-J patent corpus
# of sent. Total words # of entries
E/J Train 1.8M 60M/64M 188K/118K
E/J Dev 916 30K/32K 4,072/3,646
E/J Eval 899 29K/32K 3,967/3,682
5.2.1 English-to-Japanese Translation
The translation direction of the first experiment
was English-to-Japanese (E-J). For phrase-based
translation model training, we used the GIZA++
toolkit (Och et al, 2003). For language model train-
ing, the SRI language model tool kit (Stolcke 2002)
was used. The language model type was word 5-
gram smoothed by Kneser-Ney discounting (Kneser
1995). For tuning of decoder parameters, we con-
ducted minimum error training (Och 2003) with re-
spect to the BLEU score using 916 development
sentence pairs. For extraction of source sentence
tree structure, we used the Charniak parser (Char-
niak 2000). We used Chasen for segmentation of the
Japanese. The numbers of entries in the language
models were 0.1 M, 2.1 M, 4.3 M, 6.2 M, and 6.9 M
for 1, 2, 3, 4, and 5grams respectively. The number
of entries in the phrase-table was 76 M. For decod-
ing, we used an in-house decoder that is a close rel-
ative to the Moses decoder. The performance of this
decoder was configured to be the same as Moses.
Another conditions are the same as the default con-
ditions of Moses decoder.
In the previous work (Zens et al, 2003, 2004),
an IBM constraints and an ITG constraints are com-
pared. In these experiments, a lexical reordering
model, the proposed IST-ITC, and combinations of
these are added as comparison targets. The combi-
nation of constraints in these experiments is as fol-
lows.
5
1. Monotone: Monotone translation (no reorder-
ing).
2. No constraints: There were no constraints for
word reordering. Any word order was allowed
without penalty.
3. IBM: IBM constraints without distortion limit.
4. ITG: ITG constraints.
5. IBM+ITG: Both IBM and ITG constraints were
used at the same time.
6. IBM+LR: Both IBM constraints and lexical re-
ordering model.
7. IST: Only the proposed IST-ITC constraints.
8. IBM+IST: Both IBM and IST-ITC constraints.
9. IBM+LR+IST: IBM constraints, Lexical re-
ordering model, and IST-ITG constraints were
used at the same time.
Table 3 shows the following experimental results.
In comparing the original ITG constraints (ITG)
with the proposed IST-ITG (IST) method, the im-
provement in BLEU was 2.67 points, and in WER
was 5.39%. WER had the largest improvement, next
was BLEU. This particular improvement order was
the same as in the previous subsection. The large im-
provement of WER helped us confirm the effective-
ness of the proposed method for global word order-
ing. When IBM constraints were used at the same
time (IBM+ITG and IBM+IST), the BLEU score
improved by 1.57 points and WER improved by
4.63%. When the lexical reordering model was used
at the same time (IBM+LR and IBM+LR+IST),
BLEU improved by 1.03 points and WER improved
by 5.12%. The lexical reordering model fixed phrase
position for the monotone and swap categories, but
did not fix phrase position for the discontinuous cat-
egory. IST-ITG fixed phrase position for the dis-
continuous category, even though it did not assign
a probability. Combinations of the lexical reorder-
ing model and IST-ITG resulted in a better WER
than with both IBM+LR and IBM+IST since both
position and probability could be assigned for the
discontinuous category.
Table 3: Evaluation results in E-J patent translation
BLEU NIST WER PER
Monotone 24.91 6.95 79.97 42.02
No constraint 26.83 7.19 81.10 39.52
IBM 28.35 7.29 78.35 39.25
ITG 27.59 7.26 80.29 39.15
IBM+ITG 28.50 7.30 78.01 39.29
IBM+LR 31.17 7.50 76.30 38.61
IST 30.26 7.41 74.90 38.93
IBM+IST 30.07 7.41 73.38 39.05
IBM+LR+IST 32.20 7.61 71.18 38.15
5.2.2 Japanese-to-English Translation
Next, we conducted J-E translation experiments
using the same corpus. The numbers of entries in
the language models were 0.2 M, 3.1 M, 4.1 M, 5.7
M, and 5.9 M for 1, 2, 3, 4, and 5grams The im-
provement. The number of entries in the phrase-
table was 76 M. For parsing of Japanese, we used
the dependency structure analyzer CaboCha. From
the dependency structure, Japanese bracketed trees
were generated. The combination of constraints in
these experiments was the same as those of the E-J
translation experiments.
Table 4 shows the translation results of sentence
evaluation with the top five alignment scores. In
comparing the original ITG constraints (ITG) with
the proposed IST-ITG (IST), BLEU was improved
by 1.21 points, and by in 3.81% in WER. The
largest improvement was in WER, and BLEU had
the next largest. This particular improvement order
of these evaluation measures was the same as that
of the E-J translation experiments. When IBM con-
straints were used at the same time (IBM+ITG and
IBM+IST), there was no improvement in BLEU, but
WER improved by 3.89%. When the lexical reorder-
ing model was used at the same time (IBM+LR and
IBM+LR+IST), there was also no improvement in
BLEU, but WER improved by 4.47%. One pos-
sible reason for the small (or no) improvement in
BLEU is the lower parsing accuracy of Japanese
compared with that of the English. However, better
the WER figure indicates that using IST-ITC con-
straints leads to better word order. In the Appendix,
differences in the translation results for the first five
6
evaluation sentences between IBM+LR (Baseline:)
and IBM+LR+IST (Proposed:) are shown.
Table 4: Evaluation results in J-E patent translation
BLEU NIST WER PER
Monotone 26.29 7.25 76.42 40.85
No constraint 26.20 7.18 81.41 40.76
IBM 27.87 7.34 78.16 39.94
ITG 27.01 7.24 80.43 40.50
IBM+ITG 28.16 7.35 78.04 40.07
IBM+LR 29.93 7.54 77.27 39.12
IST 28.32 7.31 76.62 40.67
IBM+IST 28.14 7.32 74.13 40.40
IBM+LR+IST 29.77 7.50 72.80 39.73
5.3 NIST MT08 English-to-Chinese
Translation Experiments
Next, we conducted English-to-Chinese (E-C) news-
paper translation experiments for different language
pairs. The training and evaluation corpora were used
in the NIST MT08 evaluation campaign English-to-
Chinese translation track. For the translation model
training, we used 6.2M bilingual sentences. For the
language model training, we used 20.1M sentences.
A development set with 1,664 sentences was used
as evaluation data in the Chinese-to-English transla-
tion track in the NIST MT07 evaluation campaign.
A single reference was used in the development
set. The evaluation set with 1,859 sentences is the
same as MT08?s evaluation data, with 4 references.
Model training and decoding conditions were the
same as those in the E-J experiments. In both base-
line and proposed condition, IBM constraints and
lexical reordering model were used at the same time.
Therefore, the baseline conditions correspond to the
IBM+LR condition in the J-E experiments, the pro-
posed conditions correspond to the IBM+LR+IST in
the J-E experiments.
The evaluation unit was both the Chinese char-
acter and word as defined by the PKU corpus. As
in the E-J experiments, the improvements in WER
and CER (character error rate) were large. The im-
provements in WER, CER, word BLEU, and charac-
ter BLEU were 5.3% (from 75.0% to 69.7%), 6.2%
(from 74.1% to 67.9%), 2.2-points (from 21.0 to
23.2), and 1.8-points (from 35.2 to 37.0) respec-
tively. We again demonstrated that the proposed
method is effective (especially in WER) for multi-
ple language pairs.
6 Conclusion
We proposed new word reordering constraints for
PBSMT using source tree structure. The proposed
IST-ITG constraints are extensions of the ITG con-
straints. In ITG constraints, the instance of the
source-side tree is not taken into account. On the
other hand, in IST-ITG constraints, the tree that
is obtained by source sentence parsing is imposed
on the decoding process. Therefore, IST-ITG con-
straints are stronger than those of the original ITG.
For example, for four-word source sentences, IST-
ITG constraints allow eight word orderings in a tar-
get sentence compared with twenty-two orderings
under the original ITG constraints. IST-ITG con-
straints can be applied to a common decoder to de-
termine a target sentence from one-pass without re-
scoring. In our E-J patent translation experiments,
the proposed method resulted in a 2.7-point im-
provement in BLEU and a 5.7% improvement in
WER compared with those of the original ITG con-
straints. In this paper we have argued the WER is
the most appropriate measure to gauge the effective-
ness of our approach since it gives importance to the
global word order. Our approach gave rise to con-
siderable gains in term of WER in all of our experi-
ments, indicating that a respectable improvement in
global word order was achieved. The improvement
could clearly be seen from visual inspection of the
output, a few examples of which are presented in
the following Appendix.
A Samples from the Translation of
Japanese Patent into English
A.1 Sentence 1
Source:
 
	

	
fiffffifl !#"$&%'#()*+
,-.	 /ffi01*+
,
-2	&ff43.57698.:;)=<>,?;@A&BCEDF
Reference: and, the kinetic energy of the liquid filled
between the rotor 16 and stator 15 is converted into
thermal energy to thereby produce a brake torque.
Baseline: then, the rotor 16 and the kinetic energy is
converted to thermal energy braking torque is gener-
7
ated between the liquid filled in the stator 15.
Proposed: then, the rotor 16 and between the stator
15, the liquid filling the kinetic energy is converted
to thermal energy braking torque is generated.
A.2 Sentence 2
Source:  
,
	>;


, fiff
)fl,
ffi
  "! @$#%"& '	
&DF
Reference: a sealant 7, which serves as a seal for
cutting gas 9, also serves as a guide for the moving
holder 3.
Baseline: the seal and movement of the holder 3 also
serves as a guide for the seal member 7 is a work gas
9.
Proposed: 7 denotes a seal material, which also
serves as a guide for the working gas 9 described
later seal and movement of the holder 3.
A.3 Sentence 3
Source: (
ff *)+,-E/.*01E3245fi/768	
9 9(*:<;

2475 / 6	.D=@?>*@ 
A
 3BC7DE;2 F.?/G,H9IKJML 	N
ffOQP95SRSDEffi2 TD$UV1@$W2 XY2C
D9F
Reference: suppose that the red signal light of a traf-
fic signal installed at a crossing situated ahead is on,
the driver has recognized the red signal light, and
the driver ?s foot is about to shift from the accelera-
tor pedal to the brake pedal to stop the vehicle.
Baseline: next , the tread brake by the driver, the
accelerator to be stopped from the traffic of recog-
nizing traffic signals is ? red ? and the intersection
ahead of the vehicle is red, it is described as an ex-
ample.
Proposed: next, a case will be exemplified below so
as to tread brakes from the accelerator to be stopped,
and of recognizing traffic signals of red, the driver is
? red ? and is traffic light ahead of the vehicle.
A.4 Sentence 4
Source:
6I ffZ[\]1/^_ @K`ba'cd! 
[*eE/gfh ji CTSDEffK,*k*l Kmn*ofip<q
@$rs   <t<uSv	w<T2F
Reference: in addition, this method is not econom-
ical because it requires special steps such as pre-
washing of the substrate surface, pre-treatments for
providing the substrate with adherability to a coat-
ing, a drying step and the like.
Baseline: further, the coating film is apt to be de-
posited on the surface of the object to be coated by
washing and drying process is required, and the pre-
liminary process advance not economical.
Proposed: further, to clean the surface of the object
to be coated beforehand so as to facilitate the ad-
hesion of the coating film preprocessing and drying
process is required, and not economical.
A.5 Sentence 5
Source: xyz{
@}|  ~2%  '?3?g?@&K?
g?? 4D9F
Reference: an oil passage 4 is formed as a hollow
portion in the main body 1.
Baseline: 4 is a hollow portion of the body 1 with an
oil supply passage is shown.
Proposed: 4 is an oil supply passage, with a hollow
portion of the main body 1.
8
References
Adam L. Berger, Peter F. Brown, Stephen A. Della
Pietra, Vincent J. Della Pietra, Andrew S. Kehler, and
Robert L. Mercer, ?Language translation apparatus
and method of using context-based translation models,
? United States patent, patent number 5510981, April,
1996.
Cabocha
http://chasen.org/ taku/software/cabocha/
Eugene Charniak, ?A Maximum-Entropy-Inspired
Parser,? Proc. NAACL-2000, Seattle, Washington,
pp.132-139, 2000.
Chasen
http://chasen-legacy.sourceforge.jp/
Yuan Ding, Martha Palmer, ?Machine translation us-
ing probabilistic synchronous dependency insert gram-
mars,? Proc. ACL, Ann Arbor, pp. 541-548, 2005.
George Doddington, ?Automatic evaluation of machine
translation quality using n-gram co-occurrence statis-
tics,? Proc. ARPA Workshop on Human Language
Technology, San Diego, CA, 2002.
Michel Galley, Jonathan Graehl, Kevin Knight, Daniel
Marcu, Steve DeNeefe, Wei Wang, Ignacio Thayer,
?Scalable Inference and Training of Context-Rich
Syntactic Models,? Proc. ACL-COLING, Sydney Aus-
tralia, pp. 961-968, 2006.
Liang Huang, Kevin Knight, Aravind Joshi, ?Statistical
Syntax-Directed Translation with Extended Domain of
Locality,? Proc. AMTA, Massachusetts, 2006
Reinhard Kneser, Hermann Ney, ?Improved backing-
off for m-gram language model,? Proceedings of the
IEEE International Conference of Acoustic, Speech,
and Signal processing. Vol. 1, pp. 181-184, 1995.
Yang Liu, Qun Liu, Shouxun Lin, ?Tree-to-String Align-
ment Template for Statistical Machine Translation,?
Proc. ACL-COLING, Sydney Australia, pp. 609-616,
2006.
Daniel Marcu, William Wong, ?A phrase-based, joint
probability model for statistical machine translation,?
Proc. EMNLP-2002, Philadelphia, pp.133-139, 2002.
p. 127-133, 2003.
Daniel Marcu, Wei Wang, Abdessamad Echihabi, Kevin
Knight, ?SPMT: Statistical Machine Translation with
Syntactified Target Language Phrases,? Proc. EMNLP-
2006, Sydney Australia, pp. 44-52, 2006.
Dan Melamed, ?Statistical machine translation by pars-
ing, ?Proc. ACL, Barcelona, pp. 653-660, 2004.
Moses
http://www.statmt.org/moses/
NIST MT08
http://www.nist.gov/speech/tests/mt/2008/
NTCIR-7
http://ntcir.nii.ac.jp/
Franz Josef Och, Hermann Ney, ?A Systematic Compar-
ison of Various Statistical Alignment Models,? Com-
putational Linguistics, No. 1, Vol. 29, pp. 19-51, 2003.
Franz Josef Och, ?Minimum error rate training for statis-
tical machine trainslation,? Proc. ACL, Sapporo Japan,
pp. 160-167, 2003.
Franz Josef Och, Hermann Ney, ?The alignment template
approach to statistical machine translation, Computa-
tional Linguistics, 30(4), pp417-449, 2004.
Kishore Papineni, Salim Roukos, Todd Ward, Wei-Jing
Zhu, ?Bleu: a method for automatic evaluation of ma-
chine translation,? Proc. ACL, Philadelphia PA, pp.
311-318, 2002.
Chris Quirk, Arul Menezes, Colin Cherry, ?Dependency
treelet translation: Syntactically informed phrasal
SMT,? Proc. ACL, Ann Arbor, pp. 271-279, 2005.
Andreas Stolcke, ?SRILM - An Extensible Language
Model Toolkit,? Proc. ICSLP?02, Denver, pp. 901-904,
2002. http://www.speech.sri.com/projects/srilm/
Christopher Tillmann, ?A unigram orientation model for
statistical machine translation,? HLT-NAACL, Boston,
pp. 101-104, 2004.
Masao Uchiyama and Hitoshi Isahara, ?Reliable Mea-
sures for Aligning Japanese-English News Articles
and Sentences?, Proc. ACL, Sapporo Japan, pp. 72-79,
2003.
Dekai Wu, ?Stochastic inversion transduction grammars,
with application to segmentation, bracketing, and
alignment of parallel corpora,? In Proc. IJCAI, pp.
1328-1334, Montreal, 1995.
Dekai Wu, ?Stochastic inversion transuduction grammars
and bilingual parsing of parallel corpora,? Computa-
tional Linguiatics, 23(3), pp.377-403, 1997.
Kenji Yamada, Kevin Knight, ?A syntax-based statistical
translation model,? Proc. ACL, Hong Kong, pp. 523-
530, 2000.
Richard Zens, Hermann Ney, ?A Comparative Study on
Reordering Constraints in Statistical Machine Transla-
tion? Proc. ACL, Sapporo Japan, pp. 144-151, 2003.
Richard Zens, Hermann Ney, Taro Watanabe, Ei-
ichiro Sumita, ?Reordering Constraints for Phrase-
Based Statistical Machine Translation? Proc. Coling,
Geneva, pp. 205-211, 2004.
9
