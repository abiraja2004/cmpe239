Coling 2008: Companion volume ? Posters and Demonstrations, pages 99?102
Manchester, August 2008
On the weak generative capacity of weighted context-free grammars?
Anders S?gaard
University of Potsdam
soegaard@ling.uni-potsdam.de
Abstract
It is shown how weighted context-free
grammars can be used to recognize lan-
guages beyond their weak generative ca-
pacity by a one-step constant time exten-
sion of standard recognition algorithms.
1 Introduction
Weighted context-free grammars (WCFGs) are
used to disambiguate strings and thus filter out
subsets of the tree languages of the underlying
context-free grammars (CFGs). Weights can ei-
ther be used as probabilities, i.e. higher weights are
preferred, or as penalities, i.e. lower weights are
preferred. The first convention, also followed by
Smith and Johnson (2007), is followed here. The
subsets of the tree languages that consist of the
heaviest tree for each yield are called the Viterbi
tree languages. String languages are the yields of
tree languages, and Viterbi string languages are the
yields of Viterbi tree languages.
Infante-Lopez and de Rijke (2006) show that the
Viterbi tree languages strictly extend the tree lan-
guages.
The idea explored in this paper is simple. If
trees must have particular weights for their yields
to be recognized, weights can be used to en-
code non-local dependencies. Technically, the
{r
1
, . . . , r
n
}-language is defined as all the strings
for which the heaviest, i.e. most probable, tree
has weight r
i
? {r
1
, . . . , r
n
}. It is shown that
this class of languages includes common classes
?Thanks to Mark Hopkins, Daniel Quernheim and the
anonymous reviewers for helpful comments.
?c
? 2008. Licensed under the Creative Commons
Attribution-Noncommercial-Share Alike 3.0 Unported li-
cense (http://creativecommons.org/licenses/by-nc-sa/3.0/).
Some rights reserved.
of context-sensitive languages. In other words,
standard Viterbi-style recognition algorithms for
WCFGs can be used to recognize these classes
by a one-step look-up that checks if the weight
of the heaviest tree is in {r
1
, . . . , r
n
}. We
say that {r
1
, . . . , r
n
}-languages are {r
1
, . . . , r
n
}-
recognized.
Sect. 1.1 presents formal preliminaries and a
Viterbi-style recognition algorithm for WCFGs.
Note that for simplicity we restrict weights to be
rational numbers.
Sect. 2 defines {r
1
, . . . , r
n
}-languages and
presents some examples of WCFGs that
{r
1
, . . . , r
n
}-recognize context-sensitive lan-
guages. Sect. 3 gives a rough characterization of
the class of languages that can be {r
1
, . . . , r
n
}-
recognized by WCFGs.
Cortes and Mohri (2000) introduced a simi-
lar idea in the context of weighted finite-state
automata (WFSAs) and showed that WFSAs
can be used to {r
1
, . . . , r
n
}-recognize context-
free languages. Their results are extended in
Sect. 4. It is shown that WFSAs can also be
used to {r
1
, . . . , r
n
}-recognize context-sensitive
languages. It is shown, however, that the non-
context-free languages that can be {r
1
, . . . , r
n
}-
recognized by WCFGs strictly extend the non-
context-free languages that can be {r
1
, . . . , r
n
}-
recognized by WFSAs.
Sect. 5 discusses a more exact characterization
of the weak generative capacity of WCFGs in this
view. Coprime WCFGs (CWCFGs), i.e. a subclass
of WCFGs where the weights can be partitioned
into reciprocal coprimes, are introduced. It is con-
jectured that the infinite hierarchy of k-CWCFGs
is non-collapsing, and the classes of languages that
can be {r
1
, . . . , r
n
}-recognized by k-CWCFGs are
characterized in terms of an untraditional modifi-
99
cation of indexed grammars.
1.1 Preliminaries
A CFG is a 4-tuple G = ?N,T, P, S? where N,T
are finite and disjoint sets of nonterminal and ter-
minal symbols, P a finite set of production rules of
the form A? ? where A ? N and ? ? (N ?T )?,
and S ? N is the start symbol. A WCFG is a
2-tuple G? = ?G,?? where G = ?N,T, P, S?
is a CFG and ? : P ? {m
n
| m ? Z
+
, n ?
Z
+
,m, n 6= 0} a (total) weight function.
A left-most derivation t(?) for some CFG G =
?N,T, P, S? is a sequence of production rules
?p
1
, . . . , p
m
? with 1 ? i ? m : p
i
? P such
that
S
p
1
=? ?
1
. . . ?
m?1
p
m
=? ?
? is called the yield of t(?). The tree language
T (G) is the set of all left-most derivations licensed
by the production rules of G. The string language
of G is the set of yields:
L(G) = {? | t(?) ? T (G)}
The accumulated weight of a derivation of a
string ? ?(t(?)) is the product of the weight of all
the productions in t(?). The Viterbi tree language
of a WCFG then is:
V (G) = {t(?) | t(?) ? arg max
t
?
(?)?T (G)
(?(t
?
(?)))}
A simple Viterbi recognition algorithm for
WCFGs is presented in Figure 1 for further ref-
erence.
2 Our extension
For a set of n many rational numbers {r
1
, . . . , r
n
},
the language that is {r
1
, . . . , r
n
}-recognized by
the WCFG G, L
{r
1
,...,r
n
}
(G), is defined:
L
{r
1
,...,r
n
}
(G) = {? | t(?) ? V (G), ?(t(?)) ?
{r
1
, . . . , r
n
}}
Call the class of all languages that can be
{r
1
, . . . , r
n
}-recognized by a WCFG for all fi-
nite and non-empty sets of rational numbers
{r
1
, . . . , r
n
} for balanced weighted context-free
languages (BWCFLs). In all our examples
{r
1
, . . . , r
n
} will be a singleton set.
Note that all there is needed to do to recognize
the BWCFLs is to change line 7 of the Viterbi al-
gorithm in Figure 1 to:
if (S, r
i
) ? t(0, n), r
i
? {r
1
, . . . , r
n
} then . . .
3 Bounds on weak generative capacity
The first result of this paper is the following:
Theorem 3.1. The BWCFLs strictly extend the
context-free languages.
Proof. It is not difficult to see that any context-free
language is a BWCFL. Simply construct a WCFG
G = ?G
?
, ?? for any CFG G? = ?N,T, P, S?
such that the weight associated with each produc-
tion rule in P is 1
1
. It then holds that L
{
1
1
}
(G) =
L(G
?
).
The other direction is not very difficult either.
It is shown that {anbncn | n ? 0}, which
is non-context-free by the Bar-Hillel lemma, is
a BWCFL. The language is, for instance, the
set of strings L
{
1
1
}
(G) for the WCFG G =
??{S, S
?
}, {a, b, c}, P, S?, ?? where P is the fol-
lowing set of production rules, and ? assigns the
weights in the left column to the items in the right
column:
1
2
: S ? Sc
2
1
: S ? S?
2
1
: S? ? aS?b
1
2
: S? ? ?
L
{
1
1
}
= {a
n
b
n
c
n
| n ? 0}. Some example
derivations are presented in Example 3.2.
Example 3.2. Consider the only and thus heaviest
tree for abc, resp. ab:
S
Q
Q


S
S?
b
b
"
"
a S?
?
b
c
S
S?
b
b
"
"
a S?
?
b
The weight of the left tree, whose yield is abc,
is 1
1
. The weight of the left tree is 2
1
.
Consider also the {1
1
}-language of G =
?{S,D, T, T
?
}, {a, b, c, d}, P, S? with production
rules P :
1
1
: S ? TD
1
2
: D ? dD
1
1
: D ? ?
1
1
: T ? aTc
1
1
: T ? T?
2
1
: T? ? bT?
1
1
: T? ? ?
100
BUILD(t, [w
1
. . . w
n
])
1 for j ? 1 to n
2 do t(j ? 1, j)? {(A,?) | A? w
j
? P, log(?(A? w
j
)) = ?}
3 for k ? (j ? 1) to 0
4 do t(k, j)? {(A,? + ?) | A? B ? P, log(?(A? B)) = ?,
(B,?) ? t(k, j), if (A,?
?
) ? t(k, j) then ? > ?
?
}
5 for i? (j ? 2) to 0
6 do t(i, j)? {(A,? + ? + ?) | A? BC ? P, log(?(A? BC)) = ?,
?k.(B,?) ? t(i, k), (C, ?) ? t(k, j), if (A,?
?
) ? t(i, j) then ? > ?
?
}
7 if (S, r
i
) ? t(0, n) then return success else failure
Figure 1: A Viterbi recognition algorithm for WCFGs
It should be relatively easy to see that L(G) =
{a
n
b
m
c
n
d
m
| n ? 0}.
It is not difficult to see that the BWCFLs are
a subset of the context-sensitive languages. This
follows from the fact that the left-most derivations
in the Viterbi tree languages of WCFGs are linear
in the length of the input string; in other words,
BWCFLs can be recognized in nondeterministic
linear space and thus by a linear bounded automa-
ton. Since any language that can be represented by
a linear bounded automaton is context-sensitive,
the BWCFLs must be a subset of the context-
sensitive ones.
The set of BWCFLs is also a subset of the range
concatenation languages (Boullier, 1998) by the
observation made in the introduction that they can
be recognized in polynomial (i.e. cubic) time by
standard algorithms and a one-step inspection of
the weight of the heaviest tree; and by the fact
that the range concatenation languages are exactly
the languages that can be recognized in polynomial
time (Boullier, 1998).
4 Weighted finite-state automata
Cortes and Mohri (2000) showed, in similar work,
that WFSAs can be used to recognize context-free,
i.e. non-regular, languages.
Example 4.1. The weighted finite-state automa-
ton T = ?{q
0
, q
1
}, {a, b}, ?, q
0
, {q
1
}? with the fol-
lowing ?-transitions {1
1
}-recognizes the language
L
{
1
1
}
(T ) = {a
n
b
n
| n ? 0}:
1
2
: ?(q
0
, a) = q
0
1
1
: ?(q
0
, ?) = q
1
2
1
: ?(q
1
, b) = q
1
It is not difficult to see that the strings
ab, aabb, . . . have derivations with weights 1
1
,
whereas the string aab, for example, only has a
derivation with weight 1
2
. Since 1
2
/? {
1
1
}, aab /?
L
{
1
1
}
(T ).
Cortes and Mohri (2000) also formulated an ex-
tension of WFSAs over cross-products of semi-
rings that recognized certain context-sensitive,
i.e. non-context-free languages, but their results
can be considerably extended. The automaton
in Example 4.2, for example, even recognizes a
language conjectured to be outside the linear in-
dexed languages, namely the MIX language (Gaz-
dar, 1988).
Example 4.2. The weighted finite-state automa-
ton T = ?{q
0
, q
1
, q
2
, q
3
}, {a, b, c}, ?, q
0
, {q
0
}?
with the following ?-transitions {1
1
}-recognizes
the MIX language:
1
8
: ?(q
0
, a) = q
1
1
8
: ?(q
1
, a) = q
2
1
8
: ?(q
2
, a) = q
3
1
125
: ?(q
0
, b) = q
1
1
125
: ?(q
1
, b) = q
2
1
125
: ?(q
2
, b) = q
3
1
729
: ?(q
0
, c) = q
1
1
729
: ?(q
1
, c) = q
2
1
729
: ?(q
2
, c) = q
3
90
3
1
: ?(q
3
, ?) = q
0
This example is a bit more complicated. Note
that 8 ? 125 ? 729 = 903. The strings
cab, bcabac, . . . have derivations with weights 1
1
,
since 903
8?125?729
=
1
1
, whereas the string cababa,
for instance, has no derivations with weight 1
1
. The
string cababa has exactly one derivation whose
weight is 903
8
2
?125
.
5 Coprime WCFGs
A 2-CWCFG is a WCFG over subsets of the ratio-
nal numbers C = { 1
n
| n ? ?} ? {
n
1
| n ? ?}
101
B. (2000) WCFGs
{a
n
1
. . . a
n
k
| n ? 0} X X
MIX X X
{a
n
b
m
c
n
d
m
| m,n ? 0} X X
{wcw | w ? {a, b}
?
} X X
Figure 2: Classes of languages {r
1
, . . . , r
n
}-
recognized by WCFGs and recognized by the ex-
tension in Boullier (2000).
where ? is an arbitrary set of coprimes (? ? N?)
such that there is a bijection from the production
rules onto themselves such that if a production rule
has weight 1
1
it is projected onto itself, and oth-
erwise, i.e. if it has weight 1
m
with m 6= 1 it is
projected onto a production rule with weight m
1
.
A k-CWCFG for k ? 1 is now the extension of
CWCFG where the sets of production rules the
product of whose weights is 1, can be of size at
most k, e.g. the WFSA in Example 4.2 is a 3-
CWCFG.
The infinite hierarchy of k-CWCFGs seems to
be non-collapsing. A k-CWCFG {r
1
, . . . , r
n
}-
recognizes the language {an
1
. . . a
n
2k
| n ? 0}, but
not {an
1
. . . a
n
2k+1
| n ? 0}. It has this property
in common with k-multiple context-free grammars
(Seki et al, 1991). 2-CWCFG can be shown to be
weakly equivalent with the extension of linear in-
dexed grammars (LIGs) (Gazdar, 1988) where the
stack is a multiset or a bag that is globally accessi-
ble and not just along spines. The universal recog-
nition problem for this extension of LIGs can be
shown to be NP-complete by reduction of the ver-
tex cover problem, similar to S?gaard et al (2007).
The generalization to k-CWCFG requires stacks of
stacks, but is otherwise relatively straight-forward.
6 Conclusions
It was shown how weighted context-free grammars
can be used to recognize languages beyond their
weak generative capacity by a one-step constant
time extension of standard recognition algorithms.
The class of languages that can be recognized this
way strictly extends the context-free languages,
but is included in the cubic time recognizable ones.
Boullier (2000) defines what he calls a ?cu-
bic time extension of CFG? that recognizes gen-
eralizations of the copy language that are beyond
WCFG. It remains to be seen if the set of BWCFLs
is a strict subset of the set of languages that can be
recognized by this formalism. They all recognize
the classes of languages in Figure 2.
References
Boullier, Pierre. 1998. Proposal for a natural language
processing syntactic backbone. Technical report, IN-
RIA, Le Chesnay, France.
Boullier, Pierre. 2000. A cubic time extension of
context-free grammars. Grammars, 3(2?3):111?
131.
Cortes, Corinna and Mehryar Mohri. 2000. Context-
free recognition with weighted automata. Gram-
mars, 3(2?3):133?150.
Gazdar, Gerald. 1988. Applicability of indexed gram-
mars to natural languages. In Reyle, Uwe and Chris-
tian Rohrer, editors, Natural language parsing and
linguistic theories, pages 69?94. Reidel, Dordrecht,
the Netherlands.
Infante-Lopez, Gabriel and Maarten de Rijke. 2006. A
note on the expressive power of probabilistic context
free grammars. Journal of Logic, Language and In-
formation, 15(3):219?231.
Seki, Hiroyuki, Takashi Matsumura, Mamoru Fujii,
and Tadao Kasami. 1991. On multiple context-
free grammars. Theoretical Computer Science,
88(2):191?229.
Smith, Noah and Mark Johnson. 2007. Weighted
and probabilistic context-free grammars are equally
expressive. Computational Linguistics, 33(4):477?
491.
S?gaard, Anders, Timm Lichte, and Wolfgang Maier.
2007. On the complexity of linguistically motivated
extensions of tree-adjoining grammar. In Proceed-
ings of Recent Advances in Natural Language Pro-
cessing 2007, Borovets, Bulgaria.
102
