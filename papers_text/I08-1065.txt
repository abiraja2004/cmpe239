Acquiring Event Relation Knowledge by Learning Cooccurrence Patterns
and Fertilizing Cooccurrence Samples with Verbal Nouns
Shuya Abe Kentaro Inui Yuji Matsumoto
Graduate School of Information Science,
Nara Institute of Science and Technology
{shuya-a,inui,matsu}@is.naist.jp
Abstract
Aiming at acquiring semantic relations be-
tween events from a large corpus, this paper
proposes several extensions to a state-of-the-
art method originally designed for entity re-
lation extraction, reporting on the present re-
sults of our experiments on a Japanese Web
corpus. The results show that (a) there are
indeed specific cooccurrence patterns use-
ful for event relation acquisition, (b) the
use of cooccurrence samples involving ver-
bal nouns has positive impacts on both re-
call and precision, and (c) over five thou-
sand relation instances are acquired from a
500M-sentence Web corpus with a precision
of about 66% for action-effect relations.
1 Introduction
The growing interest in practical NLP applications
such as question answering, information extraction
and multi-document summarization places increas-
ing demands on the processing of relations between
textual fragments such as entailment and causal rela-
tions. Such applications often need to rely on a large
amount of lexical semantic knowledge. For exam-
ple, a causal (and entailment) relation holds between
the verb phrases wash something and something is
clean, which reflects the commonsense notion that if
someone has washed something, this object is clean
as a result of the washing event. A crucial issue is
how to obtain and maintain a potentially huge col-
lection of such event relations instances.
Motivated by this background, several research
groups have reported their experiments on automatic
acquisition of causal, temporal and entailment re-
lations between event mentions (typically verbs or
verb phrases) (Lin and Pantel, 2001; Inui et al,
2003; Chklovski and Pantel, 2005; Torisawa, 2006;
Pekar, 2006; Zanzotto et al, 2006, etc.). The com-
mon idea behind them is to use a small number of
manually selected generic lexico-syntactic cooccur-
rence patterns (LSPs or simply patterns). to Verb-X
and then Verb-Y, for example, is used to obtain tem-
poral relations such as marry and divorce (Chklovski
and Pantel, 2005). The use of such generic patterns,
however, tends to be high recall but low precision,
which requires an additional component for pruning
extracted relations. This issue has been addressed in
basically two approaches, either by devising heuris-
tic statistical scores (Chklovski and Pantel, 2005;
Torisawa, 2006; Zanzotto et al, 2006) or training
classifiers for disambiguation with heavy supervi-
sion (Inui et al, 2003).
This paper explores a third way for enhancing
present LSP-based methods for event relation acqui-
sition. The basic idea is inspired by the following
recent findings in relation extraction (Ravichandran
and Hovy, 2002; Pantel and Pennacchiotti, 2006,
etc.), which aims at extracting semantic relations be-
tween entities (as opposed to events) from texts. (a)
The use of generic patterns tends to be high recall
but low precision, which requires an additional com-
ponent for pruning. (b) On the other hand, there are
specific patterns that are highly reliable but they are
much less frequent than generic patterns and each
makes only a small contribution to recall. (c) Com-
bining a few generic patters with a much larger col-
lection of reliable specific patterns boosts both pre-
497
cision and recall. Such specific patterns can be ac-
quired from a very large corpus with seeds.
Given these insights, an intriguing question is
whether the same story applies to event relation ac-
quisition as well or not. In this paper, we explore this
issue through the following steps. First, while previ-
ous methods use only verb-verb cooccurrences, we
use cooccurrences between verbal nouns and verbs
such as cannot ?find out (something)? due to the
lack of ?investigation? as well as verb-verb cooc-
currences. This extension dramatically enlarge the
pool of potential candidate LSPs (Section 4.1). Sec-
ond, we extend Pantel and Pennacchiotti (2006)?s
Espresso algorithm, which induces specific reliable
LSPs in a bootstrapping manner for entity relation
extraction, so that the extended algorithm can apply
to event relations (Sections 4.2 to 4.4). Third, we
report on the present results of our empirical experi-
ments, where the extended algorithm is applied to a
Japanese 500M-sentence Web corpus to acquire two
types of event relations, action-effect and action-
means relations (Section 5)
2 Related work
Perhaps a simplest way of using LSPs for event rela-
tion acquisition can be seen in the method Chklovski
and Pantel (2005) employ to develop VerbOcean.
Their method uses a small number of manually se-
lected generic LSPs such as to Verb-X and then Verb-
Y to obtain six types of semantic relations including
strength (e.g. taint ? poison) and happens-before
(e.g. marry ? divorce) and obtain about 29,000 verb
pairs with 65.5% precision.
One way for pruning extracted relations is to in-
corporate a classifier trained with supervision. Inui
et al (2003), for example, use a Japanese generic
causal connective marker tame (because) and a su-
pervised classifier learner to separately obtain four
types of causal relations: cause, precondition, effect
and means.
Torisawa (2006), on the other hand, acquires en-
tailment relations by combining the verb pairs ex-
tracted with a highly generic connective pattern
Verb-X and Verb-Y together with the cooccurrence
statistics between verbs and their arguments. While
the results Torisawa reports look promising, it is not
clear yet if the method applies to other types of rela-
tions because it relies on relation-specific heuristics.
Another direction from (Chklovski and Pantel,
2005) is in the use of LSPs involving nominalized
verbs. Zanzotto et al (2006) obtain, for example, an
entailment relation X wins ? X plays from such a
pattern as player wins. However, their way of using
nominalized verbs is highly limited compared with
our way of using verbal nouns.
3 Espresso
This section overviews Pantel and Pennacchiotti
(2006)?s Espresso algorithm. Espresso takes as input
a small number of seed instances of a given target
relation and iteratively learns cooccurrence patterns
and relation instances in a bootstrapping manner.
Ranking cooccurrence patterns For each given
relation instance {x, y}, Espresso retrieves the sen-
tences including both x and y from a corpus and
extracts from them cooccurrence samples. For ex-
ample, given an instance of the is-a relation such
as ?Italy,country?, Espresso may find cooccurrence
samples such as countries such as Italy and extract
such a pattern as Y such as X. Espresso defines the
reliability rpi(p) of pattern p as the average strength
of its association with each relation instance i in
the current instance set I , where each instance i is
weighted by its reliability r?(i):
rpi(p) = 1|I|
?
i?I
pmi(i, p)
max pmi ? r?(i) (1)
where pmi(i, p) is the pointwise mutual information
between i and p, and maxpmi is the maximum PMI
between all patterns and all instances.
Ranking relation instances Intuitively, a reliable
relation instance is one that is highly associated with
multiple reliable patterns. Hence, analogously to the
above pattern reliability measure, Espresso defines
the reliability r?(i) of instance i as:
r?(i) = 1|P |
?
p?P
pmi(i, p)
max pmi ? rpi(p) (2)
where rpi(p) is the reliability of pattern p, defined
above in (1), and maxpmi is as before. r?(i) and
rpi(p) are recursively defined, where r?(i) = 1 for
each manually supplied seed instance i1.
1For our extension, r?(i) = ?1 for each manually supplied
negative instance.
498
4 Event relation acquisition
Our primary concerns are whether there are in-
deed specific cooccurrence patterns useful for ac-
quiring event relations and whether such patterns
can be found in a bootstrapping manner analogous to
Espresso. To address these issues, we make several
extensions to Espresso, which is originally designed
for entity relations (not scoping event relations).
4.1 Cooccurences with verbal nouns
Most previous methods for event relation acquisition
rely on verb-verb cooccurrences because verbs (or
verb phrases) are the most typical device for refer-
ring to events. However, languages have another
large class of words for event reference, namely
verbal nouns or nominalized forms of verbs. In
Japanese, for example, verbal nouns such as kenkyu
(research) constitute the largest morphological cate-
gory used for event reference.
Japanese verbal nouns have dual statuses, as verbs
and nouns. When occurring with the verb suru (do-
PRES), verbal nouns function as a verb as in (1a).
On the other hand, when accompanied by case mark-
ers such as ga (NOMINATIVE) and o (ACCUSATIVE),
they function as a noun as in (1b). Finally, but even
more importantly, when accompanied by a large va-
riety of suffixes, verbal nouns constitute compound
nouns highly productively as in (1c).
(1) a. Ken-ga gengo-o kenkyu-suru
Ken-NOM language-ACC research-PRES
Ken researches on language.
b. Ken-ga gengo-no kenkyu-o yame-ta
Ken-NOM language-on research-ACC quit-PAST
Ken quitted research on language.
c. -sha (person):
e.g. kenkyu-sha (researcher)
-shitsu (place):
e.g. kenkyu-shitsu (laboratory)
-go (after):
e.g. kenkyu-go (after research)
These characteristics of verbal nouns can be made
use of to substantially increase both cooccurrence
instances and candidate cooccurrence patterns (see
Section 5.1 for statistics). For example, the verbal
noun kenkyu (research) often cooccurs with the verb
jikken (experiment) in the pattern of (2a). From
those cooccurrences, one may learn that jikken-suru
(to experiment) is an action that is often taken as a
part of kenkyu-suru (to research). In such a case, we
may consider a pattern as shown in (2b) useful for
acquiring part-of relations between actions.
(2) a. kenkyu-shitsu-de jikken-suru
research-place-in experiment-VERB
conduct experiments in the laboratory
b. (Act-X)-shitsu-de (Act-Y)-suru
(Act-X)-place-in (Act-X)-VERB
(Act-Y) is often done in doing (Act-X)
When functioning as a noun, verbal nouns are po-
tentially ambiguous between the event reading and
the entity/object reading. For example, the ver-
bal noun denwa (phone) in the context denwa-de
(phone-by) may refer to either a phone-call event
or a physical phone. While, ideally, such event-
hood ambiguities should be resolved before collect-
ing cooccurrence samples with verbal nouns, we
simply use all the occurrences of verbal nouns in
collecting cooccurrences in our experiments. It is
an interesting issue for future work whether event-
hood determination would have a strong impact on
the performance of event relation extraction.
4.2 Selection of arguments
One major step from the extraction of entity rela-
tions to the extraction of event relations is how to
address the issue of generalization. In entity rela-
tion extraction, relations are typically assumed to
hold between chunks like named entities or simply
between one-word terms, where the issue of deter-
mining the appropriate level of the generality of ex-
tracted relations has not been salient. In event rela-
tion extraction, on the other hand, this issue imme-
diately arises. For example, the cooccurrence sam-
ple in (3) suggests the action-effect relation between
niku-o yaku (grill the meat) and (niku-ni) kogeme-ga
tsuku ((the meat) gets brown)2.
(3) ( kogeme-ga tsuku ) -kurai niku-o yaku
a burn-NOM get -so that meat-ACC grill
grill the meat so that it gets brown
(grill the meat to a deep brown)
In this relation, the argument niku (meat) of the
verb yaku (grill) can be dropped and generalized
2The parenthesis in the first row of (3) indicates a subordi-
nate clause.
499
to something to grill; namely the action-effect rela-
tion still holds between X-o yaku (grill X) and X-ni
kogeme-ga tsuku (X gets brown). On the other hand,
however, the argument kogeme (a burn) of the verb
tsuku (get) cannot be dropped; otherwise, the rela-
tion would no longer hold.
One straightforward way to address this problem
is to expand each cooccurrence sample to those cor-
responding to different degrees of generalization and
feed them to the relation extraction model so that its
scoring function can select appropriate event pairs
from expanded samples. For example, cooccurrence
sample (3) is expanded to those as in (4):
(4) a. ( kogeme-ga tsuku ) -kurai niku-o yaku
a burn-NOM get -so that meat-ACC grill
b. ( tsuku ) -kurai niku-o yaku
get -so that meat-ACC grill
c. ( kogeme-ga tsuku ) -kurai yaku
a burn-NOM get -so that grill
d. ( tsuku ) -kurai yaku
get -so that grill
In practice, in our experiments (Section 5), we re-
strict the number of arguments for each event up to
one to avoid the explosion of the types of infrequent
candidate relation instances.
4.3 Volitionality of events
Inui et al (2003) discuss how causal rela-
tions between events should be typologized for
the purpose of semantic inference and classify
causal relations basically into four types ? Ef-
fect, Means, Precondition and Cause relations
? based primarily on the volitionality of in-
volved events. For example, Effect relations hold
between volitional actions and their resultative
non-volitional states/happenings/experiences, while
Cause relations hold between only non-volitional
states/happenings/experiences.
Following this typology, we are concerned with
the volitionality of each event mention. For our
experiments, we manually built a lexicon of over
12,000 verbs (including verbal nouns) with volition-
ality labels, obtaining 8,968 volitional verbs, 3,597
non-volitional and 547 ambiguous. Volitional verbs
include taberu (eat) and kenkyu-suru (research),
while non-volitional verbs include atatamaru (get
warm), kowareru (to break-vi) and kanashimu (be
sad). We discarded the ambiguous verbs in the ex-
periments.
4.4 Dependency-based cooccurrence patterns
The original Espresso encodes patterns simply as a
word sequence because entity mentions in the rela-
tions it scopes tend to cooccur locally in a single
phrase or clause. In event relation extraction, how-
ever, cooccurrence patterns of event mentions in the
relations we consider (causal relations, temporal re-
lations, etc.) can be captured better as a path on
a syntactic dependency tree because (i) such men-
tion pairs tend to cooccur in a longer dependency
path and (ii) as discussed in Section 4.2, we want
to exclude the arguments of event mentions from
cooccurrence patterns, which would be difficult with
word sequence-based representations of patterns.
A Japanese sentence can be analyzed as a se-
quence of base phrase (BP) chunks called bunsetsu
chunks, each which typically consists of one con-
tent (multi-)word followed by functional words. We
assume each sentence of our corpus is given a de-
pendency parse tree over its BP chunks. Let us call
a BP chunk containing a verb or verbal noun an
event chunk. We create a cooccurrence sample from
any pair of event chunks that cooccur if either (a)
one event chunk depends directly on the other, or
(b) one event chunk depends indirectly on the other
via one intermediate chunk. Additionally, we apply
the Japanese functional expressions dictionary (Mat-
suyoshi et al, 2006) to a cooccurrence pattern for
generalization.
In (5), for example, the two event chunks,
taishoku-go-ni (after retirement) and hajimeru (be-
gin), meet the condition (b) above and the depen-
dency path designated by bold font is identified as a
candidate cooccurrence pattern. The argument PC-o
of the verb hajimeru is excluded from the path.
(5) (taishoku-go-no tanoshimi)-ni PC-o hajimeru
retirement-after as a hobby PC-ACC begin
begin a PC as a hobby after retirement
5 Experiments
5.1 Settings
For an empirical evaluation, we used a sample
of approximately 500M sentences taken from the
500
Table 1: Examples of acuired cooccurrence patterns and relatio instances for the action-effect relation
freq cooccurrence patterns relation instances
94477 ?verb;action?temo?verb;effect?nai
(to do ?action? though ?effect? dose not happen)
sagasu::mitsukaru (search::be found),
asaru::mitsukaru (hunt::be found), purei-suru::kuria-
suru (play::finish)
6250 ?verb;action?takeredomo?verb;effect?nai
(to do ?action? though ?effect? dose not happen)
shashin-wo-toru::toreru (shot photograph::be shot),
meiru-wo-okuru::henji-ga-kaeru (send a mail::get an
answer)
1851 ?noun;action?wo-shitemo?verb;effect?nai
(to do ?action? though ?effect? dose not happen)
setsumei-suru::nattoku-suru (explain::agree), siai-
suru::katsu (play::win), siai-suru::makeru (play::lose)
1329 ?verb;action?yasukute?adjective;effect?
(to simply do ?action? and ?effect?)
utau::kimochiyoi (sing::feel good),
hashiru::kimochiyoi (run::feel good)
4429 ?noun;action?wo-kiite?verb;effect?
(to hear ?action? so that ?effect?)
setsumei-suru::nattoku-suru (explain::agree), setsumei-
suru::rikai-dekiru (explain::can understand)
Web corpus collected by Kawahara and Kuro-
hashi (2006). The sentences were dependency-
parsed with Cabocha (Kudo and Matsumoto, 2002),
and cooccurrence samples of event mentions were
extracted. Event mentions with patterns whose fre-
quency was less than 20 were discarded in order to
reduce computational costs. As a result, we obtained
34M cooccurrence tokens with 11M types. Note
that among those cooccurrence samples 15M tokens
(44%) with 4.8M types (43%) are those with ver-
bal nouns, suggesting the potential impacts of using
verbal nouns.
In our experiments, we considered two of Inui et
al. (2003)?s four types of causal relations: action-
effect relations (Effect in Inui et al?s terminology)
and action-means relations (Means). An action-
effect relation holds between events x and y if and
only if non-volitional event y is likely to happen as
either a direct or indirect effect of volitional action
x. For example, the action X-ga undou-suru (X exer-
cises) and the event X-ga ase-o kaku (X sweats) are
considered to be in this type of relation. A action-
means relation holds between events x and y if and
only if volitional action y is likely to be done as a
part/means of volitional action x. For example, if
case a event-pair is X-ga hashiru (X runs) is consid-
ered as a typical action that is often done as a part of
the action X-ga undou-suru (X exercises).
Note that in these experiments we do not differ-
entiate between relations with the same subject and
those with a different subject. However we plan to
conduct further experiments in the future that make
use of this distinction.
In addition, we have collected action-effect rela-
tion instances for a baseline measure. The baseline
consists of instances that cooccur with eleven pat-
terns that indicate action-effect relation. The dif-
ference between the extended Espresso and baseline
is caused by the low number and constant scores of
patterns.
5.2 Results
We ran the extended Espresso algorithm starting
with 971 positive and 1069 negative seed relation
instances for action-effect relation and 860 positive
and 74 negative seed relations for action-means re-
lation. As a result, we obtained 34,993 cooccurrence
patterns with 173,806 relation instances for the
action-effect relation and 23,281 coocurrence rela-
tions with 237,476 relation instances for the action-
means relation after 20 iterations of pattern rank-
ing/selection and instance ranking/selection. The
threshold parameters for selecting patterns and in-
stances were decided in a preliminary trial. Some
of the acquired patterns and instances for the action-
effect relation are shown in Table 1.
5.2.1 Precision
To estimate precision, 100 relation instances were
randomly sampled from each of four sections of the
ranks of the acquired instances for each of the two
relations (1?500, 501?1500, 1501?3500 and 3500?
7500), and the correctness of each sampled instance
was judged by two graduate students (i.e. 800 rela-
tion instances in total were judged).
Note that in these experiments we asked the asses-
sors to both (a) the degree of the likeliness that the
effect/means takes place and (b) which arguments
are shared between the two events. For example,
while nomu (drink) does not necessarily result in
501
futsukayoi-ni naru (have a hangover), the assessors
judged this pair correct because one can at least say
that the latter sometimes happens as a result of the
former. For criterion (b), as shown in Table 1, the
relation instances judged correct include both the X-
ga VP1::X-ga VP2 type (i.e. two subjects are shared)
and the X-o VP1::X-ga VP2 type (the object of the
former and the subject of the latter are shared). The
issue of how to control patterns of argument sharing
is left for future work.
The precision for the assessed samples are shown
in Figures 1 to 3. ?2 judges? means that an instance
is acceptable to both judges. ?1 judges? means that
it is an acceptable instance to at least one of the two
judges. ?strict? indicates correct instance relations
while ?lenient?3 indicates correct instance relations
? when a judge appends the right cases.
As a result of this strictness in judgement, the
inter-assessor agreement turned out to be poor. The
kappa statistics was 0.53 for the action-effect rela-
tions, 0.49 for the action-effect relations (=baseline)
and 0.55 for action-means relations.
The figures show that both types of relations were
acquired with reasonable precision not only for the
higher-ranked instances but also for lower-ranked
instances. It may seem strange that the precision
of the lower-ranked action-means instances is some-
times even better than the higher-ranked ones, which
may mean that the scoring function given in Section
3 did not work properly. While further investiga-
tion is clearly needed, it should also be noted that
higher-ranked instances tended to be more specific
than lower-ranked ones.
5.2.2 Effects of seed number
We reran the extended Espresso algorithm for the
action-effect relation, starting with 500 positive and
500 negative seed relation instances. The preci-
sion is shown in Figure 44. This precision is fairly
lower than that of action-effect relations with all
seed instances. Additionally, the number of seed in-
stances affects the precision of both higher-ranked
and lower-ranked instances. This result indicates
that while the proposed algorithm is designed to
work with a small seed set, in reality its performance
3If an instance is judged as ?strict? by one assessor and ?le-
nient? by the other, then the instance is assessed as ?lenient?.
4It was only judged by one assessor.
severely depends on the number of seeds.
5.2.3 Effects of using verbal nouns
We also examine the effect of using verbal nouns.
Of the 500 highest scored patterns for the action-
effect relation, 128 patterns include verbal noun
slots, and for action-means, 495 patterns. Hence,
the presence of verbal nouns greatly effects some
acquired instances. Additionally, to see the influ-
ence of frequency, of the 500 high frequent patterns
selected from the 2000 highest scored patterns for
action-effect relation, 177 include verbal noun slots,
and for action-means, 407 patterns. This result pro-
vides further evidence that the inclusion of verbal
nouns has a positive effect in this task.
5.2.4 Argument selection
According to our further investigation on argu-
ment selection, 49 instances (12%) of the correct
action-effect relation instances that are judged cor-
rect have a specific argument in at least one event,
and all of them would be judged incorrect (i.e. over-
generalized) if they did not have those arguments
(Recall the example of kogeme-ga tsuku (get brown)
in Section 4.2). This figure indicates that our method
for argument selection works to a reasonable degree.
However, clearly there is still much room for im-
provement. According to our investigation, up to
26% of the instances that are judged incorrect could
be saved if appropriate arguments were selected. For
example, X-ga taberu (X eats) and X-ga shinu (X
dies) would constitute an action-effect relation if the
former event took such an argument as dokukinoko-
o (toadstool-ACC). The overall precision could be
boosted if an effective method for argument selec-
tion method were devised.
6 Conclusion and future work
In this paper, we have addressed the issue of how
to learn lexico-syntactic patterns useful for acquir-
ing event relation knowledge from a large corpus,
and proposed several extensions to a state-of-the-art
method originally designed for entity relation ex-
traction, reporting on the present results of our em-
pirical evaluation. The results have shown that (a)
there are indeed specific cooccurrence patterns use-
ful for event relation acquisition, (b) the use of cooc-
currence samples involving verbal nouns has pos-
502
 0
 0.2
 0.4
 0.6
 0.8
 1
 0  1000  2000  3000  4000  5000  6000  7000  8000
pre
cis
ion
 [%
]
rank
strict (2 judged)
lenient (2 judged)
strict (1 judged)
lenient (1 judged)
Figure 1: action-effect
 0
 0.2
 0.4
 0.6
 0.8
 1
 0  1000  2000  3000  4000  5000  6000  7000  8000
pre
cis
ion
 [%
]
rank
strict (2 judged)
lenient (2 judged)
strict (1 judged)
lenient (1 judged)
Figure 2: action-means
 0
 0.2
 0.4
 0.6
 0.8
 1
 0  1000  2000  3000  4000  5000  6000  7000  8000
pre
cis
ion
 [%
]
rank
strict (2 judged)
lenient (2 judged)
strict (1 judged)
lenient (1 judged)
Figure 3: action-effect (baseline)
 0
 0.2
 0.4
 0.6
 0.8
 1
 0  1000  2000  3000  4000  5000  6000  7000  8000
pre
cis
ion
 [%
]
rank
system (strict)
system (lenient)
baseline (strict)
baseline (lenient)
half (strict)
half (lenient)
Figure 4: action-effect (half seed)
503
itive impacts on both recall and precision, and (c)
over five thousand relation instances are acquired
from the 500M-sentence Web corpus with a preci-
sion of about 66% for action-effect relations.
Clearly, there is still much room for exploration
and improvement. First of all, more comprehensive
evaluations need to be done. For example, the ac-
quired relations should be evaluated in terms of re-
call and usefulness. A deep error analysis is also
needed. Second, the experiments have revealed that
one major problem to challenge is how to optimize
argument selection. We are seeking a way to incor-
porate a probabilistic model of predicate-argument
cooccurrences into the ranking function for relation
instances. Related to this issue, it is also crucial
to devise a method for controlling argument shar-
ing patterns. One possible approach is to employ
state-of-the-art techniques for coreference and zero-
anaphora resolution (Iida et al, 2006; Komachi et
al., 2007, etc.) in preprocessing cooccurrence sam-
ples.
References
Timothy Chklovski and Patrick Pantel. 2005. Global
path-based refinement of noisy graphs applied to verb
semantics. In Proceedings of Joint Conference on Nat-
ural Language Processing (IJCNLP-05), pages 792?
803.
Ryu Iida, Kentaro Inui, and Yuji Matsumoto. 2006. Ex-
ploiting syntactic patterns as clues in zero-anaphora
resolution. In Proceedings of the 21st International
Conference on Computational Linguistics and the 44th
annual meeting of the ACL, pages 625?632.
Takashi Inui, Kentaro Inui, and Yuji Matsumoto. 2003.
What kinds and amounts of causal knowledge can be
acquired from text by using connective markers as
clues? In Proceedings of the 6th International Con-
ference on Discovery Science, pages 180?193. An ex-
tended version: Takashi Inui, Kentaro Inui, and Yuji
Matsumoto (2005). Acquiring causal knowledge from
text using the connective marker tame. ACM Trans-
actions on Asian Language Information Processing
(TALIP), 4(4):435?474.
Daisuke Kawahara and Sadao Kurohashi. 2006. A fully-
lexicalized probabilistic model for japanese syntactic
and case structure analysis. In Proceedings of the Hu-
man Language Technology Conference of the NAACL,
Main Conference, pages 176?183.
Mamoru Komachi, Ryu Iida, Kentaro Inui, and Yuji Mat-
sumoto. 2007. Learning based argument structure
analysis of event-nouns in japanese. In Proceedings
of the Conference of the Pacific Association for Com-
putational Linguistics (PACLING), pages 120?128.
Taku Kudo and Yuji Matsumoto. 2002. Japanese depen-
dency analysis using cascaded chunking. In CoNLL
2002: Proceedings of the 6th Conference on Natu-
ral Language Learning 2002 (COLING 2002 Post-
Conference Workshops), pages 63?69.
Dekang Lin and Patrick Pantel. 2001. DIRT - discov-
ery of inference rules from text. In Proceedings of
ACM SIGKDD Conference on Knowledge Discovery
and Data Mining 2001, pages 323?328.
Suguru Matsuyoshi, Satoshi Sato, and Takehito Utsuro.
2006. Compilation of a dictionary of japanese func-
tional expressions with hierarchical organization. In
Proceedings of the 21st International Conference on
Computer Processing of Oriental Languages, pages
395?402.
Patric Pantel and Marco Pennacchiotti. 2006. Espresso:
Leveraging generic patterns for automatically harvest-
ing semantic relations. In the 21st International Con-
ference on Computational Linguistics and 44th Annual
Meeting of the ACL, pages 113?120.
Viktor Pekar. 2006. Acquisition of verb entailment from
text. In Proceedings of the Human Language Tech-
nology Conference of the NAACL, Main Conference,
pages 49?56.
Deepak Ravichandran and Eduard Hovy. 2002. Learning
surface text patterns for a question answering system.
In Proceedings of the 21st International Conference
on Computational Linguistics and 40th Annual Meet-
ing of the Association for Computational Linguistics,
pages 41?47.
Kentaro Torisawa. 2006. Acquiring inference rules with
temporal constraints by using japanese coordinated
sentences and noun-verb co-occurrences. In Proceed-
ings of the Human Language Technology Conference
of the NAACL, Main Conference, pages 57?64.
Fabio Massimo Zanzotto, Marco Pennacchiotti, and
Maria Teresa Pazienza. 2006. Discovering asym-
metric entailment relations between verbs using selec-
tional preferences. In Proceedings of the 21st Interna-
tional Conference on Computational Linguistics and
44th Annual Meeting of the Association for Computa-
tional Linguistics, pages 849?856.
504
