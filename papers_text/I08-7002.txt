Gazetteer Preparation for Named Entity Recognition in Indian Languages
Sujan Kumar Saha
Indian Institute of Technology
Kharagpur, West Bengal
India - 721302
sujan.kr.saha@gmail.com
Sudeshna Sarkar
Indian Institute of Technology
Kharagpur, West Bengal
India - 721302
shudeshna@gmail.com
Pabitra Mitra
Indian Institute of Technology
Kharagpur, West Bengal
India - 721302
pabitra@gmail.com
Abstract
This paper describes our approaches for the
preparation of gazetteers for named entity
recognition (NER) in Indian languages. We
have described two methodologies for the
preparation of gazetteers1. Since the rel-
evant gazetteer lists are more easily avail-
able in English we have used a translitera-
tion based approach to convert available En-
glish name lists to Indian languages. The
second approach is a context pattern induc-
tion based domain specific gazetteer prepa-
ration. This approach uses a domain specific
raw corpus and a few seed entities to learn
context patterns and then the corresponding
name lists are generated by using bootstrap-
ping.
1 Introduction
Named entity recognition involves locating and clas-
sifying the names in text. NER is an important task,
having applications in information extraction (IE),
question answering (QA), machine translation and
in most other NLP applications.
NER systems have been developed for resource-
rich languages like English with very high accura-
cies. But constructing an NER for a resource-poor
language is very challenging due to unavailability of
proper resources. Name-dictionaries or gazetteers
are very helpful NER resources and in most Indian
1Specialized list of names for a particular class of Named
Entity (NE). For Example, India is in the location gazetteer,
Sachin is in the person first name gazetteer.
languages there is no reasonable size publicly avail-
able list. The web contains lots of such resources,
which can be used for Indian language NER devel-
opment. But most of the web resources are in En-
glish. Our approach is to transliterate the relevant
English resources and name dictionaries into Indian
languages to make them useful for Indian language
NER task. But direct transliteration from English to
an Indian languages is not easy. Few attempts are
taken to build English to Indian language transliter-
ation systems but the word agreement ratio (WAR)
reached is upto 69.3% (Ekbal et al, 2006).
We have attempted to build a transliteration sys-
tem which uses an intermediate alphabet. Both
the English and the Indian language strings are
transliterated to the intermediate alphabet and for a
English-Indian language pair, if the transliterated in-
termediate alphabet strings are same then we have
concluded that the strings are the transliteration of
one another. We have transliterated the available En-
glish name lists into the intermediate alphabet and
these might be used as gazetteers. The Indian lan-
guage words need to be transliterated to the inter-
mediate format to check whether the word is in a
gazetteer or not. This system does not transliter-
ate the English name lists into Indian languages but
makes them useful in Indian languages NER task.
Transliteration based approaches are useful when
there is availability of English name lists. But when
relevant English name lists are not available then
also we can prepare gazetteers from raw corpus.
We have defined a semi-automatic context pattern
(CP) extraction based gazetteer preparation frame-
work. This framework uses bootstrapping to prepare
The 6th Workshop on Asian Languae Resources, 2008
9
the gazetteers from a large raw corpus starting from
few seed entities. Firstly fixed length patterns are
formed using the surrounding words of the seeds.
Depending on the pattern precision, the patterns are
discarded or generalized by dropping tokens from
the patterns. This set of high precision patterns ex-
tracts other named entities (NEs) which are added to
the seed list for the next iteration of the process. Fi-
nally we are able to prepare the required gazetteers.
To prove the effectiveness of the gazetteer prepa-
ration approach, we have prepared some gazetteers
like names of cricketers, names of tennis players etc.
from a raw Hindi sports domain corpus. The de-
tails of the approaches are given in the following
sections.
The paper is organized as follows. Usefulness
of gazetteers in NER, transliteration approaches in
general and specific for Indian languages and gen-
eral pattern extraction methodologies are discussed
in section 2. Section 3 presents the architecture of
the 2-phase transliteration system and preparation of
gazetteers using that. In section 4 context pattern
extraction based gazetteer preparation is discussed.
Finally section 5 concludes the paper.
2 Previous Work
The main approaches to NER are Linguistic ap-
proaches and Machine Learning (ML) based ap-
proaches. The linguistic approach typically uses
rule-based models manually written by linguists.
ML based techniques make use of a large amount
of annotated training data to acquire high-level lan-
guage knowledge. Several ML techniques like Hid-
den Markov Model (HMM)(Bikel et al, 1997),
Maximum Entropy Model(MaxEnt) (Borthwick,
1999), Conditional Random Field(CRF) (Li and
McCallum, 2004) etc. have been successfully used
for the NER task. Both the approaches may make
use of gazetteer information to build systems. There
are many systems which use gazetteers to improve
the accuracy.
Ralph Grishman has developed a rule-based NER
system which uses some specialized name dictionar-
ies including names of all countries, names of major
cities, names of companies, common first names etc
(Grishman, 1995). Another rule based NER system
is developed by Wakao et al (1996) which has used
several gazetteers like organization names, location
names, person names, human titles etc.
We will now mention some ML based sys-
tems. MENE is a MaxEnt based system de-
veloped by Borthwick. This system has used 8
dictionaries (Borthwick, 1999), which are: First
names (1,245), Corporate names (10,300), Corpo-
rate names without suffix (10,300), Colleges and
Universities (1,225), Corporate suffixes (244), Date
and Time (51) etc. The italics numbers in bracket
indicates the size of the dictionaries. The hy-
brid system developed by Srihari et al(2000) com-
bines several modules built by using MaxEnt, HMM
and handcrafted rules. This system uses the fol-
lowing gazetteers: First name (8,000), Family
name (14,000) and a big gazetteer of Locations
(250,000). There are many other systems which
have used name dictionaries to improve the accu-
racy. Kozareva (2006) described a methodology
to generate gazetteer lists automatically for Spanish
and to build NER system with labeled and unlabeled
data. The location gazetteer is built by finding loca-
tion patterns which looks for specific prepositions.
And the person gazetteer is constructed with graph
exploration algorithm.
Transliteration is also a very important topic
and lots of transliteration systems for different lan-
guages have been developed using different ap-
proaches. The basic approaches for transliteration
are phoneme based or spelling-based. A phoneme-
based statistical transliteration system from Ara-
bic to English was developed by Knight and
Graehl(1998). This system uses a finite state
transducer that implements transformation rules to
do back-transliteration. A spelling-based model
that directly maps English letter sequences into
Arabic letters was developed by Al-Onaizan and
Knight(2002). Several transliteration systems ex-
ist for English-Japanese, English-Chinese, English-
Spanish and many other languages to English. But
very few attempts have been reported on the de-
velopment of transliteration systems between Indian
languages and English. We can mention a transliter-
ation system for Bengali-English transliteration de-
veloped by Ekbal et al(2006). They have proposed
different models modifying the joint source chan-
nel model. In that system a Bengali string is di-
vided into transliteration units containing a vowel
The 6th Workshop on Asian Languae Resources, 2008
10
modifier or matra at the end of each unit. Sim-
ilarly the English string is also divided into units.
Then they defined various unigram, bigram or tri-
gram models depending on the consideration of the
contexts of the units. They have also considered lin-
guistic knowledge in the form of possible conjuncts
and diphthongs in Bengali and their representations
in English. This system is capable of transliterat-
ing mainly person names. The highest transliteration
accuracy achieved by them is 69.3% Word Agree-
ment Ratio (WAR) for Bengali to English and 67.9%
WAR for English to Bengali transliteration.
In the field of IE, patterns play a key role in
identifying relevant pieces of information. Soder-
land et al(1995), Rillof and Jones(1999), Lin et
al.(2003), Downey et al(2004), Etzioni et al(2005)
described different approaches to context pattern in-
duction. Talukder et al(2006) combined grammati-
cal and statistical techniques to create high precision
patterns specific for NE extraction. An approach to
lexical pattern learning for Indian languages is de-
scribed by Ekbal and Bandopadhyay (2007). They
used seed data and annotated corpus to find the pat-
terns for NER.
3 Transliteration based Gazetteer
Preparation
Gazetteers or name dictionaries are helpful in NER.
We have already discussed about some English NER
systems where the usefulness of the gazetteers have
been established. However while developing NER
systems in Indian languages, we tried to find relevant
gazetteers. But we could not obtain openly available
gazetteer lists for these languages. But we found
that there are a lot of resources of names of Indian
persons, Indian places, organizations etc. in English
available in the web. In Table 1 we have mentioned
some of the sources which contains relevant name
lists.
But it is not possible to use the available name
lists directly in the Indian language NER task as
these are in English. We have decided to translit-
erate the English lists into Indian languages to make
them useful in the Indian language NER task.
List Web Sources
http://www.bsnl.co.in/ onlinedi-
rectory.htm
First
Name
http://web1.mtnl.net.in/ direc-
tory/
http://www.eci.gov.in/
http://hiren.info/indian-baby-
names/
http://www.indiaexpress.com/
specials/babynames/
http://surnamedirectory.com/
surname-index.html
Surname http://web1.mtnl.net.in/ direc-
tory/
http://en.wikipedia.org
India Lo-
cation
http://indiavilas.com/ indi-
ainfo/pincodes.asp
http://www.indiapost.gov.in
http://www.eci.gov.in/
World
Location
http://www.maxmind.com/
app/worldcities
http://en.wikipedia.org/wiki
Table 1: Web sources for some relevant name lists
3.1 Transliteration
The transliteration from English to Hindi is quite
difficult. English alphabet contains 26 characters
whereas the Hindi alphabet contains 52 characters.
So the mapping is not trivial. We have already men-
tioned that for Bengali a transliteration system was
developed by Ekbal et al Similar approach can be
used to develop transliteration systems for other In-
dian languages. But this approach uses a bilingual
transliteration corpus, which requires much efforts
to built, is unavailable in proper size in all Indian
languages. Also using this approach the word agree-
ment ratio obtained is below 70%.
To make the transliteration process easier and
more accurate, we have decided to build a 2-phase
transliteration module. Our goal is to make deci-
sion that a particular Indian language string is in an
English gazetteer or not. We need not transliterate
directly from Indian language strings to English or
English name lists into Indian languages. Our idea is
to define an intermediate alphabet and both English
and Indian language strings will be transliterated to
The 6th Workshop on Asian Languae Resources, 2008
11
the intermediate alphabet. For two English-Hindi
string pair, if the intermediate alphabet is same then
we can conclude that one string is the transliteration
of the other.
First of all we need to decide the size of the inter-
mediate alphabet. Preserving the phonetic proper-
ties we have defined our intermediate alphabet con-
sisting of 34 characters. To indicate these 34 charac-
ters, we have given unique character-id to each char-
acter.
3.2 English to Intermediate Alphabet
Transliteration
For transliterating English strings into the interme-
diate state, we have built a phonetic map table. This
phonetic map table maps an English n-gram into an
intermediate character. A part of the map table is
given in Table 2. In the map table, the mapping is
from strings of varying length in the English to one
character in the intermediate alphabet. In our table
the length of the left hand side varies from 1 to 3.
English Intermediate
A a?
EE, I, II ??
OO, U u?
B, W ?b
BH, V v?
CH c?
R, RH r?
SH, S s?
Table 2: A part of the map table
In the following we have described the procedure
of transliteration.
Procedure 1: Transliteration
Source string - English, Output string - Intermediate.
1. Scan the source string (S) from left to right.
2. Extract the first n-gram (G) from the string.
(n = 3)
3. Find if it is in the map-table.
4. If yes, insert its corresponding intermediate
state entity into target string T.
Remove the n-gram from S.
S = S ? G.
Go to step 2.
5. Else set n = n? 1.
Go to step 3.
Here we can take an Indian language name,
?surabhi?, as example to explain the procedure in
details. When the name is written in English, it
may be written in several ways like ?suravi, ?shu-
ravi?, ?surabhee?, ?shurabhi? etc. The English string
?surabhi? is transliterated to ?s?u?r?a?v???? by the translit-
erator. Again if we see the transliteration for ?shu-
ravi?, then also the intermediate transliterated string
is same as the previous one.
3.3 Indian Language to Intermediate Alphabet
Transliteration
This is a 2-phase process. The first phase transliter-
ates the Indian language string into itrans. Itrans is
representation of Indian language alphabets in terms
of ASCII. Since Indian text is composed of syllabic
units rather than individual alphabetic letters, itrans
uses combinations of two or more letters of En-
glish alphabet to represent an Indian language syl-
lable. However, there being multiple sounds in In-
dian languages corresponding to the same English
letter, not all Indian syllables can be represented by
logical combinations of English alphabet. Hence,
itrans uses some non-alphabetic special characters
also in some of the syllables. A map table2, with
some heuristic knowledge, is used for the translit-
eration. For example, the Hindi word ?surabhi? is
converted ?sUrabhI? in itrans.
In the second phase the itrans string is translit-
erated into the intermediate state using the similar
procedure described section 3.2. Here also we use
a map-table containing the mappings from itrans to
intermediate alphabet. This procedure transliterates
the example itrans word ?sUrabhI? to ?s?u?r?a?v????.
3.4 Evaluation
In section 3.2 and 3.3 we have described two phase
transliteration with an example word. We have
shown that our transliteration system transliterates
the Indian language name ?surabhi? and the corre-
sponding English strings into the same intermediate
2The map table is available at www.aczoom.com/itrans.
The 6th Workshop on Asian Languae Resources, 2008
12
string. The system has limitations like sometimes
two different strings can be mapped into a same in-
termediate alphabet string.
For the evaluation of the system we have applied
the transliteration system for two languages - Hindi
and Bengali. For evaluating the system for Hindi
we have created a bi-lingual corpus containing 1070
English-Hindi word pair most of which are names.
980 of them are transliterated correctly by the sys-
tem. The system accuracy is 980 ? 100/1070 =
91.59%. For evaluating the system for Bengali, we
have used a similar bi-lingual corpus and the system
transliterates with 89.3% accuracy.
3.5 Prepared Gazetteer Lists
Previously we have mentioned the web sources
where some name lists are available. Names of
a particular category are collected from different
sources and merged to build a English name list of
that category. Then we have applied our transliter-
ation procedure on the list and transliterated the list
into the intermediate alphabet. This intermediate al-
phabet list acts as a gazetteer in NER task in Indian
languages. When an Indian language NER system
needs to access the gazetteer lists, it transliterates the
Indian language strings into the intermediate alpha-
bet, and searches into the list. In the following we
have described the prepared gazetteer lists which are
useful for a general domain Indian language NER
system.
First Name List: This list contains 10,200 first
names collected from the web. Most of the collected
first names are of Indian origin. Apart from the In-
dian names, we have also collected some non-Indian
names. These non-Indian names are generally the
names of some famous persons, like sports stars,
film stars, scientists, politicians, who are likely to
come in Indian language texts. In our first name list
1500 such names are included.
Surname List: This is a very important list which
contains common surnames. We have prepared the
surname list from different sources containing about
1500 Indian surnames and 400 other surnames.
Indian Locations: This list contains about
14,000 entities. The names of states, cities and
towns, districts, important places in different cities
and even lots of village names are collected in the
list. The list needs to be processed into a list of un-
igrams (e.g., kolakAtA3 (Kolkata), bihAra (Bihar)),
bigrams (e.g., nayI dillI (New Delhi), pashchima
bA.nglA (West Bengal)) and trigrams (e.g. uttaara
chabisha paraganA (North 24 Pargana)). The words
are matched with unigrams, sequences of two con-
secutive words are matched against bigrams and
sequences of three consecutive words are matched
against trigrams.
World Location: The list contains the names of
the countries, different state and city names in world
and also the names of important rivers, mountains
etc. The list contains about 4,000 location names.
Similar to the Indian location list, this list also needs
to be processed as unigram, bigrams and trigrams.
4 Context Pattern Extraction based
Gazetteer Preparation
Gazetteers can also be prepared by extracting con-
text patterns. Transliteration based gazetteer prepa-
ration is applicable while there is availability of En-
glish or parallel language name list. But if such
relevant name lists are not available, but a large
raw corpus is available, then we can use the con-
text pattern extraction based methodology to prepare
the gazetteers. This method seeks some high pre-
cision context patterns by using some seed entities
and hits the patterns to the raw corpus to prepare the
gazetteers.
The overall methodology of extracting context
patterns from a raw corpus is summarized as fol-
lows:
1. Find a large raw corpus and some seed entities
(E) for each class of NEs.
2. For each seed entity e in E, from the corpus
find context string(C) comprised of n tokens
before e, a placeholder for the class instance
and n tokens after e. [We have used n = 3]
This set of words form initial pattern.
3. Search the pattern to the corpus and find the
coverage and precision.
4. Discard the patterns having low precision.
5. Generalize the patterns by dropping one or
more tokens to increase coverage.
3The Indian languages strings are written in italics font and
using itrans transliteration.
The 6th Workshop on Asian Languae Resources, 2008
13
6. Find best patterns having good precision and
coverage.
The details of the context pattern extraction
based gazetteer preparation methodology is de-
scribed in the following subsections. We have taken
a Hindi sports domain raw corpus and prepared
some gazetteers like names of cricketers, names of
tennis players to prove the effectiveness of the pro-
posed methodology.
4.1 Selection of Seed Entity
Context pattern extraction based gazetteer prepa-
ration methodology is applied to a sports domain
corpus which contains about 20 lakhs words col-
lected from the popular Hindi newspaper ?Dainik
Jagaran?. We have worked on preparing the lists
of cricket players, list of tennis players. We have
collected the most frequent names to build the seed
list. For preparing the list of tennis players, we
have taken 5 names as seed entities : Andre Agassi,
Steffi Graf, Serena Williams, Roger Federer and Jus-
tine Henin. Similarly the seed list of cricket players
name list contains only 3 names: Sachin Tendulkar,
Brian Lara and Glenn McGrath.
4.2 Context Extraction
To extract the patterns for a particular category, we
select a part of the corpus where the target seeds will
be available with high frequency. For example to
get the patterns for the names of the cricketers, we
select a part of the corpus where most of the sen-
tences are cricket related. To select the cricket re-
lated sentences, we prepared a list containing the
most frequent words related to cricket like, rAna
(run), ballebAja (batsman), gedabAja (bowler) etc.
Depending upon the presence of such words we have
selected the ?part?. In our development the cricket
?part? contains 120K words. Similar ?part? is devel-
oped for other gazetteers. For a particular seed, we
find the occurrences of the seed entity in the corre-
sponding raw ?part? corpus. Then we extracted three
tokens immediately preceding the seed and three to-
kens immediately following the seed. A placeholder
(CRIC for cricketers, TENS for tennis players)
replaces the seed. The placeholder and the surround-
ing tokens t?3 t?2 t?1 placeholder t+1 t+2 t+3)
form the initial set of patterns.
For the seed sachina tedulkara (Sachin Ten-
dulkar) we extract 92 initial patterns. Some of which
are:
? ki mAsTara blAsTara CRIC ko Tima ke
? dravi.Da aura CRIC 241 nAbAda ke
? bhAratiya ballebAja CRIC ne 100 rana
? mere vichAra se CRIC ko Takkara dene
4.3 Pattern Quality Measure
We measured the quality of a pattern depending on
its precision and coverage. Precision is the ratio of
correct identification and the total identification. If
the precision is high then also we have assumed that
the pattern is a good pattern. In our development
we have marked a pattern as good if the precision is
100%.
We search the initial patterns in the correspond-
ing ?part? corpus to measure the precision and cov-
erage. If the precision is less than 100% for a pat-
tern then we have rejected the pattern. Otherwise we
have tried to make it more generalized to increase
the coverage. To make the generalization we have
dropped the left most and right most tokens one by
one and checked the pattern quality. If for a initial
pattern, several patterns presents with 100% preci-
sion then we have selected those patterns for which
no subset of those is a good pattern. By this way we
have prepared a list of good patterns for a particular
gazetteer type.
In time of ?good? pattern selection we have made
some interesting observations.
? There are some patterns which satisfy the 100%
precision criteria but the coverage is very poor
in terms of new entity extraction. For exam-
ple, ?mAsTara blAsTara CRIC ko? is a pattern
with 100% precision. The pattern has 24 in-
stances in the ?part? corpus, but all the extracted
entities are ?sachina tedulkara?. We have also
examined the pattern in the total raw corpus.
It is capable of extracting ?sachina tedulkara?
only. So in spite of fulfilling all the criteria the
pattern is not a ?good? pattern.
? Another interesting observation is, that there
are some patterns which are ?good? patterns in
The 6th Workshop on Asian Languae Resources, 2008
14
the context of the ?part? corpus, but when used
in the total raw corpus, it extracts non-relevant
entities. For example ?mere vichAra se CRIC
ko Takkara? is a ?good? pattern so it should ex-
tract the names of the cricketers. But when
this is used in the total raw corpus it extracts
non-cricketer entities (e.g. tennis players, chess
players) also. To make such patterns useful we
have extracted all the cricket related sentences
in the similar way which was used for selecting
the ?part? corpus and then the patterns are used
to extract entities from these sentences.
? There present are patterns with very high cover-
age but precision is just below 100%. We have
analyzed these patterns and manually identified
the wrongly extracted entities. If the wrong en-
tities can be grouped together and are having
some specific properties then we have added
these entities in a ?pattern exception list?. Then
the pattern is used as a ?good? pattern and the
exception list is used to detect the wrong iden-
tifications.
In the following we have given some example of
?good? patterns which are useful in identification of
the names of the cricket players.
? ballebAja CRIC ko Tima ke
? ballebAja CRIC ne
? CRIC kA arddhashataka
4.4 Gazetteer Preparation
The extracted ?good? patterns are capable of iden-
tifying NEs from a raw corpus. These patterns are
then used to prepare the gazetteers. The seeds form
the initial gazetteer list for a particular gazetteer
type. The ?good? patterns are used to extract entities
from the total raw corpus. The entities identified by
the patterns are added to the corresponding gazetteer
list. In that way we can add more entities in our first
phase gazetteer list. These new entities are taken as
seeds for the next phase. Then the same procedure
is followed repeatedly to develop a large gazetteer.
We have already mentioned that we have worked
with a sports domain corpus and prepared some
gazetteers. This gazetteers are prepared just to prove
the efficiency of our approach. By using only 3 seed
entities we become able to prepare a gazetteer which
contains 412 names of the cricketers. Even using
this approach only one seed ?Sachin Tendualkar? ex-
tracts 297 names after the second iteration. Similarly
we have collected 245 names of tennis players from
5 seed entities.
5 Conclusion
In this paper we have described our approaches for
the preparation of gazetteers. We have also prepared
some gazetteers using both the approaches to show
their effectiveness. These approaches are very use-
ful for the NER task in resource-poor languages and
also in domain specific NER task.
References
Al-Onaizan Y. and Knight K. 2002. Machine Translit-
eration of Names in Arabic Text. Proceedings of
the ACL Workshop on Computational Approaches to
Semitic Languages.
Bikel Daniel M., Miller Scott, Schwartz Richard and
Weischedel Ralph. 1997. Nymble: A high perfor-
mance learning name-finder. In Proceedings of the
Fifth Conference on Applied Natural Language Pro-
cessing, peges 194?201.
Borthwick Andrew. 1999. A Maximum Entropy Ap-
proach to Named Entity Recognition. Ph.D. thesis,
Computer Science Department, New York University.
Downey D., Etzioni O., Soderland S., Weld D.S. 2004.
Learning text patterns for Web information extraction
and assessment. In AAAI-04 Workshop on Adaptive
Text Extraction and Mining, pages 50?55.
Ekbal A. and Bandyopadhyay S. 2007. Lexical Pattern
Learning from Corpus Data for Named Entity Recog-
nition. In Proceedings of International Conference on
Natural Language Processing (ICON), 2007.
Ekbal A., Naskar S. and Bandyopadhyay S. 2006. A
Modified Joint Source Channel Model for Translitera-
tion. In Proceedings of the COLING/ACL 2006, Aus-
tralia, pages 191?198.
Etzioni Oren, Cafarella Michael, Downey Doug, Popescu
Ana-Maria, Shaked Tal, Soderland Stephen, Weld
Daniel S. and Yates Alexander. 2005. Unsupervised
named-entity extraction from the Web: An experimen-
tal study. In Artificial Intelligence, 165(1): 91-134.
Grishman Ralph. 1995. The New York University Sys-
tem MUC-6 or Where?s the syntax? In Proceedings of
the Sixth Message Understanding Conference.
The 6th Workshop on Asian Languae Resources, 2008
15
Knight K. and Graehl J. 1998. Machine Transliteration.
Computational Linguistics, 24(4): 599?612.
Kozareva Zornitsa. 2006. Bootstrapping Named Entity
Recognition with Automatically Generated Gazetteer
Lists. In Proceedings of EACL student session (EACL
2006).
Li Wei and McCallum Andrew. 2004. Rapid Develop-
ment of Hindi Named Entity Recognition using Condi-
tional Random Fields and Feature Induction (Short Pa-
per). In ACM Transactions on Computational Logic.
Lin Winston, Yangarber Roman and Grishman Ralph.
2003. Bootstrapped learning of semantic classes from
positive and negative examples. In Proceedings of
ICML-2003 Workshop on The Continuum from La-
beled to Unlabeled Data.
Riloff E. 1996. Automatically Generating Extraction
Patterns from Untagged Text. In Proceedings of the
Thirteenth National Conference on Articial Intelli-
gence, pages 1044?1049.
Srihari R., Niu C. and Li W. 2000. A Hybrid Approach
for Named Entity and Sub-Type Tagging. In Proceed-
ings of the sixth conference on Applied natural lan-
guage processing.
Soderland Stephen, Fisher David, Aseltine Jonathan,
Lehnert Wendy. 1995. CRYSTAL: Inducing a Con-
ceptual Dictionary. In Proceedings of the Fourteenth
International Joint Conference on Artificial Intelli-
gence.
Talukdar P. Pratim, T. Brants, M. Liberman and F.
Pereira. 2006. A context pattern induction method
for named entity extraction. In Proceedings of the
Tenth Conference on Computational Natural Lan-
guage Learning (CoNLL-X).
Wakao T., Gaizauskas R. and Wilks Y. 1996. Evaluation
of an algorithm for the recognition and classification
of proper names. In Proceedings of COLING-96.
The 6th Workshop on Asian Languae Resources, 2008
16
