Proceedings of EMNLP 2011, Conference on Empirical Methods in Natural Language Processing, pages 65?69,
Edinburgh, Scotland, UK, July 27?31, 2011. c?2011 Association for Computational Linguistics
Phone set selection for HMM-based dialect speech synthesis
Michael Pucher
Telecommunications
Research Center (FTW)
Vienna, Austria
pucher@ftw.at
Nadja Kerschhofer-Puhalo
Acoustics Research
Institute (ARI)
Vienna, Austria
nadja.kerschhofer@oeaw.ac.at
Dietmar Schabus
Telecommunications
Research Center (FTW)
Vienna, Austria
schabus@ftw.at
Abstract
This paper describes a method for selecting an
appropriate phone set in dialect speech synthe-
sis for a so far undescribed dialect by applying
hidden Markov model (HMM) based training
and clustering methods. In this pilot study we
show how a phone set derived from the pho-
netic surface can be optimized given a small
amount of dialect speech training data.
1 Introduction
In acoustic modeling for dialect speech synthesis we
are confronted with two closely related major prob-
lems1, (1) to find an appropriate phone set for syn-
thesis and (2) to design a recording script with suf-
ficient phonetic and prosodic coverage. In HMM-
based synthesis, we can use the training process of
the voices itself to analyze the used phone set and to
try to optimize it for synthesis.
2 Corpus and phone set design
Goiserian, the dialect of Bad Goisern in the most
southern part of Upper Austria, is a local dialect
of the Middle Bavarian/Southern Bavarian transition
zone. The target variety for speech synthesis de-
scribed here demonstrates the typical problems re-
lated to scarcity of data. While several varieties of
the central and northern part of Upper Austria are
quite well described, detailed descriptions of the va-
rieties in this region do not exist. Lacking a lexi-
con, a phonological description, orthographic rules
1Apart from additional problems that have to do with text
analysis, orthography, and grapheme-to-phoneme conversion.
or a transcription system, a speech corpus and an
appropriate phone set have to be created. Our cur-
rent project aims at audio-visual dialect synthesis,
which is based on a systematic description of speech
data collected from spontaneous speech, word lists
and translated sentences by 10 speakers of the same
dialect. Although it would be ideal to use con-
versational speech data for dialect speech synthe-
sis (Campbell, 2006) we decided to use a hybrid ap-
proach for our full corpus where we plan to collect
a set of prompts from conversational dialect speech,
which will be realized by the dialect speakers.
The speech data for the first preliminary study
presented here consists of 150 sentences and col-
loquial phrases spoken in Goiserian by a female
speaker who can be described as a conservative
speaker of the original basic dialect of the region.
The prompts were translated spontaneously by the
speaker from Standard German into Goiserian and
contain typical phonetic and phonological character-
istics of local Bavarian varieties in multiple occur-
rences.
3 Voice building
The data was originally recorded at 96kHz, 24 bit
and was downsampled to 16kHz, 16 bit for synthesis
and voice building. A preliminary phone set (PS1)
was created on the basis of a fine phonetic transcrip-
tion including sub-phonemic details (e.g. nasaliza-
tion of vowels before nasals ?VN?). Phones occur-
ring less than twice were substituted prior to voice
training with phonetically similar phones or repre-
sentatives of the same phoneme. This leaves us with
a set of 72 phones (see Table 1 and 2).
65
The TRA voice was trained with a HMM-
based speaker-dependent system. Given the limited
amount of training data (150 prompts) and to be able
to analyze the decision trees we only used the cur-
rent, 2 preceding, and 2 succeeding phones as fea-
tures.
HTK IPA # HTK IPA #
s s 207 t t 204
d d 179 n n 171
m m 115 k k 98
h h 84 g g 79
v v 79 f f 62
r r 61 S S 49
N n
"
42 l l 41
b b 31 ts ? 27
ng N 19 p p 17
w B 14 L l
"
12
X x 11 c c 10
RX X 9 j j 7
R R 6 ks ks 3
pf pf 3
Table 1: Consonants (27) in phone set PS1 for training
(72 phones) (Blue = not in PS2).
Based on a phonetic transcription of the training
corpus, flat-start forced alignment with HTK was
carried out. Stops are split into two parts, one for
the closure and one for plosion plus burst. Ad-
ditionally, we applied forced alignment using pro-
nunciation variants2, which is the preferred method
when building a voice for dialect synthesis using a
larger corpus (Pucher, 2010). With this method it
is not necessary to have a phonetic transcription of
the recordings. Given our small corpus, this method
produced several errors ([tsvoa] / [tsvai], [tsum] /
[tsun] etc.) which led us to use the standard align-
ment method from a transcription of the corpus. Af-
ter the transcription we had to correct severe align-
ment errors. These errors are simple to find since
several segments within the utterance are affected.
From this corpus we selected 5 prompts contain-
ing only phonemes that appear at least more than 3
times in the rest of the corpus. This leaves us with
a training corpus of 145 prompts and a 5 prompt
2In a previous project on Viennese dialect synthesis, 33% of
the lexicon entries are pronunciation variants.
HTK IPA # HTK IPA #
a a 138 aa a: 10
A 6 80 AA 6: 3
AN 6? 80 Ai 6i 3
AuN 6?u 7
e e 100 ee e: 9
ei ei 22 eiN e?i 10
E E 20 EE E: 11
EN E? 4 EiN E?i 6
i i 175 ii i: 7
iN i? 6
o o 45 oo o: 3
ou ou 4 Ou O 4
u u 20 U U 15
UN U? 3
q ? 9 qY ?Y 3
QY ?Y 4
y y 9 yy y: 3
Y Y 4
eV @ 11 aV 5 89
ai ai 24 aiN a?i 9
au au 24 ea e5 7
eaN e?5 4 ia i5 30
oa o5 16 oaN o?5 9
Oi Oi 6 oi oi 26
ua u5 21 ui ui 6
Table 2: Vowels (33) and diphtongs (12) in phone set PS1
for training (72 phones) (Blue = not in PS2, Red = not in
PS2 and PS3, green = not in PS3).
test set. For the subjective evaluation, the entire re-
synthesized corpus was used to show us how well
the used phone set covers the data.
The 145 prompts were then used for training
a speaker-dependent HMM-based synthetic voice.
Figure 1 shows the architecture of the HMM-based
speaker dependent system (Zen, 2005). For synthe-
sis we used the full-context label files of the corpus
without duration information. By that text analysis
is not necessary for synthesis. Our implicit assump-
tion is that the letter-to-sound rules and text analysis
produce exactly the string of phones from the tran-
scription. In this way we can evaluate the acoustic
modeling part separately, independently from text
analysis.
66
Excitation
parameter
extraction
Spectral
parameter
extraction
Training of MSD-HSMM
Parameter generation
from MSD-HSMMText analysis
Excitation 
generation Synthesisfilter
Speech signal
Labels
Single speaker
speech database
Training
Synthesis
Spectral parametersExcitation parameters
Labels
Context-dependent
multi-stream MSD-HSMMs
TEXT
SYNTHESIZED
SPEECH
Figure 1: HMM-based speaker dependent speech synthe-
sis system.
4 Voice analysis
To be able to analyze the decision trees we used
phone features only. The HMM-based voice con-
sists of a mel-cepstrum, duration, F0, and an aperi-
odicity model. In a first step we defined the phones
that are not used for modeling, or are used for a cer-
tain model only.
Figure 3 shows those phones that are not used for
clustering of the different models. This may be due
to their rare occurrence in the data (3-4 times) or due
to possible inconsistencies in their phonetic realiza-
tion. The F0 model is not shown since all phonemes
were used in the F0 tree in some context.
To define other possible phone sets we decided
to substitute the phones only occurring in the F0
model but not in the other 3 models, namely the
mel-cepstrum, duration, and the aperiodicity model.
We therefore merged ?Ai?, ?AuN?, ?EN?, ?ks?, ?L?,
?Ou?, ?qY?, ?yy? with their phonetically most sim-
ilar equivalents (e.g. syllabic ?L? with ?l?, ?ks?
with ?k?+?s?, or a nasalized ?EN? or ?AuN? before
nasals with the non-nasal phone) and thus obtained
a new smaller phone set (PS2), which was used for
training a second voice model.
Another possible set of phones (PS 3) is defined
by merging long (VV) and short (V) vowels of the
same quality, namely ?ii?, ?yy?, ?ee?, ?EE?, ?aa?,
?AA?, ?oo? with their short counterpart. From a lin-
guistic point of view, the phonemic status of vowel
C-sil
C-s
no
mcep_s4_1
yes
C-A
no
L-sil
yes
C-t
no
mcep_s4_2
yes
mcep_s4_35
no
mcep_s4_34
yes
C-n
no
mcep_s4_3
yes
C-m
no
mcep_s4_4
yes
C-e
no
mcep_s4_5
yes
C-a
no
L-h
yes
C-AN
no
mcep_s4_6
yes
mcep_s4_37
no
mcep_s4_36
yes
C-k
no
mcep_s4_7
yes
C-d
no
mcep_s4_8
yes
C-g
no
mcep_s4_9
yes
C-b
no
mcep_s4_10
yes
C-N
no
mcep_s4_11
yes
C-f
no
mcep_s4_12
yes
C-i
no
mcep_s4_13
yes
C-r
no
mcep_s4_14
yes
C-h
no
mcep_s4_15
yes
C-X
no
mcep_s4_16
yes
C-c
no
mcep_s4_17
yes
C-oa
no
mcep_s4_18
yes
C-ua
no
mcep_s4_19
yes
C-oaN
no
mcep_s4_20
yes
C-EE
no
mcep_s4_21
yes
C-ia
no
mcep_s4_22
yes
C-ei
no
mcep_s4_23
yes
C-ng
no
mcep_s4_24
yes
C-au
no
mcep_s4_25
yes
C-ai
no
mcep_s4_26
yes
C-aV
no
mcep_s4_27
yes
C-v
no
mcep_s4_28
yes
C-ea
no
mcep_s4_29
yes
C-aa
no
mcep_s4_30
yes
C-ee
no
mcep_s4_31
yes
C-oi
no
mcep_s4_32
yes
R-n
no
mcep_s4_33
yes
C-y
no
C-Oi
yes
C-eV
no
mcep_s4_38
yes
mcep_s4_40
no
mcep_s4_39
yes
mcep_s4_42
no
mcep_s4_41
yes
Figure 2: Part of the mel-cepstrum clustering tree for the
3rd state of the HMM.
duration as a primary feature in Austrian German
is a controversial issue. While differences in length
do exist at the phonetic surface, these differences are
not necessarily of phonemic relevance (Moosmu?ller,
2007; Scheutz, 1985). We obtain thus a third phone
set (PS3) by merging long and short vowels.
Model # #C #L #LL #R #RR
Mel-cep. 42 38 2 0 1 0
Aperiod. 36 31 0 3 0 1
F0 196 54 37 38 30 36
Duration 83 32 14 9 14 13
Table 3: Number of models and questions in mel-
cepstrum, aperiodicity, F0, and duration model for central
HMM state.
4.1 Mel-cepstrum and aperiodicity model
The mel-cepstrum model contains a separate model
for each phone that is used in the cepstral clus-
tering. In Figure 2 this is shown with the model
?mcep s4 32?, which is used in case that the cur-
rent phone is an ?ee? (C-ee) and with the model
?mcep s4 33?, which is used in case that the cur-
rent phone is an ?oi?. These two models are special
models which only cover certain phones. The only
effect of the clustering is that some phones are not
modeled separately, resulting in an unbalanced tree.
However there is one instance of context cluster-
67
MEL-CEP DURATION
APERIODICITY
aa ea ii iN ou
Ai AuN EN ks 
L Ou qY yy
AA ai aiN au
eaN ee EE ei EiN j
ng oa oaN oi Oi q 
QY R u ua w X y  
E eiN
oo pf RX
U ui UN Y
p 
Figure 3: Phones that were not used for clustering in the
trees for mel-cepstrum, duration, and aperiodicity in any
context (current, 2 preceding, and 2 succeeding phones)
and any of the 5 states.
ing in the central state of the mel-cepstrum HMMs.
If the right phone is an ?n? (R-n) there are two dif-
ferent models used (?mcep s4 39?, ?mcep s4 40?),
depending on whether the current phone is an ?Oi?
(C-Oi) or not (Figure 2).
All phones that are not modeled through a sepa-
rate model are modeled by the model at the end of
the tree (model ?mcep s4 42?).
The aperiodicity model is very similar to the mel-
cepstrum model, as can be seen in Table 3 and Fig-
ure 3.
4.2 F0 and duration model
The F0 model uses all phones as shown in Figure 3
and is the most complex model in terms of context
questions as can be seen from Table 3.
The duration model contains the lowest number of
phone related questions as shown by Figure 3 but is
still more complex than the spectrum related models
in terms of context-dependent questions as shown
in Table 3. Similarly to the F0 model, it is rather
difficult to analyze this model directly.
5 Voice evaluation
After the analysis of the voice that was trained with
our basic phoneset PS1 we defined two new phone-
sets PS2 and PS3. These phonesets were used to
train additional voice models for the same speaker.
With these voice models, we synthesized our small
set of 5 test sentences. To evaluate the suitabil-
ity of the phonesets for the training data, we re-
synthesized the training corpus of 145 prompts.
In a pair-wise comparison test of the 150 prompts
we evaluated the three voice models in a subjective
listening test with three expert listeners. The experts
listened to a set of prompts, each prompt synthesized
with two different voice models. They were asked
to compare them and to decide which prompt they
would prefer in terms of overall quality, or whether
they would rate them as ?equally good?.
PS1 PS2 PS3
56 102 105
Table 4: Number of winning comparisons per phone set
(PS1-PS3).
Table 4 illustrates that both approaches to reduce
and redefine the phoneset (PS2, PS3) improved the
overall quality estimation considerably compared to
the initial phoneset PS1.
6 Conclusion
One major challenge for speech synthesis of so far
undescribed varieties is the lack of an appropriate
phoneset and sufficient training data. We met this
challenge by deriving a phoneset directly from the
phonetic surface of a very restricted corpus of natu-
ral speech. This phone set was used for voice train-
ing. Based on the outcome of the first voice training
we reconsidered the choice of phones and created
new phone sets following 2 approaches: (1) remov-
ing phones that are not used in the clustering, and
(2) a linguistically motivated choice of phone sub-
stitutions based on clustering results. Both methods
yielded a considerable improvement of voice qual-
ity. Thus, HMM-based machine learning methods
and supervised optimization can be used for the def-
inition of the phoneset of an unkown dialect. Our
future work will elaborate this method with dialect
speech training corpora of different size to show
whether it can be applied to adaptive methods in-
volving multiple-speaker training. The considera-
tion of inter- and intra-speaker variation and style
shifting will be a crucial question for further study.
68
References
Nick Campbell. 2006. Conversational speech synthesis
and the need for some laughter. IEEE Transactions
on Speech and Audio Processing, 14(4), pages 1171-
1178.
Michael Pucher, Friedrich Neubarth, Volker Strom,
Sylvia Moosmu?ller, Gregor Hofer, Christian Kranzler,
Gudrun Schuchmann and Dietmar Schabus. 2010. Re-
sources for speech synthesis of Viennese varieties. In
Proceedings of the 7th International Conference on
Language Resources and Evaluation (LREC), Valletta,
Malta.
Sylvia Moosmu?ller. 2007. Vowels in Standard Aus-
trian German. An Acoustic-Phonetic and Phonologi-
cal Analysis. Habilitationsschrift, Vienna.
Hannes Scheutz. 1985. Strukturen der Lautvera?nderung.
Braumu?ller, Vienna.
Heiga Zen and Tomoki Toda. 2005. An Overview
of Nitech HMM-based Speech Synthesis System for
Blizzard Challenge 2005. In Proceedings of the 9th
European Conference on Speech Communication and
Technology (INTERSPEECH), Lisboa, Portugal.
69
