Statistical Machine Translation Using Coercive Two-Level Syntactic
Transduction
Charles Schafer and David Yarowsky
Center for Language and Speech Processing / Department of Computer Science
Johns Hopkins University
Baltimore, MD 21218 USA
{cschafer,yarowsky}@cs.jhu.edu
Abstract
We define, implement and evaluate a novel model for
statistical machine translation, which is based on shal-
low syntactic analysis (part-of-speech tagging and phrase
chunking) in both the source and target languages. It
is able to model long-distance constituent motion and
other syntactic phenomena without requiring a full parse
in either language. We also examine aspects of lexical
transfer, suggesting and exploring a concept of transla-
tion coercion across parts of speech, as well as a transfer
model based on lemma-to-lemma translation probabili-
ties, which holds promise for improving machine trans-
lation of low-density languages. Experiments are per-
formed in both Arabic-to-English and French-to-English
translation demonstrating the efficacy of the proposed
techniques. Performance is automatically evaluated via
the Bleu score metric.
1 Introduction
In this work we define, implement and evaluate a novel
model for statistical machine translation (SMT).
Our goal was to produce a SMT system for translat-
ing foreign languages into English which utilizes some
syntactic information in both the foreign language and
English without, however, requiring a full parse in either
language. Some advantages of not relying on full parses
include that (1) there is a lack of availability of parsers
for many languages of interest; (2) parsing time com-
plexity represents a potential bottleneck for both model
training and testing.
Intuitively, the explicit modeling of syntactic phenom-
ena should be of benefit in the machine translation task;
the ability to handle long-distance motion in an intelli-
gently constrained way is a salient example of such a
benefit. Allowing unconstrained translation reorderings
at the word level generates a very large set of permu-
tations that pose a difficult search problem at decoding
time. We propose a model that makes use of shallow
parses (text chunking) to support long-distance motion
of phrases without requiring deeper analysis of syntax.
The resources required to train this system on a new lan-
guage are minimal, and we gain the ability to model
long-distance movement and some interesting proper-
ties of lexical translation across parts of speech. One of
the source languages we examine in this paper, Arabic,
has a canonical sentence-level order of Verb-Subject-
Object, which means that translation into English (with
a standard ordering of Subject-Verb-Object) commonly
requires motion of entire phrasal constituents, which is
not true of French-to-English translation, to cite one lan-
guage pair whose characteristics have wielded great in-
fluence in the history of work on statistical machine
translation. A key motivation for and objective of this
work was to build a translation model and feature space
to handle the above-described phenomenon effectively.
2 Prior Work
Statistical machine translation, as pioneered by IBM
(e.g. Brown et al, 1993), is grounded in the noisy chan-
nel model. And similar to the related channel problems
of speech and handwriting recognition, the original SMT
language pair French-English exhibits a relatively close
linear correlation in source and target sequence. Much
common local motion that is observed for French, such
as adjective-noun swapping, is adequately modeled by
the relative-position-based distortion models of the clas-
sic IBM approach. Unfortunately, these distortion mod-
els are less effective for languages such as Japanese or
Arabic, which have substantially different top-level sen-
tential word orders from English, and hence longer dis-
tance constituent motion.
Wu (1997) and Jones and Havrilla (1998) have sought
to more closely tie the allowed motion of constituents
between languages to those syntactic transductions sup-
ported by the independent rotation of parse tree con-
stituents. Yamada and Knight (2000, 2001) and Alshawi
et al (2000) have effectively extended such syntactic
transduction models to fully functional SMT systems,
based on channel model tree transducers and finite state
head transducers respectively. While these models are
well suited for the effective handling of highly divergent
sentential word orders, the above frameworks have a lim-
itation shared with probabilistic context free grammars
that the preferred ordering of subtrees is insufficiently
constrained by their embedding context, which is espe-
cially problematic for very deep syntactic parses.
In contrast, Och et al (1999) have avoided the con-
straints of tree-based syntactic models and allow the rel-
atively flat motion of empirically derived phrasal chunks,
which need not adhere to traditional constituent bound-
aries.
Our current paper takes a middle path, by grounding
motion in syntactic transduction, but in a much flatter 2-
level model of syntactic analysis, based on flat embed-
ded noun-phrases in a flat sentential constituent-based
chunk sequence that can be driven by syntactic brack-
eters and POS tag models rather than a full parser, facili-
tating its transfer to lower density languages. The flatter
2-level structures also better support transductions condi-
tioned to full sentential context than do deeply embedded
tree models, while retaining the empirically observed ad-
vantages of translation ordering independence of noun-
phrases.
Another improvement over Och et al and Yamada and
Knight is the use of the finite state machine (FSM) mod-
elling framework (e.g. Bangalore and Riccardi, 2000),
which offers the considerable advantage of a flexible
framework for decoding, as well as a representation
which is suitable for the fixed two-level phrasal mod-
elling employed here.
Finally, the original cross-part-of-speech lexical coer-
cion models presented in Section 4.3.3 have related work
in the primarily-syntactic coercion models utilized by
Dorr and Habash (2002) and Habash and Door (2003),
although their induction and modelling are quite differ-
ent from the approach here.
3 Resources
As in other SMT approaches, the primary training re-
source is a sentence-aligned parallel bilingual corpus.
We further require that each side of the corpus be part-
of-speech (POS) tagged and phrase chunked; our lab
has previously developed techniques for rapid training
of such tools (Cucerzan and Yarowsky, 2002). Our trans-
lation experiments were carried out on two languages:
Arabic and French. The Arabic training corpus was a
subset of the United Nations (UN) parallel corpus which
is being made available by the Linguistic Data Consor-
tium. For French-English training, we used a portion of
the Canadian Hansards. Both corpora utilized sentence-
level alignments publicly distributed by the Linguistic
Data Consortium.
POS tagging and phrase chunking in English were
done using the trained systems provided with the fnTBL
Toolkit (Ngai and Florian, 2001); both were trained
from the annotated Penn Treebank corpus (Marcus et al,
1993). French POS tagging was done using the trained
French lexical tagger also provided with the fnTBL soft-
ware. For Arabic, we used a colleague?s POS tagger and
tokenizer (clitic separation was also performed prior to
POS tagging), which was rapidly developed in our lab-
oratory. Simple regular-expression-based phrase chun-
kers were developed by the authors for both Arabic and
French, requiring less than a person-day each using ex-
isting multilingual learning tools.
A further input to our system is a set of word alignment
links on the parallel corpus. These are used to compute
word translation probabilities and phrasal alignments.
The word alignments can in principle come from any
source: a dictionary, a specialized alignment program,
or another SMT system. We used alignments generated
by Giza++ (Och and Ney, 2000) by running it in both di-
rections (e.g., Arabic ? English and English ? Arabic)
on our parallel corpora. The union of these bidirectional
alignments was used to compute cross-language phrase
correspondences by simple majority voting, and for pur-
poses of estimating word translation probabilities, each
link in this union was treated as an independent instance
of word translation.
4 Translation Model
Now we turn to a detailed description of the proposed
translation model. The exposition will give a formal
specification and also will follow a running example
throughout, using one of the actual Arabic test set sen-
tences. This example, its gloss, system translation and
reference human translation are shown in Table 1.
The translation model (TM) we describe is trained di-
rectly from counts in the data, and is a direct model, not
a noisy channel model. It consists of three nested com-
ponents: (1) a sentence-level model of phrase correspon-
dence and reordering, (2) a model of intra-phrase trans-
lation, and (3) models of lexical transfer, or word transla-
tion. We make a key assumption in our construction that
translation at each of these three levels is independent of
the others.
4.1 Sentence Translation
As mentioned, both the foreign language and English
corpora are input with ?hard? phrase bracketings and la-
beled with ?hard? phrase types (e.g., NP, VP1, PPNP2,
etc.) as given by the output of the phrase chunker. These
are denoted in the top-level model presentation in Table
2(1). Given word alignment links, as described in Sec-
tion 2, we compute phrasal alignments on training data.
We contrain these to have cardinality
(foreign)N ? 1(English). Next, we collect counts over
aligned phrase sequences and use the relative frequen-
cies to estimate the probability distribution in Table 2(2).
Particularly for smaller training corpora, unseen foreign-
language phrase sequences are a problem, so we imple-
mented a simple backoff method which assigns proba-
bility to translations of unseen foreign-language phrase
sequences. Table 2(3) encapsulates the remainder of the
translation model, which is described below.
As an example, Table 3 shows the most probable
aligned English phrase sequence generations given an
Arabic simple sentence having the canonical VSO or-
dering. Also, note that all probabilities in the following
1VP in our parlance is perhaps more properly called a verb chunk:
it consists of a verb, its auxiliaries, and contiguous adverbs.
2PPNP consists of a NP with its prepositional head attached.
Arabic Example Sentence From Test Set
(ARABIC) twSy Al- ljnp Al- sAdsp Al- jmEyp Al- EAmp b- AEtmAd m$rwE Al- mqrr Al- tAly :
(PHR.-BRACKETED AR.) [twSy] [Al- ljnp Al- sAdsp] [Al- jmEyp Al- EAmp] [b- AEtmAd m$rwE Al- mqrr Al- tAly] [:]
(AN ENG. GLOSS) [recommends] [the committee the sixth] [the assembly the general] [to adoption draft the decision the following] [:]
(ENG. MT OUTPUT) [the sixth committee] [recommends] [the general assembly] [in the adoption of the following draft resolution] [:]
(REFERENCE TRANS.) the sixth committee recommends to the general assembly the adoption of the following draft decision :
Table 1: An Arabic translation from the test set. We revisit portions of this example throughout the text. All Arabic
strings in this paper are rendered in the reversible Buckwalter transliteration. In addition, all words or symbols referring
to Arabic and French in this paper are italicized.
figures and tables are from the actual Arabic and French
trained systems.
Arabic Phrase Aligned English Prob.
Sequence Phrase Sequence
VP1 NP2 NP3 NP2 VP1 NP3 0.23
VP1 NP2 NP3 VP1 NP2 PP3 0.10
VP1 NP2 NP3 NP3 VP1,2 0.06
Table 3: Top learned sentence-level reorderings for Ara-
bic, for canonical Arabic simple sentence structure VP
(verb) NP (subject) NP (object). Subscripts in English
phrase sequence are alignments to positions in the corre-
sponding Arabic phrase sequence.
4.2 Phrase Translation
Given an Arabic test sentence, a distribution of aligned
English phrase sequences is proposed by the sentence-
level model described in the previous section and in Ta-
ble 2. Each proposed English phrase in each of the phrase
sequence possibilities, therefore, comes to the middle
level of the translation model with access to the identity
of the French phrases aligned to it. Phrase translation is
implemented as shown in Table 4. The phrase transla-
tion model is structured with several levels of backoff: if
no observations exist from training data for a particular
level, the model backs off to the next-more-general level.
In all cases, generation of an English phrase is condi-
tioned on the foreign phrase as well as the type
(NP, VP, etc.) of the English phrase.
Table 4 (1) describes the initial phrase translation
model. It comes into play if the precise sequence of
foreign words has been observed aligning to an En-
glish phrase of the appropriate type. In the example,
we are trying to generate an NP given the Arabic word
string ?Al- ljnp Al- sAdsp? (literally: ?the committee the
sixth?). If this has been observed in data, then that rela-
tive frequency distribution serves as the translation prob-
ability distribution. Table 11 contains examples of some
of these literal phrase translations from the French data.
The next stage of backoff from the above, literal level
is a model that generates aligned English POS tag se-
quences given foreign POS tag sequences: details and
an example can be found in Table 4(2). The sequence
alignments determine the position in English phrase and
the part-of-speech into which we translate the foreign
word. Again, translation is also conditioned on the En-
glish phrase type. Table 5 and Table 6 show the most
probable aligned English sequence generations for two
of the phrases in the example sentence.
If there were no counts for (foreign-POS-sequence,
english-phrase-type) then we back off to counts
collected over (foreign-coarse-POS-sequence, english-
phrase-type), where a coarse POS is, for example, N in-
stead of NOUN-SG. This is shown in Table 4(3).
In case further backoff is needed, as shown in Table
4(4), we begin stripping POS-tags off the ?less signifi-
cant? (non-head) end of the foreign POS-sequence until
we are left with a phrase sequence that has been seen in
training, and from this a corresponding English phrase
distribution is observable. We define the ?less signifi-
cant? end of a phrase to be the end if it is head-initial,
or the beginning if it is head-final, and at this point ig-
nore issues such as nested structure in French and Arabic
NP?s.
Aligned English POS-tag Sequence Translation Probabilities
(conditioned on Arabic POS-tag sequence from NP in example)
P ( DT? JJ4 NN2 | DET1 NOUN-SG2 DET3 ADJ4 , NP) = 0.22
P ( JJ4 NN1 | DET1 NOUN-SG2 DET3 ADJ4 , NP) = 0.20
P ( DT? NN1 | DET1 NOUN-SG2 DET3 ADJ4 , NP) = 0.13
P ( DT? VBN4 NNS2 | DET1 NOUN-SG2 DET3 ADJ4 , NP) = 0.13
P ( DT1 NN2 | DET1 NOUN-SG2 DET3 ADJ4 , NP) = 0.04
P ( DT3 JJ4 NN2 | DET1 NOUN-SG2 DET3 ADJ4 , NP) = 0.03
P ( DT1 VBN4 NNS2 | DET1 NOUN-SG2 DET3 ADJ4 , NP) = 0.03
P ( DT? NN4 NN2 | DET1 NOUN-SG2 DET3 ADJ4 , NP) = 0.02
P ( JJ4 NNS2 | DET1 NOUN-SG2 DET3 ADJ4 , NP) = 0.02
P ( DT1 JJ4 NN2 | DET1 NOUN-SG2 DET3 ADJ4 , NP) = 0.02
P ( NN2 | DET1 NOUN-SG2 DET3 ADJ4 , NP) = 0.02
P ( NN4 NN2 | DET1 NOUN-SG2 DET3 ADJ4 , NP) = 0.02
Table 5: From the running Arabic example, top English
NP generations given an Arabic phrase DET NOUN-SG
DET ADJ. Note: ? denotes a null alignment (generation
from null). Generation from a null alignment is allowed
for specified parts of speech, such as determiners and
prepositions.
4.3 Lexical Transfer
4.3.1 The Basic Model
In the basic model of word generation, phrases may be
translated directly as single atomic entities (as in Table
4(1)), or via phrasal decomposition to individual words
translated independently, conditioned only on the source
word and target POS. Word translation in the latter case
Top-level Definition of Translation Model
Example Instantiation of Model Variables Model Description
P ( the sixth committee recommends the general assembly .. | P ( english words | foreign words ) =
twSy Al- ljnp Al- sAdsp Al- jmEyp Al- EAmp .. ) =
P ( [twSy]V P1 [Al- ljnp Al- sAdsp]NP1 [Al- jmEyp Al- EAmp]NP2 .. | (1) P ( foreign bracketing , foreign phrase sequence | foreign words )
twSy Al- ljnp Al- sAdsp Al- jmEyp Al- EAmp .. )
?P ( NP2 VP1 NP3 PPNP4 PUNC5 | (2) P ( english phrase sequence , phrase alignment matrix |
VP1 NP2 NP3 PPNP4 PUNC5 ) foreign phrase sequence )
?P ( [the sixth committee]NP2 [recommends]V P1 (3) P ( english words , english bracketing , english phrase sequence |
[the general assembly]NP3 .. | foreign words , foreign bracketing , foreign phrase sequence ,
[twSy]V P1 [Al- ljnp Al- sAdsp]NP1 [Al- jmEyp Al- EAmp]NP2 .. , english phrase sequence , phrase alignment matrix )
NP2 VP1 NP3 PPNP4 PUNC5 )
Table 2: Statement of the translation model at top level.
.
Phrase Translation Model with Backoff Pathways
Example Instantiations Model Statement
P ( the sixth committee | Al- ljnp Al- sAdsp , NP ) =
P ( the sixth committee | Al- ljnp Al- sAdsp , NP ) (1) P ( WE1 WE2 .. WEn | WF1 WF2 .. WFm , phr typeE )
? ? (backoff if C( WF1 WF2 .. WFm , phr typeE) = 0)
P ( DT1 JJ4 NN2 | DET1 NOUN-SG2 DET3 ADJ4 , NP ) (2) P ( TfineE1
TfineE2
.. TfineEn
, ?i | TfineF1
TfineF2
.. TfineFm
, phr typeE )
. ?P ( the | Al- , DT ) . ?P ( WE1 | WF?i(1)
, TfineE1
)
. ?P ( committee | ljnp , NN ) . ?P ( WE2 | WF?i(2)
, TfineE2
)
. ?P ( sixth | sAdsp , JJ ) . ?.. ? P ( WEn | WF?i(n)
, TfineEn
)
? ? (backoff if C( TfineF1
TfineF2
.. TfineFm
, phr typeE) = 0)
P ( DT1 JJ4 NN2 | D1 N2 D3 A4 , NP ) (3) P ( TfineE1
TfineE2
.. TfineEn
, ?i | TcoarseF1
TcoarseF2
.. TcoarseFm
, phr typeE )
. ?P ( the | Al- , DT ) . ?P ( WE1 | WF?i(1)
, TfineE1
)
. ?P ( committee | ljnp , NN ) . ?P ( WE2 | WF?i(2)
, TfineE2
)
. ?P ( sixth | sAdsp , JJ ) . ?.. ? P ( WEn | WF?i(n)
, TfineEn
)
? ? (backoff if C( TcoarseF1 TcoarseF2 .. TcoarseFm , phr typeE ) = 0)
P ( ? | D1 N2 D3 , NP ) (4) P ( TfineE1
TfineE2
.. TfineEn
, ?i | TcoarseF1
TcoarseF2
.. TcoarseFm?1
, phr typeE )
. * ? * .. * ? . * ? * .. * ?
? ? (backoff if C( TcoarseF1 TcoarseF2 .. TcoarseFm?1 , phr typeE) = 0)
P ( ? | D1 N2 , NP ) (4) P ( TfineE1
TfineE2
.. TfineEn
, ?i | TcoarseF1
TcoarseF2
.. TcoarseFm?2
, phr typeE )
. * ? * .. * ? . * ? * .. * ?
? ? (backoff if C( TcoarseF1 TcoarseF2 .. TcoarseFm?2 , phr typeE) = 0)
.... ....
Table 4: The phrase translation model, with backoff. Examples on the left side are from one of the Arabic test
sentences. (1) is the direct, lexical translation level. (2) - (4) constitute the backoff path to handle detailed phenomena
unseen in the training set. (2) is a model of fine POS-tag reordering and lexical generation; (3) is similar, but conditions
generation on coarse POS-tag sequences in the foreign language. (4) is a model for progressively stripping off POS-
tags from the ?less significant? end of a foreign sequence. The idea is to do this until we reach a subsequence that has
been seen in training data, and which we therefore have a distribution of valid generatons for. The term ?i in (2) - (4)
is a position alignment matrix. At all times, we generate not just an English POS-tag sequence, but rather an aligned
sequence. Similarly, in the lexical transfer probabilities shown in this table, there is a function ?i() which takes an
English sequence position index and returns the (unique) foreign word position to which it is aligned4.
Aligned English POS-tag Sequence Translation Probabilities
(conditioned on Arabic POS-tag sequence from VP in example)
P ( VBZ1 | VERB-IMP1 , VP ) = .28
P ( VBP1 | VERB-IMP1 , VP ) = .17
P ( VBD1 | VERB-IMP1 , VP ) = .09
...
P ( MD? VB1 | VERB-IMP1 , VP ) = .06
Table 6: From the Arabic example, top English VP gen-
erations given an Arabic phrase VERB-IMP.
is done in the context that the model has already pro-
posed a sequence of POS tags for the phrase. Thus we
know the English POS of the word we are trying to gen-
erate in addition to the foreign word that is generating it.
Consequently, we condition translation on English POS
as well as the foreign word. Table 7 describes the backoff
path for basic lexical transfer and presents a motivating
example in the French word droit. Translation probabili-
ties for one of the words in the example Arabic sentence
can be found in Table 8.
4.3.2 Generation via a Lemma Model
To counter sparse data problems in estimating word
translation probabilities, we also implemented a lemma-
Word Generation
Examples Model with Backoff Pathways
P (WE | droit , NNS) P (WE |WF , TfineE )
rights 0.4389 p(rights | droit , NNS)
benefits 0.0690
people 0.0533
laws 0.0188
? (backoff if C(WF , TfineE ) = 0)
P (WE | droit , N) P (WE |WF , TcoarseE )
right 0.4970
law 0.1318
rights 0.0424 p(rights | droit , N)
property 0.0115
? (backoff if C(WF , TcoarseE ) = 0)
P (WE | droit) P (WE |WF )
right 0.2919
entitled 0.0663
law 0.0652
the 0.0249
to 0.0240
rights 0.0210 p( rights | droit )
? (backoff if C(WF ) = 0)
p( UNKNOWN WORD |WF ) = 1
Table 7: Description of the conditioning for different lev-
els of backoff in the lexical transfer model. The exam-
ple shows translations for the French word droit (?right?)
conditioned on decreasingly specific values. The pro-
gressively lower ranking of the correct translation as we
move from fine, to coarse, to no POS, illustrates the ben-
efit of conditioning generation on the English part of
speech.
Arabic Word English POS English Wd. Prob.
ljnp NN committee 0.591
ljnp NN commission 0.233
ljnp NN subcommittee 0.035
ljnp NN acc 0.013
ljnp NN report 0.005
ljnp NN ece 0.004
ljnp NN icrc 0.004
ljnp NN aalcc 0.004
ljnp NN escap 0.004
ljnp NN escwa 0.004
ljnp NN eca 0.003
ljnp NNS members 0.088
ljnp NNS recommendations 0.033
ljnp NNS copuos 0.033
ljnp NNS questions 0.027
ljnp NNS representatives 0.024
ljnp N committee 0.577
ljnp N commission 0.227
ljnp N subcommittee 0.035
Table 8: From running example, translation probabilities for Arabic
noun ljnp, ?committee?.
based model for word translation. Under this model,
translation distributions are estimated by counting word
alignment links between foreign and English lemmas, as-
suming a lemmatization of both sides of the parallel cor-
pus as input. The form of the model is illustrated below:
P ( WE | WF ,TcoarseF ,TfineE ) =
P ( WE | lemmaE , TcoarseF , TfineE )?
P ( lemmaE | lemmaF , TcoarseF , TfineE )?
P ( lemmaF | WF , TcoarseF , TfineE )
? approximated by
P ( WE | lemmaE , TfineE )?
P ( lemmaE | lemmaF , TcoarseE )?
P ( lemmaF | WF , TcoarseF )
First, note that P ( lemmaF | WF , TcoarseF ) is very
simply a hard lemma assignment by the foreign lan-
guage lemmatizer. Second, English word generation
from English lemma and coarse POS (P ( WE | lemmaE
, TfineE )) is programmatic, and can be handled by
means of rules in conjunction with a lookup table for
irregular forms. The only distribution here that must be
estimated from data is P ( lemmaE | lemmaF , TcoarseE
). This is done as described above. Furthermore, given
an electronic translation dictionary, even this distribution
can be pre-loaded: indeed, we expect this to be an
advantage of the lemma model, and an example of
a good opportunity for integrating compiled human
knowledge about language into an SMT system. Some
examples of the lemma model combating sparse data
problems inherent in the basic word-to-word models can
be found in Table 9.
4.3.3 Coercion
Lexical coercion is a phenomenon that sometimes occurs
when we condition translation of a foreign word on the
word and the English part-of-speech. We find that the
system we have described frequently learns this behav-
ior: specifically, the model learns in some cases how
to generate, for instance, a nominal form with similar
meaning from a French adjective, or an adjectival real-
ization of a French verb?s meaning; some examples of
this phenomenon are shown in Table 10. We find this
coercion effect to be of interest because it identifies in-
teresting associations of meaning. For example, in Table
10 ?willing? and ?ready? are both sensible ways to re-
alize the meaning of the action ?to accept? in a passive,
descriptive mode. droit behaves similarly. Though the
English verb ?to right? or ?to be righted? does not have
the philosophical/judicial entitlement sense of the noun
?right?, we see that the model has learned to realize the
meaning in an active, verbal form: e.g., VBG ?receiving?
and VB ?qualify?.
5 Decoding
Decoding was implemented by constructing finite-state
machines (FSMs) per evaluation sentence to encode
relevant portions (for the individual sentence in ques-
tion) of the component translation distributions described
above. Operations on these FSMs are performed using
the AT&T FSM Toolkit (Mohri et al, 1997). The FSM
constructed for a test sentence is subsequently composed
with a FSM trigram language model created via the SRI
Language Modeling Toolkit (Stolcke, 2002). Thus we
use the trigram language model to implement rescoring
of the (direct) translation probabilities for the English
word sequences in the translation model lattice.
We found that using the finite-state framework and the
general-purpose AT&T toolkit greatly facilitates decoder
development by freeing the implementation from details
of machine composition and best-path searching, etc.
The structure of the translation model finite-state ma-
chines is as illustrated in Figure 1. The sentence-level
(aligned phrase sequence generation) and phrase-level
(aligned intra-phrase sequence generation) translation
probabilities are encoded on epsilon arcs in the ma-
chines. Word translation probabilities are placed onto
arcs emitting the word as an output symbol (in the fig-
ure, note the arcs emitting ?committee?, ?the?, etc.). The
FSM in Figure 1 corresponds to the Arabic example sen-
tence used throughout this paper. In the portion of the
machine shown, the (best) path which generated the ex-
ample sentence is drawn in bold. Finally, Figure 2 is
a rendering of the actual FSM (aggressively pruned for
display purposes) that generated the example Arabic sen-
tence; although labels and details are not visible, it may
provide a visual aid for better understanding the structure
of the FSM lattices generated here.
As a practical matter in decoding, during translation
model FSM construction we modified arc costs for out-
put words in the following way: a fixed bonus was as-
signed for generating a ?content? word translating to a
?content? word. Determining what qualifies as a con-
tent word was done on the basis of a list of content POS
tags for each language. For example, all types of nouns,
verbs and adjectives were listed as content tags; deter-
miners, prepositions, and most other closed-class parts of
speech were not. This implements a reasonable penalty
on undesirable output sentence lengths. Without such a
penalty, translation outputs tend to be very short: long
sentence hypotheses are penalized de facto merely by
containing many word translation probabilities. An ad-
ditional trick in decoding is to use only the N-best trans-
lation options for sentence-level, phrase-level, and word-
level translation. We found empirically (and very consis-
tently) in dev-test experiments that restricting the syntac-
tic transductions to a 30-best list and word translations to
a 15-best list had no negative impact on Bleu score. The
benefit, of course, is that the translation lattices are dra-
matically reduced in size, speeding up composition and
search operations.
.
.
.
.
.
.
etc ...
... next phrase,
.
.
.
.
.
.
S
P(the | NULL)
P(an | NULL) P(committee | ljnp)
P(commission | ljnp)
NULLP( DT       NN      |   NOUN?SG    )1
1 1
P(NP    VP    NP  .. |VP   NP   NP  .. )
32
"commission"
"committee"
"the"
"an"
1
2 3
Figure 1: An illustration of the translation model structure for an
Arabic test sentence.
319 321W__:the/-0
0
1
S__:<s>/5.411
2
S__:<s>/5.629
3
S__:<s>/5.835
4
S__:<s>/5.868
5
S__:<s>/5.940
6
S__:<s>/6.226
7
S__:<s>/6.381
8
S__:<s>/6.385
9
S__:<s>/6.396
10
S__:<s>/6.529
11S__:<s>/6.546
12
S__:<s>/6.620
13
S__:<s>/6.657
14S__:<s>/6.698
15
S__:<s>/6.711
16
S__:<s>/6.717
17S__:<s>/6.748
18
S__:<s>/6.825
19S__:<s>/6.875
20S__:<s>/6.942
21
S__:<s>/6.946
116
137
W__:committee/-0
224
247P__ADJP:<epsilon>/-0
412 439T__-:<epsilon>/0.129
702
714
W__:of/1.969
W__:in/2.215
22
P__NP:<epsilon>/-0
117
138
G__:<epsilon>/-0
225 248G__:<epsilon>/-0
272 273W__:general/-0
413
440T__recommends:<epsilon>/0.227
474
501W__:the/1.188
W__:a/1.736
W__:this/2.266
703
715
W__:on/2.917
W__:of/1.969
W__:against/4.731
W__:by/2.975
W__:under/4.248
W__:at/3.201
W__:in/2.215
W__:that/2.614
W__:after/4.880
W__:before/4.435
W__:with/3.075
W__:for/2.660
W__:because/4.073
W__:from/3.270
W__:as/3.201
W__:through/4.435
W__:into/3.971
W__:about/3.426
W__:between/4.602
W__:like/4.665
W__:during/4.572
W__:whether/4.697
W__:if/3.704
W__:than/4.147
W__:over/4.385
W__:per/3.988
W__:out/4.410
W__:within/4.766
521
555W__:of/1.969
558
590
W__:the/0.132
631
630
W__:rapporteur/0.699
W__:decision/1.000
23
P__NP:<epsilon>/-0
118
139G__:<epsilon>/-0
226
227
W__:committee/-0
322
W__:assembly/-0
414 441T__recommends:<epsilon>/0.227
522 556W__:of/1.969
W__:in/2.215
525
559
P__O:<epsilon>/-0
24
P__NP:<epsilon>/-0
119 140P__O:<epsilon>/-0
249
G__:<epsilon>/-0
415
442
T__2:<epsilon>/0.631
443
T__2#xslax/NULL:<epsilon>/1.194
632 647P__NP:<epsilon>/-0
367
G__:<epsilon>/-0
523
557
W__:on/2.917
W__:of/1.969
W__:by/2.975
W__:under/4.248
W__:at/3.201
W__:in/2.215
W__:that/2.614
W__:before/4.435
W__:with/3.075
W__:for/2.660
W__:because/4.073
W__:from/3.270
W__:as/3.201
W__:through/4.435
W__:into/3.971
W__:about/3.426
W__:if/3.704
W__:than/4.147
W__:over/4.385
W__:per/3.988
W__:out/4.410
592
T__::<epsilon>/0.028
704
716
W__:of/1.969
W__:in/2.215
W__:that/2.614
W__:for/2.660
25
P__O:<epsilon>/-0
228 229
W__:sixth/-0
416
444
T__IN#NGEN+DT#NN#NGEN+IN#NGEN+DT#JJ#NN#NN:<epsilon>/3.545
445T__IN#NGEN+DT#NN#NGEN+IN#JJ#NN#NNS:<epsilon>/4.133
446
T__IN#NGEN+DT#NN#NGEN+IN#DT#JJ#NN#NN:<epsilon>/4.895
475 502G__:<epsilon>/-0
633
648
P__VP:<epsilon>/-0
120
141
P__NP:<epsilon>/-0
560
561
W__:the/-0
705
717
P__O:<epsilon>/-0
26
P__NP:<epsilon>/-0
417 447T__-:<epsilon>/0.129
476 503P__NP:<epsilon>/-0
634
635
W__:draft/0.404
W__:project/1.841
121
142
G__:<epsilon>/-0
230
251
P__VP:<epsilon>/-0
323
325
W__:by/-0
27P__NP:<epsilon>/-0
524
W__:of/1.969
W__:in/2.215
593W__:sixth/-0
122 143G__:<epsilon>/-0
324 W__:to/-0
477
504W__:adoption/0.711
W__:provision/1.929
532
G__:<epsilon>/-60
706
718W__:police/-0
28
P__ADJP:<epsilon>/-0
231
252
G__:<epsilon>/-0
418
448
W__:-/-0
526
T__the/NULL#sixth#committee:<epsilon>/0.454
T__the#sixth#committee:<epsilon>/1.871
T__sixth#committee:<epsilon>/1.871
562
534
W__:by/-0
123 144
P__O:<epsilon>/-0
29P__NP:<epsilon>/-0
232
253
W__:adoption/0.711
W__:provision/1.929
527 T__by/NULL#the/NULL#general#assembly:<epsilon>/1.085
563T__to/NULL#the/NULL#general#assembly:<epsilon>/1.254 W__:to/-0
636 649P__ADJP:<epsilon>/-0
327W__:the/-0
419 W__:2/-0
30
P__NP:<epsilon>/-0
124 145P__O:<epsilon>/-0
528 565T__-:<epsilon>/0.129
573
W__:-/-0
637
650
W__:on/2.046
W__:of/2.238
W__:by/1.908
W__:under/3.942
W__:at/3.536
W__:in/1.425
W__:that/4.161
W__:with/1.853
W__:for/3.134
W__:as/2.616
326
328
W__:the/-0
420 449W__:2/-0
707
696
W__:in/-0
31
P__NP:<epsilon>/-0
32
P__VP:<epsilon>/-0
33
P__SBAR:<epsilon>/-0
529 566
W__:on/2.917
W__:of/1.969
W__:by/2.975
W__:at/3.201
W__:in/2.215
W__:that/2.614
W__:with/3.075
W__:for/2.660
W__:from/3.270
W__:as/3.201
W__:about/3.426
594
W__:the/1.188
W__:that/2.597
W__:a/1.736
W__:this/2.266
638 651
W__:on/2.046
W__:of/2.238
W__:by/1.908
W__:under/3.942
W__:at/3.536
W__:in/1.425
W__:that/4.161
W__:with/1.853
W__:for/3.134
W__:as/2.616
125
146
G__:<epsilon>/-0
421
450
W__:on/2.046
W__:of/2.238
W__:by/1.908
W__:at/3.536
W__:in/1.425
W__:with/1.853
W__:for/3.134
W__:as/2.616
34P__NP:<epsilon>/-0
329
T__the/NULL#general#assembly:<epsilon>/0.938
369
T__had#decided:<epsilon>/2.442
370
T__will#consider:<epsilon>/2.442
639
652
W__:in/1.425
708 719
W__:world/-0
104 126G__:<epsilon>/-0
422
451
W__:on/2.046
W__:of/2.238
W__:by/1.908
W__:at/3.536
W__:in/1.425
W__:with/1.853
W__:for/3.134
W__:as/2.616
530 567
W__:on/2.917
W__:of/1.969
W__:by/2.975
W__:at/3.201
W__:in/2.215
W__:that/2.614
W__:with/3.075
W__:for/2.660
W__:from/3.270
W__:as/3.201
35P__NP:<epsilon>/-0
330
W__:decided/-0
478
505
W__:adoption/0.711
W__:provision/1.929
640
653
W__:on/2.046
W__:by/1.908
W__:in/1.425
W__:with/1.853
709 720P__VP:<epsilon>/-0
423
452
W__:on/2.046
W__:of/2.238
W__:by/1.908
W__:in/1.425
W__:with/1.853
W__:for/3.134
W__:as/2.616
36
P__NP:<epsilon>/-0
233
254W__:adoption/0.711
W__:provision/1.929
331
W__:consider/-0
531 568
W__:on/2.917
W__:of/1.969
W__:by/2.975
W__:in/2.215
W__:that/2.614
W__:with/3.075
W__:for/2.660
641
654W__:on/2.046
W__:of/2.238
W__:by/1.908
W__:under/3.942
W__:at/3.536
W__:in/1.425
W__:that/4.161
W__:with/1.853
W__:for/3.134
W__:as/2.616
710
721
P__O:<epsilon>/-0
147P__VP:<epsilon>/-0
148
P__PPNP:<epsilon>/-0
424
453
W__:on/2.046
W__:of/2.238
W__:by/1.908
W__:under/3.942
W__:at/3.536
W__:in/1.425
W__:with/1.853
W__:for/3.134
W__:as/2.616
37
P__O:<epsilon>/-0
332
307W__:to/-0
533 570
T__accountable:<epsilon>/0.693
571T__present/NULL:<epsilon>/0.693
642
655
W__:on/2.046
W__:of/2.238
W__:by/1.908
W__:in/1.425
W__:with/1.853
127
P__PPNP:<epsilon>/-0
149P__NP:<epsilon>/-0
425
454W__:on/2.046
W__:of/2.238
W__:by/1.908
W__:under/3.942
W__:at/3.536
W__:in/1.425
W__:with/1.853
W__:for/3.134
W__:as/2.616
38
P__O:<epsilon>/-0
333 371
W__:with/-0
537
W__:the/-0
711
722
W__:the/1.188
W__:that/2.597
W__:a/1.736
W__:those/3.154
W__:all/3.201
W__:an/2.837
W__:no/3.547
W__:any/3.434
W__:some/3.097
W__:this/2.266
W__:these/3.201
W__:every/4.241
W__:another/4.082
128 P__VP:<epsilon>/-0
426
455
W__:in/1.425
39
P__O:<epsilon>/-0
535
538
W__:the/-0
595W__:following/0.227
129 150
P__O:<epsilon>/-0
334
372
W__:next/1.854
W__:following/0.227
427
456
W__:on/2.046
W__:of/2.238
W__:by/1.908
W__:at/3.536
W__:in/1.425
W__:with/1.853
W__:for/3.134
W__:as/2.616
643
656
T__to/NULL#2/NULL:<epsilon>/1.299
T__to/NULL#2:<epsilon>/2.397
657T__with/NULL#article/NULL#2:<epsilon>/2.397
658
T__under/NULL#review/NULL:<epsilon>/3.091
659
T__by/NULL#2#police/NULL#officers/NULL:<epsilon>/3.091
660T__in/NULL#only/NULL#2:<epsilon>/3.091
661
T__in/NULL#order/NULL:<epsilon>/3.091
662T__for/NULL#just/NULL#2:<epsilon>/3.091
663
T__on/NULL#2:<epsilon>/3.091
664T__at/NULL#2:<epsilon>/3.091
665
T__with/NULL#regard/NULL:<epsilon>/3.091
666
T__for/NULL#2:<epsilon>/3.091
667
T__to/NULL#2.7/NULL#in/NULL:<epsilon>/3.091
668
T__in/NULL#document:<epsilon>/3.091
669
T__into/NULL#the/NULL#world/NULL#economy/NULL:<epsilon>/3.091
40
P__NP:<epsilon>/-0
479
506
W__:adoption/0.711
W__:provision/1.929
428
457
W__:in/1.425
536 572
W__:the/-0
41
P__PPNP:<epsilon>/-0
130 151P__NP:<epsilon>/-0
234
255
W__:adoption/0.711
W__:provision/1.929
429
458
W__:the/1.188
W__:that/2.597
W__:a/1.736
W__:those/3.154
W__:all/3.201
W__:an/2.837
W__:no/3.547
W__:any/3.434
W__:some/3.097
W__:this/2.266
W__:these/3.201
42P__VP:<epsilon>/-0
131
152G__:<epsilon>/-0
539
574
W__:the/1.188
W__:that/2.597
W__:a/1.736
W__:those/3.154
W__:all/3.201
W__:an/2.837
W__:any/3.434
W__:some/3.097
W__:this/2.266
W__:these/3.201
644 670T__-:<epsilon>/0.129
43
P__NP:<epsilon>/-0
132
153P__PPNP:<epsilon>/-0
645
646
W__:the/-0
44
P__NP:<epsilon>/-0
133
154
P__VP:<epsilon>/-0
480
508
W__:adoption/0.711
W__:provision/1.929
W__:appropriation/3.108
W__:accreditation/3.18
235
257
P__NP:<epsilon>/-0
335
373
W__:rapporteur/0.699
W__:decision/1.000
W__:the/0.132
45
T__the/NULL#sixth#committee:<epsilon>/0.454
T__the#sixth#committee:<epsilon>/1.871
46
T__sixth#committee:<epsilon>/1.871
134
155
P__NP:<epsilon>/-0
671W__:sixth/-0
236
258
P__NP:<epsilon>/-0
47
T__the/NULL#sixth#committee:<epsilon>/0.454
T__the#sixth#committee:<epsilon>/1.871
48T__sixth#committee:<epsilon>/1.871
135
156
G__:<epsilon>/-0
430
459
W__:the/1.188
W__:that/2.597
W__:a/1.736
W__:those/3.154
W__:all/3.201
W__:an/2.837
W__:no/3.547
W__:any/3.434
W__:some/3.097
W__:this/2.266
W__:these/3.201
336
374W__:2/-0
49T__2:<epsilon>/0.631
50
T__2#xslax/NULL:<epsilon>/1.194
136
157
G__:<epsilon>/-0
237
259
G__:<epsilon>/-0
337
375
W__:2/-0
51
T__-:<epsilon>/0.129
T__-/NULL:<epsilon>/2.988
158
G__:<epsilon>/-0
238
260
G__:<epsilon>/-0
569P__O:<epsilon>/-0
287
338
W__:sixth/-0
672
T__2:<epsilon>/0.631
673
T__2#xslax/NULL:<epsilon>/1.194
52T__the/NULL#sixth#committee:<epsilon>/0.454
T__the#sixth#committee:<epsilon>/1.871
53
T__sixth#committee:<epsilon>/1.871
159
P__VP:<epsilon>/-0
239
261
G__:<epsilon>/-0
596T__::<epsilon>/0.028
376W__:committee/-0
674
T__recommends:<epsilon>/0.227
54T__the/NULL#sixth#committee:<epsilon>/0.454
T__the#sixth#committee:<epsilon>/1.871
55T__sixth#committee:<epsilon>/1.871
160
P__VP:<epsilon>/-0
240
262
P__PPNP:<epsilon>/-0
481
509
W__:adoption/0.711
W__:provision/1.929
W__:appropriation/3.108
W__:accreditation/3.18
W__:accountable/-0
431
460
W__:the/1.188
W__:that/2.597
W__:a/1.736
W__:those/3.154
W__:all/3.201
W__:an/2.837
W__:some/3.097
W__:this/2.266
W__:these/3.201
540
575
W__:next/1.854
W__:following/0.227
56T__asean/NULL:<epsilon>/1.098
57
T__imf-2:<epsilon>/1.098
58
T__concerned/NULL#with/NULL:<epsilon>/1.098
161T__-:<epsilon>/0.129
241
263P__NP:<epsilon>/-0
339
377
W__:committee/-0
W__:present/-0
59
T__2:<epsilon>/0.631
60T__2#xslax/NULL:<epsilon>/1.194
162
T__the/NULL#sixth#committee:<epsilon>/0.454
T__the#sixth#committee:<epsilon>/1.871
163
T__sixth#committee:<epsilon>/1.871
242
264
T__by/NULL#the/NULL#general#assembly:<epsilon>/1.085
T__by/NULL#the#general#assembly:<epsilon>/2.725
265T__to/NULL#the/NULL#general#assembly:<epsilon>/1.254
T__to/NULL#the#general#assembly:<epsilon>/2.748
266
T__with/NULL#general#assembly#decision/NULL:<epsilon>/3.313
340 342W__:the/-0
W__:general/-0
675
T__asean/NULL:<epsilon>/1.098
676T__imf-2:<epsilon>/1.098
677T__concerned/NULL#with/NULL:<epsilon>/1.098
61
T__the/NULL#sixth#committee:<epsilon>/0.454
T__the#sixth#committee:<epsilon>/1.871
62
T__sixth#committee:<epsilon>/1.871
164
P__VP:<epsilon>/-0
243
267
P__VP:<epsilon>/-0
341
343
W__:the/-0
W__:assembly/-0
678
W__:the/1.188
W__:that/2.597
W__:a/1.736
W__:those/3.154
W__:all/3.201
W__:an/2.837
W__:no/3.547
W__:any/3.434
W__:some/3.097
W__:this/2.266
W__:these/3.201
W__:every/4.241
W__:another/4.082
63T__728#xslax/NULL:<epsilon>/1.421
64
T__the/NULL#committee:<epsilon>/1.981 65
T__the/NULL#advisory#committee:<epsilon>/2.268
66T__729#xslax/NULL:<epsilon>/2.674
165P__VP:<epsilon>/-0
244
268
P__NP:<epsilon>/-0
564
W__:wish/-0
344 346
W__:the/-0
67
T__recommends:<epsilon>/0.227
166
T__-:<epsilon>/0.129
245
269
P__NP:<epsilon>/-0
432
461
W__:the/1.188
345
347
W__:the/-0
597
G__:<epsilon>/-0
712
723
W__:next/1.854
W__:following/0.227
68T__that:<epsilon>/-0
167T__-:<epsilon>/0.129
246
270
T__the/NULL#general#assembly:<epsilon>/0.530
T__the#general#assembly:<epsilon>/2.122
271
T__the/NULL#assembly:<epsilon>/1.941
433
462
W__:on/2.046
W__:of/2.238
W__:by/1.908
W__:under/3.942
W__:at/3.536
W__:in/1.425
W__:that/4.161
W__:with/1.853
W__:for/3.134
W__:as/2.616
482
510
W__:adoption/0.711
348
368
W__:accountable/-0
598
W__:next/1.854
W__:following/0.227
69T__2:<epsilon>/0.631
70T__2#xslax/NULL:<epsilon>/1.194
168P__VP:<epsilon>/-0
274T__accountable:<epsilon>/0.693
275T__present/NULL:<epsilon>/0.693
434
463
W__:on/2.046
W__:of/2.238
W__:by/1.908
W__:under/3.942
W__:at/3.536
W__:in/1.425
W__:that/4.161
W__:with/1.853
W__:for/3.134
W__:as/2.616
483
511
W__:adoption/0.711
W__:provision/1.929
349 W__:present/-0
72T__the/NULL#sixth#committee:<epsilon>/0.454
T__the#sixth#committee:<epsilon>/1.871
73T__sixth#committee:<epsilon>/1.871
169T__the/NULL#sixth#committee:<epsilon>/0.154
170
T__will#establish:<epsilon>/1.945
276P__PPNP:<epsilon>/-0
435
464
W__:in/1.425
350
380
W__:2/-0
541
W__:the/0.132
679
W__:the/1.188
W__:that/2.597
W__:a/1.736
W__:those/3.154
W__:all/3.201
W__:an/2.837
W__:no/3.547
W__:any/3.434
W__:some/3.097
W__:this/2.266
W__:these/3.201
W__:every/4.241
W__:another/4.082
74T__the/NULL#general#assembly:<epsilon>/0.530
T__the#general#assembly:<epsilon>/2.122
75
T__the/NULL#assembly:<epsilon>/1.941
171T__by/NULL#the/NULL#sixth#committee:<epsilon>/0.490
T__by/NULL#the/NULL#sixth/NULL#committee:<epsilon>/1.589
436
465W__:in/1.425
277
P__NP:<epsilon>/-0
351
W__:article/-0
78T__-:<epsilon>/0.129
172
T__the/NULL#sixth#committee:<epsilon>/0.454
T__the#sixth#committee:<epsilon>/1.871
173
T__sixth#committee:<epsilon>/1.871
437
466
W__:on/2.046
W__:of/2.238
W__:by/1.908
W__:under/3.942
W__:at/3.536
W__:in/1.425
W__:with/1.853
W__:for/3.134
W__:as/2.616
250
W__:committee/-0
352
W__:review/-0
71
T__-:<epsilon>/0.129
438
467
W__:in/1.425
W__:with/1.853
278
G__:<epsilon>/-0
353
381
W__:2/-0
79
T__-:<epsilon>/0.129
174
T__-:<epsilon>/0.129
468
W__:-/-0
599
W__:rapporteur/0.699
W__:decision/1.000
T__the/NULL#general#assembly:<epsilon>/0.938
279
T__had#decided:<epsilon>/2.442
280T__will#consider:<epsilon>/2.442
354 W__:only/-0
80
T__the/NULL#sixth#committee:<epsilon>/0.454
T__the#sixth#committee:<epsilon>/1.871 81
T__sixth#committee:<epsilon>/1.871
175
T__2:<epsilon>/0.631
176T__2#xslax/NULL:<epsilon>/1.194
W__:recommends/-0
484
512
W__:adoption/0.711
281
P__PPNP:<epsilon>/-0
355 W__:order/-0
82
T__to/NULL#2/NULL:<epsilon>/1.299
177
P__VP:<epsilon>/-0
469W__:recommends/-0
485
514
W__:on/2.917
W__:of/1.969
W__:by/2.975
W__:under/4.248
W__:at/3.201
W__:in/2.215
W__:that/2.614
W__:before/4.435
W__:with/3.075
W__:for/2.660
W__:because/4.073
W__:from/3.270
W__:as/3.201
W__:through/4.435
W__:into/3.971
W__:about/3.426
W__:if/3.704
W__:than/4.147
W__:over/4.385
W__:per/3.988
W__:out/4.410
576
600W__::/-0
680
W__:the/1.188
282
W__:on/2.917
W__:of/1.969
W__:by/2.975
W__:at/3.201
W__:in/2.215
W__:that/2.614
W__:with/3.075
W__:for/2.660
W__:because/4.073
W__:from/3.270
W__:as/3.201
W__:into/3.971
W__:about/3.426
W__:if/3.704
W__:than/4.147
W__:per/3.988
356 W__:just/-0
507
542
P__O:<epsilon>/-0
83T__add:<epsilon>/1.704
84
T__take/NULL:<epsilon>/2.397
178
T__IN#NGEN+DT#NN#NGEN+IN#NGEN+DT#JJ#NN#NN:<epsilon>/3.545
179
T__IN#NGEN+DT#NN#NGEN+IN#JJ#NN#NNS:<epsilon>/4.133
180
T__IN#NGEN+DT#NN#NGEN+IN#DT#JJ#NN#NN:<epsilon>/4.895
470
W__:2/-0
577
601
W__:next/1.854
W__:following/0.227
681
W__:the/1.188
W__:a/1.736
T__::<epsilon>/0.028
85
T__the/NULL#sixth#committee:<epsilon>/0.454
T__the#sixth#committee:<epsilon>/1.871
86
T__sixth#committee:<epsilon>/1.871
181T__add:<epsilon>/1.704
182T__take/NULL:<epsilon>/2.397
283
W__:on/2.917
W__:of/1.969
W__:by/2.975
W__:at/3.201
W__:in/2.215
W__:that/2.614
W__:with/3.075
W__:for/2.660
W__:from/3.270
W__:as/3.201
W__:into/3.971
W__:about/3.426
W__:if/3.704
W__:per/3.988
471W__:2/-0
357 W__:regard/-0
486
515
W__:on/2.917
W__:of/1.969
W__:by/2.975
W__:under/4.248
W__:at/3.201
W__:in/2.215
W__:that/2.614
W__:with/3.075
W__:for/2.660
W__:because/4.073
W__:from/3.270
W__:as/3.201
W__:into/3.971
W__:about/3.426
W__:if/3.704
W__:than/4.147
W__:per/3.988
543
W__:the/1.188
W__:that/2.597
W__:a/1.736
W__:those/3.154
W__:all/3.201
W__:an/2.837
W__:no/3.547
W__:any/3.434
W__:some/3.097
W__:this/2.266
W__:these/3.201
87
T__the/NULL#sixth#committee:<epsilon>/0.454
T__the#sixth#committee:<epsilon>/1.871
88T__sixth#committee:<epsilon>/1.871
183T__2:<epsilon>/0.631
184T__2#xslax/NULL:<epsilon>/1.194
472
W__:on/2.046
W__:of/2.238
W__:by/1.908
W__:in/1.425
W__:with/1.853
W__:as/2.616
284
W__:on/2.917
W__:of/1.969
W__:by/2.975
W__:at/3.201
W__:in/2.215
W__:that/2.614
W__:with/3.075
W__:for/2.660
W__:from/3.270
W__:as/3.201
W__:about/3.426
W__:if/3.704
682
W__:the/1.188
W__:that/2.597
W__:a/1.736
W__:those/3.154
W__:all/3.201
W__:an/2.837
W__:no/3.547
W__:any/3.434
W__:some/3.097
W__:this/2.266
W__:these/3.201
W__:another/4.082
W__:the/-0
185
P__VP:<epsilon>/-0
358 382W__:2.7/-0
473
W__:on/2.046
W__:of/2.238
W__:by/1.908
W__:in/1.425
W__:with/1.853
W__:as/2.616
487
516
W__:for/2.660
W__:because/4.073
W__:from/3.270
W__:as/3.201
W__:into/3.971
W__:about/3.426
W__:if/3.704
W__:than/4.147
W__:per/3.988
W__:on/2.917
W__:of/1.969
W__:by/2.975
W__:at/3.201
W__:in/2.215
W__:that/2.614
W__:with/3.075
186
P__VP:<epsilon>/-0
286
T__the/NULL#sixth#committee:<epsilon>/0.454
359 W__:document/-0
W__:on/2.046
W__:of/2.238
W__:by/1.908
W__:in/1.425
W__:with/1.853
89
W__:sixth/-0
488
517
W__:of/1.969
187
P__VP:<epsilon>/-0
288T__the/NULL#sixth#committee:<epsilon>/0.454
T__the#sixth#committee:<epsilon>/1.871
289
T__sixth#committee:<epsilon>/1.871
360
383
W__:the/-0
W__:-/-0
W__:the/-0
490
519
W__:adoption/0.711
W__:provision/1.929
W__:appropriation/3.108
W__:accreditation/3.18
188T__recommends:<epsilon>/0.227
189T__recommended:<epsilon>/2.759
290
P__NP:<epsilon>/-0
361
384
G__:<epsilon>/-0
G__:<epsilon>/-0
578
602
W__:rapporteur/0.699
W__:decision/1.000
713 724W__:the/1.188
90
W__:sixth/-0
190T__recommends:<epsilon>/0.227
191T__recommended:<epsilon>/2.759
192T__recommend:<epsilon>/3.200
291
P__NP:<epsilon>/-0
362
W__:xslax/-0
W__:xslax/-0
580 604W__:sponsors/1.131
91
W__:2/-0
193W__:-/-0
292P__ADJP:<epsilon>/-0
683
W__:the/1.188
W__:a/1.736
725
W__:following/0.227
363
385W__:assembly/-0
W__:the/1.188
W__:that/2.597
W__:a/1.736
W__:those/3.154
W__:all/3.201
W__:an/2.837
W__:any/3.434
W__:some/3.097
W__:this/2.266
W__:these/3.201
92W__:2/-0
W__:the/-0
293
T__to/NULL#2/NULL:<epsilon>/1.299
T__to/NULL#2:<epsilon>/2.397
294
T__with/NULL#article/NULL#2:<epsilon>/2.397
295T__under/NULL#review/NULL:<epsilon>/3.091
296T__by/NULL#2#police/NULL#officers/NULL:<epsilon>/3.091
297T__in/NULL#only/NULL#2:<epsilon>/3.091
298
T__in/NULL#order/NULL:<epsilon>/3.091
299T__for/NULL#just/NULL#2:<epsilon>/3.091
300T__on/NULL#2:<epsilon>/3.091
301
T__at/NULL#2:<epsilon>/3.091
302
T__with/NULL#regard/NULL:<epsilon>/3.091
303
T__for/NULL#2:<epsilon>/3.091
304
T__to/NULL#2.7/NULL#in/NULL:<epsilon>/3.091
305T__in/NULL#document:<epsilon>/3.091
306T__into/NULL#the/NULL#world/NULL#economy/NULL:<epsilon>/3.091
579 603W__:following/0.227
364
386
G__:<epsilon>/-0
W__:the/0.132
W__:a/3.066
93
W__:-/-0
T__2:<epsilon>/0.631
308T__2#xslax/NULL:<epsilon>/1.194
309
T__it/NULL:<epsilon>/3.818
581 605W__:2/-0
194W__:sixth/-0
W__:by/-0
582 606W__:2/-0
W__:to/-0
W__:the/-0
195
T__recommends:<epsilon>/0.227
316
317
W__:general/-0
491
520
W__:adoption/0.711
W__:provision/1.929
W__:appropriation/3.108
W__:accreditation/3.18
W__:to/-0
583
607W__:rapporteur/0.699
W__:decision/1.000
685
W__:with/-0
196T__recommends:<epsilon>/0.227
197
T__recommended:<epsilon>/2.759
365
W__:assembly/-0
94
W__:sixth/-0
W__:the/1.188
W__:that/2.597
W__:a/1.736
W__:those/3.154
W__:all/3.201
W__:an/2.837
W__:some/3.097
W__:this/2.266
W__:these/3.201
198
W__:-/-0
544
W__:next/1.854
W__:following/0.227
584
608
W__:implications/2.139
W__:sponsors/1.131
W__:projects/2.972
686
W__:under/-0
W__:the/-0
310W__:with/-0
387
G__:<epsilon>/-0
199W__:-/-0
687W__:by/-0
311T__recommends:<epsilon>/0.227
312
T__recommended:<epsilon>/2.759
313T__recommend:<epsilon>/3.200
320
W__:general/-0
585
586
W__:draft/0.404
95W__:sixth/-0
200T__recommends:<epsilon>/0.227
688W__:in/-0
314
T__the/NULL#general#assembly:<epsilon>/0.530
T__the#general#assembly:<epsilon>/2.122
315
T__the/NULL#assembly:<epsilon>/1.941
366W__:assembly/-0
587 610G__:<epsilon>/-0
96
W__:asean/-0
201W__:the/-0
689
W__:in/-0
318
T__the/NULL#general#assembly:<epsilon>/0.530
T__the#general#assembly:<epsilon>/2.122
T__the/NULL#assembly:<epsilon>/1.941
588
611
W__:next/1.854
W__:following/0.227
W__:imf-2/-0
202W__:will/-0
388G__:<epsilon>/-0
W__:the/1.188
W__:that/2.597
W__:a/1.736
W__:those/3.154
W__:an/2.837
W__:some/3.097
W__:this/2.266
492
W__:adoption/0.711
690W__:for/-0
W__:the/-0
97
W__:concerned/-0
203W__:by/-0
389
P__PPNP:<epsilon>/-0
493
W__:adoption/0.711
W__:on/-0
W__:the/-0
98W__:2/-0
494 W__:adoption/0.711
W__:provision/1.929
W__:appropriation/3.108
W__:accreditation/3.18
W__:at/-0
W__:the/-0
99W__:2/-0
W__:accountable/-0
W__:general/-0
691W__:with/-0
W__:the/-0 204
W__:sixth/-0
W__:present/-0
W__:assembly/-0
W__:the/1.188
W__:that/2.597
W__:a/1.736
W__:those/3.154
W__:all/3.201
W__:an/2.837
W__:no/3.547
W__:any/3.434
W__:some/3.097
W__:this/2.266
W__:these/3.201
W__:for/-0
205
W__:-/-0
T__by/NULL#the/NULL#general#assembly:<epsilon>/1.085
T__by/NULL#the#general#assembly:<epsilon>/2.725
T__to/NULL#the/NULL#general#assembly:<epsilon>/1.254
T__to/NULL#the#general#assembly:<epsilon>/2.748
692W__:to/-0
100
W__:sixth/-0
390
G__:<epsilon>/-0
589
612
W__:rapporteur/0.699
W__:decision/1.000
W__:2/-0
T__the/NULL#general#assembly:<epsilon>/0.530
T__the#general#assembly:<epsilon>/2.122
T__the/NULL#assembly:<epsilon>/1.941
693W__:in/-0
101W__:728/-0
W__:the/0.132
206W__:2/-0
P__VP:<epsilon>/-0
391
W__:had/-0
545 W__:following/0.227
613
W__:following/0.227
694W__:into/-0
102
W__:the/-0
207
T__recommends:<epsilon>/0.227
392W__:will/-0
495
W__:adoption/0.711
546
W__:the/0.132
591
614
W__:sponsors/1.131
684W__:-/-0
103W__:the/-0
W__:had/-0
208
W__:on/2.046
W__:of/2.238
W__:by/1.908
W__:at/3.536
W__:in/1.425
W__:with/1.853
W__:for/3.134
W__:as/2.616
W__:the/1.188
W__:that/2.597
W__:a/1.736
W__:those/3.154
W__:all/3.201
W__:an/2.837
W__:no/3.547
W__:any/3.434
W__:some/3.097
W__:this/2.266
W__:these/3.201
496 P__NP:<epsilon>/-0
726
T__::<epsilon>/0.028
W__:729/-0
W__:will/-0
695W__:committee/-0
209
W__:on/2.046
W__:of/2.238
W__:by/1.908
W__:in/1.425
W__:with/1.853
W__:for/3.134
W__:as/2.616
497 P__PPNP:<epsilon>/-0
615W__::/-0
W__:officers/-0
105W__:recommends/-0
T__to/NULL#2/NULL:<epsilon>/1.299
T__to/NULL#2:<epsilon>/2.397
T__with/NULL#article/NULL#2:<epsilon>/2.397
W__:article/-0
W__:2/-0
210
W__:on/2.046
W__:of/2.238
W__:by/1.908
W__:in/1.425
W__:with/1.853
W__:for/3.134
W__:as/2.616
498 P__O:<epsilon>/-0
106
W__:that/-0
W__:the/1.188
W__:that/2.597
W__:a/1.736
W__:those/3.154
W__:all/3.201
W__:an/2.837
W__:some/3.097
W__:this/2.266
W__:these/3.201 393W__:rapporteur/0.699
W__:decision/1.000
616
W__:committee/-0
697
W__:2/-0
W__:economy/-0
211W__:add/-0
107W__:2/-0
499 W__:adoption/0.711
W__:provision/1.929
W__:recommends/-0
728T__recommends:<epsilon>/0.227
W__:take/-0
394W__:implications/2.139
W__:sponsors/1.131
W__:projects/2.972
W__:of/-0
108W__:2/-0
W__:asean/-0
727
T__-:<epsilon>/0.129
T__-/NULL:<epsilon>/2.988
212
W__:2/-0
W__:the/1.188
W__:the/-0
395G__:<epsilon>/-0
W__:imf-2/-0
729
W__:next/1.854
W__:following/0.227
213W__:2/-0
W__:the/1.188
W__:that/2.597
W__:a/1.736
W__:those/3.154
W__:all/3.201
W__:an/2.837
W__:no/3.547
W__:any/3.434
W__:some/3.097
W__:this/2.266
W__:these/3.201
500
W__:adoption/0.711
W__:provision/1.929
617
W__:following/0.227
W__:xslax/-0
698W__:concerned/-0
110W__:sixth/-0
214T__recommends:<epsilon>/0.227
396
G__:<epsilon>/-0
699
W__:adoption/0.711
W__:provision/1.929
W__:approval/3.758
W__:appropriation/3.108
W__:accreditation/3.18
W__:dependence/3.758
W__:reliance/3.746
76W__:the/-0
215
T__recommends:<epsilon>/0.227
W__:adoption/0.711
547 W__:the/0.132
397
G__:<epsilon>/-0
513 548P__NP:<epsilon>/-0
618
W__:rapporteur/0.699
W__:decision/1.000
77W__:the/-0
216
T__recommends:<epsilon>/0.227
W__:general/-0
T__2:<epsilon>/0.631
T__2#xslax/NULL:<epsilon>/1.194
217W__:recommends/-0
P__ADJP:<epsilon>/-0
619W__::/-0
112
W__:-/-0
378W__:assembly/-0
W__:the/1.188
549
W__:next/1.854
W__:following/0.227
W__:recommended/-0
W__:next/1.854
W__:following/0.227
T__the/NULL#general#assembly:<epsilon>/0.530
T__the#general#assembly:<epsilon>/2.122
T__the/NULL#assembly:<epsilon>/1.941
T__the#assembly:<epsilon>/3.641
T__the/NULL#wish/NULL#of/NULL#the/NULL#general#assembly:<epsilon>/3.421
109
W__:-/-0
W__:adoption/0.711
W__:provision/1.929
W__:appropriation/3.108
W__:accreditation/3.18
218
W__:recommends/-0
398G__:<epsilon>/-0
W__:on/2.917
W__:of/1.969
W__:by/2.975
W__:at/3.201
W__:in/2.215
W__:that/2.614
W__:with/3.075
W__:for/2.660
W__:because/4.073
W__:from/3.270
W__:as/3.201
W__:into/3.971
W__:about/3.426
W__:if/3.704
W__:than/4.147
W__:per/3.988
113
W__:-/-0
620
P__PPNP:<epsilon>/-0
730
W__:rapporteur/0.699
W__:decision/1.000
W__:recommended/-0
W__:general/-0
W__:the/-0
W__:on/2.917
W__:of/1.969
W__:by/2.975
W__:at/3.201
W__:in/2.215
W__:that/2.614
W__:with/3.075
W__:for/2.660
W__:because/4.073
W__:from/3.270
W__:as/3.201
W__:into/3.971
W__:about/3.426
W__:if/3.704
W__:per/3.988
621
W__:rapporteur/0.699
W__:decision/1.000
W__:recommend/-0
379
W__:assembly/-0
731
W__:following/0.227
700
W__:adoption/0.711
W__:provision/1.929
W__:approval/3.758
W__:appropriation/3.108
W__:accreditation/3.18
W__:dependence/3.758
W__:reliance/3.746
114W__:sixth/-0
219G__:<epsilon>/-0
W__:on/2.917
W__:of/1.969
W__:by/2.975
W__:at/3.201
W__:in/2.215
W__:that/2.614
W__:with/3.075
W__:for/2.660
W__:from/3.270
W__:as/3.201
W__:about/3.426
W__:if/3.704
622W__:implications/2.139
W__:sponsors/1.131
W__:projects/2.972
732
W__:sponsors/1.131
399
G__:<epsilon>/-0
W__:to/-0
220
W__:committee/-0
W__:on/2.917
W__:of/1.969
W__:by/2.975
W__:under/4.248
W__:at/3.201
W__:in/2.215
W__:that/2.614
W__:before/4.435
W__:with/3.075
W__:for/2.660
W__:because/4.073
W__:from/3.270
W__:as/3.201
W__:through/4.435
W__:into/3.971
W__:about/3.426
W__:between/4.602
W__:during/4.572
W__:if/3.704
W__:than/4.147
W__:over/4.385
W__:per/3.988
W__:out/4.410
550
W__:rapporteur/0.699
W__:decision/1.000
623
G__:<epsilon>/-0
W__:add/-0
221
W__:recommends/-0
400G__:<epsilon>/-0
W__:adoption/0.711
W__:provision/1.929
624W__:rapporteur/0.699
W__:decision/1.000
733
W__::/-0
W__:take/-0
222
W__:recommends/-0
W__:the/0.132
551
W__:following/0.227
W__:the/-0
W__:on/2.917
W__:of/1.969
W__:by/2.975
W__:under/4.248
W__:at/3.201
W__:in/2.215
W__:that/2.614
W__:before/4.435
W__:with/3.075
W__:for/2.660
W__:because/4.073
W__:from/3.270
W__:as/3.201
W__:through/4.435
W__:into/3.971
W__:about/3.426
W__:if/3.704
W__:than/4.147
W__:over/4.385
W__:per/3.988
W__:out/4.410
625
W__:implications/2.139
W__:sponsors/1.131
W__:projects/2.972
W__:recommended/-0
401W__:police/-0
552 W__::/-0
W__:recommends/-0
115
W__:sixth/-0
223G__:<epsilon>/-0
553
W__:the/1.188
W__:that/2.597
W__:a/1.736
W__:those/3.154
W__:all/3.201
W__:an/2.837
W__:no/3.547
W__:any/3.434
W__:some/3.097
W__:this/2.266
W__:these/3.201
W__:draft/0.404
W__:-/-0
W__:the/-0
G__:<epsilon>/-0
W__:of/1.969
626
W__:of/1.969
701W__:adoption/0.711
734
W__:rapporteur/0.699
W__:decision/1.000
W__:recommends/-0
W__:in/-0
W__:on/2.917
W__:of/1.969
W__:by/2.975
W__:under/4.248
W__:at/3.201
W__:in/2.215
W__:that/2.614
W__:with/3.075
W__:for/2.660
W__:because/4.073
W__:from/3.270
W__:as/3.201
W__:into/3.971
W__:about/3.426
W__:if/3.704
W__:than/4.147
W__:per/3.988
627G__:<epsilon>/-0
W__:adoption/0.711
W__:sixth/-0
W__:sixth/-0
W__:adoption/0.711
W__:provision/1.929
W__:xslax/-0
735
W__:articles/3.975
W__:implications/2.139
W__:sponsors/1.131
W__:projects/2.972
W__:co-sponsors/3.808
402W__:world/-0
W__:of/1.969
W__:adoption/0.711
W__:provision/1.929
W__:appropriation/3.108
W__:accreditation/3.18
W__:committee/-0
W__:establish/-0
256
285P__NP:<epsilon>/-0
W__:draft/0.404
W__:project/1.841
403P__O:<epsilon>/-0
W__:the/1.188
W__:that/2.597
W__:a/1.736
W__:those/3.154
W__:all/3.201
W__:an/2.837
W__:no/3.547
W__:any/3.434
W__:some/3.097
W__:this/2.266
W__:these/3.201
W__:draft/0.404
W__:the/-0
T__2:<epsilon>/0.631
T__2#xslax/NULL:<epsilon>/1.194
W__:committee/-0
489G__:<epsilon>/-60
736
W__:of/1.969
W__:in/2.215
W__:that/2.614
W__:for/2.660
W__:the/-0
W__:decision/-0G__:<epsilon>/-0
W__:committee/-0 737G__:<epsilon>/-0
W__:the/-0
404P__NP:<epsilon>/-0
W__:xslax/-0
G__:<epsilon>/-0
609
W__:of/1.969
405
P__PPNP:<epsilon>/-0
W__:adoption/0.711
G__:<epsilon>/-0
W__:sixth/-0
W__:rapporteur/0.699
W__:draft/0.404
W__:resolution/3.339
W__:project/1.841
W__:xslax/-0
406
P__PPNP:<epsilon>/-0
W__:the/1.188
W__:that/2.597
W__:a/1.736
W__:those/3.154
W__:all/3.201
W__:an/2.837
W__:no/3.547
W__:any/3.434
W__:some/3.097
W__:this/2.266
W__:these/3.201
T__the/NULL#general#assembly:<epsilon>/0.530
T__the#general#assembly:<epsilon>/2.122
T__the/NULL#assembly:<epsilon>/1.941
628P__NP:<epsilon>/-0
W__:committee/-0
W__:recommends/-0
407T__IN#NGEN+DT#NN#NGEN+IN#NGEN+DT#JJ#NN#NN:<epsilon>/3.545
408
T__IN#NGEN+DT#NN#NGEN+IN#JJ#NN#NNS:<epsilon>/4.133
409
T__IN#NGEN+DT#NN#NGEN+IN#DT#JJ#NN#NN:<epsilon>/4.895
410
T__IN#NGEN+DT#NN#NGEN+IN#DT#JJ#NN#NGEN+IN#NN:<epsilon>/5.049
W__:adoption/0.711
G__:<epsilon>/-60
T__the/NULL#general#assembly:<epsilon>/0.530
T__the/NULL#assembly:<epsilon>/1.941
629
W__:rapporteur/0.699
W__:decision/1.000
W__:the/1.188
W__:that/2.597
W__:a/1.736
W__:those/3.154
W__:all/3.201
W__:an/2.837
W__:some/3.097
W__:this/2.266
W__:these/3.201
411
P__PPNP:<epsilon>/-0
W__:committee/-0
T__accountable:<epsilon>/0.693
T__present/NULL:<epsilon>/0.693
W__:decided/-0
W__:implications/2.139
W__:sponsors/1.131
W__:projects/2.972
W__:co-sponsors/3.808
W__:article/-0
G__:<epsilon>/-0
W__:to/-0
W__:consider/-0
W__:review/-0
W__:with/-0
W__:draft/0.404
W__:rapporteur/0.699
W__:decision/1.000
W__:with/-0
554
W__:next/1.854
W__:following/0.227
W__:2/-0
W__:draft/0.404
W__:project/1.841
W__:the/1.188
W__:that/2.597
W__:a/1.736
W__:those/3.154
W__:all/3.201
W__:an/2.837
W__:no/3.547
W__:any/3.434
W__:some/3.097
W__:this/2.266
W__:these/3.201
W__:of/1.969
W__:in/2.215
G__:<epsilon>/-0
W__:under/-0
W__:only/-0
W__:the/1.188
W__:that/2.597
W__:a/1.736
W__:those/3.154
W__:all/3.201
W__:an/2.837
W__:some/3.097
W__:this/2.266
W__:these/3.201
W__:next/1.854
W__:following/0.227
G__:<epsilon>/-0
W__:xslax/-0
W__:by/-0
G__:<epsilon>/-60
W__:order/-0
738/0<epsilon>:</s>/-0
G__:<epsilon>/-0
W__:in/-0
W__:just/-0
W__:committee/-0
W__:rapporteur/0.699
W__:decision/1.000
W__:in/-0
P__O:<epsilon>/-0
W__:xslax/-0
W__:implications/2.139
W__:sponsors/1.131
W__:for/-0
W__:regard/-0
W__:committee/-0
W__:the/1.188
W__:that/2.597
W__:a/1.736
W__:an/2.837
W__:some/3.097
W__:this/2.266
P__VP:<epsilon>/-0
W__:on/-0
W__:the/1.188
G__:<epsilon>/-0
W__:advisory/-0
P__VP:<epsilon>/-0
W__:2.7/-0
W__:at/-0
W__:the/1.188
T__IN#NGEN+DT#NN#NGEN+IN#NGEN+DT#JJ#NN#NN:<epsilon>/3.545
T__IN#NGEN+DT#NN#NGEN+IN#JJ#NN#NNS:<epsilon>/4.133
T__IN#NGEN+DT#NN#NGEN+IN#NGEN+DT#JJ#NN#NGEN+IN#NN:<epsilon>/4.443
T__IN#NGEN+DT#NN#NGEN+IN#JJ#NNS#NGEN+IN#NN:<epsilon>/4.644
T__IN#NGEN+DT#NN#NGEN+IN#DT#JJ#NN#NN:<epsilon>/4.895
T__IN#NGEN+DT#NN#NGEN+IN#DT#JJ#NN#NGEN+IN#NN:<epsilon>/5.049
P__NP:<epsilon>/-0
W__:document/-0
G__:<epsilon>/-0
W__:with/-0
W__:the/1.188
W__:that/2.597
W__:a/1.736
W__:those/3.154
W__:all/3.201
W__:an/2.837
W__:no/3.547
W__:any/3.434
W__:some/3.097
W__:this/2.266
W__:these/3.201
W__:draft/0.404
W__:project/1.841
P__PPNP:<epsilon>/-0
W__:the/-0
G__:<epsilon>/-0
W__:for/-0
G__:<epsilon>/-0
P__O:<epsilon>/-0
G__:<epsilon>/-60
G__:<epsilon>/-0
G__:<epsilon>/-0
W__:to/-0
W__:officers/-0
W__:the/0.132
G__:<epsilon>/-0
W__:xslax/-0
G__:<epsilon>/-0
W__:in/-0
P__PPNP:<epsilon>/-0
G__:<epsilon>/-0
G__:<epsilon>/-0
W__:xslax/-0
W__:into/-0
W__:economy/-0
W__:draft/0.404
W__:project/1.841
W__:xslax/-0
W__:recommends/-0
W__:2/-0
T__-:<epsilon>/0.129
T__-/NULL:<epsilon>/2.988
W__:the/1.188
W__:the/1.188
W__:committee/-0
W__:recommends/-0
W__:2/-0
W__:following/0.227
G__:<epsilon>/-60
W__:general/-0
T__2:<epsilon>/0.631
T__2#xslax/NULL:<epsilon>/1.194
G__:<epsilon>/-0
W__:recommends/-0
W__:it/-0
W__:with/-0
111W__:assembly/-0
T__IN#NGEN+DT#NN#NGEN+IN#NGEN+DT#JJ#NN#NN:<epsilon>/3.545
T__IN#NGEN+DT#NN#NGEN+IN#JJ#NN#NNS:<epsilon>/4.133
T__IN#NGEN+DT#NN#NGEN+IN#DT#JJ#NN#NN:<epsilon>/4.895
W__:the/0.132
G__:<epsilon>/-0
G__:<epsilon>/-0
W__:on/2.917
W__:of/1.969
W__:against/4.731
W__:by/2.975
W__:under/4.248
W__:at/3.201
W__:in/2.215
W__:that/2.614
W__:after/4.880
W__:before/4.435
W__:with/3.075
W__:for/2.660
W__:because/4.073
W__:from/3.270
W__:as/3.201
W__:up/5.208
W__:without/5.054
W__:since/5.054
W__:so/5.103
W__:through/4.435
W__:into/3.971
W__:about/3.426
W__:between/4.602
W__:like/4.665
W__:during/4.572
W__:whether/4.697
W__:if/3.704
W__:than/4.147
W__:over/4.385
W__:per/3.988
W__:out/4.410
W__:within/4.766
W__:upon/5.054
W__:across/5.208
T__IN#NGEN+DT#NN#NGEN+IN#NGEN+DT#JJ#NN#NN:<epsilon>/3.545
T__IN#NGEN+DT#NN#NGEN+IN#JJ#NN#NNS:<epsilon>/4.133
T__IN#NGEN+DT#NN#NGEN+IN#JJ#NNS#NGEN+IN#NN:<epsilon>/4.644
T__IN#NGEN+DT#NN#NGEN+IN#DT#JJ#NN#NN:<epsilon>/4.895
T__IN#NGEN+DT#NN#NGEN+IN#DT#JJ#NN#NGEN+IN#NN:<epsilon>/5.049
W__:rapporteur/0.699
G__:<epsilon>/-0
W__:general/-0
G__:<epsilon>/-0
G__:<epsilon>/-0
W__:on/2.046
W__:of/2.238
W__:by/1.908
W__:at/3.536
W__:in/1.425
W__:with/1.853
W__:for/3.134
W__:as/2.616
P__O:<epsilon>/-0
G__:<epsilon>/-0
W__:recommends/-0
W__:xslax/-0
W__:on/2.046
W__:of/2.238
W__:by/1.908
W__:at/3.536
W__:in/1.425
W__:with/1.853
W__:for/3.134
W__:as/2.616
G__:<epsilon>/-0
W__:recommended/-0
W__:the/1.188
W__:that/2.597
W__:a/1.736
W__:this/2.266
W__:the/0.132
P__PPNP:<epsilon>/-0
W__:on/2.046
W__:of/2.238
W__:by/1.908
W__:at/3.536
W__:in/1.425
W__:with/1.853
W__:for/3.134
W__:as/2.616
518P__O:<epsilon>/-0
W__:recommend/-0
W__:on/2.917
W__:of/1.969
W__:against/4.731
W__:by/2.975
W__:under/4.248
W__:at/3.201
W__:in/2.215
W__:that/2.614
W__:after/4.880
W__:before/4.435
W__:with/3.075
W__:for/2.660
W__:because/4.073
W__:from/3.270
W__:as/3.201
W__:without/5.054
W__:since/5.054
W__:through/4.435
W__:into/3.971
W__:about/3.426
W__:between/4.602
W__:like/4.665
W__:during/4.572
W__:whether/4.697
W__:if/3.704
W__:than/4.147
W__:over/4.385
W__:per/3.988
W__:out/4.410
W__:within/4.766
W__:upon/5.054
W__:committee/-0
G__:<epsilon>/-0
W__:in/1.425
T__::<epsilon>/0.028
W__:the/-0
T__the/NULL#sixth#committee:<epsilon>/0.454
T__the#sixth#committee:<epsilon>/1.871
T__sixth#committee:<epsilon>/1.871
G__:<epsilon>/-0
T__IN#NGEN+DT#NN#NGEN+IN#NGEN+DT#JJ#NN#NN:<epsilon>/3.545
T__IN#NGEN+DT#NN#NGEN+IN#JJ#NN#NNS:<epsilon>/4.133
T__IN#NGEN+DT#NN#NGEN+IN#NGEN+DT#JJ#NN#NGEN+IN#NN:<epsilon>/4.443
T__IN#NGEN+DT#NN#NGEN+IN#JJ#NNS#NGEN+IN#NN:<epsilon>/4.644
T__IN#NGEN+DT#NN#NGEN+IN#DT#JJ#NN#NN:<epsilon>/4.895
T__IN#NGEN+DT#NN#NGEN+IN#DT#JJ#NN#NGEN+IN#NN:<epsilon>/5.049
W__:on/2.917
W__:of/1.969
W__:against/4.731
W__:by/2.975
W__:under/4.248
W__:at/3.201
W__:in/2.215
W__:that/2.614
W__:before/4.435
W__:with/3.075
W__:for/2.660
W__:because/4.073
W__:from/3.270
W__:as/3.201
W__:through/4.435
W__:into/3.971
W__:about/3.426
W__:between/4.602
W__:like/4.665
W__:during/4.572
W__:whether/4.697
W__:if/3.704
W__:than/4.147
W__:over/4.385
W__:per/3.988
W__:out/4.410
W__:within/4.766
W__:the/-0
W__:draft/0.404
W__:project/1.841
G__:<epsilon>/-0
W__:the/1.188
W__:a/1.736
W__:this/2.266
W__:committee/-0
W__:the/-0
G__:<epsilon>/-60
P__NP:<epsilon>/-0
W__:on/2.917
W__:of/1.969
W__:by/2.975
W__:under/4.248
W__:at/3.201
W__:in/2.215
W__:that/2.614
W__:before/4.435
W__:with/3.075
W__:for/2.660
W__:because/4.073
W__:from/3.270
W__:as/3.201
W__:through/4.435
W__:into/3.971
W__:about/3.426
W__:between/4.602
W__:like/4.665
W__:during/4.572
W__:whether/4.697
W__:if/3.704
W__:than/4.147
W__:over/4.385
W__:per/3.988
W__:out/4.410
W__:of/1.969
W__:in/2.215
Figure 2: A portion of the translation model for an Arabic test sen-
tence, compacted and aggressively pruned by path probability for dis-
play purposes.
6 Evaluation
Results Tables A and B below list evaluation results for
translation on the Arabic and French test sets respec-
tively. In each case, results for a comparison system ?
the Giza++ IBM Model 4 implementation (Och and Ney,
2000) with the ReWrite decoder (Marcu and Germann,
2002) ? are included as a benchmark. Results were gen-
erated for training corpora of varying sizes. For Arabic,
we ran our system on two large subsets of the UN cor-
pus and evaluated on a 200-sentence held-out set (refer
to Results Table A below). For the 150K sentence Ara-
bic training set, Giza++ and the shallow syntax model
achieved very similar performance. We were unable to
obtain evaluation numbers for Giza++/ReWrite on the
large Arabic training set, however, since its language
model component has a vocabulary size limit which was
exceeded in the larger corpus. In French we observed the
systems to perform similarly on the small training sets
we used (Results Table B). We performed some exper-
iments in classifier combination using the two compat-
ible (150K-training-sentence) Arabic systems, wherein
a small devtest set was used to identify simple system
combination parameters based on model confidence and
sentence length. In situations where our system was con-
fident we used its output, and used Giza++ output other-
wise. We achieved a 3% boost in Bleu score over Giza++
performance on the evaluation set with these very sim-
ple classifier combination techniques, and anticipate that
research in this direction ? classifier combination of di-
versely trained SMT systems ? could yield significant
performance improvements.
Bleu Score
System 150K 500K
Trn. Sent. Trn. Sent.
Giza++/ReWrite Decoder 0.17 *
2-level Syntax Model 0.17 0.18
Results Table A: Results comparison for Arabic to English
translation on the UN corpus, with a 200-sentence evaluation
set. Note that Giza++/ReWrite cannot be run for the 500K
sentence training set; the CMU Language Modeling Toolkit,
which ReWrite uses, has a vocabulary size limit which is
exceeded in the 500K corpus.
Bleu Score
System 5K 20K
Trn. Sent. Trn. Sent.
Giza++/ReWrite Decoder 0.08 0.11
2-level Syntax Model 0.08 0.09
Results Table B: Results comparison for French to English
translation on the Canadian Hansards corpus (200-sentence
evaluation set).
7 Conclusions
We have described and implemented an original syntax-
based statistical translation model that yields baseline re-
sults which compete successfully with other state-of-the-
art SMT models. This is particularly encouraging in that
the authors are not well-versed in Arabic or French and
it appears that the quality of the rule-based phrase chun-
kers we developed in a single person-day offers substan-
tial room for improvement. We expect to be able to at-
tain improved bracketings from native speakers and, in
addition, via translingual projection of existing brack-
eters. Secondly, the lemma model we have proposed for
lexical transfer provides an efficient framework for in-
tegrating electronic dictionaries into SMT models. Al-
though we have at this time no large electronic dictionar-
ies for either Arabic or French, efforts are underway to
acquire electronic or scanned paper dictionaries for this
purpose. We did evaluate the lemma models in isola-
tion for French and Arabic without dictionary inclusion,
but in each experiment the results did not differ signifi-
cantly from the word-specific lexical transfer models, de-
spite their substantially reduced dimensionality. We an-
ticipate that the relatively seamless direct incorporation
of dictionaries into the lemma-based models will be par-
ticularly effective for translating low-density languages,
which suffer from data sparseness in the face of limited
parallel text. Finally, we incorporated lexical translation
coercion models into this full SMT framework, the in-
duction of which is a phenomenon of interest in its own
right.
8 Acknowledgements
This work was supported in part by NSF grant number IIS-9985033. In
addition, we owe many thanks to colleagues who generously lent their
time and insights. David Smith shared his tools for Arabic part-of-
speech tagging and morphological analysis and answered many ques-
tions about the Arabic language. Thanks to Skankar Kumar and San-
jeev Khudanpur for numerous helpful discussions.
9 References
H. Alshawi, S. Bangalore, and S. Douglas. 2000. Learning depen-
dency translation models as collections of finite state head transducers
Computational Linguistics, 26(1), 45?60.
S. Bangalore and G. Riccardi. 2000. Stochastic finite-state models for
spoken language machine translation. In Proceedings of the Workshop
on Embedded Machine Translation Systems., pp. 52?59.
P. Brown, S. Della Pietra, V. Della Pietra and R. Mercer. 1993. The
mathematics of statistical machine translation: Parameter estimation.
Computational Linguistics, 12(2), 263?312.
S. Cucerzan and D. Yarowsky. 2002. Bootstrapping a Multilingual
Part-of-speech Tagger in One Person-day. Proceedings of the Sixth
Conference on Natural Language Learning (CoNLL), Taipei, 2002.
B. Dorr and N. Habash. 2002. Interlingua approximation: A
generation-heavy approach. In Proceedings of AMTA-2002.
W. A. Gale and K. W. Church. 1991. A Program for Aligning
Sentences in Bilingual Corpora. In 29th Annual Meeting of the ACL,
Berkeley, CA.
N. Habash and B. Dorr. 2003. A categorial variation database for
English. In Proceedings of NAACL-HLT 2003
D. Jones and R. Havrilla. 1998. Twisted pair grammar: Support for
rapid development of machine translation for low density languages.
In Proceedings of AMTA98, pp. 318?332.
D. Marcu and U. Germann. 2002. The ISI ReWrite Decoder Release
0.7.0b. http://www.isi.edu/licensed-sw/rewrite-decoder/.
M. Marcus, B. Santorini, and M. Marcinkiewicz. 1993. Building a
large annotated corpus of English: the Penn Treebank. Computational
Linguistics, Vol. 19.
M. Mohri, F. Pereira, and M. Riley. 1997.
ATT General-purpose finite-state machine software tools.
http://www.research.att.com/sw/tools/fsm/.
G. Ngai and R. Florian. Transformation-based learning in the fast lane.
In Proceedings of North Americal ACL 2001, pages 40-47, June 2001.
F. J. Och and H. Ney. 2000. Improved statistical alignment models.
In Proceedings of the 38th Annual Meeting of the Association for
Computational Linguistics, pages 440?447.
F.J. Och, C. Tillmann, H. Ney. Improved Alignment Models for
Statistical Machine Translation. In Proceedings of EMNLP 1999, pp.
20-28.
K. Papineni, S. Roukos, T. Ward, and W. Zhu. 2001. Bleu: a method
for automatic evaluation of machine translation. Technical Report
RC22176 (W0109-022), IBM Research Division.
A. Stolcke. 2002. SRILM - an extensible language modeling
toolkit. In Proceedings of the International Conference on Spo-
ken Language Processing, pages 901-904. Denver, CO, USA.
http://www.speech.sri.com/projects/srilm/.
D. Wu. 1997. Stochastic inversion transduction grammars and
bilingual parsing of parallel corpora. Computational Linguistics,
23(3), 377?404.
K. Yamada and K. Knight. 2001. A syntax-based statistical translation
model. In Proceedings of ACL-2001, pp. 523?529.
K. Yamada and K. Night. 2002. A decoder for syntax-based statistical
MT In Proceedings of ACL-2002, pp. 303?310.
Word Translation Probabilities
Word translation for mangeait conditioned on
French Word, EnglishPOS
mangeait VBG eating 1.00
mangeait VB go 0.50
mangeait VB anticipate 0.50
mangeait VBD were 1.00
mangeait VBP knelt 1.00
mangeait NN bill 1.00
Word translation for mangeait conditioned on
French Word, English Coarse POS
mangeait V eating 0.44
mangeait V were 0.22
mangeait V knelt 0.11
mangeait V go 0.11
mangeait V anticipate 0.11
mangeait N bill 1.00
Word translation for mangeait conditioned on
French Word only
mangeait eating 0.29
mangeait were 0.14
mangeait go 0.07
mangeait bill 0.07
Word translation for mangeant
conditioned on French Word, EnglishPOS
mangeant RB mostly 1.00
mangeant JJ final 1.00
mangeant VBN obtained 1.00
mangeant VBG eating 1.00
mangeant WP who 1.00
mangeant IN through 1.00
mangeant NN lard 1.00
mangeant VBZ eats 0.50
mangeant VBZ comes 0.50
Lemma Translation Probabilities
Generation of a verb lemma given manger
manger V eat 0.60
manger V feed 0.05
manger V have 0.04
Generation of a noun lemma given manger
manger N meal 0.06
manger N trough 0.04
manger N loaf 0.04
manger N food 0.04
Generation of an adj. lemma given manger
manger J hungry 0.33
Raw lemma translation probabilities
(ignoring English Coarse POS)
manger eat 0.28
manger to 0.03
manger feed 0.03
manger out 0.02
manger have 0.02
manger are 0.02
manger , 0.02
manger you 0.01
manger meal 0.01
Table 9: Direct generation (word-to-word translation probabilities
at the various levels of backoff) is contrasted with lemma generation.
Manger (?to eat?) is a relatively rare word in the Hansards. Note that
due to low counts, the desired verb POS (target of generation) for ?eat?
may not have been observed as a translation in training data. In addi-
tion, in this situation, noisy word alignments may cause an incorrect
translation to have similar estimated translation probability. This prob-
lem is addressed by the lemma model; note the much sharper probabil-
ity distribution for verb lemmas given manger. Generation of English
inflections given lemma and target POS is algorithmic (and irregular
exceptions are handled via a lookup table).
French Wd. Eng. POS Eng. Wd. Prob.
accepter JJ unacceptable 0.12
accepter JJ acceptable 0.12
accepter JJ willing 0.11
accepter JJ ready 0.03
accepter NN acceptance 0.09
accepter NN amendment 0.03
droit VBN entitled 0.66
droit VBN allowed 0.09
droit VBN denied 0.03
droit VBN given 0.02
droit VBN permitted 0.02
droit VBN justified 0.01
droit VBN qualified 0.01
droit VBN allotted 0.01
droit VB qualify 0.14
droit VB be 0.11
droit VB have 0.09
droit VB receive 0.08
droit VB get 0.07
droit VB expect 0.03
droit VBG receiving 0.11
droit VBG getting 0.08
droit NNS rights 0.44
droit NNS benefits 0.69
Table 10: Examples of word translation coercions. Co-
ercions of the French verb accepter ?to accept? and the
French noun droit ?right? (there is parallel polysemy be-
tween the two languages for this word, but the predom-
inant sense in our corpus is the philosophical/judicial
sense, as opposed to the direction).
Eng. Phrase French Eng. Prob.
Type Phrase Phrase
NP dans le cas pre?sent a situation 0.25
NP dans le cas pre?sent the subject of debate 0.25
NP dans le cas pre?sent the position 0.25
NP dans le cas pre?sent it 0.25
VP dans le cas pre?sent should apply 1.00
ADVP dans le cas pre?sent really 1.00
PPNP dans le cas pre?sent in this case 0.63
PPNP dans le cas pre?sent in this instance 0.04
PPNP dans le cas pre?sent in this actual case 0.04
PPNP dans le cas pre?sent in this particular case 0.04
PPNP dans le cas pre?sent in that case 0.04
PPNP dans le cas pre?sent in the present circumstances 0.04
VP acceptons accept 0.48
VP acceptons agree 0.14
NP acceptons this consent 1.00
PPNP par an per year 0.67
PPNP par an in each year 0.03
PPNP par an for a year 0.03
ADVP par an annually 1.00
NP par an a year 0.79
NP par an each year 0.02
NP un discours a speech 0.83
NP un discours an address 0.05
VP un discours to speak 1.00
Table 11: Examples of direct phrase translations (see Ta-
ble 4(1)), including some coercions.
