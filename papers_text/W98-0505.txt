t 
Types of syntagmatic grammatical relations and their 
representation 
E lke  Te ich  
Inst i tute of Applied Linguistics, Translation and Interpreting 
University of the Saarland 
66041 Saarbriicken 
Germany 
e lke~dude,  un i - sb ,  de 
Abst rac t  
The paper reviews the kinds of representation f 
syntagmatic grammatical relations typically em- 
pl~'ed in grammar models used in computa- 
tional linguistics. Exemplars of dependency- 
only, constituency-only and hybrid constituency- 
dependency approaches will be considered. In a 
move away fi'om the much discussed question 'Con- 
stituency or dependency?', the purpose of the paper 
is to ask more radically: 'Are constituency and de- 
pendency sufficient at all to represent the kinds of 
syntagmatic patterning we find in language?' Dis- 
cussing three problem cases for representation with 
constituency/dependency - coordinate structure, in- 
formation structure and agreement, I argue for a 
more diversified view of syntagmatic structure. 
1 In t roduct ion :  the  goa ls  o f  th i s  
paper  
The paper reviews the kinds of syntagmatic gram- 
matical relations typically acknowledged in gram- 
mar models used in computational linguistics and 
the kinds of means employed for their represen- 
tation. The kinds of representation f syntag- 
matic structure can be broadly classified into three 
types: dependency, constituency and hybrid con- 
stituency/dependency approaches. Here, the follow- 
ing are considered in particular as representatives of 
these three types: Word Grammar (Hudson, 1984) 
(henceforth w(;) as an example of dependency ap- 
proaches, Categorial Grammar (co) (e.g., (Steed- 
man, 1985; Steedman, 1987; Uszkoreit, 1986) as 
an example of constituency approaches, and Head- 
driven Phrase Structure Grammar (HI'SO) (Pollard 
and Sag, 1987; Pollard and Sag, 1994) as an example 
of hybrid approaches. 
Moving away from the much discussed question 
'Constituency or dependency?', the purpose of the 
paper is to ask more radically: 'Are constituency and 
dependency sufficient for representing all the kinds 
of syntagmatic patterning we find in language?' Fo- 
cusing on three problem cases for representation 
with constituency/dependency --  oordinate struc- 
ture, information structure and syntactic agreement, 
I argue for a more diversified view of syntagmatic 
structure. 
The paper is organized as follows. Section 2 re- 
views some of the main issues in the 'constituency 
or dependency' debate based on the two positions 
brought forward in (Zwicky, 1985) and (Hudson, 
1987). Section 3 then asks more generally about 
tile limits of dependency, constituency and hybrid 
models, discussing coordinate structure as a prob- 
lem case for dependency approaches and informa- 
tion structure as a problem case for traditional con- 
stituency approaches, and presenting agreement as 
yet another kind of problem case. Section 4 intro- 
duces the view on representating syntagmatic re- 
lations subscribed to Systemic Functional Gram- 
mar (SFG; cf. (Halliday, 1979; Halliday, 1985; 
Matthiessen, 1995)), reflected in the 'modes of ex- 
pression' hypothesis. I will show that with a func- 
tionally diversified model of syntagmatic relations 
such as the one employed in SFG some of the 
representational problems of dependency and con- 
stituency approaches do not arise. Section 5 con- 
cludes the paper with a summary and some implica- 
tions for computational representation a d process- 
ing. 
2 'Const i tuency  or dependency  or  
const i tuency  and dependency? '  -
A br ie f  rev i s i t  
It was shown already quite early in the discussion 
of constituency vs. dependency that dependency 
representations a d constituency representations are
at least weaidy equivalent (Hays, 1964; Gaifman, 
1965; Robinson, 1970). However, the discussion has 
come up again and again bringing forward a num- 
ber of arguments for and against dependency-only/ 
constituency-only and for and against hybrid ap- 
proaches. 
Dependency-only approaches. Dependency- 
only approaches (Tesniere, 1959) maintain that it is 
sufficient o account for the relation between words 
for a syntactic description to be adequate, the word 
being the only syntactic unit acknowledged. Fig- 
39 
I 
I 
I 
I 
I 
I 
I 
I 
l 
I 
l 
I 
l 
I 
I 
I 
I 
I 
I 
V 
She left the possum on the deck 
Figure 1: A dependency structure 
ure 1 shows an example of a syntactic structure re- 
sulting from a dependency analysis. 
The early arguments put forward against the 
dependency-only approach in the areas of linear se- 
quencing (e.g., (Baumgiirtner, 1970)), features and 
categorization of higher nodes, and headless con- 
structions could be largely dismissed. Linear order 
was considered a problem for dependency grammars 
at a time in the development of grammar theory 
when in constituency-based grammars sequence was 
reflected ill tile surface-syntactic ree. 
With removing linear ordering from tree represen- 
tations and formulating sequencing rules separately, 
this was no longer considered a problem for depen- 
dency grammars (cL (Matthews, 1981))..,Moreover, 
higher nodes as domains for rule application have 
been shown not to be necessary because they can 
equally well be formulated on words, e.g., gapping 
rules can be formulated on verbs (Hudson, 1989). 
Furthermore. headless constructions can be circum- 
vented, if the notion of category is broadened so 
that there will be no headless constructions; ee e.g., 
(Hudson, 1980. 194-195). 
Characteristic of current dependency approaches 
like Meaning-Text Models (XtTM:s; (Mel'~uk. 1988)) 
or Word Grammar (Hudson, 1984) is the notion of 
lexicalization: the descriptive burden is in the lex- 
icon, which carries information that acts as con- 
straint on syntactic structure. In particular, the 
notion of valence is often combined with that of de- 
pendency by associating valence with heads, whose 
properties thus become major constraining factors 
on syntactic structure. 
Const i tuency-on ly  approaches.  At the other 
extreme is tile constituency-only position arguing for 
heads not being necessary for syntactic description, 
if constituency relations are accounted for. For an 
example of a traditional constituency structure see 
Figure 2. 
Strong arguments for the constituency-only po- 
sition are brought forward for instance in (Zwicky, 
40 
1985). Zwicky mainly discusses five candidates for 
tile concept of head: the subcategorizand, the seman- 
tic ar~ment, he morphosvntactic locus, the deter- 
minant of concord, and the constituent determining 
government. These notions have to be included in 
any grammar model, if it is to interface with se- 
mantics, the lexicon, and morphology. However, it 
should not be necessary to introduce a separate cate- 
gory 'head', unless it can be sho~a that the head-like 
notions can be generalized int O one category that one 
could then call 'head'. 
Analyzing six syntactic onstructions (Det + N, V 
+ NP, Aux + VP, P + NP, NP + VP, and Comp + 
S), Zwicky shows that the x~arious head-like notions 
represent different, actually competing, analyses of 
syntactic structure. There is identity only between 
the semantic functor, which he has not listed as a 
head candidate, the subcategorizand and the gov- 
ernor. Also, the three additional head-like notions 
that are considered--two of which are often quoted 
as providing operational criteria for headship~ the 
distributional equivalent and the obligatory element, 
the other one representing the head concept of ruler 
used in dependency grammar--are completely new 
concepts that do not harmonize with the other five. 
In conclusion, a head is not only superfluous, but it 
would be a completely different additional category 
whose use for a grammar model is doubtful. 
Hybr id  const i tuency /  dependency  ap- 
proaches. In a reply to (Zwicky, 1985), (Hudson, 
1987) arrives at the opposite conclusion. He argues 
for a different analysis of Zwicky's sample construc- 
tions which reveals that 'head' can be considered a 
uni~'ing category of most of the head-like notions 
brought forth by Zwick): 
As all additional head-like notion Hudson puts 
forward the semantic functor--rather than the se- 
mantic argument--because it is the semantic func- 
tor, ill his view, that must be taken as 'semantically 
characterizing' (Hudson, 1987, 115). The semantic 
argument is thus taken away from the list of can- 
didate heads; and also the determinant of concord 
is removed because there is no dependency im-olved 
in concord, as Hudson maintains. On the basis of 
these a priori alterations, Hudson argues that if all 
the remaining head-like notions were either identical 
with the semantic functor or not applying, then one 
could claim that most of the head-like notions are 
tile same category; and that therefore, a generaliz- 
ing super-category 'head' could be established that 
embraces them all. 
The critical points in (Zwicky, 1985) are removed 
by Hudson's analysis with no contradictions remain- 
ing and he concludes that 'head' is a grammatical 
category on a par with grammatical functions but 
more general, allowing generalizations that can oth- 
ii 
NP 
She 
VP 
V NP 
/ \  
Det N 
I I 
left the possum on 
PP 
P NP 
/ \  
Det N 
I I 
the deck 
Figure 2: A constituency structure 
erwise not be made (cf. (Hudson, 1987, 131)). 
What (Zwicky. 1985) does not realize with his 
starting point and analysis results is that the con- 
vergence of semantic functor, subcategorizand, and 
governor can already be of adrantage. Creating the 
super-category of head for these converging notions 
can provide a general category which can actually be 
used as an anchor for both valence (subcategoriza- 
tion) and government, as well as for semantic role 
assignment, hus providing a straightforward way" of 
interfacing semantics and syntax. 
The identity of semantic functor, subcategorizand 
and governor is actually what underlies the notion 
of head both in MT.XI's as proposed by Meaning Text 
Theory (.XITT) (.Mel'~uk. 1988). a dependency nmdel. 
and I-IPSG (Pollard and Sag, 1987), a hybrid model. 
Ill MT.M'S. governn~ent patterns are associated with 
lexemes that are considered heads in the syntactic 
zone of the lexicon, covering subcategorization a d 
case government, and act as constraint on syntac- 
tic structure. Similarly, in HPSG, SUBCAT lists are 
associated with lexemes that are heads and the sub- 
categorization principle takes care of the 'projection' 
of that information in a phrasal unit. 
The concepts of head and dependency had actu- 
ally been taken up already in early Transformational 
Grammar, e.g., by (Hays, 1964; Robinson, 1970; An- 
derson, 1971), and incorporated in the deep struc- 
ture representation. Most clearly, however, a con- 
cept of head received a special status in X-bar syn- 
tax (Chomsk3, 1970" Jackendoff, 1977), which has 
become the phrase structure model underlying man)" 
current grammar aproaches. For example, in Gov- 
ernment and Binding (GB) theory, X-bar theory is 
a subtheory on a par with Binding Theory, Theta 
Theory', etc., in LFG, c-structure representations are 
based on X-bar. and also HPSG'S syntactic structure 
representations conform to the X-bar scheme. For 
a sample X-bar structure see Figure 3. Similar to 
dependency grammars, X-bar goes together with a 
strong notion of lexicalization, where syntactic on- 
straints are primarily associated with lexemes or lex- 
ical classes and projected to syntactic structure. 
Subcategorization a d government are surely two 
essential aspects of a grammatical description on 
the syntagmatic plane. There are other aspects to 
cover, however; two other kinds of syntagrnatic pat- 
tenting that need to be considered in an exhaus- 
tive treatment of syntagrnatic relations are agree- 
ment and word order. Also, what has not been 
considered in the Zwicky-Hudson debate are com- 
plex syntactic units, such as for example coordinate 
st1~tctures. These potentially present problems for 
hierarchical representations such as dependency and 
constituency, as we will see below in Section 3. 
Coordinate structures are in fact a notorious 
prol)lem for both dependency and constituency ap- 
proaches, and there are numerous proposals of how 
to treat them. Word order, in particular word or- 
der x~riation attributed to information distribution 
is another notorious problem. Agreement, while be- 
ing a well-understood phenomenon, can be a prob- 
lem for a dependency-only analysis. 
Looking at the ~ariety of treatments uggested 
in these areas, it seems that constituency is hard 
pressed to accommodate information structure, that 
the representation of coordinate structure is prob- 
lematic for both constituency and dependency, and 
that agreement cannot be described as involving 
a dependency relation in the strict sense (see Sec- 
tion 3 below). In the next section these observa- 
tions are illustrated iscussing coordinate structure 
in Word Grammar (WG) (Hudson, 1984), informa- 
tion structure in Combinatory Categorial Grammar 
(CCG) (Steedman, 1991) and agreement in Head- 
Driven Phrase Structure Grammar (HPSG) (Pollard 
and Sag, 1994). 
41 
I 
I 
I 
I 
I 
I 
I 
I 
I 
I 
l 
I 
I 
I 
I 
I 
I 
I 
I 
S / \  
NP V'" 
I 
V" 
V NP PP 
She left the possum on the deck 
Figure 3: An X-bar structure 
3 L imi ts  o f  dependency  and  
const i tuency :  Coord inate  
s t ructure ,  in fo rmat ion  s t ructure  
and  agreement  
In this section I illustrate tile problematic nature 
of hierarchical representations, such as constituency 
and dependency, for the representation f coordi- 
nate structure, infornmtion structure and syntactic 
agreement. More particularly. I discuss 
? why coordinate structure is a problem for a de- 
pendency granunar like WG (Section 3.1), 
? why CCG. as an example of constituency-only 
approaches, works quite well with information 
structure (Section 3.2), and 
? why HPSG, a hybrid model, works well for agree- 
ment (Section 3.3). 
3.1 Coord inate  st ructure:  the l imit of  
dependency  in WG 
Word grammar (Hudson, 1984; Fraser and Hudson, 
1992) strives to account for all grammatical relations 
by head-dependent relations. However, there is one 
type of construction where Hudson concedes the ne- 
cessity of constituency: this is the coordinate struc- 
ture, including incomplete conjuncts 1 as in gapping, 
reduced conjunct and right-node raising construc- 
tions. 
While the problem for the ma- 
jority of constituency-based approaches i how to 
accommodate he conjunction in the phrase struc- 
ture representation a d how to deal with phrasally 
incomplete conjuncts, in a dependency grammar the 
IA conjunct is a component part of a coordinate structure 
(Hudson, 1984). 
42 
problem is that there is no unit acknowledged with 
which a coordinate structure can be referred to, since 
conjuncts (and, but, etc) cannot be considered the 
heads (or dependents) of these constructions. For 
coordinate structures, constituency has to be intro- 
duced to wc, so that bracketings uch as I l i ke  
( ( red apples) and (green plums)) become pos- 
sible (el. (Hudson, 1984, 218)). Hudson thus has 
to single out the representation of coordinate struc- 
ture from the rest of the representational pparatus: 
Dependency is not a possible kind of representation. 
3.2 Informat ion structure in CCG 
Information structuring is a problem for traditional 
constituent- approaches because units of informa- 
tion structure often do not coincide with the units 
established by phrase structure. For example, a tra- 
ditional phrase structure for Fred ate the beans would 
reflect tile following bracketing: (Fred) (ate  the 
beans), which coincides only with one possible in- 
formation structuring, where Fred is the Given ele- 
ment, but not with an information structure where 
Fred ate is the Given element (of. (Steedman, 1991, 
274-275)). The definition of 'Given' used here is that 
of (Halliday, 1985). It is that element in clause struc- 
ture that represents he cotextually or contextually 
known information. 2 See Figure 4 illustrating these 
two kinds of information structuring. 
Fled ate the beans. 
(1) What about the beans? Who ate them? 
(Fred) (ate tile beans) 
(2) What about Fred? What did he eat? 
(Fred ate) (the beans) 
Figure 4: Two information structure readings for 
Fred ate the beans 
As (Steedman, 1991) points out, proposals for in- 
tonation structure, which is the reflex of informa- 
tion distribution in spoken mode, that try to deal 
with this divergence either come up with very com- 
plex derivations of intonational structure from a sur- 
face syntactic structure or they stipulate two au- 
tonomous levels of representation. These have to 
communicate, however, and the representation is 
2Another term that  has been used for Given is Topic - -  
however, the notion of Topic is often a conflation of Given 
and Theme, which in Halliday's view is distinct from Given: 
While Given represents that part of an utterance that  is pre- 
sented as known, Theme is that part which is taken to be the 
point of departure of a message, whether that  is given or new 
information. In English, Theme is said to occupy the first 
position in the clause; Gi~en can be coexistent with Theme,  
but can also be part of Rheme, or cover more const ituents 
thau Theme. 
thus considerably complicated (cf. (Steedman, 1991, 
261)). 
In Categorial Grammar, constituency groupings 
other than the ones of traditional PS-markers are 
possible - including those that are coexistent with 
information structuring, as shown in the proposal 
of (Steedman. 1991) using Combinatory Categorial 
Grammar (CCG). In CCG a constituent grouping 
of Fred ate the beans as (Fred ate)  (the beans) is 
thus possible, opening up the possibility of a uni- 
fied treatment of information structure and syntac- 
tic structure. 
Traditional constituency inhibits a fornmlation of 
information structuring, in which information struc- 
ture, and consequently intonation structure, and 
syntactic structure are isomorphic, because it sub- 
scribes to one particular kind of constituent group- 
ing. 
3.3 Syntact ic  agreement  in HPSG 
Syntactic agreemeut can be described as involving 
the sharing of grammatical features across some of 
tile component parts of a syntactic unit. While for 
syntactic agreement tile domains of agreement axe 
often coexistent with head-dependent domains, it is 
not necessarily the case that tile head is the deter- 
minant of concord, nor is it true that it is one set 
of features that is 'shared' across all the component 
parts. Thus. heads cmmot simply be equated with 
determinants of concord. 
However, as just pointed out, the domain of agree- 
ment is often coexistent with head-dependent group- 
ings. and agreement can be described based on head- 
dependent structures. One such proposal for the 
German nonfinal group is made in (Pollard and Sag, 
1994). 
In terms of agreement relations, tile German nom- 
inal group (NG) can be briefly characterized as 
follows: German nouns carr.v grammatical gender, 
number and case. Adjectives are said to carry these 
features, too. and exhibit three inflectional patterns: 
weak, strong and mixed. The choice of inflectional 
class depends on whether the nominal group con- 
tains a definite determiner, a nonspecific or zero de- 
ternfiner, or an indefinite deternfiner. Determiners 
are roughly either definite or indefinite, and they re- 
flect gender, number and case as well. Agreement is
therefore not attributable to the head noun as tile 
source of agreement constraints, but rather, there 
are several determinants ofagreement that affect dif- 
ferent grammatical features. 
In (Pollard and Sag, 1994), agreement in the Ger- 
man NG is described in the following way. 
Case agreement is accounted for by feature (or 
structure) sharing between a head (the noun, of 
which CASE is an attribute) and its dependents. 
Here, the determinant of concord is coexistent with 
the head. This is specified by structure sharing of 
tile CASE attribute between head and dependents, 
e.g., between the head noun and the determiner: 
\[HEADno~n oun\[CASE #i\] 
SUBCAT <DetP \[CASE #I\] >\] 
Adjectives are described as having GENDER and 
NUMBER attributes in the CONTENTIINDEX slot and 
they are structure-shared with the index of the noun 
that the adjective modifies. This is accounted for 
by the general scheme for head-adjunct structures, 
where the adjunct's MOD ~alue is shared with the 
head's SYNSEM x-alue. Furthermore, adjectives, or 
more precisely adjectix~l forms, are described as im- 
posing restrictions on the kind of determiner they 
can combine with, e.g., forms belonging to the weak 
inflectional class restrict he determiners they com- 
bine with to be of type strong whereas adjectix~l 
forms of the strong class require the determiner in 
the nominal group to be weak or absent. The sign 
representing kluge M~dchen (smart girl) 
\[HEADnounnoun\[CASE #1nora V acc\] 
SUBCAT <DetP \[strong,CASE #1\] \[,ing.neut}>\] 
(cf. (Pollard and Sag, 1994, 87)) can thus only com- 
bine with the determiner das (definite determiner), 
but not with ein (indefinite determiner). 
This description of agreement in the German nom- 
inal group acknowledges several determinants ofcon- 
cord, which conforms to the linguistic observations 
made about the phenomenon. The determinant of 
concord for case is the head noun, for gender and 
number it is also the head noun; and agreement 
between adjective and determiner (the relation be- 
tween selection of type of determiner and type of 
adjectival form) is interpreted as the type of inflec- 
tional class of the adjective selecting the type of de- 
terminer, i.e., the adjective is taken as determinant 
of concord. 
4 A diversified view of syntagmatic  
relations: SFG 
Ill the preceding section I have tried to illustrate that 
some kinds of syntagrnatic patternings are hard to fit 
into dependency and constituency representations. 
The approaches that do work - like CCG for infor- 
mation structure, and HPSG for agreement, make use 
of all mltraditional notion of phrase structure and a 
rather flexible notion of dependency, respectively. 
Abstracting away from the particular epresenta- 
tional means that have been discussed here, con- 
stituency and dependency, I now want to point to 
another way of looking at syntagmatic relations that 
is not a priori committed to a strict notion of de- 
pendency or a traditional notion of phrase structure 
and is therefore unlikely to encounter the problems 
dicussed ill the preceding section. This is Systemic 
43 
I 
I 
I 
I 
I 
I 
I 
I 
I 
I 
I 
I 
I 
I 
I 
I 
I 
Functional Grammar (SFG; (Hallida), 1973; Halli- 
day, 1985)) which is known in computational lin- 
guistics foremostl.v by application ill Natural Lan- 
guage Generation (NLG) (e.g., (Matthiessen and 
Bateman, 1991; Fawcett and Tucker, 1989; Bate- 
man et al, 1991; Teich and Bateman, 1994)). The 
representational aspect of SFC, that is most promi- 
nent is the system network. System networks are 
descriptions of paradignlatic ga'ammatical relations 
intended as declarative statements of grammatical 
features and the coocurrence constraints between 
them. System networks are like the type hierar- 
chies used in HPS(J ill this regard (cf. also (Bateman, 
1991: Bateman et al, 1992; Henschel, 1995; Teich, in 
press)): the grammatical types in SI:G, however, are 
functionally rather than surface-syntactically moti- 
vated. Also. constraints on syntactic structure are 
tied to grammatical t.vpes, so that one could speak 
of a 'grammaticized" grammar~as opposed to lexi- 
calized grammars. Ill SFG, it is not lexical, but gram- 
marital classes that exhibit constraints on syntactic 
structure. 
Because syntactic structure is one of the less 
prominent opics in NLG and because SF6 is pri- 
marily a classification-based approach to gramnmr. 
SFG's representation f syntagmatic structure is less 
known. 
SFG maintains that there are four different kinds 
of syntagmatic patterning (Halliday, 1979). 
P rosod ic  s t ructure .  Agreement is a syntag- 
matic phenomenon that is ptvsodic in nature, in the 
sense that a particular ealizational effect spreads 
over more than one constituent, similar to prosodic 
features that are strung throughout an intonational 
unit (see Figure 5 displaying Subject-Finite agree- 
lnellt). 
Mood 
Subject3,.,}.~:~ Finite3,.a.,~ 
Site left ... 
Figure 5: Prosodic aspect of syntagmatic structure 
Per iod ic  s t ructure .  Information structure be- 
longs to a class of structure that is said to be pe- 
riodic. It reflects one of the points of prvminence 
we find ill clauses: informational prominence, which 
shows ill the distribution of Given and New, where 
in spoken mode. the intonation focus, which falls 
into the New part of the utterance, marks the in- 
formational pronfinence by carrying the major pitch 
change. Another point of prominence is thematic 
prominence: the structuring of a clause in theme 
and rheme (see Figure 6). 
In terdependency  structure.  Coordinate 
structures belong to a class of structure called in- 
Given New 
Theme Rheme 
She left the possum on the deck 
Figa\]re 6: Periodic aspect of syntagmatic structure 
te~rlependency structure. Coordinate structures are 
paratactic structures and are opposed to hypotac- 
tic, i.e., subordinate, structures. While a depen- 
dency representation can handle the latter because 
there is an identifiable head element, there is no 
head element in paratactic structures: its elements 
are rather mutually dependent. The term interde- 
pendency is used to cover both hypotactically and 
paratactically related syntactic units, s For an ex- 
ample see Figure 7. 
(1) Paratactic structure: 
1 2 
(Extended) (Coordinator) (Extension) 
Lucy stood inside and Fred waited 
(2) Hypotactic structure: 
(Euhanced) (Enhancement) .. 
He might have come if you had called him 
Figure 7: Interdependency aspect of syntagmatic 
structure 
Ill SFG, the notation for the elements of paratactic 
structures is 1, 2, etc. and for those of hypotactic 
stuctures it is ta, 8, ~" etc. Paratactic structures are 
said not to have heads, whereas in hypotactic struc- 
tures, n is considered the head. The additional label- 
ing (Extender, Extension, Enhanced, Enhancement) 
marks the semantic-rhetorical relation between the 
dements of the structure: In (1) in Figure 7 the 1 
element is said to be extended (by the 2 element); 
ill (2), tile a element is said to be enhanced by the 
'3 element. 
Const i tuency  st ructure.  The fourth kind of 
syntagmatic patterning SF6 finds is one that has 
unique elements uch as Subject, Object, Predi- 
cate or Actor, Goal, Process. 4 Here, constituency 
is considered an appropriate means of representa- 
tion. The categorial values (S, NP, PP etc) are sim- 
ply attributes associated with these functional con- 
stituents. See Figure 8 for an example. 
3See (Hjelmslev, 1961) for a similar distinction in the de- 
termination and interdependence subtypes of dependency. 
4This is similar to LFG'S f-structures. 
I 44 
I 
Subject,vp Finitev ObjectN/, Adjunct/,/, 
Actor Process Goal Location 
She on the deck teft the possum 
Figure 8: Constituency aspect of syntagrnatic struc- 
ture 
A unif ied view: the  funct ion s t ructure .  A 
representation f syntagmatic structure in SFG com- 
prises all of these aspects. The distinction of syn- 
tagmatic patterning into these four aspects stems 
from the conception of fimction in SFG. The func- 
tional nmtivation of categories in the system net- 
work, i.e., tile granunatical type hierarchy, is four- 
fold: paradigmatic gramnmtical types are exper/- 
entially, logically, interpersonally or textually moti- 
vated. Each of these describes the grammar of a 
language from a different angle and goes together 
with a particular mode of expression in syntag- 
matic structure. The experiential aspect of syntag- 
matic structuring is elemental, reflecting part-whole 
relations--tiffs aspect can be suitably represented by 
constituency: the logical aspect can be represented 
by a special kind of dependency structure, the in- 
terdependency structure, which represents part-part 
relations; the interpersonal nd tile textual aspects, 
however, prosodic and periodic structure, are diffi- 
cult to press into these schemes because they can 
cut across constituency boundaries or nmy contra- 
dict constituency groupings. Therefore, if all of 
these aspects of syntagmatic patterning are to be 
uniformly described in one representation, the cola- 
stituency representation part should be as little com- 
mitted to a particular kind of grouping as possible. 
so as to avoid conflicts with other groupings as re- 
quired for instance by information distribution. In 
fact, the kind of constituency SFG subscribes to is 
a nmltiple-branching structure, where the nodes are 
functionally annotated, reflecting a minimal brack- 
eting strategy (see below). 
A syntagmatic representation at clause level of 
Fred ate the beans, for example, where in terms of 
infornmtion structure Fred is Given would look as 
follows: '~ 
Actor 
Theme 
Given 
Subject 
Fred 
Process I Goal 
Rheme 
New 
Finite \ [Object  
ate the beans 
Sin a feature structure notation (here: including informa- 
tion about categorial and lexical realization) this is: 
\[ac$or: II\[NP \[lex: Frcd\]\], subject: 81, theme: 
goal:  12\[NP \[ lex:  bean~\] ,  object: $2, 
process: $3\[V \ [ lex:  ate\]\], f in i te :  #3, 
theme: <#2,#3>, 
hey: <#2,#3>\] 
Ill, 
And for the interpretation with Fred ate as Given, 
'Given' can be conflated with both Actor and Pro- 
cess (Subject and Finite): 
Actor Process Goal 
Theme Rheme 
Given New 
Subject Finite Object 
Fred ate the beans 
Here. a constituent is codescribed from several 
perspectives, taking into account the different as- 
pects of syntagmatic patterning sketched above, 
each creating a separate "layer" in the representa- 
tion. or in other words, each coming with a particu- 
lar set of attributes, like Theme and Rheme/Given 
anti New for the textual mode, Actor, Process, Goal 
for the experiential mode and Subject, Finite, Ob- 
ject for the interpersonal modefi 
A function structure like this implies a very fiat 
constituency, where the constituent boundaries do 
not necessarily match one-to-one. Thus, both of the 
interpretations of information distribution of Fred 
ate the beans are compatible with the rest of the 
st ructure .  
The representation f coordinate structure in SFG 
benefits imilarly from the minimal bracketing strat- 
egy: The coordinating conjunction itself is an im- 
mediate constituent of a coordinate structure, e.g., 
for red apples and green plums, the function struc- 
ture implies a bracketing as (red apples)  (and) 
(green plums) : 
1 2 
Extended Coordinator Extension 
Ted apples and green plums 
Here, none of the elements has to be attributed 
head status and the conjunction itself is a con- 
stituent. 
In terms of agreement interpreted as prosodic 
structure, the HPSG representation f agreement in 
the German nominal group by structure sharing is 
actually a possible realization of this view. However, 
with the current representational means employed in 
computational implementations of SFC, such as the 
NIGEL grammar in KPML (Bateman, 1997), such a 
formulation is not readily possible. This has two 
reasons, one being of a theoretical nature, the other 
one being a matter of computational representation. 
The theoretical problem is that features in the gram- 
marital system network have to be unique and fea- 
ture sharing among constituents i thus not allowed. 
As a consequence, there is no mechanism in the 
~There are no logical attributes here, because logical struc- 
turing only pertains to complex syntactic units, such as parat- 
actic and hypotactic structures. 
45 
I 
I 
I 
I 
I 
I 
I 
I 
I 
I 
I 
I 
I 
I 
I 
I 
I 
I 
KPML implementation for feature sharing. In uni- 
fication and constraint-based feature structure rep- 
resentations of NIGEL (Kasper, 1987; Henschel, 1994: 
Henschel, 1995) , feature sharing is possible, but still 
the feature uniqueness postulate would have to be 
relaxed in order to nmke use of this mechanism. 
5 Conc lus ions  
In this paper I have tried to raise the often discussed 
question of constituency vs. dependent" for syn- 
tactic representation to a more general level asking 
whether constituency and dependency are sufficient 
at all for the representation f syntagmatic relations. 
After reviewing some of the main issues in the dis- 
cussion 'constituency vs. dependency', I have pre- 
sented some kinds of syntagmatic patternings that 
can be problematic for det)endency/constituency 
representations: coordinate structure, infornmtion 
structure and syntactit" aga'eement: also, I have given 
further evidence of these obserx~ltions by presenting 
examples of granlular models that do work for some 
of the problems discussed, if a more unconventional 
approach is l)ursued, such as e.g., COG for informa- 
tion strcture. 
I have then questioned the primacy of con- 
stituency and del)endenc.v for the representation f 
syntactic structure and sketched the more diver- 
sifted, fimctionally-based view of Systemic Func- 
tional Grammar. in which only minimal constituent 
grotlpillgs are used and Solne of the represeuta- 
tional l~rol)lems encountered with true del)endency 
apl)ronches ~llld traditional constituency approaches 
do not arise. 
There are two caveats in place here, one concern- 
ing the .~F(; approach to syntagmatic structure itself. 
the other one conceruing SFG'S computational ppli- 
cation more generally. 
The st-c; view of syntagmatic structure inextri- 
cably goes together with a classification-based ap- 
proach to grammar in which grammatical classes 
arc fimctionally motivated. The kernel of an SI:G is 
the grammatical classification hierarchy, represent- 
ing the paradigmatic relations that characterize the 
gramnmr of a language. It is important o note 
that the SFG approach to the representation f syn- 
tagmatic structure by itself is therefore not a full 
model of grammar--just like itPSG would not be a 
full nmdel of ga'ammar without its hierarchy of lex- 
ical and phrasal types. However, the insight that 
SFG has to offer is the acknowledgment of the di- 
versity of syntagmatic patterning and pointing to 
the limits of the l)art-whole (constituency) and part- 
part (depeudency) representations comnmnly em- 
ployed in syntactic modeling. Recent developments 
in constraint-based fornmlations of SFG (Henschel, 
1994: Henschel, 1995) may introduce new methods 
of representation to SFG (sudl as feature or structure 
46 
sharing; cf. Section 4). However, the typed feature 
structures Henschel has experimented with all show 
particular weaknesses when faced with large classifi- 
cation hierarchies, as they are commonly employed 
in implementations of Systemic Functional Gram- 
nmr, such as the KPML system. 
The second caveat concerns the computational 
processing of sFc's in Natural Language Under- 
standing. SF6 is widely used in Natural Language 
Generation and has inspired a number of generation 
grmnmars. However, sr'c is hardly used in parsing. 
For NL generation, the major attraction of SFC lies 
in the centrality of functional grammatical c assifica- 
tion, whid~ draws distinctions that are relevant for 
generation, sFc's flat structures work fine for gen- 
eration, where the functional labeling and the an- 
notation with interpersonal nd textual information 
is andmred in the functional, paradigmatic descrip- 
tion. i.e.. the grammatical system network. The few 
attempts that have been made in parsing with SFG: 
notably (Kasper, 1988). have shown that SFG func- 
tional structures are just not informative nough. 
Kasper had to add a set of phrase structure rules, 
so that possible patterns for each major constituent 
category could be more easily recognized. The suit- 
ability of a model of syntactic structure for computa- 
tiomd application can thus also depend on the kind 
of computational pplication--NL understanding or
NL generation. 
Acknowledgments 
The author would like to thank Erich Steiner and 
the reviewers of this paper for comments and sug- 
gestions for improvements. 
Re ferences  
John M. Anderson. 1971. Dependency and gram- 
matical functions. Foundations o\] Language, 
7:30-37. 
John A. Bateman, Elisabeth A. Maier, Elke Te- 
ich. and Leo Wanner. 1991. Towards an archi- 
wcture for situated text generation. In Interna- 
tion.al Conference on Current Issues in Computa- 
tional Linguistics, Penang, Malaysia. Also a~Tlil- 
able as technical report of GMD/Institut Ftir In- 
tegrierte Publikations- und Informationssysteme, 
Darmstadt, Germany. 
John A. Bateman, Martin Emele, and Stefan 
Momma. 1992. The nondirectional representation 
of Systemic Functional Grammars and Semantics 
as Typed Feature Structures. In Proceedings of 
COLING-92, Nantes, France, July. 
John A. Bateman. 1991. Language as con- 
straint and language as resource: a com'er- 
gence of metaphors in systemic-functional gram- 
mar. Technical report, Gesellschaft fftir Mathe- 
matik und Datenverarbeitung - Institut fiir In- 
= 
t 
: 
tegrierte Publikations- und Informationssysteme, 
Darmstadt, Germany. Written version of pa- 
per l)resented at the International Workshop on 
Constraint-based Formalisms for Natural Lan- 
guage Generation, November 27-30, 1990, Bad 
Teinach. 
John A. Bateman, 1997. KPML Development Envi- 
ronment: multilingual linguistic resource develop- 
meat and sentence gevcration. German National 
Center for hffornmtion Technology (GMD), Insti- 
tute for Integrated Publication and Information 
Systems (IPSI), Darmstadt. Germany, March. 
(Release 1.0). 
Klaus Baumg/irtner. 1970. Konstituenz und De- 
pendenz. Zur Integration tier beiden Prinzipien. 
In Steger H., editor, Vorschl@e f~r eine struktu- 
rale Gramamtik des Deutschen, pages 52-77. Wis- 
sensdmftliche Buchgesellschaft, Darmstadt. 
Noam Chomsky 1970. Remarks on nominalization. 
In R. 3acobs and P.S. Rosenbaum, editors, Read- 
ings in Evglish Transformational Grammar. Ginn 
and Co.. V~sdtham..Massachusetts. 
Robin P. Fawcett and Gordon H. Tucker. 1989. 
Prot,type generators 1 and 2. Technical Report 
COMMUNAL Report Number 10, Computational 
Linguistics Unit, University of Wales College of 
Cardift. 
Norman M. Fraser and Richard A. Hudson. 1992. 
Inheritance in Word Grammar. Computational 
Linguistics, 18(2). 
H. Gaifinan. 1965. Dependency systems and phrase 
structure systems, lnfo~Tnation and Control, 
8:304-337. 
Michael A.K. Hallida.v. 1973. Explorations in the 
Functions of Language. Edward Arnold. London. 
.Michael A.K. Halliday. 1979. Modes of meaning 
and modes of saying: types of grammatical struc- 
ture and their determination by different seman- 
tic functions. In In D.J. Allerton, E. Carney. 
and D. Holdcroft, editors. Function and Context 
in Linguistic Analysis. Essays offered to William 
Haas. Cambridge University Press, Cambridge. 
Michael A.K. Halliday. 1985. An Introduction to 
Functioval Grammar. Edward Arnold, London. 
D. G. Hays. 1964. Del)endency theory: a formalism 
and some observations. Language, 40(4):511-525. 
Renate Henschel. 1994. Declarative representation 
and l)rocessing of systemic grammars. In Carlos 
Martin-Vide. editor, Current Issues in Mathemat- 
ical Linguistics, l)ages 363-371, Amsterdam. Else- 
vier Science Publisher B.V. 
Renate Henschel. 1995. Traversing the Labyrinth 
of Feature Logics for a Declarative Implementa- 
tion of Large Scale Systemic Grammars. In Suresh 
Manandhar, editor, Proceedings of the CLNLP 95. 
April 1995, South Queensferry. 
47 
Louis Hjelmslev. 1961. Prolegomena to a Theory of 
Language. University of Wisconsin Press, Madi- 
son, Wisconsin. 
Richard A. Hudson. 1980. Constituency and depen- 
dency. Linguistics, 18:179-198. 
Richard A. Hudson. 1984. Word Grammar. Basil 
Blackwell, Oxford. 
Richard A. Hudson. 1987. Zwicky on heads. Jour- 
nal of Linguistics, 23:109-132. 
Richard A. Hudson. 1989. Gapping and grammati- 
cal relations. Journal of Linguistics, 25(1):57-94. 
Ray Jackendoff. 1977. X Syntax: a study of phrase 
structure. The M.I.T. Press, Cambridge, MA. 
Robert T. Kasper. 1987. Systemic grammar and 
functional unification grammar. In James D. 
Benson and William S. Greaves, editors, Sys- 
temic Perspectives on Discourse, Volume 1. 
Ablex, Norwood, New Jersey. Also available as 
USC/Information Sciences Institute, Reprint Re- 
port ISI\[RS-87-179, I987. 
Robert T. Kasper. 1988. An Experimental Parser 
for Systemic Grammars. In Proceedings of the 
12th International Conference on Computational 
Linguistics, August I988. Budapest, Hungar): 
Association for Computational Linguistics. Also 
available as Information Sciences Institute Tech- 
nical Report No. ISI/RS-88-212, .Marina del Re),, 
CA. 
P. H. Matthews. 1981. Syntax. Cambridge Univer- 
sit)" Press, Cambridge. 
Christian M.I.M. Matthiessen and John A. Bate~ 
nmn. 1991. Text generation and systemic- 
functional inguistics: experiences from English 
and ,hqmnese. Frances Pinter Publishers and St. 
Martin's Press, London and New York. 
Christian M.I.M. Matthiessen. 1995. Lezicogram- 
marital cartography: English systems. Interna- 
tional Language Science Publishers, Tokyo, Taipei 
and Dallas. 
Igor A..Mei'~uk. 1988. Dependency Syntax: Theory 
and Practice. State University of New York Press, 
Albany. 
Carl Pollard and Ivan A. Sag. 1987. Information. 
based syntax and semantics: volume 1. Chicago 
University Press, Chicago. Center for the Study of 
Language and Information; Lecture Notes Num- 
ber 13. 
Carl Pollard and Ivan A. Sag. 1994. Head- 
Driven Phrase Structure Grammar. University of 
Chicago Press and CSLI Publications, Chicago, 
Illinois. 
Jane J. Robinson. 1970. Dependency structures and 
transformational rules. Language, 46(2):259-285. 
M. Steedman. 1985. Dependency and coordination 
in the grammar of dutch and english. Language, 
61(2):523-568. 
.M. Steedman. 1987. CombinatoD" grammars and 
parasitic gaps. Natural language and linguistic 
theol. 5(2):403-439. 
M. Steedmau. 1991. Structure and intonation. Lan- 
guage, 67(2):260-296. 
Elke Teich and Jolm A. Bateman. 1994. Towards 
an application of text generation in an inte- 
grated publication system. In Proceedings o/the 
Seventh b~ternational Workshop on Natural Lan- 
guage Generation, KennebunkTort, Maine, USA, 
June 21-'24, 1994, Kennebunkport, Maine, USA. 
Elke Teidl. in press. Systemic Functional Gram- 
mar in Natural Language Generation: Linguis- 
tic DescT~ption and Computational Representa- 
tion. Cassell Academic, London. 
Lucien Tesniere. 1959. Elements de syntaxe st~c- 
turale. Klincksieck. Pads. 
Hans Uszkoreit. 1986. Categorial unification gram- 
mars. In Proceedings o/ COLING-86. Also ap- 
pears as Center for the Study of Language and In- 
formation Report No. CSLI-86-66. Stanford. CA. 
Arnold 3I. Zwicky. 1985. Heads. Journal o/Lin- 
guistics, 21:1-30. 
48 
