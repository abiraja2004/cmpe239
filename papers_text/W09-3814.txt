Proceedings of the 11th International Conference on Parsing Technologies (IWPT), pages 85?88,
Paris, October 2009. c?2009 Association for Computational Linguistics
Evaluating Contribution of Deep Syntactic Information
to Shallow Semantic Analysis
Sumire Uematsu Jun?ichi Tsujii
Graduate School of Information Science and Technology
The University of Tokyo
{uematsu,tsujii}@is.s.u-tokyo.ac.jp
Abstract
This paper presents shallow semantic pars-
ing based only on HPSG parses. An
HPSG-FrameNet map was constructed
from a semantically annotated corpus, and
semantic parsing was performed by map-
ping HPSG dependencies to FrameNet re-
lations. The semantic parsing was evalu-
ated in a Senseval-3 task; the results sug-
gested that there is a high contribution of
syntactic information to semantic analysis.
1 Introduction
This paper presents semantic parsing based only
on HPSG parses, and examines the contribution of
the syntactic information to semantic analysis.
In computational linguistics, many researchers
have studied the relationship between syntax and
semantics. Its quantitative analysis was formal-
ized as semantic parsing, or semantic role label-
ing, and has attracted the attention of researchers.
Recently, an improvement in the accuracy and
robustness of ?deep parsers? has enabled us to di-
rectly map deep syntactic dependencies to seman-
tic relations. Deep parsers are based on linguisti-
cally expressive grammars; e.g. HPSG, LFG, etc,
and less affected by syntactic alternations such as
passivization. Their results are therefore expected
to closely relate to semantic annotations. For ex-
ample, the sentences in figure 1 share the same
set of semantic roles, and the roles have one-to-
one relations to deep syntactic dependencies in the
sentences. However, the results of the deep parsers
are represented in complex structures, shown in
figure 3, and cannot be straightforwardly com-
pared to semantic annotations.
In order to directly map the deep dependencies
to semantic relations, we adapted the corpus anal-
ysis method of (Frank and Semecky?, 2004) for
the semantic parsing using HPSG parses. We per-
formed the semantic parsing by mapping paths in
HPSG parses to semantic predicate-argument re-
lations. The analysis of the HPSG paths for the
predicate-argument pairs, and the preliminary re-
sult of the semantic parsing indicate the contribu-
tion of syntactic analysis to semantic parsing.
2 Related Work
Besides (Frank and Semecky?, 2004)?s work, as
mentioned above, there have been several studies
on the relationship between deep syntax and se-
mantic parsing. Although the studies did not focus
on direct mappings between deep syntax and shal-
low semantics, they suggested a strong relation-
ship between the two. (Miyao and Tsujii, 2004)
evaluated the accuracy of an HPSG parser against
PropBank semantic annotations, and showed that
the HPSG dependants correlated with semantic ar-
guments of the PropBank, particularly with ?core?
arguments. In (Gildea and Hockenmaier, 2003)
and (Zhang et al, 2008), features from deep parses
were used for semantic parsing, together with fea-
tures from CFG or dependency parses. The deep
features were reported to contribute to a perfor-
mance gain.
3 Syntactic and Semantic Parsing
Some semantic relations are easily identified by
using syntactic parsing while others are more diffi-
cult. This section presents easy and difficult cases
in syntax-semantics map construction.
Trivial when using syntactic analysis: Syn-
tactic parsing, including CFG analysis, detects
semantic similarity of sentences sharing similar
phrase structures. For the example sentences a)
and b) in figure 1, the parsing provides similar
phrase structures, and therefore gives the same
syntactic dependency to occurrences of each role.
Trivial when using deep analysis: Deep pars-
ing reveals the semantic similarity of sentences
85
a) ?, ICommunicator praise themEvaluee for being 99 percent perfectReason. 
b) ?, but heCommunicator praised the Irish premierEvaluee for making a ``sensible?? speechReason.
?, HeEvaluee has been particularly praised as an exponent of ?,
d) ?, SheCommunicator was supposed, therefore, to praise himEvaluee and then ? 
c) The childEvaluee is praised for having a dry bedReason and ?
e) ItEvaluee received high praise, ?
f) AliceWearer ?s dress
g) Versace?s dress
Figure 1: Sentences with a set of semantic roles for the predicate praise.
a) ?, ICommunicator praise themEvaluee for being 99 percent perfectReason. 
b) ?, but heCommunicator praised the Irish premierEvaluee for making a ``sensible?? speechReason.
?, HeEvaluee has been particularly praised as an exponent of ?,
d) ?, SheCommunicator was supposed, therefore, to praise himEvaluee and then ? 
c) The childEvaluee is praised for having a dry bedReason and ?
e) ItEvaluee received high praise, ?
f) AliceWearer ?s dress
g) Versace?s dress
Figur 2: Example phr ses
for section 3.
Mary
Head?Complement?schema
Head?Subject?schema
likes
SYNSEM|LOCAL CATCONT|HOOK
HEADVAL 3?
6?
VFORM:??finverbAUX:???????noneSUBJ:???<??????>?1COMP:<???????>2?verb_arg12PRED:???like?ARG1: 4?ARG2: 5?The
SYNSEM: LOCAL CATCONT|HOOKHEAD:??detVAL|?SPEC:?<???????>8det_arg1PRED:???the?ARG1: 4?7? LOCAL2?
noun_arg0PRED:???Mary?
CAT
CONT|HOOK
HEADVAL CASE:??acc
nounAGR:???3sg
5?SUBJ:???<??????>?COMP:<???????>
SYNSEM:?girl noun_arg0PRED:???girl?SPR:?????<???????>?
LOCALCAT
CONT|HOOK
HEADVAL CASE:??nom
nounAGR:???3sg
4?
SUBJ:???<??????>?COMP:<???????>7SYNSEM:8?
Head?Specifier?schema
1?SYNSEM:? LOCALCAT
CONT|HOOK:?
HEADVAL CASE:??nom
nounAGR:???3sg
4?SUBJ:???<??????>?COMP:<???????> SYNSEM|LOCAL CATCONT|HOOK:?
HEAD:VAL 3?
6?
SUBJ:???<??????>?1COMP:<???????>
SYNSEM|LOCAL CATCONT|HOOK:?
HEAD:VAL 3?
6?
SUBJ:???<??????>?COMP:<???????>
Figure 3: An HPSG parse for The girl likes Mary.
containing complex syntactic phenomena, which
is not easily detected by CFG analysis. The sen-
tences c) and d) in figure 1 contain passivization
and object raising, while deep parsing provides
one dependency for each role in the figure.
Not trivial even when using deep analysis:
Some semantic arguments are not direct syntactic
dependants of their predicates - especially of noun
predicates. In sentence e) in figure 2, the Evaluee
phrase depends on the predicate praise, through
the support verb receive. The deep analysis would
be advantageous in capturing such dependencies,
because it provides receive with direct links to the
phrases of the role and the predicate.
Problematic when using only syntactic analy-
sis: Sometimes, the semantic role of a phrase is
strongly dependent on the type of the mentioned
entity, rather than on the syntactic dependency. In
phrases f) and g) in figure 2, the phrases Alice and
Versace, have the same syntactic relation to the
predicate dress. However, the Wearer role is given
only to the former phrase.
4 A Wide-Coverage HPSG Parser
We employed a wide-coverage HPSG parser for
semantic parsing, and used deep syntactic depen-
dencies encoded in a Predicate Argument Struc-
ture (PAS) in each parse node.
In our experiments, the parser results were con-
sidered as graphs, as illustrated by figures 3 and 4,
to extract HPSG dependencies conveniently. The
The               girl                likes            Mary.verb_arg12 noun_arg0noun_arg0det_arg1
ARG1
ARG2ARG1
Figure 4: A simplified representation of figure 3.
graph is obtained by ignoring most of the linguis-
tic information in the original parse nodes, and
by adding edges directing to the PAS dependants.
The PAS information is represented in the graph,
by the terminal nodes? PAS types, e.g. verb arg12,
etc., and by the added edges. Note that the inter-
pretation of the edge labels depends on the PAS
type. If the PAS type is verb arg12, the ARG2 de-
pendant is the object of the transitive verb or its
equivalence (the subject of the passive, etc.). If
the PAS type is prep arg12, then the dependant is
the NP governed by the preposition node.
5 Semantic Parsing Based on FrameNet
We employed FrameNet (FN) as a semantic cor-
pus. Furthermore, we evaluated our semantic pars-
ing on the SRL task data of Senseval-3 (Litkowski,
2004), which consists of FN annotations.
In FN, semantic frames are defined, and each
frame is associated with predicates that evoke the
frame. For instance, the verb and noun praise are
predicates of the Judgment communication frame,
and they share the same set of semantic roles.
The Senseval-3 data is a standard for evaluation
of semantic parsing. The task is defined as identi-
fying phrases and their semantic roles for a given
sentence, predicate, and frame. The data includes
null instantiations of roles1, which are ?conceptu-
ally salient?, but do not appear in the text.
6 Methods
The semantic parsing using an HPSG-FN map
consisted of the processes shown in figure 5.
1An example of a null instantiation is the Communicator
role in the sentence, ?All in all the conference was acclaimed
as a considerable success.?
86
Map?construc?n?
HPSG?parsingRaw?sentences?
Seman??annota?ns?
Training?data?
HPSG?parses?
Phrase?projec?n? 
HPSG?parses?with?seman?ally?marked?nodes?
HPSG?dependency?extrac?n? 
HPSG?dependency?between??predicate1?and?role1?
Map?instances?
HPSG?dependency?between??predicate1?and?role2?
HPSG?parsingRaw?sentences?
Predicate?annota?ns?
Test?data?
HPSG?parses?
Phrase?projec?n? 
HPSG?parses?with?nodes?marked?as?predicates?
Role?node?predic?n 
Feature?filter?
HPSG?parses?with?seman?ally?marked?nodes?
Role?predic?n?rules?
Seman??parsing?(Map?evalua?n)?
Figure 5: Processes in the map construction and evaluation.
It           recieved       high         praise,  ?adj_arg1verb_arg12noun_arg0
ARG2 ARG1ARG1
Evaluee?role
noun_arg0
Figure 6: an HPSG path for a
semantic relation.
Predicate base: The base form of the semantic
predicate word. (praise in the case of figure 6).
Predicate type: The PAS type of the HPSG
terminal node for the predicate - see section 4.
(noun arg0 in figure 6).
Intermediate word base: The base form of the
intermediate word, corresponding to a terminal
passed by the path, and satisfying pre-defined
conditions. The word may be a support verb.
- see figure 6. (receive in figure 6).
Intermediate word type: The PAS type of the
intermediate word. (verb arg12 in figure 6).
Dependency label sequence: The labels of
the path?s edges. We omitted labels presenting
head-child relations, for identifying a phrase with
another phrase sharing the same head word.
(Reverse of ARG2, ARG1 in figure 6).
Table 1: Features used to represent a HPSG path.
Filter Pred. Inter. Dep.
base type base type label
Same ? ? ? ? ?
AllInter ? ? ? ?
AllPred ? ? ? ?
AllPred-AllInter ? ? ?
Table 2: Syntactic features for role prediction.
Phrase projection: Because we used FN anno-
tations, which are independent of any syntactic
framework, role phrases needed to be projected
to appropriate HPSG nodes. We projected the
phrases based on maximal projection, which was
generally employed, with heads defined in the
HPSG.
HPSG dependency extraction: As an HPSG
dependency for a predicate-argument pair, we
used the shortest path between the predicate node
and the argument node in the HPSG parse. The
path was then represented by pre-defined fea-
tures, listed in table 1. The search for the short-
est path was done in the simplified graph of the
HPSG parse (see figure 4), with the edges denot-
ing deep dependencies, and head-child relations.
An instance of the HPSG-FN map consisted of the
path?s features, the FN frame, and the role label.
Role node prediction: The role prediction was
based on simple rules with scores. The rules were
obtained by filtering features of the map instances.
Table 2 shows the feature filters. The score of a
rule was the number of map instances matching
the rule?s features. In the test, for each node of a
HPSG parse, the role label with the highest score
was selected as the result, where the score of a la-
bel was that of the rule providing the label.
7 Experiments
For the experiments, we employed a wide cover-
age HPSG parser, Enju version 2.3.12, and the data
for the Semantic Role Labeling task of Senseval-3.
7.1 Analysis of Map Instances
We extracted 41,193 HPSG-FN map instances
from the training set, the training data apart from
the development set. The instances amounted to
97.7 % (41,193 / 42,163) of all the non-null in-
stantiated roles in the set, and HPSG paths were
short for many instances. Paths to syntactic ar-
guments were almost directly mapped to semantic
roles, while roles for other phrases were more am-
biguous.
The length distribution of HPSG paths: 64 %
(26410 / 41193) of the obtained HPSG paths were
length-one, and 8 % (3390 / 41193) were length-
two, due to the effect of direct links provided by
HPSG parsing. The length of a path was defined
2http://www-tsujii.is.s.u-tokyo.ac.jp/enju/
87
Pred. Freq. Feature representation Interpretation
Verb 3792 verb arg12/?/?/ARG2 The object of the transitive predicate
3191 verb arg12/?/?/ARG1 The subject of the transitive predicate
Noun 7468 noun arg0/?/?/? NP headed by the predicate
1161 noun arg0/of/prep arg12/Rev-ARG1 The PP headed by ?of?, attaching to the predicate
Adj 1595 adj arg1/?/?/ARG1 The modifiee of the predicate
274 verb arg12/?/?/ARG2 The modifiee of the predicate treated as a verb
Table 3: Most frequent syntactic paths extracted for predicates of each POS.
as the number of the labels in the Dep. label seq.
of the path. Most of the one-length paths were
paths directing to syntactic arguments, and to PPs
attaching to the predicates. The two-length paths
included paths using support verbs (see figure 6).
Most frequent HPSG dependencies: The most
frequent paths are shown in table 3; syntactic de-
pendencies are presented and counted as taples of
Pred. type, Inter. base, Inter. type, and Dep.
label seq. The interpretation column describes
the syntactic dependencies for the taples. Note
that the column denotes normalized dependencies,
in which object indicates objects of active voice
verbs, subjects of passive-voiced verbs, etc.
7.2 Performance of Semantic Parsing
Finally, semantic parsing was evaluated on the test
data. Table 4 shows the overall performance. The
scores were measured by the Senseval-3 official
script, in the restrictive setting, and can be directly
compared to other systems? scores. Since our pre-
liminary system of semantic parsing ignored null
instantiations of roles, it lost around 0.10 point
of the recalls. We believe that such instantia-
tions may be separately treated. Although the sys-
tem was based on only the syntactic information,
and was very na??ve, the system?s performance was
promising, and showed the high contribution of
syntactic dependencies for semantic parsing.
8 Conclusion
This paper presents semantic parsing based on
only HPSG parses, and investigates the contribu-
tion of syntactic information to semantic parsing.
We constructed an HPSG-FN map by finding
the HPSG paths that corresponded to semantic re-
lations, and used it as role prediction rules in se-
mantic parsing. The semantic parsing was evalu-
ated on the SRL task data of Senseval-3. Although
the preliminary system used only the syntactic in-
formation, the performance was promising, and
Rule set Prec. Overlap Recall
Same 0.799 0.783 0.518
AllInter 0.599 0.586 0.589
AllPred 0.472 0.462 0.709
AllPred-AllInter 0.344 0.335 0.712
Senseval-3 best 0.899 0.882 0.772
Senseval-3 4th best 0.802 0.784 0.654
Table 4: Semantic parsing result on the test data.
indicated that syntactic dependencies may make
significant contribution to semantic analysis.
This paper also suggests a limit of the seman-
tic analysis based purely on syntax. A next step
for accurate HPSG-FN mapping could be analy-
sis of the interaction between the HPSG-FN map
and other information, such as named entity types
which were shown to be effective in many studies.
Acknowledgments
This work was partially supported by Grant-in-Aid
for Specially Promoted Research (MEXT, Japan)
and Special Coordination Funds for Promoting
Science and Technology (MEXT, Japan).
References
Anette Frank and Jir??? Semecky?. 2004. Corpus-based
induction of an LFG syntax-semantics interface for
frame semantic processing. In Proc. of International
Workshop on Linguistically Interpreted Corpora.
Daniel Gildea and Julia Hockenmaier. 2003. Identi-
fying semantic roles using combinatory categorial
grammar. In Proc. of EMNLP.
Ken Litkowski. 2004. Senseval-3 task: Automatic la-
beling of semantic roles. In Proc. of Senseval-3.
Yusuke Miyao and Jun?ichi Tsujii. 2004. Deep lin-
guistic analysis for the accurate identification of
predicate-argument relations. In Proc. of Coling.
Yi Zhang, Rui Wang, and Hans Uszkoreit. 2008. Hy-
brid learning of dependency structures from hetero-
geneous linguistic resources. In Proc. of CoNLL.
88
