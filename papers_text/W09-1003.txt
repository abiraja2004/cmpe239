Proceedings of the EACL 2009 Workshop on Computational Linguistic Aspects of Grammatical Inference, pages 7?15,
Athens, Greece, 30 March 2009. c?2009 Association for Computational Linguistics
Dialogue Act Prediction Using Stochastic Context-Free Grammar
Induction
Jeroen Geertzen
Research Centre for English & Applied Linguistics
University of Cambridge, UK
jg532@cam.ac.uk
Abstract
This paper presents a model-based ap-
proach to dialogue management that is
guided by data-driven dialogue act predic-
tion. The statistical prediction is based on
stochastic context-free grammars that have
been obtained by means of grammatical
inference. The prediction performance of
the method compares favourably to that of
a heuristic baseline and to that of n-gram
language models.
The act prediction is explored both for
dialogue acts without realised semantic
content (consisting only of communicative
functions) and for dialogue acts with re-
alised semantic content.
1 Introduction
Dialogue management is the activity of determin-
ing how to behave as an interlocutor at a specific
moment of time in a conversation: which action
can or should be taken at what state of the dia-
logue. The systematic way in which an interlocu-
tor chooses among the options for continuing a di-
alogue is often called a dialogue strategy.
Coming up with suitable dialogue management
strategies for dialogue systems is not an easy task.
Traditional methods typically involve manually
crafting and tuning frames or hand-crafted rules,
requiring considerable implementation time and
cost. More recently, statistical methods are be-
ing used to semi-automatically obtain models that
can be trained and optimised using dialogue data.1
These methods are usually based on two assump-
tions. First, the training data is assumed to be
representative of the communication that may be
encountered in interaction. Second, it is assumed
that dialogue can be modelled as a Markov De-
cision Process (MDP) (Levin et al, 1998), which
1See e.g. (Young, 2002) for an overview.
implies that dialogue is modelled as a sequential
decision task in which each contribution (action)
results in a transition from one state to another.
The latter assumption allows to assign a reward
for action-state pairs, and to determine the dia-
logue management strategy that results in the max-
imum expected reward by finding for each state
the optimal action by using reinforcement learn-
ing (cf. (Sutton and Barto, 1998)). Reinforce-
ment learning approaches to dialogue manage-
ment have proven to be successful in several task
domains (see for example (Paek, 2006; Lemon et
al., 2006)). In this process there is no supervision,
but what is optimal depends usually on factors that
require human action, such as task completion or
user satisfaction.
The remainder of this paper describes and eval-
uates a model-based approach to dialogue man-
agement in which the decision process of taking
a particular action given a dialogue state is guided
by data-driven dialogue act prediction. The ap-
proach improves over n-gram language models
and can be used in isolation or for user simula-
tion, without yet providing a full alternative to re-
inforcement learning.
2 Using structural properties of
task-oriented dialogue
One of the best known regularities that are ob-
served in dialogue are the two-part structures,
known as adjacency pairs (Schegloff, 1968), like
QUESTION-ANSWER or GREETING-GREETING.
A simple model of predicting a plausible next
dialogue act that deals with such regularities could
be based on bigrams, and to include more context
also higher-order n-grams could be used. For in-
stance, Stolcke et al (2000) explore n-gram mod-
els based on transcribed words and prosodic in-
formation for SWBD-DAMSL dialogue acts in the
Switchboard corpus (Godfrey et al, 1992). After
training back-off n-gram models (Katz, 1987) of
7
different order using frequency smoothing (Witten
and Bell, 1991), it was concluded that trigrams and
higher-order n-grams offer a small gain in predi-
cation performance with respect to bigrams.
Apart from adjacency pairs, there is a variety
of more complex re-occurring interaction patterns.
For instance, the following utterances with cor-
responding dialogue act types illustrate a clarifi-
cation sub-dialogue within an information-request
dialogue:
1 A: How do I do a fax? QUESTION
2 B: Do you want to send QUESTION
or print one?
3 A: I want to print it ANSWER
4 B: Just press the grey button ANSWER
Such structures have received considerable at-
tention and their models are often referred to as
discourse/dialogue grammars (Polanyi and Scha,
1984) or conversational/dialogue games (Levin
and Moore, 1988).
As also remarked by Levin (1999), predict-
ing and recognising dialogue games using n-gram
models is not really successful. There are vari-
ous causes for this. The flat horizontal structure of
n-grams does not allow (hierarchical) grouping of
symbols. This may weaken the predictive power
and reduces the power of the representation since
nested structures such as exemplified above cannot
be represented in a straightforward way.
A better solution would be to express the struc-
ture of dialogue games by a context-free grammar
(CFG) representation in which the terminals are
dialogue acts and the non-terminals denote con-
versational games. Construction of a CFG would
require explicit specification of a discourse gram-
mar, which could be done by hand, but it would be
a great advantage if CFGs could automatically be
induced from the data. An additional advantage
of grammar induction is the possibility to assess
the frequency of typical patterns and a stochastic
context-free grammar (SCFG) may be produced
which can be used for parsing the dialogue data.
3 Sequencing dialogue acts
Both n-gram language models and SCFG based
models work on sequences of symbols. Using
more complex symbols increases data sparsity:
encoding more information increases the number
of unique symbols in the dataset and decreases
the number of reoccurring patterns which could be
used in the prediction.
In compiling the symbols for the prediction ex-
periments, three aspects are important: the identi-
fication of interlocutors, the definition of dialogue
acts, and multifunctionality in dialogue.
The dialogue act taxonomy that is used in the
prediction experiments is that of DIT (Bunt, 2000).
A dialogue act is defined as a pair consisting of a
communicative function (CF) and a semantic con-
tent (SC): a =< CF,SC >. The DIT taxonomy
distinguishes 11 dimensions of communicative
functions, addressing information about the task
domain, feedback, turn management, and other
generic aspects of dialogue (Bunt, 2006). There
are also functions, called the general-purpose
functions, that may occur in any dimension. In
quite some cases, particularly when dialogue con-
trol is addressed and dimension-specific functions
are realised, the SC is empty. General-purpose
functions, by contrast, are always used in combi-
nation with a realised SC. For example:
dialogue act
utterance function semantic content
What to do next? SET-QUESTION next-step(X)
Press the button. SET-ANSWER press(Y) ?
button(Y)
The SC ?if realised? describes objects, prop-
erties, and events in the domain of conversation.
In dialogue act prediction while taking multi-
dimensionality into account, a dialogue D can be
represented as a sequence of events in which an
event is a set of one dialogue act or multiple di-
alogue acts occurring simultaneously. The infor-
mation concerning interlocutor and multifunction-
ality is encoded in a single symbol and denoted by
means of a n-tuple. Assuming that at most three
functions can occur simultaneously, a 4-tuple is
needed2: (interlocutor,da1,da2,da3). An ex-
ample of a bigram of 4-tuples would then look as
follows:
(A,<SET-Q,"next-step(X)">, , ) ,
(B,<SET-A,"press(Y) ? button(Y)">, , )
Two symbols are considered to be identical when
the same speaker is involved and when the sym-
bols both address the same functions. To make
2Ignoring the half percent of occurrences with four simul-
taneous functions.
8
it easy to determine if two symbols are identical,
the order of elements in a tuple is fixed: func-
tions that occur simultaneously are first ordered on
importance of dimension, and subsequently on al-
phabet. The task-related functions are considered
the most important, followed by feedback-related
functions, followed by any other remaining func-
tions. This raises the question how recognition
performance using multifunctional symbols com-
pares against recognition performance using sym-
bols that only encode the primary function
4 N-gram language models
There exists a significant body of work on the use
of language models in relation to dialogue man-
agement. Nagata and Morimoto (1994) describe a
statistical model of discourse based on trigrams of
utterances classified by custom speech act types.
They report 39.7% prediction accuracy for the top
candidate and 61.7% for the top three candidates.
In the context of the dialogue component of the
speech-to-speech translation system VERBMO-
BIL, Reithinger and Maier (1995) use n-gram dia-
logue act probabilities to suggest the most likely
dialogue act. In later work, Alexandersson and
Reithinger (1997) describe an approach which
comes close to the work reported in this paper: Us-
ing grammar induction, plan operators are semi-
automatically derived and combined with a statis-
tical disambiguation component. This system is
claimed to have an accuracy score of around 70%
on turn management classes.
Another study is that of Poesio and Mikheev
(1998), in which prediction based on the previous
dialogue act is compared with prediction based on
the context of dialogue games. Using the Map
Task corpus annotated with ?moves? (dialogue
acts) and ?transactions? (games) they showed that
by using higher dialogue structures it was possi-
ble to perform significantly better than a bigram
model approach. Using bigrams, 38.6% accuracy
was achieved. Additionally taking game structure
into account resulted in 50.6%; adding informa-
tion about speaker change resulted in an accuracy
of 41.8% with bigrams, 54% with game structure.
All studies discussed so far are only concerned
with sequences of communicative functions, and
disregard the semantic content of dialogue acts.
5 Dialogue grammars
To automatically induce patterns from dialogue
data in an unsupervised way, grammatical infer-
ence (GI) techniques can be used. GI is a branch
of unsupervised machine learning that aims to find
structure in symbolic sequential data. In this case,
the input of the GI algorithm will be sequences of
dialogue acts.
5.1 Dialogue Grammars Inducer
For the induction of structure, a GI algorithm has
been implemented that will be referred to as Dia-
logue Grammars Inducer (DGI). This algorithm is
based on distributional clustering and alignment-
based learning (van Zaanen and Adriaans, 2001;
van Zaanen, 2002; Geertzen and van Zaanen,
2004). Alignment-based learning (ABL) is a sym-
bolic grammar inference framework that has suc-
cessfully been applied to several unsupervised ma-
chine learning tasks in natural language process-
ing. The framework accepts sequences with sym-
bols, aligns them with each other, and compares
them to find interchangeable subsequences that
mark structure. As a result, the input sequences
are augmented with the induced structure.
The DGI algorithm takes as input time series of
dialogue acts, and gives as output a set of SCFGs.
The algorithm has five phases:
1. SEGMENTATION: In the first phase of DGI,
the time series are ?if necessary? seg-
mented in smaller sequences based on a spe-
cific time interval in which no communica-
tion takes place. This is a necessary step in
task-oriented conversation in which there is
ample time to discuss (and carry out) several
related tasks, and an interaction often con-
sists of a series of short dialogues.
2. ALIGNMENT LEARNING: In the second
phase a search space of possible structures,
called hypotheses, is generated by compar-
ing all input sequences with each other and
by clustering sub-sequences that share simi-
lar context. To illustrate the alignment learn-
ing, consider the following input sequences:
A:SET-Q, B:PRO-Q, A:PRO-A, B:SET-A.
A:SET-Q, B:PAUSE, B:RESUME, B:SET-A.
A:SET-Q, B:SET-A.
The alignment learning compares all input
sequences with each other, and produces the
9
hypothesised structures depicted below. The
induced structure is represented using brack-
eting.
[i A:SET-Q, [j B:PRO-Q, A:PRO-A, ]j B:SET-A. ]i
[i A:SET-Q, [j B:PAUSE, A:RESUME, ]j B:SET-A. ]i
[i A:SET-Q, [j ]j B:SET-A. ]i
The hypothesis j is generated because of the
similar context (which is underlined). The
hypothesis i, the full span, is introduced by
default, as it might be possible that the se-
quence is in itself a part of a longer sequence.
3. SELECTION LEARNING: The set of hypothe-
ses that is generated during alignment learn-
ing contains hypotheses that are unlikely to
be correct. These hypotheses are filtered out,
overlapping hypotheses are eliminated to as-
sure that it is possible to extract a context-
free grammar, and the remaining hypotheses
are selected and remain in the bracketed out-
put. The decision of which hypotheses to se-
lect and which to discard is based on a Viterbi
beam search (Viterbi, 1967).
4. EXTRACTION: In the fourth phase, SCFG
grammars are extracted from the remaining
hypotheses by means of recursive descent
parsing. Ignoring the stochastic informa-
tion, a CFG of the above-mentioned example
looks in terms of grammar rules as depicted
below:
S ? A:SET-Q J B:SET-A
J ? B:PRO-Q A:PRO-A
J ? B:PAUSE A:RESUME
J ? ?
5. FILTERING: In the last phase, the SCFG
grammars that have small coverage or involve
many non-terminals are filtered out, and the
remaining SCFG grammars are presented as
the output of DGI.
Depending on the mode of working, the DGI
algorithm can generate a SCFG covering the com-
plete input or can generate a set of SCFGs. In the
former mode, the grammar that is generated can be
used for parsing sequences of dialogue acts and by
doing so suggests ways to continue the dialogue.
In the latter mode, by parsing each grammar in the
set of grammars that are expected to represent di-
alogue games in parallel, specific dialogue games
may be recognised, which can in turn be used ben-
eficially in dialogue management.
5.2 A worked example
In testing the algorithm, DGI has been used to
infer a set of SCFGs from a development set of
250 utterances of the DIAMOND corpus (see also
Section 6.1). Already for this small dataset, DGI
produced, using default parameters, 45 ?dialogue
games?. One of the largest produced structures
was the following:
4 S ? A:SET-Q , NTAX , NTBT , B:SET-A
4 NTAX ? B:PRO-Q , NTFJ
3 NTFJ ? A:PRO-A
1 NTFJ ? A:PRO-A , A:CLARIFY
2 NTBT ? B:PRO-Q , A:PRO-A
2 NTBT ? ?
In this figure, each CFG rule has a number in-
dicating how many times the rules has been used.
One of the dialogue fragments that was used to in-
duce this structure is the following excerpt:
utterance dialogue act
A1 how do I do a short code? SET-Q
B1 do you want to program one? PRO-Q
A2 no SET-A
A3 I want to enter a kie* a short code CLARIFY
B2 you want to use a short code? PRO-Q
A4 yes PRO-A
B3 press the VK button SET-A
Unfortunately, many of the 45 induced struc-
tures were very small or involved generalisations
already based on only two input samples. To en-
sure that the grammars produced by DGI gen-
eralise better and are less fragmented, a post-
processing step has been added which traverses
the grammars and eliminates generalisations based
on a low number of samples. In practice, this
means that the post-processing requires the re-
maining grammatical structure to be presented N
times or more in the data.3. The algorithm without
post-processing will be referred to as DGI1; the
algorithm with post-processing as DGI2.
6 Act prediction experiments
To determine how to behave as an interlocutor at
a specific moment of time in a conversation, the
DGI algorithm can be used to infer a SCFG that
models the structure of the interaction. The SCFG
3N = 2 by default, but may increase with the size of the
training data.
10
can then be used to suggest a next dialogue act
to continue the dialogue. In this section, the per-
formance of the proposed SCFG based dialogue
model is compared with the performance of the
well-known n-gram language models, both trained
on intentional level, i.e. on sequences of sets of di-
alogue acts.
6.1 Data
The task-oriented dialogues used in the dialogue
act prediction tasks were drawn from the DIA-
MOND corpus (Geertzen et al, 2004), which con-
tains human-machine and human-human Dutch
dialogues that have an assistance seeking na-
ture. The dataset used in the experiments con-
tains 1, 214 utterances representing 1, 592 func-
tional segments from the human-human part of
corpus. In the domain of the DIAMOND data,
i.e. operating a fax device, the predicates and argu-
ments in the logical expressions of the SC of the
dialogue acts refer to entities, properties, events,
and tasks in the application domain. The appli-
cation domain of the fax device is complex but
small: the domain model consists of 70 entities
with at most 10 properties, 72 higher-level actions
or tasks, and 45 different settings.
Representations of semantic content are often
expressed in some form of predicate logic type
formula. Examples are Quasi Logical Forms (Al-
shawi, 1990), Dynamic Predicate Logic (Groe-
nendijk and Stokhof, 1991), and Underspecified
Discourse Representation Theory (Reyle, 1993).
The SC in the dataset is in a simplified first order
logic similar to quasi logical forms, and is suitable
to support feasible reasoning, for which also theo-
rem provers, model builders, and model checkers
can be used. The following utterances and their
corresponding SC characterise the dataset:
1 wat moet ik nu doen?
(what do I have to do now?)
?x . next-step(x)
2 druk op een toets
(press a button)
?x . press(x) ? button(x)
3 druk op de groene toets
(press the green button)
?x . press(x) ? button(x) ? color(x,?green?)
4 wat zit er boven de starttoets?
(what is located above the starttoets?)
?x . loc-above(x,?button041?)
Three types of predicate groups are distin-
guished: action predicates, element predicates,
and property predicates. These types have a fixed
order. The action predicates appear before element
predicates, which appear in turn before property
predicates. This allows to simplify the semantic
content for the purpose of reducing data sparsity
in act prediction experiments, by stripping away
e.g. property predicates. For instance, if desired
the SC of utterance 3 in the example could be sim-
plified to that of utterance 2, making the semantics
less detailed but still meaningful.
6.2 Methodology and metrics
Evaluation of overall performance in communi-
cation is problematic; there are no generally ac-
cepted criteria as to what constitutes an objective
and sound way of comparative evaluation. An
often-used paradigm for dialogue system evalua-
tion is PARADISE (Walker et al, 2000), in which
the performance metric is derived as a weighted
combination of subjectively rated user satisfac-
tion, task-success measures and dialogue cost.
Evaluating if the predicted dialogue acts are con-
sidered as positive contributions in such a way
would require the model to be embedded in a fully
working dialogue system.
To assess whether the models that are learned
produce human-like behaviour without resorting
to costly user interaction experiments, it is needed
to compare their output with real human responses
given in the same contexts. This will be done by
deriving a model from one part of a dialogue cor-
pus and applying the model on an ?unseen? part
of the corpus, comparing the suggested next dia-
logue act with the observed next dialogue act. To
measure the performance, accuracy is used, which
is defined as the proportion of suggested dialogue
acts that match the observed dialogue acts.
In addition to the accuracy, also perplexity is
used as metric. Perplexity is widely used in re-
lation to speech recognition and language models,
and can in this context be understood as a metric
that measures the number of equiprobable possi-
ble choices that a model faces at a given moment.
Perplexity, being related to entropy is defined as
follows:
Entropy = ?
?
i
p(wi|h) ? log2 p(wi|h)
Perplexity = 2Entropy
11
where h denotes the conditioned part, i.e. wi?1
in the case of bigrams and wi?2, wi?1 in the case
of trigrams, et cetera. In sum, accuracy could be
described as a measure of correctness of the hy-
pothesis and perplexity could be described as how
probable the correct hypothesis is.
For all n-gram language modelling tasks re-
ported, good-turing smoothing was used (Katz,
1987). To reduce the effect of imbalances in the
dialogue data, the results were obtained using 5-
fold cross-validation.
To have an idea how the performance of both
the n-gram language models and the SCFG mod-
els relate to the performance of a simple heuris-
tic, a baseline has been computed which suggests
a majority class label according to the interlocutor
role in the dialogue. The information seeker has
SET-Q and the information provider has SET-A as
majority class label.
6.3 Results for communicative functions
The scores for communicative function prediction
are presented in Table 1. For each of the three
kinds of symbols, accuracy and perplexity are cal-
culated: the first two columns are for the main CF,
the second two columns are for the combination
of speaker identity and main CF, and the third two
columns are for the combination of speaker iden-
tity and all CFs. The scores for the latter two cod-
ings could not be calculated for the 5-gram model,
as the data were too sparse.
As was expected, there is an improvement in
both accuracy (increasing) and perplexity (de-
creasing) for increasing n-gram order. After the
4-gram language model, the scores drop again.
This could well be the result of insufficient train-
ing data, as the more complex symbols could not
be predicted well.
Both language models and SCFG models per-
form better than the baseline, for all three groups.
The two SCFG models, DGI1 and DGI2, clearly
outperform the n-gram language models with a
substantial difference in accuracy. Also the per-
plexity tends to be lower. Furthermore, model
DGI2 performs clearly better than model DGI1,
which indicates that the ?flattening? of non-
terminals which is described in Section 5 results
in better inductions.
When comparing the three groups of sequences,
it can be concluded that providing the speaker
identity combined with the main communicative
function results in better accuracy scores of 5.9%
on average, despite the increase in data sparsity. A
similar effect has also been reported by Stolcke et
al. (2000).
Only for the 5-gram language model, the data
become too sparse to learn reliably a language
model from. There is again an increase in per-
formance when also the last two positions in the
4-tuple are used and all available dialogue act as-
signments are available. It should be noted, how-
ever, that this increase has less impact than adding
the speaker identity. The best performing n-gram
language model achieved 66.4% accuracy; the
best SCFG model achieved 78.9% accuracy.
6.4 Results for dialogue acts
The scores for prediction of dialogue acts, includ-
ing SC, are presented in the left part of Table 2.
The presentation is similar to Table 1: for each of
the three kinds of symbols, accuracy and perplex-
ity were calculated. For dialogue acts that may in-
clude semantic content, computing a useful base-
line is not obvious. The same baseline as for com-
municative functions was used, which results in
lower scores.
The table shows that the attempts to learn to
predict additionally the semantic content of utter-
ances quickly run into data sparsity problems. It
turned out to be impossible to make predictions
from 4-grams and 5-grams, and for 3-grams the
combination of speaker and all dialogue acts could
not be computed. Training the SCFGs, by con-
trast, resulted in fewer problems with data sparsity,
as the models abstract quickly.
As with predicting communicative functions,
the SCFG models show better performance than
the n-gram language models, for which the 2-
grams show slightly better results than the 3-
grams. Where there was a notable performance
difference between DGI1 and DGI2 for CF pre-
diction, for dialogue act prediction there is only a
very little difference, which is insignificant con-
sidering the relatively high standard deviation.
This small difference is explained by the fact that
DGI2 becomes less effective as the size of the
training data decreases.
As with CF prediction, it can be concluded that
providing the speaker identity with the main dia-
logue act results in better scores, but the difference
is less big than observed with CF prediction due to
the increased data sparsity.
12
Table 1: Communicative function prediction scores for n-gram language models and SCFGs in accuracy
(acc, in percent) and perplexity (pp). CFmain denotes the main communicative function, SPK speaker
identity, and CFall all occurring communicative functions.
CFmain SPK + CFmain SPK + CFall
acc pp acc pp acc pp
baseline 39.1?0.23 24.2?0.19 44.6?0.92 22.0?0.25 42.9?1.33 23.7?0.41
2-gram 53.1?0.88 17.9?0.35 58.3?1.84 16.8?0.31 61.1?1.65 16.3?0.59
3-gram 58.6?0.85 17.1?0.47 63.0?1.98 14.5?0.26 65.9?1.92 14.0?0.23
4-gram 60.9?1.12 16.7?0.15 65.4?1.62 15.2?1.07 66.4?2.03 14.2?0.44
5-gram 60.3?0.43 18.6?0.21 - - - -
DGI1 67.4?3.05 18.3?1.28 74.6?1.94 14.8?1.47 76.5?2.13 13.9?0.35
DGI2 71.8?2.67 16.1?1.25 78.3?2.50 14.0?2.39 78.9?1.98 13.6?0.35
Table 2: Dialogue act prediction scores for n-gram language models and SCFGs. DAmain denotes the
dialogue act with the main communicative function, and DAall all occurring dialogue acts.
DAmain SPK + DAmain SPK + DAall
full SC simplified SC
acc pp acc pp acc pp acc pp
baseline 18.5?2.01 31.0?1.64 19.3?1.79 27.6?0.93 18.2?1.93 31.6?1.38 18.2?1.93 31.6?1.38
2-gram 31.2?1.42 28.5?1.03 34.6?1.51 24.7?0.62 35.1?1.30 26.9?0.47 37.5?1.34 26.2?2.37
3-gram 29.0?1.14 34.7?2.82 31.9?1.21 30.5?2.06 - - 29.1?1.28 28.0?2.59
4-gram - - - - - - - -
5-gram - - - - - - - -
DGI1 38.8?3.27 25.1?0.94 42.5?0.96 25.0?1.14 42.9?2.44 27.3?1.98 46.6?2.01 24.6?2.24
DGI2 39.2?2.45 25.0?1.28 42.7?1.03 25.3?0.99 42.4?2.19 28.0?1.57 46.4?1.94 24.7?2.55
The prediction scores of dialogue acts with full
semantic content and simplified semantic content
are presented in the right part of Table 2. For both
cases multifunctionality is taken into account by
including all occurring communicative functions
in each symbol. As can be seen from the table,
the simplification of the semantic content leads to
improvements in the prediction performance for
both types of model. The best n-gram language
model improved with 2.4% accuracy from 35.1%
to 37.5%; the best SCFG-based model improved
with 3.7% from 42.9% to 46.6%.
Moreover, the simplification of the semantic
content reduced the problem of data-sparsity, mak-
ing it also possible to predict based on 3-grams
although the accuracy is considerably lower than
that of the 2-gram model.
7 Discussion
Both n-gram language models and SCFG based
models have their strengths and weaknesses. n-
gram models have the advantage of being very ro-
bust and they can be easily trained. The SCFG
based model can capture regularities that have
gaps, and allow to model long(er) distance rela-
tions. Both algorithms work on sequences and
hence are easily susceptible to data-sparsity when
the symbols in the sequences get more complex.
The SCFG approach, though, has the advantage
that symbols can be clustered in the non-terminals
of the grammar, which allows more flexibility.
The multidimensional nature of the DIT++
functions can be adequately encoded in the sym-
bols of the sequences. Keeping track of the inter-
locutor and including not only the main commu-
nicative function but also other functions that oc-
cur simultaneously results in better performance
even though it decreases the amount of data to
learn from.
The prediction experiments based on main com-
municative functions assume that in case of multi-
functionality, a main function can clearly be iden-
tified. Moreover, it is assumed that task-related
functions are more important than feedback func-
tions or other functions. For most cases, these as-
sumptions are justified, but in some cases they are
13
problematic. For instance, in a heated discussion,
the turn management function could be considered
more important for the dialogue than a simultane-
ously occurring domain specific function. In other
cases, it is impossible to clearly identify a main
function as all functions occurring simultaneously
are equally important to the dialogue.
In general, n-grams of a higher order have a
higher predictability and therefore a lower per-
plexity. However, using high order n-grams is
problematic due to sparsity of training data, which
clearly is the case with 4-grams, and particularly
with 5-grams in combination with complex sym-
bols as for CF prediction.
Considerably more difficult is the prediction of
dialogue acts with realised semantic content, as
is evidenced in the differences in accuracy and
perplexity for all models. Considering that the
data set, with about 1, 600 functional segments,
is rather small, the statistical prediction of logical
expressions increases data sparsity to such a de-
gree that from the n-gram language models, only
2-gram (and 3-grams to some extent) could be
trained. The SCFG models can be trained for both
CF prediction and dialogue act prediction.
As noted in Section 6.2, objective evaluation of
dialogue strategies and behaviour is difficult. The
evaluation approach used here compares the sug-
gested next dialogue act with the next dialogue act
as observed. This is done for each dialogue act in
the test set. This evaluation approach has the ad-
vantage that the evaluation metric can easily be un-
derstood and computed. The approach, however,
is also very strict: in a given dialogue context, con-
tinuations with various types of dialogue acts may
all be equally appropriate. To also take other pos-
sible contributions into account, a rich dataset is
required in which interlocutors act differently in
similar dialogue context with a similar established
common ground. Moreover, such a dataset should
contain for each of these cases with similar dia-
logue context a representative set of samples.
8 Conclusions and future work
An approach to the prediction of communicative
functions and dialogue acts has been presented
that makes use of grammatical inference to auto-
matically extract structure from corpus data. The
algorithm, based on alignment-based learning, has
been tested against a baseline and several n-gram
language models. From the results it can be con-
cluded that the algorithm outperforms the n-gram
models: on the task of predicting the communica-
tive functions, the best performing n-gram model
achieved 66.4% accuracy; the best SCFG model
achieved 78.9% accuracy. Predicting the seman-
tic content in combination with the communica-
tive functions is difficult, as evidenced by moder-
ate scores. Obtaining lower degree n-gram lan-
guage models is feasible, whereas higher degree
models are not trainable. Prediction works better
with the SCFG models, but does not result in con-
vincing scores. As the corpus is small, it is ex-
pected that with scaling up the available training
data, scores will improve for both tasks.
Future work in this direction can go in sev-
eral directions. First, the grammar induction ap-
proach shows potential of learning dialogue game-
like structures unsupervised. The performance on
this task could be tested and measured by applying
the algorithm on corpus data that have been anno-
tated with dialogue games. Second, the models
could also be extended to incorporate more infor-
mation than dialogue acts alone. This could make
comparisons with the performance obtained with
reinforcement learning or with Bayesian networks
interesting. Third, it would be interesting to learn
and apply the same models on other kinds of con-
versation, such as dialogue with more than two in-
terlocutors. Fourth, datasets could be drawn from
a large corpus that covers dialogues on a small
but complex domain. This makes it possible to
evaluate according to the possible continuations
as found in the data for situations with similar di-
alogue context, rather than to evaluate according
to a single possible continuation. Last, the rather
unexplored parameter space of the DGI algorithm
might be worth exploring in optimising the sys-
tem?s performance.
References
Jan Alexandersson and Norbert Reithinger. 1997.
Learning dialogue structures from a corpus. In
Proceedings of Eurospeech 1997, pages 2231?2234,
Rhodes, Greece, September.
Hiyan Alshawi. 1990. Resolving quasi logical forms.
Computational Linguistics, 16(3):133?144.
Harry Bunt. 2000. Dialogue pragmatics and context
specification. In Harry Bunt and William Black, ed-
itors, Abduction, Belief and Context in Dialogue;
Studies in Computational Pragmatics, pages 81?
150. John Benjamins, Amsterdam, The Netherlands.
14
Harry Bunt. 2006. Dimensions in dialogue annota-
tion. In Proceedings of the 5th International Confer-
ence on Language Resources and Evaluation (LREC
2006), pages 1444?1449, Genova, Italy, May.
Jeroen Geertzen and Menno M. van Zaanen. 2004.
Grammatical inference using suffix trees. In
Proceedings of the 7th International Colloquium
on Grammatical Inference (ICGI), pages 163?174,
Athens, Greece, October.
Jeroen Geertzen, Yann Girard, and Roser Morante.
2004. The DIAMOND project. Poster at the 8th
Workshop on the Semantics and Pragmatics of Dia-
logue (CATALOG 2004), Barcelona, Spain, July.
John Godfrey, Edward Holliman, and Jane McDaniel.
1992. SWITCHBOARD: Telephone speech corpus
for research and development. In Proceedings of the
ICASSP-92, pages 517?520, San Francisco, USA.
Jeroen Groenendijk and Martin Stokhof. 1991. Dy-
namic predicate logic. Linguistics and Philosophy,
14(1):39?100.
Slava M. Katz. 1987. Estimation of probabilities from
sparse data for the language model component of a
speech recognizer. IEEE Transactions on Acoustics,
Speech, and Signal Processing, 35(3):400?401.
Oliver Lemon, Kallirroi Georgila, and James Hender-
son. 2006. Evaluating effectiveness and portabil-
ity of reinforcement learned dialogue strategies with
real users: The talk towninfo evaluation. In Spoken
Language Technology Workshop, pages 178?181.
Joan A. Levin and Johanna A. Moore. 1988. Dialogue-
games: metacommunication structures for natural
language interaction. Distributed Artificial Intelli-
gence, pages 385?397.
Esther Levin, Roberto Pieraccini, and Wieland Eck-
ert. 1998. Using markov decision process for
learning dialogue strategies. In Proceedings of the
ICASSP?98, pages 201?204, Seattle, WA, USA.
Lori Levin, Klaus Ries, Ann Thyme?-Gobbel, and Alon
Lavie. 1999. Tagging of speech acts and dialogue
games in spanish call home. In Proceedings of ACL-
99 Workshop on Discourse Tagging, College Park,
MD, USA.
Masaaki Nagata and Tsuyoshi Morimoto. 1994. First
steps towards statistical modeling of dialogue to pre-
dict the speech act type of the next utterance. Speech
Communication, 15(3-4):193?203.
Tim Paek. 2006. Reinforcement learning for spoken
dialogue systems: Comparing strenghts and weak-
nesses for practical deployment. In Interspeech
Workshop on ?Dialogue on Dialogues?.
Massimo Poesio and Andrei Mikheev. 1998. The
predictive power of game structure in dialogue
act recognition: Experimental results using maxi-
mum entropy estimation. In Proceedings Interna-
tional Conference on Spoken Language Processing
(ICSLP-98), Sydney, Australia, December.
Livia Polanyi and Remko Scha. 1984. A syntactic ap-
proach to discourse semantics. In Proceedings of
the 10th international conference on Computational
linguistics, pages 413?419, Stanford, CA, USA.
Norbert Reithinger and Elisabeth Maier. 1995. Uti-
lizing statistical dialogue act processing in VERB-
MOBIL. In Proceedings of the 33rd annual meeting
on the Association for Computational Linguistics
(ACL), pages 116?121, Cambridge, Massachusetts.
Association for Computational Linguistics (ACL).
Uwe Reyle. 1993. Dealing with ambiguities by under-
specification: Construction, representation and de-
duction. Journal of Semantics, 10(2):123?179.
Emanuel A. Schegloff. 1968. Sequencing in con-
versational openings. American Anthropologist,
70:1075?1095.
Andreas Stolcke, Klaus Ries, Noah Coccaro, Eliza-
beth Shriberg, Rebecca Bates, Daniel Jurafsky, Paul
Taylor, Rachel Martin, Carol Van Ess-Dykema, and
Marie Meteer. 2000. Dialogue act modeling for
automatic tagging and recognition of conversational
speech. Computational Linguistics, 26(3):339?373.
Richard S. Sutton and Andrew G. Barto. 1998. Re-
inforcement Learning: An Introduction (Adaptive
Computation and Machine Learning). MIT Press,
March.
Menno van Zaanen and Pieter W. Adriaans. 2001.
Comparing two unsupervised grammar induction
systems: Alignment-Based Learning vs. EMILE.
Technical Report TR2001.05, University of Leeds,
Leeds, UK, March.
Menno M. van Zaanen. 2002. Bootstrapping Structure
into Language: Alignment-Based Learning. Ph.D.
thesis, University of Leeds, Leeds, UK, January.
Andrew J. Viterbi. 1967. Error bounds for convolu-
tional codes and an asymptotically optimum decod-
ing algorithm. IEEE Transactions on Information
Theory, 13(2):260?269, April.
Marilyn Walker, Candace Kamm, and Diane Litman.
2000. Towards developing general models of usabil-
ity with paradise. Natural Language Engineering,
6(3-4):363?377.
Ian H. Witten and Timothy C. Bell. 1991. The zero-
frequency problem: Estimating the probabilities of
novel events in adaptive text compression. IEEE
Transactions on Information Theory, 37(4):1085?
1094.
Steve Young. 2002. The statistical approach to the
design of spoken dialogue systems. Technical Re-
port CUED/F-INFENG/TR.433, Engineering De-
partment, Cambridge University, UK, September.
15
