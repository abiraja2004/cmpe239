Towards the Generations.of Rebul;tals in a Bayesian 
Argumentation System 
Natha l ie  J i tnah ,  Ingr id  Zukerman,  R ichard  McConachy  and  Sarah  George 
School  of  Computer  Sc ience and Sof tware  Eng ineer ing  
Monash  Un ivers i ty  
C layton ,  V ic tor ia  3800, AUSTRAL IA  
emaih {nj  i tnah ,  ingr id ,  r i cky ,  sarahg}@csse ,  monash ,  edu .  au 
Abst ract  
We describe a mechanism which generates rebuttals 
to a user's rejoinders in the context of arguments 
generated from Bayesian etworks. This mechanism 
is implemented in an interactive argumentation sys- 
tem. Given an argument generated by the system 
and an interpretation f a user's rejoinder, the gener- 
ation of the rebuttal takes into account the intended 
effect of the user's rejoinder, determined on a model 
of the user's beliefs, and its actual effect, determined 
on a model of the system's beliefs. We consider three 
main rebuttal strategies: refute the user's rejoinder, 
strengthen the argument goal, and dismiss the user's 
line of reasoning. 
1 In t roduct ion  
During argumentation, conversational partners of- 
ten use expressions of doubt, such as "But the vic- 
tim was stabbed", and requests for the considera- 
tion of additional facts they consider elevant, such 
as "What about the fingerprints found on the gun?". 
In this paper, we describe a mechanism which gen- 
erates rebuttals to such rejoinders in the context of 
arguments generated from Bayesian etworks (BNs) 
(Pearl, 1988). This mechanism is implemented in 
a system called BIAS (Bayesian Interactive Argu- 
mentation System). Given an argument produced 
by BIAS and a follow-up rejoinder posed by a user, 
our mechanisln generates a rebuttal on tim basis of a 
line of reasoning identified by BIAS from the user's 
rejoinder. These capabilities constitute a significant 
step towards allowing a user to interact freely with 
an argumentation system and to improve the expla- 
nation capability of Bayesian systems. 
Normal arguments are unconstrained in the sense 
that they can use whatever means are available to 
? justify a goal proposition:i,:"In'~conterast, rebuttals 
are constrained, since they must address the point 
through which the conversational partner attempted 
to undermine or question a previous argument. To 
illustrate the operation of BIAS and its rebuttal ca- 
pability, consider the exchange in Figure 1, which 
consists of a preamble that contains background in- 
formation~ followed by an argument generated by 
BIAS, a user's rejoinder and BIAS' rebuttal. 1 The 
domain of implementation is a murder investigation 
where the question under consideration (the goal 
proposition) is "Did Mr Green murder Mr Body?", 
and both the user and the system have access to evi- 
dence. After the presentation of the argument where 
BIAS contends Mr Green's possible innocence, 2 the 
user presents a rejoinder which requests that BIAS 
consider a fact that was omitted from the argument: 
The \]found gun is available only to Mr Green. BIAS 
infers from this rejoinder that the user is adding sup- 
port to Mr Green having the means to kill Mr Body, 
and hence to Mr Green's guilt, through the following 
line of reasoning, which is determined as described 
in (Zukerman et al, 2000): The gun being available 
only to Mr Green ~ The gun was fired by Mr Green 
Mr Green had the means to kill Mr Body -+ Mr 
Green killed Mr Body. BIAS finds that it does not 
share the user's belief in the rejoinder proposition, 
and that in addition, the effect of this proposition on 
the goal is rather weak. This prompts the genera- 
tion of a rebuttal of the form Deny-Dismiss-Follow, 
whereby the rejoinder proposition is denied, its effect 
on the goal proposition is dismissed, and its impli- 
cations are followed hypothetically until they break 
down due to the marginal effect of the rejoinder on 
Mr Green's guilt. 
In the next section, we present our knowledge rep- 
resentation formalism, followed by an outline of our 
procedure for determining a user's line of reasoning. 
In Section 4, we describe our algorithm for rebuttal 
generation and discuss our results. We then review 
related work and present concluding remarks. 
2 ' -  Knowledge Representat ion  
During the argumentation process, BIAS maintains 
two models of belief: a normative model and a user 
model,eaeh-of-which is-represented as a BN. The 
normative model contains information gathered i- 
rectly by BIAS from the murder scenario, while the 
user model stores propositions that are presumed to 
1The argument  and rebuttals hown in this paper are re- 
alized in English as described in (Zukerman et al, 1999). 
2The mechanism which generates this argument is de- 
scribed in (Zukerrnan et al, 1998). 
39 
Preamble: 
Mr. Body was found.dead in his bedroom, which is in .the.seecond .story. of.his.house. Bul letwounds 
were found in Mr. Body's body. The bedroom window was broken and broken glass was found inside 
the window. A gun was found on the premises, and some fingerprints were found on the gun. In 
addition, inspection of the. grounds revealed footprints in the garden and circular indentations in the 
ground outside the bedroom window. 
BIAS' argument: 
Bullets being found in Mr Body's body implies Mr Body was almost certainly shot. This implies he 
was almost certainly murdered. 
Forensics matching the bullets with the found gun implies the gun is almost certainly the murder 
weapon. Forensics matching the fingerprints,witth Mr.Gr.een implies_Mr Gregn~ probably fired the gun. 
This together with the gun almost certainly being the murder weapon implies Mr Green probably 
fired the murder weapon, which implies he very probably had the means to murder Mr Body. 
The Bayesian Times reporting Mr Body took Mr Green's girlfriend implies Mr Green and Mr Body 
possibly were enemies, which implies Mr Green possibly had a motive to murder Mr Body. 
The neighbour eporting Mr Green not being in the garden at 11 implies Mr Green very probably 
wasn't in the garden at 11. 
Forensics reporting the time of death being 11 and the forensic analysis of the time of death being 
reliable implies the time of death was probably 11, which together with Mr Green very probably not 
being in the garden at 11 implies he probably wasn't in the garden at the time of death. This implies 
he probably didn't have the opportunity to murder Mr Body. 
Even though Mr Green very probably had the means to murder Mr Body and he possibly had a 
motive to murder Mr Body, Mr Green probably not having the opportunity to murder Mr Body 
implies he probably didn't murder Mr Body. 
User 's  re jo inder:  Consider that the found gun is available only to Mr Green. 
BIAS' rebuttal: 
Actually, it is very improbable that the found gun is available only to Mr Green. However, even if it 
was available only to Mr Green, this would have only a small effect on the likelihood that Mr Green 
murdered Mr Body. This is for the following reason. 
The found gun being available only to Mr Green implies it is more likely that Mr Green fired the gun, 
making it almost certain. This implies it is more likely that he fired the murder weapon, making it 
almost certain, which implies it is even more likely that he had the means to murder Mr Body. This 
implies it is only slightly more likely that he murdered Mr Body. 
Figure 1: Sample Argument, Rejoinder and Rebuttal 
be believed by the user. These propositions may be 
obtained from a variety of sources, e.g., they may 
have been inspected by the user in the murder sce- 
nario (by means of a WWW interface), or appear in 
BIAS' previous arguments or the user's rejoinders. 
Arguments generated by BIAS are represented by 
means of an Argument Graph - a sub-network of 
the normative model BN which ideally also contains 
nodes from the user model BN. 
The interpretation process, where BIAS identifies 
the reasoning path intended by the user, takes place 
in the user model; since ,BIAS tries, to .%nake sense"- 
of what the user is saying according to the system's 
view of the user's beliefs (Zukerman et al, 2000). 
In contrast, the processes for generating the initial 
argument and the rebuttals consult both tile user 
model and the normative model to produce argu- 
ments that rely on beliefs held by both BIAS and 
tile user if possible. Further, during rebuttal gener- 
ation, the choice of a rebuttal strategy depends on 
the intended effect of the user's argument (according 
to the user model) and its actual effect (according 
to the normative model). 
3 Determin ing  a User ' s  L ine  o f  
Reason ing  
Our procedure for recognizing a user's intended line 
of reasoning from his/her rejoinder eceives two in- 
puts: a linguistic clue ("but" or "consider") and a 
rejoinder proposition (R), e.g., "but Mr Green was 
in the garden"~..It then-finds paths in the user model 
BN that connect R to the goal proposition (Zuker- 
man et al, 2000). During this process, BIAS copes 
with inference patterns that are different from its 
own by allowing inferred paths to contain a small 
"gap" composed of propositions that did not ex- 
ist previously in the user model. Figure 2(a) il- 
lustrates an Argument Graph, a rejoinder R, and 
40 
(a) Argument Graph and userPath 
M~ I ') 
A 
(c) Dismiss userPath: 
R = userVal has small effect on G 
for BIAS 
Figure 2: Sample Argument 
path R-I-M-E-A-G between them (composed of grey 
nodes). This path, called userPath, represents the 
line of reasoning intended by the user. The gap in 
this path contains nodes I and M (in italics), which 
means that the user inferred E directly from R. 
Each path is assigned a score based on the fol- 
lowing factors: the impact of R on BIAS' argu- 
ment along this path, whether path nodes are in 
the user's attentional focus, and BIAS' confidence in 
this path (determined from the information source 
of the nodes in this path, e.g., whether the user has 
seen the propositions in the path, asserted a be- 
lief about them or read them in BIAS' arguments). 
BIAS then selects the highest-scoring path. If sev- 
eral paths have a high score, the user is asked to 
choose one of them. Typically,-BIAS returns a single 
path, and sometimes it returns two or three paths. 
Hence, presenting them to the user for selection is a 
reasonable course of action. 
4 Rebut ta l  Generat ion  
Given a user's rejoinder proposition R, we consider 
three main types of rebuttals: (1) refute R, (2) dis- 
(b) Refute R: 
R = userVal has large effect on G; 
BIAS and the user disagree on R 
- i - . _@ 
(d) Strengthen G: 
R = userVal has large effect on G; 
BIAS and the user agree on R 
Graph and Rejoinder Strategies 
miss the line of reasoning intended by the user (user- 
Path), and (3) strengthen the argument goal G. Di- 
agrammatic representations of these rebuttal strate- 
gies and abridged versions of their applicability con- 
ditions appear in Figure 2(b-d). These conditions, 
which are specified in the following sections, depend 
oil (1) whether the rejoinder affects the system's ar- 
gument directly or indirectly, (2) the beliefs in R in 
the normative and user models, and (3) the impact 
of R on the goal proposition along userPath in the 
normative and user models. 
4.1 Refute  the rejoinder 
This strategy consists of generating an argument 
against he user's belief in the rejoinder proposition 
R. This strategy.isapplicable under the following 
conditions: . . . . . .  
(R1) The beliefs in R in the user model and the 
normative model differ significantly (the user's 
belief in R contradicts BIAS' belief); and 
(R2) Either 
(a) R was stated or implied in BIAS' argument 
(R appears in the Argument Graph), or 
41 
(b) The belief in R stated by the user has a 
significant.effect on. the goal G in ,the nor- 
mative model in the same direction as its 
effect on G in the user model. 
For example, if the user's rejoinder to the argu- 
ment in Figure 1 was "But Mr Green and Mr Body 
were not enemies", then conditions R1 and R2a 
would be satisfied, since the rejoinder directly con- 
tradicts what was stated by BIAS in the argument. 
If the user's rejoinder was "But the neighbour saw 
Mr Green shoot ..Mr, Body~!-i.~then :.conditions-,R1 
and R2b would be satisfied, since an inference from 
this rejoinder contradicts BIAS' belief in Mr Green's 
lack of opportunity to kill Mr Body (and conse- 
quently in Mr Green's guilt). The argument schema 
for the refute the rejoinder strategy and a sample 
rebuttal produced with this schema are shown in 
Figure 3. a The sub-argument that argues against 
the rejoinder proposition is generated by activating 
our Bayesian argument generator (Zukerman et al, 
1998) with the proposition Mr Green and Mr Body 
were enemies as the goal. In this case, the belief in 
the rejoinder node resulting from the sub-argument 
differs from that stated in the initial argument, ow- 
ing to the additional information included in the 
sub-argument. Hence, the implications from the re- 
joinder node are followed. The procedure for follow- 
ing these implications is described in Section 4.2. 
4.2 Dismiss the user's line of reasoning 
This strategy consists of showing the user how 
his/her argument fails to achieve its intended ef- 
fect. We distinguish between concessive and con- 
tradictory dismissals. The former is used when the 
system agrees with the rejoinder proposition R, and 
the latter when the system disagrees with R. This 
strategy is applicable under the following condition: 
(D) R does not significantly affect the belief in G 
in the normative model. 
This condition is illustrated by the rejoinder to the 
argument in Figure 1, "Consider that the found gun 
was available only to Mr Green", which purports to 
increase the belief in Mr Green's means to kill Mr 
Body, and hence Mr Green's guilt. However, since 
this increment is quite small, BIAS adopts the dis:. 
missal strategy, which follows the effect of the user's 
rejoinder through the user's line of reasoning, point- 
ing out how the effect of the rejoinder differs from its 
intended effect. It is worth noting that the main dif- 
ference between a dismissal and a strengthening of
the goal is that BIAS decides to generate a dismissal 
when its current beliefs are sufficient to invalidate 
the user's line of reasoning, whereas it decides to 
aThe rejoinders shown in this paper are posed by the user 
immediately after the argument in Figure 1. 
Refute R: 
t .  Deny, the behef in"R stated by the'user. 
2. Present a sub-argument for the normative 
belief in R. 
3. If R is not in the Argument Graph or the 
belief in R as a result of the sub-argument 
differs from that originally stated by BIAS, 
then follow the effect of R along userPath 
up to the first node in the Argument Graph 
... .  vchose belief.is, the ~ same.as ..that stated in 
the initial argument. 
Rejoinder: 
But Mr Green and Mr Body were not enemies. 
Rebuttal :  
Actually, it is quite likely that Mr Green and 
Mr Body were enemies. This is for the following 
reason. 
The forensic analysis of the blue paint being 
reliable and forensics having found some blue 
paint which they estimate is one week old im- 
plies a blue car was here last week. This to- 
gether with Mr Green having a blue car implies 
Mr Green's car was almost certainly here last 
week, which implies Mr Green almost certainly 
visited Mr Body last week. 
The neighbour being sober implies she is very 
probably reliable. This together with the neigh- 
bour reporting Mr Green arguing with Mr Body 
last week implies the neighbour very probably 
heard Mr Green arguing with Mr Body last 
week, which together with Mr Green almost 
certainly visiting Mr Body last week implies he 
almost certainly argued with Mr Body. 
The Bayesian Times reporting Mr Body took 
Mr Green's girlfriend implies Mr Body prob- 
ably seduced Mr Green's girlfriend. This to- 
gether with Mr Green almost certainly arguing 
with Mr Body implies Mr Green and Mr Body 
probably were enemies. 
Let's now go back to the main argument. 
Mr Green and Mr Body probably being enemies 
implies it is more likely that Mr Green had a 
motive to murder Mr Body, making it rather 
likely. This implies it is only slightly more likely 
that he murdered Mr Body. 
Figure 3: Refute the rejoinder Schema nd Example 
strengthen the goal when additional information is 
required to defeat he impact of the user's rejoinder. 
Our algorithm for dismissing the user's line of rea- 
soiling follows userPath until it reaches a point where 
the user's line of reasoning fails, i.e., it has no ef- 
fect on a proposition on userPath in tile Argument 
Graph. It is necessary for the rebuttal to reach the 
42 
Argument Graph even if the failure of the rejoinder 
occurs earlier in userPathrbecause the user's ~ejoin= . 
der refers to the argument, hence at least one propo- 
sition in the argument must be mentioned when ad- 
dressing the impact of this rejoinder. 
The user's line of reasoning may fail due to the 
following factors: (1) s/he did not consider propo- 
sitions that have a significant effect on the propo- 
sitions in userPath; or (2) his/her belief in one or 
more of the propositions /he did consider differs 
significantly from thatSn t.he normative model, .and 
this proposition has a substantial ~effect on a pr,515o--:: 
sition in userPath. Propositions of the first type are 
included in a set called SIGneighbours, and proposi- 
tions of the second type are included in DIFFneigh- 
bouts. Our dismissal algorithm calls our Bayesian ar- 
gument generator to generate sub-arguments for the 
propositions in DIFFneighbours, but simply presents 
the propositions in SIGneighbours without arguing 
for them. 
A lgor i thm DismissUserReasoning( userPath) 
Let userPath be composed of propositions 
R=Po--+ PI ~ P2--+...--+ Pr,=G. 
1. For i= l tondo:  
(a) Set SIGneighbours(Pi) to the nodes that 
are linked to Pi in the normative model but 
not in the user model and have a significant 
effect on the belief in Pi. 
(b) If the belief in Pi in the user model 
differs significantly from the belief in 
Pi in the normative model, then set 
DIFFneighbours(Pi) to the nodes that are 
linked to Pi in both the user model and the 
normative model and which have a differ- 
ent belief in the user model from that in 
the normative model. 
(c) For each node Pj E DIFFneighbours(Pi) 
generate a sub-argument for the normative 
belief in Pj. 
2. Present. the resulting rebuttal using the appro- 
priate schema, DismissContradict or Dismiss- 
Concede (Figures 4 and 5 and respectively). 
Our concessive schema differs fi'om our contradic- 
tory" schema in two respects. Firstly,, the former ac- 
knowledges the user's rejoinder, while the latter de- 
nies it. In addition, the concessive schema follows 
the user's line of reasoning-starting,from the nor- 
mative belief in the rejoinder proposition (which is 
close to the belief indicated by the user), while the 
contradictory" schema follows a hypothetical line of 
reasoning starting from the user's belief in the re- 
joinder proposition (which differs substantially from 
the normative belief). In both cases the user's line 
of reasoning fizzles out, due to its small effect on the 
DismissContradict userPath: 
...... t".-Deny -tiie~betiefdn. ~ - stated . . . . . . . . . . . . . .  -'by the user," 
and dismiss its hypothetical effect on the 
goal proposition. 
2. Present he sub-arguments for the nodes in 
DIFFneighbours. 
3. FollowPath userPath from the rejoinder 
proposition to the goal. 
Fo l lowPath  userPath 
For i :-= 0 to:.n.X-~:t.,.(whe/'e'n is-i;h&i4umber of 
nodes in userPath) do: 
1. If Pi+l is not in the Argument Graph or 
DIFFneighbours(Pi+l)?O, then present an 
implication from Pi to Pi+l which includes 
the nodes linked to Pi+l in the user model 
plus the nodes in SIGneighbours(Pi+l ). 
Else present an implication which reflects 
only the relative impact of Pi on Pi+l. 
2. If the resulting belief in Pi+l is the same 
as that stated in the initial argument, then 
stop. 
Figure 4: DismissContradict Schema and Follow- 
Path Procedure 
goal according to the normative model irrespective 
of its truth value. 
Both schemas follow userPath from tile rejoinder 
proposition to the goal using procedure FollowPath 
(Figure 4). This procedure distinguishes between 
propositions in userPath for which the main influ- 
encing factors (DIFFneighbours and SIGneighbours) 
should be presented, and those which require only 
information regarding the relative impact of the pre- 
ceding proposition in userPath. The latter proposi- 
tions are characterized as follows: (1) they appear 
in the Argument Graph; and (2) the user's beliefs in 
the nodes outside userPath that have a significant 
effect on these propositions are consistent with the 
normative beliefs in these nodes. For instance, the 
rebuttal in Figure 1~ which is generated by means of 
the DismissContradict schema, presents the relative 
influence of Mr Green fired the gun on Mr Green 
fired the murder weapon, since the user and BIAS 
hold consistent beliefs regarding the gun being the 
murder weapon. 
? " To iltustratte"t.he operation 'Of t-he dismissal algo- 
rithm, let us consider the rejoinder "But the time of 
death was 11", which yields the following line of rea- 
soning: The time of death was 11 (~ Mr Green was 
in the garden at 11) ~ Mr Green was in the .qarden 
at the time of death + Mr Green had the opportu- 
nity to kill Mr Body ---+ Mr Green killed Mr Body. 
DIFFneighbours includes only one proposition, Mr 
43 
DismissConcede userPath:  
1. Acknowledge.the,belief"in'-R stated bythe  
user, and dismiss its effect on the goal 
proposition. 
2. Present he sub-arguments for the nodes in 
DIFFneighbours. 
3. FollowPath userPath from the rejoinder 
proposition to the goal. 
Rejoinder: But the time of death was 11. 
Rebuttal: -: . . . . . . . . . .  
Indeed, it is quite likely but not entirely certain 
that the time of death was 11. However, this 
has only a small effect on the likelihood that 
Mr Green murdered Mr Body. 
I will show that Mr Green almost certainly 
wasn't in the garden at 11. 
Mr Green's witness not being related to Mr 
Green implies she is very probably reliable. 
This together with Mr Green's witness report- 
ing Mr Green being at the football at 10:30 
implies Mr Green was almost certainly at the 
football at 10:30. 
The neighbour being sober implies she is almost 
certainly reliable. This together with the neigh- 
bour reporting Mr Green not being in the gar- 
den at 11 implies the neighbour never saw Mr 
Green in the garden at 11, which together with 
Mr Green almost certainly being at the football 
at 10:30 implies he almost certainly wasn't in 
the garden at 11. 
Let's now go back to the main argument. 
Even though the time of death was probably 
11, Mr Green almost certainly not being in the 
garden at 11 implies it is only slightly less likely 
that he was in the garden at the time of death. 
This implies it is only slightly less likely that 
he had the opportunity to murder Mr Body, 
which implies it is only slightly less likely that 
he murdered Mr Body. 
Figure 5: DismissConcede Schema and Example 
Green was in the garden at 11, since the belief in it 
in the normative model differs from that in the user 
model, thereby prompting the generation of a sub- 
argument for this proposition.. This sub-argument 
is stronger than that incorporated in the initial ar- 
gument, yielding a belief in Mr  Green.being in the 
garden at 11 that is lower than the belief indicated 
in the original argument, which in turn reduces the 
belief in Mr Green being in the garden at the time of 
death, Mr Green having the opportunity to kill Mr 
Body, and Mr Green actually nmrdering Mr Body. 
The resulting rebuttal, which is presented by means 
of the DismissConcede schema, appears in Figure 5. 
4.3 Strengthen the goal 
: .:This: strategy, consist~-of.germrafing a stronger argu- 
ment for the original goal proposition G, bringing to 
bear information that did not appear in the initial 
argument (either because BIAS was unaware of it 
or because BIAS chose to exclude it from the argu- 
ment). This strategy is applicable under the follow- 
ing conditions: 
(G1) The beliefs in R in the normative and user 
models are consistent; and 
(G2) Rhas  a=Substantia\] detrimentgI effect on the 
belief in G in the normative model. This change 
in belief should be in the same direction as the 
change occurring in the user model. 
These conditions represent a situation where the 
system did not take into account a particular fact, 
but when this fact comes to its attention the sys- 
tem realizes the effect of this fact on the goal. For 
instance, if the user discovers new evidence that 
places Mr Green in the garden at 11, a rejoinder 
which presents this proposition will increase the be- 
lief in Mr Green's opportunity to kill Mr Body along 
the following line of reasoning: Mr Green was in 
the garden at 11 -+ Mr Green was in the garden at 
the time of death --+ Mr Green had the opportunity 
to kill Mr Body ~ Mr Green killed Mr Body. In 
this case, BIAS tries to strengthen the argument for 
Mr Green's innocence by arguing separately against 
propositions along this line of reasoning (other than 
the rejoinder node, which is true in this example). 
If no sub-argument can be generated for these nodes 
or the generated sub-arguments do not significantly 
affect the goal, then BIAS agrees with the user. 
Our algorithm for strengthening the goal searches 
along userPath for propositions that have been af- 
fected by the rejoinder, but that will reinforce BIAS' 
goal proposition if their belief is changed. It then 
tries to generate sub-arguments that change the be- 
liefs in these propositions. In order to localize the 
effect of the user's rejoinder, the search and sub- 
argument generation processes tart at R and pro- 
ceed towards the goal. The presentation of the re- 
buttal is also done in this order, using a procedure 
which is similar to the FollowPath procedure de- 
scribed in Section 4.2. 
A lgor i thm StrengthenGoal( userPath) 
Let userPath be composed of propositions 
R=Po---~ Pi ~ P2-+. . . -~  Pn=G. 
1. For i = 1 to n, while the belief in G is not as 
intended by BIAS, do: 
(a) Determine which belief in Pi will move the 
belief in G in the normative model in the 
direction intended by BIAS. 
(b) If this belief in Pi differs from the current 
belief in Pi, then 
44 
i. Generate a sub-argument for the de- 
sired belief in Pi. 
ii. If the sub-argument yields a significant 
change in the belief in Pi or in the be- 
lief in G then store the sub-argument in 
SubAG(P~). 
2. Present he resulting rebuttal (composed of the 
user's line of reasoning and intervening sub- 
arguments) using the StrengthenGoal schema 
in  Figure 6. 
To illustrate the operation of this algorithm, let 
us reconsider the rejoinder "Consider Mr Green was 
in the garden at 11", and let us assume that the re- 
joinder proposition is true. Inspection of the prop- 
ositions affected by this rejoinder eveals that if Mr 
Green was not in the garden at the time of death, 
then the belief in the goal would be closer to that 
intended by BIAS. However, an argument for this 
proposition cannot be generated. Hence, BIAS pro- 
ceeds to the next proposition, Mr Green had the op- 
portunity to murder Mr Body, and calls our Bayesian 
argument generator to generate an argument hat 
contradicts this proposition. The Bayesian genera- 
tor produces an argument which reduces the belief 
in this proposition. However, this belief cannot be 
reduced to the extent hat it exculpates Mr Green. 
Thus, BIAS attempts to generate an argument for 
the goal node (by trying to reduce the belief in Mr 
Green's means and motive to kill Mr Body). How- 
ever, this attempt also fails, leaving BIAS with a 
moderate belief in Mr Green's guilt. 4 
It is important o note that although BIAS' im- 
mediate objective is to strengthen its belief in the 
goal proposition, its primary purpose is to "tell the 
truth" to the best of its knowledge (which may con- 
tradict its initial beliefs), rather than to win the ar- 
gument at all costs. Our algorithm supports this 
attitude by retaining any sub-argument which has 
a significant impact on the goal or on a proposi- 
tion on userPath. We use this disjunctive condition 
on impacts in order to address a situation where a 
proposition Pj on userPath has been affected by a 
sub-argument, but does not affect the goal because 
of an inaccurate belief in aproposition Pk which ap- 
pears later on userPath:(recalt that the propositions 
are inspected from R towards the goal). However, 
S t rengthenGoa l  userPath: 
.... t-. ~Aekn0wledge~the.~etief.in'-R stated"by the" 
user, and set lastProposition to R. 
2. Until the goal proposition is reached o: 
(a) If after lastProposition there is a 
proposition Pi EuserPath for which 
a sub-argument was generated 
(SubAG(Pi)? 0), then 
i. Follow userPath from lastProposi- 
tion-to-Pi. . . . .  
ii. Present he sub-argument for Pi. 
iii. Set lastProposition to Pi. 
(b) Else follow the remainder of userPath. 
Figure 6: Strengthen the goal Schema 
5 Re la ted  Research  
Our research builds on work described in (Zukerman 
et al, 1998), which generated arguments from BNs, 
and (Zukerman et al, 1999), which enabled a user 
to explore the impact of different propositions on 
the generated arguments. The former system only 
generated arguments, while the latter received in- 
structions from a user (through a menu) about mod- 
ifications to be performed to a previously generated 
argument, e.g., including or excluding a proposition, 
and then generated a new argument in response to 
these instructions. Neither of these systems gener- 
ates rebuttals which take into account a user's in- 
tentions, as done by BIAS. 
Several researchers have dealt with different as- 
pects of argumentation; e.g., (Flowers et al, 1982; 
Quilici, 1992; Chu-Carroll and Carberry, 1995; Car- 
berry and Lambert, 1999). Like BIAS, the system 
described in Carberry and Lambert (1999) combined 
linguistic and contextual knowledge to recognize a
user's intentions from rejoinders. However, their 
system did not generate rebuttals. Chu-Carroll and 
Carberry (1995) provided a comprehensive approach 
for proposal evaluation which focused on dialogue 
strategies rather than argumentation strategies. In 
additiom they considered exchanges where each par- 
ticipant utters one or two propositions in each con- 
versational turn. In contrast, we focus on strategies 
for the generation of extended probabilistie rebuttals 
to individual rejoinders. In the future, our strategies 
once a sub-argument for Patispresented, then Pj af,: ;, ?will be~'e0mbined with.'dialbgue stra~gies in a corn- 
fects the goal. If BIAS accepted only sub-arguments 
for propositions which have a significant impact on 
the goal, then in this case it would miss the oppor- 
tunity to strengthen the goal. 
1The resulting argument has not been included owing to 
space limitations, 
plete argumentation system. 
Flowers et al (1982) presented a partial theory 
of argumentation which advocated the combination 
of distinct knowledge sources; their implementation 
focused on recognizing and providing episodic justi- 
fications to historical events. Our focus oil the gen- 
eration of rebuttals in the context of BNs allows us 
45 
to provide an operational definition for the broad 
argumentation strategies discussed in the l i terature,  
e.g., attack the main point directly or attack the- 
supporting evidence (Flowers et al, 1982). 5
The argumentation system described in (Quilici, 
1992) used a plan-based model of the user's beliefs to 
recognize the justification for-a user's proposal and 
provide its own justifications. However, the rebut- 
tals generated by this system were based on a single 
strategy: applying backwards chaining using a set of 
justification rules. This strategy is a special case of 
the more general rebuttal Schemas presented here. 
6 Conclusion and Future Work 
We have offered a mechanism for generating rebut- 
tals to a user's rejoinders in the context of argu- 
ments generated by a Bayesian argumentation sys- 
tem. We have implemented three main argumenta- 
tion strategies: refuting the rejoinder, strengthening 
the argument goal, and dismissing the user's line of 
reasoning. For each strategy we have identified ap- 
plicability conditions, proposed a procedure which 
determines the information to be included in a re- 
buttal, and defined a presentation schema. 
An interesting area of future research pertains 
to the omission of information from an argument. 
There are different ypes of information which may 
be omitted from an argument, such as (1) easily 
inferred information and information which has a 
small effect on the argument; (2) information which 
is required for representational reasons, but makes 
the resulting argument more confusing; (3) proba- 
bilistic information which, although correct, makes 
the resulting argument more tedious; and (4) pre- 
viously stated information. Our previous research 
deals with the first type of information (Zukerman 
et al, 1998), and in this paper we have identified 
some conditions for the omission of previously stated 
information when expressing the relative impact of 
a proposition. Another factor that affects the onfis- 
sion of information is the trade off between accuracy 
and conciseness. The omission of information affects 
the belief in the conclusion(s) presented in an argu- 
ment. Stating beliefs that differ from a system's own 
beliefs may cause the system to appear inconsistent 
or even deceitful, while presenting all the relevant 
factors may yield a verbose argument. A mecha- 
nism which addresses these issues will support he 
generation of better arguments and rebuttals. 
The evaluation of Chis. xeseareh,encompassessev- 
eral components: (1) the WWW interface, (2) the 
path-finding mechanism, and (3) the rebuttal- 
generation mechanism. A preliminary evaluation of 
5\Ve do not handle the "attack the claim that the evidence 
lcives support for the main point" strategy, as this involves 
inferring Conditional Probability Matrices for the user model, 
which is outside the scope of this research. - 
the path-finding mechanism has yielded encourag- 
ing results (Zuke~man e~ al.,: 2000).: Two.types of 
evaluation are envisaged for the rebuttal-generation 
mechanism. A whole-system evaluation, where users 
interact freely with BIAS, may be used to deter- 
mine whether users are satisfied with the system as 
a whole. In contrast, a specific evaluation of rebut- 
tals would be restricted to showing users rejoinder- 
rebuttal pairs (after showing an initial argument), 
and eliciting the users' reactions regarding the ap- 
propriateness of the rebuttals. 
7 Acknowledgments 
This work was supported in part by Australian Re- 
search Council grant A49927212. 
References 
Carberry, S. and Lambert, L. (1999). A pro- 
cess model for recognizing communicative acts 
and modeling negotiation subdialogues. Compu- 
tational Linguistics, 25(1):1-53. 
Chu-Carroll, J. and Carberry, S. (1995). Generat- 
ing information-sharing subdialogues in expert- 
user consultation. In IJCAI95 - Proceedings of 
the Fourteenth International Joint Conference on 
Artificial Intelligence, pages 1243-1250. 
Flowers, M., McGuire, R., and Birnbaum, L. (1982). 
Adversary arguments and the logic of personal 
attack. In Strategies for Natural Language Pro- 
cessing, pages 275-294. Lawrence Erlbaum Asso- 
ciates, Hillsdale, New Jersey. 
Pearl, J. (1988). Probab:ilistic Reasoning in Intelli- 
gent Systems. Morgan Kaufmann Publishers, San 
Mateo, California. 
Quilici, A. (1992). Arguing about planning al- 
ternatives. In COLING-92 - Pwceedings of the 
Fourteenth International Conference on Computa- 
tional Linguistics, pages 906-910, Nantes, France. 
Zukerman, I., Jitnah, N., McConachy, R., and 
George, S. (2000). Recognizing intentions from re- 
joinders in a Bayesian interactive argumentation 
system. To appear in PRICAI2000 - Proceedings 
of the Sixth Pacific Rim International Conference 
on Artificial InteUigence, Melbourne, Australia. 
Zukerman, I., McConachy, R., and Korb, K. B. 
(1998). Bayesian reasoning in an abductive mech- 
anism for argument generation-and analysis. In 
AAAI98 - Proceedings of the Fifteenth National 
Conference on Artificial Intelligence, pages 833- 
.838,, Madison~-;Wisconsin. . 
Zukerman, I., McConachy, R., K0rb, K. B., and 
Pickett, D. A. (1999). Exploratory interaction 
with a Bayesian argumentation system. In IJ- 
CAI99 - Proceedings of the Sixteenth Inter~m- 
tional Joint Conference on Artificial Intelligence, 
pages 1294-1299, Stockholm, Sweden. 
46 
