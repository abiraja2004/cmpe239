Proceedings of the 15th Conference on Computational Natural Language Learning: Shared Task, pages 66?70,
Portland, Oregon, 23-24 June 2011. c?2011 Association for Computational Linguistics
Combining Syntactic and Semantic Features by SVM for Unrestricted
Coreference Resolution
Huiwei Zhou1, Yao Li2, Degen Huang3, Yan Zhang4, Chunlong Wu5, Yuansheng Yang6
Dalian University of Technology
Dalian, Liaoning, China
{1zhouhuiwei,3huangdg,6yangys}@dlut.edu.cn
2tianshanyao@mail.dlut.edu.cn
4zhangyan zyzy@yeah.net
5wuchunlong@gmail.com
Abstract
The paper presents a system for the CoNLL-
2011 share task of coreference resolution. The
system composes of two components: one for
mentions detection and another one for their
coreference resolution. For mentions detec-
tion, we adopted a number of heuristic rules
from syntactic parse tree perspective. For
coreference resolution, we apply SVM by ex-
ploiting multiple syntactic and semantic fea-
tures. The experiments on the CoNLL-2011
corpus show that our rule-based mention iden-
tification system obtains a recall of 87.69%,
and the best result of the SVM-based corefer-
ence resolution system is an average F-score
50.92% of the MUC, B-CUBED and CEAFE
metrics.
1 Introduction
Coreference resolution, defined as finding the dif-
ferent mentions in a document which refer to the
same entity in reality, is an important subject in Nat-
ural Language Processing. In particular, coreference
resolution is a critical component of information ex-
traction systems (Chinchor and Nancy, 1998; Sund-
heim and Beth, 1995) and a series of coreference
resolution tasks have been introduced and evaluated
from MUC (MUC-6, 1995). Some machine learning
approaches have been applied to coreference resolu-
tion (Soon et al, 2001; Ng and Cardie, 2002; Bengt-
son and Roth, 2008; Stoyanov et al, 2009). Soon
et al(2001) use a decision tree classifier to decide
whether two mentions in a document are coreferen-
t. Bergsma and Lin (2006) exploit an effective fea-
ture of gender and number to a pronoun resolution
system and improve the performance significantly,
which is also appeared in our feature set. Howev-
er, automatic coreference resolution is a hard task
since it needs both syntactic and semantic knowl-
edge and some intra-document knowledge. To im-
prove the performance further, many deep knowl-
edge resources like shallow syntactic and seman-
tic knowledge are exploited for coreference resolu-
tion (Harabagiu et al, 2001; McCallum and Well-
ner, 2004; Denis and Baldridge, 2007; Ponzetto and
Strube, 2005; Versley, 2007; Ng, 2007). In order to
make use of more syntactic information, Kong et al
(2010) employ a tree kernel to anaphoricity determi-
nation for coreference resolution and show that ap-
plying proper tree structure in corefernce resolution
can achieve a good performance.
The CoNLL-2011 Share Task (Pradhan et
al., 2011) ?Modeling Unrestricted Coreference in
OntoNotes? proposes a task about unrestricted
coreference resolution, which aims to recognize
mentions and find coreference chains in one docu-
ment. We participate in the closed test.
In this paper, we exploit multi-features to a
coreference resolution system for the CONLL-2011
Share Task, including flat features and a tree struc-
ture feature. The task is divided into two steps in
our system. In the first step, we adopt some heuristic
rules to recognize mentions which may be in a coref-
erence chain; in the second step, we exploit a num-
ber of features to a support vector machine (SVM)
classifier to resolute unrestricted coreference. The
experiments show that our system gets a reasonable
result.
The rest of the paper is organized as follows. In
66
Section 2, we describe in detail how our system does
the work of coreference resolution, including how
we recognize mentions and how we mark the coref-
erence chains. The experimental results are dis-
cussed in Section 3. Finally in Section 4, we give
some conclusion.
2 The Coreference Resolution System
The task of coreference resolution is divided into
two steps in our system: mentions detection and
coreference resolution. In the first step, we use some
heuristic rules to extract mentions which may re-
fer to an entity. In the second step, we make up
mention-pairs with the mentions extracted in the
first step, and then classify the mention-pairs in-
to two groups with an SVM model: Coreferent or
NotCoreferent. Finally we get several coreference
chains in a document according to the result of clas-
sification. Each coreference chain stands for one en-
tity.
2.1 Rule-based Identification of Mentions
The first step for coreference resolution is to identify
mentions from a sequence of words. We have tried
the machine-learning method detecting the bound-
ary of a mention. But the recall cannot reach a high
level, which will lead to bad performance of coref-
erence resolution. So we replace it with a rule-based
method. After a comprehensive study, we find that
mentions are always relating to pronouns, named en-
tities, definite noun phrases or demonstrative noun
phrases. So we adopt the following 5 heuristic rules
to extract predicted mentions:
1. If a word is a pronoun, then it is a mention.
2. If a word is a possessive pronoun or a posses-
sive, then the smallest noun phrase containing
this word is a mention.
3. If a word string is a named entity, then it is a
mention.
4. If a word string is a named entity, then the s-
mallest noun phrase containing it is a mention.
5. If a word is a determiner (a, an, the, this, these,
that, etc.), then all the noun phrase beginning
with this word is a mention.
2.2 Coreference Resolution with
Multi-Features
The second step is to mark the coreference chain us-
ing the model trained by an SVM classifier. We ex-
tract the marked mentions from the training data and
take mention-pairs in one document as instances to
train the SVM classifier like Soon et al(2001) . The
mentions with the same coreference id form the pos-
itive instances while those between the nearest posi-
tive mention-pair form the negative instance with the
second mention of the mention-pair.
The following features are commonly used in
NLP processes, which are also used in our system:
? i-NamedEntity/j-NamedEntity: the named en-
tity the mention i/j belongs to
? i-SemanticRole/j-SemanticRole: the semantic
role the mention i/j belongs to which
? i-POSChain/j-POSChain: the POS chain of the
mention i/j
? i-Verb/j-Verb: the verb of the mention i/j
? i-VerbFramesetID/j-VerbFramesetID: the verb
frameset ID of the mention i/j, which works to-
gether with i/j-Verb
All the 5 kinds of features above belong to a sin-
gle mention. For mention-pairs, there are another 4
kinds of features as below:
? StringMatch: after cutting the articles, 1 if the
two mentions can match completely, 2 if one is
a substring of the other, 3 if they partly match,
4 else.
? IsAlias: after cutting the articles, 1 if one men-
tion is the name alias or the abbreviation of the
other one, 0 else
? Distance: it is the number of sentences between
two mentions, 0 if the two mentions are from
one sentenci-Verb/j-Verb: the verb of the men-
tion i/j
? SpeakerAgreement: 1 if both the speakers of
the two mentions are unknown, 2 if both the
two mentions come from the same speaker, 3 if
the mentions comes from different speakers.
67
All of the 14 simple and effective features above
are applied in the baseline system, which use the
same method with our system. But coreference res-
olution needs more features to make full use of the
intra-documental knowledge, so we employ the fol-
lowing 3 kinds of features to our system to catch
more information about the context.
? i-GenderNumber/j-GenderNumber (GN): 7
values: masculine, feminine, neutral, plu-
ral, ?rst-person singular, ?rst-person plural,
second-person.
? SemanticRelation (SR): the semantic relation
in WordNet between the head words of the t-
wo mentions: synonym, hyponym, no relation,
unknown.
? MinimumTree (MT): a parse tree represents the
syntactic structure of a sentence, but corefer-
ence resolution needs the overall context in a
document. So we add a super root to the forest
of all the parse trees in one document, and then
we get a super parse tree. The minimum tree
(MT) of a mention-pair in a super parse tree is
the minimum sub-tree from the common par-
ent mention to the two mentions, just like the
method uesd by Zhou(2009). And the similari-
ty of two trees is calculated using a convolution
tree kernel (Collins and Duffy, 2001), which
counts the number of common sub-trees.
We try all the features in our system, and get some
interesting results which is given in Experiments and
Results Section.
3 Experiments and Results
Our experiments are all carried out on CONLL-2011
share task data set (Pradhan et al, 2007).
The result of mention identification in the first
step is evaluated through mention recall. And the
performance of coreference resolution in the second
step is measured using the average F1-measures of
MUC, B-CUBED and CEAFE metrics (Recasens et
al., 2010). All the evaluations are implemented us-
ing the scorer downloaded from the CONLL-2011
share task website 1 .
1http://conll.bbn.com/index.php/software.html
3.1 Rule-based Identification of Mentions
The mention recall of our system in the mention i-
dentification step reaches 87.69%, which can result
in a good performance of the coreference resolution
step. We also do comparative experiments to inves-
tigate the effect of our rule-based mention identifica-
tion. The result is shown in Table 1. The CRF-based
method in Table 1 is to train a conditional random
field (CRF) model with 6 basic features, including
Word, Pos, Word ID, Syntactic parse label, Named
entity, Semantic role.
Method Recall Precision F-score
Rule-based 87.69 32.16 47.06
CRF-based 59.66 50.06 54.44
Table 1: comparative experiments of CRF-based and
rule-based methods of mention identification(%)
Table 1 only shows one kind of basic machine-
learning methods performs not so well as our rule-
based method in recall measure in mention iden-
tification, but the F1-measure of the CRF-based
method is higher than that of the rule-based method.
In our system, the mention identification step should
provide as many anaphoricities as possible to the
coreference resolution step to avoid losing corefer-
ent mentions, which means that the higher the recal-
l of mention identification is, the better the system
performs.
3.2 Coreference Resolution with
Multi-Features
In the second step of our system, SVM-LIGHT-
TK1.2 implementation is employed to coreference
resolution. We apply the polynomial kernel for
the flat features and the convolution tree kernel for
the minimum tree feature to the SVM classifier, in
which the parameter d of the polynomial kernel is
set to 3 (polynomial (a ? b + c)d) and the combin-
ing parameter r is set to 0.2 (K = tree? forest ?
kernel ? r + vector ? kernel). All the other pa-
rameters are set to the default value. All the exper-
iments are done on the broadcast conversations part
of CoNLL-2011 corpus as the calculating time of
SVM-LIGHT-TK1.2 is so long.
Experimental result using the baseline method
with the GenderNumber feature added is shown in
68
d=? MUC B3 CEAFE AVE
2 47.49 61.14 36.15 48.26
3 51.37 62.82 38.26 50.82
Table 2: parameter d in polynomial kernel in coreference
resolution using the baseline method with the GN fea-
ture(%)
Talbe 2. The result shows that the parameter d in
polynomial kernel plays an important role in our
coreference resolution system. The score when d is
3 is 2.56% higher than when d is 2, but the running
time becomes longer, too.
r=? MUC B3 CEAFE AVE
1 31.41 45.08 22.72 33.07
0.25 34.15 46.87 23.63 34.88
0 51.37 62.82 38.26 50.82
Table 3: combining parameter r (K = tree ? forest ?
kernel ? r + vector? kernel) in coreference resolution
using the baseline with the GN and MT features(%)
In Table 3, we can find that the lower the combin-
ing parameter r is, the better the system performs,
which indicates that the MT feature plays a negative
role in our system. There are 2 possible reasons for
that: the MT structure is not proper for our coref-
erence resolution system, or the simple method of
adding a super root to the parse forest of a document
is not effective.
Method MUC B3 CEAFE AVE
baseline 42.19 58.12 33.6 44.64
+GN 51.37 62.82 38.26 50.82
+GN+SR 49.61 64.18 38.13 50.64
+GN 50.97 62.53 37.96 50.49
+SEMCLASS
Table 4: effect of GN and SR features in coreference res-
olution using no MT feature (%)
Table 4 shows the effect of GenderNumber fea-
ture and SemanticRelation feature, and the last item
is the method using the SemanticClassAgreement-
Feature (SEMCLASS) used by (Soon et al, 2001)
instead of the SR feature of our system. The GN fea-
ture significantly improves the performance of our
system by 6.18% of the average score, which may
be greater if we break up the gender and number
feature into two features. As the time limits, we
haven?t separated them until the deadline of the pa-
per. The effect of the SR feature is not as good as
we think. The score is lower than the method with-
out SR feature, but is higher than the method using
SEMCLASS feature. The decreasing caused by S-
R feature may be due to that the searching depth in
WordNet is limited to one to shorten running time.
To investigate the performance of the second step,
we do an experiment for the SVM-based corefer-
ence resolution using just all the anaphoricities as
the mention collection input. The result is shown in
Table 5. As the mention collection includes no in-
correct anaphoricity, any mistake in coreference res-
olution step has double effect, which may lead to a
relatively lower result than we expect.
MUC B3 CEAFE AVE
65.55 58.77 39.96 54.76
Table 5: using just all the anaphoricities as the mention
collection input in coreference resolution step (%)
In the three additional features, only the GN fea-
ture significantly improves the performance of the
coreference resolution system, the result we finally
submitted is to use the baseline method with GN fea-
ture added. The official result is shown in Table 6.
The average score achieves 50.92%.
MUC B3 CEAFE AVE
48.96 64.07 39.74 50.92
Table 6: official result in CoNLL-2011 Share Task using
baseline method with GN feature added (%)
4 Conclusion
This paper proposes a system using multi-features
for the CONLL-2011 share task. Some syntactic and
semantic information is used in our SVM-based sys-
tem. The best result (also the official result) achieves
an average score of 50.92%. As the MT and S-
R features play negative roles in the system, future
work will focus on finding a proper tree structure
for the intra-documental coreference resolution and
combining the parse forest of a document into a tree
to make good use of the convolution tree kernel.
69
References
A. McCallum and B. Wellner. 2004. Conditional models
of identity uncertainty with application to noun coref-
erence. In Advances in Neural Information Processing
Systems (NIPS), 2004.
Chinchor, Nancy A. 1998. Overview of MUC-7/MET-2.
In Proceedings of the Seventh Message Understanding
Conference (MUC-7).
Eric Bengtson, Dan Roth. 2008. Understanding the Val-
ue of Features for Coreference Resolution Proceed-
ings of the 2008 Conferenceon Empirical Methods in
Natural Language Processing, pages294C303.
Fang Kong, Guodong Zhou, Longhua Qian, Qiaoming
Zhu. 2010. Dependency-driven Anaphoricity Deter-
mination for Coreference Resolution Proceedings of
the 23rd International Conferenceon Computational
Linguistics (Coling2010), pages599C607.
Guodong Zhou, Fang Kong. 2009. Global Learning of
Noun Phrase Anaphoricity in Coreference Resolution
via Label Propagation. In Proceedings of the 2009
Coreference on Empirical Methods in Natural Lan-
guage Processing, pages 978-986, 2009.
M. Collins, N.Duffy. 2001. Convolution Kernels for Nat-
ural Language Resolution NIPS? 2001.
Marta Recasens, Llu?s Mrquez, Emili Sapena, M. Antnia
Mart?, Mariona Taul, Vronique Hoste, Massimo Poe-
sio, Yannick Versley 2010. SemEval-2010 Task 1:
Coreference Resolutionin Multiple Languages In Pro-
ceeding SemEval 2010 Proceedings of the 5th Interna-
tional Workshop on Semantic Evaluation, 2010.
MUC-6. 1995. Coreference task definition (v2.3, 8 Sep
95) In Proceedings of the Sixth Message Understand-
ing Conference (MUC-6), pages 335-344.
P.Denis, J.Baldridge. 2007. Joint determination of
anaphoricity and coreference resolution using integer
programming. In Proceedings of HLT/NAACL, 2007.
V. Ng and C. Cardie. 2002. Improving machine learning
approaches to coreference resolution. In Proceedings
of ACL, 2002.
V. Ng. 2007. Shallow semantics for coreference resolu-
tion. In Proceedings of IJCAI, 2007.
Veselin Stoyanov, Nathan Gilbert, Claire Cardie, Ellen
Riloff. 2009. Conundrums in Noun Phrase Corefer-
ence Resolution: Making Sense of the State-of-the-Art
Proceeding ACL ?09 Proceedings of the Joint Confer-
ence of the 47th Annual Meeting of the ACL.
W.Soon,H.Ng,and D.Lim. 2001. A machine learning ap-
proach to coreference resolution of noun phrase. Com-
putational Linguistics, 27(4):521-544,2001.
S. M.Harabagiu,R.C.Bunescu,and S.J. Maiorano. 2001.
Text and knowledge mining for coreference resolution.
In Proceedings of NAACL, 2001.
S.Ponzetto, M.Strube. 2005. Semantic role labeling for
coreference resolution. In Proceedings of EACL, Italy,
April 2005.
Sameer Pradhan, Lance Ramshaw, Mitchell Marcus,
Martha Palmer, Ralph Weischedel, Nianwen Xue.
2011. CoNLL-2011 Shared Task: Modeling Unre-
stricted Coreference in OntoNotes. Proceedings of the
Fifteenth Conference on Computational Natural Lan-
guage Learning (CoNLL 2011).
Sameer S. Pradhan, Lance Ramshaw, Ralph Weischedel,
Jessica MacBride, Linnea Micciulla. 2007. Unre-
stricted Coreference: Identifying Entities and Events
in OntoNotes. In International Conference on Seman-
tic Computing, 2007.
Shane Bergsma, Dekang Lin. 2006. Bootstrapping Path-
Based Pronoun Resolution. In Proceedings of the 21st
International Conference on Computational Linguis-
tics, 2006.
Sundheim, Beth M. 1995. Overview of results of the
MUC-6 evaluation. In Proceedings of the Sixth Mes-
sage Understanding Conference (MUC-6), pages 13-
31.
Y.Versley. 2007. Antecedent selection techniques for
high-recall coreference resolution. In Proceedings of
EMNLP/CoNLL, 2007.
70
