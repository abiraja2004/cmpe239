JEP-TALN-RECITAL 2012, Atelier DEFT 2012: D?fi Fouille de Textes, pages 69?75,
Grenoble, 4 au 8 juin 2012. c?2012 ATALA & AFCP
Algorithme automatique non supervis? pour le Deft 2012
Murat Ahat 1 Coralie Petermann 1, 2 Yann Vigile Hoareau 3 Soufian Ben
Amor 1 Marc Bui 2
(1) Prism, Universit? de Versailles Saint-Quentin-en-Yvelines, 35 avenue des Etats-Unis, F-78035 Versailles.
(2) LaISC, Ecole Pratique des Hautes Etudes, 41 rue Gay-Lussac, F-75005 Paris.
(3) CHArt, 41 rue Gay-Lussac, F-75005 Paris.
murat.ahat@prism.uvsq.fr, coralie.petermann@laisc.net,
hoareau@lutin-userlab.fr, soufian.ben-amor@uvsq.fr, marc.bui@ephe.sorbonne.fr
R?SUM?
Nous d?crivons l?approche mise en oeuvre dans le cadre du D?fi de Fouille de Texte 2012 pour
la piste 1 qui consistait ? identifier, pour un article scientifique et son r?sum? donn?s, la liste
des mots cl?s qui lui correspondent parmi un ensemble de mot cl?s possibles. Cette approche
est bas?e sur le couplage entre les m?thodes d?espaces s?mantiques pour la repr?sentation des
connaissances s?mantiques d?une part, et les graphes pour la d?cision sur l?affectation d?un mot
cl? ? un article, d?autre part. La m?thode propos?e est enti?rement automatique, sans phase de
param?trage, non-supervis?e et ne n?cessite aucune ressource externe.
ABSTRACT
Automatic unsupervised algorithm for Deft 2012
We describe our approach in Deft 2012 for track 1, which consist in identifying a corresponding
list of key word, for a given scientific paper and summary, from a set of possible key words.
The approach is based on the one hand, semantic space for the representation of semantic
knowledge, and, on the other hand, graphs for the decision on the allocation of a key word to a
document. The proposed method is fully automatic, without any particular tuning, unsupervised
and requires no external resources.
MOTS-CL?S : Espace s?mantique, Graphe, Random Indexing.
KEYWORDS: Semantic Space, Graph, Random Indexing.
69
1 Introduction
Dans cette ?dition 2012 du D?fi Fouille de Texte, nous avons appliqu? notre m?thode d?j?
pr?sent?e lors du Deft 2011 (Hoareau et al, 2011b), qui consiste ? mixer deux m?thodes de
repr?sentation des connaissances : les espaces s?mantiques qui sont des espaces vectoriels ?
grandes dimensions et les mod?les de graphes. L?int?r?t du couplage des deux approches est
de b?n?ficier d?une part des propri?t?s d?apprentissage non-supervis? ainsi que des propri?t?s
s?mantiques latentes associ?s aux espaces s?mantiques et, d?autre part de la sophistication des
math?matiques sous-jacentes ? la th?orie des graphes.Pour ce faire, la premi?re contrainte ?
respecter est de produire un graphe ayant les m?mes propri?t?s que l?espace s?mantique en ce qui
concerne la repr?sentation des relations s?mantiques latentes entre les mots ou les documents
(Louwerse et al, 2006). Cette contrainte satisfaite, des applications peuvent alors ?tre r?alis?es
directement ? partir du graphe. Un exemple d?application de cette approche mixte est celui de la
visualisation des relations s?mantiques latentes entre documents au sein de grandes bases de
donn?es textuelles (Hoareau et al, 2011a).
L?an pass?, le challenge consistait ? associer un article ? son r?sum?. Dans la suite de cet article,
nous allons voir si cette ann?e, toujours sans param?trage ni apprentissage, notre m?thode
produit d?aussi bon r?sultats pour la t?che 1 qui consiste ? apparier un article et son r?sum?
? une liste de mots cl?s. Cette m?thode a ?t? instanci?e de telle sorte ? repr?senter la relation
s?mantique entre chaque mot cl? et chaque couple article/r?sum? dans un graphe construit ?
partir d?un espace s?mantique, puis ? utiliser ce graphe complet pour associer ? chaque article un
ou plusieurs mot cl?.
L?article est organis? de la fa?on suivante. Dans la premi?re section nous d?crivons le cadre
th?orique de notre algorithme en pr?sentant les espaces s?mantiques et les algorithmes de
cr?ation de tels espaces ? partir d?un quelconque contenu, ainsi que les bases de la th?orie des
graphes n?cessaires ? notre approche, afin de repr?senter les documents sous la forme d?un
graphe ayant les m?mes propri?t?s que l?espace s?mantique construit. Dans la deuxi?me section,
nous d?crivons notre algorithme. Dans le troisi?me section, nous pr?sentons bri?vement les
r?sultats de notre approche et les comparons avec les r?sultats obtenus l?an pass?. Enfin, nous
concluons l?article en pr?sentant les perspectives de recherche qui pourraient prolonger le pr?sent
travail.
2 Cadre th?orique
2.1 Les espaces s?mantiques
La th?orie des espaces s?mantiques est un ensemble de m?thodes alg?briques permettant de
repr?senter des documents de tout type selon leur contenu. Plusieurs m?thodes permettent de
mod?liser des espaces s?mantiques. Elles admettent toutes l?hypoth?se distributionnelle suivante :
les mots ayant un sens proche apparaissent dans des documents similaires. Mais toutes reposent
sur la s?mantique vectorielle : les corpus sont analys?s et mod?lis?s sous forme de vecteurs ?
grandes dimensions, rassembl?s dans une matrice de co-occurences. Cette matrice peut ?tre
construite de deux mani?res selon les algorithmes :
? matrice mots-documents, utilis?e par exemple dans LSA et RI, qui compte le nombre d?occur-
70
rences de chaque mot dans chaque document
? matrice mots-mots, utilis?e par HAL, qui regroupe les probabilit?s de co-occurences pour
chaque groupe de mots
Etant donn?e une repr?sentation vectorielle d?un corpus de documents, on peut introduire une
notion d?espace vectoriel permettant de mettre en place la notion math?matique de proximit?
entre documents. En introduisant des mesures de similarit? adapt?es, on peut quantifier la
proximit? s?mantique entre diff?rents documents. Les mesures de similarit? sont choisies en
fonction de l?application.
Une mesure tr?s utilis?e est la similarit? cosinus, qui consiste ? quantifier la similarit? entre
deux documents en calculant le cosinus de l?angle entre leurs vecteurs. Ainsi, un cosinus nul,
signe de l?orthogonalit? des deux vecteurs, indiquera que ces 2 documents n?ont aucun mot en
commun. L?avantage de cette m?thode est que la longueur des documents n?influe en rien le
r?sultat obtenu.
Une autre mesure possible est la distance de Manhattan (appel?e aussi city-block), qui elle, prend
en compte la longueur des documents compar?s.
2.2 Random Indexing
Random Indexing (Kanerva et al, 2000) est un mod?le d?espace s?mantique bas? sur des projec-
tions al?atoires.
La m?thode de construction d?un espace s?mantique avec RI est la suivante :
? Cr?er une matrice A (d ? N), contenant des vecteurs-index, o? d est le nombre de documents
ou de contextes correspondant au corpus et N , le nombre de dimensions (N > 1000) d?fini
par l?exp?rimentateur. Les vecteurs-index sont creux et alatoirement g?n?r?s. Ils consistent en
un petit nombre de (+1) et de (-1) et de centaines de 0 ;
? Cr?er une matrice B (M ? N) contenant les vecteurs-termes, o? M est le nombre de termes
diff?rents dans le corpus. Pour commencer la compilation de l?espace, les valeurs des cellules
doivent ?tre initialis?es ? 0 ;
? Parcourir chaque document du corpus. Chaque fois qu?un terme ? appara?t dans un docu-
ment d, il faut accumuler le vecteur-index correspondant au document d au vecteur-terme
correspondant au terme ?.
? la fin du processus, les vecteurs-termes qui sont apparus dans des contextes (ou documents)
similaires, auront accumul? des vecteurs-index similaires.
Cette m?thode a d?montr? des performances comparables (Kanerva et al, 2000) et parfois m?me
sup?rieures (Karlgren et Sahlgren, 2001) ? celles de LSA pour le test de synonymie du TOEFL
(Landauer et Dumais, 1997). RI a ?t? aussi appliqu? ? la cat?gorisation d?opinion (Sahlgren et
C?ster, 2004).
2.3 Th?orie des graphes
La th?orie des graphes est une th?orie informatique et math?matique. Cette th?orie est largement
utilis?e dans tous les domaines li?s ? la notion de r?seau (r?seau social, r?seau informatique,
t?l?communications, etc.) et dans bien d?autres domaines (g?n?tique, transports...).
71
Un graphe G = (V, A) est une paire compos?e de (Berge, 1970) :
1. un ensemble V = {x1, x2, ..., xn} appel? sommets (en r?f?rence aux poly?dres) ou noeuds(en r?f?rence ? la loi des noeuds).
2. une famille A= (a1, a2, ..., an) d??l?ments du produit Cart?sien V ? V = {(x , y)/x ? V, y ?V} appel?s arcs (cas d?un graphe orient?) ou ar?tes (cas d?un graphe non orient?).
En g?n?ral, on note n le nombre de noeuds (aussi not? |V (G)|) et m le nombre d?arcs (aussi not?
|A(G)|).
Un chemin P est compos? de k arcs tels que P = (a1, a2, ..., ai , ..., ak) o? pour chaque arc ai , lafin co?ncide avec le d?but de ai+1. Une chaine est l??quivalent d?un chemin dans le cadre nonorient?.
Un graphe est simple si au plus une ar?te relie deux sommets et s?il n?y a pas de boucle sur un
sommet. Dans les cas o? une ar?te relie un sommet ? lui-m?me (une boucle), ou plusieurs ar?tes
relient deux m?mes sommets, on appelle ces graphes des multigraphes.
FIGURE 1 ? Multigraphe.
Un graphe est biparti si ses sommets peuvent ?tre divis?s en deux ensembles X et Y , de sorte
que toutes les ar?tes du graphe relient un sommet dans X ? un sommet dans Y (dans l?exemple
ci-dessous, on a X = 1,3,5 et Y = 2,4).
FIGURE 2 ? Graphe biparti.
Dans notre m?thode, nous utiliserons des graphes simples bipartis, afin d?associer chaque article
? une liste de mots cl?s. Dans la section suivante, nous pr?sentons notre algorithme en d?tails.
72
3 Notre algorithme
Cette section d?crit le processus de construction (i) d?un graphe complet repr?sentant les pro-
pri?t?s s?mantiques d?un espace s?mantique, puis (ii) d?un graphe biparti ? partir d?un espace
s?mantique.
Notre m?thode d?bute par une ?tape de pr?traitements qui consiste ? supprimer les mots vides
de sens tels que les conjonction de coordination, articles ind?fini, pronoms...
Le proc?d? consiste ensuite ? g?n?rer notre espace s?mantique ? l?aide de la m?thode RI puis
? calculer la distance euclidienne pond?r?e entre chaque document et chaque mots cl?s de
l?espace s?mantique afin de construire un graphe biparti complet. L?int?r?t de cette m?thode tr?s
simple est de g?n?rer automatiquement un graphe biparti et de permettre ainsi d?y appliquer les
m?thodes issues de la th?orie des graphes (Hoareau et al, 2011a).
FIGURE 3 ? Notre algorithme.
L?algorithme d?crit ci-apr?s a pour objectif de construire un graphe biparti ? partir d?un espace
s?mantique. Il prend en entr?e un ensemble d?articles . Une matrice m "article ? mots cl?s" est
construite. Cette matrice contient dans chaque cellule mi, j , la valeur de la distance euclidiennepond?r?e entre les vecteurs de l?article i et du mots cl?s j. ? partir de cette matrice, un graphe
biparti complet g est produit. Un processus de filtre est appliqu? ? ce graphe afin de produire un
graphe biparti o? ? un article est connect? ? ces mots cl?s.
Procedure main()
Var
A as Article Set;
K as Kew word Set;
N as number of articles;
M as number of keywords;
m as Matrix Article Key word;
g as graph (article --> key word);
Begin
spaceSemantic = RandomIndexing(A)
For (i:=1 to N)
artVector = spaceSemantic(A[i]);
73
For (j:=1 to M)
keyVector = spaceSemantic(R[j]);
m[i,j] = cosine(artVector, resVector);
End For; //j
End For; //i
g = createGraph(m);
End Procedure //main()
Procedure createGraph(m);
Var
m as Matrix Article Key word;
g as graph (article --> key word);
knumList as number of keywords for articles;
Begin
g = emptyGraph();
For (i:= 1 to N)
templist = Max(m[i,:],knumbList);
g.add(i,templist);
End
Return g;
End Procedure //createGraph()
4 R?sultats et discussion
Pour le d?fi Deft 2012, nous avons soumis deux groupes de r?sultats, obtenus ? l?aide de
deux espaces s?mantiques diff?rents. Le premier est cr?? ? partir des documents de test et
d?apprentissage, alors que le second est cr?? uniquement ? partir des documents de test. La
librairie utilis?e impl?mentant random indexing est semantic vectors, et la dimension des vecteurs
a ?t? param?tr?e ? 2048 avec un cycle d?entrainement. M?me si notre algorithme nous a fourni
de bons r?sultats pour Deft 2011 en nous hissant sur la premi?re place ex aequo du podium
(Hoareau et al, 2011b), les r?sultats obtenus cette ann?e ne sont pas satisfaisants (voir le tableau
suivant).
Run Pr?cision Rappel F-score
1 0,0428 0,0428 0,0428
2 0,0242 0,0242 0,0242
TABLE 1 ? Scores pour les t?ches d?appariement du DEFT 2012
Nous avons tent? en vain d?am?liorer nos r?sultats avec des param?trages diff?rents des espaces
s?mantiques pour tester des dimensions jusqu?? 6000 et jusque 5 cycle d?entrainement. Nous
assumons alors que la m?thode de random indexing peut ?tre une des causes de cet ?chec. Nous
poursuivons donc nos recherches sur ce sujet, en testant diverses m?thodes de constructions
d?espaces s?mantiques et divers outils concernant les espaces s?mantiques.
74
5 Conclusion et perspectives
La m?thode propos?e dans le cadre de notre participation au Deft repose sur le couplage
entre les espaces s?mantiques et les graphes. Le faible nombre de documents disponibles pour
l?apprentissage constituait une contrainte forte pour notre m?thode enti?rement bas?e sur une
approche distributionnelle. En 2011, nous avions obtenu de bons r?sultats mais la t?che du Deft
2012 a montr? les limites de notre m?thode.
De prochaines exp?riences seront r?alis?es afin de comparer notre m?thode, et am?liorer son
param?trage.
R?f?rences
BERGE, C. (1970). Graphes et Hypergraphes. Dunod, Paris.
HOAREAU, Y. V., AHAT, M., MEDERNACH, D. et BUI, M. (2011a). Un outil de navigation dans un
espace s?mantique. In KHENCHAF, A. et PONCELET, P., ?diteurs : Extraction et gestion des connais-
sances (EGC?2011), volume RNTI-E-20 de Revue des Nouvelles Technologies de l?Information,
pages 275?278. Hermann-?ditions.
HOAREAU, Y. V., AHAT, M., PETERMANN, C. et BUI., M. (2011b). Couplage d?espaces s?mantiques
et de graphes pour le deft 2011 : une approche automatique non supervis?e. In D?fi Fouille de
Textes (DEFT 2011), Montpellier, France.
KANERVA, P., KRISTOFERSON, J. et HOLST, A. (2000). Random Indexing of Text Samples for
Latent Semantic Analysis. In GLEITMAN, L. et JOSH, A., ?diteurs : Proceedings of the 22nd Annual
Conference of the Cognitive Science Society, Mahwah. Lawrence Erlbaum Associates.
KARLGREN, J. et SAHLGREN, M. (2001). From Words to Understanding. In UESAKA, Y., KANERVA, P.
et ASOH, H., ?diteurs : Foundations of Real-World Intelligence. CSLI Publications, Stanford.
LANDAUER, T. et DUMAIS, S. (1997). A Solution to Plato?s Problem : The Latent Semantic
Analysis Theory of Acquisition, Induction and Representation of Knowledge. Psychological
Review, 104(2):211?240.
LOUWERSE, M., CAI, Z., HU, X., VENTURA, M. et JEUNIAUX, P. (2006). Cognitively inspired natural-
language based knowledge representations : Further explorations of latent semantic analysis.
International Journal of Artificial Intelligence Tools, 15:1021?1039.
SAHLGREN, M. et C?STER, R. (2004). Using bag-of-concepts to improve the performance of
support vector machines in text categorization. In COLING ?04 : Proceedings of the 20th interna-
tional conference on Computational Linguistics, page 487, Morristown, NJ, USA. Association for
Computational Linguistics.
75

