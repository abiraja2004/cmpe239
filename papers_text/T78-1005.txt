Taxonomic Latt ice Structures for S i tuat ion Recognition 
Wil l iam A. Woods 
Bolt Beranek and Newman Inc. 
50 Moulton Street 
Cambridge, MA 02138 
I. The Role of a Knowledge Network for an 
Intel l igent Machine 
The kinds of intel l igent computer 
assistants that we would like to be able 
to construct are very much like 
intel l igent organisms in their own right. 
Imagine for a moment an intel l igent 
organism trying to get alng in the world 
(find enough food, stay out of trouble, 
satisfy basic needs, etc.). The most 
valuable service played by an internal 
knowledge base for such an organism is to 
repeatedly answer quest ions like "what's 
going on out there?", "can it harm me?", 
"how can I avoid/p lacate it?", "Is it good 
to eat?", "Is there any special thing I 
should do about it?", etc. To support 
this kind of activity, a substantial  part 
of the knowledge base must be organized as 
a recognit ion device for c lass i fy ing and 
identi fying s ituat ions in the world. The 
major purpose of this s i tuat ion 
recognit ion is to locate internal 
procedures which are appl icable 
(appropriate, permitted, mandatory,  etc.) 
to the current situation. 
In construct ing an intel l igent 
computer assistant, the roles of knowledge 
are very similar. The basic goals of food 
gett ing and danger avoidance are replaced 
by goals of doing what the user wants and 
avoiding things that the machine has been 
instructed to avoid. However, the 
fundamental problem of analyzing a 
s i tuat ion (one establ ished either 
l inguist ica l ly  or physica l ly  or by some 
combinat ion of the two) in order to 
determine whether it is one for which 
there are procedures to be executed, or 
one which was to be avoided (or one which 
might lead to one that is to be avoided), 
etc. is basical ly the same. For example, 
one might want to instruct such a system 
to remind the user in advance of any 
upcoming scheduled meetings,  to inform him 
if he tries to assign a resource that has 
already been committed, to always print 
out messages in reverse chronological  
order (when requested),  to assume that 
"the first" refers to the first day of the 
upcoming month in a future schedul ing 
context and the first day of the current 
month in a past context, etc. 
The pr incipal  role of the knowledge 
network for such a system is essent ia l ly  
to serve as a "coat rack" upon which to 
hang various pieces of advice for the 
system to execute. Thus the notion of 
procedural  attachment becomes not just an 
ef f ic iency technique, but the main purpose 
for the existence of the network. This 
does not necessar i ly  imply, however, that 
the procedures involved consist  of 
low-level machine code. They may instead, 
and probably usual ly will, be high level 
speci f icat ions of things to be done or 
goals to be achieved. The pr incipal  
structure that organizes all of these 
procedures is a conceptual  taxonomy of 
s i tuat ions about which the machine knows 
something. 
TO support the above uses of 
knowledge, an important character ist ic  
required of an ef f ic ient  knowledge 
representat ion seems to be a mechanism of 
inheritance that will permit information 
to be stored in its most general form and 
yet stil l  be tr iggered by any more 
specif ic s i tuat ion or instance to which it 
applies. Moreover,  the nodes in the 
network (or at least a major class of 
nodes) should be interpretable as 
s i tuat ion descr ipt ions.  One of the most 
fundamental  kinds of information to be 
stored in the knowledge base will be rules 
of the form "if <situat ion descr ipt ion> is 
sat isf ied then do <action descr ipt ion>",  
or "if <situat ion descr ipt ion> then expect 
<situat ion descr ipt ion>".  Situat ion 
descr ipt ions are in general 
character izat ions of classes of s i tuat ions 
that the machine could be in. They are 
not complete descr ipt ions of world states, 
but only partial  descr ipt ions that apply 
to classes of world states. (The machine 
should never be assumed or required to 
have a complete descr ipt ion of a world 
state if it is to deal with the real 
world.) A situation in this part ial  sense 
is def ined by the results of certain 
measurements,  computat ions,  or recognit ion 
procedures  applied to the system's input. 
Examples  of s i tuat ions might be "You have 
a goal to achieve which is an example of 
s i tuat ion Y", "You are perceiv ing an 
object of class Z", "The user has asked 
you to perform a task of type W", etc. 
33 
More specif ic s i tuat ions might be: 
"trying to schedule a meet ing for three 
people, two of which have busy schedules",  
"about to print a message from a user to 
himself",  "about to refer to a date in a 
recent previous year in a context where 
prec is ion but conciseness is required". 
The major references to this 
conceptual  taxonomy by the intel l igent 
machine wil l  be attempts to identify and 
act ivate those s i tuat ion descr ipt ions that 
apply to its current s i tuat ion or some 
hypothes ized s i tuat ion in order to 
consider any advice that may be stored 
there. Note that "consider ing advice of 
type X" is itself an example of a 
s ituat ion, so that this process can easi ly 
become recursive and potent ia l ly  
unmanageable without appropr iate care. 
Conceptual ly,  one might  think of the 
process of act ivat ing all of the 
descr ipt ions that are sat isf ied by the 
current  s i tuat ion as one of taking a 
descr ipt ion of the current s i tuat ion and 
matching it against descr ipt ions stored in 
the system. However, there are in general  
many d i f ferent  ways in which the current 
s i tuat ion might be described, and it is 
not clear how one should construct  such a 
descr ipt ion.  
Moreover,  until  it is so recognized, 
a s i tuat ion consists of a co l lect ion of 
unrelated events and condit ions.  The 
process of recogniz ing the elements 
current ly  being perceived as an instance 
of a s i tuat ion about which some 
information is known consists of 
d iscover ing that those elements can be 
interpreted as f i l l ing roles in a 
s i tuat ion descr ipt ion known to the system. 
In fact, the process of creat ing a 
descr ipt ion of the current s i tuat ion is 
very much like the process of pars ing a 
sentence, and inherent ly uses the 
knowledge structure of the system like a 
parser uses a grammar in order to 
construct  the appropr iate descr ipt ion.  
Consequent ly,  by the time a descr ipt ion of 
the s i tuat ion has been constructed,  it has 
already been ef fect ive ly  matched against 
the descr ipt ions in the knowledge base. 
2. Parsing Situations 
As suggested above, the process of 
recogniz ing that a current s i tuat ion is an 
instance of an internal s i tuat ion 
descr ipt ion is similar to the process of 
parsing a sentence, a lthough cons iderably  
more di f f icu l t  due to a more open ended 
set of possib le re lat ionships among the 
"const i tuents" of a situation. That is, 
whereas the pr incipal  re lat ionship between 
const i tuents in sentences is merely  
adjacency in the input string, the 
re lat ionships among const i tuents of a 
s i tuat ion may be arbi t rary (e.g. events 
preceding one another in time, people, 
places, or physical  objects in var ious 
spatial re lat ionships with each other, 
objects in physical  or legal possess ion of 
people, people in re lat ionships of 
author i ty  to other people, etc.) However, 
the basic character is t ic  of parsers,  that 
the objects recognized are character ized 
as structured objects assembled out of 
recognizable parts according to known 
rules of assembly, is shared by this task 
of s i tuat ion recognit ion.  
Note that it is not suf f ic ient  merely  
to character ize a s i tuat ion as a member of 
one of a f inite number of known classes. 
That is, where it is not suf f ic ient  for a 
parser to simply say that its input is an 
example of a declarat ive sentence (one 
wants to be able to ask what the subject 
is, what the verb is, whether the sentence 
has past, present or future tense, etc.), 
in a similar way it is insuff ic ient  to 
merely  say that an input s i tuat ion is an 
example of someone doing something. One 
must generate a detai led descr ipt ion of 
who is doing what to whom, etc. 
It is also not suf f ic ient  to 
character ize  a s i tuat ion as a single 
instance of an exist ing concept with 
values f i l led in for empty slots. In 
general ,  a s i tuat ion descr ipt ion must be a 
composite structured object, var ious 
subparts of which wil l  be instances of 
other concepts assembled together in ways 
that are formal ly permitted,  in much the 
same way that the descr ipt ion of a 
sentence is put together from instances of 
noun phrases, clauses, and prepos i t ional  
phrases. The specif ic  instance bui lt  up 
must  keep track of which const i tuents  of 
the specif ic  s i tuat ion fill which roles of 
the concepts being recognized. Moreover,  
it cannot do so by simply f i l l ing in the 
slots of those general  concepts,  since a 
general  concept may have mult ip le  
instant iat ions in many situat ions.  
Rather, new structures represent ing 
instances of those concepts must be 
constructed and pair ings of const i tuent  
roles from the concept and role f i l lers 
from the current s i tuat ion must  be 
associated with each new instance. 
3. ~he Process of Situation Recognition 
The process of s i tuat ion recognit ion 
consists of detect ing that a set of 
part ic ipants  of certain kinds stand in 
some specif ied re lat ionship to each other. 
In general,  when some set of part ic ipants  
is present at the sensory interface of the 
system (immediate input plus past memory),  
the task of determining whether there is 
some s i tuat ion descr ipt ion in memory that 
wil l  account for the re lat ionships  of 
those inputs is not trivial. If the total 
number of s i tuat ion descr ipt ions in the 
system is suf f ic ient ly  small, all of them 
can be indiv idual ly  tested against the 
input to see if any are satisf ied. If the 
34 
number of such descr ipt ions is 
suf f ic ient ly  large, however, this is not 
feasible. 
Al ternat ively,  if there is some 
part icular part ic ipant  that by virtue of 
its type strongly suggests what s i tuat ion 
descr ipt ions it might part ic ipate in, then 
an index from this part ic ipant  might 
select a more manageable set of s i tuat ion 
descr ipt ions to test. Even in this case, 
however, the number of s i tuat ions in which 
the const i tuent could part ic ipate may 
still be too large to test eff ic ient ly.  
In the most di f f icult  s ituation, no single 
part ic ipant in the input is suf f ic ient ly  
suggest ive by itself to constra in the set 
of possible patterns to a reasonable 
number. However, it may stil l  be that the 
coincidence of several const i tuents and 
re lat ionships may suff ice, providing that 
the coincidence can be detected. It is 
this problem of coincidence detect ion that 
I bel ieve to be crucial to solving the 
general  s i tuat ion recognit ion problem. 
As an example, consider the fol lowing 
fragment of a protocol  of a commander 
giving commands to an intel l igent d isplay 
system: 
Cdr : Show me a display of the 
eastern Mediterranean.  
\[computer produces display\] 
Cdr: Focus in more on Israel and 
Jordan. 
\[computer does so\] 
Cdr: Not that much; I want to be 
able to see Port Said and the 
Island of Cyprus. 
In the first clause of the third command 
of this discourse, (i.e. "not that much"),  
there is no single word that is strongly 
suggest ive of the interpretat ion of the 
sentence. Moreover, there is nothing 
expl ic i t  to suggest the re lat ionship of 
this clause to the one that fol lows the 
semicolon. The latter, if interpreted in 
isolation, would merely be a request for a 
display, or perhaps a succession of two 
displays, while in the context given, it 
is a request to modify a previous display. 
There are two methods that I bel ieve 
may be suff ic ient,  either indiv idual ly  or 
in combination, to model coincidence 
detection. One is the use of factored 
know!ed@e structures that merge common 
parts of a l ternat ive hypotheses.  The 
other involves the use of a markable 
c lass i f icat ion structure in which the 
ind iv idua l "  recognit{on pred icates  
tr iggered by the ongoing discourse will 
leave traces of their having fired, so 
that coincidences of such traces can be 
ef f ic ient ly  detected. I have been 
invest igat ing a structure which I call a 
"taxonomic latt ice", that combines some 
features of both methods.  
3;1 Factored Knowledge Structures 
Given a knowledge-based system with 
large numbers of s i tuat ion-act ion rules, 
where it is infeasible to find the rules 
that match a given s i tuat ion by 
systemat ica l ly  consider ing each rule, one 
needs to have some way of reducing the 
computat ional  load. As ment ioned before, 
one approach is to index the rules 
according to some sal ient feature that 
wil l  be easi ly  detectable in the input 
s ituat ion and can then be used to find a 
much more l imited set of rules to apply. 
This has been done in many systems, 
including the LUNAR system for natural 
language quest ion answering \[Woods, 1973, 
1977\]. In that system, rules for 
interpret ing the meanings of sentences 
were indexed according to the verb of the 
sentence and rules for interpret ing noun 
phrases were indexed by the head noun. 
Although this approach reduces the number 
of rules that need to be considered, it 
has several l imitat ions still. The f irst 
is that there may be some values of the 
index key for which there are stil l  a 
large number of rules to consider.  In the 
case of the LUNAR system, for example, the 
verb "be" had a large number of rules to 
account for d i f ferent senses of the word. 
Another is that there can be certain 
construct ions for which there is no single 
easi ly  detected feature that is strongly 
constraining as to possible meaning. In 
this case, there is no useful index key 
that can be used to select a suf f ic ient ly  
constrained set of rules to try. 
Another l imitat ion of this indexing 
approach as the range of language becomes 
more fluent is that in certain el l ipt ical  
sentences, the constra in ing key may be 
el l ipsed, and although one can have the 
rules indexed by other keys as well, the 
remaining ones may not suf f ic ient ly  
constrain the set of rules that need to be 
considered. Finally, even when the set of 
rules has been constrained to a re lat ive ly  
small set, there is f requent ly  a good deal 
of sharing of common tests among di f ferent  
rules, and consider ing each rule 
independent ly  results in repeating these 
tests separately for each rule. 
One approach to solving all of the 
above problems is to use what I have been 
cal l ing a "factored knowledge structure" 
for the recognit ion process. In such a 
structure, the common parts of d i f ferent 
rules are merged so that the process of 
test ing them is done only once. With such 
structures, one can ef fect ively test all 
of the rules in a very large set, and do 
so eff ic ient ly,  but never consider any 
single rule individual ly.  At each point 
in a factored knowledge structure, a test 
is made and some information gained about 
the input. The result of this test 
determines the next test to be made. As 
each test is made and addit ional  
information accumulated, the set of 
35 
possible rules that could be sat isf ied by 
the input, given the values of the tests 
so far made, is gradual ly  narrowed until 
eventual ly  only rules that actual ly match 
the input remain. Until the end of this 
decis ion structure is reached, however, 
none of these rules is actual ly  considered 
expl ic it ly.  This pr inciple of factoring 
together common parts of d i f ferent  
patterns to faci l i tate shared processing 
is the basic technique that makes ATN 
grammars \[Woods, 1970\] more ef f ic ient  in 
some sense than ordinary phrase structure 
grammars. It has also been used by the 
lexical retr ieval component of the BBN 
speech understanding system \[Woods et al, 
1976; Wolf and Woods, 1977\] and accounts 
for the ef f ic iency of the finite state 
grammar approach of the CMU Harpy system 
\[Lowerre, 1976\]. A recent innovative use 
of this pr inc ip le appears in Rieger's 
"tr igger trees" for organiz ing spontaneous 
computat ions \[Rieger, 1977\]. 
Whether factored together or not, the 
task of accessing rules is not a simple 
one. One problem is that rules don't  
match the input letter- for - letter :  rather, 
they have var iables in them with var ious 
restr ict ions on what they can match. For 
example a rule might  say that whenever an 
access is made to a c lass i f ied file, then 
a record of the person making the request 
should be made. The descr ipt ion,  "an 
access to a c lass i f ied file" needs to be 
matched against the user's request (or 
some subpart of it) and in that match, the 
descr ipt ion  "a c lass i f ied file" will be 
matched against some specif ic file name. 
In this kind of s i tuat ion, there is no 
natural  ordering of the rules, analogous 
to the alphabet ical  ordering of words, 
that will help in f inding the rules that 
are sat isf ied by the given situation. Nor 
is a structure as simple as the d ict ionary 
tree above adequate for this case. 
Another problem is that a given 
s i tuat ion may be matched by several rules 
s imultaneously  with di f fer ing degrees of 
general i ty.  For example, there may be a 
rule that says "whenever access is made to 
a top secret file (more specif ic than 
classi f ied),  then check the need-to-know 
status of the user for that information 
and block access if not satisf ied". In 
the case of a request to a top secret 
file, both of the above rules must be 
found, while in the case of an ordinary 
c lass i f ied file, only the first should. 
The actual input, however,  will not 
expl ic i t ly  ment ion either "top-secret" or 
"c lassi f ied",  but will mere ly  be some file 
name that has many attr ibutes and 
propert ies,  among which the attr ibute 
"classif ied" is not part icu lar ly  salient. 
3.2 Markable C lass i f i cat ion Structures 
Another technique that holds promise 
for s i tuat ion recognit ion is the use of a 
markable c lass i f icat ion structure in which 
coinc idences of re lat ive ly  non-sal ient  
events can be detected. The keystone of 
this approach is a technique that Qui l l ian 
proposed for model ing certain aspects of 
human associat ive memory \[Quil l ian, 1966, 
1968\]. Qui l l ian's  technique of "semantic 
intersect ion" consisted of propagat ing 
traces of "act ivation" through a semantic 
network structure so that connect ion paths 
relat ing arbitrary concepts could be 
detected. For example, his system was 
able to connect concepts such as "plant" 
and "nourishment" by d iscover ing the 
"chain" equivalent  to "plants draw 
nour ishment  from the soil". If the 
appropr iate information were in the 
network, this technique would also find 
chains of indirect connect ions such as 
"Plants can be food for people" and 
"People draw nour ishment from food." The 
method was capable of f inding paths of 
arbitrary length. 
The problem of f inding connect ions 
between concepts in a knowledge network is 
l ike the problem of f inding a path through 
a maze from a source node to some goal 
node. At the lowest level, it requires a 
trial and error search in a space that can 
be large and potent ia l ly  combinator ic .  
That is, if one element of the input could 
be connected to k d i f ferent  concepts,  each 
of which would in turn be connected to k 
others, and so on, until  f inal ly  a concept 
that connected to the goal was discovered,  
then the space in which one would have to 
search to find a path of length n would 
contain k n paths. However,  if one started 
from both ends (assuming a branching 
factor of k also in the reverse 
direct ion),  one could find all the paths 
of l~Dgth n/2 from either end in only 
2.kn/z . 
If one then had an ef f ic ient  way to 
determine whether any of the paths from 
the source node connected with any of the 
paths from the goal node, such a search 
from both ends would have a cons iderable 
savings. This can be done quite 
e f f ic ient ly  if the a lgor i thm is capable of 
putt ing marks in the structure of the maze 
itself (or some structure isomorphic to 
it), so that it can tell when reaching a 
given node whether a path from the source 
or the goal has already reached that node. 
However, without such abi l i ty to mark the 
nodes of the maze, the process of testing 
whether a given path from the source can 
hook up with a path from the goal would 
involve a search through all the paths 
from the goal individual ly,  and a search 
down each such path to see if the node at 
the end of the source path occurred 
anywhere on that path. If this were 
necessary,  then all of the advantage of 
searching from both ends would be lost. 
36 
The use of the graph structure itself to 
hold marks is thus cr it ical  to gaining 
advantage from this algorithm. 
Essential ly,  the nodes of the graph serve 
as rendezvous points where paths that are 
compatible can meet each other. The 
coincidence of a path from the source 
meeting a path from the goal at some node 
guarantees the d iscovery of a complete 
path without any path requir ing more than 
a simple test at the corresponding node in 
the graph as each link is added to the 
path. 
What is needed for s ituat ion 
recognit ion in a genera l izat ion of 
Qui l l ian's  semantic intersect ion technique 
in which the source and goal nodes are 
replaced by a potent ia l ly  large number of 
concept nodes, some of which are 
st imulated by immediate input, and some of 
which are remembering recent act ivat ion in 
the past. Moreover, what is s igni f icant 
is not just simple paths between two 
nodes, but the conf luence of marks from 
mult ip le  sources in predetermined 
patterns. Moreover, unlike Qui l l ian, who 
considered all connect ions ident ical ly in 
searching for paths, we will consider 
marker passing strategies in which marks 
can be passed select ively along certain 
links. Recently, Fahlman \[1977\] has 
presented some interest ing formal machine 
speci f icat ions of Qui l l ian-type spreading 
act ivat ion processes which have this 
character ist ic .  
4. The Structure of Concepts 
In bui lding up internal descr ipt ions 
of situations, one needs to make use of 
concepts of objects, substances, times, 
places, events, condit ions,  predicates,  
functions, individuals, etc. Each such 
internal concept wil l  itself have a 
structure and can be represented as a 
conf igurat ion of attr ibutes or parts, 
sat isfying certain restr ict ions and 
standing in specif ied re lat ionships to 
each other. Brachman \[1978\] has developed 
a set of ep is temolog ica l ly  expl ic i t  
conventions for represent ing such concepts 
in a "Structured Inheritance Network", in 
which interre lat ionships of various parts 
of concepts to each other and to more 
general and more specif ic concepts are 
expl ic i t ly  represented. The essential  
character ist ic  of these networks is their 
abi l i ty to represent descr ipt ions of 
structured objects of var ious degrees of 
genera l i ty  with expl ic i t  representat ion of 
the inheritance re lat ionships between 
corresponding const i tuents of those 
structures. A concept node in Brachman's 
formulat ion consists of a set of dattrs (a 
genera l izat ion of the notions of 
attr ibute, part, const ituent,  feature, 
etc.) and a set of structural  
re lat ionships among them. Some of these 
dattrs are represented direct ly  at a given 
node, and others are inherited indirect ly 
from other nodes in the network to which 
they are related. 
Let us assume that each concept that 
the system understands is represented as a 
node in one of these structured 
inheritance networks. The network, as a 
whole, then serves as a conceptual  
taxonomy of all possible "entit ies" that 
the system can perceive or understand. 
Each node in this taxonomy can be thought 
of as a micro schema for the recognit ion 
of instances of that concept. Each has a 
set of dattrs with individual restr ict ions 
and a set of structural  condit ions that 
relate the dattrs to one another. These 
restr ict ions and structural  condit ions may 
themselves be defined in terms of other 
concepts defined by other micro schemata, 
and so on until a level of pr imit ive ly  
defined, direct ly perceivable concepts is 
reached. 
Each concept in the taxonomy can be 
thought of as having a level of 
abstractness def ined as the maximum depth 
of nesting of its const i tuent  structure. 
Instances of pr imit ive ly  def ined concepts 
have level 0, conste l lat ions of those 
concepts have level i, a concept having 
level 1 and lower concepts as dattrs has 
level 2,, and so on. If a taxonomy 
contained only level 0 and level 1 
concepts, then the s i tuat ion recognit ion 
problem would be great ly simpli f ied, since 
one never needs to recognize port ions of 
the input as ent it ies that part ic ipate as 
const i tuents of larger entit ies. The 
general problem, however, requires us to 
do exact ly that. More seriously, the 
general case requires us to recognize a 
concept some of whose dattrs may have 
restr ict ions def ined in terms of the 
concept itself. This is true, for 
example, for the concept of noun phrase in 
a taxonomy of syntact ic construct ions.  
Such recursively def ined concepts have no 
maximum level of abstractness,  although 
any given instance will only involve a 
f inite number of levels of recursion. 
This potential  for recursive def in i t ion 
must be kept in mind when formulat ing 
algor ithms for s i tuat ion recognit ion. 
5. The Need for Inher i tance Structures 
AS a result of having di f ferent  
levels of abstract ion in one's taxonomy, 
an input s ituat ion will often sat isfy 
several situation, descr ipt ions 
s imultaneously,  no one of which will 
account for all of the input nor supplant 
the relevance of the others. For example, 
adding a ship to a d isplay is 
s imultaneously an example of changing a 
d isplay and of d isplaying a ship. Advice 
for both act ivit ies must be considered. 
Moreover,  a single descr ipt ion may have 
several d i f ferent instant iat ions in the 
current situation, with s i tuat ion 
descr ipt ions becoming arbi t rar i ly  complex 
37 
by the addit ion of var ious qual i f iers,  by 
the conjunct ion and d is junct ion of 
descr ipt ions,  etc. For example, one might 
want to store advice associated with the 
s i tuat ion \[wanting to d isplay a large ship 
at a locat ion on the screen that is within 
one unit distance from either the top, 
bottom, or side of the screen when the 
scale of the d isp lay is greater than 
1:1000\]. Finally, s i tuat ion descr ipt ions 
may subsume other descr ipt ions at lower 
levels of detail ,  and advice from both may 
be relevant and may either supplement or 
contradict  each other. For example, 
d isp laying an aircraft  carrier is a 
special case of d isplaying a ship, and 
there may be specif ic  advice associated 
with d isplaying carr iers as well as more 
general  advice for d isplaying any ship. 
Thus, convent ions wil l  be required to 
determine which advice takes precedence 
over the other if conf l icts arise. 
The organizat ion of large numbers of 
such s i tuat ion descr ipt ions of varying 
degrees of genera l i ty  so that all 
descr ipt ions more general  or more specif ic  
than a given one can ef f ic ient ly  be found 
is one thing we require of an intel l igent 
computer assistant.  In order to bui ld and 
mainta in  such a structure, it is important 
to store each rule at the appropr iate 
level of general i ty,  relying on a 
mechanism whereby more specif ic s i tuat ions 
automat ica l ly  inherit  information from 
more general  ones. That is, when one 
wants to create a s i tuat ion descr ipt ion 
that is more specif ic than a given one in 
some dimension, one does not want to have 
to copy all of the attr ibutes of the 
general  situation, but only those that are 
changed. Aside from conserving memory 
storage, avoiding such copying also 
fac i l i tates updating and mainta in ing the 
consistency of the data base by avoiding 
the creat ion of dupl icate copies of 
information that then may need to be 
independent ly  modif ied and could 
acc identa l ly  be modif ied inconsistent ly.  
For example, one may want to store 
advice about d isplaying geographical  
features, about d isp laying such features 
that cover an area, about d isplaying 
bodies of water, about d isplaying lakes, 
etc. Thus, information about f inding the 
area covered by a feature would be stored 
at the level of deal ing with such 
area-cover ing features, information about 
displaying water in a certain color would 
be stored at the level of d isp laying 
bodies of  water, and information about 
having inlets and outlets would be stored 
at the level of lakes. In any specif ic 
s i tuat ion that the system finds itself, 
many such concepts at d i f ferent  levels of 
genera l i ty  wil l  be satisf ied, and the 
advice associated with all of them becomes 
appl icable.  That is, any more specif ic 
concept, including that of the current 
s ituation, inherits a great deal of 
information that is expl ic i t ly  stored at 
higher levels in the taxonomy. 
In the case of the s i tuat ion 
descr ipt ions that we are deal ing with, 
even the speci f icat ion of what dattrs a 
g iven concept possesses is stored at the 
most general  level and inherited by more 
specif ic concepts. Thus, for example, the 
descr ipt ions of attr ibute dattrs for color 
and weight are stored for a general  
concept of physical  object. These dattrs 
are then inherited by any more specif ic  
concepts of physical  objects, such as 
planes, ships, desks, and penci ls.  
6. ~e  Taxonomic  Latt ice 
I bel ieve that a general  solut ion to 
the s i tuat ion recognit ion problem can be 
obtained by the use of a c lass i f i cat ion  
structure in which traces of individual 
e lements of complex concepts can intersect 
to faci l i tate the d iscovery  of 
co inc idences and connect ions that may not 
be strongly inferable from constra in ing 
expectat ions.  The structure that I 
propose to use is a vers ion of Brachman's  
structured inheritance networks, in which 
descr ipt ions of all potent ia l ly  relevant 
s i tuat ions are stored with expl ic i t  
indicat ions of general  subsumption of one 
s i tuat ion by another, and expl ic i t  
indicat ions of the inheritance of dattrs 
and of advice by one concept from another. 
This structure, which I have cal led a 
taxonomic latt ice, is character ized by a 
mult~t6de of s i tuat ion descr ipt ions at 
d i f ferent  levels of general i ty.  
We say that a s i tuat ion descr ipt ion 
Sl subsumes a descr ipt ion $2 if any 
s i tuat ion sat isfying $2 wil l  also satisfy 
SI. In this case, S1 is a more general  
descr ipt ion than $2, and is placed higher 
in the taxonomy. For example, \[displaying 
a port ion of country\] is a more specif ic 
s i tuat ion than \[displaying a geographical  
area\], which is in turn more speci f ic  than 
\[displaying a d isp layable entity\].  All of 
these are subsumed by a general  concept 
\[purposive activity\] ,  which in turn is 
more specif ic  than \[activity\]. Moreover,  
a given descr ipt ion can subsume many 
incomparable descr ipt ions and can itself 
be subsumed by many incomparable 
descr ipt ions.  For example, an instance of 
\[displaying a geographical  area\] is also 
an instance of \[accessing a geographical  
area\], \[displaying information\] ,  and 
\[using the display\[,  and may poss ib ly  also 
be an instance of \[responding to a user 
command\].  
The space of possib le s i tuat ion 
descr ipt ions forms a latt ice under the 
relat ion of subsumption. At the top of 
the latt ice is a single, most general  
s i tuat ion we will call T, which is always 
sat isf ied and can be thought of as the 
d is junct ion of all poss ib le  s ituat ions.  
Anything that is universal ly  true can be 
stored here. Conversely,  at the bottom of 
the latt ice is a s i tuat ion that is never 
38 
satisf ied, which we call NIL. It can be 
thought of as the conjunct ion of all 
possible (including inconsistent) 
situations. Assert ions of negative 
existence can be stored here. 
At the "middle" level of the latt ice 
are a set of pr imit ive percept ib le 
predicates -- descr ipt ions whose truth in 
the world are d i rect ly  measurable by the 
"sense organs" of the system. All c lasses 
above this level are constructed by some 
form of genera l izat ion operation, and all 
c lasses below are formed by some form of 
special izat ion. At some point 
suf f ic ient ly  low in the lattice, one can 
begin to form inconsistent descr ipt ions by 
the conjunct ion of incompatible concepts, 
the imposit ion of impossible restr ict ions,  
etc. There is nothing to prevent such 
concepts from being formed; indeed, it is 
necessary in order for the organism to 
contemplate, store, and remember their 
inconsistency. 
There are a number of specif ic 
relat ionships that can cause one s i tuat ion 
descr ipt ion to subsume another.  A given 
situat ion descr ipt ion can be made more 
general  by relaxing a condit ion on a 
dattr, by el iminat ing the requirement for 
a dattr, by relaxing the constraints of 
its structural descr ipt ion,  or by 
expl ic i t ly  dis jo ining it (or'ing it) with 
another descript ion. A given descr ipt ion 
can be made more specif ic by t ightening 
the condit ions on a dattr, by adding a 
dattr, by t ightening the constraints of 
its structural descr ipt ion,  or by 
expl ic i t ly  conjoining (and'ing) it with 
another descript ion. These operat ions 
applied to any finite set of s i tuat ion 
descr ipt ions induce a latt ice structure of 
possible s i tuat ion descr ipt ions that can 
be formed by combinat ions of the elements 
of the initial set. We refer to this 
structure as the virtual latt ice induced 
by a given set of s i tuat ion descr ipt ions.  
Note that only a f inite port ion of this 
latt ice need be stored with expl ic i t  
connect ions from more specif ic to more 
general concepts. By processing this 
expl ic i t  lattice, one can test any given 
descr ipt ion for membership in the virtual 
latt ice and assimi late any new situat ion 
descr ipt ion into the expl ic i t  latt ice in 
the appropriate place corresponding to its 
posit ion in the virtual lattice. 
In operation, any s i tuat ion 
descr ipt ion about which information is 
expl ic i t ly  stored will be entered into the 
expl ic i t  lattice. Any s i tuat ion that the 
machine can understand is in some sense 
already in the virtual latt ice and needs 
only be "looked up" in it. One task we 
have set for ourselves to develop 
ef f ic ient  a lgor i thms to tell whether a 
given situation can be understood in terms 
of the concepts of the latt ice and if so, 
to construct its corresponding descr ipt ion 
and expl ic i t ly  record its relat ions to 
other concepts in the expl ic i t  lattice. 
7. An Example 
As an example of the s i tuat ion 
recognit ion process using marker 
propagat ion in a taxonomic lattice, let us 
consider a simple case of interpret ing the 
intent of a simple English sentence. The 
example chosen is not complex enough to 
require all of the machinery  discussed, 
but is presented here to i l lustrate the 
mechanism. The major features of the 
s i tuat ion recognit ion mechanism only 
become crit ical in interpret ing commands 
that require several sentences to bui ld 
up, or which depend on the current context 
in complex ways, but such s ituat ions are 
d i f f icu l t  to i l lustrate. 
For our example, suppose that the 
system contained a concept for requests to 
display a geographical  region, and the 
user's input request were "Show me the 
eastern end of the Mediterranean."  The 
concept \[request\] contains dattrs for the 
requestor, the requestee, a descr ipt ion of 
the state that the requestor desires, a 
form of request (demand, order, pol i te 
request, expression of preference, etc.), 
and perhaps others. Requests can take 
many forms. Assume that we have stored in 
the system a rule that s@ys "Any sentence 
of the form: 'show me NP' is a request to 
display that NP." This rule could be 
stored in the latt ice as a piece of advice 
associated with the concept "A sentence of 
the form: 'show me NP'," in such a way 
that when a sentence of the indicated form 
was found, an instance of a d isp lay 
request would be created. At that point, 
this result ing display request would be 
placed in the latt ice in such a way that 
all more general concepts of which it is 
an instance would be activated, and in 
part icular ,  the concept of a request to 
display a geographical  region would be 
activated. 
The pars ing of the original sentence 
can either be done by an ATN grammar, or 
by a version of the taxonomic latt ice 
itself (one that character izes a taxonomy 
of sentence types). Let us assume here 
that it is done by an ATN grammar that is 
c losely coupled to a taxonomic lattice, 
with the ATN represent ing the syntact ic 
information about sentence form and the 
taxonomic latt ice represent ing general  
semantic information. As the ATN grammar 
picks up const i tuents of the sentence, it 
reaches states where it makes hypotheses 
about the syntact ic roles that those 
const i tuents play in the sentence (e.g. 
"this is the subject", "this is the verb", 
etc.). Such hypotheses are then entered 
into the lattice, where they begin to 
act ivate the recognit ion condit ions of 
concepts in the network. For example, in 
the taxonomic latt ice there is a concept 
of an imperative sentence whose subject is 
the system, whose verb is "show", whose 
indirect object is the user and whose 
direct object is a d isplayable object. 
39 
As the parsing proceeds, the ATN will 
make assert ions about the sentence it is 
bui ld ing up, and it wil l  not only be 
bui ld ing up syntactic representat ions of 
const i tuents of the sentence, but will 
also be bui ld ing up representat ions of 
possib le meanings of those const i tuents.  
In part icular,  it wil l be bui ld ing up a 
l ist of those concepts in the latt ice of 
which the current const i tuent  may be a 
restr ict ion or instance and a l ist of the 
dattr -value pair ings that have been found 
so far. If a parse path succeeds (i.e. 
reaches a POP arc), then a node in the 
taxonomic latt ice corresponding to that 
hypothesis  will be found or constructed.  
This node will have l inks to more general  
and more specif ic  concepts, and will have 
its const i tuents l inked to appropr iate 
dattrs of those concepts. At the point 
when this concept node is 
found/constructed,  a process of act ivat ion 
spreading wil l  be launched in the latt ice 
to find any advice that may be inherited 
by that concept. This process will also 
leave "footprints" in the latt ice that 
wil l  faci l i tate the detect ion of concepts 
of which the current one may itself be a 
dattr (or part of a structural  condit ion).  
In the example above, when the parser 
has parsed the init ial port ion of the 
sentence "show me", it has bui l t  up in its 
internal registers the information 
corresponding to the hypothes is  that the 
sentence is an imperative, with subject 
"you" and indirect object "me". Moreover,  
it knows that (in input sentences) "you" 
refers to the system itself, whi le "me" 
refers to the speaker. It also knows that 
the main verb is the verb "show". Let us 
suppose that at this point, the parser 
decides to act ivate the corresponding 
taxonomic latt ice nodes for the concepts 
\[the system\], \[the user\], and \[the verb 
show\] (possibly with pointers to the 
syntact ic hypothesis  being constructed 
and/or the labels SUBJECT, OBJECT, VERB, 
respect ively) .  Ignoring for now whatever 
information or advice may be found 
associated with these concepts or their 
genera l izat ions,  the footpr ints that they 
leave in the network will intersect at a 
node \[display request\] which has dattrs 
for requestor, requestee, form of request, 
and requested thing. They also intersect 
at other concepts such as \[ imperative 
sentence\],  \[active sentence\],  \[action\], 
and a more specif ic kind of d isplay 
request \[region display request\],  whose 
requested thing is a geographical  region. 
This latter concept was created and 
inserted into the latt ice precisely to 
hold advice about how to d isp lay 
geographical  regions, and to serve as a 
monitor for the occurrence of such 
situations. Fig. 1 is a fragment of a 
taxonomic latt ice showing the concepts of 
interest. (For detai ls  of the notation, 
see Brachman \[1978\], Woods and Brachman 
\[1978\].) 
When the final noun phrase has been 
parsed and given an interpretat ion,  the 
footpr ints that its act ivat ion leaves in 
the network will awaken the \[region 
display request\] node, which will then be 
ful ly satisf ied, and the parser will 
create a corresponding instance node, with 
appropr iate bindings for its dattrs. In 
process ing the noun phrase, the parser 
wil l  discover the adject ive "eastern" and 
the noun "Mediterranean" and wil l  act ivate 
the corresponding nodes in the taxonomic 
latt ice. The concept \[east\] is an 
instance of \[direction\],  which, among 
other things, is the restr ict ion for a 
dattr of a concept \ [d irect ional ly  
determined subregion\] that def ines the 
meaning of such concepts as "north eastern 
Idaho". Another dattr of this same 
concept has the restr ict ion \[geographical  
region\],  which is on the superc chain from 
Mediterranean.  Hence, footpr ints from 
"eastern" and "Mediterranean" wil l  
intersect at the concept \ [d irect ional ly  
determined subregion\],  causing an instance 
of that concept to be constructed as a 
possib le meaning of the noun phrase. The 
\ [direct ional ly determined subregion\] 
concept itself has a superc connect ion to 
\[geographical  region\], which happens to be 
the restr ict ion for the "requested thing" 
dattr of the concept \[region d isp lay 
request\] which has a l ready received marks 
for its other dattrs. Thus, the 
intersect ion of footpr ints from the 
var ious const i tuents of the sentence at 
this concept node has served to select 
this node out of all the other nodes in 
the network. Since the more general  
concept \[display request\] is on a superc 
chain from \[region d isp lay request\],  it 
wil l  also be activated, and advice from 
both places wil l  be considered.  
8.  Conc lus ion  
In s i tuat ion recognit ion,  the nodes 
of a taxonomic latt ice structure serve as 
rendezvous points where footpr ints from 
var ious const i tuent  elements of a concept 
can meet. This fac i l i tates the detect ion 
of co inc idences of related events, which 
in many cases wil l  not be suggest ive in 
isolation. The implementat ion of the 
kinds of operat ions descr ibed above 
involves a system of marker passing 
convent ions for propagat ing the various 
"footprints" around the network, detect ing 
coinc idences,  creat ing instance nodes, and 
propagat ing further markers when 
co inc idences are found. A major port ion 
of our current  research involves the 
d iscovery  of ef fect ive convent ions for 
such marker passing operat ions.  Other 
issues include working out convent ions for 
how far markers  should propagate 
(amounting to decis ions as to where to 
rendezvous),  deciding how much information 
a mark carr ies with it and to what extent 
marks are inherited, developing ways to 
al low a node to remember part ial  
40 
intersections of marks in such a way that 
it can incrementally extend them as 
additional marks accumulate, identifying 
implications of the marker passing 
strategies on representational 
conventions, etc. 
9. References 
Brachman, R.J. (1978) 
"A Structural Paradigm for Representing 
Knowledge," Technical Report No. 3605, 
Bolt Beranek and Newman Inc., Cambridge, 
MA. 
Fahlman, S.E. (1977) 
"A System for Representing and Using ' 
Real-World Knowledge," Ph.D. dissertation, 
Dept. of Electrical Engineering and 
Computer Science, M.I.T. 
Lowerre, B.T. (1976) 
"The HARPY Speech Recognition System," 
Technical Report, Department of Computer 
Science, Carnegie-Mellon university, 
Pittsburgh, Pa. 
Quillian, M.R. (1966) 
"Semantic Memory," 
No. AFCRL-66-189, Bolt Beranek and 
Inc., Cambridge, Ma. 
Report 
Newman 
Quillian, M.R. (1968) 
"Semantic Memory," in Semantic Information 
Processinq (M. Minsky, ed.). Cambridge, 
Ma:M.I.T. Press., pp. 27-70. 
Rieger, C. (1977) 
"Spontaneous Computation in Cognitive 
Models," Cognitive Science I, No. 3, 
pp. 315-354. 
Wolf, J.J. and W.A. Woods (1977) 
"The HWIM Speech Understanding System," 
Conference Record, IEEE International 
Conference o n_n Acoustics, Spe@ch L an ~ 
Signal Processing, Har?ford, Conn., May. 
Woods, W.A (1970) 
"Transition Network Grammars for Natural 
Language Analysis," CACM, Vol. 13, No. 10, 
October (reprints available). 
Woods, W.A. (1973) 
"Progress in Natural Language 
Understanding: An Application to Lunar 
Geology," AFIPS Conference Proceedinq, 
Vol. 42, 1973 National Computer Conference 
and Exposition (reprints available). 
Woods, W.A., M. Bates, G. Brown, B. Bruce, 
C. Cook, J. Klovstad, J. Makhoul, 
B. Nash-Webber, R. Schwartz, J. Wolf, 
V. Zue (1976) 
Speech Understanding Systems - Final 
Report, 30 October 1974 to 29 October 
1976, BBN Report No. 3438, Vols. I-V, Bolt 
Beranek and Newman Inc., Cambridge, Ma. 
Woods, W.A. (1977) 
"Semantics and Quantification in Natural 
Language Question Answering," to appear in 
Advances in Computers, Vol. 17, New York: 
Academic Press. (Also Report No. 3687, 
Bolt Beranek and Newman Inc., 1977). 
Woods, W.A. and R.J. Brachman (1978) 
"Research in Natural Language 
Understanding" - Quarterly Technical 
Progress Report No. 1 (BBN Report 
No. 3742), Bolt Beranek and Newman Inc., 
Cambridge, MA 
Fig. 1 
41 
