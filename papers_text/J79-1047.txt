American Journal of Computational Litrguis tics Mi crof i che 4 7 
A S U R V E Y  O F  
S Y N T A C T I C  A N A L Y S I S  P R O C E D U R E S  
F O R  N A T U R A L  L A N G U A G E  
Computer Science Department 
Courant-Institute of Matheniatical Sciences 
New York University 
251 Mercer Street,  New York. 10012 
FYris survey was prepared under contract No. N00014-67A-0467-0032 w i t h  the 
Office of N a v a l  Research, and was o r i g i n a l l y  i s s u e d  as Report No. NSO-8 of 
the Courant Institute of Mathematical Sciences, New York ~niversity. 
Copyright 0 1976 
Association for Computational Linguistics 
k SURVEY OF SYNTACTIC ANN-YS IS PROCEDURES 
FOR NATURAL LANGUAGE 
R A L P H  G R X S H M A N  
C o m p u t e r  Science D e p a r t m e n t  
C o u r a n t  Institute o f  M a t h e m a t f i c a l  S c i e n c e s  
N e w  Y o r k  University 
This s u r v d y  w a s  p r e p a r e d  u n d e r  c o n t r a c t  
No. N00014-E7A-0467-0032 w C t h  t h e  O f f Z c e  of  
NauaZ Research, and w a s  originaZZy i s s u e d  a s  
Report No. NSO-8 of t h e  Couraa t  I n s t i t u t e  of 
MathematicaZ Sciences, New Y o r k  University. 
S U M M A R Y  
T h i s  r e p o r t  i n c l u d e s  a b r i e f  d i s c u s s i o n  of  t h e  
r o l e  o f  a u t o m a t i c  s y n t a c t i c  a n a l y s i s ,  a  s u r v e y  
o f  p a r s i n g  p r o c e d u r e s  used i n  t h e  a n a l y s i s  of  
n a t u r a l  l a n g u a g e ,  and a d i s c u s s i o n  of  t h e  
a p p r o a c h e s  t aken  t o  a number o f  d i f f i c u l t  l i n -  
g u i s t i c  p rob lems ,  such a s  c o n j u n c t i o n  a n d  g r a -  
d e d  a c c e p t a b i l i t y .  I t  a l s o  c o n t a ' i n s  p r e c i s e .  
s p e c i f i c a t i o n s  i n  t h e  programming l anguage  S E T L  
o f  a n u m b e r  o f  p a r s i n g  a l g o r i t h m s ,  i n c l u d i n q  
s e v e r a l  c o n t e x t - f r e e  p a r s e r s ,  a u n r e s t r i c t e d  
r e w r i t i n g  r u l  e P a r s e r ,  and  a t ransformational  
p a r s e r .  
Table of Contents 
Page 
The R o l e  of Syntactic Analysis ..................... i, 
Computational and Theoret ical  L i r : g u i s t i c s . .  ........ I 
............... GENEFtAL SURVEY OF PARSING PROCEDITmS 1, 1 
E a r l y  Systems : Context-Free and Context-Sensitive 
Parse r s - . . . . . . . . .  ....I..........................L. 11 
......... Transformational A n a l y z e r s  : F i r s t  Sys terns. lq 
Transformational Analyzers : Subsequent Developmepts 1: 
, > I  
............... O t h e r  S y n t a c t i c  A n a l y s i s  Procedures .  ..-I 
-3 P a r s i n g  w i t h  P r o b a b i l i t y  and Graded A c c e y t a b i l i t y  .. .--V 
7s 
....................... Conjunc t ion  and Adjunc t ion . .  L 
T l  .......................... ALGORITHM SPECIFICATIONS. 
...... Parsing A l g o r i t h m s  for C o n t e x t - F r e e  Grammars. 3 1 
A Parser for Unres t r ic ted  R e w r i t i n g  Rule Grammars.. 54 
. Parsing Procedures f o r  Transformational Grammars.. 60 
A P P E N D I X -  A V e r y  S h o r t  I n t r o d u c t i o n  to S E T L . . . . . .  . 34 
....................................... BIBLIOGRAPHY 92 
1. INTRODUCTION 
The Computer Science Department of d e w  Y o r K  University, 
under  contract t o  t h e  O f f i c e  of Naval Resea rch ,  has p r e p a r e d  
a series of r e p o r t s  examining s e l e c t e d  a r e a s  of a r t i f i c i a l  
i n t e l l i g e n c e .  W e  hope i n  t h e s e  a r i t i c a l  surveys  t o  p l a c e  i n  
p e r s p e c t i v e  the main l i n e s  of p a s t  research and the reby  perhaps 
t o  s u g g e s t  f r u i t f u l  directions for f u t u r e  work. A s  part of 
these surveys w e  have p r e p a r e d  precise s p e c i f i c a t i b n s ,  i n  the 
programing language SETL, of some of t h e  basic algorithms i n  
each area. These  s p e c i f i c a t i o n s  are i n t e n d e d  t o  p rov ide  c l e a r  
points of reference for s t r u c t u r i n g  o u r  review of past work.  
* * * * *  
T h i s  first r e p o r t  i s  conce rned  with natural l anguage  proces- 
sing sys  tems, systems which are able t o  a c c e p t  instructions 'or 
d a t a  in natural language. In V e r y  g e n e r a l  terms, these systems 
p r o c e s s  the text through s e v e r a l  s t a g e s :  
(1) s y n t a c t i c :  ana lyzes  the structure of e a c h  s e n t e n c e  ( o r  
o t h e r  text u n i t )  and rearranges t h e  e l e m e n t s  of t h e  s e n t e n c e  
t o  s i m p l i f y  its s t r u c t u r e s ;  this stage shou ld  r e c o g n i z e  
paraphrases due t o  a l t e x n a t i ~ ~ e  arra~lgements  of words in a 
s e n t e n c e  
( 2 )  semahtic: restructures the s e n t e n c e s  into the form used 
f o r  internal p r o c e s s i n g ,  such as i n f e r e n c e  o r  da ta  r e t r i e v a l ;  
depending  on the  a p p l i c a t i o n ,  t h e  o u t p u t  may b e  a command i n  
an  information retrieval l anguage ,  a s t r u c t u r e  based on some 
set of semantic " p r i m i t i v e s " ,  o r  a t a b u l a r  s t r u c t u r e  s u i t a b l e  
as a d a t a  base; this stage should r e c o g n i z e  some o f  the 
pa raph ra se s  due t o  a l t e r n a t i v e  choices of words. 
( 3 )  pracjmatic: i n t e r p r e t s  the t e x t  based on p a r t i c u l a r  c o n t e x t  
(problem s i t u a t i o n  or data base) ; this stage should r ecogn ize  
s e n t e n c e s  which are e q u i v a l e n t  i n  e f f e c t ,  (such as " T h r ~ w  that 
switch." and "Turn on the light.") . 
The reader w i l l  note t h a t  these stages are very-.vaguely charac- 
t e r i  zed. Current language p r o c e s s i n g  s y s  tems differ very g rea t l y  
i n  t h e i r  s t ruc tu re  and n o t  oven these general d i v i s i o n s  can 
be identified in a l l  sys tems .  
Ihe pragmatic stage is the most heterogeneous and t h e  common 
t h reads  which do appear are based more on g e n e r a l  problem-solving 
methods t h a n  on specifically linguistic t e c h n i q u e s .  Since the 
s e m h n t i c  s tage  maps into the n o t a t i o n  required by the p r a g m a t i c s ,  
i t  is  correspondingly varied.  There i s  , however, a fair amount 
of c u r r e n t  research on the selection of semantic p r i m i t i v e s  o r  
selnantic classes; some of t h i s  research is  reviewed in t h e  
p r o c e e d i ~ ~ g s  of a recent  Courant I n s t i t u t e  symposium on D i r e c t i o n s  
i n  A r t i f i c i a l  I r~ l l c i l i gence  (Couran t  ComputPr Science Repor t  No. 7 )  . 
The syntactic s t a g e  i s  by f a r  the bes t  established a'rrd-most 
clearly def ined .  There i s  a g e n e r a l  ( a l t h o u g h  far from t o t a l )  
agreement on t h e  m o s t ;  basic u ~ l d e r l y i n g  p r i n c i p l e s ,  and t h a r e  are 
a number of wide ly -used  p r o c e d u r e s .  For  t h i s  stage , therefore, 
it seems poss ib le  to p r e s e n t  a s u r v e y  of c u r r e n t  research in 
some o rgan ized  f a s h i o n .  In the report ~ d l i c h  f o l l o w s ,  we have 
endeavored  t o  show th.e r e l a t i o n  between t h e  various syntactic 
analyzers in terms of t h e i r  h i s t o r i c a l  d e v e l o p m e n t ,  l i n g u i s t i c  
assumptions, and a l a l y s i s  p r o c e d u r e s .  For  a broader s u r v e y  of 
automated l anguage  process ing ,  readers are refer red  to [ J a lke r  
19731 - 
1.1 The Role of S y n t a c t i c  A n a l y s i s  
The sys t ems  w e  s h a l l  be d e s c r i b i n g  are a l l  motivated by 
particular applications r e q u i r i n g  natural language input, rather 
than by p u r e l y  l i n g u i s t i c  considerations. C o n s e q u e n t l y ,  t h e  
pjarsing of a t e x t  (determining i t s  s t r u c t u r e )  w - i l l  be viewed as 
ari essential s t e p  p r e l i m i n a r y  to processing t h e  i n f o r m a t i o n  i n  
t h e  text, r a t h e r  than as an end in i t s e l f .  
There  are a wide variety of a p p l i c a t i o n s  i n v o l v i n g  natural 
l a n g u a g e  i n p u t ,  such as machine t r a n s l a t i o n ,  i n f o r m a t i o n  r e t r i e v a l  , 
ques t ion  answering, conunand s y s t e m s ,  and da t a  collection. I t  may 
t h e r e f o r e  s e e m  a t  f i r s t  that there would  be l i t t l e  t e x t  processing 
which w a  id' be generally u s e f u , i  beyond the determination of a 
s t r u c t u r j a l  d e s c r i p t i o n  (e. g .  a par'se tree) f o r  each sentence. 
There are, however, a numbet of o p e r a t i o n s  whfch can r e q u l a r i z e  
s e n t e n c e  s t r u c t u r e ,  and thereby s i m p l i f y -  t h e  subsequen vA a p p l i -  
c a t i o n - s p e c i f  i c  p r o c e s s i n g .  For example, Some m a t e r i a l  i n  
sentences (enclosed i n  brackets i n  t h e  ekamples below) can be 
o m i t t e d  or "zeroed":  
John a t e  cake and Mary [ a t e ]  cookies. 
. . five o r  more [than f i v e ]  radishes 
i3e t a l k s  faster than John [ t a L k s ] .  
. . . the man [whom] I met . 
S e n t e n c e  structure can be r e g u l a r i z e d  by r e s t o r i n g  such zeroed 
i n f o r m a t i o n .  Other t r a n s f o r m a t i o n s  can relate sentences w i t h  
normal word order (I crushed those grapes.  That  I like wine 
i s  e v i d e n t . )  t o  passive (Those grapes were crushed by m e . )  and 
cleft I t  i s  e v i d e n t  that I like wine . )  c o n s t r u c t i o n s ,  and c= 
relate nominal (the b a r b a r i a n s '  d e s t r u c t i o n  of Rome) and verbal 
( t h e  barbarians d e s t r o y e d  Rome) c o n s t r u c t i o n s .  Such transforma- 
tions will p e r m i t  f u r t h e r  (e. g . ,  semantic) p r o c e s s i n g  t o  concern 
itself with a much smaller nurnper o f  structures. I n  a d d i t i o n ,  
if the s t r u c t u r e s  are appropriately chosen, operator-operand 
r e l a t i o n s  should be c l e a r l y  evident i n  the o u t p u t  of t he  
syntactic s t a g e .  
Some lexical processes, s u c h  as n o m i n a l i z a t i o n  and l e x i c a l  
decomposition, are considered s y n t a c t i c  by some and seman t i c  by 
o t h e r s .  Whether a  c l e a r  d i v i s i o n  between the syntactic m d  
semantic stages is ~ o s s i b l e  a t  all has  been a major p o i n t  of 
con t rove r sy  i n  l i n g u i s t i c s  -- between i n t e r p r e t i v e  and genera- 
t i v e  s e m a n t i c i s t s  -- over t h e  p a s t  decade. W e  may t h e r e f o r e  
expec t  t h a t ,  w h i l e  some t r a n s f o r m a t i o n s  will c l e a r l y  be  t h e  
p rov ince  o f  the syntactic stage and others the  province 
of the semantic stage, there w i l l  be a c o n s i d e r a b l e  f uzzy  
area- i n  between. This, hmever,  shou ld  not disqualify 
automatic syntactic analysis  as an a rea  of s e p a r a t e  r e s e a r c h ;  
t h e r e  i s  h a r d l y  a field of science or e n q i n e e r i n g  which is  clearly 
deIineaked from i t s  neighbors .  
The last few years have seen most work in language  processing 
devoted to the  development of  i n t e g r a t e d  s y s  terns, combining 
syntactic, semantic, pragmatic,  and generative components. T h i s  
was a h e a l t h y  and p ~ d i c t h l e  reac t ion  t o  the  e a r l i e r  research,  
which had l a rge ly  approached s y n t a c t i c  p r o c e s s i n g  i n  i s o l a t i o n  
froin these other areas.  Pt produced some systcms whose modest 
successes d i s p e l l e d  t h e  s k e p t i c i s m  t h a t  n a t u r a l  language  proccs- 
sors would ever be a b l e  to - do a n y t h i n g .  These systcms i n d i c a t e d  
how s y n t a c t i c ,  semantic, and praglnn t i c  i n f o r m L ~ t  ion I I I U S ~  i n t e r a c t  
to select  the correct  sentence a n a l y s i s .  
It is now generally understood t h a t  s y n t a c t i c  p rocess ing  by 
itself i s  inadequate  to select t h e  i n t e n d e d  a n a l y s i s  of a sen tence .  
e s h o u l d  n o t  conclude from t h i s ,  however, that i t  is impossible 
to s t u d y  the processes of s y n t a x  a n a l y s i s  s epa ra t e ly  from the 
other  components. Rather, i t  means t h a t  s y n t a x  a n a l y s i s  m u s t  
be s t u d i e d  w i t h  an u n d a r s t a n d i n g  of i ts r o l e  i n  a l a r g e r  system 
and t h e  info- rmat ion  i t  should  be able to c a l l  upcjn from o t h e r  
components ( i  e .  , t h e  p r o c e s s i n g  which t he  subsequen t  con~ponen t s  
must do to select among t h e  a n a l y s e s  produced by t h e  syntactic 
component) . 
While r ecogn iz ing  the i m p o r t a ~ ~ c e  of t o t a l  systems i n  i n s u r i n g  
t h a t  none of t h e  problems has  f a l l e n  i n  t h e  gaps between s tages  
and been fo rgo t t en ,  it s t i l l  seers t h a t  more s p e c i a l i z e d  research 
projects are e s s e n t i a l  if t he  field-of n a t u r a l  l a l ~ y u a g e  proces- 
s i n g  is to mature. The development of a n o t h e r  t o t a l  system will 
n o t  advance the f i e l d  unless it endeavors  t o  pe r fo rm some 
p a r t i c u l a r  p rocess ing  task bet ter  t h a n  i t s  predecessors; t h e  
problems are t o o  vast for each research p r o j e c t  to u s e f u l l y  
a t t ack  t h e  problems invo lved  in all t h e  phases  of process ing  at 
once. 
Some researchers have a s s e r t e d  recently that h a t u r a l  language 
p r o c e s s i n g  can be done w i t h o u t  s y n t a x  a n a l y s i s .  I t  seems to US 
that such  c l a ims  are exagge ra t ed ,  b u t  t h e y  do arise o u t  of some 
o b s e r v a t i o n s  t h a t  are n o t  w i t h o u t  validity: 
(1) For the rek i t ive ly  s imple ,  s e n t e n c e s  whose s lemant ics  i s  
w i t h i n  the  scope of current a r t i f i c i a l  d n t ~ l l i g e n c e  sys tems,  
s o p h i s t i c a t e d  s y n t a c t i c  p r o c e s s i n g  i s  unnecessary.  
T h i s  Was c e r t a i n l y  t r u e  of some e a r l y  ques t ipn-answer ing  s y s  teqs , 
whose s y n t a x  w a s  l i m i t e d  t o  a few f i x e d  i m p e r a t i v e  s t r u c t u r e s ,  
i n t o  which adjective and prepos i t i ona l  phrabe modifiers cou ld  be 
inserted. I t  i s  q u e s t i o n a b l e  whether t h i s  i s  t r u e  of  t h e  most 
s y n t a c t i c a l l y  s o p h i s t i c a t e d  of  t o d a y ' s  sys  terns (such as P d t r i c k ' s )  
I n  any case, i t  is ha rd  t o  imagine how s e n t e n c e s  of t h e  complexity 
t y p i c a l  i n  technical w r i t i n g  c ~ u l d  be unde t s tood  w i t h o u t  u t i l i z i n g  
s y n t a c t i c  ( a s  w e l l  as semant ic )  r e s t r i c t i o $ s  t o  select  t h e  
correct a n a l y s i s .  
( 2 )  S y n t a c t i c  analysis may appear in g u i s k s  o t h e r  t h a n  the 
t r a d i t i o n a l  p a r s i n g  p rocedures  ; i t  can be  in te rwoven with 
other components of the system and cqh be embedded into the 
a n a l y s i s  programs themselves .  T h i s  w i l l  often i n c r e a s e  the 
par s ing  speed cons idexably  . 
The "grammar i n  program" approach which c h a r a c t e r i z e d  many of 
the early machine t r a n s l a t i o n  efforts i s  s t i l l  employed i n  some 
of  t o d a y ' s  sys tems.  Its pr imary  j u s t i f i c a t i o n  seems t o  be 
p a r s i n g  e f f i c i e n c y ,  b u t  this should be a secondary ,  c o n s i d e r a t i o n  
for r e s e a r c h  purposes  a t  p r e s e n t ,  s i n o e  most c u r r e n t  systems a r e  
a b l e  to  p a r s e  ( o r ,  a s  often, r e j e c t  a s  unana lyzab l e )  a s e n t e n c e  
i n  under a minute. More impor t an t  as r e s e a r c h  goals should  be 
the a b i l i t y  t o  manage grammatical  complexi ty  and t h e  a b i l i t y  t o  
communicate s u c c e s s f u l  methods t o  o t h e r s .  I n  both these r e g a r d s ,  
a s y n t a c t i c  a n a l y z e r  us ing  a t t m i f i e d ,  semiformal. se t  of  r u l e s  
is bound t o  be m o r e  e f f e c t i v e .  
(3) Syntax analvsis can be d r i v e n  by s eman t i c  a n a l y s i s  ( i n s t e a d  
of b e i n g  a separate, ea r l i e r  s t a g e )  , and, i n  p a r t i c u l a r ,  
can be done by logking f o r  semant i c  p a t t e r n s  i n  t h e  s e n t e n c e .  
Syntax a n a l y s i s  i s  done s epa ra t e ly  because there are r u l e s  of 
sentence formation and %ransformation which can be s t a t e d  in 
terms of t h e  relatively broad s y n t a c t i c  categories  ( t e n s e d  verb, 
c o u n t  noun,  e tc .  ) . If t h e  semantic classes are subcategori- 
z a t i o n s  of t h e  syntactic ones  t h e n  clearly t h e  tr2i.p~ for~nnt ions  
could  be s t a t e d  i n  terms of sequepces o f  s e m a n t i c  classes.  
For those t r n n s f o r ~ n a t i o n s  which are p r o p e r l y  syntactic, however, 
w e  would find that seve ra l  t r a n s f o r m a t i o n s  a t  the seman t i c  s t a g e  
w o u l d  be r e q u i r e d  i n  place of one a t  the syntactic s t a g e ;  
certain usefu l  g e n e r a l i z a t i o n s  would bc l a s t .  
The strongest axgument of those advocating a s c m ~ n t i s s - d r i . \ . c n  
s y n t a x  i s  the a b i l i t y  of people  to i n t e r p r e t  sentcncos  from 
s e m a n t i c  c l u e s  i n  the f a c e  of s y n t a c t i c  errors or m i s s i n g  i n f o r -  
11 mation ("I want t o  - xx t o  the inovies tonight. ) . T h i s  argument  
w o r k s  both ways, however -- people can also use  s y n t a c t i c  r u l e s  
when s e m a n t i c s  i s  lackirlg; S o x  e s a m p l e ,  t o  understand the function 
of a word i n  a sentence without knowing  i t s  meaning ("Isn't t h a t  
man wearing a very frimple c o a t ? " )  . U l t i m a t e l y ,  w e  want an 
analyzer w h i c h  c a n  work from p a r t i a l  information of e i t h e r  k i n d ,  
and research i n  t h a t  d i r e c t i ~ n  i s  t o  be welcomed ( s o n e  work o n  
p a r s i n g  i n  t h e  face of u n c e r t a i n t y  has been done by s p e e c h - u n d e r -  
s t a n d i n g  g r o u p s ) .  A t  the same time, s i n c e  s c z c e s s f u l  p rocess ing  
of "perfect" s e n t e n c e s  i s  presumably a p r e r e q u i s i t e  f o r  p rocess ing  
i m p e r f e c t  sentences, i t  seems reasonable  t o  c o n t i n u e  d e v o t i n g  
subs tan t i a l  effort t o  t h e  rrmsibrable pl-oblems which remain  in 
a n a l y z i n g  perfect  s e n t e n c e s .  
1 . 2  Compu ta t ionaJ  and Theore t i ca l  L i n g u i s t i c s  
T h e o d t i c a l  l i n g u i s t s  and t h e  sort of c o m p u t a t i o n a l  
l i n g u i s t s  w e  have b e e n  c o n s i d e r i n g  espouse quite d i f f e r e n t  
research object ives  . A p r i m a r y  i n t e r e s t  of t r a n s f o r m a t i o n a l  
l i n g u i s t s  i s  expl; . ining g r a m m a t i c a l  competence -- how people 
come t o  accept some s e n t e n c e s  as  grammatical and r e jec t  others 
as ungraunatical. In p a r t i 6 u l a r ,  t h e y  a re  concerned trri th 
language u n i v e r s a l s  -- p r i n c i p l e s  of  grammar which app ly  t o  a l l  
n a t u r a l  languages .  
Computational l i n g u i s t s ,  i n  contrast, a r e  usually d e l i g h t e d  
i f  they  can manage t o  hand l e  one language (two, i f  t hey  ' re 
t r a n s l a t i n g ) .  Their primary conce rn  lies i h  t r a n s f o r m i n g  
sentences -- often assumed t o  be gramrnatioal -- i n t o  a form 
acceptable t o  some p a r t i c u l a r  a p p l i c a t i o n  s y s  tern. They are 
concerned w i t h  the  efficiency of such processing, whereas 
t h e o r e t i c a l  linguists g e n e r a l l y  don ' t worry about  t h e  r e cogn i  
t i o n  problem at a l l .  
I . Ionetheless,  the  two s p e c i a l t i e s  should have many common 
areas of interest. Ques t ions  of g r a m m a t i c a l i t y  - are i m p o r t a n t ,  
because  e x u e r i e n c e  has shown t h a t  a grammat ica l  c o n s t r a i n t  
which+ one c a s e  de te rmines  i f  h sentence i s  o r  i s  n o t  
a c c e p t a b l e  w i l l  i n  other cases be needed t o  choose between 
correct and i n c o r r e c t  ana lyses  of  a sentence. The r e l a t i o n s  
between s e t s  of sen tences ,  which are a prime focus of t r a n s f o r -  
ma t iona l  grammar, p a r t i c u l a r l y  i n  t h e  H a r r i s i a n  f famework, a r e  
c r u c i a l  t o  t h e  success of syntact ic  a n a l y s i s  p r o c e d u r e s ,  s i n c e  
t hey  enable a l a r g e  v a r i e t y  of s e n t e n c e s  t o  be reduced  t o  a 
r e l a t i v e l y  s m a l l  number o f  s t r u c t u ' r e s  . 
More g e n e r a l l y ,  both s p e c i a l t i e s  seek t o  understand a 
p a r t i c u l a r  mode'of communication. T r a d i t i o n a l  l i n g u i s t s  axe 
interested i n  a mode whioh has evo lved  as an efficient means 
of communicating ideas between people;  u l t i m a t e l y ,  w e  may hope 
that they  will unders tand  n o t  on ly  the principles of language 
structure, b u t  also some of tlle reasons why language has 
developed i n  this way. Computat ional  l i n g u i s t s ,  in s t u d y i n g  
how language can be wed for man-machine communication, are 
r e a l l y  a sk ing  much the same questions. They want t o  develop 
a mode of communication for which people are n a t u r a l l y  s u i t e d  
and t h e y  want t o  understand the p r i n c i p l e s  f o r  d e s i g n i n g  
languages  which are e f f i c i e n t  for c o m n ~ m i c a t i n g  i d e a s .  
PROCEDURES 
We can impose s e v e r a l  rough groupings on t h e  s e t  of parsers 
in order t o  structure t h e  fol lawing survey. T o  b e g i n  withr we 
may try to separate those sys  tcms davclobed w i t h  solme reference 
to t r ans fo rmat iona l  theory from the nont - ransfor lna t iona l  s y s  terns. 
T h i s  t u r n s  o u t  s l s o  to be an approximate h i s t o r i c a l  d i + v i s i o n ,  
s i n c e  most s y s t e m s  written since 1 9 6 5  have made soir~c connection 
w i t h  transformational theory, even though their ihcthods of 
a n a l y s i s  nmy ke only di%tzant ly  r e l a t e d  t o  t r a n s f o l - m a t i o n a l  
mc ch an i s IIIS . 
Z'hc t r ~ ~ n s f o r m a t i a n a l  sys t cms  may i n  t u r n  be d i v i d e d  into 
those parsers which have bccn systematically clerivca f rom a 
spec i f i c  transformational g~ncrative gracunar and those  which 
have " s a c r i f i c e d "  t h i s  d i r e c t  c o n n e c t i o n  r r i i  t h  a g e n e r a t i v e  
grammar i n  order  t o  o b t a i n  a more d i rec t  and e f f i c i e n t  a l g o r i t h m  
f o r  recovering base s t r u c k u r e s .  This division appears t o  be 
i n  part a r e s u l t  of o u r  i n a d e q u a t e  t h e o r e t i c a l  understanding of 
t r a n ' s f o r m a t i o n a l  grammars, and may be reduced by some r e c e n t  
theore  tical work on t r ans fo rmat iona l  grammar's. 
2 . 1  E a r l y  Systems : C o n t e x t L F r e e  . and Con tex t -Sens i  t i v e  Parsers 
The p r c t r a n s f o r m a t i o n a l  systems, developed mostly between 
1 9 5 9  and 1 9 6 5 ,  were, w i t h  a few e s c c p t i o n s ,  parsers  f o r  con tex t -  
free l a n g u a g e s ,  a l t hough  c loaked in a n u r ~ b e r  of d i f f e r e n t  g u i s e s .  
These s y s  terns were based on immediate c o n s t i t u e n t  a n a l y s i s ,  
dependency tlieory , linguistic string theory,  o r  somet imes  no 
theory a t  all. 
The l a rge s t  and  probably the most impor tan t  o f  these early 
projects was t h e  H a r v a r d  P r e d i c t i v e  Analyzer [Runo 1 9 6 2 1 .  A 
predictive a n a l y z e r  i s  a top-down parser  for c o n t e s t - f r e e  
g rammars  written in Greibach normal form; t h i s  formulation of 
t h e  grammar w a s  adopted from e a r l i e r  work by Ida Rhodes for 
h e r  R u s s i a n - E n g l i s h  t r a n s l a t i o n  p r o j e c t .  The size of the  
grammar was staggering: a 1 9 6 3  r e p o r t  [Kuno 19631 q u o t e s  
f i g u r e s  of 1 3 3  Uord c l a s s e s  'and about 2100 p roduc t ions .  Even 
with  a grammar of this size, the s y s t e m  did not i n c o r p o r a t e  
simple agreement restrictions of  E n g l i s h  syntax Since t h e  
program was designed t o  produce p a r s e s  f o r  s en t ences  which 
were presumed to be grammatical ( and  n o t  t o  d i f f e r e n t i a t e  
between grammatical, and nongrammatica1 septences) , it was 
a t  first hoped that it could operate without these res t r ic -  
tions. It was soon discoveredr however, t h a t  these restric- 
tions were required t o  eliminate i n v a l i d  analyses of grammatical 
s e n t e n c d s  . Because the direct i n c l u s i o n  o f ,  s ay ,  sub jec t -verb  
number agreement would cause a l a r g e  increase i n  an a l ready  
very l a r g e  grammar, the Harvarq group chose i n s t e a d  t o  include 
a spec ia l  mechanism i n  the parsing program t o  pe r fo rm a 
rudimentary check on number agreement. Thus the Harvard Predic-  
tive Analyze r ,  though p r o b a b l y  the most successful of the  
c o n t e x t 4  ree a n a l y z e r s ,  c l e a r l y  i n d i c a t e d  the inadequacy of 
a context- free fo rmula t ion  of natural languqge grammar. 
The ~ a r v a r d  Pred i c t i ve  Analyzer parsing a l g o r i t h m  progressed 
through several stages. The f i r s t  version of t h e  p r e d i c t i v e  
a n a l y z e r  produced only one a n a l y s i s  of a s e n t e n c e .  The next  
version i n t r o d t x e d  an automatic backup mechanism in order t o  
produce a l l  a n a l y s e s  of a sentence. This i s  an e x p o n e n t i a l  t i m e  
algorithm, hence  very slow f o r  l o n g  sentences; a 1 9 6 2  r epor t  
gives t y p i c a l  times as 1 minute  for an 18 word s e n t e n c e  and 
12 m i n u t e s  for a 35 word sentence. A n  improvement o f  more t h a n  
an 0- of magnitude was obtained i n  t h e  f i n a l  v e r s i o n  of t h e  
program by using a b i t  matrix for a p a t h - e l i m i n a t i o n  technique 
[Kuno 19651. When an attempt was made to match a nonterminal 
symbol t o  t h e  sentence b e g i n n i n g  a t  a p a r t i c u l a r  word and no 
match was found; t h e  c o r r e s p o n d i n g  bit was turned on; if the 
same symbol came up a g a i n  l a t e r  i n  the ~ a r s i n g  a t  t h e  same 
p o i n t  i n  the sentence, the program would n o t  have t o  try t o  
match it again. 
Another  important e a r l y  pa r se r  was t h e  immediate c o n s t i t u e n t  
anal-yzer used  at RAND.   his s y s t e m  used a grammar in Chornsky 
normal form. and a parsing algorithm designed by John Cocke ,  
which produced all ~ n a l y s e s  bottom-up in a single l e f t - t o -  
r i g h t  scan of - the sentence [Hays 1 9 6 7  f. This was a fqst 
a lgo r i thm but - because a l l  p a r s e s  were dcve  loped s i ~ ~ ~ u l t - n n c o u s  ly 
it nccdcd a l o t  of space f o r  long  sentences; t h e  Rand s y s t e m  
appears therefore to have bccn l i m i t e d  to sentences of abou t  
30 words. 
A d i f f e r e ~ k  bottom-up ~ I I A ~ Y S ~ S  PI-occadure was ust2d ill t h e  
f i r s t  l i n g u i s t i c  s t r i n g  t ~ n ~ l h * s i s  pqogram d c v a l ~ p c d  at t h e  
U n i v e r s i t y  o f  P e n n s y l v a n i a  [Harris 1 9 6 5 1 .  T h i s  proctxlure, 
called a cycling c a n c e l l i n g .  automaton, makes n stvies l e f t -  
t o - r i g h t  passes t h r o u g h .  the  s e n t e n c e ;  in each p ~ ~ s s  o n e  t y p e  of 
reduct ion was performed. The s t r i n g  pa r se r  r e c o g n i z e d  two 
c lasses  of s t r i h g s  : first o ~ d e r ,  pot c o n t a i n i n g  verb-object, 
and second order ,  c o n t a i n i n g  verb-ob ject ; the r e d u c t i o n  i,f the 
sentences  was correspondingly done in two s tages .  In addition 
& 
to these r e d u c t i o n s ,  w h i c h  corresponded to context- f  ree r u l e s  
t he  parsipg program a l so  i n c l u d e d  some s y n t a c t i c  r e s t r i c t i ~ n s  
which  w e r e  checked when second order  s t r i n g s  were reduced. 
A system incorpo; t -a t ing this &lrclinq automaton ~ c h c m e  was later 
used by Bross at Rdsewll P a r k  f o r  t h e  a n a l y s i s  of rrlcdical 
repor ts  [Bross 196 8, ~ h a p i r o  19711.  
As f a r  as we k~low,  onJy  one major p a r s i n g  s y s t e m  has been 
developed using a context-sensitive p h r a s e  s t r u c t u r e  graimar, 
T h i s  w a s  DZACON, Direct E n g l i s h  Access and Control, which was 
des igned  as a n a t u r a l  laqguaqe i n t e r f a c e  to a co~r~isnd,  c o n t m l ,  
and i n f o r m a t i o n  retrieval system for the A r m y  and w a s  developed 
at General Electric [Craig 1'3661. DZACOiJ was one of t h e  f i r s t  
systems t o  p rov ide  f l e x i b l e ,  s y s t e m a t i c  i n t e r a c t i o n  between 
the parser  and the s e m a n t i c  c o n ~ p o n e n t .  Associgated with each 
p roduc t i on  in t h e  grammar was a semantic  rule. ~ h e s e  r u l e s  
opera ted  on a ring-structured data base and had  t h e  f u n c t i o n s  
of locat ing,  adding,  and changing informat ion i n  t he  data base. 
The parsing was done bottom-up, developing all analyqes of the 
sentence i n  p a r a l l e l .  A s  each r educ t ion  was performed,  t h e  
associated semantic rule was invoked. I n  the Case of  a query ,  
the sequence of r u l e s  associated with the correct analysis w a s  Q 
supposed to Locate the desired answer in the data base. In 
some cases a rule could  n o t  be appl ied t o  t he  data base (e .g . ,  
a particqlar relation between two items d i d  n o t  e x i s t )  ; t h e  
rule then returned a fai l-ure s i g n a l  t o  the parser, i n d i c a t i n g  
that the analysis was semantically anomalous, and t h i s  a n a l y s i s  
was aborted. 
W o o d s  has noted [Woods 197Ql t h a t  t h e  parser  used i n  t he  
Dmm4 pro jecf may produce redundant parses, and has g iven  
a parsing algorithm for contex t -sens i t ive  languages which 
repedies this deficiency . 
2 - 2  Transformational Analyzers: F i r s t  Systems 
When the theory of transformational grammar was elaborated 
in the early l . 9 6 0 1 s  there was c o n s i d e r a b l e  i n t e r e s t  in finding 
a corresponding recognition procedure.  Because t h e  grammar is 
stated i n  a generative form, however, t h i s  i s  no  s imple  matter. 
A &hornsky) tree transformational grammar c o n s i s t s  of a set 
of context-sensitive phrase s t r u c t u r e  rules, which g e n e r a t e  a 
set of base treesa, and a set of t ransformat ions ,  which a c t  on 
base trees to produce the s u r f  ace trees. A (Harris) s t r i n g  
t r a n s f o ~ t i o n a l  grammar consists of a finite set of sequences 
of word categories, c a l l e d  kernel s e n t e n c e s ,  and a set of 
transformations which combine and modify these kernel s e n t e n c e s  
t6 e the other sentences of t he  language. There are a t  
least three basic  problems i n  reversing the g e n e r a t i v e  process: 
(1) for a tree t r a n s f o r m a t i o n a l  grammar, a s s i g n i n g  t o  a given 
sentence a set of p a r s e  trees which includes a l l  the su r face  
trees which would be assigned by the trans f o r m a t i o n a l  grammar 
( 2 )  giveq a tree n o t  i n  t h e  b a s e ,  d e t e r m i n i n g  which sequences 
of transf orma t igns  might have applied t o  generate this t r e e  
( 3 )  hav ing  decided on a transformation whose r e s u l t  may be 
the p r e s e n t  t ree ,  undoing this t r a n s f o r m a t i o n  
If we a t t a c k  each of these problems i n  t h e  most s t r a i g h t f o r w a r d  
manner ,  w e  are likely t o  try many false p a t h s  w h i c h  w i l l  not 
lead  t o  an analysis. F o r  the f i r s t  problem, w e  could u s e  a 
c o n t e x t - ?  ree gramrnar which will g i v e  all the  su r face  trees 
assigned by the t r a n s f o r m a t i o n a l  granunar, and probably l o t s  more 
The superabundance  of ' ' false" s u r f a c e  trees is aggravated by t h e  
f a c t  that most E ~ ~ g l i s h  words have more t h a n  one word category 
( p l a y  more t h a n  one  s y n t a c t i c  role), a l t h o u g h  n o r m a l l y  on ly  o n e  
is used  in any g i v e n  sen'tcnce. F t h e  second and  th ird  p r p b ? e m s ,  rrie 
can mnswuct a set of r e v e r s e  tYans formations ; however, since 
w e  are probab ly  unable t o  determine uniquely in ,  advance the 
t r ans fo rma t ions  which produced a g iven  t r e e ,  w e  w i l l  have t o  
t r y  many sequences  of r e v e r s e  t r a n s f o l r r n a t i o n s  wh ich  will n o t  
y i e l d  a base tree. 
Because of  these problems,  the e a r l i e s t  r e c o g n i t i o n  p r o c e d u r e ,  
c t l gges ted  by Mat thews ,  was based on the idea of s y n t h e s i z i n g  trees 
t o  match a g iven  s e n t e n c e .  Al though some checks were t o  have 
been made a g a i n s t  the s e n t e n c e  d u r i n g  the g e n e r a t i o n  p r o c e d u r e ,  
i t  was still an i n h e r e n t l y  aery i r ~ e f f i c i e n t  procedure and was 
n e v e r  implemented.  Two. major  systems were developed i n  t h e  
mid-GO ' s ,  however, which d i d  have  limited success: t h e  s y s t e m  
of Zwicky et al at MITRE and t h a t  of P e t r i c k .  
The t r a n s f  o r rna t i ona l  g e n e r a t i v e  grammar f r o m  w h i c h  the MITRE 
group worked  had a base component with abou t  2 7 5  rules and a s e t  
of 5 4  t r a n s f o r m a t i o n s  [Zwicky 19651.  For  the r e c o g n i t i o n  proce- 
I t  dure t h e y  developed manual ly  a context- f ree c o v e r i n g "  g r a m m a r  
with about 550 p r o d u c t i o n s  t o  produce t h e  s u r f a c e  t rees  and a 
s e t  of 134 reverse transformational rules.  heir r e c o g n i t i o n  
procedure had f o u r  phases: 
(1) a n a l y s i s  of the s e n t e n c e  u s i n g  t h e  c o n t e x t - f r e e  c o v e r i n g  
grammar (with a bottom-up p a r s e r )  
( 2 )  appl ica t ion  of the  revexse trans ro r rna t iona l  rules 
'i3) for each candidate base tree produced by steps (1) and ( 2 )  , 
a check whether it can i n  f a c t  be generated by the base 
component 
( 4 )  f o r  each base tree and sequence of transformations 
which passes the t e s t  in s t e p  ( 3 )  , the (forward) t r ans -  
foZmat ions  a r e  a p p l i e d  to verify that t he  o r i g i n a l  
sen tence  can i n  fact be generated 
(The f i n a l  check i n  step ( 4 )  i s  r e q u i r e d  bccause the cover ing  
grammar may lead. t o  s p u r i o u s  matches of a transformation to t h e  
sentence in the reverse transformational process and because 
the  r e v e r s e  transformations may not incorpora te '  a l l  the 
c o n s t r a i n t s  i nc luded  i n  the forward  t rans format ions .  ) The 
covering grammar produced a large number of spurious surface 
analyses which the parser must process. The 1 9 6 5  r e p o r t  f o r  
example, cites a 1 2  word sentence which produced 4 8  parses 
with t he  covering grammar; each must be followed through s t e p s  
(2)  and ( 3 )  before most can be e l i m i n a t e d .  The system was 
therefore  very s l o w ;  36 minutes were r e q u i r e d  to analyze one 
11 word s e n t e n c e .  
TWO measures were taken Sy t h e  MITRE group to speed up t h e  
program: "super-trees" and r e j e c t i o n  rules [Walker 1 9 6  61 . 
"Super- t rees"  w a s  the MITRE t e r m  fo r  a nodal span representation, 
in which severa l  parse trees were r e p r e s e n t e d  i n  a s i n g l e  
structure. They in tended  t o  app ly  t h e  reverse transformations 
t o  these s u p e r - t r e e s ,  thus processing several possible  surf ace 
t r e e s  simultaneously; i t  is n o t  clear i f  t hey  succeeded i n  
implementing t h i s  i d e a .  R e j e c t i o n  r u l e s  w e r e  tests which w e r e  
applied t o  the tree d u r i n g  the reverse transformational process 
(step (2) above) , in order, t o  eliminate some trees as early 
as possible in t h e  pa r s ing .  The rejection rules incorporated 
some c o n s t r a i n t s  wi~j-ch p r e v i o u s l y  w e r e  only i n  the  forward 
t r ans fo rma t iona l  component, and so  eliminated some trees i n  
s tep 12) which before had su rv ived  t o  step ( 4 )  . The rejection 
r u l e s  had a s igni f ic :ant  e f fec t  on parsing t i m e s  - the 11 word 
1 s e n t e n c e  which  t o o k  36 m i n u t e s  hefore now took o n l y  6 
The system developed by P e t r i c k  [ P e t r i c k  1965, 1966; 
Keyse r  19671 is similar in o u t l i n e :  a p p l y i n g  a series oE 
reverse t ransformations,  check ing  if the r e s u l t i n g  tree can 
be generated by the base component, and the: verifying the 
a n a l y s i s  by applying the forward t r a n s f o ~ m a t i o n s  ta the base 
tree . There are, however, several d i i f e r e ~ c e s  from the M'TTRE 
s y s t e m ,  motivated by t he  desire to have a parser which  could 
be produced automatically from t h e  generative formulation of 
the grammar. P e t r i c k  d e v i s e d  a p rocedure  t o  generate, from 
the  base component and trans f o r m a t i o n s ,  an enlarged c o n t e x t -  
f r e e  granunar s u f f i c i e n t  to ana lyze  t h e  surface sentence s t r u c -  
tures. He also automatict*J.ly converted a se t  of forward t r a n s -  
formations mi?- ting certain condit ions i n t o  pseudo-inverse 
(reverse)  t r a n s f o r m a t i o n s .  H A S  parsing procedure a l so  o i f  fered 
from the d I T R E  algori thm i n  the way i n  which the reverse 
t r a n s f o r m a t i o n s  are  applied. I n  the MITRE: program reverse t rans-  
f o r m a t i o n s  operated on  a sentence tree, just like f o q v a r d  
t rar ls format ions  i n  a Chonlsky grammar. P e t r i c k ,  on the other hand, 
did riot construct a surface t ree  in the analysis phase; when a 
p a r t i c u l a r  reverse t r a n s f o r m a t i o n  came up for cons idera t ion ,  he  
built just enough s t r u c t u r e  above the sentence ( u s i n g  t h e  enlarged 
context-? ree grammar) to de t e rmine  if the t r ans fo rmat ion  was 
applicable. If it was,  t h e  transformation w a s  applied and t h e  
s t r u c t u r e  above t h e  s e n t e n c e  then t o r n  down aga in ;  w h a t  was 
passed f r o m  one  reverse t r a n s f o r m a t i o n  t o  the next was o n l y  
the string of word categories.  I n  t h e  verifying phase ,  of  course, 
P e x r i c k  had to fo l low the rules of C h o n ~ k y  grammar and apply 
the forward t ransformat ions  to a s e n t e n c e  tree.  
The price f o r  g e n e r a l i t y  was p a i d  in e f f i c i e n c y .  Petrick's 
problems w e r e  more severe t h a n  M I T R Z ' s  f o r  t w o  reasons. ~ i r s t ,  
the ~ b s e n c e  of a s e n t e n c e  tree during t h e  application of the 
reverse t rans  formational r u l e s  meant t h a t  many sequences of 
re-rse transformations were t r i ed  which did n o t  correspond to 
any sequence of tree transformations and hence would eventually 
be rejected. Second, i f  several rever se transformations Could 
apply a t  some point in the a n a l y s i s ,  the procedure c o u l d  not 
tell i n  advance which would l ead  t o  a v a l i d  deep s t r u c t u r e .  
Consequent ly ,  each one had to be t r i ed  and the r e s u l t i n g  s t r u c -  
ture followed t o  a deep structure of a "dead end" (where no 
more transformations a p p l y ) .  T h i s  produces a growth i n  the number 
of a n a l y s i s  paths  which is exponential in the number of r e v e r s e  
transformations applied. This explssion ntn be avoided on ly  if t h e  
reverse transformations include t e s t s  of the c u r r e n t  analys i s  t ree  
to d6terrnine which transformations a p p l i e d  to generate .this tree. 
Such t e s t s  were included in the manually prepared reverse t rans-  
formations of t h e  MITRE group,  b u t  it would have been  fax t o o  
complicated f o r  Pe trick t o  produce s u c h  tests automatlcally when 
i n v e r t i n g  the trans formations. 
Potrick's system has been s i g n i f i c a n t l y  revised over the 
past decade [ P e t r i c k  1973,  Plath 1974aI. I n  t h e  c u r r e n t  sys tem 
t h e  covering grammar and reverse t r a n s  format ions  are both 
prepared manual ly .  The trans formational decomposi t ion  p r o c e s s  
works on a t ree  (as d i d  MITRE ' s )  , and considerably f l e x i b i l i t y  
has been .,provided in s t a t i n g  t h e  trankformations and the condi-  
tions of applicability . The transformations and c o n d i t i o n s  
may be stated e i the r  i n  the t r a d i t i o n a l  dorm (used by linguists) 
or i n  terms of elementary o p e r a t i o n s  combined i n  LISP p rocedures .  
The r e s u l t i n g  system is fast enough to be used i n  an i n f o r m a t i o n  
r e t r i e v a l  system with a grammar of moderate s i z e ;  most r eques t s  
are processed in less than one minute. 
2.3 Transformational Analyzers :  Subsequent Developmi!ints 
One result of the early t r a n s f o r r n a t i ~ n a l  sys tems w a s  a 
r e c o g n i t i o n  of t h e  importance sf f i n d i n g  an e f f i c i e n t  pa r s i ng  
procedure i f  traiisformationa.l a n a l y s i s  was ever t o  be a u s e f u l  
19 
t e c h n i ~ u e .  As the systems i n d i c a t e d ,  there are two main 
obstacles to an e f f i c i e n t  procedure. First, there is the problem 
of r e f i n i ' n g  the s u r f a c e  analysis, s o  Chat each s e n t e n c e  produces 
fewer troes f o r  which transformational decomposit ion must  be 
at ten~pted.  This h a s  g e n e r a l l y  been approached by u s i n g  a inore 
1% 
powerful  mechanism than a context- .free p a r s e r  for t h e  surface 
analysis. Second, there is the problem of dc tc r rn in ing  the base 
s t r u c t u r e  (or k e r n e l  s e n t e n c e s )  from the s u r f a c e  s t ruc . t :u re  i n  a 
r e l a t i v e l y  d i r e c t  fash ion .  This has  g e n e r a l l y  been done by 
associaEing p a r t i c u l a r  r u l e s  fo r  building t h e  deep s t r u c t u r e  
w i t h  rules of t h e  surface  s t ruc tu re  analysis. The approach 
here has  g e n e r a l l y  been ad hoc, d e v e l o p i n g  a reverse mapping 
w i t h o u t  m p l i c i t  reference to a evr re spond ing  s e t  of f o ~ w a r d  
trans format i o n s .  
S e v e r a l  groups which have p l a y e d  a significant role in the 
deve lopmen t  of c u r r e n t  p a r s i n g  systems have been t i e d  t o g e t h e r  
by t h e i r  comofl use c>f r e c u r s i v e  transition networks. Althouqh 
t h e i r  use of these transition networks  i s  n o t  c e n t r a l  t o  the i r  
basic c o n t r i b u t i o n ,  it i s  f r e q u e n t l y  r e f e r r e d  t o  and so  deserves 
a few words of exp lana t ion .  A t r a n s i t i o n  ne twork  is a se t  of 
nodes ( i n c l u d i n g  one initial and at l e a s t  one  t e r m i n a l  node) 
and a s e t  of directed arcs between the nodes, l abe l ed  w i t h  
symbols from the language; it is a standard r e p r e s e n t a t i o n  f o r  
r e g u l a r  languages. A r e c u r s i v e  transition network i s  a set of 
t r a n s i t i o n  n e t w o r k s  in which t h e  arcs of one network may also 
be labeled w i t h  the names of other n e t w o r k s ;  i t  is  a form of 
r e p r e s e n t a t i o n  of context-f ree languages.  In c o n t r a s t  to the 
u s u a l  context-f ree phrase  s t r u c t u r e  grammars, this i s  e q u i v a l e n t  
t o  a l l o w i n g  r e g u l a r  e x p r e s s i o n s  i n  place of f i n i t e  sequences  of 
elements i n  productions. T h i s  does n o t  increase the weak 
g e n e r a t i v e  capac t i ty  of the grammars, b u t  a l lows n o n r c c u r s i v e  
fo rmula t i ons  for otherwise r e c u r s i v e  cons t - ruc t ions .  
The first system u s i n g  such a network was developed by 
Thorne, B r a t l e y ,  and D e w a r  a t  Edinburgh [Thorne 1968, D e w a r  1 9 6 9 1 .  
They s t a r t e d  w i t h  a regular base grammar, i - e . ,  a transition 
network. The i m p o r t a k e  of using a regu la r  base l i e s  i n  their 
claim that some transformations are equAvalent i n  e f fec t  to 
changing the base t o  a recursive transition network. Transfor- 
m a t i o n s  which could n o t  be handled i n  this fasion, such as 
conjunction, were incorporated  in^^ the p a r s i n g  program. P a r s i n g  
a sentence with t h i s  surface grammar should  t h e n  a l s o  give some 
i n d i c a t i o n  of t he  a s s o c i a t e d  base and t r a n s f s L T n a t i o n a l  structure. 
Their p u b l i s h e d  papers do n o t  describe, however,  thee process by 
which the  surface grammar i s  c o n s t r u c t e d  and s o  it i s  n o t  c lear  
just how t h e  transformation and base s t r u c t u r e  i s  extracted, 
from their parse. 
The recutsive t r a n s i t i o n  network was developed i n t o  an 
augmented recursive t r a n s i t i o n  network grammar i n  the system of 
Bobrow and Frasex m w  9 An ausmented network i s  one 
in which an a r b i t r a r y  predicate, w r i t t e n  i n  some g e n e r a l  purpose 
language ( i n  this case, L I S P ) .  may be associated u i t h  each arc i n  
the network. A t r a n s i t i o n  i n  the n e t w ~ r k  is n o t  allowed if t h e  
predicate associated w i t h  t h e  arc f a i l s .  These predicates 
perform t w o  functions i n  the  grammar. F i r s t ,  they are used 
t o  incorpora te  r e s t r i c t i o n s  i n  the language which would be 
difficult or impossible to s t a t e  w i t h i n  the amtext-free 
mechanisms of the recursive network ,  e. g. , agreement r e s t r i c t i o n s .  
Second, t h e y  are used t o  c o n s t r u c t  the deep s t r u c t u r e  tree as t h e  
sentence is being parsed. 
The augmented t r a n s i t i o n  network was further developed by 
Woods a t  B o l t  Be ranek  and Newman .  In order to r e g u l a r i z e  the 
predicates,  he in t roduced  a standard set of operations for 
b u i l d i n g  and t e s t i n g  the deep structure lWoods 1970bl. He 
considerably e n l a ~ g e d  t h e  scope of the grammar and added a 
semantic component fbr t r a n s l a t i n g  the deep structure into 
information r e t r i e v a l  commands. With these a d d i t i o n s ,  the 
system served as a moderate ly  successful natural language i n p u t  
interface t o  a retrieval system for data about moon rocks [Woods 
1 9 7 2 ,  19731. The augmented t r a n s i t i o n  network, and i n  pa r t i -  
cular the formalism developed bv Woods, has proven t a  be an 
effective i n s t r u m e n t  for c o n s t r u c t i n g  n a t u r a l  language front-ends 
which  is r e l a t i v e l y  simple to implement and use; it i s  probably 
the most widely used procedure today. 
L i k e  seve ra l  of t h e  sys tems  descr ibed  above, Proto-RELADES, 
developed 1 IBM Cambridge [Culicover 19691 ,  t r i e d  to o b t a i n  a11 
e f f i c i e n t  t r ~ n s f o r ~ n a t i o n a l  d e c o m p o s i t i o n  a lgor i thm by linking 
t h e  r u l e s  f o r  building the deep s t r u c t u r e  to the produc t ions  
of t h e  sur face  granmar. T h e i r  su r f ace  granunar w a s  a l s o  augmented 
by res t r i c t ions  ( i n  P L / I  this time). Aorvover, t h e i r  system 
d i f f e r e d  from t hose  mcnt ioncd  e a r l i e r  in several important 
respects : ~ i r s t ,  t h e  s u r f  ace grammar allowed c o n t e x t - s e n s i t i v e  
as  well as contest-free ru les .  Second, the r u l c s  which b u i l t  
the deep s t r u c t u r e  d u r i n g  the p a r s e  were in the form af reverse 
transformations a c t i n g  or! an ( incomplete)  s e n t e n c e  tree (in 
c o n t r a s t  to t h e  rules used by  V400dsr f o r  example, which f i r s t  
put- wer& -8nto registers l abe led  " s u b j e c t "  , "verb", and "object" 
and l a t e r  b u i l d  a tree out of t h e m ) .  Pro to-RELADES was tested 
as a r e s t r i c t e d  E n g l i s h  language preprocessor f o r  a library c a r d  
c a t a l o g  r e t r i e v a l  system [Loveman 1 9 7 1 1 .  
One drawback of these procedures was the  relatively ad hoe 
methodsr from a l i n g u i s t i c  p o i n t  of view, used to c o n s t r u c t  the 
s u r f a c e  grammars and to tie them i n  t o  t h e  app rop r i a t e  reverse 
t r a n s  formations. A more p r i n c i p l e d  approach t o  trans formational  
decomposit ion w a s  proposed by J o s h i  and H i z  1 9 6 2 ,  Biz 1 9 6 7 1 .  
In c o n t r a s t  to the s y s t e m s  descr ibed above, their p r o c e d u r e  
w a s  based on Harris' s t r i n g  transformational granunar. 
One advantage of the H a r r i s i a n  t h e o r y  over that of Chomsky is 
t h e  theoretical basis  i t  prov ides  f o r  the segmenta t ion  of t h e  
s e n t e n c e  into " l i n g u i s t i c  s t r i n g s "  (Chomsky ' s  theory, i n  
c o n t r a s t ,  m a k e s  no g e n e r a l  a s s e r t i o n s  about the surface s t r u c t u r e  
of sentences.) The procedure of ~ o s h i  and H i z  was p r e d i c a t e d  on 
the claim that, from a n  a n a l y s i s  of the sentence into linguistic 
s t r i n g s ,  one could directly determine  the transformations w h i c h  
acted to produce the  s e n t e n c e ,  w i t h o u t  hav ing  to t r y  many s equences  
sf reverse transformations. T h e i r  proposed sys tern therefore 
consis ted of a procedure f o r  l i n g u i s t i c  string analysis (a  
context-free p a r s i n g  problem at the level ,of s i m p l i  f i c a t i o n  
of t h e i r  o r i g i n a l  proposal) and a s e t  of r u l e s  which  constructed 
from each s t r i n g  a corresponding k e r n e l - l i k e  sentence. 
T h e i r  o r i g i n a l  proposal was a s i m p l i f i e d  scheme which 
accounted for only a l imi t ed  s e t  of t rans . formations.  It has 
been followed by a good deal of theore t ica l  work on adjunct 
grammars and trace conditions [Joshi  19731 which has l a i d  a 
fbrrnal b a s i s  f o r  t h e i r  procedures. These studaies indicate k o w  
it may be p o s s i b l e ,  starting from a transformational grammar 
not specifically oriented towards r e c o g n i t i o n ,  to dkterrn ine  the 
features of a sentence which i n d i c a t e  t h a t  a particu1a.c t r ans fo r -  
mation applied i n  generating it ,  and hence t o  produce an eff  i- 
cient analysis procedure* 
Another group which has used l i n g u i s t i c  s t r i n g  a n a l y s i s  is 
t h e  Linguistic S t r i n q  Project a t  New York University, led by 
Sager [Sager 1967, 1973; Grishman 1973a, 1973131. T h e i r  sys t em,  
which has gone through ssvera l  versions since 1965, is based 
on a context-  free grammar augmented w i t h  res t r ic t ions .  Because 
they were conce ned with processing s c i e n t i f i c  text, rather than 
commands or queries, t hey  were l ed  to develop a grammar of 
particularly broad coverage. The p r e s e n t  gramrr~ar has about 250 
context-free rules and about 200 res t r ickions;  al though not as 
swift as some of the smaller sys tems ,  t h e  parser is able to 
analyze most sentences in less than one minute. Because of the 
large size of their grammar, t h i s  group *has been p a r t i c u l a r l y  
concerned w i t h  techniques for organizing and s p e c i f y i n g  the 
grammar which w i l l  f a c i l i t a t e  f u r t h e r  development. In p a r t i c u l a r ,  
the most recent implementation of t h e i r  s y s t e m  has added a spec i a l  
language designed for t h e  economical and perspicuous s t a e m e n t  
of the res t r ic t ions  [Sager 19751. 
One of t he  earlier versions of t h i s  s y s t e m ,  w i t h  a much more 
restricted grammar, was used as the f r o n t  end for an information 
re t r i eva l  sys t em developed by C a u t i n  at t h e  U n i v e r s i t y  of 
P e n n s y l v a n i a  [ C a u t i n  1369 ] . 
The ~inguistic S t r i n g  P ro jec t  s y s t e m  has r e c e n t l y  been extended 
to include a transformational decomposition phase;  t h i s  phase 
follows t h e  l i n g u i s t i c ?  s t r i n g  a n a l y s i s  [IIobbs 1 9 7 5 1 .  As in 
the case of the Josh i - I I i z  parser ,  thc s t r i n g s  i d e ~ ~ t i f i c d  in
the sentence generally indicate which rcvcrsc t ransfrsrmat isns  
must be a p p l i e d .  '?he trans'forrnations are w r i t t e n  i n  an exten- 
s i o n  of t h e  1-anguage which w a s  u s e d  f u r  w r i t i n g  the restrictions. 
The s y s t e l u s  of Woods, P e t r i c k ,  and S a y e r  e x h i b i t  a range of 
approaches to the prob J . m  of tral.lsf or~naticanal deceinpos i tion. 
T h e i r  p a r s i n g  p~octzclurcs are  si f i l a r  i n  ,nany respects:  they have  
a contcx t -?see granunar as t h e  Ert t~uowsrk for the i r  su r f ace  a n a l y s i s ,  
and they use procedures  bo th  to cspress gral1~11rltical c o ~ ~ s t r a i n t s  
and to ef fec t  t h e  reverse t ransformat ions .  Petrick's s y s t e m  
d i f f e r s  from t h e  o thers  in t w o  p r imary  respects : the r e s t r i c t i o n s  
on the context-free grammar are  imposed by f i l t e r i n g  trans forn~a- 
tions w h i c h  a c t  e a r l y  i n  the  t r a n s f o r m a t i p n a l  phase to r e j e c t  
i l l - formed trees, rather than  by p r o c e r l u r e s  o p e r a t i n g  during 
t h e  su r f ace  a n a l y s i s .  T h i s  w o l  l d  s e e m  to be disadvantageous  
from the p o i n t  of view of e f f i c i c n c y ,  s i n c e  e r roneous  parses  
which m i g h t  be aborted a t  the ' b e g i n n i n g  of t h e  s u x f a c e  a n a l y s i s  
m u s t  be followed through t h e  ent i re  sur face  a n a l y s i s  and p a r t  
of the transformational deconpss i  t i o n .  Second, the t r ans  forma- 
t i ons  are n o t  assoc ia ted  wi.m p a r t i c u l a r  productions of the 
sur face  grarxnar, b u t  rather w i t h  p a r t i c u l a r  p a t t e r n s  in t h e  
tree ( " s t r u c t u r a l  descriptions") , so p a t t e r n  match; ng o p e r a -  
t i o n s  a r e  r e q u i r e d  to d e t e r m i n e  1;rhich t r a n s f o r m a t i o n s  t o  apply.  
These d i f f e r e n c e s  r e f l ec t  P e t r i c k  ' s  c'iesire to remain as close 
as is prac t i ca l  to the f o r m a l i s m  of t r ans format iona l  l i n g u i s t i c s .  
T h e  primary d i s t i n c t i o n  of  t h e  Woods system is that the deep 
structure tree is built during the surface analysis. Conse- 
quently, his "transformati .ona1" procedures c o n s i s t  of t ree 
b u i l d i n g  ra ther  than tree t r a n s f o r m i n g  opera t ions .  The t r a d e o f f s  
between this approach and the two-stage a n a l y z e r s  of p e t r i c k  
and Sager are d i f f i c u l t  tg weigh at this t i m e .  They are p a r t  
of the more general  problem of pa ra l l e l  vs. serial processing; 
e.g.  should semantic a n a l y s i s  be done c o n c u r r e n t l y  with 
Syntactic ana lys i s .  P a r a l l e l  processing is preferred if t h e  
added time required by the deeper a n a l y s i s  i s  outweighed by t h e  
f r ac t i on  of i n c o r r e c t  analyses which can be e l imina ted  early i n  
the parsing erocess. In the case of s ?mantic analysis, it 
clearly depends on t h e  r e l a t ive  complexity of t h e  s y n t a c t i c  and 
semantic components. I n  t h e  case of transformational a n a l y s i s ,  
it depends on the f rac t ion  of grammatical and s e l e c t i ~ n a l  
c o n s t r a i n t s  which can be expressed at: t h e  surface l eve l  (if 
most of these can only be realized through t ransformational  
allalysis , concurrent trans formational ana ly s i s  i s  probably more 
e f f i c i e n t ) .  This may depend i n  Lurn on the type  of surface 
a n a l y s i s  ; for example, the r e l a t i o n s h i p s  exhibited by l i n g u i s t i c  
string analysis axe s u i t a b l e  for expressing many of these 
c o n s t r a i n t s ,  so there i s  less motivation in the Linguistic S t r i n g  
Project system f o r  concurrent trans f o r m a t i o n a l  decompos i t ion .  
2 . 4 .  Other S y n t a c t i c  Analysis Pxocedures 
The system developed by Winograd at M. I. T. [Winograd 19711 
for accept ing  E n g l i s h  commands and q u e s t i o n s  about a "block 
world" also uses a context-free grammar augmented by res t r ic-  
t i o n s .  Winograd's context-free grammar was encoded as a s e t  
of procedures i n s t e a d  of  a da ta  structure to be i n t e r p r e t e d ,  
b u t  t h i s  is n o t  a material d i f f e r e n c e .  H i s  grammar i s  based 
I1 on Hal l iday  ' s  sys t emic  grammar" to the extent that  it 
extracts  from a sentence the set of fea tu res  descr ibed by 
Ha l l i day ;  however, H a l l i d a y  ' s  grammar (at least i n  its present  
stage of' development) i s  e s s e n t i a l l y  d e s c r i p t i v e  rather than 
generative, so most of the detailed grammatical s t r u c t u r e  had 
to be supplied by Winograd. H i s  parser  does not cons t ruc t  a 
deep s t r u c t u r e ;  ra ther ,  it b u i l d s  semantic s t r u c t u r e s  d i r ec t l y  
d u r i n g  parsing. The primary d i s t i n c t i v e  f ea tu re  of h i s  s y s t e m  
i s  the i n t e g r a t i o n  of t h e  s y n t a c t i c  component w i t h  senant ics  
and pragmatics (the manipulation of objects in the block wor ld )  ; 
hi$ parser is t h u s  able to use n o t  on ly  s y n t a c t i c  c o n s t r a i n t s  
but a l s o  s e m a n t i c  and p r a g m a t i c  information in s e l e c t i n g  a 
proper sentence analysis. With regard .to t h e  se r i a l  vs. 
parallel d i s t i n c t i o n  d rawn in the p r e v i o u s  s e c t i o n ,  his s y s t e m  
w o u l d  be charac te r ized  as h i g h l y  p a t a l l e l .  
A number  o f  n a t u r a l  l anguage  s y s t e n ~ s  ?lave u s e d  granunars 
composed of finrestricted phrase-structure r e w r i t i n g  r u l c s .  
S i n c e  unrestricted r e w r i t i n g  r u l e s ,  l i k e  transformational 
grammars, can be u s e d  to d e f i n e  any recurs ive ly  enumerable 
l anguage ,  they may be s u f  f i c i c n t  f o r  ana lyz ing  bo th  sur face  and 
deep s t r u c t u r e .  As w i t h  t ransformat iona l .  grallunars, it will in 
prac t ice  be n e c e s s a r y  to inlpose s o m e  cons  t r a l n t  ( s u c h  as o r d e r i n g )  
on the r u l e s ,  so that the language d e f i n e d  is r e c u r s i v e ;  o ther-  
w i s e  a p a r s e r  will never be able to determine w h z t h e r  some 
s e n t e n c e s  are grammatical or n o t .  
One parser f o r  u n r e s t r i c t e d  rewriting rules was described 
by Kay [Kay 19671. This parse r  i n c l u d q d  a number of mechanisms 
for restricting t h e  a p p l i c a t i o n  of rules, such as r u l e  o r d e r i n g ,  
specifying p a r t  of the s t r u c t u r e  dominated by one elernentkof 
t h e  r u l e ,  or r e q u i r i h g  t h e  e q u a l i t y  of t he  s t r u c t u r e s  don~ ina t cd  
by t w o  elements. These mechanisms do not increase t h e  gcnera-  
tive power of the grammars, b u t  are des igned  to make granunars 
easier to w r i t e .  Kay described how his parser could be u s e d  
to e f f e c t  some gfeverse t r ans fo rma t ions .  
Kay's parser w a s  incorpora ted  i n t o  a s y s t e m  ca l led  REL 
(Rap id ly  E x t e n s i b l e  Langllage) developed by Thompson, Dos te r t ,  
et al at the California Institute of Technoloqy [Thompson 1 9 6 9 ,  
Dostert 19711 . K a y ' s  o r i g i n a l  p a r s o r  was auqmented b y  allowing 
a s e t  of b i n a r y  fea tures  to be associa ted  w i t h  each node, 
i n c l u d i n g  fea ture  t e s t s  as p a r k  of t h e  rewrite  r u l e s ,  and 
p e r m i t t i n g  more genera l  r e s t r i c t i o n s  w h e r e  t h e  f ea tu res  w e r e  
i nadequa t e .  The REL sys tem w a s  d e s i g n e z  to suppor t  a number 
of graimnars, each interfaced to its own data base. One of 
these is REL Engl i sh ,  which analyzes a subset of E n g l i s h  i n t o  a 
s e t  of sub ject-verb-ob ject-time modifier deep structures ; 
t h i s  grammarhas 239 rules. In suppor t  of the  use o f  general 
rewrite rules w i t h  features,  they note that on ly  29 of t he  
239 rules required c o n s t r a i n t s  which could  n o t  be conven ien t ly  
s ta ted  in terms of feature t e s t s .  T h i s  is a l so  a f ac to r  i n  
e f f i c iency ,  since b i n a r y  f ea tu re  t e s t s  can be performed very 
q u i c k l y .  
Another system which uses u n r e s t r i c f e d  rewriting r u l e s  w i t h  
op t i ona l  conditions on the elements is the "Q" system developed 
by Colmerauer [Colmerauer 19701. * h i s  s y s t e m  is p re sen t l y  be ing  
used in a machine t r a n s l a t i o n  prqject af the U n i v e r s i t v  of 
Montreal [Kittredge 19731. 
Colmerauer and de Chastellier [de Chas te l l ie r  196 9 ] have 
also investigated the possibility of using Wijngaarden grammars 
(as were developed f o r  s p e c i f y i n g  ALGOL 6 8 )  for  :tr.ansformational 
decomposition and machine t r a n s l a t i o n .  L i k e  u n r e s t r i c t e d  
r e w r i t i n g  rules,  W-grammars can d e f i n e  every r e c u r s i v e l y  enumer- 
able l a q u a g e ,  and so  can perform t h e  functions of t h e  syrface 
and reverse transformational components. They show how por t ions  
of transformational grammars of English and French may be 
rewritten as W-grammarsr w i t h  t h e  pseudo-rules in t h e  W-grammar 
t a k i n g  the place of the t ransfol 'mat ions~ 
2.5 Parsinq w i t h  Prop-abi l i ty  and Graded A c c e p t a b i l i t y  
In all t h e  systems dqscribed above, a sharp line was drawn 
between correct and incomect parses: a t emina l  node ei ther  
did or d i d  n o t  m a t c h  t h e  n e x t  word in the  sentence:  an analysis  
of a phrase was e i t h e r  acceptable or  unacceptable. There are 
circumstances under which we would want to re lax  these require- 
ments. For one thing, i n  analyzing connected speech, We 
segmentation and i d e n t i f i c a t i o n  of words can never be done with 
complete c e r t a i n t y .  A t  best ,  one can say that a ce r t a in  sound 
has some p r o b a b i l i t y  of being one phoneme and son= o t h e r  
probabiJ i  ty of being another  phoneme; some expected phonemes 
may be l o s t  e n t i r e l y  in the sound received. c o n s e q u e n t l y ,  
one w i l l  associate some n u f i e r  w i t h  each t e r m i n a l  node, i n d i -  
c a t i n g  t h e  p r o b a b i l i t y  or q u a l i t y  of match; noflcrminal  nodes 
will be as s igned  some va lue  based on t h e  va lues  of t he  t e r m i n a l  
nodes ) x n e a t h .  Another circuinstance arises in n a t u r a l  language 
s y s t e m s  w h i c h  a ro  s o p h i s t i c a t e d  m o u g h  to r e a l i z e  t h a t  s y n t a c t i c  
and semantic rcs t r i c t i o n s  are r a r e l y  a l l - o r - n o t h i n g  a f f a i r s ,  
and t h a t  some restrictions arc  s t ronger  than o t h e r s #  F u r  r s a n ~ p l a ,  
t h e  nominative-accusative distinction h a s  become q u i  tc !tqc,ak 
f o r  r e l a t ive  pronouns (?The man ~ 1 7 x 1  I met 1'ester;Flay. ) b u t  r e m a i n s  
s t r o n g  f o r  personal  p ronouns  (*The man whom, me ~nct y e s t e r d a y . ) .  
As a r e s u l t ,  a parser  w h i c h  wants to g e t  t h e  best a n a l y s i s  even 
if every a n a l y s i s  violates some c o n s t r a i n t  m u s t  a s s o c i a t e  a 
measure  of grammat ica l i ty  or a c c e p t a b i l i t y  w i t h  the ana lyse s  
of p o r t i o n s  of t h e  sentence ,  and ultimately w i t h  t h e  ana lyses  
o f  t h e  e n t i r e  sentence .  
In p r i n c i p l e ,  one could g e n e r a t e  every  s e n t e n c e  a n a l y s i s  w i t h  
a nonzero a c c e p t a b i l i t y  or probab i l i t y  of n ~ a t c h ,  and then  select 
the bes t  a n a l y s i s  ob ta ined .  IIobbs [ 1 9 7 4 ]  has descr ibed  a modi- 
f i c a t i o n  to the bottom-up n o d a l  s p a n s  p a r s i n g  a lgor i thm which 
uses t h i s  approach. WPlks [ 1 9 7 5 ]  uses an e s s e n t i a l l y  s i m i l a r  
technique  in his l L u g u a g e  a n a l y z e r  based on "preference 
semant ics  " 
A more e f f i c i e n t  approach, c a l l e d  "bes t - f i r s t "  parsing, 
h a s  been developed by Paxton  and Robinson of t h e  S t a n f o r d  Research 
I n s t i t u t e  as p a r t  of a speech u n d e r s t a n d i n g  s y s t e m   axto ton 19731. 
Their procedure  involves a modi f i c a t i o n  of t h e  s tandard top-down 
se r ia l  pa r s ing  a lgor i thm f o r  ccn tex t - f ree  grammars. The  
s tandaqd algorithm generates one p o s s i b l e  parse  t ree  u n t i l  it 
gets s t u c k  (generates a t e r m i n a l  node which does n o t  match the 
next s e n t e n c e  word) ; it t h en  "backs up" to t r y  another a l t e rna t ive .  
The best-first procedure instead tries all alternatives in 
IleL A measure is associated with each a l t e r n a t i v e  path, 
fadicating the l i k e l i h o o d  t ha t  this a n a l y s i s  matches the 
sentence p w s s e d  so far and t ha t  it can be extended to a 
let@ s@xtence analysis. At each moment, t h e  path with the 
higbsst likelihood is extended; if its measure f a l l s  below that 
otner path, the parser s h i f t s  its a t t e n t i o n  to t h a t  
2-6  ur~lon4uhction and Adjunction 
mere am$ certain pervasive n a t u r a l  language c ~ n s t r u c t i v n s  
rch ds not f i t  naturally i n t o  t h e  standard syntax ana lys i s  
dues,  such as augmented context-free parsers. Two o f  
se are coordinate conjunctions and adjuncts .  Special 
reastAres have Deen developed to h a n d l e  these cons t ruc t ions ;  
these measur&s deserve br ie f  mention here. 
allowed patterns o f  occwl-rence of con jo in ings  i n  a 
sentence are quite  regular .  Loosely speaking, a sequence  of 
e nts in the sentence tree may be followed by a con junct ion  
aad by same or all of the elements immediately preceding the 
jrmction. For example, allowed p a t t e r n s  of con joining 
subject-verb-ob ject-and-sub ject-verb-ob ject ( I  drank 
d w  and nary ate cake. ) , sub ject-verb-ob ject-and-verb-object 
a milk and ate cake. ) and sub ject-verb-ob ject-and-ob ject 
[I ikank dlk and se l tzer .  ) . There are c e r t a i n  excep t ions ,  known 
as ing phenomena, in which one of the elements fo l l owing  the 
amjlmction may be omitted; f o r  example, sub ject-verb-object-and- 
ject-object (I drank milk and Mary seltzer.) . 
trouble w i t h  coordinate conjunctions is  that they can 
t anywhere in t h e  s t r u c t u r e  of a sentence. Thus ,  
it would be possible tr, extend a context-free surface 
to allow for all*possible conjoinings ,  such an extension 
increase the s i z e  of the grammar by perhaps an o r d e r  of 
. The alternative scheme which has therefore been 
developed involves the automat'ic g e n e r a t i o n  of productions 
which allow f o r  c o n j u n c t i o n  as r e q u i r e d  d u r i n g  t h e  p a r s i n g  
process. When a conjunction i s  encountered i n  t h e  s e n t e n c e ,  
t h e  normal parsing procedure is i n t e r r u p t e d  and a spec i a l  
c o ~ l j u n c t i o n  node i s  inser ted  in t h e  parse tree. The a l t e r -  
n a t i v e  values of t h i s  node p rov ide  f o r  t h e  v a r i o u s  c o n j o i ~ ~ c d  
element 'sequences allowed at t h i s  p o i n t .  
An i n t e r r u p t  mechanism of t h i s  s o r t  i n c l u d i n g  provision for 
gapping, is p a r t  of t h e  L i n g u i s t i c  S t r i n g  P r o j e c t  p a r s e r  [Sager  
1 9 6 7 1 .  A similar mechanism i s  i n c l u d e d  i n  Woods ' augnlen t ed  
t r a n s i t i o n  ne twork  parser  [Woods 19731 and a number of o t h e r  
s y s  terns. 
T h i s  s o l v e s  t h e  problem of co r rec t ing  t h e  context-frcc 
granmar f o r  con junc t ions ,  but the c o n t e s t - f  rcc granw~lar is 
generally o n l y  a small part of the t o t a l  s y s t e m .  The t a s k  
r e m a i n s  of modifying the r o u t i n e s  which enforce  granxmatical 
c o n s t r a i n t s  and the transformations to account  f o r  con j u n c t i o n s .  
S i n c e  p r a c t i c a l l y  every r o u t i n e  which examines a parse  tree 
is someWow a f f ec t ed  by c o n j u n c t i o n ,  t h i s  can be a l a r g e  job, 
b u t  f o r t u n a t e l y  the changes are ve ry  r e g u l a r  for  most  r o u t i n e s .  
The L i n g u i s t i c  S t r i n g  P r o j e c t  grammar; by pe r fo rming  a & l  
opera t ions  on t h e  parse tree through a s ~ n a l l  nunbcr  of low- 
l e v e l  r o u t i n e s ,  was able to l o c a l i z e  t h e  changes to these 
routines and a srngll number of r e s t r i c t i o n s  ( s u c h  as nun&er  
agrcerneJt) which are specially af fectcd by con j u n c t i o n  [Raze 
1 9 7 4 1 .  
C e r t a i n  classes of a d j u n c t s  or modi f i e r s  g ive  rise to a 
d i f f e r e n t  kind of problem:  a h igh  degree of s y n t a c t i c  ambigui ty.  
For i n s t a n c e ,  i n  t h e  s e n t e n c e )  "I f ixed  the -p ipe  under the sink 
i n  the bathroom tzri th a wrench .  " there is no s y n t a c t i c  b a s i s  
fo r  d e c i d i n g  whe the r  t h e  pipe had a wrench t h e  s i n k  had a 
wrenoh, the  bathroom had a wrench, or the t i x i n g  was done with 
a wrench. If s e m a n t i c  and pragmatic r e s t r i c t i o n s  a re  invoked 
d u r i n g  t h e  s y n t a c t i c  analysis, t he  parser w i l l  have t o  generate 
s e v e r a l  analyses, a l l  but one of which will (hopefully) be 
r e j e c t e d  by the r e s t r i c t i o n s  ; t h i s  i s  moderately i n e f f i c i e n t .  
I f  s y n t a c t i c  analysis  precedes semant ic  p rocess ing  i t h e  
ambigu i t i e s  of t h e  various adjuncts wi 11 be m u l t i p l i e d  
producing dozens of analyses f o r  a sen tence  of moderate s i z e  ; 
this is h o p e l e s s l y  i n e f f i c i e n t -  
A m o r e  e f f i c i e n t  s o l u t i o n  has t h e  parser i d e n t i f y  t h e  
a d j u n c t s  and l i s t  for  each adjunct t h e  words it could be 
modifying, w i t h o u t  gene ra t ing  a complee  separate arp-alysis 
f o r  each p o s s i b i l f t y .  The ambigu i t i e s  a s s o c i a t e d  with the 
a d j u n c t s  are thus f a c t o r e d  out. The semantic and pragmatic 
components may t h e n  choose f o r  each a d j u n c t  i t s  most l i k e l y  
o r  a c c e p t a b l e  host (modif ied word). T h i s  may be done either 
during t h e  s y n t a c t i c  a n a l y s i s  [woods 1 9 7 3 ,  Simmons 1 9 7 5 1  or  
after the syntax phase is complete [ ~ o r g i d a  1975 ,  Hobbs 19751. 
3.  ALGORITHM SPECIFICATIOtJS  
W e  present below p r e c i s e  specifications for some o f  the 
parsing a lgor i thms which have been d i scussed .  These algor i thms 
are presented in SETL, a programming language which is based on 
concepts Prom s e t  theory and has  been developed at N e w  York 
Univer s i ty  by a group l e d  by Jack Schwartz .  The large v a r i e t y  
of data types, operators ,  and control s t r u c t u r e s  in SETL makes 
it poss ib l e  to s p e c i f y  t h e  a lgor i thms  in a r e l a t i v e l y  compact 
and n a t u r a l  f a sh ion .  An imp lemen ta t i on  i s  ava i l ab le  which 
i n c l u d e s  most of the fcaturcs of t h e  s p e c i f i c a t i o n  l anguage ,  
so that algor i thms can be t e s t e d  in essentially t h e  form i n  
which they are pub l i shed .  A d e s c r i p t i o n  of t h e  subset of SETL 
w h i c i ~  h a s  been used in this report is g i v e n  i n  the appendix.  
3 . 1  Parsing A l q o r i t h m s  f o r  Contex t -Free  G r a m m a r s  _ .  
C o n t e x t - f r e e  grammars p layed  a major role i the e a r l y  s tages  
of automatic n a t u r a l  language a n a l y s i s .  A1 though they  have now 
gene ra l l y  been superceded by more con~plex  and powerful grammars, 
many of these grammars are based o n  or have as one of t h e i r  
components a context-f  ree grammar. The se lec t ion  of an e f f i c i e n t  
con tex t - f ree  parser  theref ore remains  an i ~ n p o r t a n t  considerat ion 
i n  n a t u r a l  Language analysis. 
Jecause so many d i f f e r e n t  c o n t e x t - f r e e  parsers have been 
proposed, a comprehensive su rvey  would be imprac t i  cable. We s i ~ a l l  
rather p r e s e n t  a taxonomy acco rd ing  t.u which m o s t  con tex t - f ree  
parsers can be c l a s s i f i e d ,  and i l l u s t r a t e  t h i s  classification 
w i t h  f i v e  of the possible bas ic  z l g o r i t h m s .  At the end we s h a l l  
mention which 6f these a r e  b e i n q  used i n  current n a t u r a l  language 
systems . 
T ? L ~  first division we s h a l l  make is according to the amount 
of memory space requLred by the parser.  Type 0 parsers s tore 
o n l y  t h e  parse tree c u r r e n t l y  being b u i l t .  T h e  o the r  parsers  
g r a b a l l y  accumulate d a t a  from which a l l  parses of a sentence 
can be e x t r a c t e d ;  types 1, 2 and 3 s t o r e  t h i s  data i n  decreas- 
ingly compact r e p r e s e n t a t i o n s .  The  four t y p e s  are : 
(0) Develops a s i n g l e  parse tree a t  a t i m e ;  a t  any i n s t a n t  t h e  
store holds a set o f  nodes co r r e spond ing  t o  the nodes  of an 
incomplete potential parse tree 
ft) The s t o r e  holds a set  of nodes ,  each of which represents the 
fact t h a t  some substring of t h e  s e n t e n c e ,  from word f to word 
R, can be a n a l y z ~ d  as some symbol N. 
( 2 )  T h e  s tore holds a s e t  of nodes, each of which represen t s  an 
analysis of some substring of the  s e n t e n c e ,  from word f to 
word a ,  as some symbol N ( i f  there are several different 
analyses of words f t o  11 as some symbol N ,  there w i l l  be several 
nodes corresponding t o  a single node i n  a type  1 parse r ) .  
( 3 )  The s to r e  holds a s e t  of nodes,  each of which corresponds  t o  
an a n a l y s i s  of? some s u b s t r i n g  of  t h e  sentence; f r o m  word f t o  
word a ,  as some symbol N appearing as part of some incomplete  
p o t e n t i a l  parse tree ( i f  symbol N ,  spanning w o r d s  f t o  !L, 
appears i n  several of t h e  incomplete p o t e n t i a l  parse trees, 
t he re  w i l l  be s e v e r a l  nodes corresponding t o  each node in a 
type 2 parser) . 
Type (0) p a r s e r s  require only an qmount of s t o r a g e  p r o p o r t i o n a l  
t o  t h e  length of the i n p u t  sentence .  T h e  storage requirements  of 
type (1) p a r s e r s  grow as the cube of t h e  length, w h i l e  t h e  r equ i r e -  
ments for types ( 2 )  and ( 3 )  grow exponen t i a l ly .  
A second d i v i s i o n  can be made between top-down and bottom-up 
parsers. A t h i r d  criterion for classification i s  whether 
a l t e r n a t i v e  parses of a s e n t e n c e  are all produced together  
( p a r a l l e l  parser) or are generated s e q u e n t i a l l y  ( s e r i a l  parser) ; 
this d iv i s ion  doe$ n o t  a p p l y  t o  type  ( 0 )  parsers. 
F ine r  divisions can be made of some of t he se  categories. 
For example, among bottom-up parsers w e  can d i s t i n g u i s h  those  
which perform a reduction only when all r e q u i r e d  elements have 
been found from those which make a tentative reduction when the 
first element of a p roduc t i on  is found (so-called " left-corner 
parsers"). Paral lel  parsers can be c l a s s i f i e d  according to the 
orderin(- s t ra tegy they use in b u i l d i n g  nodes:  by l e f tmos t  or 
rightmast word subsumed i . e , spanned)  by the node or by level l .  
In a d d i t i o n ,  w e  s h a l l  not consider a number of o p t i m i z a t i o n  
s t ra tegies ,  such as s e l e c t i v i t y  matrices and shape r  and general-  
i z e d  shaper  t e s t s  for top-down parsers. 
We s h a l l  naw describe a lgor i thms  i n  f i ve  of the ca teyor ics :  
A Type 0 Top-down s e r i a l  
B Type 2 Bottom-up parallel 
C Type 1 Bottom-up parallel 
D ~ y ~ e '  2 Top-down seri  a1 
E Type 1 Top-down s e r i a l  
We have not i n c l u d e d  any t y p e  3 parsers  b c c a u s c ,  despite their 
profligate use nE storage, they do not operate inuch E a s t e r  t h a n  
t y p e  0 parsers. The o n l y  repor ted  use of s u c h  a parser of 
w h i c h  we are  a w a r e  is t h e  " E r r o r - C o r r e c t i n g  Parse A l g o r i t h m "  of 
I r o n s  (Cornm. ACM - 6, 669 (1963) ) . A top-down l e f t - t o - r i g h t  
p a r a l l e l  s t r a t egy  was employed so t h a t  the parser  could  make a 
suitable modification to the sentence w h e n  it " g o t  stuck1' because 
of an error  in the i n p u t .  
STSITL ~ r o c e d u r e s  are given for these five par se r s .  The i n p u t  
d a t a  s t r u c t u r e s  are the s a m e  in all cases: The sentence, passed 
through parameter SENTENCE, is a t u p l e .  The e l e m e n t s  0 the 
t u p l e ,  t h e  words of :he sen tence ,  are to be matched by terminal 
symbols from the grammar. The con tex t - f  ree grammar, passed 
through pa rame te r  GRAMMAR, is  a set each of w h o s e  e l e m e n t s  
corresponds to a p r o d u c t i o n *  The p r o d u c t i o n  
a -+ al a2 ... 0 a r? 
is t ransformed into t h e  [ntl) - t u p l e  
<ao, alra2, .. ,a, > 
The root symbol sf the grammar is passed to t h e  parser  in 
parameter ROOT. 
A l g o r i t h m  A, Type 0 T-op-down S e r i a l  
This procedure bui lds  the  parse trees for the i n p u t  s e n t e n c e  
s e q u e n t i a l l y  i n  a two-dimen~iona$ a r r a p  TREE. The first 
subscript of TREE specif ies  t he  number of the node, t h e  second 
selects t component of the node as fo l lows:  
TREE(n, 'NAME1) name o f  node n 
TREE ( n  , ' PARENT ' ) number of B a r e n t  node of node n 
(= 0 far  root node) 
T E E  ( n , ' DAUGHTERS ' ) tuple o f  numbers of daugh t e r  nodes 
of node n 
TREE ( n  , ' CURRENT OPTIOY ) t u p l e  of c u r r e n t  product ion used 
t o  expand this node 
TREE ( n ,  'ALTEEJATIVE O P T I O N S ~ ' )  s e t  of t u p l e s  r ep resen t ing  
p r o d u c t i o n s  not yet! tried for  
this node 
TRlEE ( n ,  'FW1) 
TREE (n, ' L W + ~ ' )  
number of  first sen t ence  word 
subsumed by node n 
(number of l a s t  s ~ l t e n c e  word subsumed 
by node n )  + 1 
As each ana ly s i s  of the sentence is completed, it i s  added 
t o  the s k t  PARSES. When p a r s i n g  is f i n i s h e d ,  this ~t of trees 
is r e t u r n e d  as the value of  the f u n c t i o n  PARSE. 
The v a r i a b l e  NODES holds a coun t  of the number of npdes i n  t h e  
pa r se  t ree;  this is also t h e  number af the  node most r q c e n t l y  added 
to t he  tree. WORD holds the number of the n e x t  word in fie sen tence  
to be matched. 
The heart of the parser is the recursive p r o c e d ~ r e  EXPAND. E X P L t D  
i s  passed one argument,  the number of a node i n  t h e  parse tree. I Y  
EXPAND has n o t  been called for this node before, it  w i l l  try t o  
expand the node, fbe. , build a parse  t ree  below the 
node which matches p a r t  of t he  remainder  of the sentence.  
If EXPAND h a s  a l ready been ca l l ed  once for this node -- so t h a t  
a tree a l r eady  e x i s t s  below this node -- EXPAND tries to f i n d  an 
a l t e rna te  tree below t h e  node which  w i l l  match u p  with p a r t  of 
the remainder of the s e n t e n c e .  
If EXPAND i s  successful -- an (al ternate)  tree below the node 
was found -- it r e t u r n s  the value true; i f  it is u n s u e e e s s f u l ,  
it returns fa l se .  In the case where  t h e  node cor responds  do 
a terminal s y ~ n b o l ,  EXPAND w i l l  r e t u r n  t r u e  on t h e  first c a l l  
o n l y  i f  the synbol  matches the next word in the  sen tence ;  i t  
w i l l  always r e t u r n  f a l se  on t h e  second c a l l .  
def inef  PARSE (6'11~filhlAR~ ROOT, SENTENCE) ; 
loca l  PARSES, TREE, NODES,  WORD ; 
TREE = nR; 
PARSES = n z ;  
WORD = 1; 
'LIJODES = 1; 
/* s e t  up root node (node 1) */ 
 TREE(^, ' N A M E ' )  = ROOT; 
T R E E ( 1 ,  'FW') = WORD; 
/* loop u n t i l  a11 parse trees have been formed .*/ 
(while EXPAND (1 ) ) 
,/* if tree s p a n s  e n t i r e  s e n t e n c e ,  add to set */ 
if WORD eq ( ( K m ? T E N C E )  +1J t h e n  
PARSES = PARSES U {'I'REE); 
end i f  WORD; 
end while EXPAND; 
re turn PARSES ; 
end PARSE; 
d e f i n e f  EXPAND(X) ; 
loca l  I, OPT; 
if GRAMMARITREE(X~~NAME~H eq nR t hen  
/* t e rmina l  symbol */ 
if TREE (X, 'ALTERNATE OPTIONS ' ) eq 0 then 
/* first call -- test for match with sentence */ 
TREE ( X ,  'ALTERNATE OPTIONS ' ) = nR; 
if WORD le #SENTENCE then 
if SENTENCE(W0RD) eq TREE(x, ' N A M E ' )  t h e n  
WORD = WORD + 1; 
TREE(X,  'LW+lf) = WORD; 
r e t u r n  t r u e  ; 
end if SENTENCE; 
end if WORD; 
else /* second c a l l  */ 
WORD = WORD-1; 
end if TREE; 
return false; 
end if GRAMMAR; 
/* nonterrninal symbol */ 
if TREE (x, 'ALTEFWATE OPTIONS ' ) eq S l  then 
/* f i rs t  c a l l ,  retrieve opt ions  from grammar */ 
TREE (XI 'ALTERNATE OPTIONS ' ) = GRAMMAR{TREE (x, 'NAME ' ) ; 
TIREB(X, 'DAUGHTERS') = nult; 
OPT = 5 2 ;  
else /* second or subsequent call */ 
OPT = TREE(XI 'CURRENT OPTION'); 
I = #OPT; 
end if TREE; 
/* select  next o p t i o n  to t r y  */ 
GE3'OPT: if OPT eq 0 th\en 
OPT from TEIEE(X, 'ALTERNATE OPTIONS1) ; 
TREE (x, 'CURRENT OPTION' ) -- OPT; 
I = 1; 
end  if OPT; 
/ *  ekpand node */ 
kvhile  I ge 1) 
/* work on l t h  e l e m e n t  of c u r r e n t  op t ion  */ 
/* if corresponding node not in parse tree, add i t  * /  
i\f TREE (XI 'DAUGIITERS ' ) (I) eq Q t h e n  
NODES A NODES + 1: 
TREE (NODES, 'NAME ) =, OPT (I) ; 
TREE= ( N O D E S ,  ' FW ' ) = WORD ; 
TREE ( N O D E S ,  'PARENT ' ) = X; 
TREE (XI ' DAUGHTERS ' ) ( I )  = N O D E S  ; 
end  if TFCEE; 
/* kry for an(o the r )  expans ion  of this node */ 
b 
if EXPAND (TREE ( X ,  ' DAUGIlTERS ' ) (I) ) then 
/* expans ion  found.. . if t h i s  is l a s t  e l e m e n t ,  r e t u r n  
s u c c e s s f u l l y ,  e lse advance to n e x t  element * /  
if I eq #OPT t h en  
TREE (X, ' LW-1'  ) = \J@RD; 
r e t u r n  true; 
else 
I = I + l ;  
end  if I; 
else  
/* n o  expansion found . . . erase t h i s  node and examine 
previous erernent */  
TREE (NODES) = n; 
NODES = NODES-1;  
TREE ( x ~  'DAUGHTERS ' ) (I) = R ;  
I = 1-1; 
end if EXPAND; 
e n d  w h i l e  I; 
/* a l l  expansions f o r  this option have been generated; 
i f  more opt ions ,  loop, else return falsa, */ 
OPT = Q ;  
if TREE ( X ,  'ALTERNATE OPTIONS ' ) ne nR then go to GETOPT; ; 
re turn  fa lse  ; 
end EXPAND; 
One way of viewing t h i s  procedure i s  t o  consider  each node 
as a s e p a r a t e  p rocess .  Each process c r e a t e s  and invokes the 
processes corresponding t o  i t s  daughter nodes.  I n  SETL, 
the algorithm cannot be represented directly i n  this way, s ince  
there are no  meckgmisms f o r  creat ing and suspending processes. 
I n s t ead ,  the data which would correspond t o  the local vaxiab1.e~ 
of the process are  s t o r e d  as components of each node i n  the 
parse tree. I n  languages which provide for the suspension of 
processes,  such as SIMULA, the algorithm can be represented even 
more succ inc t ly  (see, for example, a vers ion  of t h i s  algori thm 
i n  "Hierarchica l  Program St ruc tu re s "  by 0.-J, Dahl and 
C. A .  R. Hoare, in Struc tured  P r o g r m i n q  by 0.-J. Dahl e t  a l . ,  
page 201). 
A l g o r i t h m  B -  Type 2 Bottom-up Para l l e l  
This algorithm i s  sometimes called t h e  "Immediate Co~stituent 
A n a l y s i s "  (IcA) alqorithm, because it was used q u i t e  early i n  
parsing n a t u r a l  langqage with ICA grammars, 1%- c o n s t r u c t s  a l l  
nodes in a single l e f t - t o - r i g h t  pass  over the sentence.  A s  each 
word i s  scanned, the pa r se r  builds a l l  nodes w h i c h  subsume a 
por t ion  of t h e  sen tence  ending a t  that word. The nodes ( "spans"  ) 
are accumualted i n  a two-dimensional a r r ay  S P A N ,  whose f i r s t  
subscript s p e c i f i e s  the number of the span and whose second 
subscript selects a component of the span, as  follows: 
SPAN (n, 'NAME ' ) = name of span  n 
SPAN (n, 'FW' ) = number of f i r s t  sentence word subsumed by span n 
SPAN (n, 'LW+ll) = (number of last sentence word subsumed 
by span n) + 1 
SPAN (n,  'D'AUGHTERS') = t u p l e  of numbers of daughter  spans 
of  span n. 
A t  t h e  end of the r o u t i n e  is some code to c o n v e r t  SPAN,  
a graph s t r u c t u r e  w i t h  each span p o t e n t i a l l y  a par t  of many 
parses,  i n t o  a s e t  of parse trees. T h i s  code has  two p a r t s :  
a loop to f i n d  all root  odes created in the immediate 
constituent analysis, and a recursive r o u t i n e  EXPAND which makes 
copies of a l l  descendants  of the roo t  node a n d  p u t s  t h e m  in TREE. 
Each node in t h e  tree has t he  f o l l o w i n g  comr,onents: 
T R E E ( n ,  'NAME' )  = n a m e  of node n 
T R E E ( n ,  ' F W ' )  = number of f i r s t  s e n t e n c e  w o r d  suksumed 
by node n 
T R E E ( n ,  'LW+ll) = (nunher  of last sentence w o r d  subsumed 
by node n )  + 1 
TREE (n, ' D A U G H T E R S ' )  = t u p l e  of numbers of daughter  nodes 
of node n 
TREE (11, ' P A R E N T ' ) =  number of p a r e n t  node of node n.  
The s e t  of parse trees is accun\ulated i.n PARSES and f i n a l l y  
r e t u rned  as t h e  v a l u e  of the f u n c t i o n  PARSE.  
de f ine f  PARSE(GRAMMAR,ROOT,SENTENCE) ; 
local  TODO, WORR, CURRENT, DEF, DEFNAME, DEFELIST, REM,  SPAN, , 
SPANS! TREE, NODES, PARSES, MS, I; 
/* initialization */  
SPAN = n1; 
SPANS = 0; 
TODO = n l ;  
/* i t e r a t e  over WORD=last word subsumed 
by spans being constructed */ 
(1 <= VWORD <= #SENTENCE) 
/* add span whose name is sen tence  word */ 
ADDSPAN (SENTENCE (WORD) , WORD, WORD+l,  n u l t )  ; 
/* TODO contains t h e  numbers of spans which were 
j u s t  created and for which ye have n o t  y e t  
checked whether they can be used as the last 
daughter span in building some more spans  */ 
( w h i l e  TODO ne  nl) 
/* select a span from TODO */ 
CURRENT from TODO; 
/* loop over a l l  product ions  whose last element 
= name of c u r r e n t  span */ 
( V D E F  E GRAMMAR(DEF(#DEF) eq SPAN(CURRENT, ' N A M E ' ) )  
/* separate left and r i g h t  sides of produc t ion  */ 
DEETIAME = hd DEF; 
DEFELIST = tl DEF; 
/* if e l e m e n t s  preceding last element  of produc t ion  
can be matched by spans, add a new span whose 
name = left-hand s i d e  of prodncision f o r  each match*/ 
( ~ R E M  E MATCH (DEFELIST (1: (#DEFELIST)  -1) , 
a 
SPAN ( C U R m N T ,  'FW') ) ) 
ADDSPAN (DEFNAME, hd R E M ,  SPAN (CUIXWNT, 'LW+l') , 
(tl REM) -t <CURRENT>) ; 
end VREM; end VDEF; 
end while TODO; 
end 1 \= VWORD; 
/* eXtract trees f r o m  s e t  of spans */ 
PARSES = nl; 
(1 <= \tI <= SPANS I (SP.W(I;'NAMG') aq ROOT) and 
(SPAN (1, ' FW' ) eq 1) and 
(SPAN(I,'LW+lt) eq  SE SENTENCE)+^))) 
NODES = 1; 
TREE = nl; 
T R E E C ~ )  = SPANII I ;  
TREE: (1, 'DAUGHTERS ' ) = E X P A N D  (TREE (I, ' DAUGEITERS ' ) , 1) ; 
end  3, <= VI; 
r e t u r n  PARSES ; 
cnd  PARSE; 
d e f i n e  rVLATCII (ELTST,  E N D W D P I )  ; 
l o c a l  I, N T U P ;  
* MATCH f i n d s  all n - t u p l e s  of spans  whose names 
match the e l e n ~ e n t s  of t he  n-tuple E L I S T  m d  .cqhich 
span a p o r t i o n  of the s e n t e n c e  whose l a s t  word +l 
= ENDFVDPI;  r e t u r n s  a s e t ,  each e l e m e n t  of which 
is an ( n t l )  - t u p l e ,  whose t a i l  is one of the n - t u p l e -  
of s p a n s  and whose head i s  the r l unhe r  of t h e  first 
word spanned by the n - t u p l e  of s p a n s  * /  
if E L I S T  cq n u 9 t  
then r e t u r n  ((ENDwDP~~~); 
else r e t u r n  [U: 1 <= 1 <= NODESJ 
(if ( S P A N  (I, ' N A M E  ' ) eq ELXST ( # E L I S T )  ) 
and (SPAN (I, 'LFJ+ll ) eq E N D W D P 1 )  
then C N T U P  + <I>, NTUP E 
bylTCH (ELIST  (1: ( $ E L I S T )  ,SPAN (1, 'FlY' ) ) 1 
else  nl) ; ; 
end MATCH ; 
&fix%@ ADDSPAN (NAME, FW r LWP1, DAUGHTERS ) 
I* ADDSPAN bui lds  a span whose components 
are passed in t h e  four  parameters */ 
mms = SPANS+l; 
% P m [ S P . S r g N A M E ' )  = NAME:; 
S~hWiiI(SPANL:,'E'W') = FW; 
SP~(SPANS,'LW+~') = LWP1; 
S3Pm [SPANS, ' DAUGHTERS ' ) = DAUGHTERS ; 
S m S  h TOM); 
*~bef  EZ~PAND (DAW, PAR) ; 
/* creates a node f o r  each span in DAW and each 
descendant thereof, and r e t u r n s  a t u p l e  w i t h  
the numbers of t he  nodes ( i n  TREE) corresponding 
to the spans in DAW */ 
Dr N i  
eq Q then return 52;  ; 
n = zBtplt; 
1 
S = NODES +; 1; 
S = BODES; 
e i ~ 3  = S P A N C S ) ;  
E(Nr*PARENT1) = PAR; 
(N,'DAqGHTERS') = EXPAND(TREE(N, 'DAUGHTERS' )  ,N) ; 
p = D + <N>; 
end YS; 
A l g o r i t h m  C Type 1 Bottom-up Parallel 
A l g o r i t h m  C i s  t he  b a s i c  "nodal  spansr' parsing algorithm 
[Cocke 19701. The s e q u e n c i n g  logic  i s  identical to t h a t  for 
Algorithm 3. The ~ n l y  difference in the t ree  representation 
i a  that a l l  spans i n  Algorithm B w i t h  conunon values in the NIIME, 
FW, and LW+1 components are jo ined  into a s i n g l e  span in 
A l g o r i t h m  C. The DAUGHTERS component now becomes a set, each of 
 hose elements correspands to the value of the  DAUGHTERS 
compbnent o f  one of the s p a n s  in A l g o r i t h m  B ( t h i s  set i s  
called t h e  " d i v i s i o n  list" .in t h e  noda l  spans  a l g o r i t h m ) :  
s p ~ ~ ( n ,  'DAUGHTERS ' )  = a set each of whose elements is a t u p l e  
of numbers of d a u g h t e r  nodes of span n 
In orde r  to effec t  t h i s  change in t h e  trce, it is necessary only 
to modify the procedure A D D S P N ~  to check whether a span w i t h  the 
spec i f i ed  va lue  of NAME, FW, and LW+1 aIlr?i?aay e x i s t s :  
d e f i n e  ADDSPAiJ (NFr).IE, FW, LWP1, DAUGHTERS) ; 
local S; 
if 1 <= 3s  <= SPANS'  I (SPA;J(S,'NtUIET) eq N U E )  and 
(SPNI ( S  , ' F W '  ) eq FIJ) and 
S P  , L )  ec, LWP1) 
t h e n  DAUGHTERS in SPALJ (S ,  'DAUGHTERS' )  ; 
else SP=\JS = S P R N S S l ;  
S P A N ( S P m ~ , ' N M ~ ' )  = NAME; 
,SPAN (SPANS, ' FW' ) = FW; 
SPAN(SBANS,~LW+S.~) = L W P ~ ;  
SPAN (SPANS, DAUGHTERS 1 = {DAUGHTERS 1 ; 
SPANS in TODO; 
end if; 
re turn ; 
end ADDNODE; 
The procedure fo r  converting the spans i n t o  a s e t  of trees i s  
now more complicated than fo r  ~ l g o r i t h m  B ;  see, f o r  example, 
Wens 1:1975], Sec. 7.  
Algorithm D. Type 2 Top-down Serial  
We now seek t o  combine t h e  advan tages  of a l g o r i t h m  A w i t h  
those of algori thms B and C. A l g o r i t h m s  B and C would construct 
any given tree over a portion of the sentence o n l y  once, whereas 
algorithm A might c o n s t r u c t  some trees many t i m e s  during t h e  course 
of a parse. On the ~ t h e r  hand, B and C would construct many trees 
which A would never try to bu i ld .  More p r e c i s l ~ l y ,  B and C would 
build trees while processing word n+l which c o u l d  not enter into 
any parse fo r  any sen t ence  whose f irst  n words were those processed 
s o  far .  
To combine t h e s e  algorithms, we shall r e t u r n  t o  the basic 
framewdrk provided by algorithm A. To t h i s  we add a mechanism 
fo r  recording "well formed subs t r ings . "  The f i r s t  t i m e  the parser  
t r i es  to analyze a por t ion  of the s e n t e n c e  b e g i n n i n g  a t  word f as 
an instance of symbol N, this mechanism records any and all trees 
constructed below node N. The nex t  time t h e  p a r s e r  tries symbol N 
at word f, the saving m e c h a n i s m  retrieves this informat ion so 
mat t h e  trees below N need not actually be r e b u i l t .  
The previously-completed trees are stored in the two-dimensional 
array WFS, whose s t r u c t u r e  i s  identical to that of SFAN in 
algorithm- Bc 
WFS (n ,  'NAME' ) = name of well-formed s u b s t r i r i g  n 
WFS (n, 'FW') = first word of well-formed substring n 
WFS (n,'LW+lr ) = ( l a s t  word of well-formed s u b s t r i n g  n) + 1 
WFS (n, 'DAUGHTERS ' ) = tuple of numbers of daughter substrings 
of substring n 
WFSS sholds  t h e  numbei- of s u b s t r i n g s  i n  WFS. When t h e  parsing 
ope ra t i on  i s  comple te ,  WFS w i l l  c o n t a i n  a subset of the e lemen t s  
which were in TREE at the end of algorithm B. 
The tree used by t h e  top-down parser must be augmented to allow 
f o r  t h e  p o s s i b i l i t y  that khe parser is n o t  b u i l d i n g  a trce below 
a g iven  node b u t  r a t h e r  c o n s u l t i n g  the t a b l e  of well-formed 
substrings for that node. In t h a t  case the node w i l l  have, ins tcad  
of a tuple of d a u g h t e r s  and  a se t  of alternative o p t i o n s ,  t h e  
nun.lber of the well-formed s u b s t r i n g  currently being used i n  t h e  
taree and the se t  of alternative weil-formed substrings. The 
s t r u c t u r e  of a node is t h u s :  
TRl?Lr ; - (n , 'NrW1)  = name of node n 
TREE (n, ' PARENT' )  = number of p s r c n t  node of  node n 
(=  0 f o r  roo t  node)  
TREE ( n ,  'UAUGHTERS ' )  = t u p l e  of n u n h e r s  of d a u g h t e r  nodes of node n 
(= n u l t  i f  node i s  r,latched by well-formed s u b s t r i n g )  
TREE ( n ,  'WFS1) =*number  of well-formed substring matched t o  node n  
(= Q i f  n o t  matched to a s u b s t r i n g )  
TREE ( n ,  'CURRENT 0PTIC3iJ1 ) = t u p l e  of current produc t ion  used t o  
expand node n  
(= SZ i f  node i s  matched by a well-formed s u b s t r i n g )  
TREE ( n ,  'ALTERNATE 0PTI:ONS ' ) = 
set of t d p l c s  r c p r c s e n t i n g  product ions  not 
y e t  tried f o r  node n 
TREE ( n ,  'ALTERNATE WFS ' ) = 
set of numbers of well-form6d substrings not 
yet tried for node n 
'TREE (n,'FW1) = number of f i rs t  word s u b s u m ~ d  by node n 
TREE ( n ,  ' L W + l t )  = (number of l a s t  word subsumed by node n )  + 1 
F i n a l l y ,  w e  require a table which i n d i c a t e s ,  for e a c h  symbol N 
and s e n t e n c e  word f, whether a11 t h e  well-formed s u b s t r i n g s  f o r  N 
s t a r t i n g  a t  f have been recorded in WFS. For this t h e  parser uses 
the two-dimensional  array EXPANDED: E X P A N D E D ( N , f )  = t rue  if a l l  
substrings have been r e c o r d e d ,  Gi i f  not. 
The t e x t  of procedure D is given below; comments arE included 
only for t h o s e  statements added to procedure  A .  
def i n e f  PARSE (GRAMMAR, ROOT, SENTENCE) ; 
local  PARSES , TREE, NDDEG , WORD, WFS , WFSS ,. EXPANDED $ 
TREE = nR; 
PARSES = nR ; 
WFS = r lk ;  
WFSS = 0; 
EXPANDED = nR; 
WORD = 1; 
NODES = I; 
TR'TE (1, ' N W  ' ) = ROOT ; 
TREE(1,'EW1) = WORD; 
( w h i l e  EXPAND (1) )
if WORD eq (#SENT+ENCE + 1) THEN 
PARSES = PARSES U {TREE 1 ; 
end i f  WORD; 
end w h i l e ;  
r e t u r n  <PARSES ,WFS> ; 
end PARSE; 
def inef  EXPAND(X) ; 
local  I, S ,  LAST, OPT; 
i f  EXPANDED (TREE (X, 'NAME ' ) , TREE (X, ' FW' ) ) eq true t h e n  
/* the expansions fo r  this symbol have been computed before */ 
/* if t h i s  is a new node, get its WFS ent r ies  */  
if TREE ( x ,  'ALTERNATE WFS ' ) eq Q then 
TREE(X,'ALTERNATE WFS') = IS, 1 - < S - < WFSS I 
(WFS (S , 'NAME ) eq TREE a, 'NAME ' ) ) and 
(WFS(S,'FWi) eq TREE(X, 'FWr))) 
end if TREE; 
if TREE (x, 'ALTERNATE WFS ' ) eq na then 
/* all WFSs t r i e d  for t h i s  node */ 
worn = TREE(X,'FW') ; 
r s t u r n  false; 
e l se  

GETOPT: if OPT eq R t h e n  
OPT from TREE (-XI 'ALTERNATE OPTIONS ' ) ; 
TREE: ( X I  'CURRELJT OPTION I ) =  OPT; 
I = 1; 
end if OPT; 
(whi le  I ge 1) 
if TREE(x,'DAUGHTERS') (I) eq Q t h e n  
NODES = NODES + 1; 
TREE (NODES, ' N A M E ' )  = OPT(1) ; 
TREE (NODES, ' FW ' ) = WORD ; 
TREE (NODES, ' PARENT ' ) = X; 
TREE(x,'DAUGI~TERS') (I) = NODES; 
end if TREE; 
if EXPAND (TREE (X, DAUGHTERS ) (I) ) then 
if I eq #OPT then 
TREE (X, ' L W + l l  ) -= WORD; 
/* record s u b s t r i n g  matched by node X * /  
ADDWFS (TREE {X ]. ) ; 
TREE(X,'WFSI) = WFSS; 
return t r u e  ; 
se 
I = I+1 
end if I; 
else TRSE (JODES) = a ;  
NODES = NODES-1; 
TREE (X, ' DAUGHTERS ' ) (I) = 5 2 ;  
I = 1-1; 
end i f  EXPAND; 
end w h i l e  I; 
OPT = Q; 
if TREE ( X ,  'ALTERHATE OPTIONS ' ) ne nR then go t o  GETOPT; ; 
/* all expansions t r ied */ 
EXPANDED (TREE (X, 'NAME ' 1 ,WORD) = true ; 
r e t u r n  fa l se ;  
end EXPAND; 
d e f i n e  ADDTUFS (NODEX) 
/* add an e n t r y  to WFS */ 
local I; 
WFSS = WFSS+l; 
WFS (WFSS, 'NAME' )  = NODEX('NAME') ; 
WFS(WFSS,~FW~) = N O D E X ( ~ F N ~ ) ;  
WFS (IVPSS , L W + ~  ) = NODEX ( LW+L ) 
i f  NODEX('DAUGHTERS1) ne Q then 
WFS(NFSS,'DAUGHTERS') = [+: I E NODEX('DAUGHTERS1) ] 
<TREE (I, T ~ ~ ~ f  1 > ;  
e n d  if NODEX; 
r e t u r n  ; 
end AQDWFS; 
Note that t h i s  parser r e t u r n s  an ordered p a i r  c o n s i s t i n g  of 
the s e t  of trees and the s e t  of well-formed s S s t r i n g s ,  
since t h e  trees alone do not c o n t a i n  complete information 
about  the s e n t e n c e  analys is .  
A l g o r i t h m  E Type 1 Top-Down S e r i a l  
T o  complete our  s e t  of a lgo r i t hms ,  we sha l l  apply to 
Algorithm D the same change we made to c o n v e r t  Algor i thm B 
to Algorithm C .  T h a t  is, where i n  A l g o r i t h m  D we may have 
had Sevc~ .~ . ;  , ~ e 1 1  formed s u b s t r i n g s  w i t h  t h e  same values of 
X A P ? ,  l?W, LIJ4-1, we s h a l l  combine these into a single s u b s t r i n g  
ir ,  Algori thm E: The component DAUGHTERS 'becomes a s e t ,  each 
o: whose elements  is a t u p l e  corresponding to the value of 
DAUGHTERS of one of ti,e s u b s t r i n g s  in Aigorithm D. J u s t  as 
we only  had to change AD7idODE in Algorithm B ,  we only  have 
to change A D D ~ F S  in A l g o r i t h m  D. 
d e f i n e  ADCWF$ (NODEX) ; 
l o c a l  W, I, DAUGHTERS; 
/* conpdte DAUGHTERS for s u b s t r i n g  */ 
DAUGHTERS = Q; 
if NODEX ( ' DAUGHTERS ' ) ne SZ then 
DAUGHTERS = : I E NODEX ( ' DAUGHTERS ' ) ] <TREE (I, ' WFS ' ) > ; 
end $f NODEX; 
/* &arch f o r  w e l l  formed substr ing w i t h  i d e n t i c a l  ;.IMil3, 
m, LW+l * /  
if 1 <= 3 W <= WFSS 1 ( (WFS (W ,INAME ' ) eq NODEX ( 'NAME ' ) ) and 
(WFS (W, 'FW') eq NQDEX('FW') 1 and 
(WFS(W, 'LiV+1') eq NODEX('LW+l') ) 
/* found one, add daughter to set */ 
then if DAUGHTERS ne 52 t h en  
DAUGHTERS in WFS (W , ' DAUG:ITERS ' ) ; 
end if DAUGHTERS ; 
else WFSS = WFSS+I : 
WFS(WFSStlNAM, 1 = NOIT'~.~(.('NAME'); 
WFS(WFSS,'r;bW1) = NOUEY(~FWI); 
W F S ( W F S P ~ ~ L W ~ - ~ ~ )  .= NODEX('~;W+~'); 
- 0 WFS[WFSS,'U~,'JG~L hs = 
Lf DAUGrlTF., eq R +hen nR else DAUGHTERS ; 
end if 3 ~ ;  
2e t u r n  ; 
end ADDWFS; 
Use of the V a r i o u b  Algo~ithms i n  Natural Language Systems 
The type  0 top-down a lgor i thm (algorithm A )  is one of the 
simplest and lnost f r e q u e n t l y  used.  For example, a spec ia l  v e r s i o n  
o f  t h i s  algorithm (for Greibach normal form grammars) was u s e d  i n  
t h e  original Harvard p r e d i c t i v e  Analyzer [ICuno 19621. The l a t e r  
version of the  ~ a r v a r d  system, i n c o r p o r n t i ~ ~ g  a "path elimination" 
t e chn ique ,  w a s  a type 1 top-down s e r i a l  parser, a v a r i a n t  of 
Algorithm E ;  i n s t e a d  of saving a l l  daughters i n  WFS during the 
parse ,  they were recomputed later f o r  those nodes appearing in 
a parse t r e e  [ X q o  1 9 6 5 1 .  
S e v e r a l  c u r r e n t  sys.t;cms u s e  nug111&11t;ed context-f ree grammars : 
grammars to which have bccn uddcd restrictions on the parse tree 
typically i n  the form of  LISP predicates, which  m u s t  be t r u e  if 
the tree is to be accepted a s  a sentence L ~ ~ ~ a l y s i s .  The lBinocjrcld [197l] 
svs tern uses an  acy~ented contest-f ree grarmar w i t h  the con tex t - f  ree  
component encoded as  a program r a t h e r  than, data. The p a r s i n g  
strategy i s  e s s e n t i a l l y  that of !a t y p e  0 top-down algorf-thm, 
except t h a t  back-up is explicitly c o n t r o l l e d  rather than automatic. 
Woods ' sys tem [1970b] also uses a t y p e  0 top-down a l g o r i t h m ,  although 
somewhat different from the one p r e s e n t e d  here s ince  h i s  grammar 
i s  a r e c u r s i v e  t r a n s i t i o n  network. The L i n c J u i s t i c  String P r o j e c t  
system [Sager  1 9 6 7 1  started out w i t h  a p a r s e r  based on a type 0 
top-down algorithm; for efficiency i t  l a t e r  progressed to a type 2 
top-down algorithm. A t y p e  2 rather than a type 1 a l g o r i t h m  was u s e d  
because t h e  restr ic t ions can o11e analysis of a portion of 
the s e n t e n c e  as a particular symbol while accepting another 
a n a l y s i s  of the same p o r t i o n  of the s e n t e n c e  as  the same s y x b o l .  
For a type  2 algorithm, t h i s  means simply e l - i n i n a t i n g  some nodes i'n 
WFS; f o r  a type 1 algorithm, w h e ~ e  a single node may represent 
several ttrees, a complicated procedure  which could c r e a t e  new nodes 
would have been r e q u i r e d  i n  g e n e r a l .  The L i n g u i s t i c  String P r o j e c t  
parser is c o n s i d e r a b l y  more complex t h a n  the type 1 top-down 
serial  parser shown above ( a lgor i thm D ) ,  i n  p a r t  because of t he  
r e s t r i c t i o n s  which must be eva lua t ed  d u r i n g  t h e  parse, i n  part 
because  (for r ea sons  of skoroge ecorloiny) the sys tem makes it 
p o s s i b l e  t o  save o n l y  s e l e c t e d  nodes i n  WFS. 
The type 2 bottom-up paral le l  algori thm also saw early use i n  
5% 
n a t u r a l  language processing. The parser de s igned  by Cocke for the 
Rand system w a s  a special version of t h i s  a l g o r i t h m  for Chomsky 
normal form grammars. A thorough survey of t h e  d i f f e r e n t  o rde r ing  
strategies possible  w i th  t h i s  algorithm was given by Hays [1967]. This 
algorithm was subsequently developed by Cocke (among others) into 
a type 1 bottom-up paralleL algorithm named "nodal spans" and 
subsequent ly  i n t o  a type .1 top-down para l le l  algorithm called 
"improved nodal spans" (see Cocke [1970] f o r  a description 
of t h e s e  a l g o r i t h m s ) .  The l a t t e r  i s  very similar t o  a parsing 
algori thm described by E a r l e y  [19 701 . +These type  1 algor i thms 
have, t o  &he b e s t  of o u r  knowledge, n o t  yet been used i n  n a t u r a l  
language parsing. 
In c l o s i n g  a few remarks are in order on the practical 
importance of the dif ferences  between t he  various algorithms. 
How s i g n i f i c a n t  is  t h e  d i f f e r e n c e  between t y p e  2 and type  1, 
between top-down and bottom-up , be tween s e r i a l  and paral le l?  
There has been no systematic s t u d y  of these q u e s t i o n s ,  and t h e  
answers t o  them are i n  all l i k e l i h o o d  qyite grammar s p e c i f i c .  
For example, t h e  advantage of the tcjp-down parser is t h a t ,  
in working on word n + l ,  i t  e l i m i n a t e s  from c o n s i d e r a t i o n  those 
symbols which could  no t  occur in any parse t ree  whose first n 
t e r m i n a l  symbols are t h e  first n words of t h e  s en t ence .  Is this 
a large effect? Although I am n o t  aware of any measurement 
of this quantity, the f ac to r  seems t o  be relatively small fo r  
large-coverage English grammars -- perhaps reducing  the number 
of symbols i n  h a l f .  
The advantage of type 1 over type  2 algorithms depends on t h e  
degree of ambiguity of the grammar. How f r e q u e n t l y  can a po r t i on  
of i+ sentence be analyzed as a particular symbol i n  s e v e r a l  ways? 
For unaugmented con tex t - f r ee  grammars t h e  answer in general has 
been very f r e q u e n t l y  -- t h i s  was one of t h e  problems of the 
context-free systems. For such grammars, type 1 algorithms 
would be much more e f f i c i e n t .  When r e s t r i c t i o n s  are added, 
however, they discriminate some of the analyses from others .  
L 53 
A rich set of s y n t a c t i c ,  semantic, and pragmatic  r e s t r i c t i o n s  
(available so f a r  o n l y  f o r  small subsets  of E n g l i s h  in limited 
areas of d i ~ c o u r s a )  would p r e s u m a b l ~ ~  eliminate almost a l l  
ambigu i ty ,  so  t h a t  the advantage of a type 1 algorithm would 
then be small. 
F i n a l l y ,  We should m e n t i a n  t h e  di f fe rence  butwecn s e r i a l  and 
parallel parsers .  S i n c e  ser ia l  and p a r a l l e l  algorithms w i ' l l  
have created the same nupber of nodes by the t i m e  parsing is 
con~ple te ,  the difference in time is probably quite small. 
The parallel algorithm pay have the edge because "bookkeeping" 
is simpl'er. Also;  the p a r a l l e l  a lgor i thm can  handle left r c c u r s i o : ~  
na tu r l a i l y ,  whereas a spec ia l  mechanism i s  r e q u i r c a  for top-down 
serial parsers. On t h e  o ther  hand, a s e r i a l  a l g o r i t h m  may be 
preferable  if o n l y  the f i r s t  parse of a s e n t e n c e  is r e q u i r e d .  
In a d d i t i o n ,  the ser ia l  a lgor i thms can m o r e  s i m ~ l y  hand le  t h e  
s i t u a t i o n  where memory space i s  marginal .  Normal ly  m o s t  of t h e  
space in a lgo r i tnms  D and E is u s e d  by the s e t  WFS, n o t  by TREE. 
C o n s e q u e n t l y  a t y p e  1 o r  2 serial  parser can " r e s c u e  itself" 
w h e n  memory is almost e x h a u s t e d  by rever t ing  to a type 0 algorithm; 
this s imply  means t n a t  it s tops  s a v i n g  nodes  in WFS. In t e r m s  of 
t h e  SETL programs g iven  above t h i s  r e q u i r e s ,  in a d d i t i o n  t o  a 
change to ADDWFS, o n l y  t h a t  e l e m e n t s  of EXPANDED no longer be set 
t6 true qnce -savTng has been t e r n ~ i n a t e d .  
3 . 2 .  A Parser for Unrestr icted R e w r i t i n a  R u l e  Grammars 
A number of n a t u r a l  language systems, such as REL (at 
t h e  Cal i fo rn ia  Institute of Technology) and the Q-system (at 
t he  U n i v e r s i t y  of Montreal) have used u n r e s t r i c t e d  phrase 
s t r u c t u r e  grammars. In such grammars, each rule specifies 
t h a t  some sequence of symbols be r e w r i ' t t e n  as some other  
sequence of symbols. The parsing algorithm used i n  these 
s y s t e m  was described by Kay in 1967 ("Experiments w i t h  a 
Powerful. Parser , "  Martin Kay, ih 26me Conference  I n t e r n a t i o n a l e  
sur le Traitmcnt Automatique des Langues , Grenoble) . 
Kay added qud te  a f e w  features to the basic parsing 
procedure t o  create h i s  "powerful parser" .  These i nc luded  
r u l e  order ing  and conditions on rule appl ica t ion .  Other 
unrest r ic ted r e w r i t i n g  rule s y s  terns have a l so  i n c l u d e d  some 
such features. t o  ~ e r m i t  he pars imonious  d e s c r i p t i o n  of 
c?~mplex natural language grammars. I n  this newsletter, 
however, we s h a l l  no t  be concerned w i t h  these a d d i t i o n a l  
features ; on ly  t h e  b a s i c  pa r s ing  procedure will be described 
below. 
The parser to be presen ted  represents  o n l y  a small modi- 
fication to the context-free parser B (the "immediate 
c o n s t i t u e n t  a n a l y z e r " )  g iven ea r l i e r  . To unders tand  t h i s  
modification, consider the  f o l l o w i n g  example. We are given 
a context-Free grammar which includes the  product ions  
a -+ def 
and 
x + y a  
a d  the s e n t e n c e  
y d e f  
We s h a l l  create a diagram f o r  the sentence by making ea th  word 
into an arc connect ing t w a  nodes ,  which are  labeled w i t h  the 
number of the word in the sentence and the number +1: 
Context-free parse r  B would f i f s t  app ly  t h e  p roduc t  a -+ do? 
i n  reverse, to ob ta in  a span 'a" , we can i n d i c a t e  this t h u s :  
Note t h a t  the arc f o r  thc s p a  connects nodas cor responding  to 
t h e  f i rs t  word and t h e  last word + 1 subsurnod by I span. 
The  parscr would then apply x -c y a i n  rcvcrse:  
g e t t i n g  a span  which subsumes the e n t i r e  sentence. 
Now cons ider  a n a l y z i n g  t h e  same sentence w i t h  t h e  
u n r e s t r i c t e d  phrase s t ructure!  grammar 
z + y a  
x + z b  
We beg in  by i lsing t h e  f i r s t  production tc reduce the s e ~ ~ t c n c e  
to y a b .  T h i s  raises the problem of how to l abe l  tthc no~ic 
between arcs a and b. ~ l t h o u g h  a and b together s u b s ~ ~ a  the
l a s t  three words of the s e n t e n c e ,  no f r ac t i on  of- this C ~ I I  be 
ass igned i n d i v i d u a l l y  to a or to b; hence we cannot  l abe l  
this new node with t h e  number of a sentence w o r d ,  h l s t e a d ,  
we ass ign  a nzw, u n i q u e  l a b e l  (here, v1) to the node: 
PiCri can thea reverse the second product ion to get a span z 
Fhallly we reverse the third product ion t o  get q span x 
subsuming t he  e n t i r e  sentence: 
In the progzam below, new node names are created by 
cans oal the S W L  function newat, which returns a d i f f e r e n t  
U c p e  symbol (a "blank atom" in SETL terminology) each time 
it is called. We have r e t a ined  the span component names 
EW and L W + l  for the labels of the nodes at the ends of t h e  arc ,  
moxagh their values may now be blank atoms instead of numbers. 
A production of the  f o r m  
al ... a + bl ... b n n 
is represented by th8 s t r u c t u r e  
<<al, ...'a >, b l , . . . , b  > 
n n 
GRAMPlZSR is a s e t  of such structures. For example, the 
mnlclestsicted rewriting rule grammar given above would be 
encOded4ar;r 
C < < a, b>, d, e, fz, 
< < zQ>, y, a>, 
< < x>, Z ,  b > 3 
fact that spans numbered s .  s, w e r e  formed by 
lying an inverse production t o  spans numbered dl . . . d 
n 
Zs mxxm3ed by assigning the component CONSTITUENTS w i t h  value 
d e f i n e  URRP&SSE (GRAMMAR, SENTENCE) 
loca l  SPAN, SPANS, WORD, TODO, CUFtRENT, DEF, DEFNAME, 
DEFELIST, MS ; 
/* initialization * /  
SPAN = nl; 
SPANS = 0; 
TODO = n u l t ;  
I* i t e ra te  over W O R D = l a s t  w o r d  
subsumed  by spans being 
cons t r u c t e d  */ 
(1 <= VWORD <= #SENTENCE) 
/* add span  whose name is s e n t e n c e  word */ 
RDDSPAN (SENTENCE (WORD) , WORD , F?ORD+l, n u 1  t) ; 
* TODO co~ l t a in s  the n u n h e r s  of s p a n s  which w e r e  
created and for which we have not y e t  checked 
j u s t  
whe the r  they can be used as t h e  last daughter span 
in building some m o r e  spans */ 
( w h i l e  TODO ne nult) 
/* select  a span from TODO */ 
CURRENT = hd TODO; TODO = tl TODO; 
/*  loop over all p r o d u c t i o n s  whose last e l e m e n t  
= name of c u r r e n t  span */ 
( V D E F  E GRAMMAR~DEF(#DEF) eq SPAN (CURRENT, ' )  ) 
/*  separate l e f t  and r i g h t  sides of production * /  
D E F N k W  = hd DEF;  
DEFELIST = tl DEF;  
/*  if elements preceding last e l e m e n t  of produc t ion  
can be matched by spans ,  add n e w  spans  whose 
names = l e f t - h a n d  side of product ion  f o r  each m a t c h * /  
(VFSM E MATCH (DEFELIST (1: (#DEFELIST) -1) , 
S F X ~  (CURRENT, 'FW'  ) ) ) 
ADDSPANS (DEFNAMEet hd REM, SPAN (CURRENT, 'LW+l ) , 
(tl REM) + < C U R R E N T > )  ; 
end VREM; e n d  VDEF; 
end w h i l e  TODO; 
end 1 <= VWORD; 
r e t u r n  SPAN; 
end URRPARSE; 
define MATCH (ELIST, E N D W D P ~ )  ; 
local I, NTUP; 
/* MATCHfinds a l l  n-tuples  sf spans whose names 
match the elements of the n - tup l e  ELIST and 
which span a port ion of the se~ltence whose 
last word + 1 = ENDWDP1; returns a set, each 
e l e m e n t  of w h i c h  i s  an ( n + l )  - tup le ,  whose t a i l  
is one of the n-tuples of spans and whose head 
is the number of t h e  f i r s t  word spanned by t h e  
n - tup le  of spans */ 
if ELIST eq n u l t  
then  r e t u r n  ( < E N D W D P l >  ; 
else r e t u r n  [U: 1 <= I .f= NODES] 
(if (SPAN (I, 'NAME ' ) eq ELIST  (#ELIST)  ) 
and (SPAN ( I, 1 ' ) eq ENDWDP~) 
then {NTUP + <I>, N T U P  E 
MATCH (ELIST (1: (#ELIST) -1) ,SPAN (I, 'FW' ) ) I 
else nl) ; ; 
end MATCH; 
de f ine  ADDSPANS (LHS , FW, LWP1, CONSTIT~JENTS ) ; 
/* b u i l d s  a sequence of spans whose names are given by tuple 
LHS, w i t h  the f i r s t  span beg inn ing  at FW and the last one 
ending at LWPl */ 
local W ,  I, TUP; 
W = FW; 
TUP ="nuLt ;  
(1 <= VI <= #LHS) 
SPANS = SPANS + I; 
TUP = TUP -+ <SPANS>; 
SPAN(SPANS,'NAME1) = LHS(1)-; 
SPAN (SPANS, TW') = W; 
W = if I eq # L H S  then L X P l  else n e w a t ;  
SPAN (SPANS, 'LW+l ' ) = W; 
end 1 <= V I ;  
SPAN (SPANS, 'CONSTITUENTS ' ) = <TUP , CONSTITUENTS>; 
TODO = TUP -t TODO; 
r e t u r n ;  
end ADDSPANS; 
T h e  u n r e s t r i c t e d  r e w r i t i n g  r u l e  parser has t h e  power of a 
T u r i n g  machine. The u s e r  is af forded  great flexibility in 
the  m a n i p u l a t i o n  of  s e n t e n c e  s t r i n g s .  One drawback ~f such  
power, however, i s  t h e  absence of a dec i s ion  procedure -- 
no parser  can determine, for an a r b i t r a r y  grammar of t h i s  
t ype ,  that a g iven  s e n t e n c e  s t r i n g  is ungrqmrnatical .  
The use r  must tllcrefore be c a r e f u l  to d e s i g n  grammars so 
that the parser w i l l  terminate (in a reasonab le  amount  of 
time) f o r  any i n p u t  s e n t e n c e .  
3 . 3 .  Parsinq Procedures for Transformational Grammars 
Most linguistic research over t h e  p a s t  fifteen years 
has been conducted w i t h i n  the framework of t ransformat ional  
grammar developed by Chom'sky and ~ a r r i s .  In  t h e  early 1 9 6 0 1 s r  
a f e w  years after t h e  blossoming of t r a n s f o r m a ~ i o n a l  grammar, 
s e v e r a l  e f f o r t s  were begun t o  develop p a r s e r s  which could 
o p e r a t e  fairly d i r e c t l y  from a t r a n s f o r m a t i o n a l  grammar. 
Two of these achieved some measure o f  success :  a p r o j e c t  
a t  MITRE led by Donald Walker [Zwicky 1965, Walker 19661 and 
work a t  MIT by Stanley P e t r i c k  [19651. 
These t w a  e f f o r t s  had quite different objectives.  
The MITRE group was concerned with a s p e c i f i c  p r a c t i c a l  
application: development of a n a t u r a l  language i n t e r f a c e  
f o r  a military i n fo rma t ion  r e t r i e v a l  sys  tex. They developed 
a grammar f o r  a s u b s e t  of E n g l i s h  meet ing t h e i r  requirements 
and w e r e  p r i m a r i l y  concerned w i t h  des ign ing  a parser which 
c o u l d  handle  this p a r t i c u l a r  grammar. P e t r i c k ,  i n  c o n t r a s t  , 
developed a general parsing procedure which would work with 
any member of a class of transformational grammars. This 
difference i n  objective affeeked a number of design decisions 
r ega rd ing  t h e  p a r s i n g  procedure, as w e  shall see l a t e r  on. 
P e t r i c k  and his coworkers ,  a t  t h e  A i r  Force Cambridge R e s e a r c h  
Laboratory and now at XBM, Yorktown Heights ,  have modified t h e  
parser t o  r e f l ec t  changes i n  t r a n s f o r m a t i o n a l  grammar and t o  
adapt it f o r  use as t h e  front-end i n  an in fo rma t ion  r e t r i e v a l  
system. I P e t r i c k  1966,1973,1975; Keyser 1967; P l a t h  1974a, 1974bl. 
Interestingly enough, these modifications have brought  
Petrick's parser much closer t o  the o r i g i n a l  MITRE design. 
Since the structure of trans fom'iational grammar h a s  
var ied in t i m e  and between d i f f e r e n t  schools of linguistic 
theory,  the notion of a transformational parser is not we11 
defined. In order to presen t  a p a r s i n g  algorithm, we have 
selected a particularly simple granular formulation. This 
Eor inula t ion  corresponds a ~ p r o x i r n a t e ~ l y  to the early work of 
Chomsky ( e . g . ,  Syntactic S t r u c t z t r e s )  and the  theory  used in 
the early versions of the MITRE and Petrick systems, 
Complicating factors, s u c h  as f ea tu res  and c o n t e n t - s e n s i t i v e  
rules f o r  lexical i n se r t i on ,  have been o n ~ i t t e d .  
The grammar cons i s t s  of a bass c u r n p s ~ t 8 n t  and a ~ ~ ~ L z ~ ~ s ~ o I * ~ * : L I -  
$.iunnZ c o n t y ~ ? t ~ ? z d .  The base componant is a contex t - f ree  g r a n u n a r  
which produces a s e t  of d c s p  s t rnc- t ;u~ .a  t rees.  The t:-ansfor~na- 
tiorla1 c o i ~ ~ p o n e n t  i s  a set of t r e e - r e w r i t i n g  r u l c s  which, when 
applied t o  a deep s t r u c t u r e  t r e e ,  p roduces  one or more s u ~ f u c c  
s t ~ u c t u r e  trees.  The frontiers ( t e r n ~ i n a l  node sequences) 
of Lhe surface s t r u c t u r e  trees are the s e n t e n c e s  of the 
language.  
The root symbol of the base component is named S. T h e  
base component a l s o  con t a in s  a distinguished symbol COMP which 
appears on t h e  l e f t  side of only one p r o d u c t i o n :  
COrviP -+ # s # 
# is referred to as t h e  sen tence  boundary  marker ,  With the 
exclusion of this production, the CralImIar is n o t  recursive. 
Each transformation consists primarily of a s + ~ z t c t u ~ a  2 
i n d e x  and a s t r z t c t u z ~ a t  c h a n g e .  The s t r l l c t u r a l  irldex is a 
t u p l e  (vector)  , <si . . . s > I each of whose components 1' n 
is either a symbol (name of a node)  or " X u -  The s t r u c t u r a l  
change is a tuple <sclr. . . ,sc of the same length as t h e  
n 
s t r u c t u r a l  index.  Each of its components is ir t u r n  a t u p l e  
S C  =<SC i il,. - . ,sc >, possibly empty (ni = 0). Each of t h e  scij  in, 
is e i t h e r  a t e r m i n a l  symbol or an integer between 1 and n. 
The a p p l i c a t i o n  of f rans fomat iona l  rules i s  based dh 
the n o t i o n  of a proper anatysis, which is in t u r n  based on t h e  
concept of a cut o f  a tree. Roughly speak ing ,  a c u t  i s  
de f ined  by drawing a line from left to r i g h t  through a tree, 
pass ing only  through nodes (hot through t h e  l i n e s  connecting 
nodes) ; t h e  nodes thus passed through form the cut. For 
example, for the tree 
- -  - <> I1 
PRO 
I l i ke  t u r n i p s  
the sequence of nodes NP, VERB, M form a cu t .  More formally 
(Aho and Ullman, The Theory of Parsing, Trans Zation, and 
Compiling, Vol. I ,  pg .140) ,  a cut i s  a s u b s e t  C of t h e  nodes D 
of the tree such t h a t  
I* no node i n  C i s  on a  s u c c e s s o r  path from some 
o t h e r  node in C 
2 .  no other node of D can be added t o  C w i thou t  
v i o l a t i n g  rule 1 
If the na&nes of the nodes i n  t h e  cut, arranged in sequence 
from l e f t  t o  r i g h t ,  match t h e  s t r u c t u r a l  index of  t h e  
t r a n s f o r m a t i o n ,  t h e  cut i s  a  p rope r  a n a l y s i s  of the t ree with 
Y 
respect to t h i s  t ransformat iof l .  A s t r u c t u r a l  index matches 
the sequence of node n a m e s  if there ex is t s  a s u b s t i t u t i o n  of 
sequences of symbols ( p o s s i b l y  n u l l  and n o t  i n c l d d i n g  # )  for 
the occurrences  of "X" i n  the s t r u c t u r a l  index which w i l l  
make the s t r u c t u r a l  index identical t o  the sequence of names. 
For example, t h e  c u t  
NP VERB N 
would be matched by any of the  s t r u c t u r a l  indices 
NP VERB N 
The proper a n a l y s i s  assoc ia tes  w i t h  each e l e m e n t  of t h e  
s t r u c t u r a l  i ndex  (except  possib~y "XX"s) a nods in thc t r e e  
and hence a subtree,  the trce dominated by t h a t  node. The? 
s t ructural  change i n d i c a t e s  how these s u b t r e e s  are to be 
s h u f f l e d  to effect  t h e  t r a n s  fornation. sc  specifies what i 
is to go i n t o  t h e  p o s i t i o n  occupied by the  node ma tch ing  sc i 
If sci is a 1- tup le ,  we s imply  have a case of one 11ode (and 
t h e  sabtrce i t  dominates) replacing a n o t h e r ;  if sc i s  an i 
n t u p l e ,  n > 1, we f i r s t  s u b s t i t u t e  sc f o r  t h e  o r ~ y i n a l  node 
and then i n s e r t  sci2 1 . . . , sc . il 
lni as r i g h t  siblings of that node: 
If sci j  is an integer,between 1 and n, t h e  new node is t h e  node 
matched to the s c i j - t h  e l e m e n t  of t h e  s t r u c t u r a l  i n d e x ;  i f  SCij 
is a t e r m i n a l  symbol, the new node is a t e r m i n a l  node w i t h  t h a t  
name. 
Because the value  of sci may be the  n u l l  t u p l e  < >, 
i t  is poss ib le  f o r  a node in the tree to be left w i t h  n o  
successors. We therefore  "clean up"  the tree a f t e r  a p p l y i n g  
the t r ans fo rma t ion  by d e l e t i n g  any n o n t e m i n a l  node not 
dominating at l e a s t  one t e r m i n a l  node. 
The p r e s c r i p t i o n  just g i v e n  is i nadequa te  f o r  components 
~f the structural index e q u a l  to "X", since these may match 
zero or moxe t han  one node. ide s h a l l  cons t r a i n  t h e  transforna- 
t i o n s  so t h a t  nodes in the c u t  which a r e  m a t c h e d  by " ~ " ' s  do 
not take p a r t  in t h e  t ransformat ion .  In terms of the s t r u c t u r a l  
change, if sik = "x" t h e n  sc = <k> and no other scij k = k. 
As an example ( 3  siqplfication of the example in 
Keyser and P e t r i c k ,  Syntactic A n a Z y s i s ,  p. 9 ) ,  consider t h e  
p a s s i v e  t r a n s f o r m a t i o n .  Its s t r u c t u r a l  index is 
<PIPt AUX, V t  XI NP, X I  BY, PASS> 
and its s t r u c t u r a l  change 
Applied to the tree 
ART 
the crocodi 
i t  produces t h e  proper a n a l y s i s  i n d i c a t e d  by t h e  d o t t e d  l i n e  
Applying t h e  t r a n s f o r m a t i o n  y i e l d s  t he  tree 
ART 
PREDP 
AUX 
t h e  g i r l  BE EN f r i g h t e n  BY t h e  c r o c o d i l e  
In additian to the s t r u c t u r a l  index  and structural 
change, some t r ans  formations may have an identity c o n d i t i o n ,  
requiring t h a t  t h e  s u b t r e e s  matched by t w o  e l e n ~ e n t s  of t h e  
s t r u c t u r a l  index be identical f o r  the transEorma.t=ion t o  
~ P P  1~
The r u l e  COMP -+ # S # ,  which maes the base conponcnt 
r e c u r s i v e ,  a l s o  p l a y s  a spec i a l  role  in t he  t r a n s f o r m a t i o n s .  
If the s t r u c t u r e  
appears in the parse t rce ,  w e  call the tree dominated by t h a t  
S a c ? 3 ) i s t i t l t d n t  (or embedded) s e n t e n c e ,  and t h e  tsce & ~ n i n a t e d  
by the n e x t  S above COMP t h e  rnadl?,ix s e n t e n c e  parse t ree .  
The transformations are of h ~ o  t y p e s ,  s and b i n a r i i  
(or embedding).  I n  a s i n g u l a r y  t r a n s f o r m a t i o n ,  the s t r u c t u r a r  
index does not contain the symbol #.  In a b h a r y  t r a n s f o r m a t i o n ,  
the structural i ndex  i s  of t h e  form a #.  B B y , w h e t e  
a ,  8 ,  and y are s t r i n g s  of symbols n o t  c o n t a i n i n g  # .  
The b i n a r y  t r a n s f o r m a t i o n  deEetes these boundary m a r k e r s  
( i f  # are the i t h  and j t h  con~yonents  of t h e  s t r u c t u r a l  i n d e x ,  
t hen  none of the S C ~ . ~  = i or j , t h u s  combining a constituent 
sentence w i t h  i t s  matrix sentence.. 
The t ransformat ions  are a l s o  cl s s e d  as o p t i o ~ w l  or 
ob l t  g a t o r y .  J u s t  l i k e  the generation of s e n t e n c e s  with a 
context-free grap.uilar, the application of t . r a n s f o r n a t i o n s  to a 
base s t r u c t u r e  may be viewed. as a ndndeterninistic process. 
Depending on t h e  choices made, one of several possible surface 
s t r u c t u r e s  may be obtained f r o m  a s i n g l e  deep structu-e. 
The transformations are c o n s i d e r e d  in a fixed order t o  be 
described momentari ly.  I f  there exists no proper a n a l y s i s  for 
a t r a n s f o r m a t i o n ,  t h e  t r a n s f q r h a t i o n  i s  sk ipped.  I f  there exist 
s e v e r a l  p r o p e r  a n a l y s e s ,  one i s  chosen. I f  t h e  transformation 
i s  obligatory, it i s  t hen  appl ied ;  if it 1 s  o p t i o n a l ,  a choice 
i s  made t o  apply it or n o t .  
The singulary and b i n a r y  trans formations are s e p a r a t e l y  
ordered. The tr ~ s f o r m a t i o n o l  process begins  by selecting 
an embedded s e n t e n c e  tree not including any o t h e r  embedded 
sentence. The singulary t r a n s f o r m a t i o n s  are appl ied i n  sequence 
t o  t h i s  tree; s t r u c t u r a l  i n d i c e s  are matched against t h e  
embedded t ree ,  n o t  the entire parse tree. The b i n a r y  trans- 
fokmations are t h e n  a p p l i e d  t o  this tree and i t s  m a t r i x  
s e n t e n c e  t ree;  one of these should actually transform the 
tree, deleting the  embedded s e n t e n c e s  (if none a p p l i e d ,  w e  
would e v e n t u a l l y  be left w i t h  a s u r f a c e  s t r u c t u r e  containing 
# ' s , which would be rejected)  . Another  deepest ernbedded 
sentence is selected and t h e  process repeats until n o  embedded 
s e n t e n c e s  remain. The s i n g u l a r y  t r a n s  format ions  are then  
applied t o  t he  e n t i r e  t ree ,  completing t h e  g e n e r a t i n g  process 
( i f  the base s t r u c t u r e  con t a ined  no embedded s e n t e n c e s ,  this 
would be the on ly  step) . 
In  order t o  parse a s e n t e n c e  -- o b t a i n  i t s  deep s t r u c t u r e s  -- 
we would l i k e  t o  r e v e r s e  the process just desc r ibedv .  First 
build one o r  more ; . > o t e n t i a l  surface structure parse t r e e s  for 
a s e n t e n c e  and $hen,  by app ly ing  the t r a n s f o r m a t i o n s  i n  r e v e r s e ,  
try t o  obtain a v a l i d  deep s t r u c t u r e  from each of these. 
We shall deal w i t h  these t w o  steps i n  t u r n .  
The surface s t r u c t u r e  parse  tree will, i n  general, c o n t a i n  
many s t r u c t u r e s  which could n o t  be directly g e n e r a t e d  by t h e  
base component. I f  w e  want to produce a l l  the s u r f a c e  s t r u c t u r e  
trees for a sentence us ing  a context-free grammar, it will be 
necessary t o  augment the base component. For example, i f  the 
base component conta ins  the product ion 
A + X Y  
and there i s  a t r ans format ion  which i n t e r changes  x and Y ,  
t h e  r u l e  
m u s t  be i n c l u d e d  i n  t h e  grammar which  is used to produce the 
surface structure t rees .  P e t r i c k  has  desc r ibed  ( i n  his P21. D. 
thesis) a procedure which can determine fro111 t h e  base and  
t r ans for~na t iona l  components, how t h e  base m u s t  be augmented 
i n  o rder  to o b t a i n  a l l  sur face  struc.turt3 t r ees .  
Because a t rnnsformnt ion  can replace one node w i t h  two, 
i t  i s  p o s s i b l e  for rcgcated application of such  a transforma- 
tion t o  produce a node i n  the surface. s t r u c t u r e  w i t h  an a rb i -  
a r b i t r a r y  n ~ u n b e s  of inmediate  descendan t s .  T l l i s   cans t h ~ t .  
an i n f i n i t e  n ~ u r ~ e l "  of rules m u s t  be added t o  1 base 
component. P e t r i c k  no ted ,  however, that ;  i f  a limit is placed 
on the l e n g t h  of  s e n t e n c e s  t o  be analyzed (and c e r t a i n  minimal  
a s sumpt ions  are made about t h e  grammar) , only a f i n i t e  number 
of rules are requ i red .  ( A l t e r n a t i v e l y ,  it seems, a recursive 
t r a n s i t i o n  ne twork  could  be used tu o b t a i n  t h e  sur face  
s t r u c t u r e ,  since such  a dev i ce  a l lows a node to have a n  
a r b i t r a r y  number of immediate d e s c e n d a n t s  . ) 
This augmented grcnlmar w i l l  produce a l l  t h e  v a l i d  s u r f a c e  
s t r u c t u r e  parse t rees  b u t  it w i l l  a! so  produce ,  in g e n e r a l ,  
many spurious t rees  ( trees not d e r i v a b l e  fl-om deep s t r u c t u r e s )  
This is unavoidable, s ince a contex t - f ree  yranuuar is a ri~uch 
weaker computational  device than  a t ra~:sfosmati  on5.1 grannaar. 
Because the  language d e f i n e d  by the augmented base component 
i s  larger t h a n  t h a t  d e f i n e d  by t h e  t ranxEormationa1 graminar, 
t he  augmented base component i s  ca l l ed  a c o d a 1 9 i n g  gramrzar. 
S i n c e  each s p u r i o u s  su r f ace  a n a l y s i s  will have to undergo 
a len'gthy reverse t r a ~ s f o r m a t i o n a l  process before it !S 
recognized  as i n v a l i d ,  i t  i s  important t o  minimize the number 
of such parses. The s e r i o u s n e s s  of t h i s  problem is i n d i c a t e d -  
by some early results obta ined  by the MITRZ group. The 
MITRE system did not have a procedure for automatically 
augmenting the base component; the i r s  was assembled manually. 
Using a small g r m a r . ,  one of their 12-word test sentences  
obtained 48 surface analyses, almost a l l  of thorn spur ious .  
P e t r i c k  had s imilar  experience: he found that t h e  covering 
grammars produced by his procedure-were too broad, produc ing  
too many surface parses .  He has i n s t e a d ,  l i k e  t h e  MITRE 
group, produced his surface grammars manually, by a n a l y z i n g  
o o n s t r u c t i o n s  which appear in the s u r f  ace s t r u c t u r e  of i n p u t  
sentences to determine w h i c h  productions are r e q u i r e d .  In 
tYlis way, he has  been able to produce a p r a c t i c a l l y  u s e f u l  
covering grammar for a l imi t ed  area of discourse. 
These p r a c t i c a l  difficulties do n ~ t  n e g a t e  t h e  v a l u e  of 
an automatic procedure, such  as t h a t  descr ibed by P e t r i c k ,  
which will produce a covering grammar w e  can be s u r c  is 
complete (will produce all valid surface analyses) . They do 
i n d i c a t e ,  however, the value of developing procedures which 
produce " t i g h t e r "  surface grammars, perhaps by observing t h a t  
cer ta in  sequences of transEormations are impossible and hence 
s u p p r e s s i n g  the corresponding surface grammar product ions .  
They also suggest t h a t  a more power fu l  device t h a n  a- context- 
free grammar -- such as an "augmented* context-free  grammar" 
should perhaps  be used t o  g e n e r a t e  t h e  surface analyses. T h i s  
view i s  held by a number of w o r k e r s ,  such as Sager and Woods, 
who are also  aiming a t  a t ransformat ional  decomposition. 
Armed with a cover ing  grammar, we t u r n  now t o  t h e  
c o n s t r u c t i o n  of a reverse transforrnafional component. This 
component should produce, from a surface structure, a l l  base 
s t r u c t u r e s  which can generate the surface s t r u c t u r e  (and fo r  
a spur ious  surface s t r u c t u r e ,  i n d i c a t e  that  there are no base 
structures) . 
* "augmented" meaning here that the grammar may c o n t a i n  
predicates which are arbitrary computable fiu7ctions. 
The f irst  problem is that it i s  not always p o s s i b l e  to 
construct such a component. If a (fonvard)  t r ans fo rma t ion  
simply deletes a p o r t i o n  of t h e  parse t ree ,  it will i n  g e n e r a l  
be impossible  to reconstruct  t h a t  p o r t i o n  when w o r k i n g  
backwards from the sur ' facc s t r u c t u r e :  t he re  may be an i n f i n i t e  
number ~f deep s t ruc tu re s  which produce one sur face  s t r u c t u r e .  
Such a s i t u a t i o n  is cal led i . z*z*e~?sur:~l~zb I t 1  . J G  t t . t % ' c v ~  ( ' P h i s  is 
i n  contrast  to recoverable d e l c t i ~ n s ,  which  make use of a 
compo~~en t  af forward t r ans fo rma t ions  b r i e f l y  i i on t i onod  o a r l i e r :  
i d e n t i t y  cond i t ions .  An i d c n t i C y  condi t ion  s p e c i f i c s  two or 
more colnpar~cnts of the s t r u o t u r a 3 .  index;  t l l e  t u L ~ n s f o r m s t . i u n  
may be a p p l i e d  o n l y  if t h e  t rccs doit~inated by the nodes 
matched by these eleinents aiue i d e n t i c a l .  If soc~e -- b u t  not a11 
-- sf thcse trces are dele ted  by a t r a n s f o r m a t i o n ,  the 
d e l e t i o n  is recoverable: t h e  reverse t ransfs~-matisnal .  
component  may restore the d e l e t i o n  by. copying another  p a r t  
o f  the tree. ) So, to be able to c o n s t r u c t  a reverse compo- 
n e n t  at a l l ,  t h e  grammar may con ta in  n o  i r r e c o v e r a b l e  
de leci ons . 
L i f e  would be r e l a t i v e l y  easy i f ,  for each t ransformat ion ,  
one c o u l d  produce an inverse t r a ~ ~ s f s r m a t i o n  which  undoes t h e  
change wrought  in the tree. Unfort:unatcly,  f o r  the ? o m  of 
t rar~sforrnat ion we have chosen ,  this is n u t  possible. Cor~s i d e r ,  
for e x a n g l e ;  a transformatior1 w i t h  s t r u c t u r a l  i n d e x  
and s t r u c t u r a l  change 
Suppsse  t h a t  the o n l y  s t r u c t u r e  to which it ever a p p l i e s  
i n  the generation o f  a sentence i s  
produc ing  
b g  a s  transformation seenp straight forward enough. 
xse transformation need n o t  be a true inverse ; it 
mt hawe to be able t o  r e c o n s t r u c t  any i n p u t  g iven  t o  
transformation. It need only be able to repon- 
Senputs which occur in the d e r i v a t i o n  of sen tences .  
this case, i t  must insert a B dominat ing  a C 
!&!# m* 
This o p e r a t i o n  cannot be performed i n  t h e  t r a n s f o r m a t i o n a L  
sm dasc?r%bed above (unless a B dominating a C i s  
present i n  the tree) . I n  terms of e l e m e n t a r y  changes 
to a parse tree, tHis formalism permits only deletion (of 
1 .  replacement (of 6ne node by ano the r ) ,  and sister 
adjunction (insertion of one node "nex t "  t o  another, with both 
natedqby the same notie); it does not a l low inse r t ion  oS 
node' below another. This formalism was used i n  P e t r i c k ' s  
original system. Most more recent systems, i n c l u d i n g  the 
s y s t e m  and Petrick's l a t e r  systems, have allowed a 
r set of elementary operat ions,  capable of making an 
ftrary change t o  a tree. 
E v e n  if the set of o p e r a t i o n s  i s  s u f f i c i e n t  t o  form a 
set oE r e h x s e  t r a n s f o r m a t i o n s ,  t h e i r  formation i s  not t r i v i a l .  
a such as t he  one just c o n s i d e r e d ,  t h e  r e v e r s e  t r a n s -  
on cannot be genexated f r o m  an examination of t h e  
transformatian a lone  One must examine the entire 
to see how the t r a n s f o r m a t i o n  i s  used i n  s e n t e n c e  
on, T h i s  i s  a complex process which has ( t o  t h e  
oras knowledge) nevert been p r o g r a m m e d .  In t h e  MITRE 
, the reverse transfofdn'ations were a l l  produced 
I 
P e t r i c k ,  seeking orj y inal ly  a procedure  w h i c h  w ~ u l d  work 
cal2y from the transf~rmational grammar took a 
actifberent tack. He developed a reverse t r a n s f o r m a t i o n a l  
& which mapped the surface strirrg (the senkence) 
h t o  a set of potential  deep structure strings; the l a t t e r  
-me ~~ parsed by the base component. The individual 
ions of the reverse component are s t r & n g  and not 
k m e  mewr5,ting sules . 
The advantage of t h i s  approach l i e s  in the simplicity of 
fo rming  the i n d i v i d u a l  reverse t r ans fo rma t ions .  The reverse 
t r a n s f o r m a t i o n s  w i l l  be i n  one- to-one  co r r e sponAence  with 
the forward o n e s ,  and each r e v e r s e  t r a n s f o r m a t i o n  T' can be 
computed on t h e  basis of the  corresponding forward t rans for -  
mation T alone. These reverse t r a n s f o r m a t i o n s  w i l l  satisfy 
the following p r o p e r t y :  f o r  any tree t w i t h  f r o n t i e r  s ,  if 
T maps t i n t o  t 1  w i t h  f r o n t i e r  s l ,  then T '  maps s 1  into s .  
Suppose we are  g i v e n  a fonvard t r a n s f o r m a t i s r ~  with 
s t r u c t u r a l  i ndex  si and s t r u c t u r a l  change sc .  s i n c e  we 
are in te res ted  o n l y  in t h e  f r o n t i e r  and n o t  in the i n t e r n a l  
s t r u c t u r e  of the t ree ,  we s h a l l  use a rcd~xccd s t r u c t u r a l  
change 
rsc = [+: 1 <= i <= # S C ]  s c ( i )  
o b t a i n e d  by c o n c a t e n a t i n g  t h e  e lements .  of the s t r u c t u r a l  
change.  The f a c t  t h a t  a proper  a n a l y s i s  e x i s t s  f o r  a tree 
w i t h  f r o n t i e r  s i m p l i e s  that s can be g iv ided  i n t o  substrings 
s1 t - ,Sn s u c h  t h a t ,  f o r  a l l  j from 1 t o  n ,  a t r e e  can be 
* b u i l t  w i t h  root si and f r o n t i e r  s j (unless si = ' X 1 ,  j j 
i n  which case t h e r e  i s  np, r e s t r i d t i o n  on s . )  : 3 
The t r a n s f o r m a t i o n  rearranges t h e  string i n t o  a s e t  of 
1 
s u b s t r i n g s  s g i v e n  by ( f o r  j from 1 to r, r = #rsc) j 
S '  (1) = if rsc( j )  is an integer then $ ( r s c ( j ) )  e l se  r s c ( j )  
, s  (rsc (r) ) 
* u s i n g  the, cove r ing  grammar. 
How can this shuf f l e  be reversed? W e  begin by c r e a t i n g  a n  
. inverse s t ruc turaZ i n d e x  isi (1 <= j <= r) according to. j 
i s i ( j )  = if r s c ( j )  is an i n t ege r  then  s i ( r sc ( j ) )  
else r s c ( j )  
and an i n v r r a e  s t r u c t u r a 2  change isc (1 = j C= n) j 
according to 
i s c ( j )  = if 3 k  I r s c ( k )  eq j then  k 
else s i ( j )  
TQen giTlen *a s t r i n g  s ' , we div ide  it i n t o  r s u b s t r i n g s ,  
r equ i r i ng  t h a t  the? j - t h  substring be the f r o n t i e r  of some 
tree with root i s i  (again unless isi = ' X' ) . One of j j 
these d i v i s i o n s  will be the  s . produced 'by the forward 3 
transformation (there may be others) . These s u b s t r i n g s  
are then rearranged acco rd ing  t o  thB i s c ,  producing t h e  
o r i g i n a l  string s j 
s ( j )  = if isc( j) i s  an i n t e g e r  t h e n  s '  ( k c (  j )  ) 
else iscl j) 
I f  there are several matches to t h e  isi, the t r a n s f o r m a t i o n  
must be a p p l i e d  t o  a l l ;  w e  can on ly  be s u r e  t h a t  one of t h e  
r e s u l t i n g  strings w i l l  be s .  I f  the forward t r a n s f o r m a t i o n  
1 
is a recoverable deletion i n v o l v i 3 s  i d e n t i t y  conditions, t h e  
formulas given  above are somewhat more complicated. 
Given a s e t  of reverse t ransformat ions ,  we must  f i n a l l y  
specify t h e  sequenc ing  among them. The reverse transforma- 
tions should be cons ide red  i n  precisely t h e  reverse o r d e r  
fro11 t h a t  of the cor respond ing  fo rward  t r a n s f o r m a t i o n s .  The 
sequericihg is aga in  cyclic, with each i t e r a t i o n  now creat ing 
an embedded sentence.  
Even i f  a  reverse t ransformat ion matches the  s e n t e n c e  
being decomposed, one cannot be s u r e  t h a t  the corresponding 
forward transformation was involved in the generat ion of the 
sentence. Uridoing the t ransformat ion may lead t o  a dead end 
( n o  o the r  reverse t r a n s f o r m a t i o n s  a p p l y ) ,  and arkother t r an s -  
formation may also have produced the current s t r u c t u r e .  
Consequent ly ,  both p o s s i b i l i t i e s  -- unsdoing and n o t  undoing 
t h e  t ransformation -- must Lie followed. In analogy w i t h  t h e  
fonvard t r a n s f o r m a t i o n s ,  one can say  t h a t  a l l  reverse trans- 
formations are  o p t i o n a l .  
T h i s  implies, unfortunately, that p a r s i n g  t i~ne  can 
increase e x p o n e n t i a l l y  w i t h  the nuinber of app l i cab le  trans- 
formations. Such a p r o c e d u r e  has therefore proved impracticabLe 
for a11 b u t  the smal les t  grammars and s e n t c n ~ c s .  T o  avo id  t h i s  
e x p o n e n t i a l  growth,  ths parser m u s t  have some way of dcter- 
mining  d i r e c t l y  from a tree t h e  last t ransformat ion which 
appl ied  to produce the trce. An a n a l y s i s  m u s t  be made o f  
t h e  p o s s i b l e  intermediate s t r u c t u r e s  which can arise i n  
s e n t e n c e  g e n e r a t i o n ,  and t h e  r e s u l t i n g  information t r a n s 1  ated 
into conditions on the reverse t r a n s f o r m a t i o n s .  Such an a n a L y s i s  
has n o t  b e e n  automated,  b u t  it: i s  norrr.al2y a straightforward 
and i n t e g r a l  part of the manual c o n s t r u u t i ~ n  of a reverse 
t r a n s f o r m a t i o n a l  component. The MITRE group was able to 
s p e c i f y  the appropr i a t e  c o n d i t i o n s  f o r  a i l  their reverse 
t r a n s  formations ; their s y s  tern p r o v i d e d  for  optional reverse 
transformations b u t  t h e i r  grammar d i d  n o t  utilize this 
facility. 
E l i m i n a t i n g  o p t i o n a l  reverse transformations i s  more 
di f f i c u l C  in a reverse zornponen t using string ~ c w r i t i n g  r u l e s ,  
not retaining any tree s t r u c t u r e  between t r a n s f o r n ~ a k i o n s .  * 
Most of the i n f o r m a t i o n  which  is  needed t o  d e t e r m i n e  which  
t ransformat ion to undo is not available. In any case, the 
o r i g i n a l  impe tus  for u s i n g  string rewriting r u l e s  -- p r o v i d i n g  
a procedure which can operate directly from the t r a n s f o r m a t i o n a l  
grammar -- i s  l o s t  when w e  seek t o  add, for r e a s o n s  of e f f i c i e n c y ,  
r e ~ e r i c t d o n s  which are n o t  a u t o m a t i c a l l y  generated f r o m  t h e  
grammar.. 
* Petrick's o r i g i n a l  system, using s ~ r i n g  r e w r i t i n g  rules, 
did retain s o m e  low-level  t ree  structures between t r ans for rna-  
tions , but h i s  l a te r  s y s  terns did not . 
P e t r i c k '  s c u r r e n t  parser, p a r t  of the REQUEST sys  tern, 
is mu& closer in overaL1 s t r u c t u r e  to the MITRE design, 
A s e t  o f  p o t e n t i a l  surface s t r u c t u r e  trees are o p e r a t e d  
upon by a reverse t r a n s f o r m a t i o n a l  component consis*ing of 
tree r e w r i t i n g  rules. The reverse t r a n s f o r m a t i o n s  are 
prepared manually, n o t  ob t a ined  automatically from corres- 
ponding forward transformations. The c o n d i t i o n s  on t h e  
r eve ree  tra,nsformations are s u f f i c i e n t l y  t i g h t  t o  o b v i a t e  
t h e  need for o p t i o n a l  reverse t r a n s f o r m a t i o n s .  As a result, 
they are able t o  operate e f f i c i e n t l y  with a moderate ly  large 
set of reverse transl?ormations (about  " 130) . 
Once a11 r e v e r s e  t r ans fo rma t ions  have been a p p l i e d ,  t h e  
r e s u l t i n g  structures n u s t  be checked t o  de termine  which are 
va l id  deep s t r u c t u r e s .  I f  t h e  reverse t r an s fo rn~a t i ons  work 
on trees, each tree must be examined for productions not 
i n  the base component. I f  t h e  r e v e r s e  t r a n s f o r m a t i o n s  work 
on strings, each string musk be parsed u s i n g  the base 
component. 
The o r i g i n a l  P e t r i c k  and MITRE procedures envisioned 
a f i n a l  syn t .hes i s  phase .  T h i s  phase would apply  t o  each 
deep s t r u c t u r e  produced by t h e  r e v e r s e  t r a n s f o r m a t i o n a l  
component. I t  would apply t h e  corresponding forward transf or -  
mations t o  determine whether  the o r i g i n a l  sentence can be 
recovered;  i f  it canno t ,  t h e  deep structure i s  rejected. 
Such a .check is necessary i f  t he  reverse t r a n s f o r m a t i o n s  can 
produce deep s t r u c t u r e s  which do n o t  lead-back to t h e  o r i g i n a l  
s e n t e n c e  and perhaps do n o t  lead t o  any s e n t e n c e  a t  a l l .  Th i s  
is c e r t a i n l y  the case with t he  r e v e r s e  t r ans fo rma t ions  applied 
t o  s t r i n g s ;  such  t r a n s f o r m a t i o n s  are unable  t o  capture many 
c o n s t r a i n t s  p r e s e n t  when app ly ing  the fomard  t r a n s f o r m a t i o n s  
t o  trees. I t  can a l s o  be true with reverse t ransformat ion ' s  
working on trees, i f  the  c o n s t r a i n t 9  on the r e v e r s e  t r a n s f o r -  
mations are t o o  l oose .  With r e v e r a  transforinations on trees, 
however, i t  should be p o s s i b l e  t o  formulate c o n s t r a i n t s  
s u f f i c i e n t l y  tight as t o  obviate t h e  need f o r  a synthesiq phase. 
A s y n t h e s i s  check i s  o p t i o n a l  in the c u r r e n t  P e t r i c k - P l a t h  
s y s t e m .  Ins tead of app ly ing  the forward t r a n s f o r m a t i o n s  i n  a 
sepsrate synLhes i s  phase a f t e r  a deep s t r u c t u r e  is o b t a i n e d ,  
however, they a r e  appl ied  d u r i n g  ana lys i s  a f t e r  each corrcs- 
pond j n g  i n v e r s e  t ransformation is app l ied .  
THE PROCE,D,UKE 
We p r e s e n t  below a SETL ver l l ion of one of Petrick's e a r l y  
trans f a r n a t i o n a l  parsers .  As was noted e a r l i e r ,  t h i s  algo- 
rithm is of i ~npor t ance  because it is t h e  o n l y  procedure which 
can work d i r c c t l y  from a forward transformational gramlear. 
The SETL program h a s  bcen adapted from t h e  L I S P  p r v y r ~ m  devel -  
oped by P e t r i c k  at the A i r  Force Cambridge Research 1,aboratories 
(1966) , and is somewhat s i m p l e r  t h a n  the v e r s i o n  p re sen ted  
i n  Petrick's t hes i s .  I n  p a r t i c u l a r ,  the 1 9 6 6  version preserves 
no t ree s t r u c t u r e  between reverse t r ans fo rma t ions .  
Considerable l i b e r t y  has  bcen taken in r e w r i t i n g  t h e  
program f o r  p r e s e n t a t i o n  here. Features  which were not deemed 
e s s e n t i a l  t o  an understanding of the b a s i c  procedure were 
dele ted .  S p e c i f i c a l l y ,  t h e  procedure  fo r  c o n v e r t i n g  Iolwirr-d 
to reverse t r ans  formations was not i n c l u d e d ;  i d e n t i t y  condi- 
tions in transformations were not p r s v i d e d ;  o p t i o n a l  d e n r e n t s  
i n  s t r u c t u r a l  indices twrc not allowed. On t h e  o ther  h a n d ,  
the gross flow o f  c o n t r o l  of the L I S P  program has bcen p r e se rved .  
The main procedure of t h e  pa r se r ,  XFPARSE, t a k e s  f i v e  
arguments : 
SENTENCE the string to be analyzed 
XFMiiI the set of reverse t r a n s f o r m a t i o n s  
iq UEVXFMN S the number of transformations 
BASEGR the ( c o n t e x t -  free) base component  
AUXRULES the a d d i t i o n a l  rules which m u s t  be 
added to the base component to form 
the c o v e r i n g  grammar 
The context-free grammars have t he  form described in Sec. 3.1. 
Each trans formation has t h e  fb l lowing components : 
XFMN (i ,'ISIf ) inverse  s t r u c t u r a l  index 
XFNY (i, 'NAME') name of transformation 
XFMH (i", ' TYPE ' ) type of transformation : 'UNARY' 
o r  ' BINARY' 
if t h e  t r ans fo rma t ion  is unary, it a iso 'has  t h e  component 
XFMN (it ' I S C ' )  i n v e r s e  s t r u c t u r a l  change 
if t h e  transformation is binary ,  the inverse  s t ruc tura l  change 
w i l l  con ta in  a p a i r  of sentence boundary markers, with the 
component sentence i n s i d e  the markers and t h e  matrix 
sentence outs ide (the general form is m m m # c c c #.m m m , 
with the m ' s  p a r t  of the matrix sentence and t h e  c ' s  
part of the component) . For the parser, it is more 
convenient  t o  represent this as two separate t u p l e s ,  
one with t h e  boundary markers and the  elements between 
them replaced by the symbol 'COMP' ( m m m 'COMP' m m m ) 
the other w i t h  the e l e m e n t s  between t h e  markers ( c  c c )  
I n  the t r a n s f o r m a t i o n ,  these are components 
XFm (i, 'ISC-MATRIX' ) i n v e r s e  s t r u c t u r a l  change for mat r ix  
s e n t e n c e  
i n v e r s e  s t r u c t u r a l  change for  
component: s e n t e n c e  
The value of XFPARSE is a s e t ,  with each e l e m e n t  g i v i n g  
one p o s s i b l e  deep S t r u c t u r e  f r o n t i e r  f o r  the s e n t e n c e ,  and 
the  reverse transformations which were app l i ed  t o  o b t a i n  
t h a t  deep s t r u c t u r e .  T o  determine whether  these are i n  f a c t  
deep structures f o r  the sen tence ,  it would be necessary to go 
through the generat ive t ransformat ional  phase f o r  each 
po ten t i a l  deep s t ruc ture  and v e r i f y  t h a t  t h e  o r i g i n a l  sentence 
can be obtained. 
I f  t he  deep structure contains no embedded sentences, 
t h e  s t ructure  of an element in t h e  re turned  s e t  is 
< d e e p - s t r u c t u r e - f r o n t i e r ,  trans format ions-appl ied> 
where deep-s t r u c t u r e - f  r on t i e r  i s  a t u p l e  whose elcmcnts a re  
t h e  symbols in the f r o n t i e r  of we possible deep s t ructure.  
Transformations-appl ied is a li,~llplo whose clcmcnts are the 
transformations appl i cd  t o  ob ta in  ' t h i s  deep structure ; the  
first elenlent g ives  t h e  lust  t ransformation app l ied  in t h e  
decomposition, and hence t h e  f i r s t  which would bc  app l i cd  in 
gcrleration. I f  tihe deep s t ruc tu re  colitains an cmbcdded sen tcnce , 
the  element w i l l  s t i l l  be a p a i r  as j u s t  described; 
deep-structure-f rontier, however, w i l l  not incltida as elements 
two boundary markers and t h e  intervening cl~beddcd suntence. 
Instead a t  t h a t  p o i n t  in t h e  t u p l e  will bc an elenlent which 
I s  itself a p a i r ,  w i t h  t h e  f i r s t  element t h e  f r o n t i e r  cf t h e  
embedded sentence and  the second the  t r a n s f ~ r m a t i o n s  a p p l i e d  
to decompose the enbedded sentence. The transformations-applied 
e lement  of the t op - l eve l  p a i r  w i l l  i n c l u d e  o n l y  t h e  embedding 
t ransformation and t h e  t r a n s f o r ~ n a t i o n s  a p p l i e d  t o  t h e  s e n t e n c e  
before it was d i v i d e d  i n t o  m a t r i x  and c o n s t i t u e n t .  
S ince  each reverse t r ans fo rma t ion  is o p t i o n a l  and may 
apply i n  several ways,  there will u s u a l l y  be n~dny p a t h s  t o  
follow d u r i n g  t h e  decon~posit ion process .  I n  XFPARSE, each 
such pa th  is recorded as an elenlent in the s e t  TODO; t h e  
element i s  a f ronbt ier , 'h is tory  p a i r ,  j ust l i k e  those  produced 
as o u t p u t .  The main loop o f *  t h e  pa r se r  runs over t h e  trsns- 
formations. For each clement TODO, if t h e  t r ans fo rma t ion  
a p p l i e s  all poss ib l e  transforms of t h e  e l e m e n t  are added t o  
TODO; since t h e  t r a n s f o r m a t i o n  is o p t i o n a l ,  t h e  o r i ~ i n a l  
e l e m e n t  remains as well. When an inve r se  embedding transforma- 
t i o n  appl ies ,  XFPARSE i s  ca l l ed  recur s ive ly  to deco~~~pose  th
embedded sentence. 
de f i n e  f XFPARSE (SENTENCE , XFMN , NUMXFMNS , BASEGR , AUXRULES ) ;
local  TODO, DONE, PARSES, SGRAMMAR, XFMNNO, CONT, SEiOT, XFAPPLD, 
MATCHSET, MATCH , COMPPARS ,, ROMP MATRIX, P ; 
WNE = { <SENTENCE, n u l t >  1 ; 
PARSES = nk; 
/ *  compute covering grammar */b 
SGRAMMAR = BASEGR CJ AUXRULES ; 
/* i te ra te  over transformations */ 
( 1 <= Y X F ~ N O  <= NUMXFMNS) 
TODO 1 =  DONE ; 
DONE = nR; 
/* i t e ra te  over active c o n t i n u a t i o n s  */  
(WONT E TODO) 
SENT = CONT (1) ; 
XFAPPLD = CONT ( 2 )  ; 
MATCHSET=PROCES (SENT, XFMN (XFMNNO , ISI ) ,1, SGRAMMAR) ; 
/* i terate over matches to s t r u c t u r a l  i ndex  */ 
(YMATCH E MATCHSET) 
if XFMN (XFMtJNO , ' TYPE ' ) eq ' BINARY' then 
/ *  fo r  b inary  transformatibns, f i rs t  t r y  
to ana lyze  embedded sentence * /  
COMl?PARS=XFPARSE (IMPOSE (MATCH, XFMI ( 
XFJ!GJNQ, ' ISC-COMP ' ) ) , XFMN , XFMNJO, BASEGR, 
AUXRULES) ; 
/* i t e ra t e  over  analyses o f  embedded 
sentence, adding m a t r l x  with analyzed 
embedded sentence to con t inua t ions  */ 
CVKOMP E COMPPARS) 
MATRIX=IMPOSE (MATCH ,XFMN (XFMNNO , 
' ISC-MATRIX' ) ) ; 
<MATRIX, <XFMiWO> -t XFAPPLD> in DONE ; 
end YKOMP; 
else /* unary transformation */ 
/* add t ransformed sen tence  to c o n t i n u a t i o n s * /  
NEWSENT = IMPOSE (MATCH, XFNJ ( X F K ~ L \ I ~ ,  ' ISC ' ) ) ; 
<NEWSENT, <XFMiVNO> + XFAPPLD> i n  DONE ; 
end VMATCH; 
/"include untrans formed sentence i n  cont inua t ions ,  
since reverse transformation is o p t i o n a l  */ 
CONT i n  DONE; 
end VCONT; 
e n d  1 c= V XFMNdO ; 
/"fi lraransfo~.mations h a w  bcon t r i o d  */ 
/* se lec t  and return those s t r i n g s  Which can be 
analyzcd by t h o  base  component */ 
t - 1  return {PCDONE~ PARSE ( D A S R G R ,  b ,P (1) ) n e  n $ )  ; 
cnd XFPARSE; 
Most of t h e  work of t h e  parser  is done by t h e  two Eout ines  
PROCES and IMPOSE, PROCES matches cv- ran t  s t r i n g  a g a i n s t  
t h e  inverse  s t r u c t ~ i r a l  i n d e x ,  a n 1  IMPOSE con~putes t h e  e'flfect 
of t h e  inverse structural change.  
PROCES t a k e s  four  arguments : 
SENTENCE 
STARTWD 
the s t r i n g  t o  be matched 
t h e  structural i n d a x  
t h e  number o t h e  f ixst  word in t h e  
s t r i n g  t o  be matcl~ed by t h e  s t r u c t u r a l  
index ( , th i s  argument i s  required 
because the procedure operates 
recursively;  its va lue  i s  1 f o r  
c a l l s  from XFPARSE) 
t h e  context- f ree  gl-anmar used in 
matching t h e  s t ruc tuxa l  index to 
t h e  s t r i n g .  
The  value of PRQCES i s  a set, w i t h  each e l emen t  giving one 
match of t h e  s t r u c t u r a l  index  t o  the s t r i n g .  Each e l e m e n t  
is a f o r e s t ,  .i.e. , a t u p l e  of t rees,  where each tree is 
represented as described in Sec. 3.1~. The 11th tree of t h e  
f o r e s t  h ~ s  as i t s  root Symbol the n t h  e l e m e n t  of the 
s t r u c t u r a l  index.  Success ive  trees subsume contiguous 
segments of the s t r i n g  b e i n g  matched. The fol lowing xou t ine  
d i f f e r s  from Petrick's r o u t i n e  of thg same name in u s i n g  
recursion instead of iteration. 
def i n e f  PROCES (SENTENCE, SI ,STARTWD, GRAMMAR) ; 
local R, RMDRSI, MATCHES, EI\;IDWD, P ,  PI, RMDRMATCH, PARSES; 
/* s p l i t  off  first e l e m e n t  of structural i n d e x  * /  
R = hd SI; 
W R S I  = tl SI; 
/* parse part of remainaer of s e n t e n c e  w i t h  t h i s  e lement* /  
PARSES = PARTPARSE (GRAMMAR I R ,  SENTENCE STARTWD) ; 
MATCHES = nR; 
(VP E PARSES) 
* s e t  ENDWD = next word in sentence to be matched * /  
ENDWD = P (1, ' LW+ll ) ; 
if RMDRSI eg n u l t  t h e n  
/* if at e n d  of s w i m ,  accept parse tree for last 
element  of s.i. on ly  i f  it extends to e n d  of 
sentence */ 
if ENDWD eq ( (#SENTEiJCE) + 1) t hen  
<P> in MATCHES; 
end if ENDWD; 
else / *  not ak end of s. i. , c a l l  P R O C E S  recurs ive ly  
to process next e lemen t  */ 
RMDRMTCH = PROCESS (SEIITENEE ,RMDRSI: , ENDWD , GRAMMAR) ; 
/* concatenate parse  tree for current e l e m e n t  
to each forest of matches t o  succeeding elements*/  
( YM E RMDRMTCH) 
<P> + M in W C H E S ;  
end RMDRMTCH ; 
end if RMDRSI; 
end VP PARSES;  
re turn MATCHES ; 
end PROCESS, 
The t r ans fo rma t iona l  parser  uses two varieties of 
context-free pa r se r .  The f i r s t ,  ca l l ed  s imply  PARSE, 
has  the external specifications g i v c n  in Sec. 3J.A. Tho o t h e r ,  
PARTPARSE, d i f f e r s  in three respects : 
1. t h e  r o u t i n e  takes  a f o u r t h  aryumant,  STARTWD, 
s p e c i f y i n g  t h e  f i rs t  word in t h e  s e n t e n c e  to be 
matched by the parser (p tccod iny  words am i g n o r e d )  ; 
tho r e tu rned  value  includes parse trccs which do not 
ex t end  to the end of t h e  sentence. 
2. if t ho  s p e c i f i e d  koot symbol is ' X' tbc r o u t i n e  
creates a s e t  of parse trees, each containi~qj a 
single node, named X, s p a ~ l n i n g  a l l  possible 
s u b s t r i n g s  with f i r s t  w6rd = STARTWD 
3. the sfmbol COMP w i l l  match an element of t h e  s t r i n g  
which i s  a t u p l e  ( s i n c e ,  as noted e a r l i e r ,  an embedded 
s e n t e n c e  is represented as a t u p l e ) .  
The f irst  two changes are  ef fec ted by + i lod i fy i r~g  the main 
r o u t i n e  of the f i r s t  parser  p r e s e n t e d  in Sec. 3.1. 
de f i n e  f PARTPARSE ( G I I A ~ A R ,  ROOT, SEW'PEACE sTARTII'D) ; 
l o c a l  P A R S E S ,  TREE, iJODES, IVORD, LW; 
i f  ROOT eq 'X' t hen  
r e t u r n  1 ,  'NAME', X I > ,  <1,'FW1,STARTWD>, <l,'~~+l',~\d+l>}, 
(STARTWD~~) <= LW <= !!SENTENCE} ; 
e n d  if ROOT; 
if STARTWD gt #SE~JQENCE t h e n  r e t u r n  nP,; end  if STARTWD; 
TREE = nR; 
PARSES = nR; 
WORD = SqhRTWD; 
NOUES = 1; 
T R E E ( ~ , ~ N A M E ~ )  = ROOT; 
TGE(1,'FW') = 'rJORV; 
( w h i l e  @ X P h ? D  (1 ,GRAMMAR,SENTENCE) ) 
PARSES = PARSES u {TREE 1 : 
end while EXPAND; 
recurn PARSES ; 
end PAR'fPARSE ; 
The third change is accomplished by modifying one line in the 
EXPEL\ID rou t ine  of the f i r s t  parser in Sec. 3.1. The l i n e  
which t e s t s  for  a match aga ins t  t h e  current sentence word is 
changed from. 
i f SENTENCE ( W O W )  eq TREE (X , 'NAME ' 9  
to 
if (SE:JTEtJCs (WORD) eq TREE (X , ' NAME ' ) ) 
or 
( ( t y p e  SENTENCE (YJORD) aq t u p l )  and 
(TREE (x,'NAME1.) eg ' C O M P ' )  ) 
IMPOSE, which computes the ef fec t  of the s t r u c t u r a l  
change, is a r o u t i n e  w i t h  two arguments. 
FQREST is a t u p l e  of trees r ep re sen t ing  t h e  
match to the s t r u c t u r a l  index (one 
element of t h e  value r e t u r n e d  byL 
PROCES) 
SC is t h e  s t r u c t u r a l  change component 
o f  a t ransformat ion 
In add i t ion ,  KOMP , which ( f o r  b i n a r y  t r a n s  formations) holds 
the embedded sentence and i t s  t r ans fo rma t iona l  h i s t o r y ,  is 
passed from XFPARSE to IMPOSE as a g loba l  variable.  IMPOSE 
returns a t u p l e ,  t h e  f r o n t i e r s  of t h e  trees in t h e  fores t  
as rearranged in accordance w i t h  t h e  s t r u c t u r a l  change. 
de f ine f  IMPOSE (FOREST ,SC) 
local  I; 
r e t u r n  [+: I E SC] 
if ( t y p e  I) eq i n t  then  FRONTIER(FOREST ( I )  )
e l se  if I eq 'COMP'  then CKObJP, 
G ~ S C ?  <I>; 
and IMPOSE; 
The f u n c t i o n  FRONTIER takes  as its a r g u n ~ e n t  a t ree  and r e t u r n s  
t he  f ron t i e r  of t h e  t ree.  S i n c e  t h e  root= node of t h a  trcc 
s p e c i f i e s  tho words s p n ~ r n c d  in t h e  sentence ( v a r i a b l e  Si7J4T, 
t ? ~ 6 ~ ~ 3 a ~ ? d  ~ ; Z I  XFPAWE)  t h i s  i s  t r i v i a l :  
de f i n &  FRQNrTLER(TREE) ; 
l oca l .  F N s  L'CVPJ,; 
~ : C J  = TREE (1, ' F I ~ J ' )  ;
E S ~ P ~  = T R E E ( ~ , . ~ L W + ~ ~ )  ; 
r e t u r n  SENT (FF.7: LWP1-FW)- ; 
end FROLITIER; 
84 
Rppendix. A Very Short I n t r a h c t i o n  to SETL 
(Prepared in collaboration with Norman ~ u h i n ,  CIMS . ) 
SETL is a programming lwguage designed aro set-theoretic 
structions and developed at NYU by a group l ed  by Jack2Schwartz. 
rich set of operators and control structures provided in 
SEZL are intended to make the specif icat ion of algorithms 
coneiderably easier i n  SETL than in other h i g h e r - l e v e l  languages. 
To fac i l i ta te  the reading o f  our  a r t i f i c i a l  inteliigerlce surveys, 
ua have used only a subset af SETL; this subset is described in 
pages which follow. Those few %points where we haw deviated 
a true SETL subset are marked on the left with  asterisks and 
mated at the end of this section. 
mer information on SETL is available i n  
J. T. Schwartz, On Programming: An Inter im Report on the 
6 Project, Parts I and XI. Courant Computer Science Notes, 
Cowant Institute of Mathematical Sciences, New York Univ. 
X. Kennedy and& Schwartz, "An  Introduction to t h e  S e t  
retical Language SET& " Comp. and Math. w i t h  Appl . - 1 9 7 .  
Wuch of the expression semantics of SZTL is modeled on that  
wed @in the mathemakical theory of s e t s ,  and many of the syn tac t i c  
ca~~entlans used reflect n o t i o n s  which are s tandard in t h a t  
theory. However, for  p r o g r a m m i n ~ u r p o s e s  a s e t  theory inc lud ing  
atoms which tnemselves have no nemrs b u t  may freely be 
@ers of sets is more conveniegt ban pure s e t  theory. Thus 
SETL contains both a general d a t h  vb j e c t  ( the  s e t )  and other 
operationally more eff icient  s tructures known as atoms ; among 
these i s  a vector-like object known as a t u p l e ,  
Atoms 
-
(1) 
12) 
( 3 )  
( 4 )  
( 5 )  
i n t e g e r s  (.1276) 
character  s t r i n g s  ('hel.10, pally ' ) 
b i t  strings (10101b) 
boolean c o n s t a n t s  ( t r u e  l b r  fa lse  E Ob) 
b l a n k  atoms (created by the f u n c t i o n  NEWAT, t h e  SETL 
equ iva l en t  of the L I S P  GENSYM) 
Q ,  the undef ined  atom 
labels ( labels  precede s tatcments , separated by a colon) 
subroutines and funct ions 
t u p l e s  (one-dimensional a r r a y s  of var iab le  l e n g t h ;  i. e . ,  
ordsred l ists;  w r i t t e n  as < 1 r  2, ' threeJ> ; the n u l l  tuple 
is designated nult) 
Sets 
are unordered co l l ec t ions  of elements, w r i t t e n  as {1,2, ' th ree '  ) 
:he null s e t  is des ignated  nR 
Oper at OPS 
In tegers  
arithmetic + * , comparison (eq,ne, it, gt, lc, gel 
max,min, abs 
Booleans 
and, or, hot (abbrev ia ted  n) , cq, ne 
Character and b i t  s t r i n g s  
concatenatiton * ( + I ,  Length # , s u b s t r i q q  ( S ( 1 : K ) .  i s  t h e  
s t r i n g  of l e n g t h  X s t a r t i n g  w i t h  the I t h  e l emen t ,  l i k e  
t b ~  PL/ I  s & s t r i n g  f u n c t i o n )  
Tuples  
A t u p l e  is a sequence of components Cl, ,C2,C3,.  . . , all b u t  
a f i n i t e  number of which are equa l  to R ,  the undef ined  atom- 
(1) T (K) is the  Kth component of T 
( 2 )  T ( 1 : K )  is the t u p l e  of l e n g t h  K s t a r t i n g  w i t h  t h e  I t h  element 
( 3 )  #T ds t h e  index of the last def ined  component of T 
( 4 )  hd T E T ( 1 )  
tR T I T(2:(#T-1)) 
T -+ U i s  t h e  c o n c a t e n a t i o n  of tuples T and U 
Tuples  are o f t e n  used as push-down s tacks ,  using 
T ( # T t l )  = X t o  push X on the stack and T(#T) = 8 to 
pop the  stack.  
S e t s  
X E. S ( t r u e  i f  X i s  an e l e m e n t  of X, otherwise f a l s e )  
arb S (an arbitrary element o f  se t  S )  
4 u B (union of s e t s  A and B )  
A (7 B ( i n t e r s e c t i o n  of se t s  A and B) 
A' / B (symmetric d i f f e r e n c e  o f  se$s A and B). 
A - R (difference, set) 
#S (numbernof  e l e m e n t s  i n  s e t  S )  
A w i t h  B 2 A U (B) 
- A less B = A w -  {B} 
sets may be compared u s i n g  eq, ne, i n c s  ( in ' c ludes )  
Precedence 
There. are ;three levels of p recedencz :  
(1). (highest b u i l t - i n  binary operators proiucing Boolean 
from non-Boolean values (eq, n e ,  lt, gt, le, ge, i n c s ,  E) 
( 2 )  unary operators. - 
( 3 )  other  binary operators 
Within each level, e v a l u a t i o n  i s  le f t - t o - r i g h t  . 
Set ~ e f i n i t i o n  
A s e t  may be def ined  by enumeration IA,B,c} or by a set-former: 
{ E X P R ( X ~ ,  .. . , X ) , range- res t r i c t ion  I c (X . . ,-X ) } n l* n 
which forms the set o f  values EXPR(,X1,. . . ,Xn) for  those 
X1 , . . , within the range-restr ict ion for which C ( X  . . . ,X ) n 1 ' n 
is t r u e .  The range-restriction is  a series o f  items, one fo r  
each of the X of t h e  form i 
For example,  
Two abbreviated forms are allowed: 
{ X  E S I C(X)] foe, I x , , X  E S I ' C ( X ) I  
and 
IEXPR(X)  , XES} for {E?xPR'(x) , , ~ ~ ~ $ t i p e }  
Conditional Operators 
i f  BOOL then EXPRl e ~ . j e  EXPR2 
has  t h e  value EXPR1 if BOOt is true, the va lue  EXPR2 if.BOOL i.s 
false.  The e lse  is cons ide red  a unary  operator ,  so tha-t;. 
i f  X gt 0 t h e n  Y else X + Y 
is ana lyzed  as 
(if X gt 0 t h e n  Y else X) + Y 
Func t iona l  Application and Sets 
If F is a s e t  and A any s e t  or atom then  
(1) F{A] (if #P gt 2 t h e n  tR P else P ( 2 )  , P E F I 
( "P  is a tuple") and (#P g t  2 )  and ( P  (1) eq A) 1 
e .g . ,  if F is a s e t  of pairs ,  F{A) is the set  of a l l  X 
such t h a t  <A,X> E F. 
( 2 )  F ( A )  if #F{A} eq 1 then grb F{A) else $2. 
i . e . , the unique image of A under F. 
( 3 )  F [A] z the union of t h e  elements of F I A } .  
S e t s  are o f t e n  used to d e f i n e  complex mappings. For ins tance ,  
F = {<111>,  < 2 , 4 > ,  < 3 , 9 > I r  
or a l t e r n a t i v e l y  
F ( 1 )  = 1; F ( 2 )  = 4 ;  F ( 3 )  = 9; 
d e f i n e s  a set  mapping the first three i n t e g e r s  i n t o  their 
squares. In either case, F ( 1 )  is 4 and F ( 4 )  is Q. 
Q u a n t i f i e d  Boolean Expressions 
The basic  forms for  q u a n t i f i e d  boolean express ions  are 
The first: is t r u e  if C (x) is t r u e  fo r  some x in s ,  and f u r t h e r -  
more s e t s  x to the f irst  value found far which C (x )  is t rue ;  
the second is true if C(x) is true f o r  all x in s .  Several 
range restrictions may be combined: 
The alternate, numerical, forms of range res t r i c t ions ,  such as 
min - < 3 x - < max and min - < Vx - < max, . may also  be used. 
Compound Operators 
Co-mound operatogs 'hdve the form 
lop: range-restrict ions I C (Xlr . . . , X,) ] EXPR ( x ~ ,  . . ,X ) 
n 
where op is a binary operator and the range-restr ic t ions have 
the form described earlier.  The value of this expression is 
t h e  value of variable VALUE after execut ing:  
PILE = ~ E X P R ~ X ~ ,  . . . , X ) , range-res t r i c t i o n s  I C (XI,. . . , X ) 1 ; n n 
VALUE from P1.W; 
(while PILE ne nR) 
X from PILE;  
'VALW = VALUE op X; 
end while P ~ L E ;  
For example, 
[max: X E 1 1 r 2 t 3 1 1  (X+1) is 4 
K 
S t a t e m e n t s  
__/ "" 
All statements are terminated by a semicolon. 
Assignment 
A = EXPR; 
< A r B , C >  = EXPR; is the same as A=EXPR(l) ;B=EXPR(2) ;C=EXPR(3) t 
Assignment may a l s o  be done with t h e  operator "is": 
"EXPR is V" is an expression w i t h  value &XPR 
and the side e f f e c t  of a s s i g n i n g  t h i s  va lue  to V 
X i n  S; is S = S w i t h  X ;  
X from S; is X=avb S; S = S lcss X ;  
X out S; is S = S less X; 
Trans fe r  
go to LABEL; 
Conditional 
if BOOLl t h e n  BLOCK, else if BOLL2 t h e n  ... else  BLOCK ; 
n 
~teration 
(while BOOL) BLOCK; 
(vxl Sit X2 E S2(X1),.-.I~(~1t-.-t X n ) )  BLOCK; 
(M - < YX - < N )  BLOCK; 
(N - > VX > M) BLOCK; 
- 
etc. 
Scope of Conditionals and I terators  
The BLOCK i n d i c a t e d  above as t h e  scope of a SETL condi- 
t i o n a l  s t a t e m e n t  ,or i t e ra to r  is any sequence of SETL s t a t e m e n t s .  
Note that the semicolon terminatir~g the block i s  in a d d i t i o n  t o  
the semicolon terminating the final statement of that block. 
This semicolon may be replaced by an end statement such as 
end V ;  end VX; end while; end while BOOL; to indicate  
to t h e  reader which scope is being closed. 
Ex.: 
(1 - VX - < 100 I P ( X ) )  Y(#Y+l) = X ;  end VX; 
if Y gt O then S = S w i t h  X ;  else N = N i - 1 ;  end  if Y ;  
Output  
print EXPR1,EXPR2,. . . ,EXPRn; 
Subrou t ines  and Functions 
Subrou t ines  
defined by define SUB(X,Y,Z); BLOCK end SUB; 
invoked by SUB ( A , B ,  C) ; 
exit from subroutine by return;! 
Functions 
d e f i n e d  by def inef  FCN ( X , Y ,  Z) ; BLOCK end FCNr 
invoked by FCN(A,B,C) 
e x i t  from f u n c t i o n  by r e t u r n  EXPR; 
I n f i x  operator  d e f i n i t i o n  
defined by X i n f i x o p  Y; BLOCK end A i n f i x o p  B;  
Scoping 
loca l  X , Y ,  Z; def ines  X , Y ,  and Z as loca l  to the  
c u r r e n t  subrout ine  or f u n c t i o n  ( these variables are 
allocated on entry to the routine). Name scoping is 
dynamic, as in LISP;  a var iable  declared loca 1 by 
procedure p is availale to all procedures invoked by p 
which do not themselves declare the variable loca l .  Thus 
d e f i n e  P; 
l o c a l  X; 
Q(1) ;
p r i n t  X ;  
r e t u r n ;  
end $; 
d e f i n e  Q ( Y )  ; 
x = 7;  
return; 
end Q ;  
will p r i n t  a 1. 
Differences  from Standard  --- SE'rL 
S tandard  SETL uscs a somewhat smaller character set than we 
have adopted in t h i s  survey .  Thus  -t (addition), -+ ( c o ~ ~ c a t c n a -  
t i o n )  and U ( u n i o n )  Are all w r i t t e n  as + i n  s t a n d a r d  SETL; 
* (multiplication) and  n (intersection) are w r i t t e n  as *. 
We have adopted the simple and familiar name-scoping rules 
of the current SETL irnplen~entatiorl in place of the relatively 
con~plex  ones of t h e  SETL s t a n d a r d .  
iVe have w r i t t e n  a l l  va r i ab l e s  f u n c t i o n  n i ; m e s ,  and  s ~ b r o u t i n  
n a m e s  i n  upper case, opera tor  names and other t o k e n s  in lower case. 
BIBLIOGRAPHY 
[Aho 19721 A.  V. Aho and J. D. Ullrnan. The Theory of 
Parsing, Trans l a t i on ,  and Compiling, Vol- I. 
Prentice-Hall, Englewood C l i f f s  , N. J. 
[ B o b r w  19691 D. Bobruw and B. Fraser, "An Augmented S t a t e  
T r a n s i t i o n  Network Analysis Procedure, " Proc. 
International J o i n t  Conference on A r t i f i c i a l  
I n t e l l i g e n c e  
[Borgida 19 751 Alexander  Borgida, Topics in the Understanding 
of English Sentences by Computer. Tech. Rep. 78, 
Dept. of Computer Science, Univ. of Torsn to .  
[Bross 19681 Irwin Bross; "A S y n t a c t i c  Formula f o r  English 
Sentences : Application t o  S c i e n t i f i c  Narrative, 1 t 
Cornpu2ers and Biomedical Research 1, 565 .  
[Cautin 19691 Harvey Cau t in ,  Real Eng l i sh :  A Transla tor  to 
Enable N a t u r a l  Language Man-Machine Conversation. 
Thesis, Moore School of ~ l e c t r i c a l  Engineering, 
Univ, of Pennsy lvan ia  . 
[Cocke 1970 1 J. Cocke and J. T. Schwartz, Programming Languages 
and their Compilers.  L e c t u r e  Note series, Courant 
I n s t i t u t e  of Mathematical Sciences ,  N e w  York Univ; 
[Culmerauex 19 70 1 Alain Colrnerauer , " ~ e s  S y s  terns-Q ou un 
formalisme pour analyser et synthe  t i s e r  des phrases 
sur o r d i n a t e u r .  P u b l .  i n t e r n e  no. 4 3 ,  ~ a c u l t e '  
des sciences, ~ n i v e r s i  te' de ~ o n t r e ' a l .  
[Craig 19661 J. A- Craig, S .  C. Berenzner ,  H. C. Carney, and 
C. R- Longyeart "DEACON: D i r e c t  English Access 
and Control. " Proc- 1966 Fall Joint C o m p u t e r  Conf., 
Thompson Books,  Washington, D. C. 
ICuliQgver 19691 P. Cul icover ,  J. K i m b a l l ,  C. Lewis, D. Loveman, 
J. Moyne, An Automated Recognit ion Grammar for  
E n g l i s h ,  IBM Technica l  Repor? ZSC 69-5007. 
Cde Chastellier 1969 ] G. ae C h a s t e l l i e ~  and A .  Colrnerauer-, 
"W-Grarpmar ,  I I Proc. 2 4  f l a f i o n a l  ~ 6 n f .  Assn. for 
C o m p  . Mach. . 
[ D e w a r  19691 HI D e w a r ,  P. Bratley,  and J. P. Thorne, "A Program 
f o r  t h e  S y n t a c t i c  Analysis of E n g l i s h  Sen tences ,  " 
Cornm. Assn. Comp. Mach. 12, 476. 
[Dostert 19711 B. D o s t e r t  and F. Thompson, "How Features Resolve 
S y n t a c t i c  Ambiguity," Proc* Symposium on Information 
Storage and Retrieval. 
[Earley 19 701 J. Earleyr "An E f f i c i e n t  Context-Free Parsing 
A l g o r i t h m .  Camm* Assn-  Cornp- Mach. 13, 9 4 .  
i ~ r i s h m a n  1973a] R a l p h  Grishman, "~mplementation of the S t r i n g  
Parser of E n g l i s h ,  " i n  N a t u r a l  Language P r o c e s s i n g ,  
ed. R.  R u s t i n ,  A l q o r i t h m i c s  Press ,  N e w  York. 
[Grishman 1973bJ R. Grishman, N .  Sager, C. Raze, and B. Bookchin,  
"The L i n g u i s t i c  S t r i n g  Parser. " Proc. 1 9 7 3  N a t l ;  
Computer Conf. , AFIPS Press, Montvale ,  N . J. 
[Xarris AS) 651 Z e l l i g  Harris, String ~nalysis of Sentence S t ruc tu re .  
Mouton, The Hague. 
[Hays 19671 David Hays I n t r o d u c t i o n  t o  Computa+ional Lingu i s t f  cs. 
A m e r i c a n  E l s e t r i e r ,  N e i J  Y o r k .  
[ H i 2  19671 D. Hiz and A. Jo sh i ,  "Transfomati 'onal  D e c o m p o s i t i o n :  
A Simple Description of an Algorithm for Transforma- 
t i o n a l  Analysis of E n g l i s h  Sen tences -  " 2'eme Conf. 
I p t e rna t idna le  s u r  le T r a i t e m e n t  Automatique des 
Langues , Gsenoble . 
[liobbs 19 $4 ] Jerry Hobbs , A Metalanguage for ~ x p r e s s i ~ g  
Grammatical R e s t r i c t i o n s  -in Nodal  Spans P a r s i n g  ~f 
Natural .  Language. Courant  Computer Science Report $2, 
Couran t  Inst. R a t h .  Sci ._ ,  N e w  York ~ n i v ,  
[Eiobbs 1 9 7 5 1  J. Hobbs and R. G r i s h m a n ,  "The Automatic. Transfbr -  
rnational Analysis of E n g l i s h  Sentences: An 1mplk- 
mentation." S u b m i t t e d  t o  Xnt'l J .  Conputer M a t n .  
[ ~ r o n s  19631 N .  Irons, "Error-Correct ing Parse Algorithm.. =om. 
Assn.  Comp. Mach. 6, 669. 
[~osh i .  19621 Aravind Joshi, A procedure for transformational 
decoinposition. Transformations and Discc~rse 
Analys i s  Pape-rs $ 4 2 ,  U n i t T .  of Pennsylvania ,  
[Joshi 19 331 Atavind Josh i ,  "A  C l a s s  of Tr,-;ulsformational Grammars " 
In The Formal Analysis of N a t u r a l  Languages* ed. 
MI Gross , M. Halle, and M. -P. Schiitzenberger, 
Mouton, The Hague. 
11 [Kay 1 9 6 7 1  Martin Kay, Experiments  with a powerfu l  Parser.. PI 
In 2 & m e  Conf. Internationale sur le ~ r a i t e m e n t  
Automat ique des Langues , Grenoble. 
[Keyser 19671 S. 5. Keyser and S .  R. p e t r i c k ,  s y n t a c t i c  Analysis * 
A i r  Force Cambirdge Research ~ a b o r a t o r i e s ,  
-WCRL-6 7-0 305. 
[ K i t t r e d g e  19731 Richard K i t t r e d g e  et al, TAUM 7 3 .  A report  
of the P r o j e t  de Traduction Automatique de I ' u n i v e r -  
sit6 de ~ o n t r g a l .  
[ K u n o  19621 S .  Kuno and A .  G. O e t t i n g e r ,  " ~ u l t i p l e - P a t h  S y n t a c t i c  
Analyzer." Information Processing 1962, North-Holland, 
Amstetdam. 
[Kuno 19631 Su$umo Kuno, "The M u l t i p l e - p a t h  S y n t a c t i c  Analyzer for 
English. " Report No. NSF-9 in Mathematical Linguistics 
and Automatic Translation of the  Computation L a b . ,  
Harvard Univ. 
[Kmo 19651 Susumo KWO, "The Predictive Analyzer  and a P a t h  
E l i m i n a t i o n  Technique."  Comm. Assn. Comp. Mach. 8, 
453.  
[Loveman 19711 D. Loveman, J. Moyne, and R. Tobey, "CUE: A Pre-  
processor S y s t e m  f o r  R e s t r i c t e d ,  N a t u r a l  E n g l i s h .  
In Proc. Symposium on Information S t o r a g e  and 
~etrieval. 
[Owens 1'9751 Phillip Owens, A Comprehensive Survey of Parsing 
A l g o r i t h m s  f o r  Programming Languages, Courant 
Computer Science R e p o r t  # 4 ,  Courant Inst. Math, 
Sci . , N e w  York Univ. (Forthcoming) . 
[Paxton 19731 W; H .  Paxton and A .  E .  Robinson, "A Parser f o r  a 
Speech ~ n d e i s t a n d i n g  System. " Advance Papers of the 
Third Intl. Join t  Conf. on ~ r t i f  i c i a i  Intelligence, 
S' tanford Research I n s t j t u t e ,  California. 
[ P e t r i c k  1965 ] S t q l e y  R e  P e t r i c k ,  A Recogni t ion Proceddre 
for  T r a n s  formational Grammars. Doctoral 
Disseztatf on . 
[ p e t r i c k  19661 Stanley R. F e t r i c k ,  A i r o g r a m  for Transformational 
S y n t a c t i c  Analysis, Air Force Cambridge Research 
Laboratories, AFCRL--66-698.  
[ P e t r i c k  19731 S t a n l e y  R .  P e t r i c k ,  Trans fo rmat iona l  Analysis, II 
I n  Natural  Language Processing, ed. R. Rust in ,  
Algorithmics P r e s s ,  N. Y. 
[ P e t r i c k  19 75 I Stanley R .  P e t r i c k ,  "Design of the Underlying 
S t r u c t u r e  for a D a t a  Base Retrieval.  Sys t em.  " In 
D i r e c t i o n s  in A r t i f i c i a l  I n t e l l i gence :  Natural 
Language Process ing ,  ed. R. Gsishman Couran t  
C o m p u t e r  Science Report #7, C o u r a n t  Institute of 
Mathematical Sciences ,  New York  nit', 
[ P l a t h  19 74a] Warren J, Plath, "Transformational Gramcar and 
T r a n s  formational  P a r s i n g  in t h e  REQUEST Sys tern. " 
In Computa t iona l  and Mathematical Linguistics, Proc, 
I n t l .  Gonf. on Computational Linguistics, ed- 
A. Zampolli, 
[ P l a t h  1974b] Warren J*. Plath, String Transformations in t h e  
REQmST System. IBM TI J. Watson Research C e n t e r ,  
RC 4 9 4 7  (#21963). 
[ ~ a z e  19741 Carol Raze, A computatidnal treatment of c~osdinate 
conjunctions. T a l k  at 12 Ann. Meeting of Assn. of 
Computational L i n g u i s t i c s ,  Amherst, Mass., July 26, 
1974. 
[Sager  19 671 N a o m i  Sager ,  " S y n t a c t i ~  analysis of n a t u r a l  language. n 
In Advances in Computers,  No. 8, ed. F a  Alt and 
M. Rubinof f ,  Academic P r e s s ,  N. Y. 
[Sager  19731 N a o m i  Sager ,  "The s t r i n g  parser f o r  s c i e n t i f i c  
l i t e r a tu re  . " In N%tural Language P r o c e s s i n g ,  ed. 
R .  R u s t i n ,  Algorithmics P r e s s ,  N. Y. 
[Sager 19751 N .  Sager and R .  G r i s h m a n ,  "The Restriction Language 
for Co~mputer Gr&mars of N a t u r a l  Language. " Comrn. 
Assn- Comp. Mach. 18,390. 
[Shapiro 19711 P- Shapiro and D w  Stermole, "ACOEUl (Automatic 
Coder Report Narrat ive )  : An Automatied N a t u r a l -  
Language Question-Answering S y s t e m  for Surgicm 
Reports, " Computers and Automation, Feb. 1971, p .  13. 
[Simmons 19751 R. Simmons and G. Bennett-Wovak, "Semantically 
Analyzing an E n g l i s h  Subse t  for the C l o w n s  Micro- 
w o r l d ,  " Tech. Report  NL-24, D e p t .  of Computer 
Sciences,  Univ. of Texas at A u s t i n .  
[Thompson 19691 F. 9. Thompson, P. C. Lockenan, B. Dostert,  
and R. S .  Deveri l l ,  "REL: A Rapidly E x t e n s i b l e  
Language S y s  tern. " Proc. 24  N a t l .  Conf. Assn. 
Cornp. Mach. 
[Thorne 13681 J. P. Thorne, P. B r a t l e y ,  and H. D e w a r ,   h he 
S y n t a c t i c  Analysis of E n g l i s h  by ~achine. i t  
~ a c h i n e  I n t e l l i g e n c e  3. 
[walker 19661 D. Walker, P. Chapin, M. ~ e i s ,  and Lo Gross, 
Recent Developments in t h e  MITRE S y n t a c t i c  Analysis 
Procedure. MITRE Repor t  MTP-11. 
11 [Walker 19 73 ] Donald Walker,  "Automated Language Processing. 
In Annual R e v i e w  of Informaticjn Sc i ence  and Techn'olog.~, 
Vo1. 8, ed. C. Cuadra, American Society f o r  Informa-  
Lion Science,  Washington, Do C. 
[Wilks 19 751 Yorick W i l k s  , "An I n t e l l i g e n t  Analyzer and Under- 
stander of E n g l i s h . "  Comrn. Assn. Cornp. Mach. 18, 
264.  
[Winograd 19 711 T e r r y  Winograd, Procedures as. a R e p r e s e n t a t i o n  
for D a t a  in a C o m p u t e r  P r o g r a m  for Understanding 
N a t u r a l  Language. MIT Report  MAC TR-48 .  
[Woods 19 70a)- William A. Woods, "Con@ext-Sensitive Par s ing .  " 
C u m .  Assn. Cornp. Mach. 13, 4 3 7 .  
[Woods 1970bJ William A. Woods, " T r a n s i t i o n  N e t w o r k  Grammars 
t I  for Natural Language Analysis. Corn. Assn. Cornp. 
Mach. 13, 591. 
[Woods 19721 W .  A. Woods, .RI M. Kaplan, B. Nash-Webber, The 
L u n a r  Sciences N a t u r a l  Language Information Syste'm: 
F i n a l  Report.  R e p o r t  tf2378, B o l t  Beranek and 
N e w m a n ,  Cambridge , M a s s .  
[woods 19731 ~ i l l i a m  A. Woods, "An E q e r i r n e n t a l  P a r s i n g  Sy\stem 
for " T r a n s i t i o n  N e t w o r k  Grammars.  ' In N a t u r a l  
Language Processing, ed. R. Rus t i n ,  Algorithmics 
P r e s s ,  New York. 
[ Z w i c k y  19 651 A .  Z w i c k y ,  J. Friedman, B. H a l l ,  and D. Walker, 
 h he MITRE S y n t a c t i c  Analyqis Procedure f o r  
T r a n s  formational Grammars. " Proc. 1965 F a l l  J o i n t  
Computer Conf. , Thompson Books, Washington,  D. C. 
SgCURITY%%$%f%%FyTHIS PAGE (W7wn Dara Entered)  
n 
r ii 
REPORT DOCUMENTATlON PAGE READ  STR RUCTIONS BEFORECOMPLETINGFORW 
7. REPORT' NUMBER 12. GQVT ACCESSION NO, 3 .  RECIPIENT'S C A 4 A C O G  N U M B E R  w 
M-S 0- 8 1 
4 .  TITLE ( m d  Svbtltds) 5 T Y P E  O F  REPORT PERIOD CQVDRED 
I A Survey of S y n t a c t i c  Analysis Procedures I Technical Report  I for N a t u r a l  Language 
Ralph Gris'hman N08014-63X-0447-P032 
d r k  U n i v e r s i t y  
unclassified 
kJa.. DECLASSl FICATION '0,OWNGRADtNG 
SCHEDULE 
L 
16. DISTRIBUTION STA~T'EMENT (of Ihir Repafrt) 1 
nacural language, syntaxt p a r s i n g ,  grammar, computational 
l i n g u i s t i c s  
I 
20 ABSTRACT (Continue on teverse side I f  necessrw w d  Ic'antliy bv block number) 
This report includes a br ie f  d i s c u s s i o n  of the role of automatic 
s y n t a c t i c  analys i s ,  a s u r v e y  of parsing proced-dues, pas t  and 
presen t ,  and a d i s c u s s i o n  of the  approaches t a k e n  to a number of 
d i f f i c u l t  l i n g u i s t i c  problems, such as con j-unction and graded 
accepkabilitty.. It also  conta ins  precise spec i f i ca t ions  in t h e  
pYogramming language SETL of a number of p a r s i n g  a l g o r i t h m s .  
FORM 
1 ,AN 7,  1473 EDITtON O F  1 NOV 65  I S  OBSOLETE UNCLASSIFIED 
SECURITY CLASSIFICATION 3 F  THIS P A G E  (When Data Entered,' 
