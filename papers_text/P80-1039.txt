REPRESENTATION OF TEXTS FOR INFORMATION RETRIEVAL 
N.J. Belkin, B.G. Michell, and D.G. Kuehner 
University of Western Ontario 
The representation of whole texts is a major concern of 
the field known as information retrieval (IR), an impor- 
taunt aspect of which might more precisely be called 
'document retrieval' (DR). The DR situation, with which 
we will be concerned, is, in general, the following: 
a. A user, recognizing an information need, presents to 
an IR mechanism (i.e., a collection of texts, with a 
set of associated activities for representing, stor- 
ing, matching, etc.) a request, based upon that need 
hoping that the mechanism will be able to satisfy 
that need. 
b. The task of the IR mechanism is to present the user 
with the text(s) that it judges to be most likely to 
satisfy the user's need, based upon the request. 
c. The user examines the text(s) and her/his need is 
satisfied completely or partially or not at all. 
The user's judgement as to the contribution of each 
text in satisfying the need establishes that text's 
usefulness or relevance to the need. 
Several characteristics of the problem which DR attempts 
to solve make current IR systems rather different from, 
say, question-answering systems. One is that the needs 
which people bring to the system require, in general, 
responses consisting of documents about the topic or 
problem rather than specific data, facts, or inferences. 
Another is that these needs are typically not precisely 
specifiable, being expressions of an anomaly in the 
user's state of knowledge. A third is that this is an 
essentially probabilistic, rather than deterministic 
situation, and is likely to remain so. And finally, 
the corpus of documents in many such systems is in the 
order of millions (of, say, journal articles or ab- 
stracts), and the potential needs are, within rather 
broad subject constraints, unpredictable. The DR situ- 
ation thus puts certain constraints upon text represen- 
tation and relaxes others. The major relaxation is 
that it may not be necessary in such systems to produce 
representations which are capable of inference. A con- 
straint, on the other hand, is that it is necessary to 
have representations which ca~ indicate problems that a 
user cannot her/himself specify, and a matching system 
whose strategy is to predict which documents might re- 
solve specific anomalies. This strategy can, however, 
be based on probability of resolution, rat.her than cer- 
tainty. Finally, because of the large amount of data,. 
it is desirable that the representation techniques be 
reasonably simple computationally. 
Appropriate text representations, given these con- 
Straints, must necessarily be of whole texts, and prob- 
ably ought to be themselves whole, unitary structures, 
rather than lists of atomic elements, each treated sep- 
arately. They must be capable of representing problems, 
or needs, as well as expository texts, and they ought 
to allow for some sort of pattern matching. An obvious 
general schema within these requirements is a labelled 
associative network. 
Our approach to this general problem is strictly prob- 
lem-oriented. We begin with a representation scheme 
which we realize is oversimplified, but which stands 
within the constraints, and test whether it can be pro- 
gressively modified in response to observed deficien- 
cies, until either the desired level of performance in 
solving the problem is reached, or the approach is shown 
to be unworkable. We report here on some lingu/stical- 
ly-derived modifications to a very simple, but neverthe- 
less psychologically and linguistically based word-co- 
occurrence analysis of text \[i\] (figure I). 
POSITION RANK (r) 
Adjacent 1 
Same Sentence 2 
Adjacent Sentences 3 
FOR EACH CO-OCCURRENCE OF EACH WORD PAIR (Wl,W 2) 
1 
SCORE = 1 + r X i00 
FOR ALL CO-OCCURRENCES OF EACH WORD PAIR IN TEXT 
ASSOCIATION STRENGTH = SUM (SCORES) 
Figure I. Word Association Algorithm 
The original analysis was applied to two kinds of texts : 
abstracts of articles representing documents stored by 
the system, and a set of 'problem statements' represent- 
ing users' information needs -- their anomalous states 
of knowledge -- when they approach the system. The 
analysis produced graph-like structures, or association 
maps, of the abstracts and problem statements which were 
evaluated by the authors of the texts (Figure 2) 
(Figure 3). 
CLUSTERING LARGE FILES OF DO~NTS 
USING THE SINGLE-LINK METHOD 
A method for clustering large files of documents 
using a clustering algorithm which takes O(n**2) 
operations (single-link) is proposed. This 
method is tested on a file of i1,613 doc%unents 
derived from an operational system. One prop- 
erty of the generated cluster hierarchy (hier- 
archy con~ection percentage) is examined and 
it indicates that the hierarchy is similar to 
those from other test collections. A comparison 
of clustering times with other methods shows 
that large files can be cluStered by single- 
link in a time at least comparable to various 
heuristic algorithms which theoretically require 
fewer operations. 
Figure 2. Sample Abstract Analyzed 
In general, the representations were seen as being ac- 
curate reflections of the author's state of knowledge 
or problem; however, the majority of respondents also 
felt that some concepts were too strongly or weakly 
comnected, and that important concepts were omitted 
(Table i). 
We think that at least some of these problems arise 
because the algorithm takes no account of discourse 
structure. But because the evaluations indicated that 
the algorithm produces reasonable representations, we 
ha%~ decided to amend the analytic structure, rather 
than abandon it completely. 
147 
TIM COMPAR 
ALGORITHM ~\  ~ \ 
-. 15 VI , ' \  ., \ / : ' , \  
o~.RAT-- - "- V \ \ 
X ~ M~fHOD N k 
\ \ 
TEST 
LINK 
= Strong Associations 
= Medium Associations 
-- -- -- - Weak Associations 
Figure 3. 
Table i. 
Oues tion 
i. ACCURATE 
REFLECTION? 
2. (a) CONCEPTS TOO 
STRONGLY 
CONNECTED? 
(b) CONCEPTS TOO 
WEAKLY 
CONNECTED? 
3. CONCEPTS 
OMITTED? 
4. IF NO OR 
' INTERM' tO 
NO. l, WAS 
ABSTRACT 
ACCURATE? 
Association Map for Sample Abstract 
Abstract Representation Evaluation 
% YES % NO % % NO 
INTERM. RESP. 
48.0 29.6 22.0 N=30 
63.0 37.0 Nffi30 
96.3 3.7 N=30 
88.9 11.1 N-30 
64.3 7.1 21.4 7.1 N=14 
Our current modifications to the analysis consist pri- 
marily of methods for translating facts about discourse 
structure into rough equivalents within the word-co- 
occurrence paradigm. We choose this strategy, rather 
than attempting a complete and theoretically adequate 
discourse analysis, in order to incorporate insights 
about discourse without violating the cost -d volume 
constraints typical of DR systems. The modi~,cations 
are designed to recognize such aspects of discourse 
structure as establishment of topic; "setting of context; 
summarizing; concept foregrounding; and stylistic vari- 
ation. Textual characteristics which correspond with 
these aspects Include discourse-initial and discourse- 
final sentences; title words in the text: equivalence 
relations; and foregrounding devices (Figure 4). 
i. Repeat first and last sentences of the text. 
These sentences may include the more important con- 
cepts, and thus should be more heavily weighted. 
2. Repeat first sentence of paragraph after the last 
sentence. 
To integrate these sentences more fully into ~he 
overall structure. 
3. Make the title the first and last sentence of the 
text, or overweight the score for each cO-OCcurrence 
containing a title word. 
Concepts in the title are likely to be the most im- 
portant in the text, yet are unlikely to be used 
often in the abstract. 
4. Hyphenate phrases in the input text (phrases chosen 
algorithmically) and then either: a. Use the phrase 
only as a unit equivalent to a single word in the 
co-occurrence analysis ; or b. use any co-occurrence 
with either member of the phrase as a co-occurrence 
with the phrase, rather than the individual word. 
This is to control for conceptual units, as opposed 
to conceptual relations. 
5. Modify original definit ion of adjacency, which 
counted stop-l ist words, to one which ignores stop- 
list words. This is to correct for the distortion 
caused by the distribution of function words in the 
recognition of multi-word concepts. 
Figure 4. Modifications to Text Analysis Program 
We have written alternative systems for each of the pro- 
posed modifications. In this experiment the original 
corpus of thirty abstracts (but not the prublem state- 
ments) is submitted to all versions of the analysis pro- 
grams and the results co~ared  to the evaluations of the 
original analysis and to one another. From the compar- 
isons can be determined: the extent to which discourse 
theory can be translated into these terms; and the rela- 
tive effectiveness of the various modif ications in im- 
proving the original representations. 
Reference 
i. Belkin, N.J., Brooks, H.M., and Oddy, R.N. 1979. 
Representation and classif ication of knowledge and 
information for use in interactive information re- 
trieval. In Human Aspects of Information Science. 
Oslo: Norwegian Library School. 
148 
