Proceedings of the 2009 Workshop on Applied Textual Inference, ACL-IJCNLP 2009, pages 27?35,
Suntec, Singapore, 6 August 2009.
c
?2009 ACL and AFNLP
Augmenting WordNet-based Inference with Argument Mapping
Idan Szpektor
Department of Computer Science
Bar-Ilan University
Ramat Gan, Israel
szpekti@cs.biu.ac.il
Ido Dagan
Department of Computer Science
Bar-Ilan University
Ramat Gan, Israel
dagan@cs.biu.ac.il
Abstract
WordNet is a useful resource for lexi-
cal inference in applications. Inference
over predicates, however, often requires
a change in argument positions, which
is not specified in WordNet. We pro-
pose a novel framework for augmenting
WordNet-based inferences over predicates
with corresponding argument mappings.
We further present a concrete implementa-
tion of this framework, which yields sub-
stantial improvement to WordNet-based
inference.
1 Introduction
WordNet (Miller, 1995), a manually constructed
lexical database, is probably the mostly used re-
source for lexical inference in NLP tasks, such
as Question Answering (QA), Information Extrac-
tion (IE), Information Retrieval and Textual En-
tailment (RTE) (Moldovan and Mihalcea, 2000;
Pasca and Harabagiu, 2001; Bar-Haim et al, 2006;
Giampiccolo et al, 2007).
Inference using WordNet typically involves lex-
ical substitutions for words in text based on
WordNet relations, a process known as lexical
chains (Barzilay and Elhadad, 1997; Moldovan
and Novischi, 2002). For example, the an-
swer to ?From which country was Louisiana ac-
quired?? can be inferred from ?The United
States bought up Louisiana from France? using the
chains ?France ? European country ? country?
and ?buy up? buy? acquire?.
When performing inference between predicates
there is an additional complexity on top of lex-
ical substitution: the syntactic relationship be-
tween the predicate and its arguments may change
as well. For example, ?X buy Y for Z ?
X pay Z for Y ?.
Currently, argument mappings are not specified
for WordNet?s relations. Therefore, correct Word-
Net inference chains over predicates can be per-
formed only for substitution relations (mainly syn-
onyms and hypernyms, e.g. ?buy? acquire?), for
which argument positions do not change. Other
relation types that may be used for inference can-
not be utilized when the predicate arguments need
to be traced as well. Examples include the Word-
Net ?entailment? relation (e.g. ?buy ? pay?) and
relations between morphologically derived words
(e.g. ?acquire? acquisition?).
Our goal is to obtain argument mappings for
WordNet relations that are often used for infer-
ence. In this paper we address several prominent
WordNet relations, including verb-noun deriva-
tions and the verb-verb ?entailment? and ?cause?
relations, referred henceforth as inferential rela-
tions. Under the Textual Entailment paradigm,
all these relations can be viewed as express-
ing entailment. Accordingly, we propose a
novel framework, called Argument-mapped Word-
Net (AmWN), that represents argument map-
pings for inferential relations as entailment rules.
These rules are augmented with subcategorization
frames and functional roles, which are proposed
as a generally-needed extension for predicative en-
tailment rules.
Following our new representation scheme, we
present a concrete implementation of AmWN for
a large number of WordNet?s relations. The map-
pings for these relations are populated by com-
bining information from manual and corpus-based
resources, which provides broader coverage com-
pared to prior work and more accurate mappings.
Table 1 shows typical inference chains obtained
27
Rule Chains
shopping:n ofX
obj
? buying:n ofX
obj
? buy:vX
obj
? pay:v forX
mod
vote:v onX
mod
? decide:v onX
mod
? debate:vX
obj
X
obj
?s sentence:n ? condemn:vX
obj
? convict:vX
obj
?X
obj
?s conviction:n
X
ind?obj
?s teacher:n ? teach:v toX
ind?obj
?X
subj
learn:v
Table 1: Examples for inference chains obtained using AmWN. Arguments are subscripted with func-
tional roles, e.g. subject (subj) and indirect-object (ind-obj). For brevity, predicate frames are omitted.
using our implementation.
To further improve WordNet-based inference
for NLP applications, we address the phenom-
ena of rare WordNet senses. Rules generated for
such senses might hurt inference accuracy since
they are often applied incorrectly to texts when
matched against inappropriate, but more frequent
senses of the rule words. Since word sense disam-
biguation (WSD) solutions are typically not suf-
ficiently robust yet, most applications do not cur-
rently apply WSD methods. Hence, we propose
to optionally filter out such rules using a novel
corpus-based validation algorithm.
We tested both WordNet and AmWN on a test
set derived from a standard IE benchmark. The
results show that AmWN substantially improves
WordNet-based inference in terms of both recall
and precision
1
.
2 Argument-Mapping Entailment Rules
In our framework we represent argument map-
pings for inferential relations between predicates
through an extension of entailment rules over syn-
tactic representations. As defined in earlier works,
an entailment rule specifies an inference rela-
tion between an entailing template and an en-
tailed template, where templates are parse sub-
trees with argument variables (Szpektor and Da-
gan, 2008). For example, ?X
subj
??? buy
obj
??? Y
? ?X
subj
??? pay
prep?for
??????? Y ?.
When a rule is applied to a text, a new conse-
quent is inferred by instantiating the entailed tem-
plate variables with the argument instantiations of
the entailing template in the text. In our example,
?IBM paid for Cognos? can be inferred from ?IBM
bought Cognos?. This way, the syntactic structure
of the rule templates specifies the required argu-
ment positions for correct argument mapping.
However, representing entailment rule structure
only by syntactic argument positions is insufficient
for predicative rules. Correct argument mapping
1
We plan to make our AmWN publicly available.
depends also on the specific syntactic functional
roles of the arguments (subject, object etc.) and on
the suitable subcategorization frame (frame) for
the predicate mention - a set of functional roles
that a predicate may occur with. For example,
?X?s buyout ? buy X? is incorrectly applied to
?IBM?s buyout of Cognos? if roles are ignored,
since ?IBM? plays the subject role while X needs
to be an object.
Seeking to address this issue, we were inspired
by the Nomlex database (Macleod et al, 1998)
(see Section 3.2.1) and explicitly specify argu-
ment mapping for each frame and functional role.
As in Nomlex, we avoid the use of semantic
roles and stick to the syntactic level, augment-
ing the representation of templates with: (a) a
syntactic functional role for each argument; (b)
the valid predicate frame for this template men-
tions. We note that such functional roles typically
coincide with dependency relations of the verbal
form. A rule example is ?X
subj
break
{intrans}
?
damage
{trans}
X
obj
?
2
. More examples are shown
in Table 1.
Unlike Nomlex records, our templates can be
partial: they may contain only some of the possi-
ble predicate arguments, e.g. ?buy
{trans}
X
obj
?,
where the subject, included in the frame, is omit-
ted. Partial templates are necessary for matching
predicate occurrences that include only some of
the possible arguments, as in ?Cognos was bought
yesterday?. Additionally, some resources, such as
automatic rule learning methods (Lin and Pantel,
2001; Sekine, 2005), can provide only partial ar-
gument information, and we would want to repre-
sent such knowledge as well.
In our framework we follow (Szpektor and Da-
gan, 2008) and use only rules between unary tem-
plates, containing a single argument. Such tem-
plates can describe any argument mapping by de-
2
Functional roles are denoted by subscripts of the argu-
ments and frames by subscripts of the predicate. We short-
hand trans for transitive frame {subject, object} and intrans
for intransitive {subject}. For brevity, we will not show all
template information when examples are self explanatory.
28
composing templates with several arguments into
unary ones, while preserving the specification of
the subcategorization frame.
To apply a rule, the entailing template must be
first matched in the text, which includes match-
ing the template?s syntactic dependency structure,
functional roles, and frame. Such procedure re-
quires texts to be annotated with these types of in-
formation. This can be reasonably performed with
existing tools and resources, as described for our
own text processing in Section 4.
Explicitly matching frames and functional roles
in rules avoids incorrect rule applications. For ex-
ample, ?X
obj
?s buyout? buy X
obj
? would be ap-
plied only to ?Cognos?s buyout by IBM? follow-
ing proper role annotation of the text, but not to
?IBM?s buyout of Cognos?. As another example,
?X
subj
break
{intrans}
? damage
{trans}
X
obj
?
would be applied only to the intransitive occur-
rence of ?break?, e.g. ?The vase broke?, but not
to ?John broke the vase?.
Ambiguous cases may occur during annotation.
For example, the role of ?John? in ?John?s invita-
tion was well intended? could be either subject or
object. Such recognized ambiguities should be left
unannotated, blocking incorrect rule application.
3 Argument Mapping for WordNet
Following our extension of entailment rules, we
present Argument-mapped WordNet (AmWN), a
framework for extendingWordNet?s inferential re-
lations with argument mapping at the syntactic
representation level.
3.1 Argument Mapping Representation
The AmWN structure follows that of WordNet: a
directed graph whose nodes are WordNet synsets
and edges are relations between synsets. Since
we focus on entailment between predicates, we
include only predicative synsets: all verb synsets
and noun synsets identified as predicates (see Sec-
tion 3.2). In addition, only WordNet relations that
correspond to some type of entailment are consid-
ered, as detailed in Section 3.2.
In our framework, different subcategorization
frames are treated as having different ?meanings?,
since different frames may correspond to differ-
ent entailment rules. Each WordNet synset is split
into several nodes, one for each of its frames. We
take frame descriptions for verbs from WordNet
3
.
3
We also tried using VerbNet (Kipper et al, 2000), with-
Figure 1: A description of ?buy/purchase X ?
pay for X? as a mapping edge in AmWN.
Since WordNet does not provide frames for noun
predicates, these are taken from Nomlex-plus (see
Section 3.2).
There are two types of graph edges that rep-
resent entailment rules between nodes: mapping
edges and substitution edges. Mapping edges
specify entailment rules that require argument
mapping, where the entailing and entailed tem-
plate predicates are replaced by synsets. Thus, an
edge represents all rules between entailing and en-
tailed synset members, as in Figure 1.
Substitution edges connect pairs of predicates,
of the same part-of-speech, which preserve argu-
ment positions in inference. This is analogous to
how WordNet may be currently used for inference
via the synonym and hypernym relations. Unlike
WordNet, substitution edges in AmWN may con-
nect only nodes that have the same subcategoriza-
tion frame.
AmWN is utilized by generating rule chains for
a given input unary template. First, starting nodes
that match the input predicate are selected. Then,
rules are generated by traversing either incoming
or outgoing graph edges transitively, depending
on the entailment direction requested. Specific
synset-ids, if known, may also be added to the in-
put to constrain the relevant starting nodes for the
input predicate. Table 1 shows examples of rule
chains from AmWN.
3.2 Argument Mapping Population
After defining the AmWN representation, we next
describe our implementation of AmWN. We first
populate the AmWN graph with substitution edges
for WordNet?s hypernyms and synonyms (as self
edges), e.g. ?buy ? purchase? and ?buy ? ac-
quire?. The following subsections describe how
mapping edges are created based on various man-
ual and corpus-based information resources.
3.2.1 Nominalization Relations
The relation between a verb and its nominaliza-
tions, e.g. between ?employ? and ?employment?,
out any current performance improvement.
29
:ORTH "employment"
:VERB "employ"
:VERB-SUBC ((NOM-NP
:SUBJECT ((DET-POSS)
(N-N-MOD)
(PP :PVAL ("by")))
:OBJECT ((DET-POSS)
(PP :PVAL ("of")))
Figure 2: Part of the employment Nomlex entry,
describing the possible syntactic dependency posi-
tions for each role of the transitive frame. It states,
for example, that the verbal ?object? role can be
mapped to employment either as a possessive or as
the complement of the preposition ?of?.
is described in WordNet by the derivationally re-
lated relation. To add argument mappings for
these relations we utilize Nomlex-plus (Meyers
et al, 2004), a database of around 5000 English
nominalizations. Nomlex specifies for each ver-
bal subcategorization frame of each nominaliza-
tion how its argument positions are mapped to
functional roles of related verbs.
For each Nomlex entry, we extract all possible
argument mappings between the verbal and nom-
inal forms, as well as between different argument
realizations of the noun. For example, the map-
pings ?X
obj
?s employment ? employ X
obj
? and
?X
obj
?s employment? employment of X
obj
? are
derived from the entry in Figure 2.
The major challenge in integrating Nomlex and
WordNet is to identify for each Nomlex noun
which WordNet synsets describe its predicative
meanings. For example, one synset of ?acquisi-
tion? that is derivationally related to ?acquire? is
not predicative: ?an ability that has been acquired
by training?. We mark noun synsets as predicative
if they are (transitive) hyponyms of the act high-
level synset.
Once predicative synsets are identified, we cre-
ate, for each synset, a node for each subcate-
gorization frame of its noun members, as found
in Nomlex-plus. In some nodes not all original
synset members are retained, since not all mem-
bers share all their frames. Mapping edges are
then added between nodes that have the same
frame. We add both noun-verb edges and noun
self-edges that map different realizations of the
same functional role (e.g. ?X
obj
?s employment?
employment of X
obj
?).
As rich as Nomlex-plus is, it still does not in-
clude all nominalizations. For example, the nouns
Lexical Relation Extracted Mappings
buy ? pay
buy forX ? payX
X buy ?X pay
divorce ? marry
divorce fromX ? marryX
divorce fromX ?X marry
kill ? die
killX ?X die
kill amongX ?X die
breathe ? inhale
breatheX ? inhaleX
breathe inX ? inhaleX
remind ? remember
remindX ?X remember
remind ofX ? rememberX
teach ? learn
teachX ? learnX
teach toX ?X learn
give ? have
giveX ? haveX
give toX ?X have
Table 2: Some argument mappings for WordNet
verb-verb relations discovered by unary-DIRT.
?divorce? (related to the verb ?divorce?) and ?strik-
ing? are missing. WordNet has a much richer set
of nominalizations that we would like to use. To
do so, we inherit associated frames and argument
realizations for each nominalization synset from
its closest hypernym that does appear in Nomlex.
Thus, ?divorce? inherits its information from ?sep-
aration? and ?striking? inherits from ?hit?. A by-
product of this process is the automatic extension
of Nomlex-plus with 5100 new nominalization en-
tries, based on the inherited information
4
.
3.2.2 Verb-Verb Relations
There are two inferential relations between verbs
in WordNet that do not preserve argument posi-
tions: cause and entailment. Unlike for nomi-
nalizations, there is no broad-coverage manual re-
source of argument mapping for these relations.
Hence, we turn to unsupervised approaches that
learn entailment rules from corpus statistics.
Many algorithms were proposed for learning
entailment rules between templates from corpora
(Lin and Pantel, 2001; Szpektor et al, 2004;
Sekine, 2005), but typically with mediocre accu-
racy. However, we only search for rules between
verbs for which WordNet aleady indicates the ex-
istence of an entailment relation and are thus not
affected by rules that wrongly relate non-entailing
verbs. We acquired a rule-set containing the top
300 rules for every unary template in the Reuters
RCV1 corpus
5
by implementing the unary-DIRT
algorithm (Szpektor and Dagan, 2008), which was
shown to have relatively high recall compared to
other algorithms.
4
We plan making this extension publicly available as well.
5
http://about.reuters.com/researchandstandards/corpus/
30
To extract argument mappings, we identify all
AmWN node pairs whose synsets are related in
WordNet by a cause or an entailment relation.
For each pair, we look for unary-DIRT rules be-
tween any pair of members in the entailing and
entailed synsets. For example, the synset {buy,
purchase} entails {pay}, so we look for rules map-
ping either ?buy? pay? or ?purchase? pay?. Ta-
ble 2 presents examples for discovered mappings.
While unary-DIRT rules are not annotated with
functional roles, they can be derived straightfor-
wardly from the verbal dependency relations avail-
able in the rule?s templates. The obtained rules are
then added to AmWN as mapping edges.
We only search for rules that map a functional
role in the frame of one verb to any role for the
other verb. Focusing on frame elements avoids ex-
tracting mapping rules learned for adjuncts, which
tend to be of low precision.
3.3 Rule Filtering
In preliminary analysis we found two phenomena,
sense drifting and rare senses, which may reduce
the effectiveness of AmWN-based inference even
if each graph edge by itself, taken out of context, is
correct. To address these phenomena within prac-
tical inference we propose the following optional
methods for rule filtering.
Sense Drifting WordNet verbs typically have
a more fine-grained set of synsets than their re-
lated nominalizations. There are cases where sev-
eral verb synsets are related to the same nomi-
nal synset. Since entailment between a verb and
its nominalization is bidirectional, all such verb
synsets would end up entailing each other via the
nominal node.
Alas, some of these connected verb synsets rep-
resent quite different meanings, which results in
incorrect inferences. This problem, which we call
sense drifting, is demonstrated in Figure 3. To ad-
dress it, we constrain each rule generation chain
to include at most one verb-noun edge, which still
connects the noun and verb hierarchies.
Rare Senses Some word senses in WordNet are
rare. Thus, applying rules that correspond to such
senses yields many incorrect inferences, since
they are typically matched against other frequent
senses of the word. Such a rule is ?have X ? X
is born?, corresponding to a rare sense of ?have?.
WSD is a possible solution for this problem. How-
ever, most state-of-the-art IE, QA and RTE sys-
tems do not rely on WSD methods, which are cur-
rently not sufficiently robust.
To circumvent the rare sense problem, we in-
stead filter out such rules. Each AmWN rule is
validated against our unary-DIRT rule-set, which,
being corpus-based, contains mostly rules for fre-
quent senses. A rule is directly-validated if it is
in the corpus-based rule-set, or if it is a nominal-
verb rule which describes a reliable morpholog-
ical change for a predicate. The AmWN graph-
path that generated each rule is automatically ex-
amined. A rule is considered valid if there is a
sequence of directly-validated intermediate rules
along the path whose transitive chaining generates
the rule. Invalid rules are filtered out.
To illustrate, suppose the rule ?a? d? was gen-
erated by the chain ?a ? b ? c ? d?. It is valid
if there is a rule chain along the path that yields ?a
? d?, e.g. {?a? b?,?b? c?,?c? d?} or {?a? b?,
?b? d?}, whose rules are all directly-validated.
4 Experimental Setup
We follow here the experimental setup presented
in (Szpektor and Dagan, 2008), testing the gener-
ated rules on the ACE 2005 event dataset
6
. This
standard IE benchmark includes 33 types of event
predicates such as Injure, Sue and Divorce
7
. The
ACE guidelines specify for each event its possi-
ble arguments. For example, some of the Injure
event arguments are Agent and Victim. All event
mentions, including their instantiated arguments,
are annotated in a corpus collected from various
sources (newswire articles, blogs, etc.).
To utilize the ACE dataset for evaluating rule
applications, each ACE event predicate was rep-
resented by a set of unary seed templates, one for
each event argument. Example seed templates for
Injure are ?A injure? and ?injure V ?. Each event ar-
gument is mapped to the corresponding seed tem-
plate variable, e.g. ?Agent? to A and ?Victim? to V
in the above example.
We manually annotated each seed template with
a subcategorization frame and an argument func-
tional role, e.g. ?injure
{trans}
V
obj
?. We also in-
cluded relevant WordNet synset-ids, so only rules
fitting the target meaning of the event will be ex-
tracted. In this experiment, we focused only on
the core semantic arguments. Adjuncts (time and
6
http://projects.ldc.upenn.edu/ace/
7
Only 26 frequent event types that correspond to a unique
predicate were tested, following (Szpektor and Dagan, 2008).
31
Synset Members WordNet Gloss
(verb) collar, nail, apprehend, arrest, pick up, nab, cop take into custody
m
(noun) apprehension, arrest, catch, collar, pinch, the act of apprehending (especially apprehending
taking into custody a criminal)
m
(verb) get, catch, capture succeed in catching or seizing, especially after a chase
m
(noun) capture, seizure the act of taking of a person by force
m
(verb) seize take or capture by force
? (hypernym)
(verb) kidnap, nobble, abduct, snatch take away to an undisclosed location against their will
and usually in order to extract a ransom
Figure 3: A WordNet sense-drifting traversal, generating the incorrect inference ?kidnap? arrest?.
place) were ignored since they typically don?t re-
quire argument mapping, the main target for our
assessment.
The ACE corpus was dependency-parsed with
Minipar (Lin, 1998) and annotated with functional
roles and frames for each predicate mention. The
functional roles for a verb mention were taken di-
rectly from the corresponding dependency tree re-
lations. Its frame was chosen to be the largest
WordNet frame of that verb that matched the men-
tion?s roles.
Nominalization frames and functional roles
in the text were annotated using our extended
Nomlex-plus database. For each nominal mention,
we found the largest Nomlex frame whose syntac-
tic argument positions matched those of the men-
tion?s arguments. The arguments were then anno-
tated with the specified roles of the chosen frame.
Ambiguous cases, where the same argument posi-
tion could match multiple roles, were left unanno-
tated, as discussed in Section 2.
Argument mentions for events were found in
the annotated corpus by matching either the seed
templates or the templates entailing them in some
rules. The matching procedure follows the one de-
scribed in Section 2. Templates are matched us-
ing a syntactic matcher that handles simple syn-
tactic variations such as passive-form and con-
junctions. For example, ?wound
{trans}
V
obj
? injure
{trans}
V
obj
? was matched in the text
?Hagel
obj
was wounded
trans
in Vietnam?. A rule
application is considered correct if the matched ar-
gument is annotated in the corpus with the corre-
sponding ACE role.
We note that our system performance on the
ACE task as such is limited. First, WordNet does
not provide all types of needed rules. Second, the
system of our experimental setting is rather basic,
with limited matching capabilities and without a
WSD module. However, this test-set is still very
useful for relative comparison of WordNet and our
proposed AmWN.
5 Results and Analysis
We tested four different rule-set configurations:
a) only the seed templates, without any rules; b)
rules generated based on WordNet 3.0 without ar-
gument mapping, using only synonym and hyper-
nym relations; c) WordNet rules from (b), filtered
using our corpus-based validation method for rare
senses; d) rules generated from our AmWN.
Out of the 8953 non-substitutable inferential re-
lations that we identified in WordNet, our AmWN
implementation created mapping edges for 75% of
8325 Noun-Verb relations and 70% of 628 Verb-
Verb relations. Altogether 41549 mapping edges
between synset nodes were added. A manual er-
ror analysis of these mappings is provided in Sec-
tion 5.2.
Each configuration was evaluated for each ACE
event. We measured the percentage of correct ar-
gument mentions extracted out of all correct argu-
ment mentions annotated for the event (recall) and
out of all argument mentions extracted (precision),
and F1, their harmonic average. We report macro
averages over the 26 event types.
5.1 Results
Table 3 summarizes the results for the different
configurations. As expected, matching only the
seed templates yields the highest precision but
lowest recall. Using the standard WordNet config-
uration actually decreases overall F1 performance.
Though recall increases relatively by 30%, thanks
to WordNet expansions, F1 is penalized by a sharp
32
Configuration R (%) P (%) F1
No Rules 13.5 63.0 20.7
WordNet 17.5 35.3 18.5
WordNet with rule validation 16.5 46.9 20.4
AmWN 20.8 43.9 24.2
Table 3: Recall (R), Precision (P) and F1 results
for the different tested configurations.
relative drop in precision (by 56%). The main rea-
son for this decline is the application of rules in-
volving infrequent word senses, as elaborated in
Section 3.3.
When our rule validation approach is applied
to standard WordNet expansions, a much higher
precision is achieved with only a small decline in
recall. This shows that our corpus-based filtering
method manages to avoid many of the noisy rules
for rare senses, while maintaining those that are
frequently involved in inference.
Finally, our main result shows that adding ar-
gument mapping improves performance substan-
tially. AmWN achieves a much higher recall
than WordNet. Recall increases relatively by 26%
over validated WordNet, and by 54% over the
no-rules baseline. Furthermore, precision drops
only slightly, by 6%, compared to validated Word-
Net. This shows that argument mapping increases
WordNet?s graph connectivity, while our rule-
validation method maintains almost the same pre-
cision for many more generated rules. The im-
provement in overall F1 performance is statisti-
cally significant compared to all other configura-
tions, according to the two-sided Wilcoxon signed
rank test at the level of 0.01 (Wilcoxon, 1945).
5.2 Error Analysis
We manually analyzed the reasons for false pos-
itives (incorrect extractions) and false negatives
(missed extractions) of AmWN by sampling 300
extractions of each type.
From the false positives analysis (Table 4) we
see that practically all generated rules are correct
(99.4%), that is, they would be valid in some con-
texts. Almost all errors come frommatching errors
(including parse errors) and context mismatches,
due to our limited IE implementation. The only
two incorrect rules sampled were due to an in-
correct Nomlex entry and a WordNet synset that
should have been split into two separate senses.
Considering that correct extractions resulted, per
our analysis, from correct rules, the analysis of this
Reason % mentions
Context mismatch 57.2
Match error 33.6
Errors in gold-standard annotation 8.6
Incorrect Rule learned 0.6
Table 4: Distribution of reasons for false positives
(incorrect argument extractions).
Reason % mentions
Rule not learned 67.7
Match error 18.0
Discourse analysis needed 12.0
Argument is predicative 1.3
Errors in gold-standard annotation 1.0
Table 5: Distribution of reasons for false negatives
(missed argument mentions).
sample indicates that virtually all AmWN edges
that get utilized in practice are correct.
Context mismatches, which constitute the ma-
jority of errors (57.2%), occur when the entail-
ing template of a rule is matched in inappropriate
contexts. This occurs typically when the match is
against another sense of the predicate, or when an
argument is not of the requested type (e.g. ?The
Enron sentence? vs. ?A one month sentence?). In
future work, we plan to address this problem by
utilizing context-sensitive application of rules in
the spirit of (Szpektor et al, 2008).
Table 5 presents the false negatives analysis.
Most missed extractions are due to rules that were
not learned (67.7%). These mainly involve com-
plex templates (?file a lawsuit ? sue?) and infer-
ence rules that are not synonyms/hypernyms (?ex-
ecute ? sentence?), which are not widely anno-
tated inWordNet. From further analysis, we found
that 10% of these misses are due to rules that are
generated from AmWN but filtered out by one of
our filtering methods (Section 3.3).
12% of the arguments cannot be extracted by
rules alone, due to required discourse analysis,
while 18% of the mentions were missed due to in-
correct syntactic matching. By assuming correct
matches in these cases and avoiding rule filtering,
we can estimate the upper bound recall of the rule-
set for the ACE dataset to be 40%.
In conclusion, for better performance the sys-
tem should be augmented with context modeling
and better template matching. Additionally, other
rule-bases, e.g. DIRT (Lin and Pantel, 2001),
should be added to increase rule coverage.
33
Configuration R (%) P (%) F1
AmWN 20.8 43.9 24.2
No nominalization mappings 18.1 45.5 21.8
No verb-verb mappings 19.3 43.8 22.8
No rule validation 22.0 30.4 20.9
No sense drift blocking 22.5 37.4 21.7
Table 6: The Recall (R), Precision (P) and F1 re-
sults for ablation tests.
5.3 Component Analysis
Table 6 presents ablations tests that assess the
marginal contribution of each AmWN component.
Nominal-verb and verb-verb mappings contribute
to the graph connectivity, hence the recall reduc-
tion when they are removed.
Complementary to recall components, rule fil-
tering improves precision. When removing the
corpus-based rule-validation, recall increases rel-
atively by 6% but precision drops relatively by
30%, showing the benefit of noisy-rule filtering.
Allowing sense drifting hurts precision, a rela-
tive drop of 22%. Yet, recall increases relatively
by 8%, indicating that some verb synsets, con-
nected via a shared nominal, entail each other even
though they are not connected directly. For exam-
ple, ?foundX? createX? was generated only via
the shared nominal ?founding?. In future work, we
plan to apply AmWN to a coarse-grained set of
WordNet synsets (Palmer et al, 2007) as a possi-
ble solution to sense drifting.
6 Related Work
Several works attempt to extend WordNet with ad-
ditional lexical semantic information (Moldovan
and Rus, 2001; Snow et al, 2006; Suchanek et al,
2007; Clark et al, 2008). However, the only pre-
vious work we are aware of that enriches Word-
Net with argument mappings is (Novischi and
Moldovan, 2006). This work utilizes VerbNet?s
subcategorization frames to identify possible verb
arguments. Argument mapping is provided only
between verbs, ignoring relations between verbs
and nouns. Arguments are mapped based on the-
matic role names shared between frames of dif-
ferent verbs. However, the semantic interpretation
of thematic roles is generally inconsistent across
verbs (Lowe et al, 1997; Kaisser and Webber,
2007). Instead, we discover these mappings from
corpus statistics, offering an accurate approach (as
analyzed in Section 5.2).
A frame semantics approach for argument
mapping between predicates is proposed by the
FrameNet project (Baker et al, 1998). Currently,
FrameNet is the only resource for frame-semantic
argument mappings. However, it is manually con-
structed and currently covers much less predi-
cates and relations than WordNet. Furthermore,
frame-semantic parsers are less robust than syntac-
tic parsers, presently hindering the utilization of
this approach in applications (Burchardt and Pen-
nacchiotti, 2008).
Nomlex argument mapping patterns similar to
ours were derived for IE in (Meyers et al, 1998),
but they were not integrated with any additional
information, such as WordNet.
7 Conclusions
We presented Argument-mapped WordNet
(AmWN), a novel framework for augment-
ing WordNet with argument mappings at the
syntactic representation level. With AmWN,
non-substitutable WordNet relations can also
be utilized correctly, increasing the coverage of
WordNet-based inference. The standard entail-
ment rule representation is augmented in our
work with functional roles and subcategorization
frames, shown to be a feasible extension needed
for correct rule application in general.
Our implementation of AmWN populates
WordNet with mappings based on combining
manual and corpus-based resources. It covers a
broader range of relations compared to prior work
and yields more accurate mappings. We also in-
troduced a novel corpus-based validation mecha-
nism, avoiding rules for infrequent senses. Our
experiments show that AmWN substantially im-
proves standard WordNet-based inference.
In future work we plan to add mappings be-
tween verbs and adjectives and between different
frames of a verb. We also want to incorporate
resources for additional subcategorization frames,
such as VerbNet. Finally, we plan to enhance our
text annotation based on noun-compound disam-
biguation (Lapata and Lascarides, 2003).
Acknowledgements
This work was partially supported by the NEGEV
project (www.negev-initiative.org), the PASCAL-
2 Network of Excellence of the European Commu-
nity FP7-ICT-2007-1-216886, the FBK-irst/Bar-
Ilan University collaboration and the Israel Sci-
ence Foundation grant 1112/08.
34
References
Collin F. Baker, Charles J. Fillmore, and John B. Lowe.
1998. The berkeley framenet project. In Proceed-
ings of ACL.
Roy Bar-Haim, Ido Dagan, Bill Dolan, Lisa Ferro,
Danilo Giampiccolo, Bernardo Magnini, and Idan
Szpektor. 2006. The second pascal recognising tex-
tual entailment challenge. In Second PASCAL Chal-
lenge Workshop for Recognizing Textual Entailment.
Regina Barzilay and Michael Elhadad. 1997. Using
lexical chains for text summarization. In Proceed-
ings of ACL.
Aljoscha Burchardt and Marco Pennacchiotti. 2008.
Fate: a framenet-annotated corpus for textual entail-
ment. In Proceedings of LREC.
Peter Clark, Christiane Fellbaum, Jerry R. Hobbs, Phil
Harrison, William R. Murray, and John Thompson.
2008. Augmenting WordNet for Deep Understand-
ing of Text. In Proceedings of STEP 2008.
Danilo Giampiccolo, Bernardo Magnini, Ido Dagan,
and Bill Dolan. 2007. The third pascal recogniz-
ing textual entailment challenge. In Proceedings of
the ACL-PASCAL Workshop on Textual Entailment
and Paraphrasing.
Michael Kaisser and Bonnie Webber. 2007. Question
answering based on semantic roles. In ACL 2007
Workshop on Deep Linguistic Processing.
Karin Kipper, Hoa Trang Dang, and Martha Palmer.
2000. Class-based construction of a verb lexicon.
In Proceedings of AAAI.
Mirella Lapata and Alex Lascarides. 2003. Detect-
ing novel compounds: The role of distributional ev-
idence. In Proceedings of EACL.
Dekang Lin and Patrick Pantel. 2001. Discovery of in-
ference rules for question answering. Natural Lan-
guage Engineering, 7(4):343?360.
Dekang Lin. 1998. Dependency-based evaluation of
minipar. In Proceedings of the Workshop on Eval-
uation of Parsing Systems at LREC 1998, Granada,
Spain.
John B. Lowe, Collin F. Baker, and Charles J. Fillmore.
1997. A frame-semantic approach to semantic an-
notation. In Proceedings of the SIGLEX Workshop
on Tagging Text with Lexical Semantics: Why, What,
and How?
Catherine Macleod, Ralph Grishman, Adam Meyers,
Leslie Barrett, and Ruth Reeves. 1998. NOMLEX:
A Lexicon of Nominalizations. In Proceedings of
EURALEX.
AdamsMeyers, CatherineMacleod, Roman Yangarber,
Ralph Grishman, Leslie Barrett, and Ruth Reeves.
1998. Using nomlex to produce nominalization pat-
terns for information extraction. In Proceedings of
COLING.
Adam Meyers, Ruth Reeves, Catherine Macleod,
Rachel Szekeley, Veronkia Zielinska, and Brian
Young. 2004. The Cross-Breeding of Dictionaries.
In Proceedings of LREC.
George A. Miller. 1995. Wordnet: A lexical database
for english. In Communications of the ACM.
Dan Moldovan and Rada Mihalcea. 2000. Using
wordnet and lexical operators to improve internet
searches. IEEE Internet Computing, 4(1):34?43.
Dan Moldovan and Adrian Novischi. 2002. Lexical
chains for question answering. In Proceedings of
COLING.
Dan Moldovan and Vasile Rus. 2001. Logic form
transformation of wordnet and its applicability to
question answering. In Proceedings of ACL.
Adrian Novischi and Dan Moldovan. 2006. Question
answering with lexical chains propagating verb ar-
guments. In Proceedings of ACL.
Martha Palmer, Hoa Trang Dang, and Christiane
Fellbaum. 2007. Making fine-grained and
coarse-grained sense distinctions, both manually
and automatically. Natural Language Engineering,
13(2):137?163.
Marius Pasca and Sanda Harabagiu. 2001. The in-
formative role of wordnet in open-domain question
answering. In Proceedings of Workshop on WordNet
and Other Lexical Resources: Applications, Exten-
sions and Customizations.
Satoshi Sekine. 2005. Automatic paraphrase discovery
based on context and keywords between ne pairs. In
Proceedings of IWP.
Rion Snow, Daniel Jurafsky, and Andrew Y. Ng. 2006.
Semantic taxonomy induction from heterogenous
evidence. In Proceedings of ACL.
Fabian M. Suchanek, Gjergji Kasneci, and Gerhard
Weikum. 2007. Yago: A core of semantic knowl-
edge - unifying wordnet and wikipedia. In Proceed-
ings of WWW2007.
Idan Szpektor and Ido Dagan. 2008. Learning entail-
ment rules for unary templates. In Proceedings of
COLING.
Idan Szpektor, Hristo Tanev, Ido Dagan, and Bonaven-
ture Coppola. 2004. Scaling web based acquisition
of entailment patterns. In Proceedings of EMNLP
2004.
Idan Szpektor, Ido Dagan, Roy Bar-Haim, and Jacob
Goldberger. 2008. Contextual preferences. In Pro-
ceedings of ACL.
Frank Wilcoxon. 1945. Individual comparisons by
ranking methods. Biometrics Bulletin, 1:80?83.
35
