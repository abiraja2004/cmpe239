Proceedings of the NAACL HLT 2010 Young Investigators Workshop on Computational Approaches to Languages of the Americas,
pages 84?91, Los Angeles, California, June 2010. c?2010 Association for Computational Linguistics
IRASubcat, a highly customizable, language independent tool for the
acquisition of verbal subcategorization information from corpus
Ivana Romina Altamirano and Laura Alonso i Alemany
Grupo de Procesamiento de Lenguaje Natural
Seccio?n de Ciencias de la Computacio?n
Facultad de Matema?tica, Astronom??a y F??sica
Universidad Nacional de Co?rdoba
Co?rdoba, Argentina
romina.altamirano@gmail.com,alemany@famaf.unc.edu.ar
Abstract
IRASubcat is a language-independent tool to
acquire information about the subcategoriza-
tion of verbs from corpus. The tool can extract
information from corpora annotated at vari-
ous levels, including almost raw text, where
only verbs are identified. It can also ag-
gregate information from a pre-existing lex-
icon with verbal subcategorization informa-
tion. The system is highly customizable, and
works with XML as input and output format.
IRASubcat identifies patterns of constituents
in the corpus, and associates patterns with
verbs if their association strength is over a fre-
quency threshold and passes the likelihood ra-
tio hypothesis test. It also implements a proce-
dure to identify verbal constituents that could
be playing the role of an adjunct in a pattern.
Thresholds controlling frequency and identi-
fication of adjuncts can be customized by the
user, or else they are given a default value.
1 Introduction and Motivation
Characterizing the behavior of verbs as nuclear or-
ganizers of clauses (the so-called subcategorization
information) is crucial to obtain deep analyses of
natural language. For example, it can significantly
reduce structural ambiguities in parsing (Carroll et
al., 1999; Carroll and Fang, 2004), help in word
sense disambiguation or improve information ex-
traction (Surdeanu et al, 2003). However, the usual
construction of linguistic resources for verbal sub-
categorization involves many expert hours, and it is
usually prone to low coverage and inconsistencies
across human experts.
Corpora can be very useful to alleviate the prob-
lems of low coverage and inconsistencies. Verbs
can be characterized by their behavior in a big cor-
pus of the language. Thus, lexicographers only need
to validate, correct or complete this digested infor-
mation about the behavior of verbs. Moreover, the
starting information can have higher coverage and
be more unbiased than if it is manually constructed.
That?s why automatic acquisition of subcategoriza-
tion frames has been an active research area since
the mid-90s (Manning, 1993; Brent, 1993; Briscoe
and Carroll, 1997).
However, most of the approaches have been ad-
hoc for particular languages or particular settings,
like a determined corpus with a given kind of an-
notation, be it manual or automatic. To our knowl-
edge, there is no system to acquire subcategorization
information from corpora that is flexible enough to
work with different languages and levels of annota-
tion of corpora.
We present IRASubcat, a tool that acquires in-
formation about the behaviour of verbs from cor-
pora. It is aimed to address a variety of situations
and needs, ranging from rich annotated corpora to
virtually raw text (because the tags to study can be
selected in the configuration file). The characteri-
zation of linguistic patterns associated to verbs will
be correspondingly rich. The tool allows to cus-
tomize most of the aspects of its functioning, to
adapt to different requirements of the users. More-
over, IRASubcat is platform-independent and open
source, available for download at http://www.
irasubcat.com.ar.
IRASubcat input is a corpus (in xml format) with
examples of the verbs one wants to characterize, and
its output is a lexicon where each verb is associated
with the patterns of linguistic constituents that re-
flect its behavior in the given corpus, an approxima-
84
tion to its subcategorization frame. Such association
is established when the verb and pattern co-occur in
corpus significantly enough to pass a frequency test
and a hypothesis test.
In the following section we discuss some previ-
ous work in the area of subcategorization acquisi-
tion from corpora. Then, Section 3 presents the
main functionality of the tool, and describe its us-
age. Section 4 details the parameters that can be cus-
tomized to adapt to different experimental settings.
In Section 5 we outline the functionality that iden-
tifies constituents that are likely to be adjuncts and
not arguments, and in Section 6 we describe the pro-
cedures to determine whether a given pattern is ac-
tually part of the subcategorization frame of a verb.
Section 7 presents some results of applying IRASub-
cat to two very different corpora. Finally, we present
some conclusions and the lines of future work.
2 Previous Work
We review here some previous work related to ac-
quisition of subcategorization information from cor-
pora, focussing on the constraints of the approach
and corpora to learn with. We specially mention ap-
proaches for languages other than English.
The foundational work of (Brent, 1993) was based
on plain text (2.6 million words of the Wall Street
Journal (WSJ, 1994)). Since the corpus had no an-
notation, verbs were found by heuristics. He de-
tected six frame types and filtered associations be-
tween verbs and frames with the binomial hypothe-
sis test. This approach obtained 73.85% f-score in
an evaluation with human judges.
Also in 1993, (Ushioda et al, 1993) exploited also
the WSJ corpus but only the part that was annotated
with part-of-speech tags, with 600.000 words. He
studied also six frame types and did not distinguish-
ing arguments and adjuncts.
The same year, (Manning, 1993) used 4 million
words of the New York Times (Sandhaus, ), selected
only clauses with auxiliary verbs and automatically
analyzed them with a finite-state parser. He defined
19 frame types, and reported an f-score of 58.20%.
Various authors developed approaches assuming a
full syntactic analysis, which was usually annotated
manually in corpora (Briscoe and Carroll, 1997;
Kinyon and Prolo, 2002). Others associated syn-
tactic analyses to corpora with automatic parsers
(O?Donovan et al, 2005).
Various approaches were also found for languages
other than English. For German, (Eckle-Kohler,
1999) studied the behaviour of 6305 verbs on auto-
matically POS-tagged corpus data. He defined lin-
guistic heuristics by regular expression queries over
the usage of 244 frame types.
(Wauschkuhn, 1999) studied 1044 German verbs.
He extracted maximum of 2000 example sentences
for each verb from a corpus, and analyzed them
with partial (as opposed to full) syntactic analysis.
He found valency patterns, which were grouped in
order to extract the most frequent pattern combi-
nations, resulting in a verb-frame lexicon with 42
frame types.
(Schulte im Walde, 2000) worked with 18.7 mil-
lion words of German corpus, found 38 frame types.
She used the Duden das Stilwo?rterbuch(AG, 2001)
to evaluate results and reported f-score 57,24% with
PP and 62,30% without.
Many other approaches have been pursued for
various languages: (de Lima, 2002) for Portuguese,
(Georgala, 2003) for Greek, (Sarkar and Zeman,
2000) for Czech, (Spranger and Heid, 2003) for
Dutch, (Chesley and Salmon-Alt, 2006) for French
or (Chrupala, 2003) for Spanish, to name a few.
3 General description of the tool
IRASubcat takes as input a corpus in XML format.
This corpus is expected to have some kind of anno-
tation associated to its elements, which will enrich
the description of the patterns associated to verbs.
The minimal required annotation is that verbs are
marked. If no other information is available, the
form of words will be used to build the patterns. If
the corpus has rich annotation for its elements, the
system can build the patterns with the value of at-
tributes or with a combination of them, and also with
combinations with lexical items. The only require-
ments are that verbs are marked, and that all linguis-
tic units to be considered to build the patterns are
siblings in the XML tree.
The output of IRASubcat is a lexicon, also in
XML format, where each of the verbs under inspec-
tion is associated to a set of subcategorization pat-
terns. A given pattern is associated to a given verb
85
if the evidence found in the corpus passes certain
tests. Thresholds for these tests are defined by the
user, so that precision can be priorized over recall or
the other way round. In all cases, information about
the evidence found and the result of each test is pro-
vided, so that it can be easily assessed whether the
threshold for each test has the expected effects, and
it can be modified accordingly.
The lexicon also provides information about fre-
quencies of occurrence for verbs, patterns, and their
co-occurrences in corpus.
Moreover, IRASubcat is capable of integrating
the output lexicon with a pre-existing one, merg-
ing information about verbs and patterns with infor-
mation that had been previously extracted, possibly
from a different corpus or even from a hand-built
lexicon. The only requirement is that the lexicon is
in the same format as IRASubcat output lexicon.
4 A highly customizable tool
IRASubcat has been designed to be adaptable in a
variety of settings. The user can set the conditions
for many aspects of the tool, in order to extract dif-
ferent kinds of information for different representa-
tional purposes or from corpora with different kinds
of annotation. For example, the system accepts a
wide range of levels of annotation in the input cor-
pus, and it is language independent. To guarantee
that any language can be dealt with, the corpus needs
to be codified in UTF-8 format, in which virtually
any existing natural language can be codified.
If the user does not know how to customize these
parameters, she can resort to the default values that
are automatically provided by the system for each of
them. The only information that needs to be speci-
fied in any case is the name of the tag marking verbs,
the name of the parent tag for the linguistic units that
characterize patterns and, of course, the input cor-
pus.
The parameters of the system are as follows:
? The user can provide a list of verbs to be de-
scribed, so that any other verb will not be con-
sidered. If no list is provided, all words marked
as verb in the corpus will be described.
? The scope of patterns can be specified as a win-
dow of n words around the words marked as
verbs, where n is a number specified by the
user. It can also be specified that all elements
that are siblings of the verb in the XML tree are
considered, which is equivalent to considering
all elements in the scope of the clause, if that is
the parent node of the verb in an annotated cor-
pus. By default, a window of 3 sibling nodes at
each side of the verb is considered.
? It can be specified that patterns are completed
by a dummy symbol if the context of occur-
rence of the verb does not provide enough lin-
guistic elements to fill the specified window
length, for example, at the end of a sentence.
By default, no dummy symbol is used.
? It can be specified whether the order of occur-
rence of linguistic units should be taken into
account to characterize the pattern or not, de-
pending of the meaning of word order in the
language under study. By default, order is not
considered.
? We can provide a list of the attributes of lin-
guistic units that we want to study, for example,
syntactic function, morphological category, etc.
Attributes should be expressed as an XML at-
tribute of the unit. It can also be specified that
no attribute of the unit is considered, but only
its content, which is usually the surface form of
the unit. By default, an attribute named ?sint?
will be considered.
? We can specify whether the content of linguis-
tic units will be considered to build patterns.
As in the previous case, the content is usually
the surface form of the unit (lexical form). By
default, content is not considered.
? A mark describing the position of the verb can
be introduced in patterns. By default it is not
considered, to be coherent with the default op-
tion of ignoring word order.
? It can be specified that, after identifying possi-
ble adjuncts, patterns with the same arguments
are collapsed into the same pattern, with all
their characterizing features (number of occur-
rences, etc.). By default, patterns are not col-
lapsed.
? The number of iterations that are carried out on
patterns to identify adjuncts can be customized,
86
by default it is not considered because by de-
fault patterns are not collapsed.
? The user can specify a minimal number of oc-
currences of a verb to be described. By default,
the minimal frequency is 0, so all verbs that oc-
cur in the corpus are described.
? A minimal number of occurrences of a pattern
can also be specified, with the default as 0.
? The user can specify whether the Log-
Likelihood Ratio hypothesis test will be ap-
plied to test whether the association between a
verb and a pattern cannot be considered a prod-
uct of chance. By defect, the test is used (and
the output will be 90, 95, 99 or 99.5 when the
co-ocurrence have that confiability) .
5 Identification of adjuncts
One of the most interesting capabilities of IRASub-
cat is the identification of possible adjuncts. Ad-
juncts are linguistic units that do not make part of
the core of a subcategorization pattern (Fillmore,
1968). They are optional constituents in the con-
stituent structure governed by a verb. Since they are
optional, we assume they can be recognized because
the same pattern can occur with or without them
without a significant difference. IRASubcat imple-
ments a procedure to identify these units by their op-
tionality, described in what follows. An example of
this procedure is shown in Figure 1.
First, all patterns of a verb are represented in a
trie. A trie is a tree-like structure where patterns are
represented as paths in the trie. In our case, the root
is empty and each node represents a constituent of a
pattern, so that a pattern is represented by concate-
nating all nodes that are crossed when following a
path from the root. Each node is associated with a
number expressing the number of occurrences of the
pattern that is constructed from the root to that node.
Constituents are ordered by frequency, so that more
frequent constituents are closer to the root.
In this structure, it is easy to identify constituents
that are optional, because they are topologically lo-
cated at the leaves of the trie and the number of oc-
currences of the optional node is much smaller than
the number of occurrences of its immediately pre-
ceding node.
We have experimented with different ratios be-
tween the frequency of the pattern with and without
the constituent to identify adjuncts. We have found
that adjuncts are usually characterized by occurring
in leaves of the trie at least for 80% of the patterns
of the verb.
Once a constituent is identified as an adjunct, it
is removed from all patterns that contain it within
the verb that is being characterized at the moment.
A new trie is built without the adjunct, and so new
adjuncts may be identified. This procedure can be it-
erated until no constituent is found to be optional, or
until a user-defined number of iterations is reached.
When an adjunct is removed, the original pat-
tern is preserved, so that the user can see whether
a given pattern occurred with constituents that have
been classified as adjuncts, and precisely which con-
stituents.
When this data structure is created, the sequential
ordering of constituents is lost, in case it had been
preserved in the starting patterns. If the mark sig-
nalling the position of the verb had been introduced,
it is also lost. However, order and position of the
verb can be recovered in the final patterns, after ad-
juncts have been identified.
6 Associating patterns to verbs
One of the critical aspects of subcategorization ac-
quisition is the association of verbs and patterns.
How often must a pattern occur with a verb to make
part of the subcategorization frame of the verb? To
deal with this problem, different approaches have
been taken, going from simple co-occurrence count
to various kinds of hypothesis testing (Korhonen et
al., 2000).
To determine whether a verb and a pattern are as-
sociated, IRASubcat provides a co-occurrence fre-
quency threshold, that can be tuned by the user, and
a hypothesis test, the Likelihood Ratio test (Dun-
ning, 1993). We chose to implement this test, and
not others like the binomial that have been exten-
sively used in subcategorization acquisition, because
the Likelihood Ratio is specially good at modeling
unfrequent events.
To perform this test, the null hypothesis is that the
distribution of an observed pattern ?Mj? is indepen-
dent of of the distribution of verb ?Vi?.
87
Figure 1: Example of application of the procedure to identify adjuncts.
1. A starting set of patterns:
[NP DirObj PP-with], [NP DirObj], [NP DirObj], [NP DirObj
PP-with],[NP DirObj] y [NP DirObj PP-for]
2. Pattern constituents are ordered by frequency:
NP > DirObj > PP-with > PP-for
3. Constituents in patterns are ordered by their relative frequency:
[NP DirObj PP-with]
[NP DirObj]
[NP DirObj]
[NP DirObj PP-with]
[NP DirObj]
[NP DirObj PP-for]
4. A trie is built with patterns:
[NP DirObj] ->3
[NP DirObj PP-with] ->2
[NP DirObj PP-for] ->1
5. Leafs in the trie are ?DirObj?,?PP-with? and ?PP-for?. Since DirObj also occurs in the trie in a
position other than leaf, it will not be considered as an adjunct in this iteration. In contrast, both
PP-with and PP-for fulfill the conditions to be considered adjuncts, so we prune the patterns the trie,
which will now have the single pattern, which forms a trie with 2 adjuncts (with information about
the number of occurrences of each adjunct constituent):
[NP DirObj {PP-with:1 PP-for:2}]
6. If the trie has been modified in this iteration, we go back to 2. If no modification has been operated,
the procedure ends.
88
Moreover, the user can also specify a minimum
number of occurrences of a verb to be taken into
consideration, thus ruling out verbs for which there
is not enough evidence in the corpus to obtain reli-
able subcategorization information.
7 Examples of applications
We have applied IRASubcat to two very different
corpora in order to test its functionalities.
We have applied it to the SenSem corpus
(Castello?n et al, 2006), a corpus with 100 sentences
for each of the 250 most frequent verbs of Span-
ish, manually annotated with information of verbal
sense, syntactical function and semantic role of sen-
tence constituents, among other information. From
all the available information, we specified as input
parameter for IRASubcat to consider only the syn-
tactic function of sentence constituents. Thus, the
expected output was the syntactic aspect of subcat-
egorization frames of verbs. We worked with the
verbal sense as the unit.
We compared the patterns associated to each ver-
bal sense by IRASubcat with the subcategorization
frames manually associated to the verbs at the a lex-
ical data base of SenSem verbs1. We manually in-
spected the results for the 20 most frequent verbal
senses. Results can be seen at Table 1. We found
that the frequency threshold was the best filter to as-
sociate patterns and verbs, obtaining an f-measure
of 74%. When hypothesis tests were used as a crite-
rion to filter out associations of patterns with verbal
senses, performance dropped, as can be seen in the
lower rows of Table 1.
We also applied IRASubcat to an unannotated
corpus of Russian. The corpus was automatically
POS-tagged with TreeTagger (Schmid, 1994). We
applied IRASubcat to work with parts of speech to
build the patterns.
We manually inspected the patterns associated to
prototypical intransitive (?sleep?), transitive (?eat?)
and ditransitive (?give?) verbs. We found that pat-
terns which were more strongly associated to verbs
corresponded to their prototypical behaviour. For
example, the patterns associated to the verb ?eat?
reflect the presence of a subject and a direct object:
1The lexical data base of SenSem verbs can be found at
http://grial.uab.es/adquisicio/.
Pattern occurrences % Likelihood
Ratio Test
[?V?, ?Nn?] 5 99
[?V?, ?C?] 5 95
[?V?, ?R?] 4 did not pass
[?V?, ?Nn?, ?C?, ?Q?] 3 95
[?V?, ?V?, ?Nn?, ?Nn?] 3 99
[?V?, ?Nn?, ?Na?] 3 99,5
[?Nn?, ?C?] 3 90
[?V?, ?Nn?, ?Nn?] 3 99
[?V?, ?R?, ?Q?] 2 95
[?V?, ?Nn?, ?An?] 2 99
For more details on evaluation, see (Altamirano,
2009).
8 Conclusions and Future Work
We have presented a highly flexible tool to acquire
verbal subcategorization information from corpus,
independently of the language and level of annota-
tion of the corpus. It is capable of identifying ad-
juncts and performs different tests to associate pat-
terns with verbs. Thresholds for these tests can be
set by the user, as well as a series of other sys-
tem parameters. Moreover, the system is platform-
independent and open-source2.
We are currently carrying out experiments to as-
sess the utility of the tool with two very different
corpora: the SenSem corpus of Spanish, where sen-
tences have been manually annotated with informa-
tion about the category, function and role of the ar-
guments of each verb, and also a raw corpus of Rus-
sian, for which only automatic part-of-speech tag-
ging is available. Preliminary results indicate that,
when parameters are properly set, IRASubcat is ca-
pable of identifying reliable subcategorization infor-
mation in corpus.
As future work, we plan to integrate evaluation
capabilities into the tool, so that it can provide pre-
cision and recall figures if a gold standard subcate-
gorization lexicon is provided.
Acknowledgments
This research has been partially funded by projects
KNOW, TIN2006-15049-C03-01 and Representa-
tion of Semantic Knowledge TIN2009-14715-C04-
03 of the Spanish Ministry of Education and Cul-
2IRASubcat is available for download at http://www.
irasubcat.com.ar
89
applied filter Precision Recall F-measure
Frequency .79 .70 .74
likelihood ratio 90% .42 .46 .39
likelihood ratio 95% .38 .42 .32
likelihood ratio 99% .31 .36 .22
likelihood ratio 99.5% .25 .28 .14
Table 1: Performance of IRASubcat to acquire subcategorization information from the SenSem corpus, for the 20
most frequent verbal senses, as compared with manual association of subcategorization patterns with verbal senses.
Performance with different filters is detailed: only the most frequent patterns are considered, or only patterns passing
a hypothesis test are considered.
ture, and by project PAE-PICT-2007-02290, funded
by the National Agency for the Promotion of Sci-
ence and Technology in Argentina.
References
Bibliographisches Institut & F. A. Brockhaus AG, editor.
2001. Duden das Stilwo?rterbuch. Dudenverlag.
I. Romina Altamirano. 2009. Irasubcat: Un sistema
para adquisicio?n automa?tica de marcos de subcatego-
rizacio?n de piezas le?xicas a partir de corpus. Master?s
thesis, Facultad de Matema?tica, Astronom??a y F??sica,
Universidad Nacional de Co?rdoba, Argentina.
Michael R. Brent. 1993. From grammar to lexicon: un-
supervised learning of lexical syntax. Comput. Lin-
guist., 19(2):243?262.
Ted Briscoe and John Carroll. 1997. Automatic extrac-
tion of subcategorization from corpora. pages 356?
363.
J. Carroll and A. Fang. 2004. The automatic acquisition
of verb subcategorisations and their impact on the per-
formance of an HPSG parser. In Proceedings of the 1st
International Joint Conference on Natural Language
Processing (IJCNLP), pages 107?114.
J. Carroll, G. Minnen, and T. Briscoe. 1999. Corpus
annotation for parser evaluation. In Proceedings of the
EACL-99 Post-conference Workshop on Linguistical ly
Interpreted Corpora, pages 35?41, Bergen, Norway.
Irene Castello?n, Ana Ferna?ndez-Montraveta, Glo`ria
Va?zquez, Laura Alonso, and Joanan Capilla. 2006.
The SENSEM corpus: a corpus annotated at the syntac-
tic and semantic level. In 5th International Conference
on Language Resources and Evaluation (LREC 2006).
Paula Chesley and Susanne Salmon-Alt. 2006. Au-
tomatic extraction of subcategorization frames for
french.
Grzegorz Chrupala. 2003. Acquiring verb subcatego-
rization from spanish corpora. Master?s thesis, Uni-
versitat de Barcelona.
Erika de Lima. 2002. The automatic acquisition
of lexical information from portuguese text corpora.
Master?s thesis, Institut fu?r Maschinelle Sprachverar-
beitung, Universita?t Stuttgart.
Ted Dunning. 1993. Accurate methods for the statistics
of surprise and coincidence. COMPUTATIONAL LIN-
GUISTICS.
Judith Eckle-Kohler. 1999. Linguistic knowledge for au-
tomatic lexicon acquisition from german text corpora.
Charles J. Fillmore. 1968. The case for case. In E. Bach
and R. T. Harms, editors, Universals in Linguistic The-
ory. Holt, Rinehart, and Winston, New York.
Effi Georgala. 2003. A statistical grammar model for
modern greek: The context-free grammar.
Alexandra Kinyon and Carlos A. Prolo. 2002. Identify-
ing verb arguments and their syntactic function in the
penn treebank. pages 1982?1987.
Anna Korhonen, Genevieve Gorrell, and Diana Mc-
Carthy. 2000. Statistical filtering and subcategoriza-
tion frame acquisition. In Proceedings of the 2000
Joint SIGDAT conference on Empirical methods in
natural language processing and very large corpora,
pages 199?206, Morristown, NJ, USA. Association for
Computational Linguistics.
Christopher D. Manning. 1993. Automatic acquisition
of a large subcategorization dictionary from corpora.
pages 235?242.
Ruth O?Donovan, Michael Burke, Aoife Cahill, Josef van
Genabith, and Andy Way. 2005. Large-scale induc-
tion and evaluation of lexical resources from the penn-
ii and penn-iii treebanks. volume 31, pages 329?365.
Evan Sandhaus, editor. New York Times.
Anoop Sarkar and Daniel Zeman. 2000. Automatic ex-
traction of subcategorization frames for czech. pages
691?697.
H. Schmid. 1994. Probabilistic part?of?speech tagging
using decision trees. In Proceedings of the Conference
on New Methods in Language Processing, pages 44?
49, Manchester, UK.
90
Sabine Schulte im Walde. 2000. Clustering verbs se-
mantically according to their alternation behaviour. In
COLING?00, pages 747?753.
Kristina Spranger and Ulrich Heid. 2003. A dutch chun-
ker as a basis for the extraction of linguistic knowl-
edge.
Mihai Surdeanu, Sanda Harabagiu, John Williams, and
Paul Aarseth. 2003. Using predicate arguments struc-
tures for information extraction. In Proceedings of the
41st Annual Meeting of the Association for Computa-
tional Linguistics (ACL 2003).
Akira Ushioda, David A. Evans, Ted Gibson, and Alex
Waibel. 1993. The automatic acquisition of frequen-
cies of verb subcategorization frames from tagged cor-
pora. pages 95?106.
Oliver Wauschkuhn. 1999. Automatische extraktion von
verbvalenzen aus deutschen text korpora. Master?s
thesis, Universita?t Stuttgart.
WSJ, editor. 1994. Wall Street Journal.
91
