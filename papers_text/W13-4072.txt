Proceedings of the SIGDIAL 2013 Conference, pages 462?466,
Metz, France, 22-24 August 2013. c?2013 Association for Computational Linguistics
Engineering Statistical Dialog State Trackers: A Case Study on DSTC
Daejoong Kim, Jaedeug Choi, Kee-Eung Kim
Department of Computer Science, KAIST
South Korea
{djkim, jdchoi, kekim}@ai.kaist.ac.kr
Jungsu Lee, Jinho Sohn
LG Electronics
South Korea
{jungsu.lee, jinho.sohn}@lge.com
Abstract
We describe our experience with engineer-
ing the dialog state tracker for the first
Dialog State Tracking Challenge (DSTC).
Dialog trackers are one of the essential
components of dialog systems which are
used to infer the true user goal from the
speech processing results. We explain the
main parts of our tracker: the observation
model, the belief refinement model, and
the belief transformation model. We also
report experimental results on a number
of approaches to the models, and compare
the overall performance of our tracker to
other submitted trackers. An extended ver-
sion of this paper is available as a technical
report (Kim et al, 2013).
1 Introduction
In spoken dialog systems (SDSs), one of the main
challenges is to identify the user goal from her ut-
terances. The significance of accurately identify-
ing the user goal, referred to as dialog state track-
ing, has emerged from the need for SDSs to be
robust to inevitable errors in the spoken language
understanding (SLU).
A number of studies have been conducted to
track the dialog state through multiple dialog turns
using a probabilistic framework, treating SLU re-
sults as noisy observations and maintaining prob-
ability distribution (i.e., belief) on user goals (Bo-
hus and Rudnicky, 2006; Mehta et al, 2010; Roy
et al, 2000; Williams and Young, 2007; Thomson
and Young, 2010; Kim et al, 2011).
In this paper, we share our experience and
lessons learned from developing the dialog state
tracker that participated in the first Dialog State
Tracking Challenge (DSTC) (Williams et al,
2013). Our tracker is based on the belief up-
date in the POMDP framework (Kaelbling et al,
1998), particularly the hidden information state
(HIS) model (Young et al, 2010) and the partition
recombination method (Williams, 2010).
2 Dialog State Tracking
Our tracker mainly follows the belief update in
HIS-POMDP (Young et al, 2010). The SDS ex-
ecutes system action a, and the user with goal
g responds to the system with utterance u. The
SLU processes the utterance and generates the re-
sult as anN -best list o = [?u?1, f1?, . . . , ?u?N , fN ?]
of the hypothesized user utterance u?i and its as-
sociated confidence score fi. Because the SLU
is not perfect, the system maintains a probability
distribution over user goals, called a belief. In ad-
dition, the system groups user goals into equiva-
lence classes and assigns a single probability for
each equivalence class since the number of user
goals is often too large to perform individual be-
lief updates for all possible user goals. The equiv-
alence classes are called partitions and denoted as
?. Hence, given the current belief b, system action
a, and recognized N -best list o, the dialog state
tracker updates the belief b? over partitions as fol-
lows:
b?(??) ?
?
u
Pr(o|u) Pr(u|??, a) Pr(??|?)b(?)
(1)
where Pr(o|u) is the observation model,
Pr(u|?, a) is the user utterance model, Pr(??|?)
is the belief refinement model.
2.1 Observation Model
The observation model Pr(o|u) is the probability
that the SLU produces the N -best list o when the
user utterance is u. We experimented with the fol-
lowing three models for the observation model.
Confidence score model: as in HIS-POMDP,
this model assumes that the confidence score fi
obtained from the SLU is exactly the probability
462
of generating the hypothesized user utterance u?i.
Hence, fi = Pr(u?i, fi|u).
Histogrammodel: this model estimates a func-
tion that maps the confidence score to the proba-
bility of correctness. We constructed a histogram
of confidence scores from the training datasets
to obtain the empirical probability Pr(cor(fi)) of
whether the entry associated with confidence score
fi is a correct hypothesis or not.
Generative model: this model is a simplified
version of a generative model in (Williams, 2008)
that only uses confidence score: Pr(u?i, fi|u) =
Pr(cor(i)) Pr(fi|cor(i)) where Pr(cor(i)) is the
probability of the i-th entry being a correct hy-
pothesis and Pr(fi|cor(i)) is the probability of the
i-th entry having confidence score fi when it is a
correct hypothesis.
2.2 User Utterance Model
The user utterance model Pr(u|?, a) indicates
how the user responds to the system action a
when the user goal is in ?. We adopted the HIS-
POMDP user utterance model, consisting of a bi-
gram model and an item model. The details are
described in (Kim et al, 2013).
2.3 Belief Refinement Model
Given the SLU result u?i and the system action
a, the partition ? is split into ??i with probabil-
ity Pr(??i|?) and ? ? ??i with probability Pr(? ?
??i|?). The belief refinement model Pr(??i|?) can
be seen as the proportion of the belief that is car-
ried from ? to ??i. This probability can be defined
by the following models:
Empirical model: we count n(?) from the
training datasets, which is the number of user
goals that are consistent with partition ?. The
probability is then modeled as Pr(??i|?) =
n(??i)
n(?)
if n(?) > 0 and Pr(??i|?) = 0 otherwise.
Word-match model: this model extends the
empirical model by using the domain knowledge
when the SLU result u?i does not appear in the
training datasets. We calculated how many words
w ? W in the user utterance u?i were included in
a bus timetable D. The model is thus defined as
Pr(??i|?) =
n(??i)
n(?) if n(??i) > 0 and Pr(??i|?) =
?
|W |
?
w?W ?(w ? D) otherwise. ? is the indica-
tor function (?(x) = 1 if x holds and ?(x) = 0
otherwise) and ? is the parameter estimated via
cross-validation.
Mixture model: this model mixes the empiri-
cal model with a uniform probability, defined as
Pr(??i|?) = ? 1nG + (1 ? ?)
n(??i)
n(?) if n(??i) > 0 and
Pr(??i|?) = 1nG otherwise. nG is the number of all
possible user goals which is treated as the param-
eter of the model and found via cross-validation,
together with the mixing parameter ? ? [0, 1].
2.4 Belief Transformation Model
The belief update described above pro-
duces the M -best hypotheses of user goals
[?g?1, b(g?1)?, . . . , ?g?M , b(g?M )?] in each dialog turn,
which consists of M most likely user goal hy-
potheses g?i and their associated beliefs b(g?i). The
last hypothesis g?M is reserved as the null hypoth-
esis ? with the belief b(?) = 1 ??M?1i=1 b(g?i),
which represents that the user goal is not known
up to the current dialog turn.
One of the problems with the belief update is
that the null hypothesis often remains as the most
probable hypothesis even when the SLU result
contains the correct user utterance with a high con-
fidence score. This is because an atomic hypothe-
sis has a very small prior probability.
To overcome this problem, we added a post-
processing step which transforms each belief b(hi)
to the final confidence score si.
Threshold model: this model ensures that the
top hypothesis has confidence score ? when a be-
lief of the hypothesis is greater than a threshold ?.
The final output list is [?h?, s??, ??, 1?s??] where
h? = argmaxh?{g?1,...,g?M?1} b(h) and
s? =
{
?, if b(h?) > ?
b(h?), otherwise.
(2)
Full-list regression model: this model esti-
mates the probability that each hypothesis is cor-
rect via casting the task as regression. The
model uses two logistic regression functions F?
and Fh. F? predicts the probability of correct-
ness for the null hypothesis ? using the sin-
gle input feature ?? = b(?). Likewise, Fh
predicts the probability of correctness for non-
null hypotheses hi using the input feature ?i =
b(hi). The model generates the final output
list [?h1, s1?, . . . , ?hM?1, sM?1?, ??, sM ?] where
hi = g?i and
si =
?
?
?
F?(?i)
PM?1
j=1 Fh(?j)+F?(??)
, if i = M
Fh(?i)
PM?1
j=1 Fh(?j)+F?(??)
, otherwise.
(3)
463
Rank regression model: this model works in
a similar way as in the full-link regression model,
except that it uses a single logistic regression func-
tion Fr for both the non-null and null hypothe-
ses, and takes the rank value of the hypotheses
as an additional input feature. The final out-
put list is [?h1, s1?, . . . , ?hM?1, sM?1?, ??, sM ?]
where hi = g?i and
si = Fr(?i)PM
j=1 Fr(?j)
. (4)
3 Experimental Setup
In the experiments, we used three labeled train-
ing datasets (train1a, train2, train3) and three test
datasets (test1, test2, test3) used in DSTC. There
was an additional test dataset (test4), which we
decided not to include in the experiments since
we found that a significant number of labels were
missing or incorrect.
We measured the tracker performance accord-
ing to the following evaluation metrics used in
DSTC1: accuracy (acc) measures the rate of the
most likely hypothesis h1 being correct, average
score (avgp) measures the average of scores as-
signed to the correct hypotheses, l2 norm mea-
sures the Euclidean distance between the vector
of scores from the tracker and the binary vector
with 1 in the position of the correct hypotheses,
and 0 elsewhere, mean reciprocal rank (mrr)
measures the average of 1/R, where R is the
minimum rank of the correct hypothesis, ROC
equal error rate (eer) is the sum of false accept
(FA) and false reject (FR) rates when FA rate=FR
rate, andROC.{v1,v2}.P measures correct accept
(CA) rate when there are at most P% false accept
(FA) rate2.
4 Results and Analyses
Since there are multiple slots to track in the dialog
domain, we report the average performance over
the ?marginal? slots including the ?joint? slot that
assigns the values to all slots.
4.1 Observation Model
Tbl. 1 shows the cross-validation results of the
three observation models. In train1a and train2, no
model had a clear advantage to others, whereas in
1http://research.microsoft.com/apps/pubs/?id=169024
2There are two types of ROC measured in DSTC depend-
ing on how CA and FA rates are calculated. The detailed dis-
cussion is provided in the longer version of the paper (Kim et
al., 2013).
Table 1: Evaluation of observation models.
Train1a Train2 Train3
Conf Hist Gen Conf Hist Gen Conf Hist Gen
accuracy 0.81 0.82 0.82 0.84 0.86 0.85 0.90 0.89 0.88
avgp 0.77 0.78 0.78 0.81 0.82 0.82 0.81 0.79 0.77
l2 0.31 0.30 0.30 0.26 0.25 0.25 0.25 0.27 0.30
mrr 0.87 0.87 0.88 0.89 0.89 0.89 0.94 0.93 0.92
roc.v1.05 0.69 0.70 0.70 0.73 0.74 0.74 0.82 0.80 0.79
roc.v1.10 0.74 0.75 0.75 0.78 0.80 0.80 0.87 0.85 0.83
roc.v1.20 0.78 0.79 0.79 0.83 0.84 0.84 0.89 0.87 0.85
roc.v1.eer 0.14 0.14 0.14 0.12 0.13 0.13 0.10 0.11 0.12
roc.v2.05 0.34 0.34 0.34 0.24 0.15 0.23 0.52 0.54 0.52
roc.v2.10 0.54 0.46 0.46 0.33 0.26 0.25 0.71 0.67 0.70
roc.v2.20 0.70 0.70 0.69 0.43 0.41 0.41 0.83 0.78 0.80
Table 2: Evaluation of belief refinement models.
Train1a Train2 Train3
Emp WordMix Emp WordMix Emp WordMix
accuracy 0.75 0.77 0.81 0.80 0.84 0.84 0.71 0.88 0.90
avgp 0.75 0.76 0.77 0.78 0.80 0.81 0.68 0.80 0.81
l2 0.34 0.34 0.31 0.31 0.27 0.26 0.42 0.26 0.25
mrr 0.83 0.85 0.87 0.86 0.89 0.89 0.82 0.93 0.94
roc.v1.05 0.66 0.68 0.69 0.64 0.68 0.73 0.58 0.78 0.82
roc.v1.10 0.69 0.71 0.74 0.73 0.78 0.78 0.65 0.83 0.87
roc.v1.20 0.73 0.74 0.78 0.77 0.82 0.83 0.68 0.86 0.89
roc.v1.eer 0.22 0.13 0.14 0.13 0.13 0.12 0.13 0.11 0.10
roc.v2.05 0.34 0.24 0.34 0.30 0.24 0.24 0.61 0.51 0.52
roc.v2.10 0.47 0.38 0.54 0.42 0.26 0.33 0.64 0.67 0.71
roc.v2.20 0.72 0.60 0.70 0.56 0.37 0.43 0.72 0.77 0.83
train3, the confidence score model outperformed
others. Further analyses revealed that the confi-
dence scores from the SLU results were not suf-
ficiently indicative of the SLU accuracy in train1a
and train2. The histogram and the generative mod-
els are expected to perform at least as well as the
confidence score model in train3, but they didn?t
in the experiments. We suspect that this is due to
the naive binning strategy we used to model the
probability distribution.
4.2 Belief Refinement Model
As shown in Tbl. 2, the mixture model outper-
formed others throughout the metrics. It even
outperforms the word-match model which tries to
leverage the domain knowledge to handle novel
user goals. This implies that, unless the domain
knowledge is used properly, simply taking the
mixture with the uniform distribution yields a suf-
ficient level of performance.
4.3 Belief Transformation Model
Tbl. 3 summarizes the performances of the belief
transformation models. All three models outper-
formed the pure belief update, although not shown
464
Table 3: Evaluation of belief transform models.
Train1a Train2 Train3
Thre Full Rank Thre Full Rank Thre Full Rank
accuracy 0.81 0.81 0.81 0.83 0.84 0.85 0.89 0.90 0.90
avgp 0.80 0.77 0.77 0.82 0.81 0.81 0.85 0.81 0.78
l2 0.28 0.31 0.32 0.25 0.26 0.26 0.22 0.25 0.28
mrr 0.84 0.87 0.87 0.86 0.89 0.89 0.91 0.94 0.92
roc.v1.05 0.66 0.69 0.69 0.65 0.73 0.72 0.45 0.82 0.80
roc.v1.10 0.71 0.74 0.75 0.69 0.78 0.79 0.68 0.87 0.86
roc.v1.20 0.71 0.78 0.78 0.74 0.83 0.83 0.79 0.89 0.89
roc.v1.eer 0.18 0.14 0.14 0.21 0.12 0.12 0.49 0.10 0.09
roc.v2.05 0.22 0.34 0.34 0.20 0.24 0.24 0.42 0.52 0.48
roc.v2.10 0.41 0.54 0.52 0.22 0.33 0.33 0.42 0.71 0.56
roc.v2.20 0.64 0.70 0.71 0.30 0.43 0.49 0.43 0.83 0.75
in the table. The full-list and the rank regres-
sion models show a similar level of performance
improvement. This is a naturally expected result
since they use regression to convert the beliefs to
final confidence scores, as an attempt to compen-
sate for the errors incurred by approximations and
assumptions made in the observation and belief re-
finement models.
4.4 DSTC Result
In order to compare our tracker with others par-
ticipated in DSTC, we chose tracker43 as the most
effective one among our 5 submitted trackers since
it achieved the top scores in the largest num-
ber of evaluation metrics. In the same way, we
selected tracker2 for team3, tracker3 for team6,
tracker3 for team8, and tracker1 for the rest of the
teams. The results of each team are presented in
Tbl. 4. The baseline tracker is included as a ref-
erence, which simply outputs the hypothesis with
the largest SLU confidence score in the N -best
list.
Compared to other teams, our tracker showed
strong performance in acc, avgp, l2 and mrr. A
detailed discussion on the results is provided in the
longer version of the paper (Kim et al, 2013).
5 Conclusion
In this paper, we described our experience with
engineering a statistical dialog state tracker while
participating in DSTC. Our engineering effort was
focused on improving three important models in
the tracker: the observation, the belief refine-
ment, and the belief transformation models. Us-
ing standard statistical techniques, we were able
3The tracker4 used the confidence score model, the mix-
ture model and the rank regression model.
Table 4: Results of the trackers. The bold face
denotes top 3 scores in each evaluation metric. T9
is our tracker.
BaseT1 T2 T3 T4 T5 T6 T7 T8 T9
Test 1
accuracy 0.71 0.83 0.81 0.81 0.74 0.80 0.87 0.78 0.51 0.82
avgp 0.73 0.77 0.77 0.81 0.74 0.79 0.82 0.76 0.49 0.79
l2 0.38 0.32 0.32 0.27 0.37 0.30 0.25 0.34 0.72 0.29
mrr 0.80 0.88 0.86 0.85 0.81 0.85 0.90 0.84 0.59 0.88
roc.v1.05 0.62 0.72 0.67 0.60 0.20 0.71 0.76 0.65 0.20 0.72
roc.v1.10 0.63 0.78 0.75 0.77 0.29 0.75 0.82 0.70 0.33 0.76
roc.v1.20 0.67 0.82 0.79 0.79 0.53 0.78 0.85 0.76 0.35 0.79
roc.v1.eer 0.24 0.13 0.25 0.24 0.74 0.12 0.12 0.15 0.52 0.14
roc.v2.05 0.49 0.64 0.01 0.02 0.00 0.55 0.16 0.19 0.04 0.26
roc.v2.10 0.69 0.71 0.14 0.03 0.00 0.68 0.39 0.35 0.05 0.47
roc.v2.20 0.71 0.80 0.48 0.29 0.00 0.74 0.59 0.58 0.27 0.62
Test 2
accuracy 0.55 0.65 0.71 0.68 0.63 0.62 0.79 0.65 0.34 0.71
avgp 0.57 0.55 0.63 0.68 0.63 0.62 0.71 0.65 0.29 0.65
l2 0.60 0.63 0.50 0.45 0.52 0.54 0.39 0.49 1.00 0.48
mrr 0.65 0.72 0.79 0.76 0.71 0.72 0.84 0.74 0.46 0.80
roc.v1.05 0.43 0.49 0.52 0.45 0.16 0.48 0.66 0.48 0.04 0.49
roc.v1.10 0.45 0.54 0.57 0.63 0.16 0.51 0.71 0.54 0.11 0.57
roc.v1.20 0.48 0.59 0.64 0.64 0.27 0.54 0.76 0.60 0.26 0.63
roc.v1.eer 0.19 0.20 0.39 0.14 0.63 0.21 0.16 0.19 0.36 0.22
roc.v2.05 0.43 0.52 0.24 0.27 0.00 0.40 0.46 0.41 0.05 0.38
roc.v2.10 0.47 0.60 0.40 0.37 0.00 0.62 0.53 0.47 0.17 0.41
roc.v2.20 0.50 0.70 0.48 0.56 0.00 0.70 0.62 0.55 0.44 0.47
Test 3
accuracy 0.79 0.79 0.84 0.82 0.82 0.78 0.84 0.79 0.79 0.85
avgp 0.75 0.72 0.76 0.79 0.78 0.70 0.75 0.75 0.76 0.74
l2 0.35 0.37 0.32 0.29 0.30 0.40 0.33 0.34 0.32 0.34
mrr 0.83 0.85 0.88 0.85 0.85 0.83 0.89 0.84 0.80 0.89
roc.v1.05 0.56 0.65 0.68 0.72 0.70 0.62 0.69 0.70 0.33 0.74
roc.v1.10 0.66 0.70 0.77 0.77 0.76 0.69 0.76 0.74 0.47 0.78
roc.v1.20 0.74 0.76 0.82 0.80 0.80 0.74 0.81 0.77 0.61 0.82
roc.v1.eer 0.19 0.16 0.15 0.27 0.12 0.17 0.15 0.12 0.34 0.13
roc.v2.05 0.56 0.62 0.34 0.28 0.21 0.62 0.61 0.14 0.00 0.56
roc.v2.10 0.59 0.71 0.48 0.37 0.52 0.66 0.66 0.42 0.00 0.67
roc.v2.20 0.66 0.78 0.73 0.52 0.82 0.71 0.78 0.87 0.00 0.79
to produce a tracker that performed competitively
among the participants.
As for the future work, we plan to refine the
user utterance model for improving the perfor-
mance of the tracker since there are a number of
user utterances that are not handled by the cur-
rent model. We also plan to re-evaluate our tracker
with properly handling the joint slot, since the cur-
rent tracker constructs models independently for
each marginal slot and then combines the results
by simply multiplying the predicted scores.
Acknowledgement
This work was supported by NRF of Korea
(Grant# 2012-007881), and MKE/KEIT of Korea
(IT R&D Program Contract# 10041678)
465
References
Dan Bohus and Alex Rudnicky. 2006. A ?k hypothe-
ses + other? belief updating model. In Proceedings
of the AAAI Workshop on Statistical and Empirical
Approaches for Spoken Dialogue Systems.
Leslie Pack Kaelbling, Michael L. Littman, and An-
thony R. Cassandra. 1998. Planning and acting in
partially observable stochastic domains. Artificial
Intelligence, 101(1?2):99?134.
Dongho Kim, Jin Hyung Kim, and Kee-Eung Kim.
2011. Robust performance evaluation of POMDP-
based dialogue systems. IEEE Transactions on Au-
dio, Speech, and Language Processing, 19(4):1029?
1040.
Daejoong Kim, Jaedeug Choi, Kee-Eung Kim, Jungsu
Lee, and Jinho Sohn. 2013. Engineering statistical
dialog state trackers:a case study on DSTC. Techni-
cal Report CS-TR-2013-379, Department of Com-
puter Science, KAIST.
Neville Mehta, Rakesh Gupta, Antoine Raux, Deepak
Ramachandran, and Stefan Krawczyk. 2010. Prob-
abilistic ontology trees for belief tracking in dialog
systems. In Proceedings of the 11th Annual Meet-
ing of the Special Interest Group on Discourse and
Dialogue (SIGDIAL), pages 37?46.
Nicholas Roy, Joelle Pineau, and Sebastian Thrun.
2000. Spoken dialogue management using proba-
bilistic reasoning. In Proceedings of the 38th An-
nual Meeting on Association for Computational Lin-
guistics (ACL), pages 93?100.
Blaise Thomson and Steve Young. 2010. Bayesian
update of dialogue state: A POMDP framework for
spoken dialogue systems. Computer Speech and
Language, 24(4):562?588.
Jason D. Williams and Steve Young. 2007. Partially
observable Markov decision processes for spoken
dialog systems. Computer Speech and Language,
21(2):393?422.
Jason Williams, Antoine Raux, Deepak Ramachan-
dran, and Alan Black. 2013. The dialog state track-
ing challenge. In Proceedings of the 14th Annual
Meeting of the Special Interest Group on Discourse
and Dialogue (SIGDIAL).
Jason D. Williams. 2008. Exploiting the ASR N-best
by tracking multiple dialog state hypotheses. In Pro-
ceedings of the 9th Annual Conference of the In-
ternational Speech Communication Association (IN-
TERSPEECH), pages 191?194.
Jason D. Williams. 2010. Incremental partition re-
combination for efficient tracking of multiple dia-
log states. In Proceedings of the IEEE International
Conference on Acoustics Speech and Signal Pro-
cessing (ICASSP), pages 5382?5385.
Steve Young, Milica Gas?ic?, Simon Keizer, Franc?ois
Mairesse, Jost Schatzmann, Blaise Thomson, and
Kai Yu. 2010. The hidden information state model:
A practical framework for POMDP-based spoken di-
alogue management. Computer Speech and Lan-
guage, 24(2):150?174.
466
