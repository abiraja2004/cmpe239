Proceedings of the 2009 Workshop on Graph-based Methods for Natural Language Processing, ACL-IJCNLP 2009, pages 54?57,
Suntec, Singapore, 7 August 2009. c?2009 ACL and AFNLP
Graph-based Event Coreference Resolution 
Zheng Chen
The Graduate Center
The City University of New York
zchen1@gc.cuny.edu
Heng Ji
Queens College and The Graduate Center
The City University of New York
hengji@cs.qc.cuny.edu
Abstract
In this paper, we address the problem of event 
coreference resolution as specified in the Au-
tomatic Content Extraction (ACE1
1 Introduction
) program.
In contrast to entity coreference resolution, 
event coreference resolution has not received 
great attention from researchers. In this paper, 
we first demonstrate the diverse scenarios of 
event coreference by an example. We then 
model event coreference resolution as a spec-
tral graph clustering problem and evaluate the
clustering algorithm on ground truth event 
mentions using ECM F-Measure. We obtain 
the ECM-F scores of 0.8363 and 0.8312 re-
spectively by using  two methods for compu-
ting coreference matrices.
Typically, an ACE Event Detection and Recog-
nition (VDR) system consists of two steps: first, 
it detects all mentions of events with certain spe-
cified types occurring in the raw text (event men-
tion detection) and second, it unifies the event 
mentions into equivalence classes so that all the 
mentions in a given class refer to an event (event 
coreference resolution). ACEdefines the follow-
ing terminologies related with VDR:
z Event: a specific occurrence involving partic-
ipants. An ACE event has six attributes (type, 
subtype, modality, polarity, genericity and 
tense), zero or more event arguments, and a 
cluster of event mentions.
z Event trigger: the word that most clearly ex-
presses an event?s occurrence.
z Event argument:  an entity, or a temporal ex-
pression or a value that has a certain role (e.g., 
Time-Within, Place) in an event. 
z Event mention: a sentence (or a text span
extent) that mentions an event, including a 
distinguished trigger and involving arguments.
1 http://www.nist.gov/speech/tests/ace/
In contrast to entity coreference, the scenarios 
in event coreference are more complicated, 
mainly because entity coreference is word (or 
phrase)-level coreference whereas event corefe-
rence is sentence-level coreference and therefore
the coreferring event mentions may have more 
flexible linguistic structures than entity mentions.
We provide an example to demonstrate this di-
versity. 
EM1An {explosion} in a cafe at one of the capital's 
busiest intersections killed one woman and injured 
another Tuesday
EM2Police were investigating the cause of the {ex-
plosion} in 
, police said.
the restroom of the multistory Crocodile 
Cafe in the commercial district of Kizilay dur-
ing the morning rush hour. EM3The {blast} shattered 
walls and windows in the building
EM4Ankara police chief Ercument Yilmaz vi-
sited 
.
the site of the morning blast but refused to say 
if a bomb
EM5The {explosion} comes a month after EM6
had caused the {explosion}.
a bomb
{exploded} at a McDonald's restaurant in Istanbul
EM7
,
causing damage but no injuries.
Radical leftist, Kurdish and Islamic groups are 
active in the country and have carried out {bomb-
ings} in the past.
Table 1. Source text and event mentions
Table 1 shows the source text of a news story. 
As an example, we only tag the event mentions 
which have the event type and subtype of (Con-
flict:Attack). In each event mention, the trigger is 
surrounded by curly brackets, and arguments are 
underlined. 
Table 2 shows the tabular representation of 
those event mentions.
Table 3 shows that the five event mentions in 
event EV1 corefer with each other. We summar-
ize EV1 as follows: a bomb (E4-1) exploded in 
the restroom (E2-1) of a caf? (E1-1 or E1-2) dur-
ing Tuesday morning?s rush hour (combination 
of T1-1, T2-1 and T3-1). EV2 is a different at-
tack event because the target (E6-1) in EV2 dif-
fers from the one (E1-3) in EV1. EV3 tells that 
the bombing attacks have occurred generically 
54
(thus the event attribute ?genericity? is ?General? 
whereas it is ?Specific? in EV1 and EV2).
EM1 Trigger: explosion
Arguments (ID: ROLE):
(E1-1: Place) a cafe at one of the capital's 
busiest intersections
(T1-1: Time-Within) Tuesday
EM2 Trigger: explosion
Arguments:
(E2-1: Place) the restroom of the multistory 
Crocodile Cafe
(E3-1: Place) the commercial district of 
Kizilay
(T2-1: Time-Within) the morning rush hour
EM3 Trigger: blast
Arguments: 
(E1-2: Place) the building
EM4 Trigger: explosion
Arguments: 
(E4-1: Instrument) a bomb
(E1-3: Target) the site of the morning blast
(T3-1: Time-Within) morning
EM5 Trigger: explosion
Arguments: None
EM6 Trigger: exploded
Arguments: 
(E5-1: Instrument) a bomb
(E6-1: Target) a McDonald's restaurant
(E7-1: Place) Istanbul
EM7 Trigger: bombings
(E8-1: Attacker) Radical leftist, Kurdish 
and Islamic groups
(E9-1: Place) the country
(T4-1: Time-Within) the past
Table 2. Tabular representation of event mentions
Event Included event mentions 
EV1 {EM1,EM2,EM3,EM4,EM5}
EV2 {EM6}
EV3 {EM7}
Table 3. Event coreference results
2 Event Coreference Resolution as 
Spectral Graph Clustering
We view the event coreference space as an undi-
rected weighted graph in which the nodes 
represent all the event mentions in a document 
and the edge weights indicate the coreference 
confidence between two event mentions. In real 
implementation,  we initially construct different 
graphs for separate event types 2
2 We view the 33 ACE event subtypes as event types
, such that, in 
each graph, all the event mentions have the same 
event type. Similar to (Nicolae and Nicolae, 
2006), we formally define a framework for event 
coreference resolution.
Let ?? = {??? : 1 ? ? ? ?} be ? event men-
tions in the document and ?? = {??? : 1 ? ? ? ?}
be ? events. Let ?:?? ? ?? be the function 
mapping from an event mention ??? ? ?? to an 
event ??? ? ?? . Let ???:???? ? ?? ? [0,1] be 
the function that computes the coreference confi-
dence between two event mentions ??? , ? ?? ?
?? . Let ? = {?? : 1 ? ? ? ?} be ? event types. 
Thus for each event type ? , we have a graph 
??(?? ,??) , where ?? = {??? |?(??? ). ???? = ?? , ??? ?
??} and ?? = ?(??? , ??? , ?????(??? , ??? ))???? , ??? ? ???.
We then model event coreference resolution as
a spectral graph clustering problem that optimiz-
es the normalized-cut criterion (Shi and Malik, 
2000). Such optimization can be achieved by 
computing the second generalized eigenvector, 
thus the name ?spectral?. In this paper, we do not 
try to propose a new spectral clustering algo-
rithm  or improve the existing algorithm. Instead, 
we focus on how to compute the coreference ma-
trix (equivalently, the affinity matrix in Shi and 
Malik?s algorithm) because a better estimation of 
coreference matrix can reduce the burden on 
clustering algorithm.
3 Coreference Matrix ?
3.1 Method 1: Computing a Coreference Formula
Obviously, the trigger pair and the argument sets 
owned by two event mentions carry much infor-
mation about whether one event mention corefers 
with the other. Based on a corpus, we compute 
the statistics about event mention pairs (with the 
same event type)  listed in Table 4.
Let ??? . ??????? be the trigger in ??? ,
????(??? . ???????) be the stem of the trigger in 
??? , ???????(??? . ???????, ? ?? . ???????) be the 
semantic similarity between the two triggers in 
???and ? ?? as computed in (Seco et al, 2004),  
??? . ??? be the argument (ID and ROLE) set in 
??? . Let 1? be the conjunction operator on ar-
gument pairs whose ID 3
??? = ?
?  1???? +???? where
and ROLE match, 2?
be the conjunction operator on argument pairs 
whose ID matches but ROLE does not match, 3?
be the conjunction operator on argument pairs 
whose ROLE matches but ID does not match, 4?
be the conjunction operator on argument pairs 
whose ID and ROLE do not match. We then pro-
pose the following formula to measure the core-
ference value between ??? and ? ?? .
3 We view two argument IDs ?E1-1? and ?E1-2? as a match 
if they mention the same entity which is ?E1?
55
11
11 12
21
  ( ) ( )
21 22
31
  ( , ) 0
31 32
41
41 42
. . 
. . 
. . 
i j
i j
T
ij
i j
T
if em trigger em trigger
T T
T
elseif stem em trigger stem em trigger
T T
w
T
elseif wordnet em trigger em trigger
T T
T
otherwise
T T
??? ?? ???? ?? ???? ?? ?????? ??
and 
1 2
3 4
1
min{ .arg , .arg }
11 21
[ .arg .arg .arg .arg
11 12 21 22
31 41
.arg .arg .arg .arg ]
31 32 41 42
A
ij
i j
i j i j
i j i j
w
em em
A A
em em em em
A A A A
A A
em em em em
A A A A
 q
?  ?  
?  ? 
The strength of this formula is that it allows to 
give credit to different cases of trigger matching 
and argument pair matching between two event 
mentions.
T11 in those coreferring event mention pairs, how 
many pairs use exactly the same triggers
T12 in those non-coreferring event mention pairs, how 
many pairs use exactly the same triggers
T21 in those coreferring event mention pairs, how 
many pairs do not have the same triggers, but 
have the same stems of triggers
T22 non-coreferring version of T21
T31 in those coreferring event mention pairs, how 
many pairs do not have the same triggers nor the 
same stems, but the semantic similarity between 
two triggers is higher than 0 in WordNet.
T32 non-coreferring version of T31
T41 in those non-coreferring event mention pairs, how 
many pairs are not in T11 or T21 or T31
T42 non- coreferring version that is not T12 or T22 or 
T32
A11 in those coreferring event mention pairs, how 
many argument pairs whose ID and ROLE match
A12 non-coreferring version of A11
A21 in those coreferring event mention pairs, how 
many argument pairs whose ID matches but 
ROLE does not match
A22 non-coreferring version of A21
A31 in those coreferring event mention pairs, how 
many argument pairs whose ROLE matches but 
ID does not match
A32 non-coreferring version of A31
A41 in those non-coreferring event mention pairs, how 
many argument pairs whose ID and ROLE do not 
match
A42 non-coreferring version of A41
Table 4. Statistics of event mention pairs
3.2 Method 2: Applying a Maximum En-
tropy Model
We train a maximum entropy model to produce 
the confidence values for ? . Each confidence 
value tells the probability that there exists corefe-
rence ? between event mention ??? and ? ?? .
??????? , ? ?? ? =
?(? ??? ??(??? , ??? ,?))
?(??? , ? ?? )
where ??(???,  ???,?) is a feature and ?? is its 
weight; ????? , ? ?? ? is the normalizing factor.
The feature sets applied in the model are listed 
in Table 5 by categories.
4 Experiments and Results
4.1 Data and Evaluation Metrics
We developed and tested the spectral clustering
algorithm for event coreference resolution using 
the ACE 2005 English corpus which contains 
560 documents. We used the ground truth event 
mentions and evaluated our algorithm based on 
ECM F-Measure (Luo, 2005). We reserved 60 
documents for testing purpose and used the left 
500 documents for training/developing purpose 
and for computing the statistics discussed above.
We applied 10-fold cross-validation in the expe-
riment of comparing two methods for computing 
coreference matrix.
4.2 Statistics of Event Mention Pairs
The results of the statistics discussed in Section 
3.1 are presented in Table 6.
T11=1042,T12=1297, T21=240,T22=840,
T31=257, T32=2637, T41=784,T42=5628
A11=888, A12= 1485, A21=31, A22=146,
A31=542, A32=6849, A41=323, A42=3000
Table 6. Results of statistics in 500 documents
From Table 6, we observe that if two event 
mentions use the same trigger or if they have 
arguments whose ID and ROLE match, it is more 
probable for them to corefer with each other than 
other cases.
4.3 Comparison of the Two Methods for 
Computing Coreference Matrix
Figure 1. ECM-F scores for both methods
56
Category Features Remarks (EM1: the first event mention, EM2: the second event 
mention)
Lexicon type_subtype pair of event type and subtype in EM1
trigger_pair trigger pair of EM1 and EM2
pos_pair part-of-speech pair of triggers of EM1 and EM2
nominal 1 if the trigger of EM2 is nominal
exact_match 1 if the spellings of triggers in EM1 and EM2 exactly match
stem_match 1 if the stems of triggers in EM1 and EM2 match
trigger_sim quantized semantic similarity score (0-5) using WordNet resource 
Distance token_dist how many tokens between triggers of EM1 and EM2 (quantized)
sentence_dist how many sentences EM1 and EM2 are apart (quantized)
event_dist how many event mentions in between EM1 and EM2 (quantized)
Arguments overlap_num,overlap_roles overlap number of arguments and their roles (role and id exactly 
match) between EM1 and EM2
prior_num, prior_roles the number and the roles of arguments that only appear in EM1
act_num, act_roles the number and the roles of arguments that only appear in EM2
coref_num the number of arguments that corefer each other but have different 
roles between EM1 and EM2
Table 5. EM(Event Mention)-pair features for the maximum entropy model
Figure 1 shows the ECM-F scores for both me-
thods by varying the cut threshold in the cluster-
ing algorithm. Both methods obtain the highest 
ECM-F score at threshold 0.85 and method 1
performs slightly better than method 2 (0.8449 vs. 
0.8418, significant at 85% confidence level,
p<=0.1447). We obtained the ECM-F scores of  
0.8363 and 0.8312 on the test set for method 1
and method 2 respectively. We also obtained
two baseline ECM-F scores, one is 0.535 if we 
consider all the event mentions with the same 
event type as a cluster, the other is 0.7635 if we 
consider each event mention as a cluster.
5 Related Work 
Earlier work on event coreference (e.g. Humph-
reys et al, 1997; Bagga and Baldwin, 1999) in 
MUC was limited to several scenarios, e.g., ter-
rorist attacks, management succession, resigna-
tion. The ACE program takes a further step to-
wards processing more fine-grained events. To 
the best of our knowledge, this paper is the first 
effort to apply graph-based algorithm to the 
problem of event coreference resolution.
Nicolae and Nicolae (2006) proposed a similar 
graph-based framework for entity coreference 
resolution. However, in our task, the event men-
tion has much richer structure than the entity 
mention, thus, it is possible for us to harness the  
useful information from both the triggers and the 
attached arguments in the event mentions.
6 Conclusions and Future Work
In this paper, we addressed the problem of event 
coreference resolution in a graph-based frame-
work, and presented two methods for computing 
the coreference matrix. A practical event corefe-
rence resolver also depends on high-performance 
event extractor. We will further study the impact 
of system generated event mentions on the per-
formance of our coreference resolver. 
Acknowledgments
This material is based upon work supported by 
the Defense Advanced Research Projects Agency 
under Contract No. HR0011-06-C-0023 via 27-
001022, and the CUNY Research Enhancement 
Program and GRTI Program.
References 
A. Bagga and B. Baldwin. 1999. Cross-document 
event coreference: Annotations, experiments, and 
observations. In Proc. ACL-99 Workshop on Core-
ference and Its Applications.
C. Nicolae and G. Nicolae. 2006. Bestcut: A graph
algorithm for coreference resolution. In EMNLP,
pages 275?283, Sydney, Australia, July.
J. Shi and J. Malik.1997. Normalized Cuts and Image 
Segmentation. In Proc. of IEEE Conf. on Comp. 
Vision and Pattern Recognition, Puerto Rico
K. Humphreys, R. Gaizauskas, S. Azzam. 1997. 
Event coreference for information extraction. In 
Proceedings of the ACL Workshop on Operational 
Factors in Practical Robust Anaphora Resolution 
for Unrestricted Texts.
N. Seco, T. Veale, J. Hayes. 2004. An intrinsic infor-
mation content metric for semantic similarity in 
WordNet. In Proc. of ECAI-04, pp. 1089?1090.
X. Luo. 2005. On coreference resolution performance
metrics. Proc. of HLT-EMNLP.
57
