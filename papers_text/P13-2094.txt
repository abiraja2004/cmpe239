Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 526?531,
Sofia, Bulgaria, August 4-9 2013. c?2013 Association for Computational Linguistics
Co-Regression for Cross-Language Review Rating Prediction 
 
Xiaojun Wan 
Institute of Computer Science and Technology, The MOE Key Laboratory of 
Computational Linguistics, Peking University, Beijing 100871, China 
wanxiaojun@pku.edu.cn 
 
Abstract 
The task of review rating prediction can be 
well addressed by using regression algorithms 
if there is a reliable training set of reviews 
with human ratings. In this paper, we aim to 
investigate  a more challenging task of cross-
language review rating prediction, which 
makes use of only rated reviews in a source 
language (e.g. English) to predict the rating 
scores of unrated reviews in a target language 
(e.g. German). We propose a new co-
regression algorithm to address this task by 
leveraging unlabeled reviews.  Evaluation re-
sults on several datasets show that our pro-
posed co-regression algorithm can consistently 
improve the prediction results. 
1 Introduction 
With the development of e-commerce, more and 
more people like to buy products on the web and 
express their opinions about the products by 
writing reviews. These reviews usually contain 
valuable information for other people?s reference 
when they buy the same or similar products. In 
some applications, it is useful to categorize a re-
view into either positive or negative, but in many 
real-world scenarios, it is important to provide 
numerical ratings rather than binary decisions.  
The task of review rating prediction aims to 
automatically predict the rating scores of unrated 
product reviews. It is considered as a finer-
grained task than the binary sentiment classifica-
tion task. Review rating prediction has been 
modeled as a multi-class classification or regres-
sion task, and the regression based methods have 
shown better performance than the multi-class 
classification based methods in recent studies (Li 
et al 2011). Therefore, we focus on investigating 
regression-based methods in this study.  
Traditionally, the review rating prediction task 
has been investigated in a monolingual setting, 
which means that the training reviews with hu-
man ratings and the test reviews are in the same 
language. However, a more challenging task is to 
predict the rating scores of the reviews in a target 
language (e.g. German) by making use of the 
rated reviews in a different source language (e.g. 
English), which is called Cross-Language Re-
view Rating Prediction. Considering that the re-
sources (i.e. the rated reviews) for review rating 
prediction in different languages are imbalanced, 
it would be very useful to make use of the re-
sources in resource-rich languages to help ad-
dress the review rating prediction task in re-
source-poor languages.  
The task of cross-language review rating pre-
diction can be typically addressed by using ma-
chine translation services for review translation, 
and then applying regression methods based on 
the monolingual training and test sets. However, 
due to the poor quality of machine translation, 
the reviews translated from one language A to 
another language B are usually very different 
from the original reviews in language B, because 
the words or syntax of the translated reviews 
may be erroneous or non-native.  This phenome-
non brings great challenges for existing regres-
sion algorithms.  
In this study, we propose a new co-regression 
algorithm to address the above problem by lever-
aging unlabeled reviews in the target language.  
Our algorithm can leverage both views of the 
reviews in the source language and the target 
language to collaboratively determine the confi-
dently predicted ones out of the unlabeled re-
views, and then use the selected examples to 
enlarge the training set. Evaluation results on 
several datasets show that our proposed co-
regression algorithm can consistently improve 
the prediction results. 
2 Related Work 
Most previous works on review rating prediction 
model this problem as a multi-class classification 
task or a regression task. Various features have 
been exploited from the review text, including 
words, patterns, syntactic structure, and semantic 
topic (Qu et al 2010; Pang and Lee, 2005; Leung 
et al 2006; Ganu et al 2009). Traditional learn-
526
ing models, such as SVM, are adopted for rating 
prediction. Most recently, Li et al (2011) pro-
pose a novel tensor-based learning framework to 
incorporate reviewer and product information 
into the text based learner for rating prediction.  
Saggion et al (2012) study the use of automatic 
text summaries instead of the full reviews for 
movie review rating prediction. In addition to 
predicting the overall rating of a full review, 
multi-aspect rating prediction has also been in-
vestigated (Lu et al 2011b; Snyder and Barzilay, 
2007; Zhu et al 2009; Wang et al 2010; Lu et al 
2009; Titov and McDonald, 2008). All the above 
previous works are working under a monolingual 
setting, and to the best of our knowledge, there 
exists no previous work on cross-language re-
view rating prediction.  
    It is noteworthy that a few studies have been 
conducted for the task of cross-lingual sentiment 
classification or text classification, which aims to 
make use of labeled data in a language for the 
binary classification task in a different language 
(Mihalcea et al, 2007; Banea et al, 2008; Wan 
2009; Lu et al 2011a; Meng et al 2012; Shi et 
al., 2010; Prettenhofer and Stein 2010). However, 
the binary classification task is very different 
from the regression task studied in this paper, 
and the proposed methods in the above previous 
works cannot be directly applied.  
3 Problem Definition and Baseline Ap-
proaches 
Let L={(x1, y1), ?, (xi, yi), ?, (xn, yn)} denote the 
labeled training set of reviews in a source lan-
guage (e.g. English), where xi is the i-th review 
and yi is its real-valued label, and n is the number 
of labeled examples; Let T denote the test review 
set in a different target language (e.g. German); 
Then the task of cross-language review rating 
prediction aims at automatically predicting the 
rating scores of the reviews in T by leveraging 
the labeled reviews in L. No labeled reviews in 
the target language are allowed to be used. 
The task is a regression problem and it is chal-
lenging due to the language gap between the la-
beled training dataset and the test dataset. Fortu-
nately, due to the development of machine trans-
lation techniques, a few online machine transla-
tion services can be used for review translation. 
We adopt Google Translate1 for review transla-
tion. After review translation, the training re-
views and the test reviews are now in the same 
                                                 
1 http://translate.google.com 
language, and any regression algorithm (e.g. lo-
gistic regression, least squares regression, KNN 
regressor) can be applied for learning and predic-
tion.  In this study, without loss of generality, we 
adopt the widely used regression SVM (Vapnik 
1995; Joachims 1999) implemented in the 
SVMLight toolkit 2  as the basic regressor. For 
comparative analysis, we simply use the default 
parameter values in SVMLight with linear kernel. 
The features include all unigrams and bigrams in 
the review texts, and the value of each feature is 
simply set to its frequency (TF) in a review.  
Using features in different languages, we have 
the following baseline approaches for addressing 
the cross-language regression problem.  
REG_S:  It conducts regression learning and 
prediction in the source language.   
REG_T: It conducts regression learning and 
prediction in the target language.   
REG_ST: It conducts regression learning and 
prediction with all the features in both languages.   
REG_STC: It combines REG_S and REG_T   
by averaging their prediction values.  
However, the above regression methods do not 
perform very well due to the unsatisfactory ma-
chine translation quality and the various lan-
guage expressions. Therefore, we need to find 
new approaches to improve the above methods.  
4 Our Proposed Approach 
4.1 Overview 
Our basic idea is to make use of some amounts 
of unlabeled reviews in the target language to 
improve the regression performance. Consider-
ing that the reviews have two views in two lan-
guages and inspired by the co-training style algo-
rithms (Blum and Mitchell, 1998; Zhou and Li, 
2005), we propose a new co-training style algo-
rithm called co-regression to leverage the unla-
beled data in a collaborative way.  The proposed 
co-regression algorithm can make full use of 
both the features in the source language and the 
features in the target language in a unified 
framework similar to (Wan 2009). Each review 
has two versions in the two languages. The 
source-language features and the target-language 
features for each review are considered two re-
dundant views of the review. In the training 
phase, the co-regression algorithm is applied to 
learn two regressors in the two languages. In the 
prediction phase, the two regressors are applied 
to predict two rating scores of the review. The 
                                                 
2 http://svmlight.joachims.org 
527
final rating score of the review is the average of 
the two rating scores.  
4.2 Our Proposed Co-Regression Algorithm 
In co-training for classification, some confidently 
classified examples by one classifier are pro-
vided for the other classifier, and vice versa. 
Each of the two classifiers can improve by learn-
ing from the newly labeled examples provided 
by the other classifier. The intuition is the same 
for co-regression. However, in the classification 
scenario, the confidence value of each prediction 
can be easily obtained through consulting the 
classifier. For example, the SVM classifier pro-
vides a confidence value or probability for each 
prediction. However, in the regression scenario, 
the confidence value of each prediction is not 
provided by the regressor. So the key question is 
how to get the confidence value of each labeled 
example. In (Zhou and Li, 2005), the assumption 
is that the most confidently labeled example of a 
regressor should be with such a property, i.e. the 
error of the regressor on the labeled example set 
(i.e. the training set) should decrease the most if 
the most confidently labeled example is utilized. 
In other words, the confidence value of each la-
beled example is measured by the decrease of the 
error (e.g. mean square error) on the labeled set 
of the regressor utilizing the information pro-
vided by the example. Thus, each example in the 
unlabeled set is required to be checked by train-
ing a new regression model utilizing the example. 
However, the model training process is usually 
very time-consuming for many regression algo-
rithms, which significantly limits the use of the 
work in (Zhou and Li, 2005). Actually, in (Zhou 
and Li, 2005), only the lazy learning based KNN 
regressor is adopted. Moreover, the confidence 
of the labeled examples is assessed based only on 
the labeled example set (i.e. the training set), 
which makes the generalization ability of the 
regressor not good.  
In order to address the above problem, we 
propose a new confidence evaluation strategy 
based on the consensus of the two regressors. 
Our intuition is that if the two regressors agree 
on the prediction scores of an example very well, 
then the example is very confidently labeled. On 
the contrary, if the prediction scores of an exam-
ple by the two regressors are very different, we 
can hardly make a decision whether the example 
is confidently labeled or not. Therefore, we use 
the absolute difference value between the predic-
tion scores of the two regressors as the confi-
dence value of a labeled example, and if the ex-
ample is chosen, its final prediction score is the 
average of the two prediction scores. Based on 
this strategy, the confidently labeled examples 
can be easily and efficiently chosen from the 
unlabeled set as in the co-training algorithm, and 
these examples are then added into the labeled 
set for re-training the two regressors. 
 
Given: 
- Fsource and Ftarget are redundantly sufficient 
sets of features, where Fsource represents 
the source language features, Ftarget repre-
sents the target language features; 
- L is a set of labeled training reviews; 
- U is a set of unlabeled reviews; 
Loop for I iterations: 
1. Learn the first regressor Rsource from L 
based on Fsource; 
2. Use Rsource to label reviews from U based 
on Fsource; Let 
source
iy? denote the predic-
tion score of review xi;  
3. Learn the second classifier Rtarget from L 
based on Ftarget; 
4. Use Rtarget to label reviews from U based 
on Ftarget; Let 
ett
iy
arg? denote the predic-
tion score of review xi;  
5. Choose m most confidently predicted re-
views E={ top m reviews with the small-
est value of sourcei
ett
i yy ??
arg
? } from U, 
where the final prediction score of each 
review in E is 2?? arg sourcei
ett
i yy + ; 
6. Removes reviews E from U and add re-
views E with the corresponding predic-
tion scores to L; 
Figure 1. Our proposed co-regression algorithm 
 
Our proposed co-regression algorithm is illus-
trated in Figure 1. In the proposed co-regression 
algorithm, any regression algorithm can be used 
as the basic regressor to construct Rsource and Rtar-
get, and in this study, we adopt the same regres-
sion SVM implemented in the SVMLight toolkit 
with default parameter values. Similarly, the fea-
tures include both unigrams and bigrams and the 
feature weight is simply set to term frequency.  
There are two parameters in the algorithm: I is 
the iteration number and m is the growth size in 
each iteration. I and m can be empirically set ac-
cording to the total size of the unlabeled set U, 
and we have I?m? |U|. 
Our proposed co-regression algorithm is much 
more efficient than the COREG algorithm (Zhou 
and Li, 2005). If we consider the time-
consuming regression learning process as one  
528
(a) Target language=German & Category=books
1.1
1.12
1.14
1.16
1.18
1.2
1.22
1 10 20 30 40 50 60 70 80 90 100110120130140150
Iteration Number (I)
M
SE
 (b) Target language=German & Category=dvd
1.1
1.12
1.14
1.16
1.18
1.2
1.22
1.24
1.26
1 10 20 30 40 50 60 70 80 90 100110120130140150
Iteration Number (I)
M
SE
(c) Target language=German & Category=music
1.19
1.21
1.23
1.25
1.27
1.29
1.31
1.33
1.35
1 10 20 30 40 50 60 70 80 90 100110120130140150
Iteration Number (I)
M
SE
Rsource
Rtarget
co-regression
REG_S
REG_T
REG_ST
REG_STC
COREG
Figure 2. Comparison results vs. Iteration Number (I) (Rsource and Rtarget are the two component regressors)  
basic operation and make use of all unlabeled 
examples in U, the computational complexity of 
COREG is O(|U|+I). By contrast, the computa-
tional complexity of our proposed co-regression 
algorithm is just O(I). Since |U| is much larger 
than I, our proposed co-regression algorithm is 
much more efficient than COREG, and thus our 
proposed co-regression algorithm is more suit-
able to be used in applications with a variety of 
regression algorithms.  
Moreover, in our proposed co-regression algo-
rithm, the confidence of each prediction is de-
termined collaboratively by two regressors. The 
selection is not restricted by the training set, and 
it is very likely that a portion of good examples 
can be chosen for generalize the regressor to-
wards the test set.  
5 Empirical Evaluation 
We used the WEBIS-CLS-10 corpus3 provided 
by (Prettenhofer and Stein, 2010) for evaluation.  
It consists of Amazon product reviews for three 
product categories (i.e. books, dvds and music) 
written in different languages including English, 
German, etc. For each language-category pair 
there exist three sets of training documents, test 
documents, and unlabeled documents. The train-
ing and test sets comprise 2000 documents each, 
whereas the number of unlabeled documents var-
ies from 9000 ? 170000. The dataset is provided 
with the rating score between 1 to 5 assigned by 
users, which can be used for the review rating 
prediction task. We extracted texts from both the 
summary field and the text field to represent a 
review text. We then extracted the rating score as 
a review?s corresponding real-valued label. In 
the cross-language scenario, we regarded English 
as the source language, and regarded German as 
the target language. The experiments were con-
ducted on each product category separately. 
Without loss of generality, we sampled and used 
                                                 
3 http://www.uni-weimar.de/medien/webis/research/corpora/ 
corpus-webis-cls-10.html 
only 8000 unlabeled documents for each product 
category. We use Mean Square Error (MSE) as 
the evaluation metric, which penalizes more se-
vere errors more heavily.  
In the experiments, our proposed co-regression 
algorithm (i.e. ?co-regression?) is compared with 
the COREG algorithm in (Zhou and Li, 2005) 
and a few other baselines. For our proposed co-
regression algorithm, the growth size m is simply 
set to 50. We implemented the COREG algo-
rithm by replacing the KNN regressor with the 
regression SVM and the pool size is also set to 
50. The iteration number I varies from 1 to 150. 
The comparison results are shown in Figure 2.  
We can see that on all product categories, the 
MSE values of our co-regression algorithm and 
the two component regressors tend to decline 
over a wide range of I, which means that the se-
lected confidently labeled examples at each itera-
tion are indeed helpful to improve the regressors.  
Our proposed co-regression algorithm outper-
forms all the baselines (including COREG) over 
different iteration members, which verifies the 
effectiveness of our proposed algorithm. We can 
also see that the COREG algorithm does not per-
form well for this cross-language regression task. 
Overall, our proposed co-regression algorithm 
can consistently improve the prediction results. 
6 Conclusion and Future Work 
In this paper, we study a new task of cross-
language review rating prediction and propose a 
new co-regression algorithm to address this task. 
In future work, we will apply the proposed co-
regression algorithm to other cross-language or 
cross-domain regression problems in order to 
verify its robustness.  
Acknowledgments 
The work was supported by NSFC (61170166), 
Beijing Nova Program (2008B03) and National 
High-Tech R&D Program (2012AA011101). 
529
References 
Carmen Banea, Rada Mihalcea, Janyce Wiebe, and 
Samer Hassan. 2008. Multilingual subjectivity 
analysis using machine translation. In Proceedings 
of the Conference on Empirical Methods in Natural 
Language Processing, pp. 127-135. 
John Blitzer, Mark Dredze, and Fernando Pereira. 
2007. Biographies, bollywood, boom-boxes and 
blenders: Domain adaptation for sentiment classifi-
cation. In Annual Meeting-Association For Com-
putational Linguistics. 
Avrim Blum and Tom Mitchell. 1998. Combining 
labeled and unlabeled data with co-training. In Pro-
ceedings of the eleventh annual conference on 
Computational learning theory, pp. 92-100. 
Hang Cui, Vibhu Mittal, and Mayur Datar. 2006. 
Comparative experiments on sentiment classifica-
tion for online product reviews. In Proceedings of 
the National Conference on Artificial Intelligence. 
Gayatree Ganu, Noemie Elhadad, and Am?lie Marian. 
2009. Beyond the stars: Improving rating predic-
tions using review text content. In WebDB. 
Thorsten Joachims, 1999. Making large-Scale SVM 
Learning Practical. Advances in Kernel Methods - 
Support Vector Learning, MIT-Press. 
CaneWing Leung, Stephen Chi Chan, and Fu Chung. 
2006. Integrating collaborative filtering and senti-
ment analysis: A rating inference approach. In 
ECAI Workshop, pages 300?307. 
Fangtao Li, Nathan Liu, Hongwei Jin, Kai Zhao, 
Qiang Yang and Xiaoyan Zhu. 2011. Incorporating 
reviewer and product information for review rating 
prediction. In Proceedings of the Twenty-Second 
International Joint Conference on Artificial Intelli-
gence (IJCAI2011).  
Yue Lu, ChengXiang Zhai, Neel Sundaresan. 2009. 
Rated Aspect Summarization of Short Comments. 
Proceedings of the World Wide Conference 2009 
( WWW'09), pages 131-140. 
Bin Lu, Chenhao Tan, Claire Cardie, Ka Yin Benja-
min TSOU. 2011a. Joint bilingual sentiment classi-
fication with unlabeled parallel corpora. In Pro-
ceedings of the 49th Annual Meeting of the Asso-
ciation for Computational Linguistics: Human 
Language Technologies, pp. 320-330. 
Bin Lu, Myle Ott, Claire Cardie and Benjamin K. 
Tsou. 2011b. Multi-aspect sentiment analysis with 
topic models. In Proceedings of Data Minig 
Workshps (ICDMW), 2011 IEEE 11th Interna-
tional Conference on, pp. 81-88, IEEE.  
Xinfan Meng, Furu Wei, Xiaohua Liu, Ming Zhou, 
Ge Xu, and Houfeng Wang. 2012. Cross-Lingual 
Mixture Model for Sentiment Classification. In 
Proceedings of ACL-2012.  
Rada Mihalcea, Carmen Banea, and Janyce Wiebe. 
2007. Learning multilingual subjective language 
via cross-lingual projections. In Proceedings of 
ACL-2007. 
Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan. 
2002. Thumbs up? sentiment classification using 
machine learning techniques. In Proceedings of the 
ACL-02 conference on Empirical methods in natu-
ral language processing-Volume 10, pp. 79-86, 
2002. 
Bo Pang and Lillian Lee. 2005. Seeing stars: Exploit-
ing class relationships for sentiment categorization 
with respect to rating scales. In Proceedings of the 
ACL, pages 115?124.  
Peter Prettenhofer and Benno Stein. 2010. Cross-
Language Text Classification using Structural Cor-
respondence Learning. In 48th Annual Meeting of 
the Association of Computational Linguistics 
(ACL 10), 1118-1127. 
Lizhen Qu, Georgiana Ifrim, and Gerhard Weikum. 
2010. The bag-of-opinions method for review rat-
ing prediction from sparse text patterns. In COL-
ING, pages 913?921, Stroudsburg, PA, USA, 2010. 
ACL.  
Horacio Saggion, Elena Lloret, and Manuel Palomar. 
2012. Can text summaries help predict ratings? a 
case study of movie reviews. Natural Language 
Processing and Information Systems (2012): 271-
276. 
Lei Shi, Rada Mihalcea, and Mingjun Tian. 2010. 
Cross language text classification by model transla-
tion and semi-supervised learning. In Proceedings 
of the 2010 Conference on Empirical Methods in 
Natural Language Processing, pp. 1057-1067, 2010. 
Benjamin Snyder and Regina Barzilay. 2007. Multi-
ple aspect ranking using the good grief algorithm. 
Proceedings of the Joint Human Language Tech-
nology/North American Chapter of the ACL Con-
ference (HLT-NAACL). 
Ivan Titov and Ryan McDonald. 2008. A joint model 
of text and aspect ratings for sentiment summariza-
tion. In Proceedings of ACL-08:HLT, pages 308-
316.  
Peter D. Turney. 2002. Thumbs up or thumbs down?: 
semantic orientation applied to unsupervised classi-
fication of reviews. In Proceedings of the 40th An-
nual Meeting on Association for Computational 
Linguistics, pp. 417-424. 
Vladimir N. Vapnik, 1995. The Nature of Statistical 
Learning Theory. Springer. 
Xiaojun Wan. 2009. Co-training for cross-lingual 
sentiment classification. In Proceedings of the Joint 
Conference of the 47th Annual Meeting of the 
ACL and the 4th International Joint Conference on 
530
Natural Language Processing of the AFNLP, pp. 
235-243. 
Hongning Wang, Yue Lu, ChengXiang Zhai. 2010. 
Latent Aspect Rating Analysis on Review Text 
Data: A Rating Regression Approach. Proceedings 
of the 17th ACM SIGKDD International Confer-
ence on Knowledge Discovery and Data Mining 
(KDD'10), pages 115-124. 
Jingbo Zhu, Huizhen Wang, Benjamin K. Tsou, and 
Muhua Zhu. 2009. Multi-aspect opinion polling 
from textual reviews. In Proceedings of the 18th 
ACM conference on Information and knowledge 
management, pp. 1799-1802. ACM. 
Zhi-Hua Zhou and Ming Li. 2005. Semi-supervised 
regression with co-training. In Proceedings of the 
19th international joint conference on Artificial in-
telligence, pp. 908-913. Morgan Kaufmann Pub-
lishers Inc. 
531
