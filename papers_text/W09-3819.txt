Proceedings of the 11th International Conference on Parsing Technologies (IWPT), pages 129?133,
Paris, October 2009. c?2009 Association for Computational Linguistics
Hebrew Dependency Parsing: Initial Results
Yoav Goldberg and Michael Elhadad
Ben Gurion University of the Negev
Department of Computer Science
POB 653 Be?er Sheva, 84105, Israel
{yoavg,elhadad}@cs.bgu.ac.il
Abstract
We describe a newly available Hebrew
Dependency Treebank, which is extracted
from the Hebrew (constituency) Tree-
bank. We establish some baseline un-
labeled dependency parsing performance
on Hebrew, based on two state-of-the-art
parsers, MST-parser and MaltParser. The
evaluation is performed both in an artifi-
cial setting, in which the data is assumed
to be properly morphologically segmented
and POS-tagged, and in a real-world set-
ting, in which the parsing is performed on
automatically segmented and POS-tagged
text. We present an evaluation measure
that takes into account the possibility of
incompatible token segmentation between
the gold standard and the parsed data.
Results indicate that (a) MST-parser per-
forms better on Hebrew data than Malt-
Parser, and (b) both parsers do not make
good use of morphological information
when parsing Hebrew.
1 Introduction
Hebrew is a Semitic language with rich morpho-
logical structure and free constituent order.
Previous computational work addressed unsu-
pervised Hebrew POS tagging and unknown word
resolution (Adler, 2007), Hebrew NP-chunking
(Goldberg et al, 2006), and Hebrew constituency
parsing (Tsarfaty, 2006; Golderg et al, 2009).
Here, we focus on Hebrew dependency parsing.
Dependency-parsing got a lot of research at-
tention lately, in part due to two CoNLL shared
tasks focusing on multilingual dependency parsing
(Buchholz and Erwin, 2006; Nivre et al, 2007).
These tasks include relatively many parsing re-
sults for Arabic, a Semitic language similar to He-
brew. However, parsing accuracies for Arabic usu-
ally lag behind non-semitic languages. Moreover,
while there are many published results, we could
not find any error analysis or even discussion of
the results of Arabic dependency parsing models,
or the specific properties of Arabic making it easy
or hard to parse in comparison to other languages.
Our aim is to evaluate current state-of-the-art
dependency parsers and approaches on Hebrew
dependency parsing, to understand some of the
difficulties in parsing a Semitic language, and to
establish a strong baseline for future work.
We present the first published results on Depen-
dency Parsing of Hebrew.
Some aspects that make Hebrew challenging
from a parsing perspective are:
Affixation Common prepositions, conjunctions
and articles are prefixed to the following word,
and pronominal elements often appear as suffixes.
The segmentation of prefixes and suffixes is of-
ten ambiguous and must be determined in a spe-
cific context only. In term of dependency pars-
ing, this means that the dependency relations oc-
cur not between space-delimited tokens, but in-
stead between sub-token elements which we?ll re-
fer to as segments. Furthermore, any mistakes in
the underlying token segmentations are sure to be
reflected in the parsing accuracy.
Relatively free constituent order The ordering
of constituents inside a phrase is relatively free.
This is most notably apparent in the verbal phrases
and sentential levels. In particular, while most sen-
tences follow an SVO order, OVS and VSO con-
figurations are also possible. Verbal arguments
can appear before or after the verb, and in many
ordering. For example, the message ?went from
Israel to Thailand? can be expressed as ?went to
Thailand from Israel?, ?to Thailand went from Is-
rael?, ?from Israel went to Thailand?, ?from Israel
to Thailand went? and ?to Thailand from Israel
went?. This results in long and flat VP and S struc-
tures and a fair amount of sparsity, which suggests
129
that a dependency representations might be more
suitable to Hebrew than a constituency one.
Rich templatic morphology Hebrew has a
very productive morphological structure, which
is based on a root+template system. The pro-
ductive morphology results in many distinct word
forms and a high out-of-vocabulary rate, which
makes it hard to reliably estimate lexical param-
eters from annotated corpora. The root+template
system (combined with the unvocalized writing
system) makes it hard to guess the morphological
analyses of an unknown word based on its prefix
and suffix, as usually done in other languages.
Unvocalized writing system Most vowels are
not marked in everyday Hebrew text, which re-
sults in a very high level of lexical and morpho-
logical ambiguity. Some tokens can admit as many
as 15 distinct readings, and the average number of
possible morphological analyses per token in He-
brew text is 2.7, compared to 1.4 in English (Adler,
2007). This means that on average, every token is
ambiguous with respect to its POS and morpho-
logical features.
Agreement Hebrew grammar forces morpho-
logical agreement between Adjectives and Nouns
(which should agree in Gender and Number and
definiteness), and between Subjects and Verbs
(which should agree in Gender and Number).
2 Hebrew Dependency Treebank
Our experiments are based on the Hebrew De-
pendency Treebank (henceforth DepTB), which
we derived from Version 2 of the Hebrew
Constituency Treebank (Guthmann et al, 2009)
(henceforth TBv2). We briefly discuss the conver-
sion process and the resulting Treebank:
Parent-child dependencies TBv2 marks sev-
eral kinds of dependencies, indicating the mother-
daughter percolation of features such as number,
gender, definiteness and accusativity. See (Guth-
mann et al, 2009) for the details. We follow
TBv2?s HEAD, MAJOR and MULTIPLE depen-
dency marking in our-head finding rules. When
these markings are not available we use head find-
ing rules in the spirit of Collins. The head-finding
rules were developed by Reut Tsarfaty and used
in (Tsarfaty and Sima?an, 2008). We slightly ex-
tended them to handle previously unhandled cases.
Some conventions in TBv2 annotations resulted in
bad dependency structures. We identified these
constructions and transformed the tree structure,
Figure 1: Coordinated Verbs
Figure 2: Coordinated Sentence
either manually or automatically, prior to the de-
pendency extraction process.
The conversion process revealed some errors
and inconsistencies in TBv2, which we fixed.
We take relativizers as the head S and SBAR,
and prepositions as the heads of PPs. In the case
the parent of a word X is an empty element, we
take the parent of the empty element as the par-
ent of X instead. While this may result in non-
projective structures, in practice all but 34 of the
resulting trees are projective.
We take conjunctions to be the head of a coordi-
nated structure, resulting in dependency structures
such as the one in Figures 1 and 2. Notice how
in Figure 1 the parent of the subject ????/He? is
the coordinator ??/and?, and not one of the verbs.
While this makes things harder for the parser, we
find this representation to be much cleaner and
more expressive than the usual approach in which
the first coordinated element is taken as the head
of the coordinated structure.1
Dependency labels TBv2 marks 3 kinds of
functional relations: Subject, Object and Comple-
mentizer. We use these in our conversion pro-
cess, and label dependencies as being SBJ, OBJ
or CMP, as indicated in TBv2. We also trivially
mark the ROOT dependency, and introduce the re-
lations INF PREP, AT INF POS INF RB INF be-
tween a base word and its suffix for the cases of
suffix-inflected prepositions, accusative suffixes,
possessive suffixes and inflected-adverbs, respec-
tively. Still, most dependency relations remain un-
labeled. We are currently seeking a method of re-
liably labeling the remaining edges with a rich set
1A possible alternative would be to allow multiple par-
ents, as done in (de Marneffe et al, 2006), but current parsing
algorithms require the output to be tree structured.
130
of relations. However, in the current work we fo-
cus on the unlabeled dependency structure.
POS tags The Hebrew Treebank follows a syn-
tactic tagging scheme, while other Hebrew re-
sources prefer a more morphological/dictionary-
based scheme. For a discussion of these two tag-
ging schemes in the context of parsing, see (Gold-
erg et al, 2009). In DepTB, we kept the two
tagsets, and each token has two POS tags asso-
ciated with it. However, as current dependency
parsers rely on an external POS tagger, we per-
formed all of our experiments only with the mor-
phological tagset, which is what our tagger pro-
duces.
3 The Parsing Models
To establish some baseline results for Hebrew de-
pendency parsing, we experiment with two pars-
ing models, the graph-based MST-parser (Mc-
Donald, 2006) and the transition-based MaltParser
(Nivre et al, 2006). These two parsers repre-
sent the current mainstream approaches for de-
pendency parsing, and each was shown to pro-
vide state-of-the-art results on many languages
(CoNLL Shared Task 2006, 2007).
Briefly, a graph-based parsing model works by
assigning a score to every possible attachment be-
tween a pair (or a triple, for a second-order model)
of words, and then inferring a global tree struc-
ture that maximizes the sum of these local scores.
Transition-based models work by building the de-
pendency graph in a sequence of steps, where each
step is dependent on the next input word(s), the
previous decisions, and the current state of the
parser. For more details about these parsing mod-
els as well as a discussion on the relative benefits
of each model, see (McDonald and Nivre, 2007).
Contrary to constituency-based parsers, depen-
dency parsing models expect a morphologically
segmented and POS tagged text as input.
4 Experiments
Data We follow the train-test-dev split estab-
lished in (Tsarfaty and Sima?an, 2008). Specifi-
cally, we use Sections 2-12 (sentences 484-5724)
of the Hebrew Dependency Treebank as our train-
ing set, and report results on parsing the develop-
ment set, Section 1 (sentences 0-483). We do not
evaluate on the test set in this work.
The data in the Treebank is segmented and
POS-tagged. All of the models were trained on the
gold-standard segmented and tagged data. When
evaluating the parsing models, we perform two
sets of evaluations. The first one is an oracle ex-
periment, assuming gold segmentation and tag-
ging is available. The second one is a real-world
experiment, in which we segment and POS-tag the
test-set sentences using the morphological disam-
biguator described in (Adler, 2007; Goldberg et
al., 2008) prior to parsing.
Parsers and parsing models We use the freely
available implementation of MaltParser2 and
MSTParser3, with default settings for each of the
parsers.
For MaltParser, we experiment both with the de-
fault feature representation (MALT) and the fea-
ture representation used for parsing Arabic in
CoNLL 2006 and 2007 multilingual dependency
parsing shared tasks (MALT-ARA).
For MST parser, we experimented with first-
order (MST1) and second-order (MST2) models.
We varied the amount of lexical information
available to the parser. Each of the parsers was
trained on 3 datasets: LEXFULL, in which all the
lexical items are available, LEX20, in which lexi-
cal items appearing less than 20 times in the train-
ing data were replaced by an OOV token, and
LEX100 in which we kept only lexical items ap-
pearing more than 100 times in training.
We also wanted to control the effect of the rich
morphological information available in Hebrew
(gender and number marking, person, and so on).
To this end, we trained and tested each model ei-
ther with all the available morphological informa-
tion (+MORPH) or without any morphological in-
formation (-MORPH).
Evaluation Measure We evaluate the resulting
parses in terms of unlabeled accuracy ? the percent
of correctly identified (child,parent) pairs4. To be
precise, we calculate:
number of correctly identified pairs
number of pairs in gold parse
For the oracle case in which the gold-standard
token segmentation is available for the parser, this
is the same as the traditional unlabeled-accuracy
evaluation metric. However, in the real-word set-
ting in which the token segmentation is done auto-
matically, the yields of the gold-standard and the
2http://w3.msi.vxu.se/?jha/maltparser/
3http://sourceforge.net/projects/mstparser/
4All the results are macro averaged. The micro-averaged
numbers are about 2 percents higher for all cases.
131
Features MST1 MST2 MALT MALT-ARA
-M
OR
PH Full Lex 83.60 84.31 80.77 80.32Lex 20 82.99 84.52 79.69 79.40
Lex 100 82.56 83.12 78.66 78.56
+M
OR
PH Full Lex 83.60 84.39 80.77 80.73Lex 20 83.60 84.77 79.69 79.84
Lex 100 83.23 83.80 78.66 78.56
Table 1: Unlabeled dependency accuracy with
oracle token segmentation and POS-tagging.
Features MST1 MST2 MALT MALT-ARA
-M
OR
PH Full Lex 75.64 76.38 73.03 72.94Lex 20 75.48 76.41 72.04 71.88
Lex 100 74.97 75.49 70.93 70.73
+M
OR
PH Full Lex 73.90 74.62 73.03 73.43Lex 20 73.56 74.41 72.04 72.30
Lex 100 72.90 73.78 70.93 70.97
Table 2: Unlabeled dependency accuracy with
automatic token segmentation and POS-tagging.
automatic parse may differ, and one needs to de-
cide how to handle the cases in which one or more
elements in the identified (child,parent) pair are
not present in the gold-standard parse. Our evalua-
tion metric penalizes these cases by regarding any
such case as a mistake.
5 Results and Analysis
Results are presented in Tables 1 and 2.
It seems that the graph-based parsers perform
better than the transitions-based ones. We at-
tribute this to 2 factors: first, our representa-
tion of coordinated structure is hard to capture
with a greedy local search as performed by a
transition-based parser, because we need to de-
fer many attachment decisions until the final co-
ordinator is revealed. The global inference of the
graph-based parser is much more robust to these
kinds of structure. Indeed, when evaluating the
gold-morphology, fully-lexicalized models on a
subset of the test-set (314 sentences) which does
not have coordinated structures, the accuracy of
MALT improves in 3.98% absolute (from 80.77 to
84.75), while MST improves only in 2.66% abso-
lute (from 83.60 to 86.26). Coordination is hard
for both parsing models, but more so to the transi-
tion based MALT.
Second, it might be hard for a transition-based
parser to handle the free constituent order of He-
brew, as it has no means of generalizing from the
training set to various possible constituent order-
ing. The graph-based parser?s features and infer-
ence method do not take constituent order into ac-
count, making it more suitable for free constituent
order language.
As expected, the Second-order graph based
models perform better than the first-order ones.
Surprisingly, the Arabic-optimized feature-set do
not perform better than the English one for the
transition-based parsers. Overall, morphological
information seems to contribute very little (if at
all) to any of the parsers in the gold-morphology
(oracle) setting. MALTARA gets some benefit
from the morphological information in the fully-
lexicalized case, while the MST variants benefit
from morphology in the lexically-pruned models.
Overall, full lexicalization is not needed. In-
deed, less lexicalized LEX20 2nd-order graph-
based models perform better than the fully lexi-
calized ones. This strengthens our intuition that
robust lexical statistics are hard to acquire from
small annotated corpora, even more so for a lan-
guage with productive morphology such as He-
brew.
Moving from the oracle morphological disam-
biguation to an automatic one greatly hurts the per-
formance of all the models. This is in line with re-
sults for Hebrew constituency parsing, where go-
ing from gold segmentation to a parser derived one
caused a similar drop in accuracy (Golderg et al,
2009). This suggests that we should either strive
to improve the tagging accuracy, or perform joint
inference for parsing and morphological disam-
biguation. We believe the later would be a better
way to go, but it is currently unsupported in state-
of-the-art dependency parsing algorithms.
Interestingly, in the automatic morphological
disambiguation setting MALTARA benefits a little
from the addition of morpological features, while
the MST models perform better without these fea-
tures.
6 Conclusions
We presented the first results for unlabeled de-
pendency parsing of Hebrew, with two state-of-
the-art dependency parsing models of different
families. We experimented both with gold mor-
phological information, and with an automatically
derived one. It seems that graph-based models
have a slight edge in parsing Hebrew over current
transition-based ones. Both model families are not
currently making good use of morphological infor-
mation.
132
References
Meni Adler. 2007. Hebrew Morphological Disam-
biguation: An Unsupervised Stochastic Word-based
Approach. Ph.D. thesis, Ben-Gurion University of
the Negev, Beer-Sheva, Israel.
Sabine Buchholz and Marsi Erwin. 2006. CoNLL-X
shared task on multilingual dependency parsing. In
Proc. of CoNLL.
Marie-Catherine de Marneffe, Bill MacCartney, and
Christopher D. Manning. 2006. Generating typed
dependency parses from phrase structure parses. In
Proc. of LREC.
Yoav Goldberg, Meni Adler, and Michael Elhadad.
2006. Noun phrase chunking in hebrew: Influence
of lexical and morphological features. In Proc. of
COLING/ACL.
Yoav Goldberg, Meni Adler, and Michael Elhadad.
2008. EM can find pretty good HMM POS-Taggers
(when given a good start). In Proc. of ACL.
Yoav Golderg, Reut Tsarfaty, Meni Adler, and Michael
Elhadad. 2009. Enhancing unlexicalized parsing
performance using a wide coverage lexicon, fuzzy
tag-set mapping, and EM-HMM-based lexical prob-
abilities. In Proc of EACL.
Noemie Guthmann, Yuval Krymolowski, Adi Milea,
and Yoad Winter. 2009. Automatic annotation of
morpho-syntactic dependencies in a modern hebrew
treebank. In Proc of TLT.
Ryan McDonald and Joakim Nivre. 2007. Character-
izing the errors of data-driven dependency parsing
models. In Proc. of EMNLP.
Ryan McDonald. 2006. Discriminative Training and
Spanning Tree Algorithms for Dependency Parsing.
Ph.D. thesis, University of Pennsylvania.
Joakim Nivre, Johan Hall, and Jens Nillson. 2006.
MaltParser: A data-driven parser-generator for de-
pendency parsing. In Proc. of LREC.
Joakim Nivre, Johan Hall, Sandra Kubler, Ryan Mc-
Donald, Jens Nilsson, Sebastian Riedel, and Deniz
Yuret. 2007. The CoNLL 2007 shared task on de-
pendency parsing. In Proc. of the EMNLP-CoNLL.
Reut Tsarfaty and Khalil Sima?an. 2008. Relational-
realizational parsing. In Proc. of CoLING, August.
Reut Tsarfaty. 2006. Integrated morphological and
syntactic disambiguation for modern hebrew. In
Proceedings of ACL-SRW.
133
