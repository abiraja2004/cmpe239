Quantifiers in Dependency Tree Semantics
Leonardo Lesmo, Livio Robaldo, Jelle Gerbrandy
Dipartimento di Informatica - Universita? di Torino
{lesmo,robaldo,gerbrand }@di. unito. it
Abstract
Dependency Tree Semantics (DTS) is an underspecified formalism for representing
quantifier scope ambiguities in natural language. DTS features a direct interface
with a Dependency grammar and an incremental, constraint-based disambiguation
mechanism. In this paper, we discuss the meaning of quantifier dependency in DTS
by translating its well formed structures into formulae of a Second Order Logic
augmented with Mostowskian generalized quantifiers.
1 Introduction
Dependency Tree Semantics (DTS) is an underspecified formalism for deal-
ing with quantifier scope ambiguity. DTS tries to keep the advantages of
most common underspecification techniques: it has a straightforward syntax-
semantics interface with a Dependency Grammar, just as QLF has [1], and
it allows for monotonically adding constraints to take partial disambiguations
into account, just as in UDRT [12], MRS [3] or CLLS [4]. These features
have been presented in [7] and [8], whereas in [9] DTS is proposed as a
possible underspecified semantic structure of Meaning?Text Theory [10].
This paper discusses a third property of DTS in further depth: the possibility
to represent branching quantifier (BQ) readings. Branching quantification in
DTS has partially been discussed in [7] and [8], in which we compared DTS
with First Order Logic (FOL). However, FOL is limited in that it allows to
represent only standard quantifiers (? and ?); in this paper we compare DTS
with the logic developed in [13] and [14], which is a fragment of Second Or-
der Logic which allows for a representation of branching quantification with
Generalized Quantifiers.
1.1 Intuitions behind Dependency Tree Semantics
The key idea of DTS is to specify quantifier scope by explicitly showing the
dependencies between involved (quantified) groups of entities, i.e. by imple-
menting a sort of ?Skolemization? in the underspecified representation. Well-
formed structures in DTS are based on a simple graph G that represents the
predicate-arguments relations, without any quantification. The nodes of G
are either predicates or discourse referents; each arc connects a predicate with
a discourse referent and is labelled with the number of the predicate argument
position. With each discourse referent we associate a quantifier (given by a
function QUANT from discourse referents to quantifiers) and its restriction,
which is given by a function RESTR that associates a subgraph of G to each
discourse referent. In (1), we show a first simple example
(1) Two students study three theorems
study?
stud?
x y
theor?
1 2
1 1
stud?
x y
theor?
1 1Restr(x)= Restr(y)=
Quant(x)= two Quant(y)= tree
The representation in (1) is still ambiguous; to disambiguate, we need to
specify how the quantifiers depend on each other. This is done by inserting
dotted arcs between discourse referents, named semdep arc. In figure 1.a and
fig 1.b two fully-specified representations of sentence (1) are given. Fig.1.a
shows the reading in which the quantifier ?three? depends on (has scope inside)
the quantifier ?two?. In figure 1.b, the arc linking x to y specifies that the two
students depend on the theorems. In both interpretations, the wide-scope
quantifier is linked to a new node called Ctx ? the context.
But DTS allows for very natural representation of a third reading of sentence
(1): in figure 1.c, both discourse referents are linked to the context. This is
the branching quantifier (BQ) reading. As we will see, the BQ reading is true
only in those models in which we can find a set of two students and a set of
three theorems, for which it holds that each student in the first set studies each
theorem in the second one. In NL, there are many cases in which the correct
study?
stud?
x y
theor?
1 2
1 1
Ctx
study?
stud?
x y
theor?
1 2
1 1
Ctx
study?
stud?
x y
theor?
1 2
1 1
Ctxa) b) c)
Fig. 1. The three readings of sentence (1)
truth conditions can be captured only via a BQ reading; in fact, it is easy to
add some context elements in the sentence in order to force the two involved
sets to be constant; for instance, in (2.i), the involved students and theorems
are explicitly mentioned in two appositions, while in (2.ii) the prepositional
modifier with my sister favours an interpretation in which three persons, two
friends of mine and my sister, went together to three same concerts.
Finally, even if there are not explicit syntactic elements forcing a BQ reading,
in many cases this is done by world knowledge; for example, in (2.iii), world
knowledge seems to render the reading in which two students have seen the
same three drug dealers the most salient; in fact, the presence of drug-dealers
in front of a school is (fortunately) a rare event and this induces to prefer the
reading minimizing the number of involved drug dealers.
(2) (i) Two students, John and Jack, study three theorems: the first three
of the book.
(ii) Two friends of mine went to three concerts with my sister.
(iii) Two students of mine have seen three drug dealers in front of the
school.
Not all possible configurations of semdep arcs are allowed. For instance, a
well-formed DTS cannot contain cycling paths, which would correspond to a
reading in which two sets of entities depend on each other, which is clearly
absurd. Furthermore, there are constraints to reduce the available readings
to those admitted in NL. In this paper, we will focus on the expressivity of
the general formalism, and provide a precise definition of the meaning of all
configurations that respect a minimal set of syntactic constraints, and abstract
from the question whether they correspond to an actual reading in NL. In other
words, in DTS the set of logical admitted readings is kept separate from the
subset of readings admitted in NL, and this paper focus on the former.
1.2 Formalisation: Syntax of DTS
A well-formed structure (wfs) in DTS is a Scoped Dependency Graph (SDG)
as defined below. We take as given a set of predicates pred and a set of
discourse referents D.
Definition 1.1 [Flat Dependency Graphs (FDG)]
A Flat Dependency Graph is a tuple ?N,L,A,Dom, f? s.t.:
- N is a set of nodes {n1, n2, . . . , nk}.
- L is a set of labels {l1, l2, . . ., lm}; in fig.1, L?{1, 2}.
- Dom ? pred?D is a set domain objects: predicates and discourse referents
- f is a function f : N 7? Dom, specifying the node referent, i.e. the domain
object with which the node is associated. In the following, whenever f(n) ?
X, we will say that node n is of type X.
- A is a set of arcs. An arc is a triple (ns, nd, l), where ns, nd ? N , ns is of
type pred, nd is of type D and l ? L.
Without going into further details, we stipulate that Gf is a connected acyclic
graph such that each node of type pred has one node of type D for each of its
places. Note that there can be two different nodes u and v s.t. f(u)=f(v),
i.e. the nodes in N can be seen as occurrences of symbols from Dom.
Definition 1.2 [Scoped Dependency Graph (SDG)]
A Scoped Dependency Graph is a tuple ?Gf , ctx,Q, quant, restr, SemDep? s.t.:
- Gf = ?N,L,A,Dom, f? is an FDG.
- ctx is a special element called the context.
- Q is a set of 2-place Mostowskian quantifiers {every, most, two, . . .} 1
- quant is a total function ND 7? Q, where ND ? N are the nodes of type D
- restr is a function assigning to each d ? ND its restriction, which is a sub-
graph of Gf .
- SemDep is a relation ND ? (ND ? {{ctx}}).
When SemDep(d, d?), we say that d depends on d?. Note that a discourse ref-
erent can depend on more than one other discourse referent. The dependence
relation needs to satisfy the following constraints:
? The transitive closure of SemDep is a partial order on all discourse referents
and ctx, with ctx as its maximal element.
? Let d be a discourse referent, and let R(d) be the smallest set that contains
d, and for which it holds that if d? is in R(d) and d?? occurs in the restriction
of d?, then also d?? ? D. It must hold that:
? If d1 ? R(d), d2 6? R(d), and d1 depends on d2, then also d depends on d2
? If d1 ? R(d), d2 6? R(d), and d2 depends on d1, then also d depends on d1
These last two constraints serve to exclude certain dependency relations that
are ?logically impossible?, and make sure that, for example, a sentence like
?Most representatives of a company took every sample? does not get a reading
in which ?a? depends on (only) ?every? and ?every? depends (only) on ?most?.
2 Branching quantification
Branching quantification was introduced by Henkin [5] in the context of FOL;
Hintikka [6] showed that it can occur also in NL. A great step toward the
definition of a model-theoretic schema for BQ was made by Barwise [2] who
merged Hintikka?s BQ account with the theory of Generalized Quantifiers.
Barwise?s idea was that the truth-conditions of BQ readings are connected
with the monotonicity of the involved quantifiers. He claimed that there is
no uniform schema for BQ: the formulae associated to sentences featuring all
monotone increasing (M?) quantifiers are different from those associated to
sentences featuring all monotone decreasing (M?) quantifiers. According to
Barwise, sentences with mixed quantifiers (some M? and some M?) make no
1 A 2-place Mostowskian Quantifier [11] (see also [13]) is a symbol Q such that, if x is an
individual variable and ?, ? are formulae then Qx(?,?) is also a formula. Semantically, Q
denotes, in every model M with universe A, a function q which takes in input two subsets B
and C of A and returns a truth-value. Mostowskian Quantifiers are cardinality quantifiers,
in the sense that q(B,C) depends only on the cardinalities of the sets (B ? C), (B \ C),
(C \B) and (A \ (B ? C)). Some examples are
? ?Allx(P1(x), P2(x))?M = true iff |(?P1(x) ? ?P2(x)?M )| = 0
? ?Fewx(P1(x), P2(x))?M = true iff |(?P1(x) ? P2(x)?M )| > ?
sense from a linguistic point of view.
On the other hand, Sher [13], [14] observed that since the semantics of
linearly ordered quantification is provided regardless to monotonicity, there
seems to be no methodological reason for imposing further constraints in case
of partially ordered quantification. In other words, even if readings from NL
are not available, this should not exclude their logical interpretation.
Sher specified the semantics of BQ on the basis of a precise definition of
the involved groups, according to so-called maximality conditions; roughly,
her claim is that the interpretation of a BQ reading with quantifiers of any
type corresponds to the one of Barwise for M? quantifiers augmented with
a maximality condition requiring that the involved sets are maximal with
respect to the body of the formula. Consider the two following sentences:
(3) (i) Most of the dots and most of the stars are all connected by lines.
(ii) Few of the dots and few of the stars are all connected by lines.
In Sher?s logic (let us name it L0) sentences in (3) are associated with formulas
of the following form:
(4) ?P1, P2[ C1 : Q1x(dot(x), P1(x))?
C2 : Q2y(star(y), P2(y))?
IN : ?xy[(P1(x) ? P2(y)) ? conn(x, y)]?
Max(?P1, P2?, IN) ]
where Q1 and Q2 are the Mostowskian quantifiers corresponding to the deter-
miners in our example: Q1=Q2=Most for (3.i); and Q1=Q2=Few for (3.ii).
The symbols C1, C2, IN are labels on the subformulae and Max(?P1, P2?, IN)
is an abbreviation for a maximality condition that states that two sets P1 and
P2 are maximal with respect to the formula with label IN , in the sense that
there are no strict supersets of P1 and P2 that satisfy IN . Formally, the max-
imality condition in (4) is the following formula:
Max(?P1, P2?, IN) ?
?P ?1, P ?2[ ?xy[ (P1(x) ? P2(y)) ? (P ?1(x) ? P ?2(y))?
(P ?1(x) ? P ?2(y)) ? conn(x, y) ] ?
?xy[ (P ?1(x) ? P ?2(y)) ? (P1(x) ? P2(y)) ]]
Sher generalizes the schema of (4), so that it applies to any partially ordered
set of arbitrary quantifiers. To achieve this, it is necessary to existentially
quantify n-ary generalized Skolem functions Hi rather than simple sets Pi,
and to assert maximality conditions also on the subformulae with label Ci.
Here, an n-ary Skolem function is just an n + 1-ary relation H ? we will
write H(x1, . . . xn+1) if x1 . . . xn+1 stand in the relation H, but also write
H(x1 . . . xn) for the set of objects xn+1 s.t. H(x1, . . . xn+1). Consider now a
branching reading such as in the following sentence:
(5) Few men inserted a coin in three coffee machines.
Fewx(man?(x)) @@
??Threey(CoffeeMach?(y))
Az(Coin?(z)) Inserted?(x, z, y)
=df ?Hx, Hy, Hz[ Cx: Fewx(man?(x), Hx(x)) &
Cy: Threey(CoffeeMach?(y), Hy(y)) &
Cz: ?xy[(Hx(x)?Hy(y))? Az(coin?(z), Hz(x, y))] &
IN: ?xyz[Hz(x, y, z)? inserted?(x, y, z)] &
Max(?Hx, Hy?, Cz) & Max(?Hz?, IN) ]
In this reading, the quantifier A depends on both Three and Few: there can be
a different coin for every pair of a man and a coffee machine. This is reflected
by the fact that Hz, the Skolem function associated with the quantifier A, is a
2-ary function, while Hx, Hy are 0-ary Skolem functions (that is, predicates).
The formula states that we have to find witnesses Hx, Hy and Hz such that
Hz corresponds to the extension of inserted?, and Hx and Hy are maximal
sets of individuals x and y such that the set of objects z inserted by x in
y, Hz(x, y, z), includes at least one coin; Hx is a set of a ?few men? and Hy
contains ?three coffee machines?. See [14] for the formal details.
3 Nested Quantification
A limitation of Sher?s logic is that it does not handle the case in which one
quantifier occurs in the syntactical restriction of another quantifier. Consider:
(6) Two representatives of three African countries arrive.
rep?
x
af?c?
1
2
1
arrive
y
1
1
of?
y
Restr(x)=
Restr(y)= Quant(x)= two
Quant(y)= tree
af?c?
rep?
x
1
2
1
y
of?
1
In this example, the quantifier Three occurs in the syntactic restriction of
Two. This corresponds to the fact that the discourse referent y occurs in the
graph RESTR(x). This type of reading cannot be directly represented in
Sher?s logic. Therefore, we propose to extend her definitions to accommodate
for these cases as well. Lack of space does not permit us to state the precise
definitions; we will give two examples instead which should illustrate how the
definitions work. Before discussing the three possible disambiguations of (6),
we introduce a new abbreviation to increase readability.
If ? is a well formed formula, x1 . . . xn a sequence of discourse referents, and
S1, . . . , Sn a sequence of predicates, we define:
?S1, . . . , Sn? ?
max
?[x1 . . . xn] ?
Max(?S1, . . . , Sn?,?x1 . . . xn[(S1(x1) ? . . . ? Sn(xn)) ? ?])
We will omit the reference to the variables x1 . . . xn in the notation when this
does not lead to confusion. By using ?
max
, the formula in (5) can be replaced
by the following equivalent
?Hx, Hy, Hz[ Fewx(man?(x), Hx(x)) & Everyy(CoffeeMach?(y), Hy(y)) &
?Hx, Hy??
max
[ Az(coin?(z), Hz(x, y, z))&
?Hz(x, y)??
max
inserted?(x, y, z) ] ]
For representing the restriction of quantifiers in the logic, in addition to the
Skolem functions Hx that represent the body of the quantifiers, we introduce
restriction sets ?x. The three readings of (6) can now be represented as:
x
y
Ctx
?Hx, Hy,?x,?y[ Twox(?x(x), Hx(x))& ?Hx??
max
(arrive?(x)) &
??x??
max
[Threey(?y(x, y), Hy(x, y)) &
??y(x)??
max
(af?c?(y)) &
?Hy(x)??
max
(repr of?(x,y)) ]]
x
y
Ctx
?Hx, Hy,?x,?y[ Threey(?y(y), Hy(y)) & ??y??
max
(af?c?(y)) &
?Hy??
max
[Twox(?x(y, x), Hx(y, x)) &
??x(y)??
max
(repr of?(x,y)) &
?Hx(y)??
max
(arrive?(x)) ]]
x
y
Ctx
?Hx, Hy,?x,?y[ Twox(?x(x), Hx(x)) & Threey(?y(y), Hy(y)) &
??x, Hy??
max
(repr of?(x,y)) & ??y??
max
(af?c?(y)) &
?Hx??
max
(arrive?(x)) ]
Let us shortly discuss each of these readings.
In the first reading, y depends on x, which is reflected in the fact that ?y and
Hy are unary Skolem functions whose values depend on the value for x. The
restriction set of ?three?, ?y(x), is (for each x) the set of all African countries,
while Hy(x) is the set of objects represented by x. Therefore, the restriction
set of ?two?, ?x, is a maximal set of individuals x that represent three African
countries. Two of these individuals must be in Hx ? the set of those that
arrive.
In the second reading, x depends on y. The set ?y consists of all African
countries. The set Hy must contain three of these, and it is required that for
each element y in Hy there are two individuals in the set of all its representa-
tives ?x(y) that are in Hx(y), which consists of all individuals that arrive.
The third formula represents the branching reading of the sentence, in which
the two discourse referents do not depend on each other. This formula states
that there are sets ?x and Hy such that each individual in ?x represents all
elements from Hy (this is expressed by the maximality condition on the pair
(?x, Hy)), and for which it holds that Hy contains three African countries,
and that two of the representatives from ?x must arrive. In the following, we
report a last complex example:
(7) Everyx teacher failed twoy students that studied less than halfz of the
topics in thew program.
The following DTS represents a reading of (7) in which the discourse referent
w depends on both y and z, and y and z depend on x.
x
1 2
failed
y
Restr(x)=
Quant(y)= ?
Quant(x)= ?
2
zof?
stud
1
study
topic
1
1
w
teacher
1
progr
1
12 x
teacher
1 Restr(w)=
w
progr
1
Restr(z)=
1
2
1
of? Restr(y)=
1
2
1
y
topic
w
z
stud study
z
Quant(z)= < 12
Quant(w)= the
x
y
Ctx
w
z
This DTS gets the translation reported below; in this interpretation, the two
students and the program depend on a teacher, while the set of topics depends
both on a program and on a student. In the formula, the pair of students
associated to a teacher x ? Hx has to belong to the set ?y, i.e. the set of
students y such that the set of things studied by y, i.e. Hz(x, y, w), contains
less than half elements of ?z, i.e. the set of topic in Hw(x), i.e. the program
of x.
?Hx, Hy, Hz, Hw,?x,?y,?z,?w[
Everyx(?x(x), Hx(x)) & {?x}?
max
(teacher?(x)) &
{Hx}?
max
[ Thew(?w(x,w), Hw(x,w)) & {?w(x)}?
max
(progr?(w)) &
Twoy(?y(x, y), Hy(x, y))] & {Hy(x)}?
max
(failed?(x, y)) &
{?y(x), Hw(x)}?
max
[Lthz(?z(x, y, w, z), Hz(x, y, w, z)) &
{?z(x, y, w)}?
max
(topic?(z)?of?(z, w)) &
{Hz(x, y, w)}?
max
(stud?(y)?study?(y, z))]]]
4 Conclusions and further works
In this paper, a comparison between Dependency Tree Semantics and Sher?s
work on Branching Quantification and Generalized Quantifiers has been pre-
sented. In particular, we have shown how disambiguated DTS structures can
be related to formulae of an extension of the formalism from [14] to represent
branching quantification. This provides a way to model-theoretically inter-
pret disambiguated DTS structures. Concerning further work, one of the next
steps in research on DTS will be extending its expressivity in order to deal
with cumulativity, which is a topic that has received very little attention in re-
cent studies on underspecification. Cumulative readings arise from a different
kind of branching quantification, as argued in [13], so the step for including
them is more natural in DTS than in other underspecified logics that do not
take BQ into account.
References
[1] Alshawi, H., editor, ?The Core Language Engine,? Mit Press, Cambridge, MA,
1992.
[2] Barwise, J., On branching quantifiers in english, The Journal of Philosophical
Logic (1979), pp. 47?80.
[3] Copestake, A., D. Flickinger and I. Sag, Minimal recursion semantics. an
introduction, Technical report, Manuscript, Stanford University (1999).
[4] Egg, M., A. Koller and J. Niehren, The constraint language for lambda
structures, J. of Logic, Language and Information 10 (2001), pp. 457?485.
[5] Henkin, L., Some remarks on infinitely long formulas, in: Finitistic methods,
Proc. Symphosium of Foundations Math, Warsaw, 1961, pp. 167?183.
[6] Hintikka, J., Quantifiers vs quantification theory, Dialectica (1973), pp. 329?
358.
[7] Lesmo, L. and L. Robaldo, Dependency tree semantics and underspecification,
in: Proc. Int. Conf. On Natural language processing (ICON2004), Hyderabad,
India, 2004.
[8] Lesmo, L. and L. Robaldo, From dependency tree semantics to fol, in: Proc. 6th
Workshop on Computational Semantics (IWCS-6), Tilburg, 2005, pp. 384?386.
[9] Lesmo, L. and L. Robaldo, Underspecification of quantifier scope in mtt, in:
Proc. 2th Int.Conf. on Meaning Text Theory, Moscow, 2005.
[10] Melcuk, I., Semantics and the lexicon in modern linguistics., in: A. Gelbukh,
editor, In Proc. of the 1st International Conference on Intelligent Text
Processing and Computational Linguistics (CICLing), 2000, pp. 6?18.
URL www.CICLing.com
[11] Mostowski, A., On a generalization of quantifiers., Fundamenta Mathematicae
44 (1957), pp. 12?36.
[12] Reyle, U., Dealing with ambiguities by underspecification: Construction,
representation and deduction, Journal of Semantics (1993), pp. 123?179.
[13] Sher, G., Ways of branching quantifiers, Linguistics and Philosophy (1990),
pp. 393?422.
[14] Sher, G., Partially-ordered (branching) generalized quantifiers: a general
definition, The Journal of Philosophical Logic (1997), pp. 1?43.
