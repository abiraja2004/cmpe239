AN EXTENDED THEORY 
OF HEAD-DRIVEN PARSING 
Mark-Jan Nederhof * 
University of Nijmegen 
Department of Computer Science 
Toernooiveld, 6525 ED Nijmegen 
The Netherlands 
markj an?cs, kun. nl 
Abstract 
We show that more head-driven parsing algorithms can 
he formulated than those occurring in the existing lit- 
erature. These algorithms are inspired by a family of 
left-to-right parsing algorithms from a recent publica- 
tion. We further introduce a more advanced notion of 
"head-driven parsing" which allows more detailed spec- 
ification of the processing order of non-head elements 
in the right-hand side. We develop a parsing algorithm 
for this strategy, based on LR parsing techniques. 
Introduct ion 
According to the head-driven paradigm, parsing of a 
formal anguage is started from the elements within the 
input string that are most contentful either from a syn- 
tactic or, more generally, from an information theoretic 
point of view. This results in the weakening of the 
left-to-right feature of most traditional parsing meth- 
ods. Following a pervasive trend in modern theories of 
Grammar (consider for instance \[5, 3, 11\]) the compu- 
tational inguistics community has paid large attention 
to the head-driven paradigm by investigating its appli- 
cations to context-free language parsing. 
Several methods have been proposed so far exploit- 
ing some nondeterministic head-driven strategy for 
context-free language parsing (see among others \[6, 13, 
2, 14\]). All these proposals can be seen as general- 
izations to the head-driven case of parsing prescrip- 
tions originally conceived for the left-to-right case. The 
methods above suffer from deficiencies that are also no- 
ticeable in the left-to-right case. In fact, when more 
rules in the grammar share the same head element, or 
share some infix of their right-hand side including the 
head, the recognizer nondeterministically guesses a rule 
just after having seen the head. In this way analyses 
that could have been shared are duplicated in the pars- 
ing process. 
Interesting techniques have been proposed in the left- 
to-right deterministic parsing literature to overcome re- 
dundancy problems of the above kind, thus reducing 
*Supported by the Dutch Organisation for Scientific Re- 
search (NWO), under grant 00-62-518 
Giorgio Satta 
Universith di Padova 
Dipartimento di Elettronica e Informatica 
via Gradenigo 6/A, 35131 Padova 
Italy 
satt a@dei, unipd, it 
the degree of nondeterminism of the resulting methods. 
These solutions range from predictive LR parsing to LR 
parsing \[15, 1\]. On the basis of work in \[8\] for nonde- 
terministic left-to-right parsing, we trace here a theory 
of head-driven parsing going from crude top-down and 
head-corner to more sophisticated solutions, in the at- 
tempt to successively make more deterministic the be- 
haviour of head-driven methods. 
Finally, we propose an original generalization ofhead- 
driven parsing, allowing a more detailed specification of 
the order in which elements of a right-hand side are to 
be processed. We study in detail a solution to such 
a head-driven strategy based on LR parsing. Other 
methods presented in this paper could be extended as 
well. 
Prel iminar ies 
The notation used in the sequel is for the most part 
standard and is summarised below. 
Let D be an alphabet (a finite set of symbols); D + 
denotes the set of all (finite) non-empty strings over D 
and D* denotes D + U {c}, where c denotes the empty 
string. Let R be a binary relation; R + denotes the 
transitive closure of R and R* denotes the reflexive and 
transitive closure of R. 
A context=free grammar G = (N, T, P, S) consists of 
two finite disjoint sets N and T of nonterminal and 
terminal symbols, respectively, a start symbol S E N, 
and a finite set of rules P. Every rule has the form 
A ~ a, where the left-hand side (lhs) A is an element 
from N and the right-hand side (rhs) e~ is an element 
from V +, where V denotes (N U T). (Note that we 
do not allow rules with empty right-hand sides. This 
is for the sake of presentational simplicity.) We use 
symbols A, B, C , . . .  to range over N, symbols X, Y, Z 
to range over V, symbols a,/3, 7 . . . .  to range over V*, 
and v, w, z , . . .  to range over T*. 
In the context-free grammars that we will consider, 
called head grammars, exactly one member from each 
rhs is distinguished as the head. We indicate the head 
by underlining it, e.g., we write A --* aXfl.  An expres- 
sion A --+ cr7/3 denotes a rule in which the head is some 
member within 7- We define a binary relation ~ such 
210 
that B <> A if and only if A --* otB__fl for some a and/3. 
Relation (>* is called the head-corner elation. 
For technical reasons we sometimes need the aug- 
mented set of rules P I ,  consisting of all rules in P plus 
the extra rule S ~ ~ .kS, where f f  is a fresh nontermi- 
hal, and 3_ is a fresh terminal acting as an imaginary 
zeroth input symbol. The relation p,t is extended to a 
relation --. on V* x V* as usual. We write ~ P-~ 6 when- 
ever 7 "-'* 6 holds as an extension of p E P ? We write 
7t"P2"'~" 6 if 7 ~ 61 ~ 6 P" 2"" "6~-x ---,6 
For a fixed grammar, a head-driven recognition algo- 
rithm can be specified by means of a stack automa- 
ton a = (T, alph, Init(n), ~--,, Fin(n)),  parameterised 
with the length n of the input. In A, symbols T 
and Aiph are the input and stack alphabets respec- 
tively, lair(n), Fin(n) E Alph are two distinguished 
stack symbols and ~ is the transition relation, defined 
on Alph + x Alph + and implicitly parameterised with the 
input. 
Such an automaton manipulates stacks F E Aiph +, 
(constructed from left to right) while consulting the 
symbols in the given input string. The initial stack 
is Init(n). Whenever F ~ F r holds, one step of the 
automaton may, under some conditions on the input, 
transform a stack of the form F"F into the stack F"F ~. 
In words, F ~ F ~ denotes that if the top-most few sym- 
bols on the stack are F then these may be replaced by 
the symbols I ' .  Finally, the input is accepted whenever 
the automaton reaches stack Fin(n).  Stack automata 
presented in what follows act as recognizers. Parsing 
algorithms can directly be obtained by pairing these 
automata with an output effect. 
A fami ly  o f  head-dr iven  a lgor i thms 
This section investigates the adaptation of a family of 
left-to-right parsing algorithms from \[8\], viz. top-down, 
left-corner, PLR, ELR, and LR parsing, to head gram- 
mars. 
Top-down pars ing  
The following is a straightforward adaptation of top- 
down (TD) parsing \[1\] to head grammars. 
There are two kinds of stack symbol (items), one of 
the form \[i, A, j\], which indicates that some subderiva- 
tion from A is needed deriving a substring of ai+l ? ? ? aj, 
the other of the form \[i, k, A --* a ? 7 ?/3, m, j\], which 
also indicates that some subderivation from A is needed 
deriving a substring of ai+l ? ? ? aj, but specifically using 
the rule A --~ ot7/3, where 7 -'-~* ak+x . . .  a,n has already 
been establishe~. Formally, we have 
1~ D = { \ [ i ,A , j \ ] l i< j}  
I f  ? = { \ [ i , k ,A -*a .y . f l ,  m, j  \] IA - -~aZ/3EP~ A 
i<k<m<_j )  
AIKor l thm 1 (Head-dr lven  top-down)  
a~ = (T, I~  D U IT  D, 1nit(n), ~-*, Fin(n)),  where 
Init(n) = \[-1,  -1 ,  S' ---* ? 3_ ? S, 0, n\], 
Fin(n) = \[-1,  -1 ,  S' --** 3-S *, n, n\], and the transition 
relation ~-~ is given by the following clauses. 
0 \[ i ,A, j \]  ~ \ [ i ,A , j \ ] \ [ i ,B , j \ ]  
where there is A ~ aB__fl E p t  
0a \[i, k, A ---, a ? 7 * B/3, m, j\] ~-, 
\[ i ,k,A---,  a ? 7 ? B/3, m, j \ ] \ [m,B , j \ ]  
0b \[i,k,A---* aB  ?7  * /3, m, j \ ]  
\ [ i ,k ,A  ~ aB ? 7 */3, m, j \ ] \ [ i ,B ,k \ ]  
1 \ [ i ,A , j \ ]~- - * \ [ i , k - l ,A - - - *a .a ? /3 ,  k, j \]  
where there are A ~ aafl  E p t  and k such that 
i<k_<jandak=a 
2a \ [ i ,k ,A  ---* a ? 7 * a\[3, m, j \ ]  ~-~ 
\ [ i ,k ,A  ~ a ? 7a */3, m + 1,j\] 
provided m < j and am+l = a 
2b Symmetric to 2a (eft 0a and 0b) 
3 \ [ i ,A , j \ ] \ [ i ' , k ,B~?6 ? ,m, j ' \ ]~  
\ [ i , k ,a  ~ a ? B * fl, m, j \ ]  
where there is A ~ aBBfl E P? 
(i = i ~ and j = f are automatically satisfied) 
4a \[i, k, A ---* a ? 7 * B\[3, m,j\]\[i ' ,  k', B --* ?6 , ,  m', j ' \ ]  
\ [ i ,k ,A  ~ c~ ? 7B  ? fl, m' , j \ ]  
provided m = k' 
(m = i' and j = j '  are automatically satisfied) 
4b Symmetric to 4a 
We call a grammar head-recursive i fA ~+ A for some 
A. Head-driven TD parsing may loop exactly for the 
grammars which are head-recursive. Head reeursion is a 
generalization of left recursion for traditional TD pars- 
ing. 
In the ease of grammars with some parameter mech- 
anism, top-down parsing has the advantage over other 
kinds of parsing that top-down propagation of parame- 
ter values is possible in collaboration with context-free 
parsing (eft the standard evaluation of definite clause 
grammars), which may lead to more efficient process- 
ing. This holds for left-to-right parsing as well as for 
head-driven parsing \[10\]. 
Head-corner  pars ing  
The predictive steps from Algorithm 1, represented by 
Clause 0 and supported by Clauses 0a and 0b, can be 
compiled into the head-corner relation ~)*. This gives 
the head-corner (HC) algorithm below. The items from 
I T  D are no longer needed now. We define I Hc = I f  D. 
Algor i thm 2 (head-corner )  
A ~tc = (T, I Hc, Init(n),  ~-*, Fin(n)),  where 
In it(n) = \[-1,  -1 ,  S' ~ ? 3- ? S, 0, n\], 
Fin(n) = \[-1,  -1 ,  S' --~ ? IS  =, n, hi, and ~ is given 
by the following clauses. (Clauses lb, 2b, 3b, 4b are 
omitted, since these are symmetric to la, 2a, 3a, 4a, 
respectively.) 
la  \ [ i , k ,a - - *aoT ?B /3 ,  m,j\]~--~ 
\[i, k, A ---* a ? 7 ? B/3, m, j\]\[m, p -  1, C ~ rl.a.O, p, j\] 
where there are C ~ r/a0 E p t  and p such that m < 
p < j and ap = a and C ~* B 
211 
2a \ [ i ,k ,A- -*  a * 7 * a~,m, j \ ]  ~-* 
\ [ i ,k ,A- -*  a * -/a * 13, m+ 1,j\] 
provided m < j and am+l - - - -  a 
3a \[i, k, D ~ a*7*A13, m,j\]\[i ' ,  k', B ~ .6 . ,  ra' , jq ~-. 
\[i, k, D --~ o~.7.A13, rn, j\]\[i', k', C --~ ~.B .8 ,  rn', j'\] 
provided m = ?, where there is C --* r/_B0 E p t  such 
that  C <>* A 
(j = j' is automatically satisfied) 
4a \ [ i , k ,A  ~ a .7 .B13,  m, j \ ] \ [ i ' , k ' ,B  ---* .6 . ,m' , j ' \ ]  
\[i, k ,A  ~ a * ' IB  * 13, m' ,  j\] 
provided m = k ~ 
(m = i' and j = j '  are automat ica l ly  satisfied) 
Head-corner parsing as well as all a lgorithms in the 
remainder of this paper may loop exactly for the gram- 
mars which are cyclic (where A ---~+ A for some A). 
The head-corner algor i thm above is the only one in 
this paper which has already appeared in the l iterature, 
in different guises \[6, 13, 2, 14\]. 
Pred ic t ive  HI  pars ing 
We say two rules A --* a l  and B --* ~2 have a common 
infix a if a l  = 1310?-/1 and a2 = 132(:~-/2, for some 131,132, 
71 and -/2. The notion of common infix is an adaptat ion 
of the notion of common prefix \[8\] to head grammars .  
If  a g rammar  contains many common infixes, then 
HC parsing may be very nondeterminist ie; in particular,  
Clauses 1 or 3 may be applied with different rules C ---} 
0_a0 E p t  or C ---* r/__B0 E P~ for fixed a or B. 
In \[15\] an idea is described that  allows reduction of 
nondeterminism in case of common prefixes and left- 
corner parsing. The resulting algor i thm is called pre- 
dictive LR (PLR)  parsing. The following is an adapta-  
tion of this idea to HC parsing. The resulting algor ithm 
is called predictive H I  (PHI)  parsing. (HI parsing, to 
be discussed later, is a general ization of LR parsing to 
head grammars . )  
First, we need a different kind of item, viz. of the 
form \[i, k ,A  --~ 7, re, j\], where there is some rule A --* 
a_713. With  such an item, we simulate computat ion of 
different i tems \ [ i , k ,A  --* (~ * 7 * 13, re, j\] E I Hc, for 
different a and 13, which would be treated individually 
by an HC parser. Formally, we have 
I Pm = { \ [ i , k ,A - - ,%m, j \ ] lA - - , c tT_13EP?A 
i<_k<m<_j}  
Algor i thm 3 (P red ic t ive  H I )  
A PHI = (T, I PHI, ln it(n),  ~-~, Fin(n)),  where 
Init(n) = \ [ -1 ,  -1 ,  S'  ---* _1_, 0, n\], 
Fin(n) = \ [ -1 , -1 ,  S'  ~ IS ,  n, n\], and ~-* is given by 
the following (symmetr ic  "b-clauses" omitted).  
la  \ [ i ,k ,A- - -*%m,j \ ]~-*  
\ [ i ,k ,A  ~ % m, j \ ] \ [m,p -  1, C --* a,p, j \ ]  
where there are C ~ y_a0, A ---* aTB13 ~ pt  and p 
such that m < p < j and ap = a an(:\] C O* B 
2a \ [ i ,k ,A--*  7, m, j \ ]  .-. \ [ i ,k ,A- -*  Ta, m + 1,j\] 
provided m < j and am+~ = a, where there is A --* 
aT_.a13 ~ pt  
3a \[i, k, o -~ % m, j \ ] \ [ i ' ,  ~', B -~ ~, m',  j ' \ ]  
\ [ i , k ,D  ---* 7, m,j\]\[i ' ,  k ' ,C  -+ B ,m' , j ' \ ]  
provided m = i' and B --* 6 E p t ,  where there are 
D --* a_TA13, C ---* q_B0 E p t  such that  C <>* A 
4a \ [ i ,k ,A  ---* 7, m, j \ ] \ [ i ' , k ' ,B  ~ 6, m', j ' \ ]  
\[i, k, A ---, -/B, m', j\] 
provided m = k' and B ~ _6 E p t ,  where there is 
A .---. ~7_.Bfl E p t  
Extended HI  pars ing  
The PHI  algor ithm can process s imultaneously a com- 
mon infix a in two different rules A --* 131_~-/1 and 
A --* 132_~72, which reduces nondeterminism. 
We may however also specify an algor i thm which suc- 
ceeds in s imultaneously processing all common infixes, 
irrespective of whether the left-hand sides of the cor- 
responding rules are the same. This a lgor i thm is in- 
spired by exlended LR (ELR)  parsing \[12, 7\] for ex- 
tended context-free grammars  (where r ight-hand sides 
consist of regular expressions over V). By analogy, it 
will be called extended HI  (EHI) parsing. 
This algor ithm uses yet another kind of item, viz. 
of the form \ [ i , k ,{A1,A~, . . . ,Ap}  --* - / ,m, j \ ] ,  where 
there exists at least one rule A --* a_713 for each 
A E {A1,Au , . . . ,Ap} .  With such an item, we simu- 
late computat ion of different i tems \[i, k, A --* a * -/ * 
13, m, j\] E I He which would be treated individually by 
an HC parser. Formally, we have 
I Em = {\[i, k, zx --+ -/, m, j\] I 
0CAC{A I A ---, a-/13 E P t} A 
i<_k<m<j}  
Algor i thm 4 (Extended H I )  
A EH1 = (T, I EHI, Init(n),  ~-*, Fin(n)),  where 
In it(n) = \ [ -1 , -1 ,  {S'} --+ .1_, 0, n\], 
Fin(n) = \ [ -1 , -1 ,  {S'} ~ _l_S, n, n\], and ~-~ is given by: 
la  \ [ i , k ,A - - - *%m, j \ ]  
\[i, k, A --. % m, j\] Ira, p - 1, A'  ---. a, p, j\] 
where there is p such that  m < p < j and ap = a 
and A' = {C \[ qc  ~ 71a_O,A --~aT_Bfl E p I (A  E 
A A C <~* B)} is not empty  
2a \[i,k,A---~ %m, j \ ]  ~ \[i,k,A'---* Ta, m + 1,j\] 
provided ra < j and am+a = a and A'  = {A E 
A \[ A --* a'/aft E pt}  is not empty  
3a \[i, k, A --+ 7, m, j\]\[i', k', A '  ---* 6, m' ,  j ' \ ]  ~-+ 
\ [ i , k ,A  --+ %m, j \ ] \ [ i ' , k ' ,A"  ---, B ,m' , j ' \ ]  
provided rn = i' and B --* ti E p t  for some B E A' 
such that  A"  = {C \] 3C ---+ yB6, D ---* aT_A~ E 
pt (D  E A A C <>* A)} is not empty  
4a \[i, k ,A  - .  %m, j \ ] \ [ i ' , k ' ,A '  ~ a,,n', j ' \]  
\ [ i , k ,h" -+ - /B ,m' , j \ ]  
provided m = k' and B ---+ 6_ E p l  for some B E A'  
such that A" = {A E A I A ---+ crTB13 E p t}  is not 
empty 
212 
This algorithm can be simplified by omitting the 
sets A from the items. This results in common infix 
(CI) parsing, which is a generalization of common pre- 
fix parsing \[8\]. CI parsing does not satisfy the correct 
subsequence property, to be discussed later. For space 
reasons, we omit further discussion of CI parsing. 
H I  pars ing  
If we translate the difference between ELR and LR pars- 
ing \[8\] to head-driven parsing, we are led to HI parsing, 
starting from EHI parsing, as described below. The al- 
gorithm is called HI because it computes head-inward 
derivations in reverse, in the same way as LR parsing 
computes rightmost derivations in reverse \[1\]. Head- 
inward derivations will be discussed later in this paper. 
Ill parsing uses items of the form \[i, k, Q, m, j\], where 
Q is a non-empty set of "double-dotted" rules A --* a * 
3' * ft. The fundamental difference with the items in 
I EHl is that the infix 3' in the right-hand sides does not 
have to be fixed. Formally, we have 
IHI = {\[ i ,k ,Q,m,j \ ]  \[ 
$c  QC {A - -a .7  .B  \] A--*aT_~ E P~)^ 
i<k<m<j}  
We explain the difference in behaviour of Il l parsing 
with regard to EHI parsing by investigating Clauses la 
and 2a of Algorithm 4. (Clauses 3a and 4a would give 
rise to a similar discussion.) Clauses la and 2a both ad- 
dress some terminal ap, with m < p < j.  In Clause la, 
the case is treated that ap is the head (which is not 
necessarily the leftmost member) of a rhs which the al- 
gorithm sets out to recognize; in Clause 2a, the case is 
treated that ap is the next member of a rhs of which 
some members have already been recognized, in which 
case we must of course have p = m + 1. 
By using the items from I t4r we may do both kinds 
of action simultaneously, provided p = m + 1 and ap is 
the leftmost member of some rhs of some rule, where 
it occurs as head)  The lhs of such a rule should sat- 
isfy a requirement which is more specific than the usual 
requirement with regard to the head-corner relation. 2
We define the left head-corner relation (and the right 
head-corner relation, by symmetry) as a subrelation of 
the head-corner relation as follows. 
We define: B / A if and only if A ---* Bo~ for some 
a. The relation Z* now is called the left head-corner 
relation. 
We define 
gotorightl(Q, X) = 
{C ~ ~.  x .o  I c~, lEoePt^ 
3A --* a * 7 * B~ E Q(C <>* B)} 
goloright 2( Q, X)  = 
l If ap is not the leftmost member, then no successful 
parse will be found, due to the absence of rules with empty 
right-hand sides ( epsiion rules). 
2Again, the absence of epsilon rules is of importance here. 
{C~.X .O\ [C~ X .OEPtA  
SA- - .a  .7  . Bfl E Q(C /* B)}U 
{A~a.  TX .~ \ [A ~a. ' r .  X3E  Q} 
and assume symmetric definitions for gotolefl 1 and 
gotoleft~. 
The above discussion gives rise to the new Clauses la 
and 2a of the algorithm below. The other clauses are 
derived analogously from the corresponding clauses of 
Algorithm 4. Note that in Clauses 2a and 4a the new 
item does not replace the existing item, but is pushed 
on top of it; this requires extra items to be popped off 
the stack in Clauses 3a and 4a. 3 
A lgor i thm 5 (HI)  
A m = (T, I Hz, Init(n), ~"h Fin(n)), where 
lnit(n) = \[ -1,  -1 ,  {S' --+ * \]- * S}, O, n\], 
Fin(n) = \ [ - i ,  -1 ,  {S' -~ * .kS .}, n, n\], and ~ defined: 
la  \ [ i ,k,Q,m,j \ ]  ~ \ [ i , k ,Q ,m, j \ ] \ [m,p -  1,Q',p,j\] 
where there is p such that m+ 1 < p_< j and ap = a 
and Q' = gotorightl(Q, a) is not empty 
2a \[i,k,Q,m,j\]~-~ \ [ i ,k ,Q,m, j \ ] \ [ i ,k ,Q ' ,m+ 1,j\] 
provided m < j and am+l = a and Q' = 
gotoright~(Q, a) is not empty 
3a \ [ i ,k ,Q,m, j \ ] I i . . . I , _ l \ [ i ' ,k ' ,Q ' ,m' , j ' \ ]  
\[i, k, Q, .~, ~\]\[i', ~', Q", m', j'\] 
provided m < k', where there is B ---* * X1 . . .X r  * 
E Q' such that Q" = gotorighti(Q, B) is not empty 
4a \[i, k, Q, m, j\] I~...  I,_~ \[i', k', Q', m', j'\] 
\[i, k, Q, m, j\]\[i, k, Q", m', j\] 
provided m = k' or k = k ', where there is B ~ * 
X1 . . .Xr  ? E Q' such that Q" = gotorighl~(Q, B) is 
not empty 
We feel that this algorithm has only limited advan- 
tages over the EHI algorithm for other than degenerate 
head grammars, in which the heads occur either mostly 
leftmost or mostly rightmost in right-hand sides. In 
particular, if there are few sequences of rules of the form 
A ---* A___Lai,Ax ~ A__2ot2,...,Am-1 --~ Amain, or of 
the form A ---, alA__ i, A1 -', a2A__g,..., A,~-i ~ amAin, 
then the left and right head-corner relations are very 
sparse and HI parsing virtually simplifies to EHI pars- 
ing. 
In the following we discuss a variant of head gram- 
mars which may provide more opportunities to use the 
advantages of the LR technique. 
A genera l i za t ion  o f  head  grammars  
The essence of head-driven parsing is that there is a 
distinguished member in each rhs which is recognized 
first. Subsequently, the other members to the right and 
to the left of the head may be recognized. 
An artifact of most head-driven parsing algorithms is 
that the members to the left of the head are recognized 
3In ? ? ? I~-1 represent a number of items, as many as there 
are members in the rule recognized, minus one. 
213 
strictly from right to left, and vice versa for the mem- 
bers to the right of the head (although recognition of 
the members in the left part and in the right part may 
be interleaved). This restriction does not seem to be 
justified, except by some practical considerations, and 
it prevents truly non-directional parsing. 
We propose a generalization of head grammars in 
such a way that each of the two parts of a rhs on both 
sides of the head again have a head. The same holds 
recursively for the smaller parts of the rhs. The con- 
sequence is that a rhs can be seen as a binary tree, in 
which each node is labelled by a grammar symbol. The 
root of the tree represents the main head. The left son 
of the root represents the head of the part of the rhs to 
the left of the main head, etc. 
We denote binary trees using a linear notation. For 
example, if a and /5 are binary trees, then (cOX(f 0 
denotes the binary tree consisting of a root labelled X, 
a left subtree a and a right subtree ft. The notation of 
empty (sub)trees (e) may be omitted. The relation --** 
ignores the head information as usual. 
Regarding the procedural aspects of grammars, gen- 
eralized head grammars have no more power than tra- 
ditional head grammars. This fact is demonstrated by 
a transformation r head from the former to the latter 
class of grammars. A transformed grammar head(e) 
contains pecial nonterminals of the form \[c~\], where c~ 
is a proper subtree of some rhs in the original gram- 
mar G = (T, N, P, S). The rules of the transformed 
grammar are given by: 
A --* \[a\] X \[fl\] for each A ---* (a )X( f  0 ? P 
\[(a)X(/~)\] ~ In\] X \[fl\] for each proper subtree 
(a)X(f l )  of a rhs in G 
where we assume that each member of the form \[e\] in 
the transformed grammar is omitted. 
It is interesting to note that vh,~d is a generalization 
of a transformation vt,~o which can be used to transform 
a context-free grammar into two normal form (each rhs 
contains one or two symbols). A transformed grammar 
rt~o(G) contains special nonterminals of the form \[a\], 
where c~ is a proper suffix of a rhs in G. The rules of 
rtwo(G) are given by 
A --~ X \[a\] for each A ---* Xa  ? P 
\[X?~\] --* X \[a\] for each proper suffix Xa  of a rhs in G 
where we assume that each member of the form \[e\] in 
the transformed grammar is omitted. 
H I  pars ing  rev is i ted  
Our next step is to show that generalized head gram- 
mars can be effectively handled with a generalization 
of HI parsing (generalized HI (GHI) parsing). This 
new algorithm exhibits a superficial similarity to the 
2-dimensional LR parsing algorithm from \[16\]. For a 
set Q of trees and rules, 4 closure(Q) is defined to be 
4It is interesting to compare the relation between trees 
and rules with the one between kernel and nonkernel items 
of LR parsing \[1\]. 
the smallest set which satisfies 
closure(Q) D_ Q U 
{A --~ (a)X(g)  ? P \] (7)A(~f) ? closure(Q) v 
B ? c l0sure(Q)}  
The trees or rules of which the main head is some 
specified symbol X can be selected from a set Q by 
goto(Q, x )= (t ? Q It = = A - .  
In a similar way, we can select trees and rules according 
to a left or right subtree. 
gotoleft(Q,~) = {t ? Q I t = (~)X(~) v 
t = A --* (a)X(/3)} 
We assume a symmetric definition for gotoright. 
When we set out to recognize the left subtrees from 
a set of trees and rules, we use the following function. 
left(Q) = closure({cr \[ (~)X(/5) ? Q v 
A --* (a)X(/~) ? Q}) 
We assume a s~,mmetric definition for right. 
The set I all1 contains different kinds of item: 
? Items of the form \ [ i ,k ,Q,m, j \ ] ,  with i < k < m < j ,  
indicate that trees (a)X(f l )  and rules A ---* (a)X(~)  
in Q are needed deriving a substring of ai+l ... aj, 
where X ---~* ak+x. . .a ,~ has already been estab- 
lished. 
? Items of the form \[k, Q, m, j\], with k < m < j, indi- 
cate that trees (cOX(fl) and rules A ~ (a)X(f l )  ill V 
are needed deriving a substring of ak+l. ? ? aj, where 
(~X ---~* ak+l . . .  a,,  has already been established. 
Items of the form \[i, k, Q, m\] have a symmetric mean- 
ing. 
? Items of the form \[k, t, m\], with k < m, indicate that 
7 "-'** ak+l ... am has been established for tree t = 7 
or rule t = A --* 7. 
A lgor i thm 6 (Genera l i zed  H I  pars ing)  
A GH1 = (T, I Gin, Init(n), ~--~, Fin(n)), where 
Init(n) : \ [ -1,  {S' --* _L(S)}, O, n\], 
Fin(n) = \[-1,  S' ---* _L(S), hi, and ~-* defined: 
la \[i,k,Q,m,j\]~--* \[ i ,k,O',m\] 
provided Q' = gotoright(Q, e) is not empty 
lb \ [ i ,k ,Q,m, j \ ]  .--, \ [k,Q',m,j \]  
provided Q' = gotoleft(Q, c) is not empty 
lc \ [k,Q,m,j \ ]  ,--* \[k,t,m\] 
provided t ? gotoright(Q, e) 
ld \[i, k, Q, m\] ~ \[k, t, m\] 
provided t ? gotoleft(Q, ~) 
2a \ [ i ,k ,Q,m, j \ ]  ~ \ [ i , k ,Q ,m, j \ ] \ [m,p -  1,Q',p,j\] 
where there is p such that m < p < j and Q' = 
goto(right(Q), ap) is not empty 
2b \ [ i ,k ,Q,m, j \ ]  ~ \ [ i , k ,Q ,m, j \ ] \ [ i ,p -  1,Q',p,k\] 
where there is p such that i < p < k and Q' = 
goto(lefl(Q), av) is not empty 
214 
Stack 
\[-1, {S' 
\[-1, {S' 
\[-1, {S' 
\[-1, {S' 
\[-~,{s' 
--* _L(S)}, 0, 4\] 
_L(S)}, 0, 4\] \[0, 3, {S ---, ((c)A(b))s, S ~ (A(d))s, S ---* (B)s}, 4, 4\] 
-+  J_(S)}, 0, 4\] \[0, 3, {S -+  ((c)A(b))s, S ---, (A(d))s, S -~  (B)s}, 4\] 
.L(S)}, 0, 4\] \[0, 3, {S ~ ((c)A(b))s, S ---* (A(d))s, S ---* (B)s}, 4\] \[0, 1, {A ~ a}, 2, 3\] 
---* .I_(S)}, 0, 4\] \[0, 3, {S ~ ((c)A(b))s, S ---* (m(d))s, S ---* (B)s}, 4\] \[0, 1, {A ---* a}, 2\] 
\[-1, {S' --* .L(S)}, 0, 4\] \[0, 3, {S ~ ((c)A(b))s, S ---* (A(d))s, S ~ (B)s},  4\] \[1, A --~ a, 2\] 
\[-1, {S' ~ .L(S)}, 0, 4\] \[0, 3, {S ---* ((c)A(b))s, S ---* (A(d))s, S ~ (B)s}, 4\] \[0, 1, {(c)A(b), A(d), g(b)}, 2, 3\] 
\[ . . .  \] \[0, 3, {S ---* ((c)A(b))s, S ---* (A(d))s, S ---* (B)s}, 4\] \[0, 1, {(c)m(b), A(d), A(b)}, 2, 3\] \[2, 2, {b}, 3, 3\] 
\[ . . .  \] \[0, 3, {S ~ ((c)A(b))s, S ---* (A(d))s, S ---* (B)s}, 4\] \[0, 1, {(c)A(b), A(d), A(b)}, 2, 3\] \[2, b, 3\] 
\[ . . .  \] \[0, 3, {S-+ ((c)A(b))s, S ---* (g(d))s,  S ---* (B)s}, 4\] \[0, 1, {(c)A(b), m(b)}, 3\] 
\[ . . .  \] \[0, 3, {S --~ ((c)A(b))s, S ~ (A(d))s, S ~ (B)s}, 4\] \[0, 1, {(c)A(b), A(b)}, 3\] \[0, 0, {c}, 1, 1\] 
\[-1, {S' --* .L(S)}, 0, 4\] \[0, 3, {S --* ((c)A(b))s, S --~ (A(d))s, S ---* (B)s}, 4\] \[0, 1, {(c)A(b), A(b)}, 3\] \[0, c, 1\] 
\[-1, {S' --~ J-(S)}, 0, 4\] \[0, 3, {S ~ ((c)A(b))s, S ---* (A(d))s, S --* (B)s}, 4\] \[0, (c)A(b), 3\] 
\[-  1, {S' --* _L(S) }, O, 41 \[0, S --* ((c)A(b))s, 4\] 
\[-1, {S' --* ?(S)}, O, 4\] \[0,0, {S},4,4\] 
\[-1, {5" ~ J_(S)}, O, 4\] \[0,S,4\] 
\ [ -  l, S' --, _L(S), 4\] 
I Clause 
3a 
la 
3b 
la 
ld 
7b 
2a 
la, ld 
4a 
3b 
la, ld 
5b 
5b 
7a 
la, ld 
5a 
Figure 1: Generalized HI parsing 
3a \[k,Q, rn,j\]~-, \[k,Q,m,j\]\[rn, p -  1,Q',p,j\] 
where there is p such that m < p _< j and Q' - 
golo(righl(Q), ap) is not empty 
35 \[i,k,Q,m\]~--* \ [ i ,k ,Q,m\] \ [ i ,p-  1, Q',p,k\] 
where there is p such that i < p < k and Q' = 
goto(iefl(Q), ap) is not empty 
4a \[ i ,k,Q,m,j\]\[k',7, m' \]~-. \[i,k,Q',m'\] 
provided m = k', where Q' = gotoright(Q, 7) 
4b Symmetric to 4a (of. 2a and 2b) 
5a \[k, Q, m, j\]\[k', 7, m'\] *--* \[k, t, rn'\] 
provided m = k ~, where t E 9otoright(Q, 7) 
5b Symmetric to 5a (cf. 3a and 3b) 
6a \[i, k, Q, m, j\]\[k', A ---* 7, rn'\] ~-~ 
\[i, k, Q, m, j\]\[m, k', Q', m', j\] 
provided m < k', where Q' = goto(right(Q), A) 
6b Symmetric to 6a 
7a \[k,Q,m,j\]\[k',A---*7, m'\]~--* 
\[k, Q, m, j\]\[m, k', O', m', j\] 
provided rn _< k', where Q' = goto(righl(Q), A) 
7b Symmetric to 7a 
The algorithm above is based on the transformation 
rhead. It is therefore not surprising that this algorithm 
is reminiscent of LR parsing \[1\] for a transformed gram- 
mar rt~oo(G). For most clauses, a rough correspondence 
with actions of LR parsing can be found: Clauses 2 
and 3 correspond with shifts. Clause 5 corresponds 
with reductions with rules of the form \[Xa\] ---, X \[a\] 
in rtwo(G). Clauses 6 and 7 correspond with reduc- 
tions with rules of the form A --* X \[a\] in rtwo(G). For 
Clauses 1 and 4, corresponding actions are hard to find, 
since these clauses seem to be specific to generalized 
head-driven parsing. 
The reason that we based Algorithm 6 on rheaa is 
twofold. Firstly, the algorithm above is more appro- 
priate for presentational purposes than an alternative 
algorithm we have in mind which is not based on "/'head , 
and secondly, the resulting parsers need less sets Q. 
This is similar in the case of LR parsing. 5
Example  1 Consider the generalized head grammar 
with the following rules: 
S --~ ((c)A(b))s \](A(d))s I (B)s 
A ~ a 
B -~ A(b) 
Assume the input is given by ala2a3a4 = c a b s. The 
steps performed by the algorithm are given in Figure 1. 
\[\] 
Apart from HI parsing, also TD, tIC, PHI, and EHI 
parsing can be adapted to generalized head-driven pars- 
ing. 
Cor rectness  
The head-driven stack automata studied so far differ 
from one another in their degree of nondeterminism. 
In this section we take a different perspective. For all 
these devices, we show that quite similar relations ex- 
ist between stack contents and the way input strings 
are visited. Correctness results easily follow from such 
characterisations. (Proofs of statements in this section 
are omitted for reasons of space.) 
Let G = (N, T, P, S) be a head grammar. To be used 
below, we introduce a special kind of derivation. 
sit is interesting to compare LR parsing for a context-free 
grammar G with LR parsing for the transformed grammar 
rtwo(G). The transformation has the effect that a reduc- 
tion with a rule is replaced by a cascade of reductions with 
smaller ules; apart from this, the transformation does not 
affect the global run-time behaviour of LR parsing. More 
serious are the consequences for the size of the parser: the 
required number of LR states for the transformed grammar 
is smaller \[9\]. 
215 
PS 
~2 
~3,0 X3,1 ~3,1 X3,2 ~3,2 X3,3 ~3,3 
Figure 2: A head-outward sentential form derived by 
the composition of a-derivations Pi, 1 < i < 3. The 
starting place of each a-derivation is indicated, each 
triangle representing the application of a single produc- 
tion. 
Def in i t ion  1 A a-derivation has the fo rm 
A p~p2...p~-~ 70B71 
P. ---+ 70ar/flV1 
p 
"-+ "/0 cl~z/~71 , (1) 
where Pl,P2 . . . .  ,Ps are productions in p t ,  s > 1, Pi 
rewrites the unique nonterminai  occurrence introduced 
as the head element of pi-1 for  2 < i < S, p, = (B  
c~)  and p E P* rewrites t1 into z E T +. 
The indicated occurrence of string 7/in (1) is called the 
handle of the a-derivation. When defined, the right- 
most (leftmost) nonterminal occurrence in a (/~, re- 
spectively) is said to be adjacent to the handle. The 
notions of handle and adjacent nonterminal occurrence 
extend in an obvious way to derivations of the form 
CA0 L ?70Z710 , where A :--, 70z71 is a a-derivation. 
By composing a-derivations, we can now define the 
class of sentential forms we are interested in. (Figure 2 
shows a case example.) 
Def in i t ion  2 A head-outward sentential  fo rm is ob- 
tained through a derivation 
Pl  S ---, 71,0zl,t71,1 
P2 
----+ "f2,0 X 2,1.),2,1X 2,2 ~,2,2 
Pq 
Vq,OT.q,lVq,lXq,2Vq,2"''\[q,q-lZq,qVq, q (2) 
where q > 1, each Pi is a a-derivation and, for  2 < i < 
q, only one string 7i- l , j  is rewritten by applying Pi at a 
nonterminal occurrence adjacent to the handle of pi-1. 
Sequence P l ,p~, . . . ,pq  is said to derive the sentential 
form in (2). 
The definition of head-outward sentential form sug- 
gests a corresponding notion of head-outward deriva- 
tion. Informally, a head-outward derivation proceeds by 
recursively expanding to a terminal string first the head 
of a rule, and then the remaining members of the rhs, 
in an outward order? Conversely, we have head-inward 
(HI)  derivations, where first the remaining members 
in the rhs are expanded, in an inward order (toward 
the head), after which the head itself is recursively ex- 
panded. Note that HI parsing recognizes a string by 
computing an HI derivation in reverse (of. Lit parsing). 
Let w = axa2 ? . -an, n > 1, be a string over T and let 
a0 = .1_. For -1  < i < j < n, we write ( i , j \ ] , ,  to denote 
substring ai+ l ? ? ? aj . 
Theorem 1 For A one of Anc ,  A PH1 or A EH~, the 
following facts are equivalent: 
(i) A reaches a configuration whose stack contents are 
I l  I~ . . . lq, q > 1, with 
It = \[ it ,kt,  At ---+ at * Ot * f i t ,mt , j t \ ]  or 
h = \ [ i t , k t ,A t  ---+ ~h,mt, j t \ ]  or 
It = \[ it ,kt,  At  ~ ~?t,mt,jt\] 
fo r  the respective automata, I < t < q; 
(it) a sequence of a-derivations Pl, P2 , . . . ,  Pq, q >_ 1, de- 
rives a head-outward sentential  fo rm 
"/'0 (k~r(1), mr(1)\]w71(k.(2), rn~(2)\]wY2 ? ? ? 
? " "Tq-1 (kTr(q), m~r(q)\]w~/q 
where lr is a permutation of {1 . . . .  ,q}, Pt has han- 
dle ~?t which derives (kTr(t),m~r(t)\]w, I < t < q, and 
m~(t -1 )  < kTr(t), 2 < t < q. 
As an example, an accepting stack configuration 
\ [ -1 , -1 ,S  l ---* ? IS  . ,n ,n \ ]  corresponds to a a- 
derivation (S' ---+ IS )p ,  p E P+, with handle 
_I_S which derives the head-outward sentential form 
70(-1, n\]~71 = _l_w, from which the correctness of the 
head-corner algorithm follows directly. 
If we assume that G does not contain any useless ym- 
bols, then Theorem 1 has the following consequence, if
the automaton at some point has consulted the sym- 
bols a i l ,a i2 , . . . ,a im from the input string, il . . . . .  im 
increasing indexes, then there is a string in the language 
generated by G of the form voai~vl . . . vm_ la i ,~vm.  
Such a statement may be called correct subsequence 
property (a generalization of correct prefix property \[8\]). 
Note that the order in which the input symbols are con- 
sulted is only implicit in Theorem 1 (the permutation 
7r) but is severely restricted by the definition of head- 
outward sentential form. A more careful characterisa- 
tion can be obtained, but will take us outside of the 
scope of this paper. 
The correct subsequence property is enforced by the 
(top-down) predictive feature of the automata, and 
holds also for A TD and A HI. Characterisations simi- 
lar to Theorem 1 can be provided for these devices. We 
investigate below the GHI automaton. 
For an item I E 1 GUt of the form \ [ i , k ,Q ,m, j \ ] ,  
\[k, Q, m, j\], It, k, Q, m\] or \[k, t, m\], we say that k (m 
respectively) is its left (right) component. Let N ~ be 
216 
the set of nonterminals of the head grammar head(G). 
We need a function yld from reachable items in I am 
into (N' tO T)*, specified as follows. If we assume 
that (cQX(fl) E Qv  A ~ (t~)X(/3) E Q and t = 
(a)X(/3) V t = A --* (a)X(~3), then 
X if / = \[i, k, Q, m, j\] 
yld(I) = \[a\]X i f I=  \[k,Q,m,j\] 
X\[fl\] if I = \[i, k, Q, m\] 
\[a\]X\[fl\] if I = \[k, t, m\] 
It is not difficult to show that the definition of yld is 
consistent (i.e. the particular choice of a tree or rule 
from Q is irrelevant). 
Theorem 2 The following facts are equivalent: 
(i) A cHl reaches a configuration whose stack contents 
are Il I~ . . . Iq, q > 1, with kt and mt the left and right 
components, respectively, of It, and yld(It) = Yt, for 
l<t<q;  
(it) a sequence of tr-derivations Pl,P2,.. . ,Pq, q > 1, de- 
rives in rh~aa(G) a head-outward sentential form 
7o(k~r(1), m,r(1)\]w"Y1 (k r (2 ) ,  mr (2) \ ]w72 ? ? ? 
" ' "  7q -  1 (k~-(q), m~(q)\]w')'q 
where ~r is a permutation of {1,. . . ,q}, Pt has han- 
dle tit which derives (k~(t),m,~(t)\]w, 1 < t < q, and 
rex(t-l) <_ kx(t), 2 < t < q. 
Discussion 
We have presented a family of head-driven algorithms: 
TD, I/C, Pill, EHI, and HI parsing. The existence of 
this family demonstrates that head-driven parsing cov- 
ers a range of parsing algorithms wider than commonly 
thought. 
The algorithms in this family are increasingly deter- 
ministic, which means that the search trees have a de- 
creasing size, and therefore simple realizations, uch as 
backtracking, are increasingly eff?cient. 
However, similar to the left-to-right case, this does 
not necessarily hold for tabular realizations of these al- 
gorithms. The reason is that the more refined an al- 
gorithm is, the more items represent computation of 
a single subderivation, and therefore some subderiva- 
tions may be computed more than once. This is called 
redundancy. Redundancy has been investigated for the 
left-to-right case in \[8\], which solves this problem for 
ELR parsing. Head-driven algorithms have an addi- 
tional source of redundancy, which has been solved for 
tabular I-IC parsing in \[14\]. The idea from \[14\] can also 
be applied to the other head-driven algorithms from 
this paper. 
We have further proposed a generalization of head- 
driven parsing, and we have shown an example of 
such an algorithm based on LR parsing. Prospects to 
even further generalize the ideas from this paper seem 
promising. 
Re ferences  
\[1\] A.V. Aho, R. Sethi, and J.D. Ullman. Compil- 
ers: Principles, Techniques, and Tools. Addison- 
Wesley, 1986. 
\[2\] G. Bouma and G. van Noord. Head-driven parsing 
for lexicalist grammars: Experimental results. In 
Sixth Conference of the European Chapter of the 
ACL, pages 71-80, April 1993. 
\[3\] G. Gazdar, E. Klein, G. Pullum, and I. Sag. Gen- 
eralized Phrase Structure Grammar. Harvard Uni- 
versity Press, Cambridge, MA, 1985. 
\[4\] Third International Workshop on Parsing Tech- 
nologies ( IWPT 3), Tilburg (The Netherlands) and 
Durbuy (Belgium), August 1993. 
\[5\] R. Jackendoff. X-bar Syntax: A Study of Phrase 
Structure. The MIT Press, Cambridge, MA, 1977. 
\[6\] M. Kay. I/ead-driven parsing. In International 
Parsing Workshop '89, pages 52-62, Pittsburgh, 
1989. 
\[7\] R. Leermakers. How to cover a grammar. In 27th 
Annual Meeting of the ACL, pages 135-142, June 
1989. 
\[8\] M.J. Nederhof. An optimal tabular parsing algo- 
rithm. In this proceedings. 
\[9\] M.J. Nederhof and J.J. Sarbo. Increasing the ap- 
plicability of LR parsing. In \[4\], pages 187-201. 
\[10\] G. van Noord. Reversibility in Natural Language 
Processing. PhD thesis, University of Utrecht, 
1993. 
\[11\] C. Pollard and I. Sag. Information-Based Syntax 
and Semantics, volume 1: Fundamentals. CSLI 
Lecture Notes Series No. 13, Center for the Study 
of Language and Information, Stanford University, 
Stanford, California, 1987. 
\[12\] P.W. Purdom, Jr. and C.A. Brown. Parsing 
extended LR(k) grammars. Acta Informatica, 
15:115-127, 1981. 
\[13\] G. Satta and O. Stock. Head-driven bidirectional 
parsing: A tabular method. In International Pars- 
ing Workshop '89, pages 43-51, Pittsburgh, 1989. 
\[14\] K. Sikkel and R. op den Akker. Predictive head- 
corner chart parsing. In \[4\], pages 267-276. 
\[15\] E. Soisalon-Soininen and E. Ukkonen. A method 
for transforming grammars into LL(k) form. Acta 
Informatica, 12:339-369, 1979. 
\[16\] M. Tomita. Parsing 2-dimensional language. In 
M. Tomita, editor, Current Issues in Parsing Tech- 
nology, chapter 18, pages 277-289. Kluwer Aca- 
demic Publishers, 1991. 
217 
