Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010), pages 922?930,
Beijing, August 2010
An Exploration of Features for Recognizing Word Emotion
Changqin Quan
Faculty of Engineering
University of Tokushima
quan-c@is.tokushima-u.ac.jp
Fuji Ren
Faculty of Engineering
University of Tokushima
ren@is.tokushima-u.ac.jp
Abstract
Emotion words have been well used as the
most obvious choice as feature in the task
of textual emotion recognition and auto-
matic emotion lexicon construction. In
this work, we explore features for rec-
ognizing word emotion. Based on Ren-
CECps (an annotated emotion corpus) and
MaxEnt (Maximum entropy) model, sev-
eral contextual features and their com-
bination have been experimented. Then
PLSA (probabilistic latent semantic anal-
ysis) is used to get semantic feature by
clustering words and sentences. The ex-
perimental results demonstrate the effec-
tiveness of using semantic feature for
word emotion recognition. After that,
?word emotion components? is proposed
to describe the combined basic emotions
in a word. A significant performance
improvement over contextual and seman-
tic features was observed after adding
word emotion components as feature.
1 Introduction
Textual emotion analysis is becoming increas-
ingly important due to augmented communication
via computer mediated communication (CMC). A
possible application of textual emotion recogni-
tion is online chat system. An emotion feedback
system can recognize users? emotion and give ap-
propriate responses. Another application exam-
ple is weblog emotion recognition and prediction.
Blogspace consists of millions of users who main-
tain their online diaries, containing frequently-
updated views and personal remarks about a range
of issues. An emotion recognition and predic-
tion system can understand the public?s reaction to
some social issues and predict emotion changes. It
would be helpful for solving some psychological
problems or giving early warnings, such as suicide
or terrorism.
Textual emotion analysis also can improve
the accuracy of other nonverbal modalities like
speech or facial emotion recognition, and to im-
prove human computer interaction systems. How-
ever, automatic recognition of emotion meaning
from texts presents a great challenge. One of the
reasons is the manifoldness of expressed emotions
in words.
Emotion words have been well used as the
most obvious choice as feature in the task of tex-
tual emotion recognition and automatic emotion
lexicon construction (Virginia and Pablo, 2006;
Tokuhisa et al, 2008, etc.). And there are many
lexical resources developed for these tasks, such
as GI (Stone et al, 1966), WordNet-Affect (Strap-
parava and Valitutti, 2004), NTU Sentiment Dic-
tionary (Ku et al, 2006), Hownet (Dong and
Dong, 2003), SentiWordnet (Esuli and Sebastiani,
2006). In these sentimental or affective lexicons,
the words usually bear direct emotions or opin-
ions, such as happy or sad, good or bad. Al-
though they play a role in some applications, sev-
eral problems of emotion expression in words
have been ignored.
Firstly, there are a lot of sentences can evoke
emotions without direct emotion words. For ex-
ample,
(1) SU3?f??p!3?f?%
p"(Spring is in children?s eyes, and in their
hearts.)
In sentence (1), we may feel joy, love or expect
delivered by the writer. But there are no direct
emotion words can be found from lexicons. As
Ortony (1987) indicates, besides words directly
referring to emotion states (e.g., ?fear?, ?cheer-
ful?) and for which an appropriate lexicon would
help, there are words that act only as an indirect
922
reference to emotions depending on the context.
Strapparava et al (2006) also address this issue.
The authors believed that all words can potentially
convey affective meaning, and they distinguished
between words directly referring to emotion states
(direct affective words) and those having only an
indirect reference that depends on the context (in-
direct affective words).
The second problem is emotion ambiguity of
words. The same word in different contexts may
reflect different emotions. For example,
(2) ??8c???U?"(This is cur-
rently the only thing I can do.)
(3)?????"(He is my only one.)
In sentence (2), the word ??? (only)? may
express the emotion of anxiety or expect; but in
sentence (3), the word ??? (only)? may express
the emotion of love or expect. The emotion cat-
egories can not be determined without their cer-
tain contexts especially for the words with emo-
tion ambiguity.
In addition, some words can express multiple
emotions, such as ?U\ (mingled feelings
of joy and sorrow)?. Statistics on an annotated
emotion corpus (Ren-CECps 1, Chinese emotion
corpus developed by Ren-lab) showed that 84.9%
of all emotion words have one emotion, 15.1%
have more than one emotions (Quan and Ren,
2010). Multi-emotion words are indispensable for
expressing complex feelings in use of language.
In this work, we explore features for recogniz-
ing word emotion in sentences. Based on Ren-
CECps and MaxEnt model, several contextual
features and their combination have been exper-
imented. Then PLSA (probabilistic latent seman-
tic analysis) is used to get semantic feature by
clustering word and sentence. The experimental
results demonstrate the effectiveness of using se-
mantic feature for word emotion recognition. Af-
ter that, the notion of ?word emotion components?
is proposed to describe the combined basic emo-
tions in a word. A significant performance im-
provement over only using contextual and seman-
tic features was observed after adding word emo-
tion components as feature and output in MaxEnt
based model.
1http://a1-www.is.tokushima-u.ac.jp/member
/ren/Ren-CECps1.0/Ren-CECps1.0.html
This paper is organized as follows. In section 2,
based on Ren-CECps and MaxEnt, an exploration
of using contextual feature for Chinese word emo-
tion recognition is described. In section 3, using
PLSA technique, the performance of adding se-
mantic feature is presented. In section 4, the no-
tion of ?word emotion components? is proposed
and the performance of using encoding feature is
presented. In section 5, the discussions are de-
scribed. Section 6 is conclusions.
2 Chinese Word Emotion Recognition
2.1 Related Works
There are many researches concerning comput-
ing semantics of words, while the researches on
computing emotions of words are relatively less.
Computing word emotions is a challenge task be-
cause the inherent of emotion is ambiguous and
natural language is very rich in emotion termi-
nology. Using the textual emotion information,
several methods have been explored for comput-
ing lexical emotions. Wilson et al (2009) pro-
posed a two-step approach to classify word po-
larity out of context firstly, and then to clas-
sify word polarity in context with a wide vari-
ety of features. Strapparava et al (2007) im-
plemented a variation of Latent Semantic Anal-
ysis (LSA) to measure the similarities between di-
rect affective terms and generic terms. Lee and
Narayanan (2005) proposed a method of comput-
ing mutual information between a specific word
and emotion category to measure how much in-
formation a word provides about a given emo-
tion category (emotion salience). Based on struc-
tural similarity, Bhowmick (2008) computed the
structural similarity of words in WordNet to dis-
tinguish the emotion words from the non-emotion
words. Kazemzadeh (2008) measured similar-
ity between word and emotion category based on
interval type-2 fuzzy logic method. Takamura
(2005) used a spin model to extract emotion po-
larity of words.
Different from the above researches, in this
work, we explore which features are effective for
word emotion recognition. The features include
contextual feature, semantic feature and encoding
feature.
923
2.2 Ren-CECps and MaxEnt based Chinese
Word Emotion Recognition
Ren-CECps is constructed based on a relative
fine-grained annotation scheme, annotating emo-
tion in text at three levels: document, paragraph,
and sentence. The all dataset consisted of 1,487
blog articles published at sina blog, sciencenet
blog, etc. There are 11,255 paragraphs, 35,096
sentences, and 878,164 Chinese words contained
in this corpus (more details can be found in (Quan
and Ren, 2010)).
In the emotion word annotation scheme of Ren-
CECps, direct emotion words and indirect emo-
tion words in a sentence are all annotated. For
example, in sentence (1) /SU (spring)0and
/?f? (the children)0are labeled. An emo-
tion keyword or phrase is represented as a vec-
tor to record its intensities of the eight basic emo-
tion classes (expect, joy, love, surprise, anxiety,
sorrow, angry and hate). For instance, the emo-
tion vector for the word /SU (spring)0??w =
(0.1,0.3,0.3,0.0,0.0,0.0,0.0,0.0) indicates the
emotions of weak expect, joy and love. In this
work, we focus on if a word contains some emo-
tion(s) in a certain context. The analysis on emo-
tion intensity of emotion words is included in our
future work.
As word emotion is subjective entity, a word
in a certain context may evoke multiple emotions
in different people?s mind. A part of documents
in Ren-CECps have been annotated by three an-
notators independently to measure agreement on
the annotation of this corpus, which include 26
documents with a total of 805 sentences, 19,738
words. This part of corpus is used as testing cor-
pus to evaluate the experimental results. (Section
5.1 shows the analysis on the annotation agree-
ment on word emotion.)
MaxEnt modeling provides a framework for in-
tegrating information from many heterogeneous
information sources for classification (Manning,
1999). MaxEnt principle is a well used technique
provides probability of belongingness of a token
to a class. In word emotion recognition, the Max-
Ent estimation process produces a model in which
each feature fi is assigned a weight ?i. The de-
terministic model produces conditional probabil-
ity (Berger, 1996), see equation (1) and (2). In
experiments, we have used a Java based open-nlp
MaxEnt toolkit 2.
p(e|context) = 1Z(context) ?i ?
fi(context,e)
i (1)
Z(context) = ??
i
? fi(context,e)i (2)
2.3 Contextual Features
The contextual features used in MaxEnt for Chi-
nese word emotion recognition are described as
follows:
Word Feature (WF): Word itself to be recog-
nized.
N-words Feature (NF): To know the rela-
tionship between word emotion and its con-
text, the surrounding words of length n for the
word (wi) to be recognized are used as feature:
(wi?n...wi...wi+n).
POS Feature (POSF): The part of speech of
the current word and surrounding words are used
as feature. We have used a Chinese segmentation
and POS tagger (Ren-CMAS) developed by Ren-
lab, which has an accuracy about 97%. The set of
POS includes 35 classes.
Pre-N-words Emotion Feature (PNEF): The
emotions of the current word may be influenced
by the emotions of its previous words. So the
emotions of previous n words are used as feature.
The value of this feature for a word (wi) is ob-
tained only after the computation of the emotions
for its previous words.
Pre-is-degree-word Feature (PDF), Pre-
is-negative-word Feature (PNF), Pre-is-
conjunction Feature (PCF): To determine if
the previous word is a degree word, a negative
word, or a conjunction may be helpful to identify
word emotions. The degree word list (contains
1,039 words), negative word list (contains 645
words), and conjunction list (contains 297 words)
extracted from Ren-CECps have been used.
2.4 The Performance of Using Contextual
Feature
We use the documents in Ren-CECps that have
been annotated by three annotators independently
2http://maxent.sourceforge.net/
924
as testing corpus. An output of word emotion(s)
will be regarded as a correct result if it is in agree-
ment with any one item of word emotion(s) pro-
vided by the three annotators. The numbers of
training and testing corpus are shown in table 1.
The accuracies are measured by F-value.
Table 1: Number of training and testing corpus
Number Training Testing
Documents 1,450 26
Sentences 33,825 805
Words 813,507 19,738
Emotion words 99,571 2,271?
(*) At least agreed by two annotators.
Table 2 gives the results of F-value for differ-
ent contextual features in the MaxEnt based Chi-
nese word emotion recognition. The results of F-
value include: (a) recognize emotion and unemo-
tion words; (b) recognize the eight basic emotions
for emotion words (complete matching); (c) rec-
ognize the eight basic emotions for emotion words
(single emotion matching).
As shown in table 2, when we only use Word
Feature(WF), the F-value of task (a) achieved a
high value (96.3). However, the F-values of task
(b) and (c) are relative low, that means the prob-
lem of recognizing the eight basic emotions for
emotion words is a lot more difficult than the
problem of recognizing emotion and unemotion
words, so we focus on task (b) and (c).
When we experiment with Word Feature(WF)
and N-words Feature (NF), we have observed
that word feature (wi) and a window of previ-
ous and next word (wi?1,wi,wi+1) give the best
results (a=96.5, b=50.4, c=69.0). Compared
with (wi?1,wi,wi+1), a larger window of previous
and next two words (wi?2,wi?1,wi,wi+1,wi+2) re-
duces the F-value. This demonstrates that wi and
wi?1,wi,wi+1 are effective features for word emo-
tion recognition.
When POS Feature (POSF) is added, the F-
value is increased. Especially the F-value is in-
creased to (a=97.1, b=51.9, c=72.0) when posi
and posi?1, posi, posi+1 are added.
We also find that Pre-N-words Emotion Fea-
ture (PNEF) (pre e0, ..., pre ei?1) increases the F-
value, but previous one word emotion can not in-
creases the F-value.
As can be seen from table 2, when only con-
textual features are used, the highest F-value
is (a=97.1, b=53.0, c=72.7) when Pre-is-degree-
word Feature (PDF), Pre-is-negative-word Fea-
ture (PNF), Pre-is-conjunction Feature (PCF) are
added.
3 Semantic Feature
To know if semantic information is useful for
emotion recognition, we have used probabilis-
tic latent semantic analysis (PLSA) (Hofmann,
1999) to cluster words and sentences. PLSA clus-
ters documents based on the term-document co-
occurrence which results in semantic decomposi-
tion of the term-document matrix into a lower di-
mensional latent space. PLSA can be defined as:
P(s,w) = ?
z?Z
P(z)P(s|z)P(w|z) (3)
where p(s,w) is the probability of word w and
sentence s co-occurrence, P(s|z) is the probability
of a sentence given a semantic class z, and P(w|z)
is the probability of a word given a semantic class
z.
For word clustering, We made the assignment
based on the maximum p(z|w), if p(z? |w) = max
p(z|w), then w was assigned to z? . Sentence clus-
tering is similar to word clustering. Word clus-
tering and sentence clustering are run separately.
The word class id and sentence class id are used
as semantic feature (SF), which including sen-
tence class feature (SCF) and word class feature
(WCF). PeenAspect implementation of PLSA has
been used for our expriments 3.
Table 3 gives the results of F-value for com-
bined all contextual features and semantic fea-
ture in the MaxEnt based Chinese word emotion
recognition.
As can be seen from table 3, when SCF is used,
the best result is obtained when the cluster num-
ber is 100; when WCF is used, the best result is
obtained when the cluster number is 100 or 160.
The results demonstrate the effectiveness of using
SCF is a little higher than using WCF.
3http://www.cis.upenn.edu/datamining/software dist/
PennAspect/
925
Table 2: F-value for different contextual features in the MaxEnt based Chinese word emotion recogni-
tion
(a) recognize emotion or unemotion words
(b) recognize the eight basic emotions for emotion words (complete matching)
(c) recognize the eight basic emotions for emotion words (single emotion matching)
Feature Features F-value
type (a) (b) (c)
WF f 1 = wi 96.3 45.9 63.0
NF f 1 = wi?1,wi,wi+1 94.8 44.8 60.7
f 1 = wi?2,wi?1,wi,wi+1,wi+2 92.4 28.4 40.3
WF+NF f 1 = wi; f 2 = wi?1,wi,wi+1 96.5 50.4 69.0
WF+NF f 1 = wi f 2 = wi?1,wi,wi+1 f 3 = posi 96.8 51.5 71.1
+POSF f 1 = wi f 2 = wi?1,wi,wi+1 f 3 = posi?1, posi, posi+1 97.0 51.7 71.6
f 1 = wi f 2 = wi?1,wi,wi+1 f 3 = posi f 4 = posi?1, posi, posi+1 97.1 51.9 72.0
WF+NF
+POSF
f 1 = wi f 2 = wi?1,wi,wi+1 f 3 = posi
f 4 = posi?1, posi, posi+1 f 5 = pre ei?1 97.1 51.9 72.0
+PNEF f 1 = wi f 2 = wi?1,wi,wi+1 f 3 = posif 4 = posi?1, posi, posi+1 f 5 = pre e0, ..., pre ei?1 97.1 52.4 72.2
WF+NF
+POSF
+PNEF
+PDF
+PNF
+PCF
f 1 = wi f 2 = wi?1,wi,wi+1 f 3 = posi
f 4 = posi?1, posi, posi+1 f 5 = pre e0, ..., pre ei?1
f 6 =?(wi?1 is a degree word)
f 7 =?(wi?1 is a negative word)
f 8 =?(wi?1 is a con junction)
97.1 53.0 72.7
4 Encoding Feature: Emotion
Components of Word
Researches on the psychology of concepts show
that categories in the human mind are not sim-
ply sets with clearcut boundaries (Murphy, 2002;
Hampton, 2007). Word emotions are certainly re-
lated to mental concepts. As for emotion states,
most theorists appear to take a combinatorial view.
Plutchik (1962), for example, talks about ?mixed
states?, ?dyads? and ?triads? of primary emotions.
Similarly, Averill (1975) argues for compound
emotions based on more elementary ones. And
one model, suggested by Ekman (1982) (emotion
blends) and Plutchik (mixed states), is that emo-
tions mix (Ortony, 1988). According to these re-
searches, we use an encoding feature: emotion
components of word.
?Emotion components of word? describes the
combined basic emotions in a word, which is rep-
resented by eight binary digits, and each digit cor-
responding to a basic emotion class respectively.
For example, the word ?U? (like)?, its possi-
ble emotion components in a certain context is
?01100000?, which expresses the combined emo-
tions by joy and love.
With the expression of emotion components
of word, it is possible to distinguish direct emo-
tion words and indirect emotion words. Those
words always demonstrate similar emotion com-
ponents in different contexts can be regarded as
direct emotion words, accordingly, those words
demonstrate different emotion components in dif-
ferent contexts can be regarded as indirect emo-
tion words. With the expression of emotion com-
ponents in word, the problem of expressing emo-
tion ambiguity in words can be solved. The same
word in different contexts may reflect different
emotions, which can be expressed by different
emotion components. The emotions of words with
multiple emotions also can be expressed by emo-
tion components.
926
Table 3: F-value for combined contextual features
(CF) and semantic feature (SF) (including sen-
tence class feature (SCF) and word class feature
(WCF))
Feature Cluster F-value
type number (a) (b) (c)
CF+SCF 20 97.0 53.1 72.8
40 97.0 53.4 72.7
60 97.0 53.5 72.8
80 97.0 52.9 72.5
100 97.0 53.6 73.1
120 97.0 53.1 72.7
150 97.0 53.2 72.9
180 97.0 53.4 73.1
CF+WCF 40 97.0 53.1 72.8
100 97.0 53.4 72.9
160 97.0 53.4 72.9
220 97.0 53.3 72.9
280 97.0 53.2 72.8
370 97.0 53.1 72.8
The statistics of word emotion components in
Ren-CECps show that there are a total of 68 emo-
tion components in all of 22,095 annotated emo-
tion words without repetitions. Figure 1 shows the
growth curve of word emotion components num-
ber with emotion word number increase.
As can be seen from figure 1, the number in-
crease of word emotion components shows a very
slow growth rate with the number increase of
emotion words. We can conclude that the space
of word emotion components is a relatively small
space.
In the model of MaxEnt based Chinese word
emotion recognition, the Pre-N-words Emotion
Feature (PNEF) and emotion output can be en-
coded to emotion components.
Pre-N-words Emotion Components Feature
(PNECF): The emotion components of its previ-
ous words for a word (wi). The value of this fea-
ture is obtained only after the computation of the
emotion components for its previous words.
Table 4 gives the results of F-value for the com-
bined contextual features and encoding feature.
As can be seen in table 4, when Pre-N-words
Emotion Feature (PNEF) is replaced by Pre-N-
Figure 1: The growth curve of word emotion com-
ponents
words Emotion Components Feature (PNECF),
and emotion components are output as results, F-
value is increased up to (a=97.3, b=57.3, c=73.3).
Then based on this result, we firstly trained a word
emotion based model, then the word emotion out-
puts of this model are used as Pre-N-words Emo-
tion Feature (PNEF) for the word emotion com-
ponents based model. A significant F-value im-
provement of task (b) and (c) (b=62.5, c=73.7)
over only using contextual and semantic features
was observed after adding the combined word
emotion and word emotion components as feature.
5 Discussion
5.1 Word Emotion Agreement on People?s
Judgments
The final aim of a human-computer interaction
recognition system is to get the result close to peo-
ple?s judgments. As word emotion is inherently
uncertain and subjective, here we report the anno-
tation agreement on word emotion of Ren-CECps,
which can be taken as an evaluation criteria for a
algorithm.
To measure the annotation agreement of Ren-
CECps, three annotators independently annotated
26 documents with a total of 805 sentences,
19,738 words. We use the following two metrics
to measure agreement on word emotion annota-
tion.
(1) Kappa coefficient of agreement (Carletta,
1996). It is a statistic adopted by the computa-
927
Table 4: F-value for the combined contextual features and encoding feature
Feature type Features F-value
(a) (b) (c)
WF+NF+POSF+PNECF
+PDF+PNF+PCF
f 1 = wi f 2 = wi?1,wi,wi+1 f 3 = posi
f 4 = posi?1, posi, posi+1
f 5 = pre es0, ..., pre esi?1
f 6 =?(wi?1 is a degree word)
f 7 =?(wi?1 is a negative word)
f 8 =?(wi?1 is a con junction)
97.3 57.3 73.3
WF+NF+POSF+PNEF
+PNECF+PDF+PNF+PCF
f 1 = wi f 2 = wi?1,wi,wi+1 f 3 = posi
f 4 = posi?1, posi, posi+1
f 5 = pre e0, ..., pre ei?1
f 6 = pre es0, ..., pre esi?1
f 7 =?(wi?1 is a degree word)
f 8 =?(wi?1 is a negative word)
f 9 =?(wi?1 is a con junction)
97.3 62.5 73.7
tional linguistics community as a standard mea-
sure.
(2) Voting agreement. It is used to mea-
sure how much intersection there is between
the sets of word emotions identified by the
annotators. It includes majority-voting agree-
ment (AgreementMV ) and all-voting agreement
(AgreementAV ). AgreementMV is defined as fol-
lows. Let A, B and C be the sets of word emo-
tion components annotated by annotators a, b and
c respectively. The expert coder is the set of ex-
pressions that agreed by at least two annotators,
see equation (4).
AgreementMV = Avg(count(ti = e j)count(ti) ) (4)
In which, ti ? T , e j ? E, T = A?B?C, E =
(A?B)?(A?C)?(B?C).
Accordingly, the expert coder of AgreementAV
is the set of expressions that agreed by all annota-
tors.
The above two metrics are used to measure the
agreements on: (a) determine if a word is an emo-
tion or unemotion word; (b) determine the eight
basic emotions for emotion words (complete emo-
tion matching); (c) determine the eight basic emo-
tions for emotion words (single matching). (b)
and (c) are provided that at least two people to be-
lieve the word is an emotion word. Table 5 shows
the agreements measured by the two metrics.
As shown in table 5, it is easier for annotators to
agree at if a word contains emotion, but it is more
difficult to agree on emotions or emotion compo-
nents of a word. Compared with the agreement on
people?s judgments, our experiments gave promis-
ing results.
Table 5: Agreement of word emotion annotation
measured by Kappa, Majority-voting (MV), and
All-voting (AV)
Measure Kappa MV AV
(a) 84.3 98.5 95.1
(b) 66.7 70.3 26.2
(c) 77.5 100 84.9
5.2 Error Analysis
Conducting an error analysis, we find that a lot
of errors occur due to the recognition on multi-
emotion words and indirect emotion words, espe-
cially in short sentences because the features can
be extracted are too few. So more features should
be considered from larger contexts, such as the
topic emotion of paragraph or document.
There are some errors occur due to more than
one emotion holders exist in one sentence, for ex-
928
ample of sentence (4).
(4) ?uy?wX?a,?"(I
found that daughter was looking at the toys of her
interest.)
In sentence (4), three annotators all agree that
the emotion components of the word ?a, (in-
terest)? is ?00000000? since they believe that this
word is an unemotion word from the view of the
writer. But our system give a result of ?00100000?
because the emotion holder ?? (daughter)? of
the emotion word ?a, (interest)? has not been
considered in our algorithm. Therefore, the recog-
nition of emotion holder is indispensable for an
accurate emotion analysis system.
In addition, Chinese segmentation mistakes and
phrasing error also cause errors.
6 Conclusions
Automatically perceive the emotions from text
has potentially important applications in CMC
(computer-mediated communication) that range
from identifying emotions from online blogs to
enabling dynamically adaptive interfaces. Therein
words play important role in emotion expressions
of text.
In this paper we explored features for recogniz-
ing word emotions in sentences. Different from
previous researches on textual emotion recogni-
tion that based on affective lexicons, we believe
that besides obvious emotion words referring to
emotions, there are words can potentially convey
emotions act only as an indirect reference. Also,
quite often words that bear emotion ambiguity and
multiple emotions are difficult to be recognized
depending on emotion lexicons. Emotion of a
word should be determined with its context.
Based on Ren-CECps (an annotated emotion
corpus) and MaxEnt (Maximum entropy) model,
we have experimented several contextual features
and their combination, then using PLSA (proba-
bilistic latent semantic analysis), semantic feature
are demonstrated the effectiveness for word emo-
tion recognition. A significant performance im-
provement over only using contextual and seman-
tic features was observed after adding encoding
feature (word emotion components). Determining
intensity of word emotion and recognizing emo-
tion of sentence or document based on word emo-
tion are included in our future work.
Acknowledgments
This research has been partially supported by
Ministry of Education, Science, Sprots and Cul-
ture, Grant-in-Aid for Challenging Exploratory
Research, 21650030. We also wish to acknowl-
edge the anonymous reviewer?s insightful com-
ments and suggestions.
References
J. R. Averill. 1975. A semantic atlas of emotional con-
cepts. JSAS Catalog of Selected Documents in Psy-
chology.
Adam Berger, Vincent Della Pietra and Stephen A.
Della Pietra. 1996. A maximum entropy approach
to natural language processing. Computational Lin-
guistic 22(1), pages 39?71.
Plaban Kumar Bhowmick, Animesh Mukherjee, Aritra
Banik, Pabitra Mitra, Anupam Basu. 2008. A com-
parative study of the properties of emotional and
non-Emotional words in the Wordnet: A complex
network approach. In Proceedings of International
conference on natural language processing (ICON
2008).
Jean Carletta. 1996. Assessing agreement on classifica-
tion tasks: the Kappa statistic. Computational Lin-
guistics. 22(2): 249-254.
Z. Dong and Q. Dong. 2003. HowNet)a hybrid
language and knowledge resource. In Proceedings
of Int?l Conf. Natural Language Processing and
Knowledge Eng., pages 820?824.
Paul Ekman. 1982. Emotion in the human face. Cam-
bridge University Press.
Andrea Esuli and Fabrizio Sebastiani. 2006. Senti-
WordNet: A publicly available lexical resource for
opinion mining. In Proceedings of the Fifth Inter-
national Conference on Language Resources and
Evaluation (LREC 2006), pages 417-422.
James A. Hampton. 2007. Typicality, graded
membership, and vagueness. Cognitive Science
31:355?384.
Thomas Hofmann. 1999. Probabilistic latent semantic
analysis. In Proceedings of the Fifteenth Conference
on Uncertainty in Artificial Intelligence (UAI?99).
Abe Kazemzadeh, Sungbok Lee, and Shrikanth
Narayanan. 2008. An interval type-2 fuzzy logic
system to translate between emotion-related ocab-
ularies. In Proceedings of Interspeech.
929
Lun-Wei Ku, Yu-Ting Liang and Hsin-Hsi Chen. 2006.
Tagging heterogeneous evaluation corpora for opin-
ionated tasks. In Proceedings of Conference on
Language Resources and Evaluation (LREC 2006),
pages 667-670.
Chul Min Lee, Shrikanth S. Narayanan. 2005. Toward
detecting emotions in spoken dialogs. Journal of
the American Society for Information Science. IEEE
Trans. on Speech and Audio Processing 13(2):293-
303.
Christopher D. Manning and Hinrich Schjtze. 1999.
Foundations of statistical natural language process-
ing. Cambridge, MA: MIT Press.
Gregory L. Murphy. 2002. The Big Book of Concepts.
Cambridge, MA: MIT Press.
Andrew Ortony. Gerald l. Clore. Mark A. Foss. 1987.
The referential structure of the affective lexicon.
Cognitive Science 11:341-364.
Andrew Ortony, Gerald L. Clore, Allan Collins. 1988.
The Cognitive Structure of Emotions. Cambridge
University Press.
Robert Plutchik. 1962. The emotions: Facts, theories,
and a new model. New York: Random House.
Changqin Quan and Fuji Ren. 2010. A blog
emotion corpus for emotional expression analy-
sis in Chinese. Computer Speech & Language,
24(4):726?749.
Philip J. Stone, Dexter C. Dunphy, Marshall S. Smith,
and Daniel M. Ogilvie. 1966. The General Inquirer:
A computer approach to content analysis. The MIT
Press.
Carlo Strapparava and Alessandro Valitutti. 2004.
Wordnet-affect: an affective extension of word-
net. In Proceedings of the 4th International Con-
ference on Language Resources and Evaluation
(LREC 2004), pages 1083-1086.
Carlo Strapparava, Alessandro Valitutti, and Oliviero
Stock. 2006. The affective weight of lexicon. In Pro-
ceedings of the Fifth International Conference on
Language Resources and Evaluation (LREC 2006),
pages 423-426.
Carlo Strapparava, Alessandro Valitutti, Oliviero
Stock. 2007. Dances with words. In Proceed-
ings of the Twentieth International Joint Confer-
ence on Artificial Intelligence (IJCAI 2007), pages
1719?1724.
Hiroya Takamura, Takashi Inui, and Manabu Oku-
mura. Extracting emotional polarity of words using
spin model. 2005. In Proceedings of the 43rd An-
nual Meeting of the Association for Computational
Linguistics (ACL 2005), pages 133?140.
Ryoko Tokuhisa, Kentaro Inui, Yuji Matsumoto. 2008.
Emotion classification using massive examples ex-
tracted from the web. In Proceedings of the 22nd In-
ternational Conference on Computational Linguis-
tics (Coling 2008). pages 881?888.
Francisco Virginia and GervSs Pablo. 2006. Exploring
the compositionality of emotions in text: word emo-
tions, sentence emotions and sutomated Tagging. In
Proceedings of the AAAI-06 Workshop on Computa-
tional Aesthetics: Artificial Intelligence Approaches
to Beauty and Happiness, pages 16?20.
Theresa Wilson, Janyce Wiebe, and Paul Hoffmann.
2009. Recognizing Contextual Polarity: an explo-
ration of features for phrase-level sentiment analy-
sis. Computational Linguistics 35(3): 1?34.
930
