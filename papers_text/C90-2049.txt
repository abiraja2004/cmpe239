Dependency Analyzer: 
A Knowledge-Based Approach to Structural Disambiguation 
Katashi  Nagao 
IBM Research, Tokyo Research Laboratory  
5--19 Sanbancho, Chiyoda-ku,  Tokyo 102, Japan 
E-mail:  nagao@jpntscvm.bitnet  
Abstract 
To resolve structural ambiguities in syntactic analysis of 
natural anguage, which are caused by prepositional phrase 
attachment, relative clause attachment, and so on, we de- 
veloped an experimental system called tile Dependency An- 
al!lzcr. The system uses instances of dependency structures 
extracted froth a terminology dictionary as a knowledge 
ba.~e. Structural (attachment) ambiguity is represented 
by showing that a word has several words as c;tndidate 
modiliees. Tim system resolves uch ambiguity as follows. 
First, it searches the knowledge base for modification re- 
lationships (dependencies) between the word and each of 
its possible modifiees, then assigns an order of preference 
to these relationships, and finally seieets the most prefer- 
able deper.dency. The knowledge base can be constructed 
semi-automatically, since the source of knowledge xists in 
the form of texts, and these sentences can be analyzed by 
the parser and transformed into dependency structures by 
the system. We are realizing knowledge bootstrapping by 
adding the outputs of the system to its knowledge base. 
1 Introduction 
The bottleneck of sentence analysis, structural ambi- 
guity, occurs when a sentence has several alternatives 
for modifier-modifiee relationships (dependencies) between 
words or phrases. This kind of ambiguity cannot be re- 
solved merely by applying grammatical knowledge: there 
is a need for semantic processing. Resolution of struc- 
tural ambiguities eems to be a problem of selecting the 
most preferable dependency from several candidates by us- 
ing large-scale knowledge on dependencies among words. 
There are two problems in realizing practical semantic pro- 
cessing: one is that knowledge must be large-scale, and 
must be constructed automatically or semi-automatically; 
the other is that the mechanism for utilizing knowledge, 
inference, must be efficient or tractable. We developed a
system called the Dependency Analyzer that resolves these 
problems. 
The Dependency Analyzer is a systenl fl)r structural dis- 
ambignation. One of its characteristics is that it selects 
the most preferabledependency by using a knowledge base 
containing terminological knowledge in the form of depen- 
dency trees. The knowledge base can be constructed semi- 
automatically, as described in Section 2. The inputs of 
this system are parse trees, which are outputs of the PEG 
parser, a broad coverage English parser \[5\]. The system 
translates the phrase structures into dependency strut- 
282 
tures that explicitly represent modifier-modifiee r lation- 
ships between words. The main processes of the system 
are executed if attachment ambiguities are included in the 
phrase structures. In the dependency structures, attach- 
ment ambiguities are represented by showing that some 
words have several candidate modiliees. From these de- 
pe.ndency structures, several candidate dependencies are 
extracted. The system decides which of these should be 
adopted by using background knowledge an,l context. The 
decision is made via tim mechanisms of path search and 
distance calculation. A precise description of path search is 
given in Section 3. An explanation of distance calculation 
is given in Section 4. Another problem for disambigua- 
tion, namely interaction (or constraints) between attach- 
ment ambiguities, is discussed in Section 5. 
2 Knowledge Base 
The knowledge must be large=scale, since natural anguage 
semantics hould have a broad coverage of lexical items. 
Since dependency structures are built by analyzing sen- 
tences and by tra:nsforming phr~e structures in a straight- 
forward way, if knowledge is assumed to consist of depen- 
dency structures, a knowledge base is easily constructed 
by using already-existing on-line dictionaries. This idea 
of using on-line dictionary definitions as a knowledge base 
was originally proposed by Karen Jensen and Jean-Louis 
Binot \[6\]. Jun-ichi Nakamura nd Makoto Nagao \[101 eval- 
uated tile automatic extraction of semantic relationships 
between words from the on-line dictionary. We emphasize 
that a data structure for representing knowledge should be 
as simple as possible, because it must be easy to construct 
and efficient. 
We selected the tree structure as a means of representing 
knowledge, because it is a very simple and manageable 
data structure, and because tree structures are suitable 
for describing dependency structures. 
Tile tree structure is defined as follows. A Tree consists 
of a Node and reeursions (or null) of Tree, and a Node con- 
sists of repetitions of a paired attribute name and u.ttribute 
value. 
For example, Figure 1 shows a tree (dependency) strnc- 
ture for the clause "the operating system stores the files in 
the disk." In this tree, "WORD," "POS (part of speech)," 
and "CASE" are att,qbute names, and "store," "VERB," 
and "AGENT" are attribute values. 
In our system, the knowledge can be extracted fi:om dic- 
tionaries of terminology, and is of two types: (1) depen- 
dency structures and (2) synonym and taxonym relation- 
( ((WORD . "store") (POS . VERB)) 
(((WORD . "operat ing system") 
(CASE . AGENT) (POS . NOUN))) 
(((WORD . "fi le") (CASE , PATIENT) 
(POS . NOUN)))  
(((WORD . "disk") (CASE . LOCATION) 
(POS . NOUN))) ) 
Table h Tree Index Table 
d synonym and taxonyra trees 
to(O)-qo(o) t~2(0) 
tsO) t~(o) tea(o) 
t~(0) t ~(0) tn (1)  
t s0)  t25(1) t82(o) 
dependency trees 
tlol(O 1) tlso(1 O) 
tu (1)  tr io(t)  
tlOl(1 1) t350(0 2 3) 
tas(1 O) tllo(1 1 O) 
lqgure h Tree structure for the clause "the operating sys- 
tem stores the files in the disk" 
ships. 
The process of knowledge xtraction is as follows. First, 
dictionary statements are rewritten manually as simple 
:~entences. Next, sentences are parsed into phrase strue- 
tm'es by tile PEG parser. Then. phrase structures are 
transformed into dependency structm'es by the Depen- 
de'nc:q Str~zctu're Builder, which is a component of tile De- 
pendency Analyzer. Finally, sernantie case markers are 
manually added to the modification links in dependency 
.structures. Synonym and taxollym relationships are ex- 
tracted from sentences of the form "X is a synonynt for 
Y" and "X is a Y" respectively. These sentences are au- 
tomatically transformed into tree structures each of which 
has two nodes R)r tile words "X" and "Y" and a link from 
"X" to "Y" with the label "isa." In the case of "X is a 
synonym for Y," since "Y" is also a synonym for "X," "Y'" 
is connected with "X" at the same time by a link with the 
label "isa.'" \Ve developed an interactive tree management 
tool, the Tree Editor. which makes it easy for users to deal 
with trees. 
Another problem of natural language processiug is the 
knowledge acquisition bottleneck. Some ideas on how to 
a.cquire knowledge fi'om a!ready-existing dictionaries auto- 
matically or semi-automatically haw~ be.en proposed \[10,41. 
But it is still difficult to develop a knowledge base hilly au- 
tomatically because of ambiguities in the natural language 
analysis of dictionary definitions. A more practical way, to 
overcome the t)otthmeck is so-called kno'wledge bootstrap- 
tn'a~.\]. By knowledge bootstrapping, the Dependency Ana- 
lyzer extends its knowledge automatically by using a eor'e 
knowledge base that includes mammllv edited dependency 
.~;truetures. Since the De.pendency Analyzer uses depen- 
dency structures as knowledge and outputs a dependency 
structure with no ambiguity (case ambiguity is also re- 
solved by the system), tile output can be added to the 
knowledge base. Of course we still need to evaluate the 
automatically constructed knowledge base. But the relia- 
bility (performance) of the knowledge base is rising grad- 
ua\[ly, so it is expected that human interw,ntion wilI be 
greatly reduced in the near future. 
"t Path  Search  An  Et I ic ient  A lgo -  
r i thm 
Path search is a process for finding relationships between 
the words in a candidate dependency by using a knowledge 
base. Since relationships between words in these candi- 
dates do not always exist in the knowledge base, relation- 
/ \  
(3 (o) ( ?O (2) 
t .5  (2 1 0) 
Figm'e 2: Tree and Node Location 
ships between synonyms and taxouyms of these words eau 
also /)e targets. Path search is done ill the following steps: 
1. Synonyms and t~u,:onyms of words in the candidate 
dependencies are found by using the knowledge base. 
In the knowledge base, synonym and taxonym rela- 
tionships are also defined in the form of trees. All the 
synonyms and taxonyms can be collected by transiting 
relationships. 
2. Dependencies between elements of each synonym and 
taxonym set (including the original words) are also 
found by using the knowledge base. 
We developed an efficient algorithm for path search, us- 
ing the table of indices shown in Table 1. In this table, t~, 
represents the pointer of the tree in which the word on the 
same line appears, and the numbers in parentheses repre- 
sent the node location of the word in the tree. Relation- 
ships between the numbers amt the node are shown in Fig- 
ure 2. The left side of tile table shows trees in which a syn- 
onym or a taxonym of the word on the same line appears as 
its parent node. For example, in the tree to, the word a is 
on the node of location (0), and by traversing to up by one 
node fl'om location (0) we can find that the word b is on the 
node of location (), so b is a synonym or a taxonym of a, as 
shown in Figure 3. Thus, in order to find a synonym or a 
taxonym of a word, we just traverse up tile tree on the left 
side of the table by one node. We assume that synonym 
and taxonym relationships are transitive, that is. that a 
synonym/taxonym of one of the synonyms/taxonyms of a 
word is also a synonym/taxonym of the word itself. We can 
to ~ b 
l synonym/tmxonym (isa) 
a 
Figure 3: Synonym/Taxonym Tree 
283 
tl. tO 0 /0~ 
/ b 
d 
"keep" .~,.. 
"VM/SP . . . .  information" / 
"virtual disk" 
Figure 6: Ambiguous Dependency Structure 
Figure 4: Dependency Tree 
~110 ~ O~ 
to ~ b 
q.,, -. d 
A 
C 
Figure 5: Path 
collect all its synonyms/taxonyms by iteration of that pro- 
cess. The next stage of path search is to find whether there 
are dependencies between words within each set of syn- 
onyms/taxonyms. This process searches trees that involve 
both words and checks whether there is a path from one 
word to the other. In the dependency trees, the words' lo- 
cations show whether there is a dependency between them. 
For example, we can see that tile word b is a dominator 
of the word d frmn the locations of these words in the 
emnmou tree tH0 (shown in Figure 4), which is included in 
both the set of dependency trees that include b. {ttl, ttl0}, 
and that of dependency trees that include d, {tas, t110}. In 
the tree structures, if the node a is an ancestor of the node 
b, then there is a unique path front b to a. Thus, finding 
dependency between words is equivalent o checking their 
node locations in the dependency trees. A path between 
words wl and w2 is found by the following processes: 
1. The synonym/taxonym sets of these words, S~,~ and 
S~,  are collected. 
"keep" 
I on 
"virtual disk" 
Figure 7: Candidate Dependency 
4 D is tance  Ca lcu la t ion  - A Heur i s t i c  
P rocess  for  Se lec t ion  o f  the  Most  
Preferable Dependency 
Several conditions are added to path.s, and the ch)seness 
of dependevcy in a path is computed according to these 
conditions. The degree of closeness of dependenc.y is called 
the dependency distance. This is calculated by using the 
number of dependencies inclnded in a path and the values 
of the conditions. Three conditions are used to calculate 
the dependency distartce: 
I. Case consistency 
For example, in the sentence "VM/SP kceps the infor- 
mation on the virtual disk," there is a prepositional 
phrase attachment ambiguity, as shown in Figure 6. If 
the path shown in Figure 8 is found together with the 
candidate dependency shown in Figure 7, then tile se- 
mantic case of the path's dependency between "store" 
and "disk" must be consistent with the grammatical 
case of the sentence's dependency between "keep" and 
"virtual disk." lIere, the case consistency between 
the sentence and the path holds, since the grammat- 
ical case "on" call have the role of the semantic case 
"location." If this consistency holds, then the value of 
case consistency is 1; otherwise, it is 0. 
2. Co-occurrence consistency 
This is the consistency between the other modifiers of 
the modifiee of tile candidate dependency, called the 
co-occurrent modifiers, and those of a path. 
2. The common trees tz . . .  that involve both elenmnts, 
ei 6 Swl and ej ~ Sw2, of each set are found. 
3. Tile node locations of ei and ej in t~. . .  are checked. 
For example, a path between the words a and c is shown 
in Figure 5. 
"store" 
"keep . . . .  disk" 
l i sa  
"virtual disk" 
Figure 8: Path 
284 
3. 
"keep" 
"VM/SP" '~virtual disk" 
Figure 9: Co-Occurrence 
"operating system" "file . . . .  disk" 
Figure 10: Dependency Tree 
In tile example sentence, for instance, there is a co- 
occurrent modifier "VM/SP"  of the candidate depen- 
dency between "keep" and "virtual disk," as shown in 
Figure 9. In this case, "VM/SP"  has the grammatical 
case subject. On the other hand, if the path is given by 
the dependency tree shown in Figure 10, then there is 
also a eo-oceurrent modilicr "operating systenf' that 
has the semantic ease of agent. In addition, there is a 
tmxonym relationship between "VM/SP"  and "oper- 
ating system" in the knowledge base, as shown in Fig- 
ure \].I. In this case, the co-occurrence consistency be- 
tween "VM/SP"  and "operating systenf' holds, since 
there is a relationship between the words and both 
case,; are consistent (the grammatical case subject call 
have a semantic case agent), as shown in Figure 12. 
The vahm of co-occurrence consistency is tile num- 
ber of co-oceurrent modifiers that are consistent be- 
tween the path and the sentence. Here, the value is 
1, since only one co-oecurrent modifier "VM/SP"  is 
consistent. 
Context consistency 
Context consistency holds if dependencies in a path 
already exist in previous sentences. For example, if 
the sentence "the data is stored in the storage device" 
comes before tile above sentence, then the dependency 
structure shown in Figure 13 is in the context base in 
which the dependency structures of previous entences 
are stored. Then the other path (shown in Figure 14), 
which corresponds to the dependency between "store" 
and "disk" in the "path," is found by using the con- 
text base. Thus the dependency between "store" and 
"disk" is defined by the context. The vahn', of context 
consistmmy is the number of dependencies in the path 
that are. defined by tile context. In this case, the wflue 
"operating system" 
l isa 
"VM/SP" 
Figure lh  Taxonym Relationship 
agent location 
"operating system" ~ "store" .i .... "disk" 
subject on 
"VM/SP" " * "keep" ~ "virtual disk" 
Figure 12: Diagram of Co-Occurrence Consistency 
"store" 
St--> 
"data . . . .  storage device" 
Figure 13: Dependency Tree in tile Context Base 
is 1, since there is one dependency in the pa& and it 
is de.fined in the context. 
The dependency distance is computed from the following 
formula: 
Distance = \[Depl + ~c'o,,, x (n -  1) 
(t~, ..... + 1) x (l@oo~ + 1) ' 
where \]Dep\] represents the number of dependencies in- 
cluded in the palh, i"c ..... is the value of case consistency, 
1 ~'oo~. is that of co-occurrence cm~sistency, and l'C,o,,t is that 
of context consistency. 
This formula assumes that case and co-occurrence consis- 
tency affect the distance of the whole path, but that context 
consistency affects the distance of each dependency in the 
path. 
n is a real number in tile range 0 < n < 1; it is a heuristic 
parameter that represents the degree of unimportance of 
context consistency. 
The dependency distance between "keep" and "virtual 
disk" that is calculated by using the path in the example is 
0.125, because the number of depenttencies is 1, the value 
of case consistency is 1, that of co-occurrence consistency 
is 1, and that of context consistency is 1 (n is defined 
0.5). 
The ambiguity of an attachment is resolved by selecting 
the candidate dependency that is separated by the shortest 
distance. 
"store" -..< 
storage device 
"disk" 
Figure 14: Path of Context 
285 
Table 2: Constraint Tables 
Constraint Table T5.6 Constraint Table 7~5,7 Cons~r~dnt Table T6.r 
tl'~ 0 I l I 0 1 ~ 
6/7 3 6 
1 0 1 
3k~__~l_L2 o V3 f l  i 212o0 \[5 ~ 1 
0 Ic~0 I m I1 2 ~  m 
,o ):% _'7_'7 
,0 / ,Q /~ "-- , / 7 
~\0~,~) I 
~O/{3,s} 
Figure 15: Ambigu,ms Dependency Slructure 
5 P lann ing ,  Const ra in t  P ropagat ion ,  
and  Process  o f  D isambiguat ion  
When there are several attachment ambiguities in one 
sentence, the relationships of each pair of ambiguities are 
represented by a constraint network \[91. The idea that am- 
Mguous syntactic structures can be represented by a data 
structure of constraint network was originally developed 
by Hiroshi Maruyama \[7 t. A constraint network consists 
of constraint ables. 
For example, the constraint ables shown in Table 2 
are constructed from tile ambiguous dependency structure 
shown in Figure 15. In this dependency structure, words 
5, 6, and 7 have attachment ambiguities, o their possi- 
ble modifiees are {1,3}, {1,5}, and {3,6} respectively. The 
constraint table is a two-dimensional matrix that repre- 
sents the. possibility of simultaneous modification of two 
ambiguous attachments. The rows and columns of the ma- 
trix show the candidate modifiees of each modifier, and an 
element in the matrix means the possibility (1 or 0) that 
both dependencies can exist simultaneously. For example, 
constraint table T5.7 indicates that if word 5 modifies word 
1, then word 7 cannot modify word 3 because of the rule 
of no-crossing. 
By using the constraint tables, the system decides which 
ambiguity should be resolved first. This process is called 
planning. In the above example, words 5, 6, and 7 have two 
candidate modifiees each. But from the constraint tables, 
we can see that if word 7 modifies word 3, then words 5 and 
6 cannot modify word 1. Thus, in this case, the ambiguity 
concerning the modification of word 7 should be resolved 
first. The algorithm for plauning consists of the following 
steps: 
1. On each row of the constraint table Ti.j, sum up the 
element values (Ai in Table 2), and subtract he sum 
from the size of the row (Bi). Then sum up the results 
on all rows (Ci). The result is the value of merit of 
286 
the ambiguity of word i. 
2. Do the same in each cohmm. The result is the value 
of merit of the ambiguity of word j. 
3. In all the constraint tables, sum up all the values of 
merit of each ambiguity, and divide each of these val- 
ues by the number of their candidate modifiees. 
4. The expected values of meTit of all ambiguities are 
given by the above process. Select the ambiguity that 
has the highest expected value. 
When an ambiguity is resolved, the system updates the 
constraint ables by tile filtering algorithm called con- 
straint propagation. We apply Mohr and Henderson's AC- 
4 algorithm \[8\] for constraint propagation. We reduce the 
computational cost of disambiguation by using planning 
and constraint propagation. 
Structural disambiguation f a sentence is done as fol- 
lows. The PEG parser tmrses a sentence and constructs its 
phrase structure. The Dependency Stracturc Builder trans- 
httes the phrase structure int.o the dependency strm:ture, 
and constructs the constraint tables when the phrase struc- 
ture contains ew~ral structural ambiguities. The Plan- 
ner, which is the component for planning, gives the Dis- 
ambiguator the information on an ambiguous dependency 
and its candidate modifiees. The Disambiguator decides 
which modifiee is the most preferable by doing path search 
and distance calculation. After resolving one ambiguous 
attachment, it calls the constraint propagation routine to 
filter the other ambiguities' candidates. After filtering, the 
Transformer t ansforms the dependency structure into one 
that has correc t dependencies forall resolved attachments. 
These processes are iterated until no ambiguity remains. 
6 Re la ted  Work  
There are several approaches to structural disambigua- 
tion, including resolution of prepositional phrase attach- 
ment. Wilks et al \[12\] discussed some strategies for dis- 
ambiguation based on preference semantics. Our frame- 
work is closely related to their ideas. While their strate- 
gies need hand-coded semantic formulas called preplates 
to decide preferences, our system can construct depen- 
dency knowledge semi-automatically. Dahlgren and Mc- 
Dowell \[2\] proposed another preference strategy for prepo- 
sitional phrase disambiguation. It is based on ontological 
knowledge, which is manually constructed. Whereas this 
framework (and also that of Wilks et al) was aimed at dis- 
ambiguating single prepositional phrases in sentences, our 
approach can handle the attachments of multiple preposi- 
tional phrases in sentences, ttirst \[3\] developed a mech- 
anism for structural disambiguation, called the Semantic 
Enquiry Desk, which is based on Chraniak's marker pass- 
ing paradigm \[1\]. Our path Search is partially equivalent 
to marker passing. While marker passing involves a high 
computational cost and finds ninny meaningless relations, 
our path search is restricted and finds only paths that in- 
elude synonym/taxonym relationships and dependencies. 
Our system can reduce the computational cost by using a 
limited knowledge search. Jensen and Binot \[6\] developed 
a heuristic method of prepositional phrase disambiguation 
usinp, on-line dictionary definitions. Our approach is sire-- 
liar t,o theirs in the sense that both use dictiouaries as 
knowledge sources. The differences are in tile ways in 
which dictionary definitions are used. While their method 
sear{:hes for knowledge by phrasal pattern matching and 
calculates certainty factors by complex procedures, ours 
uses knowledge it: a simt)le and efficient way, searching 
tree:: and traversing nodes, and calculates t)referenees by 
afe, w simplified processes. Wernlter \[11\] t)rop{}sed a e:}n- 
neeliol:ist approach to 8lrllctllra.\[ disan:biguation f noun 
phrases. He integrated syntaclic and semantic onslraints 
on lhe relaxation etwork. ~el:laI:tic {2OllS'{l'ailltS ol: prepo-  
s i t ional  reh:tionshil)s betweetl words are learned by a back- 
l}ro\]}agation algorithm. Learned semantics is often very 
t:seful for natural language processing, when sexnantic re- 
htti,mshit)s cannot be represented explicitly. \\2: represm:t 
semantic relationships between words by explicit relation- 
ship chains, al:d therefore do not need learning by back- 
propagation. We integrate sem.mti{: preferences and syn- 
tactic eonstrailllS t}y using e(mstraint t}ropagathm. }n:t it 
is a sequential {:o::ue{'tion a d does not allow their iilterac-. 
ti{m. \\k! are thii:king of desigIfinp a frau:ework that deals 
wilh both syntactic and semanli{: constraints simultam'- 
ousty. 
7 Concluding Remarks 
We deveh)ped the DepeT~dcrtcy Anal:/zer to re:olve struc- 
tural ambiguity by sen:antic processing. It aims t<~ over- 
come two serious problems in realizing pr:'a'tical semantic 
pr,~,cessing: : en::@u'::nm:ie conslru{tion of knowledge 
and efficient use nf that knowledge. The key ideas, path. 
.sea~'ch and distance calcuiatiora, ~~e.re shown to be feasible. 
\Ve now have a knowledge base constructed by using 
defi:,.itions giver~ in the "IBM Dictionary of Computing/' 
which inch:des about 20.009 instance.s ofdependency :true- 
turc'.s, h: addilion, we evaluated the system by disan:- 
biguat.ing the prepositional phrase attachment of about 
2,0()0 sentence.':. The results were as follows: (1) :he num- 
ber of arzflJiguou:-; prepositio::al phrases wa> 4.290, (2) the 
numbe, of correctly (lisanfi}iguat.ed a'~ta{:hm{'n:s was 3,569, 
and (3) the success ratio of disambiguatio:: was 83.2%. 
Further enhancement plans arc listed be.low: 
,, ~,?~'. are exploring the formalization of dependency dis- 
tar, ce with reference to graph theory. I)epe.ndeney dis- 
tMlee is aSsl lnled to be a score lbr the (:OIlSistel~cy of a 
dependency with tim background knowledge and con- 
text. The background knowledge and context are rep- 
resented as trees (special ca.~es of graphs), and c(msis- 
tency might be defined by a degree of matching be- 
tween trees. 
,L. We are planning to enhance tile system for other prob- 
lems such as adverb attachment and scope of eonj'unc- 
tion.s. To resolve general struetmal ambiguity prob- 
lems, we must design a general ambiguity-packed syn- 
tactic strncture, since the system can deal wilh locally 
packed ambiguities. 
Acknowledgements 
i would like to thank members of the IBM Tokyo Re- 
search Laboratory, Karen Jensen of the IBM Thomas J. 
Watson Research Ceqter, and tile reviewers for their vain- 
able comments on a draft of this paper, Hiroshi Nomiyama 
for his help in implementing tile system, Mizuho Tanaka, 
~%hko Kobayashi, Mitsuyo Sadohara, and Xbmoko Uehida 
for their kind support it: constructing the knowledge base 
and evaluating the system, and Michael McDonakl for his 
helpful adviee on the wordi\[:g of this paper. 
References  
\[1\] Charniak, E., "A Neat Theory of Marker Pressing," 
Procec.dirzgs of AAAI-86, 584-588, 1986. 
\[2\] Dahlgren. K. and McDowe!l, J., "Using Commonsense 
Km~wledge to Disambiguate Prepositional Phr~u~e Xiod- 
ifiers," Proceedin.q.s of A.4A\[-a< 589-593, !986. 
\[3\] tlirst, G., Scmanlic hlterpre.t,Ltion and Zhe Rc.s,)hLtio.n 
of A'mbiguity, Cambridge University Press, 1!357. 
\[.1\] Jacob:, P. and Zernik. U., "Acquiring Lexical K'aowl- 
edge from Text: A Case Study," Proceedings (;f AAAL  
88, 739-7-1.1, 988. 
\[5\] Jensen, K., HeMorn, G.E., Richardson, S.D., and Haas, 
N., "PLNLP, PEG, and CRYI'IQUE: Th,'ee Contribn- 
tions to Computing in the Humanities." IBM Research 
Report, EC 11841. 1986. 
\[6\] Jensen, K. and Binot J-L., "Disambiguating Prep(> 
sitional Phrase Attachments by Using On-Line Dictio- 
nary Definitions," Coraputational Ling'u?stics~ 13:251- 
260, 1987. 
\[7\] Maruyama, H., "Structural Disambiguation with Con- 
strain~, Propagation," Proceedings o/ ~l~e 28th Annual 
Meeting of the A CL, 1990. 
\[8\] Mohr, E. and Henderson, T.. "Are and Path Con- 
siste.ney IIevisited." Artificial Intelligence, 28:225-233. 
1986. 
\[9\] Montanari, U., "Networks of Constraints: Fundamen- 
tal Properties and Applications to Picture Processing," 
Inf~imation Sciences, 7:95-132, 1974. 
\[10\] Nakamura, J. and Nagao, M., "Extraction of Seman- 
tic information from an Ordinary English Dictionary 
and its Evaluation." Proceedings of COLING-88. 459- 
46,1, 1!)88. 
\[ll\] Wermter, S., "Integration of Semantic and Syntac- 
tic Constraints for Structural Noun Phrase t)isambigua- 
tion," P'roceedirLgs of IJCA\[-89, 1-186-1491, 989. 
\[i\[2\] Wilks, Y., Huang, X., and Fass, D., "Syntax, Preflu- 
ence and Right Attachment," Proceedings of I.ICAL85, 
779 78.1, \]!)85. 
287 
