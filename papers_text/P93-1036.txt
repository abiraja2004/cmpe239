A Competition-Ba sed Explanation of Syntactic Attachment 
Preferences and Garden Path Phenomena 
Suzanne Stevenson  
Depar tment  of  Computer  Sc ience 
Un ivers i ty  of  Toronto  
Toronto ,  Ontar io  MSS 1A4 Canada 
suzanne@cs . to ronto .edu  
Abst ract  
This paper presents a massively parallel parser that pre- 
dicts critical attachment behaviors of the human sentence 
processor, without he use of explicit preference heuristics 
or revision strategies. The processing of a syntactic am- 
biguity is modeled as an active, distributed competition 
among the potential attachments for a phrase. Computa- 
tionally motivated constraints on the competitive mecha- 
nism provide a principled and uniform account of a range 
of human attachment preferences and garden path phe- 
no lnena .  
1 A Compet i t ion -Based  Parser  
A model of the human parser must explain, among 
other factors, the following two aspects of the pro- 
cessing of a syntactic ambiguity: the initial attach- 
ment preferences that people exhibit, and their abil- 
ity or inability to later revise an incorrect attachment. 
This paper presents a competition-based parser, CA- 
PERS, that predicts critical attachment behaviors of 
the human sentence processor, without the use of ex- 
plicit preference heuristics or revision strategies. CA- 
PERS is a massively parallel network of processing 
nodes that represent syntactic phrases and their at- 
tachments within a parse tree. A syntactic ambi- 
guity leads to a network of alternative attachments 
that compete in parallel for numeric activation; an at- 
tachment wins over its competitors when it amasses 
activation above a certain threshold. The competi- 
tion among attachments i achieved solely through 
a technique called competition-based spreading ac- 
tivation (CBSA) (Reggia 87). The effective use of 
CBSA requires restrictions on the syntactic attach- 
ments that are allowed to compete simultaneously. 
Ensuring these network restrictions necessitates the 
further constraint hat a stable state of the network 
can only represent a single valid parse state. The re- 
sulting network structure defines a limited set of corn- 
peting attachments hat simultaneously define the ini- 
tial attachments for the current input phrase, along 
with the reanalysis possibilities for phrases previously 
structured within the parse tree. 
The competitive mechanism and its ensuing restric- 
tions have profound consequences for the modeling of 
the human sentence processor. Whereas other mod- 
els must impose explicit conditions on the parser's 
attachment behavior (Abney 89; Gibson 91; McRoy 
& Hirst 90; Pritchett 88), in CAPERS both initial 
attachment preferences and reanalyzability are a side 
effect of independently motivated computational s- 
sumptions. Furthermore, parsing models generally 
employ two different computational mechanisms in 
determining syntactic attachments: a general parser 
to establish the attachment possibilities, and addi- 
tional strategies for choosing among them (Abney 89; 
Frazier 78; Gibson 91; McRoy & Hirst 90; Shieber 
83). By contrast, CAPERS provides a more restric- 
tive account, in which a single competitive mechanism 
imposes constraints on the parser that determine the 
potential attachments, as well as choosing the pre- 
ferred attachment from among those. 
The competitive mechanism of CAPERS also leads 
to an advantageous integration of serialism and paral- 
lelism. In order to conform to human memory limita- 
tions, other parallel models must be augmented with 
a scheme for reducing the number of structures that 
are maintained (Gibson 91; Gorrell 87). Such pruning 
schemes are unnecessary in CAPERS, since inherent 
properties of the competitive mechanism lead to a re- 
striction to maintain a single parse state. However, 
in spite of this serial aspect, CAPERS is not a sim- 
ple serial model. The network incorporates each in- 
put phrase through a parallel atomic operation that 
determines both the initial attachment for the cur- 
rent phrase and any revision of earlier attachments. 
Thus, CAPERS avoids the problems of purely serial 
or race-based models that rely on backtracking, which 
is cognitively implausible, or explicit revision strate- 
266 
gies, which can be unrestrictive (Abney 89; Frazier 
78; Inoue & Fodor 92; McRoy & Hirst 90; Pritchett 
88). 
Other work (Stevenson 93b, 90) describes the de- 
tailed motivation for the CAPERS model, its expla- 
nation of serial and parallel effects in human parsing, 
and its predictions of a broad range of human attach- 
ment preferences. This paper focuses on the competi- 
tive mechanism described above. Section 2 briefly de- 
scribes the implementation f the parser) Section 3 
discusses the constraints on the network structure, 
and Section 4 demonstrates the consequences ofthese 
constraints for the processing of attachment ambigui- 
ties. Section 5 summarizes how the competitive mech- 
anism provides a principled and uniform account of 
the example human attachment preferences and gar- 
den path phenomena. 
2 The  Pars ing  Network  
CAPERS dynamically creates the parsing network by 
allocating processing nodes in response to the input. 
Control of the parse is distributed among these nodes, 
which make attachment decisions olely on the basis 
of the local communication f simple symbolic fea- 
tures and numeric activation. The symbolic informa- 
tion determines the grammaticality of potential at- 
tachments, while numeric activation weighs the rela- 
tive strengths of the valid alternatives. The spread- 
ing activation process allows the network to gradually 
settle on a set of winning attachments hat form a 
globally consistent parse tree. 
Building the Network 
When an input token is read, the parser activates a set 
of phrasal nodes, or p-nodes, from a pool of X tem- 
plates; their symbolic features are initialized based 
on the input token's lexical entry. Figure 1 shows a 
sample X template and its instantiation. Syntactic 
phrases are only allocated in response to explicit evi- 
dence in the input; top-down hypothesizing of phrases 
is disallowed because it greatly increases the complex- 
ity of the network. Next, the parser allocates process- 
ing nodes to represent the potential attachments be- 
tween the current input phrase and the existing parse 
tree. Attachment nodes, or a-nodes, are established 
between potential sisters in the parse tree; each a- 
node connects to exactly two p-nodes, as shown in 
Figure 2. (In all figures, a-nodes are shown as squares, 
which are black when the a-node is fully activated.) 
Once the current phrase is connected to the existing 
network, each processing node iteratively updates its 
l CAPERS is implemented in Conunoa Lisp, serially simu- 
lating the parallel processing of the network. 
~ has Case: 
has_category :  
selects_categ ory: 
assignsCase: 
ass igns jheta :  
selects category: 
~ has Oase:"none" has_category: V setects_category: "none" assigns_Case; Acc 
assigns_theta: theme 
selects_category: (N I C) 
expect 
Figure 1: An X template and sample instantiation. 
Figure 2: (a) The basic configuration of a phrase in 
X theory. (b) Representation f these attachments a
sister relations in CAPERS. 
symbolic features and numeric activation, and out- 
puts them to its neighbors. This network processing 
loop continues until the activation level of each a-node 
is either above a certain threshold O, or is zero. 2 The 
set of active a-nodes in this stable state represents he 
current parse tree structure. At this point, the next 
input token is read and the proeess is repeated. 
Grammaticality of Attachments 
Unlike other connectionist parsers (Cottrell 89; Fanty 
85; Selman & Hirst 85), CAPERS is a hybrid model 
whose limited symbolic processing abilities support 
the direct representation f the grammar of a cur- 
rent linguistic theory. In Government-Binding theory 
(GB) (Chomsky 81, 86; Rizzi 90), the validity of syn- 
tactic structures i achieved by locally satisfying the 
grammatical constraints among neighboring syntac- 
tic phrases. CAPERS directly encodes this formula- 
tion of linguistic knowledge as a set of simultaneous 
local constraints. Symbolic features are simple at- 
tribute/value pairs, with the attributes corresponding 
to grammatical entities uch as Case and theta roles. 
The values that these attributes can assume are taken 
from a pre-defined list of atoms. GB constraints are 
implemented as equality tests on the values of cer- 
tain attributes. For example, the Case Filter in (;B 
states that every NP argument must receive Case. In 
CAPERS, this is stated as a condition that the at- 
tribute Case must receive a value when the attribute 
Category equals Noun and the attribute IsArgument 
equals True. 
An a-node receives symbolic features from its p- 
2The network always stabifizes in less than 100 iterations. 
267 
expect to 
Sara 
Figure 3: The NP can attach as a sister to the V or the 
I'. The attachment to the V has a higher grammatical 
state value, and thus a higher initial activation level. 
nodes, which are used to determine the grammatical-  
ity of the attachment. If  an a-node receives incom- 
patible features from its two p-nodes, then it is an in- 
valid attachment and it becomes inactive. Otherwise, 
it tests the equality conditions that were developed 
to encode the following subset of GB constraints: the 
Theta Criterion, the Case Filter, categorial selection, 
and the binding of traces. The algorithm outputs a 
numeric representation of the degree to which these 
grammatical constraints are satisfied; this state value 
is used in determining the a-node's activation level. 
Choos ing  Pre fer red  At tachments  
Multiple grammatical attachments may exist for a 
phrase, as in Figure 3. The network's task is to focus 
activation onto a subset of the grammatical attach- 
ments that form a consistent parse tree for the input 
processed thus far. Attachment alternatives must be 
made to effectively compete with each other for nu- 
meric activation, in order to ensure that some a-nodes 
become highly activated and others have their activa- 
tion suppressed. There are two techniques for pro- 
ducing competitive behavior in a connectionist net- 
work. The traditional method is to insert inhibitory 
links between pairs of competing nodes. Competition- 
based spreading activation (CBSA) is a newer tech- 
nique that achieves competitive behavior indirectly: 
competing nodes vie for output from a common neigh- 
bor, which allocates its activation between the com- 
petitors. In a CBSA function, the output of a node is 
based on the activation levels of its neighbors, as in 
equation 1. 
aj 
? (1 )  Oji = 
ak 
k 
where: 
oji is the output from node ni to node nj; 
ai is the activation of node hi; 
k ranges over all nodes connected to node hi. 
For reasons of space ei-liciency, flexibility, and cogni- 
tive plausibility (Reggia et al 88), CBSA was adopted 
as the means for producing competitive behavior 
among the a-nodes in CAPERS. Each p-node uses a 
CBSA function to allocate output activation among 
its a-nodes, proportional to their current activation 
level. For example, the NP node in Figure 3 will send 
more of its output to the attachment to the V node 
than to the I' node. The CBSA function is designed 
so that in a stable state of the network, each p-node 
activates a number of a-nodes in accordance with its 
grammatical properties. Since every XP must have a 
parent in the parse tree, all XP nodes must activate 
exactly one a-node. An X or X ~ node must activate 
a number of a-nodes equal to the number of comple- 
ments or specifiers, respectively, that it licenses. The 
a-nodes enforce consistency among the p-nodes' indi- 
vidual attachment decisions: each a-node numerically 
ANDs together the input from its two p-nodes to en- 
sure that they agree to activate the attachment. 
A p-node that has obligatory attachments must at 
all times activate the appropriate number of a-nodes 
in order for the network to stabilize. However, since 
the phrase(s) that the p-node will attach to may oc- 
cur later in the input, the parser needs a way to rep- 
resent a "null" attachment to act as a placeholder 
for the p-node's eventual sister(s). For this purpose, 
the model uses processing nodes called phi-nodes to 
represent a "dummy" phrase in the tree. 3 Every X 
and X' node has an a-node that connects to a phi- 
node, allowing the possibility of a null attachment. A
phi-node communicates default symbolic information 
to its a-node, with two side effects. The a-node is 
always grammatical ly valid, and therefore represents 
a default attachment for the p-node it connects to. 
But, the default information does not fully satisfy the 
grammatical constraints of the a-node, thereby lower- 
ing its activation level and making it a less preferred 
attachment alternative. 
3 Rest r i c t ions  on  the  Network  
The competitive mechanism presented thus far is in- 
complete. If all possible attachments are established 
between the current phrase and the existing network, 
CBSA cannot ensure that the set of active a-nodes 
forms a consistent parse tree. CBSA can weed out 
locally incompatible a-nodes by requiring that each 
p-node activate the grammatical ly appropriate num- 
ber of a-nodes, but it cannot rule out the simulta- 
neous activation of certain incompatible attachments 
that are farther apart in the tree. Figure 4 shows the 
types of structures in which CBSA is an insufficient 
3 Ph i -nodes also represent the traces of displaced phrases ill 
the parse tree; see (Stevenson 93a, 93b). 
268 
Figure 4: Example pairs of incompatible attachments 
that CBSA alone cannot prevent from being active 
simultaneously. 
competitive mechanism. Both cases involve violations 
of the proper nesting structure of a parse tree. Since 
CBSA cannot rule out these invalid structures, the 
parsing network must be restricted to prevent hese 
attachment configurations. The parser could insert 
inhibitory links between all pairs of incompatible a- 
nodes, but this increases the complexity of the net- 
work dramatically. The decision was made to instead 
reduce the size and connectedness of the network, si- 
multaneously solving the tree structuring problems, 
by only allowing attachments between the current 
phrase and the right edge of the existing parse tree. 
Limiting the attachment of the current phrase to 
the right edge of the parse tree rules out all of the 
problematic ases represented by Figure 4(a). In- 
terestingly, the restriction leads to a solution for the 
cases of Figure 4(b) as well. Since there is no global 
controller, each syntactic phrase that is activated 
must be connected to the existing network so that 
it can participate in the parse. However, sometimes 
a phrase cannot attach to the existing parse tree; for 
example, a subject in English attaches to an inflec- 
tion phrase (IP) that follows it. The network con- 
nections between these unattached phrases must be 
maintained as a stack; this ensures that the current 
phrase can only establish attachments to the right 
edge of an immediately preceding subtree. The stack 
mechanism in CAPERS is implemented as shown in 
Figure 5: a phrase pushes itself onto the stack when 
its XP node activates an a-node between it and a spe- 
cially designated stack node. Because the stack can- 
not satisfy grammatical constraints, stack node at- 
tachments are only activated if no other attachment 
is available for the XP. The flexibility of CBSA al- 
lows the stack to activate more than one a-node, so 
that multiple phrases can be pushed onto it. The sur- 
prising result is that, by having the stack establish a- 
nodes that compete for activation like normal attach- 
ments, the indirect competitive relationships within 
the network effectively suppress all inconsistent at- 
tachment possibilities, including those of Figure 4(b). 
This result relies on the fact that any incompatible 
a-nodes that are created either directly or indirectly 
stack 
of 
partial 
parse trees 
.... ::t 
y ~treeon 
(x3 top of stack 
Figure 5: The stack is implemented as a degenerate 
p-node that can activate attachments o XP nodes. 
current 
a 1 phase 
of 
Figure 6: Attachments al-a4 were previously acti- 
vated. To attach the current phrase to the tree on 
the stack, the following must occur: exactly one of the 
prior attachments, al, must become inactive, and the 
corresponding pair of attachments, pi, must become 
active. This relationship holds for a tree of arbitrary 
depth on the stack. 
compete with each other through CBSA. To guaran- 
tee this condition, all inactive a-nodes must be deleted 
after the network settles on the attachments for each 
phrase. Otherwise, losing a-nodes could become acti- 
vated later in the parse, when the network is no longer 
in a configuration in which they compete with their 
incompatible alternatives. Since losing a-nodes are 
deleted, CAPERS maintains only a single valid parse 
state at any time. 
The use of CBSA, and the adoption of a stack mech- 
anism to support this, strongly restrict the attach- 
ments that can be considered by the parser. The only 
a-nodes that can compete simultaneously are those 
in the set of attachments between the current phrase 
and the tree on top of the stack. The competitive 
269 
current 
s t a c k ~  
(~ past (~/  al V Sara 
expect 
Figure 7: The network after attaching the NP Sara. 
current 
top/ expect ( 
( ) 
Sara 
Figure 8: A-nodes a2 and a 3 define the necessary at- 
tachments for the current phrase. 
relationships among the allowed a-nodes completely 
define the sets of a-nodes that can be simultaneously 
active in a stable state of the network. These logi- 
cal attachment possibilities, shown in Figure 6, fol- 
low directly from the propagation of local competi- 
tions among the a-nodes due to CBSA. In over 98% 
of the approximately 1400 simulations of attachment 
decisions in CAPERS, the network stabilized on one 
of these attachment sets (Stevenson 93b). The com- 
petitive mechanism of CAPERS thus determines a
circumscribed set of attachment possibilities for both 
initial and revised attachments in the parser. 
4 Pars ing  At tachment  Ambigu i t ies  
This section demonstrates the processing of CAPERS 
on example attachment ambiguities from the sentence 
processing literature. 4 In sentence (1), the parser is 
4 A more complete presentation of CAPERS' explanation of 
expect 
,op/ 
2;  
Sara 
Figure 9: The misattachment of the NP to the V has 
been revised. 
faced with a noun phrase/sentential complement am- 
biguity at the post-verbal NP Sara: 
(1) Mary expected Sara to leave. 
People show a Minimal Attachment preference to at- 
tach the NP as the complement of the verb, but have 
no conscious difficulty in processing the continuation 
of the sentence (Frazier & Rayner 82; Gorrell 87). 
The CAPERS network after attaching Sara is shown 
in Figure 7. 5 The NP has valid attachments to the 
stack (a0) and to the V (al). Since the default stack 
attachment is less competitive, a-node al is highly 
activated. This initial attachment accounts for the 
observed Minimal Attachment preferences. Next, the 
word to projects an IP; its initial connections to the 
network are shown in Figure 8. 6 The same set of a- 
nodes that define the initial attachment possibilities 
for the current IP phrase, a2 and a3, simultaneously 
define the revised attachment necessary for the NP 
Sara. A-node al competes with a2 and a3 for the ac- 
tivation from the V and NP nodes, respectively; this 
competition draws activation away from al. When 
the network stabilizes, a2 and a3 are highly active 
and al has become inactive, resulting in the tree of 
Figure 9. In a single atomic operation, the network 
these and related psycholinguistic data can be found in (Steven- 
son 93b). 
5Note that a tensed verb such as expected projects a full 
sentential s t ructure- - that  is, CP/\[P/VP--as in (Abney 86), 
although the figures here are simplified by onfitting display of 
the CP of root clauses. 
6In tlfis and the remaining figures, grannnatically invalid 
a-nodes and irrelevant phi-nodes are not shown. 
270 
t:!~c k~ ~ ph:r=n: 
Kiva 
eat 
Figure 10: The NP food has a single valid attachment 
to the parse tree. 
has revised its earlier attachment hypothesis for the 
NP and incorporated the new IP phrase into the parse 
tree. 
Sentence (2), an example of Late Closure effects, is 
initially processed in a similar fashion: 
(2) When Kiva eats food gets thrown. 
After attaching food, the network has the configura- 
tion shown in Figure 10. As in sentence (1), the post- 
verbal NP makes the best attachment available to it, 
as the complement of the verb. This behavior is again 
consistent with the initial preferences of the human 
sentence processor (Frazier ~ Rayner 82). Since the 
initial attachment in these cases of Late Closure is de- 
termined in exactly the same manner as the Minimal 
Attachment cases illustrated by sentence (1), these 
two classic preferences receive a uniform account in 
the CAPERS model. 
Additional processing of the input distinguishes the 
sentence types. At gets, a sentential phrase is pro- 
jected, and the network settles on the attachments 
shown in Figure 11. As in Figure 8, the revision nec- 
essary for a valid parse involves the current phrase 
and the right edge of the tree. However, in this case, 
the misattached NP cannot break its attachment to 
the verb and reattach as the specifier of the IP. The 
difference from the prior example is that here the V 
node has no other a-node to redirect its output to, and 
so it continues to activate the NP attachment. The 
attachment of the NP to the I ~ is not strong enough 
by itself to draw activation away from the attachment 
of the NP to the V. The current I' thus activates the 
default phi-node attachment, leading to a clause with 
current 
phrase ? 
When 
present 
present 
Kiva 
eat 
,:0/ 
stack 
food 
Figure 11: The attachment of the NP food to the V 
is not strong enough to break the attachment of the 
NP to the V. 
an empty (and unbound) subject. Since the network 
settles on an irrecoverably ungrammatical nalysis, 
CAPERS correctly predicts a garden path. 
The next two examples, adapted from (Pritchett 
88), involve double object verbs; both types of sen- 
tences clearly garden path the human sentence pro- 
cessor. In each case, the second post-verbal NP is 
the focus of attention. In sentence (3), this NP is the 
subject of a relative clause modifying the first NP, 
but the parser misinterprets it as the verb's second 
complement: 
(3) Jamie gave the child the dog bit a bandaid. 
The initial Connections of the NP the dog to the net- 
work are shown in Figure 12. The NP can either push 
itself onto the stack, or replace the null attachment 
of the verb to the phi-node. Since both stack attach- 
ments and phi-node attachments are relatively weak, 
the NP attachment to the V wins the a-node competi- 
tion, and the network settles on the tree in Figure 13. 
In accordance with human preferences, the NP is at- 
tached as the second object of the verb. When bit 
is processed, the network settles on the configuration 
in Figure 14. As in the earlier examples, the misat- 
tached NP needs to attach as the subject of the cur- 
rent clause; however, this would leave the V node with 
only one a-node to activate instead of its required two 
attachments. CAPERS again settles on an ungram- 
matical analysis in which the current clause has an 
271 
;cUrra~:t 
J I / /  th~ Jamie ~ = ~  
/ 0,w=  
top / . . .<~== .j.. 
the child 
Figure 12: The initial connections of the NP the dog 
to the network. 
the child the 
Figure 13: The NP the dog attaches as the verb's 
second complement. 
empty (unbound) subject, consistent with the garden 
path effect of this sentence. 
The second example with a double object verb in- 
volves the opposite problem. In sentence (4), the sec- 
ond post-verbal NP is mistakenly interpreted as part 
of the first object; in a complete parse, it is part of 
the second object: 
(4) I convinced her children are noisy. 
Initially, the parser attaches her as the NP object 
of convinced. The structure of the network after at- 
tachment of children is shown in Figure 15. The NP 
children cannot replace the phi-node attachment to 
the verb, since the second object of convince must be 
~ ~ current 
? .,/ 
toy /  . . . .~ /  m ft... ,,oz.,, T 
of - ~e~ (N) ~ dog 
s,ack "V" "V  T 
the child the 
Figure 14: If the NP the dog activates the attachment 
to the V, the V node would be left with only one active 
attachment. 
sentential. In order to maximally satisfy the attach- 
ment preferences, her is reanalyzed as the specifier of 
children, with her children replacing her as the first 
object of convinced. This reanalysis is structurally 
the same as that required in Figure 8; the relevant a- 
nodes have been numbered the same in each figure to 
highlight he similarity. Problems arise when the net- 
work attaches the next input word, are; see Figure 16. 
Once again, the misattached NP needs to attach as 
the specifier of the following sentential phrase, but 
a V node would be left with only one active a-node 
when it requires two. A garden path once more re- 
sults from the network settling on an ungrammatical 
analysis. 
This example highlights another aspect of the com- 
petitive mechanism of CAPERS in driving the attach- 
ment behavior of the parser: the only way a pre- 
vious attachment can be broken is if it participates 
in a competition with an attachment to the current 
phrase. A correct parse requires her to break its at- 
tachment o children and re-attach directly to the 
verb. Because the a-node attaching her to children 
has no competitor, there is no mechanism for chang- 
ing the problematic attachment. 
5 Summary  
In each of the examples of Section 4, the initial attach- 
ment of a phrase was incompatible with the remain- 
der of the sentence. CAPERS can recover from an 
attachment error of this type exactly when the mis- 
attached phrase can reattach to the current phrase, 
with the current phrase "replacing" the misattached 
272 
cu rr::t 
@ ' , i    ,,Oren 
top /  convirtce ~) 
?,  
stack 
her 
Figure 15: Attaching the NP children requires reanal- 
ysis of the NP her. 
current 
children 
her 
Figure 16: If the NP headed by children activates 
the attachment to the I', the V node would be left 
without an NP complement. 
phrase in its original attachment site. If the p-node to 
which the misattached phrase was originally attached 
does not have an alternative a-node to activate, re- 
analysis cannot take place and a garden path results. 
The allowable attachment configurations are a direct 
consequence of the restrictions imposed by the com- 
petitive mechanism of CAPERS. The resulting initial 
attachment preferences, and the parser's ability or in- 
ability to revise the incorrect structure, account for 
the preferred readings of these temporarily ambigu- 
ous sentences, as well as the garden path results. 
References 
Abney, S. (1986). "Functional elements and licensing." GLOW 
Conference, (-;erona, Spain. 
Abney, S. (1989). "A computational model of human parsing." 
Journal of Psycholinguistic Research 18:1, 129-144. 
Chomsky, N. (1981). Lectures on Government and Binding: The 
Piss Lectures. Dordrecht: Foris Publications. 
Chomsky, N. (1986). Barriers. Cambridge: MIT Press 
Cottrell, G.W.(1989). A Connectionist Approach to Word Sense 
D=sambiguation. Los Altos, CA: Morgan Kaufmann. 
Fanty, M. (1985). "Context-free parsing in connectionist net- 
works." Technical Report TR174, University of Rochester. 
Frazier, L. (1978). On Comprehending Sentences: Syntactic 
Parsing Strategies. Doctoral dissertation, University of Connecti- 
cut. Bloomington, IN: Indiana University Linguistics Club. 
Frazier, L., and K. Rayner (1982). "Making and correcting errors 
during sentence comprehension: Eye movements in the analysis of 
structurally ambiguous sentences." Cognitive Psychology 14, 178- 
210. 
Gibson, E. (1991). "A Computational Theory of Human Linguis- 
tic Processing: Memory Limitations and Processing Breakdown." 
Doctoral dissertation, Carnegie-Mellon University. 
Gorrell, P. (1987). "Studies of Human Syntactic Processing: 
Ranked-Parallel versus Serial Models." Unpublished octoral dis- 
sertation, University of Connecticut, Storrs, CT. 
Inoue, A. and J. Fodor (1992). "Information-paced parsing of 
Japanese." Presented at the Fifth Annual CUNY Conference on 
Human Sentence Processing, New York. 
McRoy, S. and G. Hirst (1990). "Race-Based Parsing and Syntactic 
Disambiguation." Cognitive Science 14, 313-353. 
Pritchett, B. (1988). "Garden Path Phenomena and the Grammat- 
ical Basis of Language Processing." Language 64:3, 539-576. 
Rizzi, L. (1990). Relativized Minimality. Cambridge: MIT Press. 
Reggia, J. (1987). "Properties of a Competition-Based Activation 
Mechanism in Neuromimetic Network Models." Proceedings of the 
First International Conference on Neural Networks, San Diego, 
II-131-11-138. 
Reggia, J., P. Marsland, and R. Berndt (1988). "Competitive Dy- 
namics in a Dual-Route Connectionist Model of Print-to-Sound 
Transformation." Complex Systems. 
Selman, G., and G. Hirst (1985). "A Rule-Based Connectionist 
Parsing Scheme." Proceedings of the Seventh Annual Conference 
of the Cognitive Science Society, 212-219. 
Shieber, S. (1983). "Sentence Disambiguation by a Shift-Reduce 
Parsing Technique." Proceedings of the 21st Annual Meeting of 
the Association for Computational Linguistics, 113-118. 
Stevenson, S. (1993a). "Establishing Long-Distance Dependencies 
in a Hybrid Network Model of Human Parsing." Proceedings of 
the 15th Annual Conference of the Cognitive Science Society. 
Stevenson, S. (1993b). "A Constrained Active Attachment Model 
for Resolving Syntactic Ambiguities in Natural Language Parsing." 
Doctoral dissertation, Computer Science Department, University of 
Maryland, College Park. 
Stevenson, S. (1990). "A Parallel Constraint Satisfaction and 
Spreading Activation Model for Resolving Syntactic Ambiguity." 
Proceedings of the Twelfth Annual Conference of the Cognitive 
Science Society, 396-403. 
273 
