The SynDiKATe Text Knowledge Base Generator
Udo Hahn
Text Knowledge Engineering Lab
Albert-Ludwigs-Universita?t Freiburg
D-79085 Freiburg, Germany
hahn@coling.uni-freiburg.de
Martin Romacker
Text Knowledge Engineering Lab
Albert-Ludwigs-Universita?t Freiburg
D-79085 Freiburg, Germany
romacker@coling.uni-freiburg.de
ABSTRACT
SynDiKATe comprises a family of text understanding sys-
tems for automatically acquiring knowledge from real-world
texts, viz. information technology test reports and medical
nding reports. Their content is transformed to formal rep-
resentation structures which constitute corresponding text
knowledge bases. SynDiKATe's architecture integrates re-
quirements from the analysis of single sentences, as well as
those of referentially linked sentences forming cohesive texts.
Besides centering-based discourse analysis mechanisms for
pronominal, nominal and bridging anaphora, SynDiKATe
is supplied with a learning module for automatically boot-
strapping its domain knowledge as text analysis proceeds.
1. INTRODUCTION
The SynDiKATe system belongs to the broad family of
information extraction (IE) systems [1]. Signicant progress
has been made already, as current IE systems provide robust
shallow text processing such that frame-style templates are
lled with factual information about particular entities (lo-
cations, persons, event types, etc.) from the analyzed doc-
uments. Nevertheless, typical MUC-style systems are also
limited in several ways. They provide no inferencing ca-
pabilities which allow substantial reasoning about the tem-
plate llers (hence, their understanding depth is low), and
their potential to deal with textual phenomena is highly
constrained, if it is available at all. Also novel and unex-
pected though potentially relevant information which does
not match given template structures is hard to account for,
since system designers commit to a xed collection of do-
main knowledge templates (i.e., they have no concept learn-
ing facilities).
With SynDiKATe, we are addressing these shortcomings
and aim at a more sophisticated level of knowledge acqui-
sition from real-world texts. The documents we deal with
are technical narratives in German language taken from two
domains, viz. test reports from the information technology
(IT) domain as processed by the itSynDiKATe system [8],
.
and nding reports from a medical subdomain (MED), the
framework of the medSynDiKATe system [10, 9]. Our rst
goal is to extract conceptually and inferentially richer forms
of knowledge than those captured by standard IE systems
such as evaluative assertions and comparisons [25, 24], tem-
poral [26] and spatial information [22]. Second, we also
want to dynamically enhance the set of knowledge templates
through incremental taxonomy learning devices [12] so that
the information extraction capability of the system is in-
creased in a bootstrapping manner. Third, SynDiKATe is
particularly sensitive to the treatment of textual reference
relations [27, 6, 14]. The capability to properly deal with
various forms of anaphora is a prerequisite for the sound-
ness and validity of the knowledge bases we create as a re-
sult of the text understanding process and likewise for the
feasibility of sophisticated retrieval and question answering
applications based on the acquired text knowledge.
2. SYSTEM ARCHITECTURE
The overall architecture of SynDiKATe, an acronymwhich
stands for \Synthesis of Distributed Knowledge Acquired
from Texts", is summarized in Figure 1. Incoming texts, T
i
,
are mapped into corresponding text knowledge bases, TKB
i
,
which contain a representation of T
i
's content. This knowl-
edge base platform may feed various information services,
such as inferentially supported question answering (fact re-
trieval), text passage retrieval or text summarization [7].
2.1 Sentence-Level Understanding
Grammatical knowledge for syntactic analysis is based
on a fully lexicalized dependency grammar [11], we refer to
as Lexicon in Figure 1. Basic word forms (lexemes) con-
stitute the leaf nodes of the lexicon tree, which are further
abstracted in terms of a hierarchy of lexeme class speci-
cations at dierent levels of generality. The Generic Lexi-
con in Figure 1 contains lexical material which is domain-
independent (lexemes such as move, with, or month), while
domain-specic extensions are kept in specialized lexicons
serving the needs of particular subdomains, e.g., IT (hard
disk, color printer, etc.) or MED (gastritis, surface mucus,
etc.). Dependency grammars capture binary valency con-
straints between a syntactic head (e.g., a noun) and possi-
ble modiers (e.g., a determiner or an adjective). To estab-
lish a dependency relation between a head and a modier,
all the lexicalized constraints on word order, compatibility
of morphosyntactic features, and semantic criteria must be
fullled. This leads to a strictly local computation scheme
which inherently lends itself to robust partial parsing [5].
Figure 1: Architecture of a SynDiKATe System
Conceptual knowledge about the dierent domains is
expressed in a Kl-One-like description logic language [28].
Corresponding to the division at the lexical level, the on-
tologies we provide are split up between one that is used by
all applications, the Upper Ontology, while several dedicated
ontologies account for the conceptual requirements of par-
ticular domains, e.g., IT (HardDisk, ColorPrinter, etc.)
or MED (Gastritis, SurfaceMucus, etc.).
Semantic knowledge accounts for emerging conceptual
relations between conceptual items according to those de-
pendency relations that are established between their cor-
responding lexical items. Semantic interpretation schemata
mediate between both levels in a way as abstract and general
as possible [20]. These schemata are applied to semantically
interpretable subgraphs which are, from a semantic point of
view, \minimal" subgraphs of the incrementally built depen-
dency graph. Their bounding nodes contain content words
(i.e., nouns, verbs, and adjectives, all of which have a concep-
tual correlate in the domain ontologies), while all possibly
intervening nodes (zero up to four) contain only noncon-
tent words (such as prepositions, articles, auxiliaries, etc.,
all of which have no conceptual correlates). Semantic in-
terpretation schemata are fully embedded in the knowledge
representation model and system (cf. Figure 1).
The ParseTalk system, which comprises the lexicalized
grammar and associated dependency parser, is embedded in
an object-oriented computation model. So, the dependency
relations are computed by lexical objects, so-called word ac-
tors, through strictly local message passing, only involving
the lexical items they represent. To illustrate how a de-
pendency relation is established computationally, we give a
sketch of the basic protocol for incremental parsing [5]:
 After a word has been read from textual input by
the WordScanner (step A
1
in Figure 1), its associated
lexeme (specied in the Lexicon) is identied (step
A
2
) and a corresponding word actor gets initialized
(step B
1
). As all content words are directly linked to
the conceptual system, each lexical item w that has a
conceptual correlate C in the domain knowledge base
(step A
3
) gets instantiated in the text knowledge base
(step B
2
). The lexical item Festplatte (hard disk)
with the conceptual correlate Hard-Disk is instanti-
ated, e.g., by Hard-Disk.3, the particular item being
talked about in a given text.
1
 For integration in the parse tree, the newly created
word actor searches its head (alternatively, its modi-
er) by sending parallel requests for dependential gov-
ernment to its left context (step C). The search space
is restricted, since these requests are propagated up-
wards only along the `right shoulder' of the depen-
dency graph constructed so far. All word actors ad-
dressed this way check, in parallel, whether their va-
lency restrictions, i.e., grammatical and conceptual con-
straints, are met by the requesting word actor. Step
D simulates a conceptual check in the text knowledge
base, step E illustrates a test in the discourse memory.
 If all required constraints are fullled by one of the
targeted word actors, an immediate semantic interpre-
tation is performed. This usually alters the conceptual
representation structures by way of slot lling (step F ).
Semantic interpretation consists of nding a relational
link between the conceptual correlates of the two content
words bounding the associated semantically interpretable
subgraph. The linkage may either be constrained by depen-
dency relations (e.g., the subject: relation of a transitive
verb such as \sell" may only be interpreted conceptually
in terms of agent or patient roles), by intervening lexical
material (e.g., some prepositions impose special role con-
straints, such as mit (with) does in terms of has-part or
instrument roles), or it may be constrained by concep-
tual criteria only (as with the genitive: dependency rela-
tion, which unlike subject: imposes no additional selective
conceptual constraints for interpretation). The correspond-
ing knowledge about these language-specic constraints is
densely encoded in the Lexicon class hierarchy, an approach
which heavily relies on the property inheritance mechanisms
inherent to the object-oriented paradigm.
2.2 Text-Level Understanding
2.2.1 Referential Text Phenomena
The textual phenomena we deal with in SynDiKATe es-
tablish referential links between consecutive utterances in a
coherent text such as illustrated by three possible continua-
tions of sentence (1), with three dierent forms of extrasen-
tential anaphora:
(1) Compaq verkauft ein Notebook mit einer Festplatte, die
von Seagate hergestellt wird.
(Compaq sells a notebook with a hard disk that is man-
ufactured by Seagate.)
(2) Pronominal Anaphora:
Es ist mit einer Pentium-III-CPU ausgestattet.
(It comes with a Pentium-III CPU.)
(3) Nominal Anaphora:
Der Rechner ist mit einer Pentium-III-CPU ausgestattet.
(The machine comes with a Pentium-III CPU.)
(4) Functional Anaphora:
Der Arbeitsspeicher kann auf 96 MB erweitert werden.
(The main memory can be expanded up to 96MB.)
1
Due to the recognition of referential relations at the text
level of analysis this instantiation might be readjusted by
subsequent coreference declarations (cf. Section 2.2).
Compaq sells a Notebook with a hard disk that is manufactured by Seagate.
3
ein
4
2
5
1
Compaq
subject:
propo:
verkauft
die
,
delimiter:
subject:
relative:specifier:
Notebook
hergestellt
von
Seagate
ppadjunct:
pobject:
wird
ppatt:
pobject:
object:
mit
specifier:
Festplatte
.
einer
verbpart:
Figure 2: Dependency Parse for Sentence (1)
Figure 3: Conceptual Interpretation for Sentence (1)
The results of sentence-level analysis for sentence (1) are
given in Figure 2, which contains a syntactic dependency
graph (together with ve congurations of semantically in-
terpretable subgraphs), and Figure 3, which displays its con-
ceptual representation. For text-level analysis, pronominal
anaphora still heavily depend on grammatical conditions {
the agreement of the antecedent (\Notebook") and the pro-
noun (\Es" (it)) in gender and number; also conceptual cri-
teria apply insofar as a potential antecedent must t the
conceptual role (or case frame) restrictions when it is in-
tegrated in governing structures, say, the head verb of the
clause. In general, however, the inuence of grammatical
criteria gradually diminishes for other types of text phe-
nomena, while the inuence of conceptual criteria increases.
For nominal anaphora, number constraints are still valid,
while a generalization relation between the anaphoric noun
(\Rechner" (machine)) and its proper antecedent (\Note-
book") must hold, in addition. In the case of functional
anaphora, no grammar constraints at all apply, while quite
sophisticated conceptual role path conditions come into play,
e.g., \Arbeitsspeicher" (main memory) being a constituent
physical part of \Notebook".
The problems text phenomena cause are of vital impor-
tance for the adequacy of the representation structures re-
sulting from text processing, and are centered around the no-
tions of incomplete, invalid and incoherent knowledge bases.
Incomplete knowledge bases emerge when references to
already established discourse entities are simply not recog-
nized, as in the case of pronominal anaphora. Consider the
reference relationship between the pronoun \Es" (it) in sen-
tence (2) which refers to the noun phrase \ein Notebook"
(a notebook) in sentence (1). The occurrence of the pro-
noun is not reected at the conceptual level, since pronouns
(as noncontent words) do not have conceptual correlates.
Hence, an incomplete concept graph emerges as shown in
Figure 4 | the referent for the pronoun \Es" (it), Note-
book.2, is not linked to Pentium-III-CPU.6. An adequate
treatment with a properly resolved anaphor is shown in Fig-
ure 6, where the representation of the relevant portions of
sentence (1) is linked to the one of sentence (2), in particu-
Figure 4: Unresolved Pronominal Anaphor, Sentence (2)
Figure 5: Unresolved Nominal Anaphor, Sentence (3)
Figure 6: Resolved Anaphors, Sentences (1) and (2)/(3)
lar by determining the equip-patient role between Equip.7
and the proper referent, Notebook.2.
Invalid knowledge bases emerge when each entity which
has a dierent denotation at the text surface is treated as
a formally distinct conceptual item at the symbol level of
knowledge representation, although all dierent denotations
refer literally to the same conceptual entity. This is the
case for nominal anaphora, an example of which is given by
the reference relation between the noun phrase \Der Rech-
ner" (the machine) in sentence (3) and the noun phrase \ein
Notebook" (a notebook) in sentence (1). An invalid referen-
tial description appears in Figure 5, where Computer.5 is
introduced as a new entity in the discourse, whereas Figure
6 shows the valid conceptual representation capturing the
intended meaning at the representation level, viz. maintain-
ing Notebook.2 as the proper referent (note that pronom-
inal as well as nominal anaphora are two equivalent ways to
corefer to the discourse entity denoted by Notebook.2).
Finally, incoherent knowledge bases emerge when entities
which are linked by nontaxonomic conceptual relations at
the knowledge level occur in a text such that an implicit
reference to these relations can be made in the text source.
Unlike the previously discussed cases of coference, these
relations have to be made explicit at the symbol level of
the targeted text knowledge base by a search for connect-
ing paths between the concepts involved [6]. This is the
basic scenario for functional (or bridging) anaphora. Con-
sider, e.g., the relationship holding between the noun phrase
\Der Arbeitsspeicher" (the main memory) in sentence (4),
which refers to the noun phrase \ein Notebook" (a note-
book) in sentence (1). In Figure 8 the relational link miss-
ing in Figure 7 between Main-Memory.8 and Notebook.2
is established (via a has-part-type relation, viz. has-main-
memory), and, hence, representational coherence at the sym-
bol level of knowledge representation is preserved.
Figure 7: Unresolved Functional Anaphor, Sentence (4)
Figure 8: Resolved Functional Anaphor, Sentences (1)
and (4)
Disregarding textual phenomena will cause dysfunctional
system behavior. A query Q such as
Q : (retrieve ?x (Computer ?x))
A-: (|I| Notebook.2, |I| Computer.5)
A+: (|I| Notebook.2)
triggers a search for all instances of Computer in the text
knowledge base. Given an invalid knowledge base (cf. Fig-
ures 3 and 5), the incorrect answer (A-) contains two entities,
viz. Notebook.2 and Computer.5 | both are in the ex-
tension of the concept Computer. If, however, a valid text
knowledge base such as the one in Figure 6 or 8 is given,
only the correct answer, Notebook.2, is inferred (A+).
Rendering also quantitative substance to our claims, we
analyzed a randomly chosen sample of 100 reports on his-
tological ndings with approximately 14,000 text tokens [9].
In IT texts, (pro)nominal anaphora and functional anaphora
occur at an almost balanced rate [27]. In the medical texts,
however, functional anaphora turn out to be the major glue
for establishing local coherence, while anaphora, pronomi-
nal anaphora in particular, play a far less important role
than in other text genres. The high proportion of func-
tional anaphora (45%) [42%-48%]
2
and the remarkable rate
of nominal (34%) [31%-37%] compared to extrasentential
pronominal anaphora (2%) [1%-3%] is clearly an indication
of the primary orientation in medical texts to convey facts
in a very compact manner. Two consequences can be drawn
from this observation. First, resolution procedures for func-
tional anaphora { supplementing well-researched procedures
for (pro)nominal anaphora { have to be provided urgently
(cf. [6] for a fully worked out approach). Second, functional
anaphora presuppose a considerable amount of deep back-
ground knowledge, with emphasis on partonomic reasoning
[13], supplementing well-known principles of taxonomic rea-
soning for text understanding.
2
For all percentage numbers 95% condence intervals are
supplied in square brackets.
2.2.2 Centering Model for Anaphora Resolution
In order to avoid the emergence of incomplete, invalid and
incoherent text knowledge bases we consider discourse enti-
ties for establishing reference relations with upcoming items
from the textual input at a local [27] and at a global level
[14] of cohesion. To preserve adequate text representation
structures a centering mechanism is used. The discourse en-
tities which occur in an utterance U
i
constitute its set of
forward-looking centers, C
f
(U
i
). The elements in C
f
(U
i
)
are ordered to reect relative prominence in U
i
in the sense
that the most highly ranked element of C
f
(U
i
) is the most
likely antecedent of an anaphoric expression in U
i+1
, while
the remaining elements are ordered according to decreasing
preference for establishing referential links.
While it is usually assumed (for the English language,
in particular) that grammatical roles are the major deter-
minant for the ranking on the C
f
[4], we claim that for
German { a language with relatively free word order { it
is the functional information structure of the sentence [27].
Accordingly, the constraints on the ordering of entries in
C
f
(U
i
) prefer hearer-old (either evoked or unused) elements
in an utterance (i.e., those that can be related to previ-
ously introduced discourse elements or generally accessi-
ble world knowledge) over mediated (inferrable) ones, while
these are preferred over hearer-new (brand-new) elements
for anaphora resolution. If two elements belong to the same
category, then preference is dened in terms of linear prece-
dence of the discourse units in the source text.
When we apply these criteria to sentence (1), Table 1 de-
picts the resulting order of forward-looking centers in C
f
(S
1
).
Since we have no discourse-bound elements in the rst sen-
tence, textual precedence applies exclusively to the ordering
of the center list items. Only nouns and their conceptual
correlates are taken into consideration. The tuple notation
takes the conceptual correlate of the lexical item in the text
knowledge base in the rst place, while the lexical surface
form appears in the second place.
(1) Cf: [Compaq: Compaq, Notebook.2: Notebook,
Hard-Disk.3: Festplatte, Seagate: Seagate]
Table 1: Centering Data for Sentence (1)
Processing of the centering list C
f
(S
1
) for sentence (3)
until the generalization constraint is fullled, nally, results
in a query whether Notebook is subsumed by Computer,
the conceptual correlate of the lexical item \Rechner". As
this relationship obviously holds, in the conceptual represen-
tation structure of sentence (3) (cf. Figure 5) Computer.5,
the literal instance identier, is declared coreferent toNote-
book.2, the referentially valid identier. Instead of having
two unlinked sentence graphs, Figures 3 and 5, the reference
resolution for (pro)nominal anaphora leads to joining them
in a common valid text graph (Figure 6). In particular,
Notebook.2 links to the relation equip-patient, formerly
occupied by Computer.5. The corresponding centering list
at the end of the analysis of sentence (3) is provided in Table
2 (C
f
(S
1
) has been updated to reect the consumption of
the antecedent, Notebook.2, in the processing of C
f
(S
3
)).
(1) Cf: [Compaq: Compaq, Notebook.2: Notebook,
Hard-Disk.3: Festplatte, Seagate: Seagate]
(3) Cf: [Notebook.2: Rechner,
Pentium-III-CPU.6: Pentium-III-CPU]
Table 2: Centering Data for Sentences (1) and (3)
2.3 Textual Learning
The approach to learning new concepts as a result of text
understanding builds on two dierent sources of evidence |
the prior knowledge of the domain the texts are about, and
grammatical constructions in which unknown lexical items
occur in the texts. The architecture of SynDiKATe's con-
cept learning component is depicted in Figure 9.
linguistic
quality
labels
conceptual
labels
Hypothesis
space-p
Hypothesis
Qualifier
quality
space-q
Quality Machine
1
2
space-1
space-i
space-n
Hypothesis
Hypothesis
Hypothesis
Language Processor
dependency parse graph
text knowledge base
Figure 9: SynDiKATe's Learning Component
The ParseTalk system generates dependency parse graphs.
The kinds of syntactic constructions (e.g., genitive, apposi-
tive, comparative), in which unknown lexical items appear,
are recorded and later assessed relative to the credit they
lend to a particular concept hypothesis, e.g., high for ap-
positives (\the notebook X"), lower for genitives (\Compaq's
X"). The conceptual interpretation of parse trees involving
unknown lexical items in the text knowledge base leads to the
deduction of concept hypotheses. These are further enriched
by conceptual annotations which reect structural patterns
of consistency, mutual justication, analogy, etc. relative to
already available concept descriptions in the text knowledge
base or other hypothesis spaces. Both kinds of evidence, in
particular their predictive `goodness' for the learning task,
are represented by corresponding sets of linguistic and con-
ceptual quality labels.
Alternative concept hypotheses for each unknown lexi-
cal item are organized in terms of corresponding hypothesis
spaces, each of which holds a dierent conceptual reading.
An inference engine embedded in the terminological system,
the so-called quality machine, determines the overall credi-
bility of single concept hypotheses by taking the available set
of quality labels for each hypothesis into account. The qual-
ier, a terminological classier extended by an evaluation
metric for quality classes, computes a preference ranking of
those hypotheses which remain valid after the text has been
processed completely (cf. [12] for details).
3. COVERAGE AND EVALUATION
SynDiKATe's coverage varies considerably depending on
the target domain. The generic lexicon currently includes
3,000 entries, the IT lexicon adds 5,000, while the MED
lexicon contributes 70,000 entries each. The Upper Ontology
contains 1,200 concepts and roles, to which the IT ontology
adds 3,000 and the MED ontology contributes 240,000 items.
The IT domain was chosen as a testbed that can be ex-
tended on demand. The MED domain, however, is subject
to ontology engineering eorts on a larger scale. In order
to cope with the enormous knowledge engineering require-
ments, we semi-automatically transformed large portions of
a semantically weak, yet high-volume medical terminology
(UMLS) to a very large terminological knowledge base [21].
Admittedly, SynDiKATe has not yet undergone a thor-
ough empirical evaluation in one of the envisaged applica-
tion dimensions. We have, however, carefully evaluated its
subcomponents. The results can be summarized as follows:
Sentence Parsing. We compared a standard active chart
parser with full backtracking capabilities with the parser
of SynDiKATe, which is characterized by limited memo-
ization and restricted backtracking capabilities, using the
same grammar specications. On average, SynDiKATe's
parser exhibits a linear time complexity the factor of which
is dependent on ambiguity rates of input sentences. The
active chart parser runs into exponential time complexity
whenever it encounters extragrammatical or ungrammatical
input, since then it conducts an exhaustive search of the en-
tire parse space. The loss of structural descriptions due to
the parser's incompleteness amounts to 10% compared with
the complete, though intractable parser [5].
Text Parsing. While with respect to resolution capac-
ity (eectiveness) no signicant dierences could be deter-
mined, the functional centering model we propose outper-
forms the best-known centering algorithms by a rate of 50%
with respect to a measure of computation costs which con-
siders \cheap" and \expensive" transitional moves between
utterances to assess a text's coherency. Hence, the proce-
dure we propose is more e?cient [27].
Semantic Interpretation. Our group has been pioneer-
ing work on the empirical evaluation of meaning representa-
tions. We assessed the quality and coverage of semantic in-
terpretation for randomly sampled texts in the two domains
we consider. While recall was rather low (57% for MED, 31%
for IT), precision peaked at 97% and 94%, respectively [19].
\Heavy" Semantics. We can deal with intricate seman-
tic phenomena for which we have provided the rst empirical
evaluation data available at all. This relates to the resolu-
tion of metonymies, where we have determined a gain in
eectiveness that amounts to 16% compared with the best
procedures known so far [16], as well as it relates to compar-
atives and evaluative assertions, where gains in eectiveness
were almost tripled [25].
Concept Learning. The performance of the concept
learning component has been compared to standard learning
mechanisms based on the terminological classier available
in any sort of description logics systems. Our data indicate
an increase of performance of 8% (87% accuracy, while that
of standard classiers is on the order of 79%) [12].
Evaluating a text knowledge acquisition rather than an IE
system poses hard methodological problems [2]. The main
reason being that a gold standard for comparison | what
constitutes a canonical, commonly agreed upon interpreta-
tion of the content of a text? | is hard to establish, even
for technical texts. A follow-up problem is constituted by
the lack of a signicant amount of annotated text knowl-
edge bases on which comparative analyses might be assessed.
MUC-style evaluation metrics, e.g., have already been qual-
ied not to adequately reect the functionality of less con-
strained text understanders [29].
4. CONCLUSIONS
A major hypothesis underlying the design of SynDiKATe
is that ignoring the referential relations between adjacent
utterances will lead to referentially incomplete, invalid, or
incoherent text knowledge bases. We determine plausible
discourse units for reference resolution using the centering
model. This allows us to deal with various forms of pronom-
inal, nominal and functional anaphora in a uniform way.
In order to establish local coherence at the text represen-
tation level, single discourse entities related by anaphoric
expressions have to be conceptually linked. We claim that
only sophisticated knowledge representation languages with
powerful terminological reasoning capabilities, such as those
from the KL-ONE family, are able to deal with the full range
of challenges of referentially adequate text understanding, in
particular considering nominal and functional anaphora.
These two types of anaphora pose an enormous burden
on the availability of rich domain knowledge. We respond
to this challenge in two ways. In a large-scale knowledge
engineering eort, we semi-automatically transform a se-
mantically weak though huge thesaurus-style medical knowl-
edge source into a terminological knowledge base. If such a
human-made resource is missing, we turn to a purely auto-
matic approach of bootstrapping a given domain knowledge
base as part of on-going text understanding processes.
The depth of understanding we provide comes closest to
systems such as Scisor [18], Tacitus [15] or Pundit/Kernel
[17], but SynDiKATe's knowledge acquisition strategies or
learning capabilities have no counterpart there. Text under-
standers which incorporate learning components are even
rarer but systems such as Snowy [3] or Wrap-Up [23] ei-
ther have a very narrow domain theory and lack robustness
for dealing with unseen input eectively, or fail to account
for a wide range of referential text phenomena, respectively.
5. ACKNOWLEDGMENTS
The development of the SynDiKATe system has been sup-
ported by various grants from Deutsche Forschungsgemeinschaft
under Ha 2097/*. SynDiKATe would not have come to existence
without the exciting contributions and enthusiasm of current and
former members of the group, in particular, Steen Staab,
Katja Markert, Michael Strube, Martin Romacker, Stefan Schulz,
Klemens Schnattinger, Norbert Broker, Peter Neuhaus, Susanne
Schacht, Manfred Klenner, and Holger Schauer.
6. REFERENCES
[1] Jim Cowie and Wendy Lehnert. Information extraction.
Communications of the ACM, 39(1):80{91, 1996.
[2] Carol Friedman and George Hripcsak. Evaluating natural
language processors in the clinical domain. Methods of
Information in Medicine, 37(4/5):334{344, 1998.
[3] Fernando Gomez and Carlos Segami. The recognition and
classication of concepts in understanding scientic texts.
Journal of Experimental and Theoretical Articial
Intelligence, 1(1):51{77, 1989.
[4] Barbara J. Grosz, Aravind K. Joshi, and Scott Weinstein.
Centering: A framework for modeling the local coherence of
discourse. Computational Linguistics, 21(2):203{225, 1995.
[5] Udo Hahn, Norbert Broker, and Peter Neuhaus. Let's
ParseTalk: Message-passing protocols for object-oriented
parsing. In H. Bunt and A. Nijholt, editors, Advances in
Probabilistic and other Parsing Technologies, pages
177{201. Kluwer, 2000.
[6] Udo Hahn, Katja Markert, and Michael Strube. A
conceptual reasoning approach to textual ellipsis. In
Proceedings of the ECAI'96, pages 572{576, 1996.
[7] Udo Hahn and Ulrich Reimer. Knowledge-based text
summarization: Salience and generalization operators for
knowledge base abstraction. In I. Mani and M. Maybury,
editors, Advances in Automatic Text Summarization, pages
215{232. MIT Press, 1999.
[8] Udo Hahn and Martin Romacker. Content management in
the SynDiKATe system: How technical documents are
automatically transformed to text knowledge bases. Data &
Knowledge Engineering, 35(2):137{159, 2000.
[9] Udo Hahn, Martin Romacker, and Stefan Schulz. Discourse
structures in medical reports { watch out! The generation
of referentially coherent and valid text knowledge bases in
the medSynDiKATe system. International Journal of
Medical Informatics, 53(1):1{28, 1999.
[10] Udo Hahn, Martin Romacker, and Stefan Schulz. How
knowledge drives understanding: Matching medical
ontologies with the needs of medical language processing.
Articial Intelligence in Medicine, 15(1):25{51, 1999.
[11] Udo Hahn, Susanne Schacht, and Norbert Broker.
Concurrent, object-oriented natural language parsing: The
ParseTalk model. International Journal of
Human-Computer Studies, 41(1/2):179{222, 1994.
[12] Udo Hahn and Klemens Schnattinger. Towards text
knowledge engineering. In Proceedings of the AAAI'98,
pages 524{531, 1998.
[13] Udo Hahn, Stefan Schulz, and Martin Romacker.
Partonomic reasoning as taxonomic reasoning in medicine.
In Proceedings of the AAAI'99, pages 271{276, 1999.
[14] Udo Hahn and Michael Strube. Centering in-the-large:
Computing referential discourse segments. In Proceedings of
the ACL'97/EACL'97, pages 104{111, 1997.
[15] Jerry R. Hobbs, Mark E. Stickel, Douglas E. Appelt, and
Paul Martin. Interpretation as abduction. Articial
Intelligence, 63(1/2):69{142, 1993.
[16] Katja Markert and Udo Hahn. On the interaction of
metonymies and anaphora. In Proceedings of the IJCAI'97,
pages 1010{1015, 1997.
[17] Martha S. Palmer, Rebecca J. Passonneau, Carl Weir, and
Tim Finin. The Kernel text understanding system.
Articial Intelligence, 63(1/2):17{68, 1993.
[18] Lisa F. Rau, Paul S. Jacobs, and Uri Zernik. Information
extraction and text summarization using linguistic
knowledge acquisition. Information Processing &
Management, 25(4):419{428, 1989.
[19] Martin Romacker and Udo Hahn. An empirical assessment
of semantic interpretation. In Proceedings of the NAACL
2000, pages 327{334, 2000.
[20] Martin Romacker, Katja Markert, and Udo Hahn. Lean
semantic interpretation. In Proceedings of the IJCAI'99,
pages 868{875, 1999.
[21] Stefan Schulz and Udo Hahn. Knowledge engineering by
large-scale knowledge reuse: Experience from the medical
domain. In Proceedings of KR 2000, pages 601{610, 2000.
[22] Stefan Schulz, Udo Hahn, and Martin Romacker. Modeling
anatomical spatial relations with description logics. In
Proceedings of the AMIA 2000, pages 779{783, 2000.
[23] Stephen Soderland and Wendy Lehnert. Wrap-up: A
trainable discourse module for information extraction.
Journal of Articial Intelligence Research, 2:131{158, 1994.
[24] Steen Staab and Udo Hahn. Comparatives in context. In
Proceedings of the AAAI'97, pages 616{621, 1997.
[25] Steen Staab and Udo Hahn. \Tall", \good", \high" {
compared to what? In Proceedings of the IJCAI'97, pages
996{1001, 1997.
[26] Steen Staab and Udo Hahn. Scalable temporal reasoning.
In Proceedings of the IJCAI'99, pages 1247{1252, 1999.
[27] Michael Strube and Udo Hahn. Functional centering:
Grounding referential coherence in information structure.
Computational Linguistics, 25(3):309{344, 1999.
[28] William A. Woods and James G. Schmolze. The Kl-One
family. Computers & Mathematics with Applications,
23(2/5):133{177, 1992.
[29] P. Zweigenbaum, J. Bouaud, B. Bachimont, J. Charlet, and
J.-F. Boisvieux. Evaluating a normalized conceptual repre-
sentation produced from natural language patient discharge
summaries. In Proceedings of the AMIA'97, pages 590{594.
