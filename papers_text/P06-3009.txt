Proceedings of the COLING/ACL 2006 Student Research Workshop, pages 49?54,
Sydney, July 2006. c?2006 Association for Computational Linguistics
Integrated Morphological and Syntactic Disambiguation
for Modern Hebrew
Reut Tsarfaty
Institute for Logic, Language and Computation, University of Amsterdam
Plantage Muidergratch 24, 1018 TV Amsterdam, The Netherlands
rtsarfat@science.uva.nl
Abstract
Current parsing models are not immedi-
ately applicable for languages that exhibit
strong interaction between morphology
and syntax, e.g., Modern Hebrew (MH),
Arabic and other Semitic languages. This
work represents a first attempt at model-
ing morphological-syntactic interaction in
a generative probabilistic framework to al-
low for MH parsing. We show that mor-
phological information selected in tandem
with syntactic categories is instrumental
for parsing Semitic languages. We further
show that redundant morphological infor-
mation helps syntactic disambiguation.
1 Introduction
Natural Language Processing is typically viewed
as consisting of different layers,1 each of which is
handled separately. The structure of Semitic lan-
guages poses clear challenges to this traditional
division of labor. Specifically, Semitic languages
demonstrate strong interaction between morpho-
logical and syntactic processing, which limits the
applicability of standard tools for, e.g., parsing.
This work focuses on MH and explores the
ways morphological and syntactic processing in-
teract. Using a morphological analyzer, a part-of-
speech tagger, and a PCFG-based general-purpose
parser, we segment and parse MH sentences based
on a small, annotated corpus. Our integrated
model shows that percolating morphological am-
biguity to the lowest level of non-terminals in the
syntactic parse tree improves parsing accuracy.
1E.g., phonological, morphological, syntactic, semantic
and pragmatic.
Moreover, we show that morphological cues facil-
itate syntactic disambiguation. A particular contri-
bution of this work is to demonstrate that MH sta-
tistical parsing is feasible. Yet, the results obtained
are not comparable to those of, e.g., state-of-the-
art models for English, due to remaining syntactic
ambiguity and limited morphological treatment.
We conjecture that adequate morphological and
syntactic processing of MH should be done in a
unified framework, in which both levels can inter-
act and share information in both directions.
Section 2 presents linguistic data that demon-
strate the strong interaction between morphology
and syntax in MH, thus motivating our choice to
treat both in the same framework. Section 3 sur-
veys previous work and demonstrates again the
unavoidable interaction between the two. Sec-
tion 4.1 puts forward the formal setting of an inte-
grated probabilistic language model, followed by
the evaluation metrics defined for the integrated
task in section 4.2. Sections 4.3 and 4.4 then
describe the experimental setup and preliminary
results for our baseline implementation, and sec-
tion 5 discusses more sophisticated models we in-
tend to investigate.
2 Linguistic Data
Phrases and sentences in MH, as well as Arabic
and other Semitic languages, have a relatively free
word order.2 In figure 1, for example, two distinct
syntactic structures express the same grammatical
relations. It is typically morphological informa-
tion rather than word order that provides cues for
structural dependencies (e.g., agreement on gen-
der and number in figure 1 reveals the subject-
predicate dependency).
2MH allows for both SV and VS, and in some circum-
stances also VSO, SOV and others.
49
SNP-SBJ
D
h
the
N
ild
child.MS
VP
V
ica
go.out.MS
PP
P
m
from
NP
D
h
the
N
bit
house
S
PP
P
m
from
NP
D
h
the
N
bit
house
VP
V
ica
go.out.MS
NP-SBJ
D
h
the
N
ild
child.MS
Figure 1: Word Order in MH Phrases (marking the
agreement features M(asculine), S(ingular))
S-CNJ
CC
?w
and
S
SBAR
REL
kf
when
S
PP
P
m
from
NP
D
h
the
N
bit?
house
VP
V
?ica?
go.out
NP
D
?h
the
N
ild?
boy
S
...
Figure 2: Syntactic Structures of MH Phrases
(marking word boundaries with ? ?)
Furthermore, boundaries of constituents in the
syntactic structure of MH sentences need not co-
incide with word boundaries, as illustrated in fig-
ure 2. A MH word may coincide with a single
constituent, as in ?ica?3 (go out), it may overlap
with an entire phrase, as in ?h ild ? (the boy), or it
may span across phrases as in ?w kf m h bit ? (and
when from the house). Therefore, we conclude
that in order to perform syntactic analysis (pars-
ing) of MH sentences, we must first identify the
morphological constituents that form MH words.
There are (at least) three distinct morphologi-
cal processes in Semitic languages that play a role
in word formation. Derivational morphology is a
non-concatenative process in which verbs, nouns,
and adjectives are derived from (tri-)consonantal
roots plugged into templates of consonant/vowel
skeletons. The word-forms in table 1, for example,
are all derived from the same root, [i][l][d] (child,
birth), plugged into different templates. In addi-
tion, MH has a rich array of agreement features,
such as gender, number and person, expressed in
the word?s inflectional morphology. Verbs, adjec-
tives, determiners and numerals must agree on the
inflectional features with the noun they comple-
3We adopt the transliteration of (Sima?an et al, 2001).
a. ?ild? b. ?iild? c. ?mwld?
[i]e[l]e[d] [i]i[l](l)e[d] mw[][l](l)a[d]
child deliver a child innate
Table 1: Derivational Morphology in MH ([..]
mark templates? slots for consonantal roots, (..)
mark obligatory doubling of roots? consonants.)
a. ild gdwl b. ildh gdwlh
child.MS big.MS child.FS big.FS
a big boy a big girl
Table 2: Inflectional Morphology in MH (marking
M(asculine)/F(eminine), S(ingular)/P(lural))
ment or modify. It can be seen in table 2 that the
suffix h alters the noun ?ild ? (child) as well as its
modifier ?gdwl ? (big) to feminine gender. Finally,
particles that are prefixed to the word may serve
different syntactic functions, yet a multiplicity of
them may be concatenated together with the stem
to form a single word. The word ?wkfmhbit ? in
figure 2, for instance, is formed from a conjunc-
tion w (and), a relativizer kf (when), a preposition
m (from), a definite article h (the) and a noun bit
(house). Identifying such particles is crucial for
analyzing syntactic structures as they reveal struc-
tural dependencies such as subordinate clauses,
adjuncts, and prepositional phrase attachments.
At the same time, MH exhibits a large-scale am-
biguity already at the word level, which means that
there are multiple ways in which a word can be
broken down to its constituent morphemes. This
is further complicated by the fact that most vo-
calization marks (diacritics) are omitted in MH
texts. To illustrate, table 3 lists two segmenta-
tion possibilities, four readings, and five mean-
ings of different morphological analyses for the
word-form ?fmnh?.4 Yet, the morphological anal-
ysis of a word-form, and in particular its mor-
phological segmentation, cannot be disambiguated
without reference to context, and various morpho-
logical features of syntactically related forms pro-
vide useful hints for morphological disambigua-
tion. Figure 3 shows the correct analyses of the
form ?fmnh ? in different syntactic contexts. Note
that the correct analyses maintain agreement on
gender and number between the noun and its mod-
ifier. In particular, the analysis ?that counted? (b)
4A statistical study on a MH corpus has shown that the
average number of possible analyses per word-form was 2.1,
while 55% of the word-forms were morphologically ambigu-
ous (Sima?an et al, 2001).
50
?fmnh? ?fmnh? ?fmnh? ?fmnh? ?f + mnh?
shmena shamna shimna shimna she + mana
fat.FS got-fat.FS put-oil.FS oil-of.FS that + counted
fat (adj) got fat (v) put-oil (v) her oil (n) that (rel) counted (v)
Table 3: Morphological Analyses of the Word-
form ?fmnh?
a. NP
N
ildh.FS
child.FS
A
fmnh.FS
fat.FS
b. NP
N
ild.MS
child.MS
CP
Rel
f
that
V
mnh.MS
counted.MS
Figure 3: Ambiguity Resolution in Different Syn-
tactic Contexts
is easily disambiguated, as it is the only one main-
taining agreement with the modified noun.
In light of the above, we would want to con-
clude that syntactic processing must precede mor-
phological analysis; however, this would contra-
dict our previous conclusion. For this reason,
independent morphological and syntactic analyz-
ers for MH will not suffice. We suggest per-
forming morphological and syntactic processing
of MH utterances in a single, integrated, frame-
work, thereby allowing shared information to sup-
port disambiguation in multiple tasks.
3 Related Work
As of yet there is no statistical parser for MH.
Parsing models have been developed for different
languages and state-of-the-art results have been
reported for, e.g., English (Collins, 1997; Char-
niak, 2000). However, these models show impov-
erished morphological treatment, and they have
not yet been successfully applied for MH parsing.
(Sima?an et al, 2001) present an attempt to parse
MH sentences based on a small, annotated corpus
by applying a general-purpose Tree-gram model.
However, their work presupposes correct morpho-
logical disambiguation prior to parsing.5
In order to treat morphological phenomena
a few stand-alone morphological analyzers have
been developed for MH.6 Most analyzers consider
words in isolation, and thus propose multiple anal-
yses for each word. Analyzers which also at-
tempt disambiguation require contextual informa-
tion from surrounding word-forms or a shallow
parser (e.g., (Adler and Gabai, 2005)).
5The same holds for current work on parsing Arabic.
6Available at mila.cs.technion.ac.il.
A related research agenda is the development of
part-of-speech taggers for MH and other Semitic
languages. Such taggers need to address the seg-
mentation of words into morphemes to which dis-
tinct morphosyntactic categories can be assigned
(cf. figure 2). It was illustrated for both MH (Bar-
Haim, 2005) and Arabic (Habash and Rambow,
2005) that an integrated approach towards mak-
ing morphological (segmentation) and syntactic
(POS tagging) decisions within the same architec-
ture yields excellent results. The present work fol-
lows up on insights gathered from such studies,
suggesting that an integrated framework is an ade-
quate solution for the apparent circularity in mor-
phological and syntactic processing of MH.
4 The Integrated Model
As a first attempt to model the interaction between
the morphological and the syntactic tasks, we in-
corporate an intermediate level of part-of-speech
(POS) tagging into our model. The key idea is that
POS tags that are assigned to morphological seg-
ments at the word level coincide with the lowest
level of non-terminals in the syntactic parse trees
(cf. (Charniak et al, 1996)). Thus, POS tags can
be used to pass information between the different
tasks yet ensuring agreement between the two.
4.1 Formal Setting
Let wm1 be a sequence of words from a fixed vo-cabulary, sn1 be a sequence of segments of wordsfrom a (different) vocabulary, tn1 a sequence ofmorphosyntactic categories from a finite tag-set,
and let pi be a syntactic parse tree.
We define segmentation as the task of identi-
fying the sequence of morphological constituents
that were concatenated to form a sequence of
words. Formally, we define the task as (1), where
seg(wm1 ) is the set of segmentations resultingfrom all possible morphological analyses of wn1 .
sn1 ? = argmax
sn1 ?seg(wm1 )
P (sn1 |wm1 ) (1)
Syntactic analysis, parsing, identifies the structure
of phrases and sentences. In MH, such tree struc-
tures combine segments of words that serve differ-
ent syntactic functions. We define it formally as
(2), where yield(pi?) is the ordered set of leaves of
a syntactic parse tree pi?.
pi? = argmax
pi?{pi?:yield(pi?)=sn1 }
P (pi|sn1 ) (2)
51
Similarly, we define POS tagging as (3), where
analysis(sn1 ) is the set of all possible POS tag as-signments for sn1 .
tn1 ? = argmax
tn1 ?analyses(sn1 )
P (tn1 |sn1 ) (3)
The task of the integrated model is to find the
most probable segmentation and syntactic parse
tree given a sentence in MH, as in (4).
?pi, sn1 ?? = argmax
?pi,sn1 ?
P (pi, sn1 |wm1 ) (4)
We reinterpret (4) to distinguish the morphological
and syntactic tasks, conditioning the latter on the
former, yet maximizing for both.
?pi, sn1 ?? = argmax
?pi,sn1 ?
P (pi|sn1 , wm1 )
? ?? ?
parsing
P (sn1 |wm1 )
? ?? ?
segmentation
(5)
Agreement between the tasks is implemented by
incorporating morphosyntactic categories (POS
tags) that are assigned to morphological segments
and constrain the possible trees, resulting in (7).
?pi, tn1 , sn1 ?? = argmax
?pi,tn1 ,sn1 ?
P (pi, tn1 , sn1 |wm1 ) (6)
= argmax
?pi,tn1 ,sn1 ?
P (pi|tn1 , sn1 , wm1 )
? ?? ?
parsing
P (tn1 |sn1 , wm1 )
? ?? ?
tagging
P (sn1 |wm1 )
? ?? ?
segmentation(7)
Finally, we employ the assumption that
P (wm1 |sn1 ) ? 1, since segments can only beconjoined in a certain order.7 So, instead of (5)
and (7) we end up with (8) and (9), respectively.
? argmax
?pi,sn1 ?
P (pi|sn1 )
? ?? ?
parsing
P (sn1 |wm1 )
? ?? ?
segmentation
(8)
? argmax
?pi,tn1 ,sn1 ?
P (pi|tn1 , sn1 )
? ?? ?
parsing
P (tn1 |sn1 )
? ?? ?
tagging
P (sn1 |wm1 )
? ?? ?
segmentation
(9)
4.2 Evaluation Metrics
The intertwined nature of morphology and syn-
tax in MH poses additional challenges to standard
parsing evaluation metrics. First, note that we can-
not use morphemes as the basic units for com-
parison, as the proposed segmentation need not
coincide with the gold segmentation for a given
sentence. Since words are complex entities that
7Since concatenated particles (conjunctions et al) appear
in front of the stem, pronominal and inflectional affixes at the
end of the stem, and derivational morphology inside the stem,
there is typically a unique way to restore word boundaries.
can span across phrases (see figure 2), we can-
not use them for comparison either. We propose
to redefine precision and recall by considering the
spans of syntactic categories based on the (space-
free) sequences of characters to which they corre-
spond. Formally, we define syntactic constituents
as ?i, A, j? where i, j mark the location of char-
acters. T = {?i, A, j?|A spans from i to j} and
G = {?i, A, j?|A spans from i to j} represent the
test/gold parses, respectively, and we calculate:8
Labeled Precision = #(G ? T )/#T (10)
Labeled Recall = #(G ? T )/#G (11)
4.3 Experimental Setup
Our departure point for the syntactic analysis of
MH is that the basic units for processing are not
words, but morphological segments that are con-
catenated together to form words. Therefore, we
obtain a segment-based probabilistic grammar by
training a Probabilistic Context Free Grammar
(PCFG) on a segmented and annotated MH cor-
pus (Sima?an et al, 2001). Then, we use exist-
ing tools ? i.e., a morphological analyzer (Segal,
2000), a part-of-speech tagger (Bar-Haim, 2005),
and a general-purpose parser (Schmid, 2000) ? to
find compatible morphological segmentations and
syntactic analyses for unseen sentences.
The Data The data set we use is taken from the
MH treebank which consists of 5001 sentences
from the daily newspaper ?ha?aretz? (Sima?an et
al., 2001). We employ the syntactic categories and
POS tag sets developed therein. Our data set in-
cludes 3257 sentences of length greater than 1 and
less than 21. The number of segments per sen-
tence is 60% higher than the number of words per
sentence.9 We conducted 8 experiments in which
the data is split to training and test sets and apply
cross-fold validation to obtain robust averages.
The Models Model I uses the morphological an-
alyzer and the POS tagger to find the most prob-
able segmentation for a given sentence. This is
done by providing the POS tagger with multiple
morphological analyses per word and maximizing
the sum ?tn1 P (tn1 , sn1 |wm1 ) (Bar-Haim, 2005, sec-tion 8.2). Then, the parser is used to find the most
8Covert definite article errors are counted only at the POS
tags level and discounted at the phrase-level.
9The average number of words per sentence in the com-
plete corpus is 17 while the average number of morphological
segments per sentence is 26.
52
probable parse tree for the selected sequence of
morphological segments. Formally, this model is
a first approximation of equation (8) using a step-
wise maximization instead of a joint one.10
In Model II we percolate the morphological am-
biguity further, to the lowest level of non-terminals
in the syntactic trees. Here we use the morpholog-
ical analyzer and the POS tagger to find the most
probable segmentation and POS tag assignment
by maximizing the joint probability P (tn1 , sn1 |wm1 )(Bar-Haim, 2005, section 5.2). Then, the parser
is used to parse the tagged segments. Formally,
this model attempts to approximate equation (9).
(Note that here we couple a morphological and
a syntactic decision, as we are looking to max-
imize P (tn1 , sn1 |wm1 ) ? P (tn1 |sn1 )P (sn1 |wm1 ) andconstrain the space of trees to those that agree with
the resulting analysis.)11
In both models, smoothing the estimated prob-
abilities is delegated to the relevant subcompo-
nents. Out of vocabulary (OOV) words are treated
by the morphological analyzer, which proposes
all possible segmentations assuming that the stem
is a proper noun. The Tri-gram model used for
POS tagging is smoothed using Good-Turing dis-
counting (see (Bar-Haim, 2005, section 6.1)), and
the parser uses absolute discounting with various
backoff strategies (Schmid, 2000, section 4.4).
The Tag-Sets To examine the usefulness of var-
ious morphological features shared with the pars-
ing task, we alter the set of morphosyntactic cate-
gories to include more fine-grained morphological
distinctions. We use three sets: Set A contains bare
POS categories, Set B identifies also definite nouns
marked for possession, and Set C adds the distinc-
tion between finite and non-finite verb forms.
Evaluation We use seven measures to evaluate
our models? performance on the integrated task.
10At the cost of incurring indepence assumptions, a step-
wise architecture is computationally cheaper than a joint one
and this is perhaps the simplest end-to-end architecture for
MH parsing imaginable. In the absence of previous MH pars-
ing results, this model is suitable to serve as a baseline against
which we compare more sophisticated models.
11We further developed a third model, Model III, which
is a more faithful approximation, yet computationally afford-
able, of equation (9). There we percolate the ambiguity all the
way through the integrated architecture by means of provid-
ing the parser with the n-best sequences of tagged morpho-
logical segments and selecting the analysis ?pi, tn1 , sn1 ? whichmaximizes the production P (pi|tn1 , sn1 )P (sn1 , tn1 |wm1 ). How-ever, we have not yet obtained robust results for this model
prior to the submission of this paper, and therefore we leave
it for future discussion.
String Labeled POS tags Segment.
Cover. Prec. / Rec. Prec. / Rec. Prec. / Rec.
Model I-A 99.2% 60.3% / 58.4% 82.4% / 82.6% 94.4% / 94.7 %
Model II-A 95.9% 60.7% / 60.5% 84.5% / 84.8% 91.3% / 91.6%
Model I-B 99.2 % 60.3% / 58.4% 81.6% / 82.3% 94.2% / 95.0%
Model II-B 95.7% 60.7% / 60.5% 82.8% / 83.5% 90.9% / 91.7%
Model I-C 99.2% 60.9% / 59.2% 80.4% / 81.1% 94.2% / 95.1%
Model II-C 95.9% 61.7% / 61.9% 81.6% / 82.3% 91.0% / 91.9%
Table 4: Evaluation Metrics, Models I and II
First, we present the percentage of sentences for
which the model could propose a pair of corre-
sponding morphological and syntactic analyses.
This measure is referred to as string coverage. To
indicate morphological disambiguation capabili-
ties we report segmentation precision and recall.
To capture tagging and parsing accuracy, we refer
to our redefined Parseval measures and separate
the evaluation of morphosyntactic categories, i.e.,
POS tags precision and recall, and phrase-level
syntactic categories, i.e., labeled precision and re-
call (where root nodes are discarded and empty
trees are counted as zero).12 The labeled cate-
gories are evaluated against the original tag set.
4.4 Results
Table 4 shows the evaluation scores for models I-A
to II-C. To the best of our knowledge, these are the
first parsing results for MH assuming no manual
interference for morphological disambiguation.
For all sets, parsing of tagged-segments (Model
II) shows improvement of up to 2% over pars-
ing bare segments? sequences (Model I). This indi-
cates that morphosyntactic information selected in
tandem with morphological segmentation is more
informative for syntactic analysis than segmenta-
tion alone. We also observe decreasing string cov-
erage for Model II, possibly since disambiguation
based on short context may result in a probable,
yet incorrect, POS tag assignment for which the
parser cannot recover a syntactic analysis. Cor-
rect disambiguation may depend on long-distance
cues, e.g., agreement, so we advocate percolating
the ambiguity further up to the parser.
Comparing the performance for the different tag
sets, parsing accuracy increases for models I-B/C
and II-B/C while POS tagging results decrease.
These results seem to contradict the common wis-
dom that performance on a ?complex? task de-
12Since we evaluate the models? performance on an inte-
grated task, sentences in which one of the subcomponents
failed to propose an analysis counts as zero for all subtasks.
53
pends on a ?simpler?, preceding one; yet, they sup-
port our thesis that morphological information or-
thogonal to syntactic categories facilitates syntac-
tic analysis and improves disambiguation capacity.
5 Discussion
Devising a baseline model for morphological and
syntactic processing is of great importance for the
development of a broad-coverage statistical parser
for MH. Here we provide a set of standardized
baseline results for later comparison while con-
solidating the formal and architectural underpin-
ning of an integrated model. However, our results
were obtained using a relatively small set of train-
ing data and a weak (unlexicalized) parser, due to
the size of the corpus and its annotated scheme.13
Training a PCFG on our treebank resulted in a
severely ambiguous grammar, mainly due to high
phrase structure variability.
To compensate for the flat, ambiguous phrase-
structures, in the future we intend to employ prob-
abilistic grammars in which all levels of non-
terminals are augmented with morphological in-
formation percolated up the tree. Furthermore,
the MH treebank annotation scheme features a set
of so-called functional features14 which express
grammatical relations. We propose to learn the
correlation between various morphological mark-
ings and functional features, thereby constraining
the space of syntactic structures to those which ex-
press meaningful predicate-argument structures.
Since our data set is relatively small,15 introduc-
ing orthogonal morphological information to syn-
tactic categories may result in severe data sparse-
ness. In the current architecture, smoothing is
handled separately by each of the subcomponents.
Enriched grammars would allow us to exploit mul-
tiple levels of information in smoothing the esti-
mated probabilities and to redistribute probability
mass to unattested events based on their similarity
to attested events in their integrated representation.
6 Conclusion
Traditional approaches for devising parsing mod-
els, smoothing techniques and evaluation metrics
are not well suited for MH, as they presuppose
13The lack of head marking, for instance, precludes the use
of lexicalized models a` la (Collins, 1997).
14SBJ for subject, OBJ for object, COM for complement,
etc. (Sima?an et al, 2001).
15The size of our treebank is less than 30% of the Arabic
Treebank, and less than 10% of the WSJ Penn Treebank.
separate levels of processing. Different languages
mark regularities in their surface structures in dif-
ferent ways ? English encodes regularities in word
order, while MH provides useful hints about gram-
matical relations in its derivational and inflectional
morphology. In the future we intend to develop
more sophisticated models implementing closer
interaction between morphology and syntax, by
means of which we hope to boost parsing accu-
racy and improve morphological disambiguation.
Acknowledgments I would like to thank Khalil
Sima?an for supervising this work, Remko Scha,
Rens Bod and Jelle Zuidema for helpful com-
ments, and Alon Itai, Yoad Winter and Shuly
Wintner for discussion. The Knowledge Cen-
ter for Hebrew Processing provided corpora and
tools, and Roy Bar-Haim provided knowledge and
technical support for which I am grateful. This
work is funded by the Netherlands Organization
for Scientific Research (NWO) grant 017.001.271.
References
Meni Adler and Dudi Gabai. 2005. MorphologicalAnalyzer and Disambiguator for Modern Hebrew.
Knowledge Center for Processing Hebrew.
Roy Bar-Haim. 2005. Part-of-Speech Tagging for He-brew and Other Semitic Languages. Master?s thesis,Technion, Haifa, Israel.
Eugene Charniak, Glenn Carroll, John Adcock, An-
thony R. Cassandra, Yoshihiko Gotoh, Jeremy Katz,Michael L. Littman, and John McCann. 1996. Tag-gers for Parsers. AI, 85(1-2):45?57.
Eugene Charniak. 2000. A Maximum-Entropy-
Inspired Parser. In Proceedings of NAACL 2000.
Michael Collins. 1997. Three Generative, LexicalisedModels for Statistical Parsing. In Proceedings of
ACL-EACL 1997.
Nizar Habash and Owen Rambow. 2005. Arabic Tok-
enization, Part-of-Speech Tagging and Morphologi-cal Disambiguation in One Fell Swoop. In Proceed-
ings of ACL 2005.
Helmut Schmid, 2000. LoPar: Design and Implemen-
tation. Institute for Computational Linguistics, Uni-versity of Stuttgart.
Erel Segal. 2000. A Probabilistic Morphological An-alyzer for Hebrew Undotted Texts. Master?s thesis,
Computer Science Department, Technion, Isreal.
Khalil Sima?an, Alon Itai, Yoad Winter, Alon Altman,and Noa Nativ. 2001. Building a Tree-Bank forModern Hebrew Text. In Traitement Automatique
des Langues, volume 42, pages 347?380.
54
