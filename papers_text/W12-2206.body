NAACL-HLT 2012 Workshop on Predicting and Improving Text Readability for target reader populations (PITR 2012)., pages 40?48,
Montre?al, Canada, June 7, 2012. c?2012 Association for Computational Linguistics
Making Readability Indices Readable
Sara Tonelli
FBK, Trento, Italy
satonelli@fbk.eu
Ke Tran Manh
Charles University, Prague, CR
ketranmanh@gmail.com
Emanuele Pianta
FBK, Trento, Italy
pianta@fbk.eu
Abstract
Although many approaches have been pre-
sented to compute and predict readability of
documents in different languages, the infor-
mation provided by readability systems often
fail to show in a clear and understandable way
how difficult a document is and which aspects
contribute to content readability. We address
this issue by presenting a system that, for a
given document in Italian, provides not only
a list of readability indices inspired by Coh-
Metrix, but also a graphical representation
of the difficulty of the text compared to the
three levels of Italian compulsory education,
namely elementary, middle and high-school
level. We believe that this kind of represen-
tation makes readability assessment more in-
tuitive, especially for educators who may not
be familiar with readability predictions via su-
pervised classification. In addition, we present
the first available system for readability as-
sessment of Italian inspired by Coh-Metrix.
1 Introduction
The task of readability assessment consists in quan-
tifying how difficult a text is for a reader. This kind
of assessment has been widely used for several pur-
poses, such as evaluating the reading level of chil-
dren and impaired persons and improving Web con-
tent accessibility for users with low literacy level.
While indices and methodologies for readabil-
ity assessment of English have been widely investi-
gated, and research on English readability has been
continuously progressing thanks to advances in psy-
cholinguistic research and in natural language pro-
cessing, only limited efforts have been made to ex-
tend current approaches to other languages. An
adaptation of the basic Flesch Index (Flesch, 1946)
exists for many languages, but only in few cases
more sophisticated approaches have been adopted,
taking into account recent studies on text cohesion,
readability and simplification.
With this work, we aim at bridging the gap be-
tween the standard approach to Italian readability
based on the Gulpease index (following the same
criteria of the Flesch Index) and the more advanced
approaches to readability currently available for En-
glish and based on psycholinguistic principles. In
particular, we present a set of indices for Ital-
ian readability covering different linguistics aspects,
from the lexical to the discourse level, which are in-
spired by Coh-Metrix (Graesser et al., 2004). We
make this analysis available online, but we differ-
entiate our service from that of Coh-Metrix1 in that
we provide a graphical representation of the aspects
affecting readability, comparing a document with
the average indices of elementary, middle and high-
school level texts. This makes readability analysis
really intuitive, so that a user can straightforwardly
understand how difficult a document is, and see if
some aspects (e.g. lexicon, syntax, discourse) affect
readability more than others.
Our research goals are: i) to analyze the adequacy
of the Gulpease index for discriminating between
the readability levels of texts used for teaching and
testing in the Italian school practice, ii) to implement
an adaptation of Coh-Metrix indices for Italian, iii)
to make the readability analysis available online and
1http://cohmetrix.memphis.edu
40
understandable to naive users.
2 Related work
The first formulas to automatically compute the dif-
ficulty of a text were devised for English, starting
from the Flesch Index (Flesch, 1946), followed by
the Gunning Fog (Gunning, 1952), the SMOG index
(McLaughlin, 1969) and the Fleisch-Kincaid (Kin-
caid et al., 1975). These metrics combine factors,
such as word and sentence length, that are easy to
compute and that should approximate the linguistic
elements that impact on readability. Similar indexes
have been proposed also for other languages such
as German (Bamberger and Vanecek, 1984), French
(Kandel and Moles, 1958) and Spanish (Huerta,
1959).
The first readability formula for Italian, the
Flesch-Vacca (Franchina and Vacca, 1986), was in-
troduced in the early seventies and was based on an
adaptation of the Flesch index (Flesch, 1946). How-
ever, it has been widely replaced by the Gulpease
index (Lucisano and Piemontese, 1988), which was
introduced in the eighties by the Gruppo Universi-
tario Linguistico Pedagogico (GULP) of the Univer-
sity of Rome. The Gulpease index takes into account
the length of a word in characters rather than in syl-
lables, which proved to be more reliable for assess-
ing the readability of Italian texts. The index ranges
from 0 (lowest readability) to 100 (maximum read-
ability).
In recent years, research on English readability
has progressed toward more sophisticated models
that take into account difficulty at syntactic, seman-
tic and discourse level thanks to advances in psy-
cholinguistic accounts of text processing (Graesser
et al., 2004) and to the availability of a wide range
of NPL tools (e.g. dependency and constituency
parsers, anaphora resolution systems, etc.) and re-
sources (e.g. WordNet). However, for many other
languages current approaches for readability assess-
ment still rely on few basic factors. A notable ex-
ception is the Coh-Metrix-PORT tool (Scarton et al.,
2009; Aluisio et al., 2010), which includes 60 read-
ability measures for Brazilian Portuguese inspired
by the Coh-Metrix (Graesser et al., 2004).
A different approach has been followed by the de-
velopers of the DeLite system for German (Glo?ckner
et al., 2006; von der Bru?ck et al., 2008): the tool
computes a set of indices measuring the linguistic
complexity of a document through deep parsing and
outputs a final readability score obtained by apply-
ing the k-nearest neighbor algorithm based on 3,000
ratings from 300 users.
As for Italian, the only work aimed at improving
on the performance of standard readability indices
has been proposed by Dell?Orletta et al. (2011), who
implement a set of lexical and morpho-syntactic fea-
tures to distinguish between normal and simplified
newspaper articles in a binary classification task.
Our work differs from their approach in that we
choose a different type of corpus for a different au-
dience (i.e. children with different proficiency levels
vs. adults with low literacy skills or mild cognitive
impairment). We also enrich their feature set in that
our indices capture also semantic and discourse as-
pects of a text. In this respect, we take advantage
of cognitive and psycholinguistic evidence support-
ing the idea behind Coh-Metrix that high textual co-
herence and cohesion result in improved readability
with any type of readers (Beck et al., 1984s; Cataldo
and Oakhill, 2000; Linderholm et al., 2000), and that
discourse connectives and spatio-temporal informa-
tion in a text strongly contribute to cohesion.
3 The corpus
Our goal is to develop a system that can be used in
real scenarios, for instance by teachers who want to
assess if a text is understandable by children in a
certain class. Therefore, we avoid collecting a cor-
pus with documents showing different degrees of
simplification according to a ?controlled? scenario.
This strategy was adopted for instance by Crossley
et al. (2011), who compared different readability in-
dices using news texts manually simplified into ad-
vanced, intermediate and beginning difficulty level.
Also the experiments on readability assessment of
Portuguese texts by Scarton et al. (2009) were con-
ducted on a corpus of news articles manually simpli-
fied by a linguist according to a natural and a strong
simplification level.
Our approach is different in that we take texts
used for teaching and comprehension exercises in
Italian schools and divide them into three classes,
according to the class level in which they are em-
41
Class 1 Class 2 Class 3
(63 docs) (55 docs) (62 docs)
Doc. length 530 776 1085
in tokens (? 273) (? 758) (? 1152)
Gulpease 55.92 53.88 50.54
(? 6.35) (? 6.13) (? 6.98)
Table 1: Corpus statistics. All values are averaged. StDev
is reported between parenthesis.
ployed. This means that in Class 1 we collect
all documents written for children in elementary
schools (aged 6-10), in Class 2 we collect texts
for children in middle schools (aged 11-13), and in
Class 3 we gather documents written for teenagers
in high schools (aged 14-18). The classes contain
respectively 63, 55 and 62 documents.
As shown in Table 1, the average length of the
documents increases with the school level. How-
ever, the single documents show high variability,
especially those in Class 3. Texts have been se-
lected so as to represent the most common genres
and knowledge domains in school texts. Thus, the
corpus contains a balanced selection of both narra-
tive and expository texts. The latter belong mostly to
the following domains: history, literature, biology,
physics, chemistry, geography and philosophy. The
corpus includes also all official text comprehension
tests used in Italy in the INVALSI school proficiency
evaluation campaign2.
4 Readability assessment based on
Gulpease
We first analyze the behaviour of the Gulpease in-
dex in our corpus, in order to assess if this measure
is adequate for capturing the readability of the doc-
uments. We compute the index by applying to each
document the standard formula:
Gulpdoc = 89 +
(300 ? #sentsdoc) ? (10 ? #charsdoc)
#tokensdoc
Average Gulpease and standard deviation for each
class are reported in Table 1.
2National Institute for the Evaluation of the Educational
System by the Ministry of Research and University, http:
//www.invalsi.it/invalsi/index.php
Fig. 1 shows the distribution of the Gulpease in-
dex in the corpus. On the x axis the document id is
reported, with document 1?63 belonging to Class 1
(elementary), document 64?118 to Class 2 (middle)
and 119?180 to Class 3 (high school). On the y axis,
the Gulpease index is reported, ranging from 41 (i.e.
the lowest readability level in the corpus) to 87 (i.e.
highest readability).
Although the highest readability score is obtained
by a document of Class 1, and the lowest scores
concern documents in Class 3, the three classes do
not seem to be separable based solely on Gulpease.
In particular, documents in Class 2, written for stu-
dents in middle school, show scores partly overlap-
ping with Class 1 and partly with Class 3. Further-
more, the great majority of the documents in the cor-
pus have a Gulpease index included between 50 and
60 and the average Gulpease does not differ consis-
tently across the three classes (Table 1).
Figure 1: Distribution of Gulpease index in the corpus.
Document id on x axis, and Gulpease on y axis
For children in the elementary school, a text with
a Gulpease index between 0 and 55 usually corre-
sponds to the frustration level. For children in the
middle school, the frustration level is reached with a
Gulpease index between 0 and 35. For high-school
students, this level is reached with Gulpease being
between 0 and 10.3
3More information on how to interpret Gulpease for each
of the three classes is reported at http://www.eulogos.
net/ActionPagina_1045.do
42
4.1 Coh-Metrix for English
Coh-Metrix is a computational tool available on-
line at http://cohmetrix.memphis.edu that
can analyze an English document and produce a list
of indices expressing the cohesion of the text. These
indices have been devised based on psycholinguistic
studies on the mental representation of textual con-
tent (McNamara et al., 1996) and address various
characteristics of explicit text, from lexicon to syn-
tax, semantics and discourse, that contribute to the
creation of this representation. Although the tool re-
lies on widely used NLP techniques such as PoS tag-
ging and parsing, there have been limited attempts to
employ it in studies on automatic assessment of text
cohesion. Nevertheless, recent works in the NLP
community investigating the impact of entity grids
(Barzilay and Lapata, 2008) or of discourse relations
(Pitler and Nenkova, 2008) on text coherence and
readability go in the same direction as research on
Coh-Metrix, in that they aim at identifying the lin-
guistic features that best express readability at syn-
tactic, semantic and discourse level.
The indices belonging to Coh-Metrix are divided
into five main classes:
? General Word and Text Information: The in-
dices in this class capture the correlation be-
tween brain?s processing time and word-level
information. For example, many syllables in a
word or many words in a sentence are likely to
make a document more difficult for the brain to
process it. Also, if the type/token ratio is high,
the text should be more difficult because there
are many unique words to be decoded.
? Syntactic Indices: The indices in this class as-
sess syntactic complexity and the frequency of
particular syntactic constituents in a text. The
intuition behind this class is that high syntactic
complexity makes a text more difficult to pro-
cess, lowering its readability, because it usually
implies syntactic ambiguity, structural density,
high number of embedded constituents.
? Referential and Semantic Indices: These in-
dices assess the negative impact on readability
of cohesion gaps, which occur when the words
in a sentence do not connect to other sentences
in the text. They are based on coreference and
anaphoric chains as well as on semantic simi-
larity between segments of the same document
exploiting Latent Semantic Analysis (LSA).
? Indices for Situation Model Dimensions: The
indices in this class express the degree of com-
plexity of the mental model evoked by a doc-
ument (Dijk and Kintsch, 1983) and involves
four main dimensions: causality, intentionality,
time and space.
? Standard readability indices: They comprise
traditional indices for readability assessment
including Flesch Reading Ease and Flesch Kin-
caid Grade Level.
Although the developers of Coh-Metrix claim that
the internal version of the tool includes hundreds of
measures, the online demo shows only 60 of them.
This is partly due to the fact that some metrics are
computed using resources protected by copyright,
and partly because the whole framework is still un-
der development. We refer to these 60 metrics in or-
der to implement the Coh-Metrix version for Italian,
that we call Coease.
4.2 Coease: Coh-Metrix for Italian
In the Coh-Metrix adaptation for Italian, we follow
as much as possible the description of the single in-
dices reported on the official Coh-Metrix documen-
tation. However, in some cases, not all implementa-
tion details are given, so that we may have slightly
different versions of single indices. Besides, one
set of indices is based on the MRC Psycholinguis-
tic Database (Wilson, 2003), a resource including
around 150,000 words with concreteness ratings col-
lected through psycholinguistic experiments, which
is not available for Italian. In general terms, how-
ever, we try to have some indices for each of the
classes described in Section 4.1, in order to repre-
sent all relevant aspects of text cohesion.
The list of all indices is reported in Table 2. In-
dices from 1 to 6 capture some information about the
length of the documents in terms of syllables, words,
sentences and paragraphs. Syllables are computed
using the Perl module Lingua::IT::Hyphenate4.
4http://search.cpan.org/?acalpini/
Lingua-IT-Hyphenate-0.14/
43
Indices from 7 to 10 focus on familiarity of con-
tent words (verbs, nouns, adjectives and adverbs)
measured as their frequency in a reference corpus.
While in English the frequency list was the CELEX
database (Baayen et al., 1995), for Italian we ex-
tracted it from the dump of Italian Wikipedia5. The
idea behind these indices is that unfamiliar words or
technical terminology should have a low frequency
in the reference corpus, which is supposed to be
a general corpus representing many domains. In-
dex 8 is the logarithm of raw frequency of content
words, because logarithm proved to be compatible
with reading time (Haberlandt and Graesser, 1985).
Index 9 is obtained by computing first the lowest fre-
quency score among all the content words in each
sentence, and then calculating the mean. Index 10 is
obtained by computing first the lowest log frequency
score among all content words in each sentence, and
then calculating the mean. Content words were ex-
tracted by running the TextPro NLP suite for Italian
(Pianta et al., 2008)6 and keeping only words tagged
with one of WordNet PoS, namely v, a, n and r.
Indices 11 and 12 compute the abstractness of
nouns and verbs by measuring the distance between
the WordNet synset containing the lemma (most fre-
quent sense) and the root. Then, the mean distance
of all nouns and verbs in the text is computed. We
obtain this index using MultiWordNet (Pianta et al.,
2002), the Italian version of WordNet, aligned at
synset level with the English one.
Indices from 13 to 17 measure the syntactic com-
plexity of sentences based on parsing output. Indices
13-15 are computed after parsing each sentence with
the Italian version of Berkeley constituency-based
parser (Lavelli and Corazza, 2009)7. NP incidence
is the incidence of atomic NPs (i.e. not containing
any other NPs) per 1000 words. Higher-level con-
stituents index is the mean distance between each
terminal word in the text and the parse tree root.
Main verb information needed for computing index
16 is obtained by parsing each sentence with Malt
parser for Italian (Lavelli et al., 2009) and taking the
sentence root as main verb. The index accounts for
5http://it.wikipedia.org
6TextPro achieved 95% PoS tagging accuracy at Evalita
2009 evaluation campaign for Italian tools.
7The parser achieved 84% F1 at Evalita 2011 evaluation
campaign for Italian tools.
the memory load needed by a reader to understand a
sentence. Index 17 is calculated by comparing each
token to a manual list of negations and computing
the total number of negations per 1000 words.
Indices 18 and 19 are computed again using
TextPro and the output of Berkeley parser. Index 18
is the ratio of words labelled as pronouns to the in-
cidence of all NPs in the text. High pronoun density
implies low readability, because it makes referential
cohesion less explicit.
Indices from 20 to 29 capture the cohesion of
sentences by taking into account different types of
connectives. In order to compute them, we manu-
ally create lists of connectives divided into additive,
causal, logical and temporal. Then, for each list, we
identify positive (i.e. extending events) and negative
(i.e. ceasing to extend expected events) connectives.
For instance, ?inoltre? (?moreover?) is a positive ad-
ditive connective, while ?ma? (?but?) is a negative ad-
ditive connective. We further compute the incidence
of conditional operators by comparing each token to
a manual list. In order to create such lists, we stick
to their English version by first translating them into
Italian and then manually adding some missing con-
nectives. However, this does not avoid ambiguity,
since some connectives with high frequency can ap-
pear in more than one list, for instance ?e? (?and?),
which can be both temporal and additive.
Indices 30 and 31 capture syntactic similarity of
sentences and are based on the assumption that a
document showing high syntactic variability is more
difficult to understand. This index computes the pro-
portion of intersecting nodes between two syntactic
trees by looking for the largest common subtree, so
that every node except terminal node has the same
production rule in both trees. Index 32 calculates
the proportion of adjacent sentences that share at
least one argument expressed by a noun or a pro-
noun, while indices 33 and 34 compute this propor-
tion based on stems and content words. Stems are
obtained by applying the Snowball stemmer8 to the
lemmatized documents.
Indices 35?40 capture the situation model dimen-
sions of the text. Causal and intentional cohesion
corresponds to the ratio between causal or inten-
tional particles (i.e. connectives and adverbs) and
8http://snowball.tartarus.org/
44
causal or intentional verbs. The rationale behind
this is that a text with many causal verbs and few
causal particles is less readable because the con-
nections between events is not explicitly expressed.
Since no details where given on how these particles
and verbs were extracted for English, we devise our
own methodology. First, we produce manual lists
of causal and intentional particles in Italian. As for
causal verbs, we first select all synsets in the En-
glish WordNet containing ?cause to? in their glosses,
and then obtain the corresponding version in Ital-
ian through MultiWordNet. Intentional verbs are
obtained by first extracting all verbs from English
WordNet that belong to the following categories:
cognition, communication, competition, consump-
tion, contact, creation, emotion, motion and percep-
tion, and then mapping them to the Italian corre-
sponding verbs in MultiWordNet. Temporal cohe-
sion is computed as the average of repetitions of
tense and aspect in the document. Repetitions are
calculated by mapping the output of TextPro mor-
phological analysis of verbs to the labels considered
for tense, i.e. past, present and future, and for as-
pect, i.e. static, completed and in progress. Spa-
tial cohesion reflects the extent to which the sen-
tences are related by spatial particles or relations,
and corresponds to the mean of location and mo-
tion ratio score. Location score is the incidence of
locative prepositions (LSP) divided by LPS plus the
incidence of location nouns. Location nouns are ob-
tained from WordNet and from the Entity Recog-
nizer of TextPro. Motion score is the incidence of
motion particles (MSP) divided by MSP plus the in-
cidence of motion verbs. Motion verbs information
is extracted from WordNet as well. As for motion
and locative particles, we first create a manual list,
which however contains particles that can express
both location and motion (for instance ?in?). The dis-
tinction between the two types of particles is based
on the dependency structure of each sentence: if the
particle is headed by a motion verb and dominates
a location noun, then we assume that it is a motion
particle. Instead, if it heads a location noun but is
not dominated by a motion verb, then it is a locative
particle. We are aware of the fact that this selection
process is quite coarse-grained and can be biased by
wrong dependency structures, ambiguity of nouns
and verbs and limited extension of Italian WordNet.
However, it is a viable solution to approximate the
information conveyed by the corresponding indices
in English, given that no clear explanation for their
implementation is given.
4.3 Additional indices
We implement also three additional indices that are
not part of Coh-Metrix for English. They are re-
ported in Table 2 with the ID 41?46.
Indices 41 and 42 are based on the Basic Ital-
ian Vocabulary (de Mauro, 2000). This resource
includes a list of 7,000 words, which were manu-
ally classified as highly familiar to native speakers of
Italian. We introduce these indices because past ex-
periments on Italian readability by Dell?Orletta et al.
(2011) showed that, by combining this information
with some basic features such as word and sentence
length, it was possible to achieve 0.95 accuracy in
a binary classification task aimed at distinguishing
standard newspaper articles from simplified articles
for L2 readers. Index 41 corresponds to the percent-
age of tokens whose base form is listed in the Basic
Italian Vocabulary, while index 42 is the percentage
of (unique) lemmas. The latter is the same feature
implemented by Dell?Orletta et al. (2011).
Index 43 is Gulpease, computed following the for-
mula reported in Section 4. We add it to our in-
dex list in line with Coh-Metrix, which includes also
standard readability metrics such as Flesch-Reading
Ease and Flesch-Kincaid.
5 The Online System
The Coease indices have been made available
online through a Web interface at http://
readability.fbk.eu. This allows users to
copy and paste a document in the text field and to
compute all available indices, similar to the func-
tionalities of the English Coh-Metrix tool. We have
normalized each index so that it is comprised be-
tween -1 and +1 using the scaling function available
in LIBSVM (Chang and Lin, 2011). Low scores ex-
press low readability for the given index while high
scores correspond to highly readable texts.
In order to identify the indices that are most cor-
related with the readability levels, we computed
Pearson correlation coefficients between each index
and the three classes, similar to Pitler and Nenkova
45
(2008). The ten most correlated indices are marked
with (*) in Table 2. It is interesting to note that 6
out of 10 indices are not part of the standard Coh-
Metrix framework, and account for lexical informa-
tion. In all cases, correlation is moderate, being
0.3 ? r ? 0.6.
Figure 2: Graphical representation of readability as plot-
ted by the Coease web interface. Index id on x axis, and
normalized value on y axis
Coease is designed in order to enable users to
compute readability of a given document and com-
pare it with the average values for the three classes in
our reference corpus (Section 3). Therefore, the av-
erage normalized score of each index for each class
has been computed based on the corpus. Then, every
time a new document is analyzed, the output scores
are plotted together with the average scores for each
of the three classes. This allows a user to compare
different aspects of the current document, such as
the lexicon or the syntax, with the averages of the
three classes. For example, a user may discover that
a document is highly complex from the lexical point
of view, since its lexical indices are in line with those
of high-school texts. However, its syntax may be
rather simple, having syntax-based indices similar to
those of elementary textbooks. This kind of compar-
ison provides information that are generally not cap-
tured via supervised classification. If we trained a
classifier using the indices as features, we would be
able to assign a new document to elementary, mid-
dle or high-school level, but a naive user would not
be able to understand how the single indices affect
classification. Besides, this graphical representation
allows a user to identify documents that should not
be classified into a specific class, because its indices
fall into different classes. Furthermore, we can de-
tect documents with different degrees of readability
within each class.
As an example, we report in Fig. 2 the graphical
representation returned by the system after analyz-
ing an article taken from ?Due Parole?9 (labeled as
?current?), an online newspaper for adult L2 learn-
ers. The scores are compared with the average val-
ues of the 10 most correlated indices, which are re-
ported on the x axis in the same order as they are
described in Table 2. According to the plot, the ar-
ticle has a degree of readability similar to the ?high-
school? class, although some indices show that its
readability is higher (see for instance the index n. 9,
i.e. lexical overlap with Class 3 documents).
The current system version returns only the 10
most correlated indices for the sake of clarity. How-
ever, it easy configurable in order to plot all indices,
or just a subset selected by the user.
6 Conclusions and Future Work
We present Coease, a system for readability assess-
ment of Italian inspired by Coh-Metrix principles.
This set of indices improves on Gulpease index in
that it takes into account discourse coherence, syn-
tactic parsing and semantic complexity in order to
account for the psycholinguistic and cognitive rep-
resentations involved in reading comprehension.
We make Coease available through an online in-
terface. A user can easily analyze a document and
compare its readability to three difficulty levels, cor-
responding to average elementary, middle and high-
school readability level. The graphical representa-
tion returned by the system makes this comparison
straightforward, in that the indices computed for the
current document are plotted together with the 10
most correlated indices in Coease.
In the future, we will analyze the reason why lex-
ical indices are among the most correlated ones with
the three classes. The lower impact of syntactic in-
formation, for instance, could be affected by parsing
performance. However, this could depend also on
how syntactic indices are computed in Coh-Metrix:
9http://www.dueparole.it/
46
we will investigate whether alternative ways to cal-
culate the indices may be more appropriate for Ital-
ian texts.
In addition, we plan to use the indices as features
for predicting the readability of unseen texts. In a
classification setting, it will be interesting to see if
the 10 best indices mentioned in the previous sec-
tions are also the most predictive features, given that
some information may become redundant (for in-
stance, the Gulpease index).
Acknowledgments
The work described in this paper has been partially
funded by the European Commission under the con-
tract number FP7-ICT-2009-5, Terence project.
References
