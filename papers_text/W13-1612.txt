Proceedings of the 4th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis, pages 87?93,
Atlanta, Georgia, 14 June 2013. c?2013 Association for Computational Linguistics
Bilingual Experiments on an Opinion Comparable Corpus
E. Mart??nez-Ca?mara
SINAI research group
University of Jae?n
E-23071, Jae?n (Spain)
emcamara@ujaen.es
M. T. Mart??n-Valdivia
SINAI research group
University of Jae?n
E-23071, Jae?n (Spain)
maite@ujaen.es
M. D. Molina-Gonza?lez
SINAI research group
University of Jae?n
E-23071, Jae?n (Spain)
mdmolina@ujaen.es
L. A. Uren?a-Lo?pez
SINAI research group
University of Jae?n
E-23071, Jae?n (Spain)
laurena@ujaen.es
Abstract
Up until now most of the methods published
for polarity classification are applied to En-
glish texts. However, other languages on the
Internet are becoming increasingly important.
This paper presents a set of experiments on
English and Spanish product reviews. Us-
ing a comparable corpus, a supervised method
and two unsupervised methods have been as-
sessed. Furthermore, a list of Spanish opinion
words is presented as a valuable resource.
1 Introduction
Opinion Mining (OM) is defined as the computa-
tional treatment of opinion, sentiment, and subjec-
tivity in text. The OM discipline combines Natural
Language Processing (NLP) with data mining tech-
niques and includes a large number of tasks (Pang
and Lee, 2008). One of the most studied tasks
is polarity classification of reviews. This task fo-
cuses on determining which is the overall sentiment-
orientation (positive or negative) of the opinions
contained within a given document.
Two main appraoches are followed by researches
to tackle the OM task. On the one hand, the Ma-
chine Learning (ML) approach (also known as the
supervised approach) is based on using a collection
of data to train the classifiers (Pang et al, 2002). On
the other hand, (Turney, 2002) proposed an unsuper-
vised method based on the semantic orientation of
the words and phrases in the reviews. Both method-
ologies have their advantages and drawbacks. For
example, the ML approach depends on the avail-
ability of labelled data sets (training data), which
in many cases are impossible or difficult to achieve,
partially due to the novelty of the task. On the
contrary, the unsupervised method requires a large
amount of linguistic resources which generally de-
pend on the language, and often this approach ob-
tains lower recall because it depends on the presence
of the words comprising the lexicon in the document
in order to determine the polarity of opinion.
Although opinions and comments on the Inter-
net are expressed in any language, most of research
in OM is focused on English texts. However, lan-
guages such as Chinese, Spanish or Arabic, are ever
more present on the web. Thus, it is important to
develop resources for these languages. The work
presented herein is mainly motivated by the need
to develop polarity classification systems and re-
sources in languages other than English. We present
an experimental study over the SFU Review Corpus
(Taboada, 2008), a comparable corpus that includes
opinions of several topics in English and in Span-
ish. We have followed this line of work: Firstly,
we have taken as baseline a supervised experiment
using Support Vector Machine (SVM). Then we
have tried different unsupervised strategies. The first
one uses the method presented in (Montejo-Ra?ez et
al., 2012). This approach combines SentiWordNet
scores with a random walk analysis of the concepts
found in the text over the WordNet graph in order to
determine the polarity of a tweet. This method ob-
tained very good results in short texts (tweets) and
so, we want to try it using larger document. Al-
though we have carried out several experiments us-
ing different parameters and modifications, the re-
sults are not as good as we hoped. For this, we have
87
tried a very simple experiment using a list of opin-
ionated words in order to classify the polarity of the
reviews. For English we have used the Bin Liu En-
glish lexicon (BLEL) (Hu and Liu, 2004) and for
Spanish we have automatically translated the BLEL
lexicon into Spanish. In addition, we have also
checked manually and improved the Spanish list.
The paper is organized as follows: Section 2
briefly describes papers that study non-English sen-
timent polarity classification and, specifically work
related to Spanish OM. In Section 3 we explain
the resources used in the unsupervised methods as-
sessed. Section 4 presents the experiments carried
out and discusses the main results obtained. Finally,
we outline conclusions and further work.
2 Related Work
There are some interesting papers that have stud-
ied the problem using non-English collections. De-
necke (2008) worked on German comments col-
lected from Amazon. These reviews were translated
into English using standard machine translation soft-
ware. Then the translated reviews were classified as
positive or negative, using three different classifiers:
LingPipe7, SentiWordNet (Baccianella et al, 2010)
with classification rule, and SentiWordNet with ma-
chine learning. Ghorbel and Jacot (2011) used a cor-
pus with movie reviews in French. They applied a
supervised classification combined with SentiWord-
Net in order to determine the polarity of the reviews.
In (Rushdi-Saleh et al, 2011a) a corpus of movies
reviews in Arabic annotated with polarity was pre-
sented and several supervised experiments were per-
formed. Subsequently, they generated the parallel
EVOCA corpus (English version of OCA) by trans-
lating the OCA corpus automatically into English.
The results showed that they are comparable to other
English experiments, since the loss of precision due
to the translation process is very slight, as can be
seen in (Rushdi-Saleh et al, 2011b).
Regarding Spanish, there are also some interest-
ing studies. Banea et al (2008) showed that au-
tomatic translation is a viable alternative for the
construction of resources and tools for subjectivity
analysis in a new target language. In (Brooke et
al., 2009) several experiments are presented deal-
ing with Spanish and English resources. They con-
clude that although the ML techniques can provide
a good baseline performance, it is necessary to inte-
grate language-specific knowledge and resources in
order to achieve an improvement. Cruz et al (2008)
manually recollected the MuchoCine (MC) corpus
to develop a sentiment polarity classifier based on
the semantic orientation of the phrases and words.
The corpus contains annotated Spanish movie re-
views from the MuchoCine website. The MC cor-
pus was also used in (Mart??nez-Ca?mara et al, 2011)
to carry out several experiments with a supervised
approach applying different ML algorithms. Finally,
(Mart??n-Valdivia et al, 2012) also dealt with the MC
corpus to present an experimental study of super-
vised and unsupervised approaches over a Spanish-
English parallel corpus.
3 Resources for the unsupervised methods
In order to tackle the unsupervised experiments we
have chosen several well-known resources in the
OM research community. In addition, we have also
generated a new Spanish linguistic resource.
Comparable corpora are those consisted of texts
in two or more languages about the same topic, but
they are not the translated version of the texts in the
source language. For the experiments, we chose the
comparable corpus SFU Review Corpus. The SFU
Review Corpus is composed of reviews of prod-
ucts in English and Spanish. The English version
(Taboada and Grieve, 2004) has 400 reviews (200
positive and 200 negative) of commercial products
downloaded in 2004 from the Epinions web which
are divided into eight categories: books, cars, com-
puters, cookware, hotels, movies, music and phones.
Each category includes 25 positive reviews and 25
negative reviews. Recently, the authors of SFU Re-
view Corpus have made available the Spanish ver-
sion of the corpus1. The Spanish reviews are divided
into the same eight categories, and also each cate-
gory has 25 positive and 25 negative reviews.
In the unsupervised experiments we have anal-
ysed the performance of two approaches, the first
one is based on lexicon and the other one in a graph-
based method. We have selected the BLEL lexicon
(Hu and Liu, 2004) to carry out the experiment based
1http://www.sfu.ca/?mtaboada/download/
downloadCorpusSpa.html
88
on lexicon on the English version of the corpus. The
lexicon is composed by 6,787 opinion words that
indicate positive or negative opinions, which 2,005
are positive and 4,782 are negative. With the aim of
following the same approach over the Spanish ver-
sion, firstly we have translated the BLEL lexicon
with the Reverso machine translator, and them we
have checked manually the resultant list. The Span-
ish Opinion Lexicon2 (SOL) is composed by 2,509
positive and 5,627 negative words, thus in total SOL
has 8,136 opinion words. If a review has more or
the same positive words than negative the polarity is
positive, otherwise negative.
The graph-based method is a modular system
which is made up of different components and
technologies. The method was first presented in
(Montejo-Ra?ez et al, 2012) with a good perfor-
mance over a corpus of English tweets. The main
idea of the algorithm is to represent each review as a
vector of polarity scores of the senses in the text and
senses related to the context of the first ones. Be-
sides, the polarity score is weighted with a measure
of importance. Taking a review as input, the work-
flow of the algorithm is the following:
1. Disambiguation: To get the corresponding
sense of the words that are in the text is required
to disambiguate them. Thus, the output of this
first step is one unique synset from WordNet3
(Miller, 1995) for each term. The input of the
algorithm is the set of words with a POS-Tag
allowed in WordNet. The graph nature of the
WordNet structure is the basis for the UKB dis-
ambiguation method proposed by (Agirre and
Soroa, 2009). The UKB disambiguation algo-
rithm apply PageRank (Page et al, 1999) on
the WordNet graph starting from term nodes,
where each term node points to all its possible
senses or synsets. The output of the process is a
ranked list of synsets for each input word, and
the highest rank synset is chosen as candidate
sense.
For the Spanish disambiguation process we
have chosen the Spanish WordNet version
offered by the project Multilingual Central
2http://sinai.ujaen.es/wiki/index.php/
SOL
3We have used the 3.0 release of WordNet.
Repository (MCR) (Gonzalez-Agirre et al,
2012). The Spanish WordNet of MCR has
38,702 synsets while WordNet has 117,659, i.e.
the MCR covers the 32.89% of WordNet.
2. PPV: Once the synsets for the reviews are com-
puted, the following step performs a second run
of PageRank described in (Agirre and Soroa,
2009). Using the Personalized PageRank, a
set of Personalized PageRank Vectors (PPVs)
is obtained. This vector is a list of synsets with
their ranked values. The key of this approach
is to take from this vector additional synsets
not related directly to the set of synsets disam-
biguated in the first step. The result is a longer
list of pair <synset, weight> where the weight
is the rank value obtained by the propagation of
the weights of original synsets across theWord-
Net graph.
3. Polarity: The following step is to calculate the
polarity score. For this purpose it is necessary a
semantic resource to take the polarity score for
each retrieved synset in the two previous steps.
The semantic resource selected is SentiWord-
Net (Baccianella et al, 2010). According to
these values, the three following equations have
been applied to obtain the final polarity value:
p(r) = 1
|r|
?
s?r
1
|s|
?
i?s
(p+i ? p
?
i )wi (1)
p(r) = 1
|r|
?
s?r
1
|s|
?
i?s
f(pi)
f(pi) =
{
p+i if p
+
i > p
?
i
p?i if p
+
i <= p
?
i
(2)
p(r) = 1
|r|
?
s?r
1
|s|
?
i?s
f(pi)
f(pi) =
?
?
?
?
?
?
?
1 if i ? [positive words]
?1 if i ? [negative words]
p+i if p
+
i > p
?
i
p?i if p
+
i <= p
?
i
(3)
where p(r) is the polarity of the review; |r| is
the number of sentences in the review r; s is a
sentence in r, being itself a set of synsets; i is a
synset in s; p+i is the positive polarity of synset
i; p?i is the negative polarity of synset i and wi
is the weight of synset i.
89
4 Experiments and Results
Systems based on supervised approach are the most
successfully in the OM literature. Therefore, we be-
gan the set of experiments applying a machine learn-
ing algorithm to the SFU corpus. Also, we have car-
ried out a set of unsupervised experiments following
a lexicon-based approach and a graph-based algo-
rithm. For all the experiments the evaluation mea-
sures have been: precision, recall, F1 and Accuracy
(Acc.). The validation approach followed for the
supervised approach has been the well-known 10-
cross-validation.
The algorithm chose for the supervised experi-
ments is SVM (Cortes and Vapnik, 1995) because
is one of the most successfully used in OM. Lib-
SVM4 (Chang and Lin, 2011) was the implementa-
tion selected to carry out several experiments using
SVM. We have evaluated unigrams and bigrams as
minimum unit of information. Also, the influence of
stemmer have been assessed. The weight scheme for
representing each unit of information is TF-IDF. The
same configuration has been applied to English and
Spanish version of SFU corpus. Table 1 and Table
2 show the results for English version and Spanish
version respectively.
Precision Recall F1 Acc.
Unigrams 79.07% 78.50% 78.78% 78.50%
Unigrams
& stemmer 79.82% 79.50% 79.66% 79.50%
Bigrams 78.77% 78.25% 78.51% 78.25%
Bigrams
& stemmer 80.64% 80.25% 80.44% 80.25%
Table 1: SVM results for English SFU corpus
Precision Recall F1 Acc.
Unigrams 73.65% 73.25% 73.45% 73.25%
Unigrams
& stemmer 74.10% 73.75% 73.92% 73.75%
Bigrams 74.02% 73.50% 73.76% 73.50%
Bigrams
& stemmer 73.90% 73.50% 73.70% 73.50%
Table 2: SVM results for Spanish SFU corpus
The results show one of the differences between
the works published in SA, the use of unigrams or
4http://www.csie.ntu.edu.tw/?cjlin/
libsvm/
bigrams. In (Pang et al, 2002) is asserted that the
reviews should be represented with unigrams, but
in (Dave et al, 2003) bigrams and trigrams outper-
formed the unigrams features. In our case, regarding
the results reached without using a stemmer, the use
of unigrams as minium unit of information achieves
better result than the use of bigrams when the lan-
guage is English, but bigrams outperform unigrams
when the texts are in Spanish. On the other hand, the
best result both in English and Spanish is reached
when a stemmer algorithm is applied. So, one con-
clusion of the supervised experiments is that the use
of stemmer enhances the polarity classification in re-
views. The following conclusion is that in English
the presence of pair of words separate better the pos-
itive and negative classes, while in Spanish the use
of unigrams is enough to classify the polarity when
a stemmer algorithm is used.
The set of unsupervised experiments begins with
a lexicon-based method. The method consists of find
the presence in the reviews of opinion words which
are included in a lexicon of opinion words. BLEL
has been used for the English reviews, and SOL for
the Spanish reviews. The results are presented in
Table 3.
Precision Recall F1 Acc.
BLEL lexicon 69.56% 64.42% 66.89% 64.75%
SOL 66.91% 61.94% 64.33% 62.25%
Table 3: Lexicon-based approch results
The differences in the results between the En-
glish and Spanish version of SFU Review Corpus
are lower when a lexicon is used instead of a ma-
chine learning algorithm is applied. In a lexicon-
based method is very important the recall value, be-
cause it indicates whether the set of words covers
the vocabulary of the corpus. The recall value is
upper 60% regarding English and Spanish, although
is not an excellent value, is good for the two small
and independent-domain lexicons. In the case of
Spanish the supervised method is only 15.59% bet-
ter regarding Accuracy. The results show that may
be considered the use of a lexicon-based method for
Spanish due to the few computer resources needed.
Moreover, it must be highlighted the performance of
SOL, so it is the first time that this resource is used
to resolve a polarity classification problem.
90
The graph-based method has been described as a
modular and flexible algorithm. Due to its modular
nature we have carried out several experiments:
1. wnet ant+ eq1 [en|es]: As baseline, we have
run the algorithm with the same configuration
as is described in (Montejo-Ra?ez et al, 2012),
i.e. using the equation 1.
2. wnet ant- eq1 [en|es]: We have assessed the
algorithm with a version of WordNet without
the antonym relation.
3. wnet ant+ eq2 [en|es]: The equation to calcu-
late the polarity is 2
4. wnet ant- eq2 [en|es]: The same as
wnet ant+ eq2 [en|es] but the antonym
relation is not considered.
5. wnet ant+ eq3 [en|es]: The same as
wnet ant+ eq2 [en|es] but the equation 3
is used to calculate the polarity.
6. wnet ant- eq3 [en|es]: The same as
wnet ant+ eq3 [en|es] but the antonym
relation is not considered.
Furthermore, one of the key elements of the al-
gorithm is the possibility of setting the number of
related synsets to get from WordNet. In all of the ex-
periments we have evaluated from an expansion of 0
sysnsets to 100 synsets. In Table 4 are the best re-
sults obtained with the English and the Spanish ver-
sion of SFU corpus.
Regarding the results, only for English is evident
that the selection of the right equation to calculate
the polarity score is important. On the other hand,
the initial assumption that the relation of antonym
could complicate the calculation of the final polarity,
and the use of a graph of WordNet without antonym
could enhance the results cannot be demonstrated
because these experiments have reached the same
results as the obtained ones using the graph with
the relation of antonym. The equation 3, which in-
cludes additional information (in this case the BLEL
lexicon) to calculate the final polarity score, out-
performs the original way to get the polarity score
(equation 1). The equation 3 for the English version
of the corpus reaches 5.84% and 8.4% better results
than equation 1 regarding F1 and Accuracy respec-
tively.
The results obtained with the Spanish reviews are
a bit different. In this case, the results are always
improved when the antonym relation is not taking
into account. So the first conclusion is the relation
of antonym is not convenient for the calculation of
the polarity value on Spanish texts. The process of
expansion with related senses has not been relevant
for the final results on the English reviews, but when
the language of the reviews is Spanish the expan-
sion is more decisive. For the wnet ant- eq3 es ex-
periment the best result has been reached consider-
ing 71 related senses, so we can conclude that for
Spanish the context should be considered. Although
the best results is obtained with the configuration
wnet ant+ eq3 es, it must be highlighted the pre-
cision value of 68.03% reached by the configura-
tion wnet ant+ eq2 es. In some OM experiments is
more important the precision of the system than the
recall or other evaluation measures, so for Spanish
reviews should be taken account this configuration
too.
Regarding English and Spanish results, Table 4
shows similar performance, i.e. the graph-based al-
gorithm obtained better results when the antonym is
not considered and the use of a lexicon of opinion
words enhances considerably the results.
The supervised approach clearly outperforms the
two unsupervised approaches. The results obtained
by the two unsupervised approaches are closer. The
lexicon based method has a better performance on
English reviews regarding the four different eval-
uation measures considered. Thus, the lexicon
method not only has better results but also it is sim-
pler, faster and more efficient than the graph-based
method. Nevertheless, the graph-based method on
Spanish reviews outperforms in precision regard-
ing the configuration wnet ant+ eq2 es and in the
other three measures take into account the configu-
ration wnet ant+ eq3 es. However, the graph-based
method is only 1.64% better regarding the precision
value, and 0.54% better regarding F1. Therefore, we
also considered the lexicon-based approach as the
more suitable approach than the graph-based one.
91
Expansion Precision Recall F1 Accuracy
wnet ant+ eq1 en 2 66.86% 57.25% 61.68% 57.25%
wnet ant- eq1 en 2 66.86% 57.25% 61.68% 57.25%
wnet ant+ eq2 en 0 65.27% 55.5% 59.99% 55.50%
wnet ant- eq2 en 0 65.27% 55.5% 59.99% 55.50%
wnet ant+ eq3 en 3 68.83% 62.50% 65.51% 62.50%
wnet ant- eq3 en 3 68.83% 62.50% 65.51% 62.50%
wnet ant+ eq1 es 0 65.42% 54.5% 59.46% 54.5%
wnet ant- eq1 es 19 64.39% 57.75% 60.89% 57.75%
wnet ant+ eq2 es 0 68.03% 52.75% 59.42% 52.75%
wnet ant- eq2 es 70 64.62% 58.00% 61.13% 58.00%
wnet ant+ eq3 es 71 65.91% 63.50% 64.68% 63.05%
wnet ant- eq3 es 71 65.91% 63.50% 64.68% 63.05%
Table 4: Results of the graph-based algorithm
5 Conclusion and future work
In this work, we have presented a set of experiments
with a comparable corpora in English and Spanish.
As it is usual, the supervised experiment has outper-
forms the unsupervised ones. The unsupervised ex-
periments have included the evaluation of two differ-
ent approaches: lexicon-based and graph-based. In
the lexicon-based approach we have presented a new
resource for the Spanish OM research community,
being an important contribution of this paper. The
results reached with SOL are very closed to the ones
obtained with graph-based methods. Although, for
short texts the graph-based method performed well,
for the kind of reviews used in these experiments is
not as good. Due to the fact that for English the
BLEL lexicon has reached better results, for Span-
ish the results of SOL are nearly the same ones ob-
tained by the graph method, and the use of a lexicon
is more efficient, we conclude that the lexicon-based
method is most suitable.
Currently we are improving the SOL lexicon, and
also we are adding domain information to the words
in SOL. Furthermore, one of our main objectives is
the treatment of the negation because we considered
that is essential for OM.
Acknowledgments
This work has been partially supported by a grant
from the Fondo Europeo de Desarrollo Regional
(FEDER), TEXT-COOL 2.0 project (TIN2009-
13391-C04-02) and ATTOS project (TIN2012-
38536-C03-0) from the Spanish Government. Also,
this paper is partially funded by the European
Commission under the Seventh (FP7 - 2007-2013)
Framework Programme for Research and Techno-
logical Development through the FIRST project
(FP7-287607). This publication reflects the views
only of the authors, and the Commission cannot be
held responsible for any use which may be made of
the information contained therein.
References
Eneko Agirre and Aitor Soroa. 2009. Personalizing
pagerank for word sense disambiguation. In Proceed-
ings of the 12th Conference of the European Chap-
ter of the Association for Computational Linguistics,
EACL ?09, pages 33?41, Stroudsburg, PA, USA. As-
sociation for Computational Linguistics.
Stefano Baccianella, Andrea Esuli, and Fabrizio Se-
bastiani. 2010. Sentiwordnet 3.0: An enhanced
lexical resource for sentiment analysis and opinion
mining. In Nicoletta Calzolari (Conference Chair),
Khalid Choukri, Bente Maegaard, Joseph Mariani,
Jan Odijk, Stelios Piperidis, Mike Rosner, and Daniel
Tapias, editors, Proceedings of the Seventh Interna-
tional Conference on Language Resources and Evalu-
ation (LREC?10), Valletta, Malta, may. European Lan-
guage Resources Association (ELRA).
Carmen Banea, Rada Mihalcea, Janyce Wiebe, and
Samer Hassan. 2008. Multilingual subjectivity
analysis using machine translation. In Proceedings
of the Conference on Empirical Methods in Natural
Language Processing, EMNLP ?08, pages 127?135,
Stroudsburg, PA, USA. Association for Computational
Linguistics.
Julian Brooke, Milan Tofiloski, and Maite Taboada.
2009. Cross-linguistic sentiment analysis: From en-
glish to spanish. In Proceedings of the International
Conference RANLP-2009, pages 50?54, Borovets,
92
Bulgaria, September. Association for Computational
Linguistics.
Chih-Chung Chang and Chih-Jen Lin. 2011. Libsvm:
A library for support vector machines. ACM Trans.
Intell. Syst. Technol., 2(3):27:1?27:27, May.
Corinna Cortes and Vladimir Vapnik. 1995. Support-
vector networks. Machine Learning, 20:273?297.
Ferm??n L. Cruz, Jose A. Troyano, Fernando Enriquez,
and Javier Ortega. 2008. Clasificacio?n de documen-
tos basada en la opinio?n: experimentos con un cor-
pus de cr??ticas de cine en espan?ol. Procesamiento del
Lenguaje Natural, 41:73?80.
Kushal Dave, Steve Lawrence, and David M. Pennock.
2003. Mining the peanut gallery: opinion extraction
and semantic classification of product reviews. In Pro-
ceedings of the 12th international conference on World
Wide Web, WWW ?03, pages 519?528, New York, NY,
USA. ACM.
Kerstin Denecke. 2008. Using sentiwordnet for multilin-
gual sentiment analysis. In Data Engineering Work-
shop, 2008. ICDEW 2008. IEEE 24th International
Conference on, pages 507?512. IEEE.
Hatem Ghorbel and David Jacot. 2011. Sentiment anal-
ysis of french movie reviews. Advances in Distributed
Agent-Based Retrieval Tools, pages 97?108.
Aitor Gonzalez-Agirre, Egoitz Laparra, and German
Rigau. 2012. Multilingual central repository version
3.0. In Nicoletta Calzolari (Conference Chair), Khalid
Choukri, Thierry Declerck, Mehmet Ug?ur Dog?an,
Bente Maegaard, Joseph Mariani, Jan Odijk, and Ste-
lios Piperidis, editors, Proceedings of the Eight In-
ternational Conference on Language Resources and
Evaluation (LREC?12), Istanbul, Turkey, may. Euro-
pean Language Resources Association (ELRA).
Minqing Hu and Bing Liu. 2004. Mining and summa-
rizing customer reviews. In Proceedings of the tenth
ACM SIGKDD international conference on Knowl-
edge discovery and data mining, KDD ?04, pages 168?
177, New York, NY, USA. ACM.
Eugenio Mart??nez-Ca?mara, M. Teresa Mart??n-Valdivia,
and L. Alfonso Uren?a Lo?pez. 2011. Opinion clas-
sification techniques applied to a spanish corpus. In
Proceedings of the 16th international conference on
Natural language processing and information sys-
tems, NLDB?11, pages 169?176, Berlin, Heidelberg.
Springer-Verlag.
M. Teresa Mart??n-Valdivia, Eugenio Mart??nez-Ca?mara,
Jose M. Perea-Ortega, and L. Alfonso Uren?a Lo?pez.
2012. Sentiment polarity detection in spanish reviews
combining supervised and unsupervised approaches.
Expert Systems with Applications. In press.
George A. Miller. 1995. Wordnet: a lexical database for
english. Communications of the ACM, 38(11):39?41.
Arturo Montejo-Ra?ez, Eugenio Mart??nez-Ca?mara,
M. Teresa Mart??n-Valdivia, and L. Alfonso Uren?a
Lo?pez. 2012. Random walk weighting over senti-
wordnet for sentiment polarity detection on twitter. In
Proceedings of the 3rd Workshop in Computational
Approaches to Subjectivity and Sentiment Analy-
sis, pages 3?10, Jeju, Korea, July. Association for
Computational Linguistics.
Lawrence Page, Sergey Brin, Rajeev Motwani, and Terry
Winograd. 1999. The pagerank citation ranking:
Bringing order to the web. Technical Report 1999-
66, Stanford InfoLab, November. Previous number =
SIDL-WP-1999-0120.
Bo Pang and Lillian Lee. 2008. Opinion mining and
sentiment analysis. Found. Trends Inf. Retr., 2(1-2):1?
135, January.
Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan.
2002. Thumbs up?: Sentiment classification using
machine learning techniques. In Proceedings of the
ACL-02 conference on Empirical methods in natural
language processing - Volume 10, EMNLP ?02, pages
79?86, Stroudsburg, PA, USA. Association for Com-
putational Linguistics.
Mohammed Rushdi-Saleh, M. Teresa Mart??n-Valdivia,
L. Alfonso Uren?a Lo?pez, and Jose? M. Perea-Ortega.
2011a. OCA: Opinion corpus for Arabic. Journal
of the American Society for Information Science and
Technology, 62(10):2045?2054, October.
Mohammed Rushdi-Saleh, Maria Teresa Martn-Valdivia,
Luis Alfonso Urea-Lpez, and Jos M. Perea-Ortega.
2011b. Bilingual Experiments with an Arabic-English
Corpus for Opinion Mining. In Galia Angelova,
Kalina Bontcheva, Ruslan Mitkov, and Nicolas Ni-
colov, editors, RANLP, pages 740?745. RANLP 2011
Organising Committee.
Maite Taboada and Jack Grieve. 2004. Analyzing ap-
praisal automatically. In Proceedings of AAAI Spring
Symposium on Exploring Attitude and Affect in Text
(AAAI Technical Re# port SS# 04# 07), Stanford Uni-
versity, CA, pp. 158q161. AAAI Press.
Maite Taboada. 2008. Sfu review corpus. http:
//www.sfu.ca/?mtaboada/research/SFU_
Review_Corpus.html.
Peter D. Turney. 2002. Thumbs up or thumbs down?:
semantic orientation applied to unsupervised classifi-
cation of reviews. In Proceedings of the 40th Annual
Meeting on Association for Computational Linguis-
tics, ACL ?02, pages 417?424, Stroudsburg, PA, USA.
Association for Computational Linguistics.
93
