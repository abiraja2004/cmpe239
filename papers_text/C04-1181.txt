Interpreting Vague Utterances in Context
David DeVault and Matthew Stone
Department of Computer Science
Rutgers University
Piscataway NJ 08854-8019
David.DeVault@rutgers.edu, Matthew.Stone@rutgers.edu
Abstract
We use the interpretation of vague scalar predi-
cates like small as an illustration of how system-
atic semantic models of dialogue context en-
able the derivation of useful, fine-grained utter-
ance interpretations from radically underspeci-
fied semantic forms. Because dialogue context
suffices to determine salient alternative scales
and relevant distinctions along these scales,
we can infer implicit standards of comparison
for vague scalar predicates through completely
general pragmatics, yet closely constrain the in-
tended meaning to within a natural range.
1 Introduction
Modeling context and its effects on interpretation
may once have seemed to call for an open-ended in-
vestigation of people?s knowledge of the common-
sense world (Hobbs et al, 1993). But research on
the semantics of practical dialogue (Allen et al,
2001) now approaches dimensions of context sys-
tematically, through increasingly lightweight, fac-
tored models. The evolving state of real-world ac-
tivity proceeds predictably according to background
plans and principles of coordination (Rich et al,
2001). The status of the dialogue itself is defined
by circumscribed obligations to ground prior ut-
terances, follow up open issues, and advance real-
world negotiation (Larsson and Traum, 2000). Fi-
nally, the evolving state of the linguistic context
is a direct outgrowth of the linguistic forms inter-
locutors use and the linguistic relationships among
successive utterances (Ginzburg and Cooper, 2001;
Asher and Lascarides, 2003). These compatible
models combine directly to characterize an aggre-
gate information state that provides a general back-
ground for interpretation (Bunt, 2000).
We argue in this paper that such integrated mod-
els enable systems to calculate useful, fine-grained
utterance interpretations from radically underspec-
ified semantic forms. We focus in particular on
vague scalar predicates like small or long. These
predicates typify qualitative linguistic expression of
quantitative information, and are thus both chal-
lenging and commonplace. Building on a mul-
tidimensional treatment of dialogue context, we
develop and implement a theoretically-motivated
model of vagueness which is unique in treating
vague predicates as genuinely vague and genuinely
context-sensitive, yet amenable to general processes
of contextual and interpretive inference.
1.1 Semantic insights
We pursue our argument in the context of an imple-
mented drawing application, FIGLET, which allows
users to give English instructions to draw a carica-
ture of an expressive face. Figure 1 shows a repre-
sentative interaction with FIGLET; the user gives the
successive instructions in (1):
(1) a. Make two small circles.
b. Draw a long line underneath.
Like Di Eugenio and Webber (1996), we empha-
size that understanding such instructions requires
contextual inference combining linguistic, task and
domain knowledge. For example, consider the re-
sponse to (1a) of placing circles so as to form the
eyes of a new face. To recognize the possibility
of drawing eyes exploits knowledge of the ongoing
drawing task. To put the eyes where they belong
in the upper part of the new face exploits domain
knowledge. The response to (1b) adds the linguis-
tic context as another ingredient. To identify where
the line goes, the user uses the objects mentioned
recently in the interaction as the understood spatial
landmark for underneath. Figure 1 highlights the
importance of using multidimensional representa-
tions of dialogue context in understanding instruc-
tions for quantitative domains.
We leverage this background context in our com-
putational approach to vagueness. We model a
vague utterance like draw a long line as though it
meant draw a line with, you know, length. In this
approach, vague predicates are completely under-
specified; linguistic knowledge says nothing about
how long something long is. Instead, vague lan-
guage explicitly draws on the background knowl-
Initial blank figure state. After the user utters (1a):
Make two small circles.
After the user utters (1b):
Draw a long line underneath.
Figure 1: Motivating interaction: Vague instructions to draw a face.
edge already being applied in utterance interpre-
tation. The user?s motivation in using long is to
differentiate an intended interpretation, here an in-
tended action, from alternative possibilities in con-
text. Background knowledge already sets out the
relevant ways to draw a line; drawing a long line
means singling out some of them by the length of
that new line. This model recalls dynamic theo-
ries of vague scalar predicates, such as the seman-
tics of Kyburg and Morreau (2000), Barker (2002),
or Kennedy (2003), but it is exactly implemented
in FIGLET. The implementation capitalizes on the
richness of current models of context to recover
content for the you know of vagueness.
1.2 Overview
In Section 2, we motivate approaches to the seman-
tics of vague scalar predicates that associate them
with a presupposed standard of comparison. We il-
lustrate how context can be understood to supply
possible standards, and how pragmatic reasoning
from utterances allows interlocutors to infer them.
In Section 3, we establish a bridge to the general
treatment of practical dialogue, by showing how
multiple dimensions of context generally contribute
to recognizing possible interpretations for under-
specified utterances. Section 4 builds on Sections 2
and 3 to show how FIGLET exploits a rich model of
utterance context to respond cooperatively to vague
utterances like (1a) and (1b), while Section 5 de-
tails FIGLET?s actual implementation. We conclude
in Section 6 by suggesting further challenges that
vagueness still poses for computational semantics.
2 Vague standards in context
We adopt a view of vague predicates motivated by
linguistic theory, particularly Kennedy?s approach
(1999; 2003). We assume that gradable adjectives
are associated with measurement functions mapping
individuals to degrees on a scale. In FIGLET?s draw-
ing domain, the relevant measurements pertain to
spatial properties. For long, for example, the mea-
surement maps individuals to their spatial lengths;
for small, it maps individuals to degrees on an in-
verted scale of size.
Positive gradable adjectives compare measured
degrees against a standard on the scale which is de-
rived from context. For example, long says that an
object?s length exceeds the threshold set by the cur-
rent standard for length. Other forms, such as com-
parative adjectives or adjectives with explicit mea-
sure phrases, compare degrees differently.
Importantly, grammar says nothing about how
standards for positive gradable adjectives are de-
rived. In other words, contra Cresswell (1977) and
others, the interpretation of adjectives is not com-
puted relative to a grammatically-specified ?com-
parison class? of related objects. And, contra Oates
et al (2000) and Roy and Pentland (2002), the in-
terpretation of adjectives need not require statistical
knowledge about how objects with different mea-
surements on a scale tend to be described. Instead,
standards are derived directly from an evolving con-
text by the general principles that govern pragmatic
resolution of context dependence.
Kennedy synthesizes a range of evidence for this
claim. Here we go further, and provide a formal,
implemented model. We can sketch the evidence
and our model by considering two key examples.
First, we illustrate that vagueness depends di-
rectly on specific contextually-relevant distinctions.
Consider the session with FIGLET shown in Fig-
ure 2. The user has elected to draw two objects side-
by-side. The initial context just contains a square.
The user utters (2).
(2) Make a small circle.
To interpret (2) it doesn?t seem to help to appeal to
general knowledge about how big circles tend to be.
(It?s quite convoluted to even frame the idea in a
sensible way.) Graff (2000) observes that standards
often implicitly appeal to what we expect about par-
ticular individuals, not just what we know about
similar individuals. In context, here, the user just
seems to be asking for a circle vaguely smaller than
the square. This is the interpretation FIGLET builds;
to comply, FIGLET draws the circle an arbitrary but
representative possible size. The point is that salient
objects and actions inevitably set up meaningful dis-
Initial figure state. After the user utters (2). Initial figure state. After the user utters (3).
Figure 2: Taking standards from context in (2):
Make a small circle.
Figure 3: Disambiguating contextual standards
in (3): Make the small square a circle.
tinctions in the context. Interlocutors exploit these
distinctions in using vague adjectives.
Figure 3 illustrates that understanding vagueness
is part of a general problem of understanding utter-
ances. Figure 3 shows FIGLET?s action in a more
complex context, containing two squares of differ-
ent sizes. We consider the user?s instruction (3):
(3) Make the small square a circle.
FIGLET?s action changes the smaller of the two
squares. The standard behind this interpretation
is implicitly set to differentiate the contextually-
salient objects from one another; the natural reso-
lution of (3) does not require that either square be
definitely small (Kyburg and Morreau, 2000). In
Figure 3, for example, there are different potential
standards that would admit either both squares or
neither square as small. However, we can rule out
these candidate standards in interpreting (3). The
user?s communicative intention must explain how
a unique square from the context can be identified
from (3) using a presupposed small standard. If that
standard is too big, both squares will fit. If that stan-
dard is too small, neither square will fit. Only when
that standard falls between the sizes of the squares
does (3) identify a unique square.
The examples in Figures 2 and 3 show two ways
new standards can be established. Once established,
however, standards become part of the evolving
context (Barker, 2002). Old standards serve as de-
faults in interpreting subsequent utterances. Only
if no better interpretation is found will FIGLET go
back and reconsider its standard. This too is general
pragmatic reasoning (Stone and Thomason, 2003).
3 Dimensions of context in interpretation
To cash out our account of contextual reasoning
with vagueness, we need to characterize the con-
text for practical dialogue. Our account presupposes
a context comprising domain and situation knowl-
edge, task context and linguistic context. In this sec-
tion, we survey each of these dimensions of context,
and show how they converge in the resolution of un-
derspecification across a wide range utterances.
Domain and situation knowledge describes the
commonsense structure of the real-world objects
and actions under discussion. Practical dialogue re-
stricts this otherwise open-ended specification to the
circumscribed facts that are directly relevant to an
ongoing collaboration. For example, in our drawing
domain, individuals are categorized by a few types:
types of shape such as circles and squares; and types
of depiction such as eyes and heads. These types
come with corresponding constraints on individuals.
For example, the shape of a mouth may be a line, an
ellipse, or a rectangle, while the shape of a head can
only be an ellipse. These constraints contribute to
interpretation. For instance, a head can never be de-
scribed as a line, for example, since heads cannot
have this shape.
Task context tracks collaborators? evolving com-
mitment to shared goals and plans during joint ac-
tivity. In FIGLET?s drawing domain, available ac-
tions allow users to build figure parts by introducing
shapes and revising them. Our experience is that
users? domain plans organize these actions hierar-
chically into strategic patterns. For example, users
tend to complete the structures they begin drawing
before drawing elsewhere; and once they are satis-
fied with what they have, they proceed in natural
sequence to a new part nearby. Task context plays
a powerful role in finding natural utterance inter-
pretations. By recording a plan representation and
keeping track of progress in carrying it out, FIGLET
has access to a set of candidate next actions at each
point in an interaction. Matching the user?s utter-
ance against this candidate set restricts the interpre-
tation of instructions based on the drawing already
created and the user?s focus of attention within it.
For example, if the user has just drawn the right eye
onto an empty face, they are likely to turn to the left
eye next. This context suggests making a winking
left eye in response to draw a line, an interpretation
that might not otherwise be salient.
Linguistic context records the evolving status
of pragmatic distinctions triggered by grammatical
conventions. One role of the linguistic context is its
contribution to distinguishing the prominent entities
Initial figure state. After the user utters (4):
Draw a line underneath.
Figure 4: Context in instructions.
that can serve as the referents of pronouns and other
reduced expressions. To see this, note that, as far
as domain knowledge and task context go, the in-
struction make it bigger could apply to any object
currently being created. If the figure is hierarchi-
cal, there will be many possibilities. Yet we typi-
cally understand it to refer specifically to an object
mentioned saliently in the previous utterance. The
linguistic context helps disambiguate it.
Figure 4 illustrates how the three different dimen-
sions of context work together. It illustrates an inter-
action with FIGLET where the user has just issued an
instruction to create two eyes, resulting in the figure
state shown at the left in Figure 4. The user?s next
instruction is (4):
(4) Draw a line underneath.
We focus on how the context constrains the position
and orientation of the line.
Linguistic context indicates that underneath
should be understood as underneath the eyes. This
provides one constraint on the placement of the line.
Task context makes drawing the mouth a plausible
candidate next action. Domain knowledge shows
that the mouth can be a line, but only if further
constraints on position, orientation and length are
met. In understanding the instruction, FIGLET ap-
plies all these contextual constraints simultaneously.
The set of consistent solutions?drawing a horizon-
tal line at a range of plausible mouth positions be-
low the eyes?constitutes the utterance interpreta-
tion. FIGLET acts to create the result in Figure 4 by
choosing a representative action from this set.
4 Interpreting vague utterances in context
In our approach, the linguistic context stores agreed
standards for vague predicates. Candidate standards
are determined using information available from do-
main knowledge and the current task context. In
FIGLET?s drawing domain, possibilities include the
actual measurements of objects that have already
been drawn. They also include the default domain
measurements for new objects that task context says
could be added. Setting standards by a measure-
ment is our shorthand for adopting an implicit range
of compatible standards; these standards remain
vague, especially since many options are normally
available (Graff, 2000).
We treat the use of new candidate standards in in-
terpretation as a case of presupposition accommo-
dation (Bos, 2003). In presupposition accommo-
dation, the interpretation of an utterance must be
constructed using a context that differs from the ac-
tual context. When speakers use an utterance which
requires accommodation, they typically expect that
interlocutors will update the dialogue context to in-
clude the additional presumptions the utterance re-
quires. We assume that all accommodation is sub-
ject to two Gricean constraints. First, we assume
whenever possible that an utterance should have a
uniquely identifiable intended interpretation in the
context in which it is to be interpreted. Second, we
assume that when interpretations in alternative con-
texts are available, the speaker is committed to the
strongest one?compare Dalrymple et al (1998).
Inferring standards for vague predicates is a special
case of this general Gricean reasoning.
The principles articulated thus far in Sections 2?4
allow us to offer a precise explanation of FIGLET?s
behavior as depicted in Figure 1. The user starts
drawing a face with an empty figure. In this domain
and task context, make two circles fits a number of
possible actions. For example, it fits the action of
drawing a round head and its gaping mouth. How-
ever, in (1a), what the user actually says is make
two small circles. The interpretation for (1a) must
accommodate a standard for small and select from
the continuum of size possibilities two new circles
that meet this standard.
The standards in this context are associated with
the size distinctions among potential new objects.
The different qualitative behavior of these standards
in interpretation can be illustrated by the standards
set from possible new circular objects that are con-
sistent with the face-drawing task. We can set the
standard from the default size of an eye, from the
default size of a mouth (larger), or from the default
size of a head (larger still).1 Because each stan-
dard allows all smaller objects to be created next,
these standards lead to 1, 3, and 6 interpretations,
respectively. So we recover the standard from the
eye, which results in a unique interpretation.2
1Since the default sizes of new objects reflect the relative
dimensions of any other objects already in the figure, FIGLET?s
default sizes are not generally equivalent to static comparison
classes.
2Note that there are many potential sources of standards for
small that FIGLET does not currently pursue. E.g. the average
size of all objects already in the figure. We believe that general
In tandem with its response, FIGLET tracks the
changes to the context. The task context is updated
to note that the user has drawn the eyes and must
continue with the process of creating and revising
the features of the face. The linguistic context is
updated to include the new small standard, and to
place the eyes in focus.
This updated context provides the background
for (1b), the user?s next instruction draw a long
line underneath. In this context, as we saw with
Figure 4, context makes it clear that any response
to draw a line underneath must draw the mouth.
Thus, unlike in (1a), all the interpretations here have
the same qualitative form. Nevertheless, FIGLET?s
Gricean reasoning can still adjust the standard for
length to differentiate interpretations quantitatively,
and thereby motivate the user?s use of the word long
in the instruction. FIGLET bases its possible stan-
dards for length on both actual and potential ob-
jects. It can set the standard from an actual eye or
from the two eyes together; and it can set the stan-
dard from the default mouth or head. The mouth, of
course, must fit inside the head; the largest standard
is ruled out. All the other standards lead to unique
interpretations. Since the length of the two eyes to-
gether is the strictest of the remaining standards, it
is adopted. This interpretation leads FIGLET to the
response illustrated at the right in Figure 1.
5 Implementation
We have implemented FIGLET in Prolog using
CLP(R) real constraints (Jaffar and Lassez, 1987)
for metric and spatial reasoning. This section
presents a necessarily brief overview of this imple-
mentation; we highlight how FIGLET is able to ex-
actly implement the semantic representations and
pragmatic reasoning presented in Sections 2?4. We
offer a detailed description of our system and dis-
cuss some of the challenges of building it in DeVault
and Stone (2003).
5.1 Semantic representation
In FIGLET, we record the semantics of user instruc-
tions using constraints, or logical conjunctions of
open atomic formulas, to represent the contextual
requirements that utterances impose; we view these
constraints as presuppositions that speakers make in
using the utterance. We assume matches take the
form of instances that supply particular domain rep-
resentations as suitable values for variables. Stone
(2003) motivates this framework in detail.
methods for specifying domain knowledge will help provide
the meaningful task distinctions that serve as candidate stan-
dards for vague predicates on our approach, but pursuing this
hypothesis is beyond the scope of this paper.
In (5a-d), we show the presuppositions FIGLET
assigns to an utterance of Make two small circles,
arranged to show the contributions of each individ-
ual word. In (5e), we show the contribution made
by the utterance to an evolving dialogue; the effect
is to propose that an action be carried out.
(5) a. simple(A)? target(A,X)?fits plan(A)?
holds(result(A,now),visible(X))?
holds(now, invisible(X))?
b. number(X ,2)?
c. standard(small,S)?
holds(result(A,now),small(X ,S))?
d. number(X ,multiple)?
holds(result(A,now),shape(X ,circle))
e. propose(A)
We formulate these constraints in an expressive
ontology. We have terms and variables for ac-
tions, such as A; for situations, such as now and
result(A,now); for objects, such as X ; for stan-
dards for gradable vague predicates (scale-threshold
pairs), such as S; and for quantitative points and in-
tervals of varying dimensionality, as necessary.
5.2 Pragmatic reasoning
Constraint networks such as (5a-e) provide a uni-
form venue for describing the various contextual
dependencies required to arrive at natural utterance
interpretations. Thus, the contextual representation
and reasoning outlined in Sections 3 and 4 is real-
ized by a uniform mechanism in FIGLET: specifica-
tions of how to reason from context to find solutions
to these constraints.
For example, Section 3 described domain knowl-
edge that links particular object types like eyes and
heads with type-specific constraints. In our imple-
mentation, we specify real and finite constraints that
individuals of each type must satisfy. In order for an
individual e of type t to serve as part of a solution
to a constraint network like (5a-e), e must addition-
ally meet the constraints associated with type t. In
this way, FIGLET requires utterance interpretations
to respect domain knowledge.
Solving many of the constraints appearing in (5a-
e) requires contextual reasoning about domain ac-
tions and their consequences. Some constraints
characterize actions directly; thus simple(A) means
that A is a natural domain action rather than
an abstruse one. Constraints can describe the
effects of actions by reference to the state of
the visual display in hypothetical situations; thus
holds(result(A,now),shape(X ,circle)) means that
the individual X has a circular shape once action
A is carried out. Constraints can additionally char-
acterize causal relationships in the domain; thus
target(A,X) means that action A directly affects X ,
and the constraints of (5a-d) together mean that car-
rying out action A in the current situation causes two
small circles to become visible. These constraints
are proved in FIGLET by what is in effect a planner
that can find complex actions that achieve specified
effects via a repertoire of basic domain actions.
Task context is brought to bear on interpretation
through the fits plan(A) constraint of (5a). FIGLET
uses a standard hierarchical, partially ordered plan
representation to record the structure of a user?s
task. We specify the solutions to fits plan(A) to
be just those actions A that are possible next steps
given the user?s current state in achieving the task.
Since these task-appropriate actions can factor addi-
tional constraints into interpretation, enforcing the
fits plan(A) constraint can help FIGLET identify a
natural interpretation.
As discussed in Section 4, FIGLET records a
list of current standards for vague scalar adjec-
tives in the linguistic context. The constraint
standard(small,S) of (5c) connects the overall ut-
terance interpretation to the available standards for
small in the linguistic context. FIGLET interprets ut-
terances carrying semantic constraints of the form
standard(vague-predicate,S) in one or two stages.
In the first stage, the constraint is solved just in
case S is the prevailing standard for vague-predicate
in the linguistic context. If there is no prevailing
standard for an evoked vague property, or if this
stage does not yield a unique utterance interpreta-
tion, then FIGLET moves to a second stage in which
the constraint is solved for any standard that cap-
tures a relevant distinction for vague-predicate in
the context. If there is a strongest standard that re-
sults in a unique interpretation, it is adopted and in-
tegrated into the new linguistic context.
5.3 Parsing and Interpretation
Language understanding in FIGLET is mediated by a
bottom-up chart parser written in Prolog. As usual,
chart edges indicate the presence of recognized par-
tial constituents within the input sequence. In ad-
dition, edges now carry constraint networks that
specify the contextual reasoning required for under-
standing. In addition to finite instances (Schuler,
2001), these networks include real constraints that
formalize metric and spatial relationships. Interpre-
tation of these networks is carried out incremen-
tally, during parsing; each edge thus records a set
of associated candidate interpretations. Since do-
main reasoning can be somewhat time-intensive in
our current implementation, we adopt a strategy
of delaying the solution of certain constraints until
enough lexical material has accrued that the asso-
ciated problem-solving is judged tractable (DeVault
and Stone, 2003).
6 Assessment and Conclusion
In our approach, we specify a genuinely vague se-
mantics: vague words evoke a domain-specific scale
that can differentiate alternative domain individuals.
To find a unique interpretation for a vague utter-
ance, we leverage ordinary inference about the do-
main, task, and linguistic context to recover implicit
thresholds on this scale.
We believe that further methodological advances
will be required to evaluate treatments of vagueness
in indefinite reference, such as that considered here.
For example, obviously the very idea of a ?gold
standard? for resolution of vagueness is problem-
atic. We believe that the best argument for a theory
of vagueness in a language interface would show
that naive users of the interface are, on the whole,
likely to accept its vague interpretations and un-
likely to renegotiate them through clarification. But
the experiment would have to rule out confounding
factors such as poorly-modeled lexical representa-
tion and context tracking as sources for system in-
terpretations that users reject.
We intend to take up the methodological chal-
lenges necessary to construct such an argument in
future work. In the meantime, while our current im-
plementation of FIGLET exhibits the promising be-
havior discussed in this paper and illustrated in Fig-
ures 1?4, some minor engineering unrelated to lan-
guage understanding remains before a fruitful eval-
uation can take place. As alluded to above, the tight
integration of contextual reasoning and interpreta-
tion that FIGLET carries out can be expensive if not
pursued efficiently. While our initial implementa-
tion achieves a level of performance that we accept
as researchers (interpretation times of between one
and a few tens of seconds), evaluation requires us to
improve FIGLET?s performance to levels that exper-
imental participants will accept as volunteers. Our
analysis of FIGLET indicates that this performance
can in fact be achieved with better-regimented do-
main problem-solving.
Nevertheless, we emphasize the empirical and
computational arguments we already have in sup-
port of our model. Our close links with the linguis-
tic literature mean that major empirical errors would
be surprising and important across the language sci-
ences. Indeed, limited evaluations of treatments of
vague definite reference using standards of differ-
entiation or very similar ideas have been promising
(Gorniak and Roy, In Press). The computational ap-
peal is that all the expensive infrastructure required
to pursue the account is independently necessary.
Once this infrastructure is in place the account is
readily implemented with small penalty of perfor-
mance and development time. It is particularly at-
tractive that the approach requires minimal lexical
knowledge and training data. This means adding
new vague words to an interface is a snap.
Overall, our new model offers three contribu-
tions. Most importantly, of course, we have devel-
oped a computational model of vagueness in terms
of underspecified quantitative constraints. But we
have also presented a new demonstration of the im-
portance and the feasibility of using multidimen-
sional representations of dialogue context in under-
standing descriptions of quantitative domains. And
we have introduced an architecture for resolving un-
derspecification through uniform pragmatic mech-
anisms based on context-dependent collaboration.
Together, these developments allow us to circum-
scribe possible resolutions for underspecified utter-
ances, to zero in on those that the speaker and hearer
could adopt consistently and collaboratively, and
so to constrain the speaker?s intended meaning to
within a natural range.
Acknowledgments
We thank Kees van Deemter and our anonymous re-
viewers for valuable comments. This work was sup-
ported by NSF grant HLC 0308121.
References
J. Allen, D. Byron, M. Dzikovska, G. Ferguson,
L. Galescu, and A. Stent. 2001. Towards conver-
sational human-computer interaction. AI Maga-
zine, 22(4):27?37.
N. Asher and A. Lascarides. 2003. Logics of Con-
versation. Cambridge.
C. Barker. 2002. The dynamics of vagueness. Lin-
guistics and Philosophy, 25(1):1?36.
J. Bos. 2003. Implementing the binding and
accommodation theory for anaphora resolution
and presupposition. Computational Linguistics,
29(2):179?210.
H. Bunt. 2000. Dialogue pragmatics and context
specification. In H. Bunt and W. Black, editors,
Abduction, Belief and Context in Dialogue, pages
81?150. Benjamin.
M. Cresswell. 1977. The semantics of degree. In
B. H. Partee, editor, Montague Grammar, pages
261?292. Academic.
M. Dalrymple, M. Kanazawa, Y. Kim, S. Mchombo,
and S. Peters. 1998. Reciprocal expressions and
the concept of reciprocity. Linguistics and Phi-
losophy, 21(2):159?210.
D. DeVault and M. Stone. 2003. Domain inference
in incremental interpretation. In Proc. ICoS.
B. Di Eugenio and B. Webber. 1996. Pragmatic
overloading in natural language instructions. Int.
Journal of Expert Systems, 9(2):53?84.
J. Ginzburg and R. Cooper. 2001. Resolving ellip-
sis in clarification. In Proc. ACL.
P. Gorniak and D. Roy. In Press. Grounded seman-
tic composition for visual scenes. Journal of Ar-
tificial Intelligence Research.
D. Graff. 2000. Shifting sands: An interest-
relative theory of vagueness. Philosophical Top-
ics, 28(1):45?81.
J. Hobbs, M. Stickel, D. Appelt, and P. Martin.
1993. Interpretation as abduction. Artificial In-
telligence, 63:69?142.
J. Jaffar and J.-L. Lassez. 1987. Constraint logic
programming. In Proc. POPL, pages 111?119.
C. Kennedy. 1999. Projecting the adjective: The
syntax and semantics of gradability and compar-
ison. Garland.
C. Kennedy. 2003. Towards a grammar of vague-
ness. Manuscript, Northwestern.
A. Kyburg and M. Morreau. 2000. Fitting words:
Vague words in context. Linguistics and Philos-
ophy, 23(6):577?597.
S. Larsson and D. Traum. 2000. Information state
and dialogue management in the TRINDI dia-
logue move engine toolkit. Natural Language
Engineering, 6:323?340.
T. Oates, M. D. Schmill, and P. R. Cohen. 2000.
Toward natural language interfaces for robotic
agents. In Proc. Agents, pages 227?228.
C. Rich, C. L. Sidner, and N. Lesh. 2001. COL-
LAGEN: applying collaborative discourse the-
ory to human-computer interaction. AI Maga-
zine, 22(4):15?26.
D. Roy and A. Pentland. 2002. Learning words
from sights and sounds: A computational model.
Cognitive Science, 26(1):113?146.
W. Schuler. 2001. Computational properties of
environment-based disambiguation. In Proc.
ACL, pages 466?473.
M. Stone and R. H. Thomason. 2003. Coordinat-
ing understanding and generation in an abductive
approach to interpretation. In Proc. DiaBruck,
pages 131?138.
M. Stone. 2003. Knowledge representation for lan-
guage engineering. In A. Farghaly, editor, A
Handbook for Language Engineers, pages 299?
366. CSLI.
