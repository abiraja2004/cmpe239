MACHINE LEARNING OF MORPHOLOGICAL RULES 
BY GENERALIZATION AND ANALOGY 
K laus  Wothke 
Arbe iLssLe \ ] le  L ingu isL i sche  DaLenverarbe iLung  
INST I \ [U I  FOR DEUTSCHE SPRAI;HE 
Mannheim, West. Germany 
ABSTRAI:T: 1h is  paper descr ibes  an experi-  
menLal procedure For Lhe inducLive auLomaLed 
learning of morphological  rules From exam- 
ples. At First an ouL\].irle of Lhe problem is 
given. Then a Formalism for Lhe represen- 
t. arian of  morpho log ica l  ru les  i s  de f ined .  
Th is  Formal i sm i s  used by Lhe auLomaLed 
procedure ,  whose anaLomy Js subsequent ly  
present ,  ed. F ina l ly  t. he per fo rmance  of t. he 
sysLem i s  eva luat ,  ed and Lhe mosL impor tant .  
unso lved  prob lems are  d i scussed .  
l .  OuL l ine  o f  Lhe Prob lem 
Learning algorithms for Lhe domain of 
naLurai languages were in Lhe pasL mainly 
developed to model Lhe acquis i t ion of synLax 
and Lo generaLe synLacLJc descr ipLions flrom 
examples (eL. Pinker 1979~ Cohen/Fe igenbaum 
\ ]982:  494-5 \ ] \ ] ) .  There ex is t  a l so  some sys -  
Lems which learn rules for Lhe auLomaLie 
phonetic Lranscr ipL ion off orLhographic  LexL 
(eL. Oakey/Cawt:horn 1981, Wolf 1977). Like 
the system presenLed in Lhis paper all Lhese 
systems sLill are expor imenLal  sysLems, the 
inductive auLomaLic learning of morphologi~ 
ca l  ru les  has L i l l  now been invesL igaLed  
on ly  Lo a smal l  degree .  Research  on Lh is  
problem was carried out by Ring (1978), 
3snsen-WJnke ln  (\]985) and Wofhl<e (1985). 
The task  of' Lhe sysLem descr ibed  here  
i s  Lo learn  ru les  f 'or in f lecL iona \ ]  and 
der ivaL iona l  morpho logy .  The system is naL 
des igned  as a sLandard  program,  but  as an 
exper imenLa l  sys tem.  I t  \ ] s  used For Lhe ex -  
per imenLa\ ]  deve lopment  and t, he Les l ing  o f  
fundamenLa l  a \ ]gor iLhmic  learn ing  st. rat. eg ies .  
Lat. er  these  sL ra teg ies  cou ld  perhaps  become 
necessary  components  o f  a s tandard  \ ] .earn ing  
program dev ised  For Lhe in teracL ive  deve lop-  
menL off \ ] ingu isL Jc  a lgor i thms For Lhe domain 
o f  morpho logy .  
Input:  Lo Lhe sysLem i s  a seL o f  exam- 
p les  ca l led  a learn ing  corpus .  Each example  
i s  an ordered  pa i r  o f  words .  We ca l l  the  
f ' i r sL  word o f  each pa i r  Lhe source .  \ [he  
second word i s  ca l led  Lhe t. a rgeL .  BeLween 
the  source  and Lhe LargeL  o f  each g iven  pa i r  
Lhere  musL ex is t :  an in f l l ec t ,  i ona l  or  a 
der ivat iona l  morpho log ica l  re laL ion .  By ap-. 
p ly ing  t. he processes  o f  genera l l zaL ion  and 
deLecL ion  ana log ies  Lhe syst. em has to  con-  
sL rucL  a seL o6 insLrucL ions  wh ich  descr ibe  
on a purely graphemic basis how Lhe LargeL 
of each pair is generaLed From the source. 
(SemanLic feaLures  o f  morphemes are  aL 
presenL  ignored  by Lhe sysLem.)  Such a seL 
of inskrucLions should not only generaLe 
correcL LargeLs For the sources given in the 
learning corpus: The insLrucLions should 
also generaLe correcL targeLs for Lhe major- 
iLy of Lhe sources not in Lhe corpus which 
part .  i c JpaLe  in  Lhe same in f lec t iona l  or  
derJvaLional  re laLienship as Lhe source- 
LargeL-pairs  Jn Lhe learning corpus. Suppose 
For example LhaL Lhe Fol lowing learning cor- 
pus is Fed JnLo Lhe sysLem: 
"assembly '  
"baLh 
"box"  
"boy"  
"bus"  
"bush 
"buzz 
"ca l f  
"copy 
"c ry"  
"door  
"F ie ld"  
'house '  
"kn i fe"  
" lady"  
"moLher"  
"sw iLch '  
"un ivers iLy"  
"assembl ies"  
"baLhs"  
"boxes"  
"boys"  
buses"  
bushes 
buzzes  
ca lves  
copies 
cr ies"  
doors"  
" f ie lds  
"houses 
"kn ives  
" lad les  
"moLhers '  
" sw iLches '  
"un Jvers iL Jes"  
F igure  \] . 
In  t. h i s  case kilo learn ing  a lgor iLhm has Lo 
consLruc l  a set. off inst .  rueL ions  wh ich  gener -  
a les  f ior each s ingu lar  noun (= SOLirce~ in  
Lhe leFL  co lumn)  of: Lh i s  corpus  a sL r ing  
wh ich  i s  idenL ica l  w.tLh t. he cor respond ing  
p lu ra l  Form (= LargeL ,  in  the  r ighL  co lumn) .  
FurLhermore ,  Lhe inst .  rucL ions  shou ld  a l so  
generat, e Lhe correcL p lura l  Form For Lbe 
major iLy of Engl ish singu\].ar nouns which are 
not, members off Lhe l~arnirlg corpus. For in- 
seance ,  Lhe ins l ruc l ,  i ons  shou ld  a l so  gener -  
aLe " f l i es"  f'rom " f i \ [y ' ,  "Lab les  " f'rom 
"Lab le  ", " foxes  " f rom " fox  ", " lays"  f rom 
"Lay ", "c lasses  " From " ( ; lass ' ,  and " th ieves  " 
From "Lh ie f ' .  Of course  Lhere  w i l l  a l so  be 
s ingu lar  nouns For wh ich  Lhe . tnsLrucL ions  
w i l l  noL be adequaLe .  These w i l l  i nc lude  a l l  
nouns whose paLLern  off p lu ra l i zaL ion  i s  not  
represenLed  by examples  in  Lhe learn ing  cor -  
pus .  WiLh t. he g iven  learn ing  corpus  one 
289 
could not expect  the in fer red  ins t rucL Jons  
to be adequat, e e. g. For the p lu ra l i za t ions  
"ox"  -> "oxen ' ,  "LooLh"  -> " teeLh ' ,  
" index"  -> " ind ices ' ,  " foot"  -> " feeL"  ~ and 
"addendum" -> "addenda ' .  As Lh is  example  
i l l us t ra tes ,  the  l ingu is t i c  adequacy  of" the  
insLrucL ions  does  not  on ly  depend on the  
qua l l Ly  o f  the  automated  learn ing  sLra teg ies  
but  a l so  on the  representat iv i ty  off a g iven  
\ ]earn ing  corpus  fo r  a morpho log ica l  pat tern .  
2, Formal i sm for the  ReEresentat ion  of 
Me r~ho~ic  a l  Rules 
\ ]here are two main types of ins t ruc t ion  the 
learn ing  a lgor i thm uses for the fo rmulat ion  
of morpho log ica l  rules: 
P re f ixa l  subst i tu t ion  ins t ruc t ions  change 
the beg inn ing  of a source in order to 
generate  the cor respond ing  target.  \]hey 
have Lhe genera \ ]  \]'arm 
X-> Y /# (Z(1) l  . . .  IZ ( i ) f  . . .  ~Z(n) ) .  
Such an ins t ruct ion  means:  If a source  
beg ins  w i th  Lhe s t r ing  X and J fi 
immedJ, a te ly  on the  r ight  of X fo l lows  the  
s t r ing  Z( \ ] . )  o r  . . .  or  Z ( i )  o r  . . .  o r  
Z (n)~ then  subst i tu te  X by Y. ( '#"  
s ign i f ies  the  word-boundary  and 
marks  the  pos i t ion  where  X must occur  in  
o rder  Lo be subst  i. Lu tab le  by Y, namely  a t  
Lhe beg inn ing  sl' a source  ( r ight  off " #" ) 
and immediate .}y  be fore  Z(1)  or  . . .  or  
Z( \ ] . )  or . . .  at" Z (n) ) .  
~uf f l i xa . l  subst J ,  tuL ion  \ ]ns t rucL Jons  change 
the  end o f  a source  in  o rder  to  generate  
the  cor respond ing  ta rget .  Ihey  have the  
form 
X -> Y/(Z( \ ] ) I  ... IZ(J)I ... IZ(n)) #. 
rhe mean ing  off such an ins t ruc t ion  .is:IF 
a source ends with the st r ing X and if 
imme( l iaLe ly  on Lhe left: of  X is the  
str.tng Z(1) or ... or Z(i) or .. .or Z(n), 
then subst i tu te  X by Y. 
Each seE of" ins t ruc t ions  const ructed  by the 
learn ing  a lgor i thm Js ordered,  i. e. the 
later app l i ca t ion  of the ins t ruc t ions  to a 
g iven source  mus~ be tr ied i n  a f ixed 
sequence  in order  to generate  a target:  The 
f irst app l i cab le  prefiixa\] i ns t ruc t ion  in the 
sequence  of pref ixa l  subst i tu t ion  
ins t ruc t ions  must be determined  and the 
f irst app l i cab le  su f f ixa l  inst ruct  Jan in the 
sequence  of su f f ixa l  subsL i tu t ion  
ins t ruc t ions  must be determined.  Then, both 
must be app l ied  to the source concur rent ly ,  
thus generat ing  the target.  
the order and app l i ca t ion  of sets of 
ins t ruc t ions  may be i l l us t ra ted  by a smal l  
example:  Suppose  the learn ing  a lgor i thm has 
consLructed  Lhe Fo l lowing set of 
ins t ruc t ions  for the negat ion  of Eng l i sh  
ad jec t ives  (the seL i s  l i ngu is t i ca l l y  noL 
Fu l ly  adequate ;  "" i s  the  nu l l s \ ] r ing ,  i .  e. 
the  s t r ing  w iLh  the  length  0 ) :  
290 
\] ) -> 
2) -> 
~)  _> 
a)  -> 
5) -> 
F igure 2. 
i l ' /#  " l "  
i r ' /#  - - ' r "  
in" /#-~("  m" I" p" ) 
i n " /#.__  
" /  # 
Then the  negat ion  o f  "per fec t '  is Formed by 
F i r s t  determin ing  t i l e  f J r sL  app l i cab le  
pre f l J xa \ ]  subst i tuL ion  ins t ruct  i. on:  
( l )  is not  app l i cab le ,  s ince  "per fec t "  
does  noL beg in  w i th  "1" .  
(2 )  i s  not  app l i cab le ,  s ince  'per fec t : "  
does  not  beg in  w i th  "r  ". 
(3 )  i s  opp\ ] . Jeab le ,  s ince  "per fec t "  beg ins  
w i th  "p ", 
The f i r s t  app l i cab le  su f f l i xa l  subst : i t :u t Jon  
ins t ruct ion  Js the  on ly  su f f i xa l  : ins t runL Jon  
at. hand,  namely  (5 ) :  "per fec t "  ends w iLh  " ' .  
By the  concur renL  app . I J ca t ion  o f  (3 )  and (5 )  
to  "per fec t  " the  ta rget  ' imper fec t  " Js 
generated ,  wh ich  \ ] s  t:he negaL ion  o f  
"per fec t  ". 
3, Anatomy o f  the  System for  the  Aufomalnd  
L e a.?ni r?~_9 fi _M o ~_tip~11 p? i  c s l R u \] e s 
l he  sysLem Js wr i t ten  J.n the  programming 
language PL / I .  I t  has the  name PRISM, wh ich  
is an acronym fo r  "PRogram For tile In ferennc 
and S JmulaL ion  of' Morpho log ica l  ru\].es'. 
PRISM has the  macro s t ruc ture  shown Jn 
F igure 3. At an actJvat ion of PRISM, its 
main procedure  MONITOR at f irst ac t ivates  
GETOPTN ~lhJch reads \]:he user 's  opt ions  For 
|111o contro l  of PRISM and checks them for 
synLact Jc  we\] \ ] . - Formedness  and For 
p laus : ih i l J tyo  \[hen MONIIOR act iva fes  Lhe 
component  ind icaLed  by the  user  "S COl / i re \ ]  
opt ions.  ~here are three a l te rnat ive  
components  : 
- A learn ing component  which infers  sels of 
Jns t rue l Jons  From a \ ]earn ing  corpus gJvee 
by the  user  o f  PRISM. Th:is component  
compr ises  the  procedures  I:ItKCRPS, DISCOV, 
STMT\[}UT, TODSE\], and o thers .  \ ]he  learn ing  
process  i s  per fo rmed by DIS('OV. The o ther  
procedures  per fo rm per iphera l  funct ions .  
A componenL For  the  app l : i ca t ion  o f  
ins t ruct ions  ~h ich  were  in fe r red  by the  
\ ] .earn ing  component ,  lh i s  component  
compr ises  the  procedures  FRODSE\], APPLY, 
DERIVE, and o thers .  
A th i rd ,  marg ina l  component  wh ich  
prepares  ins t rac t ions  For  the i r  p r in tout .  
IL cons is ts  of FRODSE\[ ,  S IM\]OU\] ,  and 
other  procedures .  
The aet:J vat \ ]on of the learn ing  
a lgor i thm starts  with a call  of CHKCRPS by 
MONITOR.  CHK(}RPS cheeks a g iven learn ing  
corpus for formal errors.  The procedure  
ac t ivated  next. is DISCOV~ which per fo rms the 
learn ing  processes .  DISI'OV first determines  
Lhe d i f fe rent  types of subst i tu t ion  pat terns  
in the qiven \ ]earn inq  corpus. Types of 
"1 . . . . . . . . . . . . . . . . .  4"  -I ............. I" 
! M 0 N I I 0 R ! . . . . . . . . . . . . . .  >t GETOPTN 
4 . . . . . . . . . . . . . . . .  f I r + + . . . . . . . . . .  + 
V V V 
. . . . . . . . . . . . . . . . . .  < . . . . . . . . . . . . . . . . . . . . .  + ! + . . . . . . . . . . . . . . . . . . .  > . . . . . . . . . . . . . . . . . . . . . . .  ~_ 
V V V 
\] .earn. i .  ng of" app\ ] . i caL ion  of" p r inLeut  of  
Lns l : rucL Jone  i net: r LIC t: J. one i r / s l : ruuL iona  
! + . . . . . . . . . .  + ! -J . . . . . . . . . . .  + + . . . . . . . . . .  j. ! 
+->!  CIIt<CRPS ! +->!  FRODSFT ! ! PRODSEI !<-+ 
! + . . . . . . . . . . .  +<====/  / ! + . . . . . . . . . .  F<=====/  /==>+ . . . . . . . . . .  + ! 
! / I.EARN1NG / ! / KNOWLEDGE / ! 
! -P . . . . . . . . . .  ,- / CORPUS / ! ~ . . . . . . . . . . .  ~. / BASE / + . . . . . . . . .  + ! 
+->\ [  DISCOV !<= / +->!  APPLY !<==/  / ! S IM IOUT !<-- ,  
! -P . . . . . . . . . . . . .  i ~ + . . . . . . . . .  F + . . . . . . . . .  + 
! + . . . . . . . . .  + V 
+->!  SIMTOUT ! / / + . . . . . . . . .  + / / 
! .i . . . . . . . . . .  + / SOURCES /=>!  DERIVE !=>I TARGErS / 
! / / + . . . . . . . . .  + / / 
! "l . . . . . . . . . . .  F 
+->!  I OI)SET !=> KNOWLEDGE / 
+ . . . . . . . . . . . .  + / BASE / 
/ / 
F. igure,  3.  Macro  eLrucLL i re  e l  PR ISM.  (For  rease l l s  oF lue Jd iLy  some macro  FeatL I res  
of  PRISM have  been . ignored  in  Lh is  char t . )  
subst ,  i LuL : i  en ps i :barns  ace Ehe d iF ferenL  
(X ,  Y ) -pa i rs  wh ich  are  iml ) l i c i L ly  p resenL  in  
Lhe learn J ,  og carpus .  (For  Lhe eLabus  of` X 
and Y cempare  Lhe deF : in iL ion  oF the  
fo rmal . Jam I 'o r  Lhe repreeenLat ion  oF 
merpho lag J  c:a.l ru Jeso  ) \ [ t ie  second st :ep o f  
\[) I S(~(\]V cempLiLes Lhe f requency  ef` each  
subst . . i LuL ion  patLern  in  I:he eor t Jas .  D\]SI~E\]V's  
learn ing  st. raLegy  presur )poses  LhaL  Lhe 
subs  b J lL lt : . ier l  pa \ [ :~:erns  oeet l r r Jng  more  
I requenf \ ] .y  Jn a \] anguage a lso  eecur  more  
F requent ly  J n Lbe \] earn : ing  corpus .  I here f 'o re  
D1SCOV creates  more  genera l  J. nst. rueL iona  Per  
Lhe mare  f ' requent  poLLerna  of" a lear r l iog  
corpus  and more spec i f i c  \]liSP. surE:bOl lS fop  
Lhe \ ] .ens f ' requenL  patLerns  oF o learn ing  
corpue~ J .  o .  the  conLexLuo\ ]  sbr inge  Z( i )  of" 
an Jn,<;Lrue|:.i. or~ X --> Y/# (Z ( \ ] ) \ ]  ... 
iZ ( : i ) !  . . .  IZ (n ) )  o r  X ->  Y~(Z( \ ] . ) I  . . .  
tZ ( : i ) l  . . .  IZ (n ) )  tt a re  l :he more  genera l  
Lhe more  f requer l t ,  l y  Lhe eubsL~t:u l : : i ,  on pat:LeFr~ 
(X~ Y) aeeUrSo  They  are  bbe more  spee l f ' . i e  
\[-.he mere  rare ly  t. he aubsL J  t. uL.i. on pal:t ,  e rn  
occurs .  P rov ided  LhaL  a learn : ing  oo?pus  JS 
represen l .a t : \ ]  ve of" Lhe morpho laq ica l  SUb-  
a t J t .  uL Jon  pa l : te rns  of` a \ ] .anguage and Lhe 
conLexLua\ ]  at. r ings  Z( J ) ,  t :h ie  genera \ ] .  
sL ra t ,  egy  Far  Lhe deLermJeaL Jon  of'  t. he Z( J )  'a 
inc reases  t. he probab J l J Ly  thaL  the  in fer red  
: ins f .r  ue I::i ons  generate  cor rect  ta rgeLs  For  
sueh  sour ( ' ,es  as a re  not. e lements  oF t, he 
g iver l  \ ] .ear r l ing  corpus .  D\[SCOV ar ranges  Lhe 
subsL i l :u t Jnn  inaLruct ton ,s  in  such  a way t. bat. 
Lhe more  npee i f ' J .e  ins t .  rueL Jons  precede t:he 
more  genera l  odes .  rh i s  o rder  of` the  in -  
st. rueL ions  guarant ,  ees  dur J .  ng t, he J r  \ ]a le r  ap -  
p \ ] i caL ion  Lhat:  pot, e r l L ia \ ] . l y  each  tns l .  cL~et, io l /  
can  be app l ied .  S IHTOU\ ]  L rans forms subst : i tu -  
t. i on  ins t rh lcL : ions  in fer i ted  by I ) IS(:OV From 
Lhe i r  inLer r la l ,  re lDresent ,  aL Jen  ~ whJcb  a l iens  
l he i r  easy  and fasL  aubomabie  breaLmenL ,  
in to  an externa l  represer lLaL lon  and pr inLs  
thenl  ouL .  For  Lh.ts  ext,  e rna i  represenLaL lon  
Lhe noLat ,  ion  is  used which  was : in t : raduced 
above  :in Lhe def ' in J l : i ons  off the  l:wo t. ypes  oF 
subst ,  i i  uL ion  in , sL rucL ions .  F . tna \ ]  \ ]y  TOI)SE \[ 
s la tes  Lhe ~ I\] a \[~ ? ill? ~, J one in  an exberns \ ]  
knowledge base ,  From i~h ieh  Lhey  can  I s le t  be 
read  by t. he oLher  |.wo componenLs  off PR ISM 
( In  Lhe l<r lo l l / ledqe base  Lhe J. nsbrL icL J ,  ons  are  
seared  J. rl theJ .  r inLet 'na \ ]  t 'epresenLaL ion) .  
The spp\ ] l caL lon  component ,  sLarLs  ~/ J th  
EROI )SE I ,  ~h Jeh  loads  a set. of" insbrucL ions  
I-o be npp J ied  From Lhe knowledge base  lo  Lhe 
eenLra l  memory .  Then l. he Ewe procedures  
APPLY and DERIVE app ly  Lbe ins t ,  I . 'uet : ions  Lo 
~/orde g ives  by Lhe user  and Lhereby  generaLe  
Large l . s  i~/hJch are  ~l Jr i t :Len to  an ouLpuL  data  
set : .  \ [he  I< i. nd of  morpho log ica l  re laL J ,  en  
beLween bhe generabed Larget -s  and t. he g iven  
wards  depends  on l. he apee i f J ,  c see af` Jn-- 
sL \ [ 'uc l ,  J ona  wh ich  is app l ied .  
4.  ~_LaLu~LL~n ~_r L??_Sy,,~Lem 
\ [he  per f `ormanee of" PRISM ~J/as eva luaLed L lnder  
the  Fo\],J. uw ing  cond i t . : i ons .  
\ ] .  A see oF i nsLruc l .  J one st lou. ' \ [d a lways  
generat ,  e cor rect .  Lai~gef. s i f '  i L  l a  app l led  
Lo t. he souz 'ces  of" Lhe learn ing  corpus  
From u /b ich  i L  was in fer red .  
2.  The la rger  Lhe learn ing  corpHs  Js For  a 
g iven  morpho Jog ica l  re laL ion ,  the  h lghar  
shou ld  be on average  t. he percenLage of" 
cor rec l : \ ]y  genet 'abed t. acget :s  f 'o r  such  
sources  as a re  not: e \ ] .emenbs  of` the  
learnLng car  pu,q (buL  never t ,  he less  
291 
part ic ipate in the given morphologica l  
relation). 
3. A set of instruct ions inferred From a 
l inguist ica l ly  representat ive learning 
corpus should generate correct targets 
for at \].east 90% of the sources which are 
not elements off the learning corpus (but 
which nevertheless  part ic ipate in the 
morphologica l  re lat ionship under discus- 
sion). 
4. If a l inguist ica l ly  representat ive 
learning corpus is given, the learning 
algor i thm should classify as regular 
those morphologica l  patterns which 
l inguists also usually c lassi fy as 
regular. 
Condit ion i is fulf i l led. This could be 
proved deduct ively with reference to the 
structure of the learning algorithm. (The 
proof is given in Wothke 1985, 144-154.) 
The fulf i lment of condit ions 2-4 could 
only be tested induct ively by applying 
PRISM's learning algorithm to di f ferent 
learning corpora and evaluat ing the results. 
Condit ion 2 was tested by applying the 
learning component to  learning corpora of 
di f ferent sizes compi led For two morphologi -  
cal relations: der ivat ion of nomina actionis 
from verbs in German (e. g.: "betreuen" -> 
"8etreuung'), der ivat ion of Female nouns 
from male nouns in French (e. g.: 
"spectateur" -> "spectaLrice').  With the 
sets  of instruct ions inferred from these  
learning corpora PRISM's appl icat ion com- 
ponent generated targets for a set of words 
not in the learning corpora. The stat ist ical  
results of these tests showed that the per- 
centage of correct ly generated targets For 
such sources as are not elements of the 
learning corpus is, on average, the higher 
the larger the learning corpus is. A Further 
important result was that the percentage of 
correct ly generated targets is the  higher 
the more regular the morphologica l  relat ion 
is: The tests yielded better results For the 
more reguiar der ivat ion of Female nouns from 
male nouns in French than For the less 
regular der ivat ion of nomina actionis Form 
verbs in German. 
To test the Fulf i lment of the third 
condit ion representat ive learning corpora 
were manual ly compi led For the der ivat ion of 
nomina act ionis From verbs in German (9.167 
source- target -pa i rs )  and For the der ivat ion 
of female nouns from male nouns in French 
(89 source-target-pai rs) .  The two sets of 
instruct ions automakieal ly  inferred from 
these two corpora were appl ied Lo large sets 
of sources which were not members of the 
learning corpora (4.793 sources for German, 
211 sources for French). In both cases the 
percentage of correct ly generated targets 
was iOO~. 
Condit ion 4 was tested with learning 
corpora for the p lura l izat ion of Engl ish 
nouns and For the der ivat ion of female nouns 
from male nouns in French. An exact quanti-  
f ication of the degree of accuracy is not 
292 
possible, since this condit ion contains some 
vague express ions  such as "regular" and 
"usually" My subject ive judgement is that 
the instruct ions constructed by the learning 
algor ithm For (approximately) representat ive 
corpora are quite similar to the morphologi-  
cal regular i t ies descr ibed in t rad J t iona I  
grammars. This may be i l lustrated by an ex- 
ample: The learning corpus shown in Figure 
is approximately  representat ive for the 
regular p lura l izat ion patterns of Engl ish 
nouns. From this corpus PRISM inferred the 
Fol lowing set of instruct ions which 
represent the most important p lura l izat ion 
ru les :  
( l )  " ->  " / #  
(2)  " f "  -> 'yes ' /  # 
(3)  " re"  -> "yes . ' /  # 
(4)  "y" -> " ies ' / (  "d ' l  " l ' i  "p ' i  ' r '~  "t ' )  # 
(5)  ' '  --> "ca ' / (  "oh ' i  " sh ' t  " s ' l  "x ' \ [  "z " )# 
(6) " '  -> "s ' /  # 
_ _ I  
Figure 4. 
5. Unso lved  Problems 
- The Formalism which PRISM uses For the 
representat ion of the instruct ions is 
designed For the descr ipt ion of graphemie 
changes at: tile beginning and/or at the 
end of a word. Thus this Formal ism Js 
inadequate For the descr ipt ion o? changes 
in the interior of a word. These, how- 
ever ,  occur  more ra re ly  t_han t~he changes  
at: the  beg inn ing  or  a t  the  end.  A so lu -  
t ion  to  th i s  p rob lem,  wh ich  cou ld  cons is t .  
in  the  des ign  o f  a new Formal i sm whose 
express ions  cou ld  a l so  be \ ] .earned 
automat ica l ly ,  has not  as yet: been Found. 
PRISM cannot recognize except ions in a 
learning corpus and treat them 
adequately. I f ,  for instance, the 
learning corpus in Figure 1 would also 
contain the pair ('goose', "geese) ,  
PRISM would infer the prefixal substitu- 
tion instruct ion "goo" -> "gee'/# and 
insert it in the set of instruct ions 
shown in Figure 4 before instruct ion (1). 
Furthermore PRISM would infer the suf- 
Fixal instruct ion " ' -> ' " / ' ose"  # and 
insert it before instruct ion (3). IF this 
new set of instruct ions is appl ied to the 
nouns "good', "goodness" and "goon" the 
incorrect plurals "geeds', "geednesses" 
and "gowns' are generated. - It would be 
preferable for PRISM to identi fy excep- 
tions as such and store them in a list of 
except ions instead of inferr ing 
overgenera l iz ing instruct ions from them. 
If a set of instruct ions is l inguist i -  
cally inadequate, the user of PRISM must 
First make the learning corpus more 
representat ive by adding suitable exam- 
plea. Then he must act ivate the learning 
component of PRISM ~hich infers a total ly 
new set  of instruct ions.  Perhaps  it 
~ould be better if PRISM could infer new 
instruct ions only From the ne~ examples 
and then synthesize these ne~ instruc- 
L ions  w iLh  the  f io rmer ly  in fe r red  and 
l Jngu isL iea l ly  inadequaLe  JnsLrueL ions  
Lo g ive  a new, more adequaLe  seL off in -  
s t rucL ions .  
References  
Cohen,  P. R . /F  e igenbaum,  E. A. (Eds , )  
( \ ]982) :  lhe  handbook  o f  ac t i f l i e ia \ ]  Jn -  
Le l l igence .  Vo l .  3. London.  
Jansen-  Win l<e ln ,  R. M. (1985): I ndukL Jves  
kez 'nen van q\['ammaL:i.l<iregeln aus ausgew~i~.\[-  
Len Be isp ie len .  In :  Savory ,  S. E. (Ed . )  
(1985): K~nst l i che  InLe l J igenz  und Exper -  
Lensystome.  \[_in Porschungsber J  chL der  
NJ. xdorF  AG, 2nd ed,  M\[inchcn/WJ. en,  
PP. 211 223. 
Oakey, S . /Cawlhorn ,  R. \[:. (\]981): Induct ive 
\ ]earn ing  o f  p ronune ia f . /on  ru les  by 
hypot,  hesLs  I. esL ing  and cor rect ,  i on .  In: 
Proceed ings  o f  Lhe 7Lh InLez 'naL iana l  
gp in t :  \ [ :onFerence  on ArL J f J cLa l  \ [n -  
Le l \ ] igence .  AugusL 1981.  Vo l .  1. 
PP. \ ]09 -114,  
P inkez" 9 S. ( \ ]979) :  Formal  mode ls  off \ ]anguage 
\ [earn inc l .  In :  ( :ogn iL ion  3. PP. 217-283.  
Ring~ II. (1978): PEI. IKAN - eJn Le \ [ 'nsys lem 
fdr  \ [ ingu JsL i sche  l< lass iF tkaL ions  - 
a \ ]gor iLhmen.  In :  Nach\ ] ' i eht -en  fldz" Dokumen-  
Lat. i on  6. PP. 224-226.  
Woi f~ E. ( \ ]977) :  Vom BuchsLaben zum Laut . .  
Masch ineL \ ]e  Erzeugung und Erpt 'ebung yon 
UmseLzauLonlaLen am Oe isp ie l  Scht'J FLeng-  
l Jsch Phono. log Jsehes  t .~ng l i sch .  
Braunseh l~e ig .  
WoLhke~ K, (1984}:  PRISM User ' s  Gu:ide. Bonn.  
(= IKP -A~be i t .  sbe\ ]~ie l lL  No. 5) 
Wot. hke ,  K. (1985) :  Masch ine l \ ] .e  ? r le rnung und 
Simu.\[ aL i(~n morpho . \ [og ischer  Ab\] e iLung .s re -  
ge ln .  Bonn.  (DocLora \ ]  d i sse l~taL ion) .  
A det. a J led  t : reaLmenL off Lhe \ [heme dea lL  ~JLb 
i r l  f ih i s  papeL" i s  g iven  in  Wot:hke (1985) .  
293 
