Proceedings of SSST, NAACL-HLT 2007 / AMTA Workshop on Syntax and Structure in Statistical Translation, pages 33?40,
Rochester, New York, April 2007. c?2007 Association for Computational Linguistics
Binarization, Synchronous Binarization, and Target-side Binarization?
Liang Huang
University of Pennsylvania
3330 Walnut Street, Levine Hall
Philadelphia, PA 19104
lhuang3@cis.upenn.edu
Abstract
Binarization is essential for achieving
polynomial time complexities in pars-
ing and syntax-based machine transla-
tion. This paper presents a new binariza-
tion scheme, target-side binarization, and
compares it with source-side and syn-
chronous binarizations on both string-
based and tree-based systems using syn-
chronous grammars. In particular, we
demonstrate the effectiveness of target-
side binarization on a large-scale tree-to-
string translation system.
1 Introduction
Several recent syntax-based models for machine
translation (Chiang, 2005; Galley et al, 2006) can
be seen as instances of the general framework of
synchronous grammars and tree transducers. In this
framework, decoding can be thought of as pars-
ing problems, whose complexity is in general expo-
nential in the number of nonterminals on the right
hand side of a grammar rule. To alleviate this prob-
lem, one can borrow from parsing the technique
of binarizing context-free grammars (into Chomsky
Normal Form) to reduce the complexity. With syn-
chronous context-free grammars (SCFG), however,
this problem becomes more complicated with the
additional dimension of target-side permutation.
The simplest method of binarizing an SCFG is
to binarize (left-to-right) on the source-side as if
treating it as a monolingual CFG for the source-
langauge. However, this approach does not guaran-
?This work is partially supported by NSF ITR grants IIS-
0428020 (while I was visiting USC/ISI) and EIA-0205456. I
also wish to thank Jonathan Graehl, Giorgio Satta, Hao Zhang,
and the three anonymous reviewers for helpful comments.
tee contiguous spans on the target-side, due to the ar-
bitrary re-ordering of nonterminals between the two
languages. As a result, decoding with an integrated
language model still has an exponential complexity.
Synchronous binarization (Zhang et al, 2006)
solves this problem by simultaneously binarizing
both source and target-sides of a synchronous rule,
making sure of contiguous spans on both sides
whenever possible. Neglecting the small amount
of non-binarizable rules, the decoding complexity
with an integrated language model becomes polyno-
mial and translation quality is significantly improved
thanks to the better search. However, this method is
more sophisticated to implement than the previous
method and binarizability ratio decreases on freer
word-order languages (Wellington et al, 2006).
This paper presents a third alternative, target-
side binarization, which is the symmetric version of
the simple source-side variant mentioned above. We
compare it with the other two schemes in two pop-
ular instantiations of MT systems based on SCFGs:
the string-based systems (Chiang, 2005; Galley et
al., 2006) where the input is a string to be parsed
using the source-side of the SCFG; and the tree-
based systems (Liu et al, 2006; Huang et al, 2006)
where the input is a parse tree and is recursively
converted into a target string using the SCFG as a
tree-transducer. While synchronous binarization is
the best strategy for string-based systems, we show
that target-side binarization can achieve the same
performance of synchronous binarization for tree-
based systems, with much simpler implementation
and 100% binarizability.
2 Synchronous Grammars and
Binarization Schemes
In this section, we define synchronous context-
free grammars and present the three binarization
33
NP
PP
VP
Chinese ??
En
gl
ish
??
NP-PP
NP-PP
VP
contiguous
ga
p
NP
PP-VP
contiguous
co
n
tig
uo
us
PP
N
P-
V
P
N
P-
V
P
gap
co
n
tig
uo
us
(a) example rule (b) source-side (c) synchronous (d) target-side
Figure 1: Illustration of the three binarization schemes, with virtual nonterminals in gray.
schemes through a motivational example.
A synchronous CFG (SCFG) is a context-free
rewriting system for generating string pairs. Each
rule (synchronous production) rewrites a nontermi-
nal in two dimensions subject to the constraint that
the sequence of nonterminal children on one side is
a permutation of the nonterminal sequence on the
other side. Each co-indexed child nonterminal pair
will be further rewritten as a unit. The rank of a rule
is defined as the number of its synchronous nonter-
minals. We also define the source and target projec-
tions of an SCFG to be the CFGs for the source and
target languages, respectively.
For example, the following SCFG1
(1)
S ? NP 1 PP 2 VP 3 , NP 1 VP 3 PP 2
NP ? Baoweier, Powell
VP ? juxing le huitan, held a meeting
PP ? yu Shalong, with Sharon
captures the re-ordering of PP and VP between
Chinese (source) and English (target). The source-
projection of the first rule, for example, is
S ? NP PP VP.
Decoding with an SCFG (e.g., translating from
Chinese to English using the above grammar) can be
cast as a parsing problem (see Section 3 for details),
in which case we need to binarize a synchronous rule
with more than two nonterminals to achieve polyno-
mial time algorithms (Zhang et al, 2006). We will
next present the three different binarization schemes
using Example 1.
1An alternative notation, used by Satta and Peserico (2005),
allows co-indexed nonterminals to take different symbols across
languages, which is convenient in describing syntactic diver-
gences (see Figure 2).
2.1 Source-side Binarization
The first and simplest scheme, source-side binariza-
tion, works left-to-right on the source projection of
the SCFG without respecting the re-orderings on the
target-side. So it will binarize the first rule as:
(2) S ? NP-PP VPNP-PP ? NP PP
which corresponds to Figure 1 (b). Notice that the
virtual nonterminal NP-PP representing the inter-
mediate symbol is discontinuous with two spans on
the target (English) side, because this binarization
scheme completely ignores the reorderings of non-
terminals. As a result, the binarized grammar, with
a gap on the target-side, is no longer an SCFG, but
can be represented in the more general formalism of
Multi-Text Grammars (MTG) (Melamed, 2003):
(3)
(
S
S
)
??? [1, 2][1, 2, 1]
(
NP-PP VP
NP-PP (2) VP
)
here [1, 2, 1] denotes that on that target-side, the first
nonterminal NP-PP has two discontinuous spans,
with the second nonterminal VP in the gap.
Intuitively speaking, the gaps on the target-side
will lead to exponential complexity in decoding with
integrated language models (see Section 3), as well
as synchronous parsing (Zhang et al, 2006).
2.2 Synchronous Binarization
A more principled method is synchronous binariza-
tion, which simultaneously binarizes both source
and target sides, with the constraint that virtual non-
terminals always have contiguous spans on both
sides. The resulting grammar is thus another SCFG,
the binary branching equivalent of the original gram-
mar, which can be thought of as an extension of the
34
[jinyibu]1
further
[ jiu
on
zhongdong
Mideast
weiji
crisis
]2 [juxing]3
hold
[huitan]4
talk
?[hold]3 [further]1 [talks]4 [on the Mideast crisis]2?
1
2
3
4
Chinese ??
En
gl
ish
??
Figure 2: An example of non-binarizable rule from the hand-aligned Chinese-English data in Liu et al
(2005). The SCFG rule is VP ? ADVP 1 PP 2 VB 3 NN 4 , VP ? VB 3 JJ 1 NNS 4 PP 2 in the notatoin
of Satta and Peserico (2005).
Chomsky Normal Form in synchronous grammars.
The example rule is now binarized into:
(4) S ? NP
1 PP-VP 2 , NP 1 PP-VP 2
PP-VP ? PP 1 VP 2 , VP 2 PP 1
which corresponds to Figure 1 (c). This represen-
tation, being contiguous on both sides, successfully
reduces the decoding complexity to a low polyno-
mial and significantly improved the search quality
(Zhang et al, 2006).
However, this scheme has the following draw-
backs. First, synchronous binarization is not always
possible with an arbitrary SCFG. Some reorder-
ings, for example, the permutation (2, 4, 1, 3), is
non-binarizable. Although according to Zhang et al
(2006), the vast majority (99.7%) of rules in their
Chinese-English dataset are binarizable, there do ex-
ist some interesting cases that are not (see Figure 2
for a real-data example). More importantly, the ra-
tio of binarizability, as expected, decreases on freer
word-order languages (Wellington et al, 2006). Sec-
ond, synchronous binarization is significantly more
complicated to implement than the straightforward
source-side binarization.
2.3 Target-side Binarization
We now introduce a novel scheme, target-side bi-
narization, which is the symmetric version of the
source-side variant. Under this method, the target-
side is always contiguous, while leaving some gaps
on the source-side. The example rule is binarized
into the following MTG form:
(5)
(
S
S
)
??? [1, 2, 1][1, 2]
(
NP-VP (2) PP
NP-VP PP
)
which corresponds to Figure 1 (d).
scheme s(b) t(b)
source-side 1 ? n/2
synchronous 1 1
target-side ? n/2 1
Table 1: Source and target arities of the three bina-
rization schemes of an SCFG rule of rank n.
Although the discontinuity on the source-side in
this new scheme causes exponential complexity in
string-based systems (Section 3.1), the continuous
spans on the target-side will ensure polynomial com-
plexity in tree-based systems (Section 3.2).
Before we move on to study the effects of vari-
ous binarization schemes in decoding, we need some
formal machineries of discontinuities.
We define the source and target arities of a
virtual nonterminal V , denoted s(V ) and t(V ), to
be the number of (consecutive) spans of V on the
source and target sides, respectively. This definition
extends to a binarization b of an SCFG rule of rank
n, where arities s(b) and t(b) are defined as the
maximum source and target arities over all virtual
nonterminals in b, respectively. For example, the
source and target arities of the three binarizations in
Figure 1 are 1 and 2 for (b), 1 and 1 for (c), and
2 and 1 for (d). In general, the arities for the three
binarization schemes are summarized in Table 1.
3 Theoretical Analysis
We now compare the algorithmic complexities of the
three binarization schemes in a central problem of
machine translation: decoding with an integrated n-
gram language model. Depending on the input be-
ing a string or a parse-tree, we divide MT systems
based on synchronous grammars into two broad cat-
egories: string-based and tree-based.
35
3.1 String-based Approaches
String-based approaches include both string-to-
string (Chiang, 2005) and string-to-tree systems
(Galley et al, 2006).2 To simplify the presentation
we will just focus on the former but the analysis also
applies to the latter. We will first discuss decoding
with a pure SCFG as the translation model (hence-
forth ?LM decoding), and then extend it to include
an n-gram model (+LM decoding).
3.1.1 Translation as Parsing
The ?LM decoder can be cast as a (monolin-
gual) parser on the source language: it takes the
source-language string as input and parses it using
the source-projection of the SCFG while building
the corresponding target-language sub-translations
in parallel. For source-side and synchronous bina-
rizations, since the resulting grammar has contigu-
ous source spans, we can apply the CKY algorithm
which guarantees cubic time complexity.
For example, a deduction along the virtual rule in
the synchronously binarized grammar (4) is notated
(PPj,k) : (w1, t1) (VPk,l) : (w2, t2)
(PP-VPj,l) : (w1 + w2, t2t1) (6)
where i, j, k are free indices in the source string,
w1, w2 are the scores of the two antecedent items,
and t1, t2 are the corresponding sub-translations.3
The resulting translation t2t1 is the inverted concate-
nation as specified by the target-side of the SCFG
rule.
The case for a source-side binarized grammar (3)
is slightly more complicated than the above, because
we have to keep track of gaps on the target side. For
example, we first combine NP with PP
(NPi,j) : (w1, t1) (PPj,k) : (w2, t2)
(NP-PPi,k) : (w1 + w2, t1 ? t2) (7)
2Our notation of X-to-Y systems is defined as follows: X de-
notes the input, either a string or a tree; while Y represents the
RHS structure of an individual rule: Y is string if the RHS is
a flat one-level tree (as in SCFGs), and Y is tree if the RHS
is multi-level as in (Galley et al, 2006). This convention also
applies to tree-based approaches.
3The actual system does not need to store the translations
since they can be recovered from backpointers and they are not
considered part of the state. We keep them here only for presen-
tation reasons.
NP-PP
NP-PP
VP
three Chinese indices
i k l
En
gl
ish
tr
an
sla
tio
ns
t 1
t 3
t 2 PP
N
P-
V
P
N
P-
V
P
four Chinese indices
i j k l
t 1
t 2
(a): Deduction (8) (b): Deduction (10)
Figure 3: Illustrations of two deductions with gaps.
leaving a gap (?) on the target-side resulting item,
because NP and PP are not contiguous in the En-
glish ordering. This gap is later filled in by the sub-
translation t3 of VP (see also Figure 3 (a)):
(NP-PPi,k) : (w1, t1 ? t2) (VPk,l) : (w2, t3)
(Si,l) : (w1 + w2, t1t3t2)
(8)
In both cases, there are still only three free indices
on the source-side, so the complexity remains cubic.
The gaps on the target-side do not require any ex-
tra computation in the current ?LM setting, but as
we shall see shortly below, will lead to exponential
complexity when integrating a language model.
For a target-side binarized grammar as in (5),
however, the source-side spans are discontinuous
where CKY can not apply, and we have to enumerate
more free indices on the source side. For example,
the first deduction
(NPi,j) : (w1, t1) (VPk,l) : (w2, t2)
(NP-VPi,j?k,l) : (w1 + w2, t1t2) (9)
leaves a gap in the source-side span of the resulting
item, which is later filled in when the item is com-
bined with a PP (see also Figure 3 (b)):
(NP-VPi,j?k,l) : (w1, t1) (PPj,k) : (w2, t2)
(Si,l) : (w1 + w2, t1t2)
(10)
Both of the above deductions have four free in-
dices, and thus of complexity O(|w|4) instead of cu-
bic in the length of the input string w.
More generally, the complexity of a binarization
scheme depends on its source arity. In the worst-
case, a binarized grammar with a source arity of s
will require at most (2s+1) free indices in a deduc-
tion, because otherwise if one rule needs (2s + 2)
36
indices, then there are s+1 spans, which contradicts
the definition of arity (Huang et al, 2005).4
These deductive systems represent the search
space of decoding without a language model. When
one is instantiated for a particular input string, it de-
fines a set of derivations, called a forest, represented
in a compact structure that has a structure of a hyper-
graph. Accordingly we call items like (PP1,3) nodes
in the forest, and an instantiated deduction like
(PP-VP1,6) ? (PP1,3)(VP3,6)
we call a hyperedge that connects one or more an-
tecedent nodes to a consequent node. In this rep-
resentation, the time complexity of ?LM decoding,
which we refer to as source-side complexity, is pro-
portional to the size of the forest F , i.e., the num-
ber of hyperedges (instantiated deductions) in F . To
summarize, the source-side complexity for a bina-
rized grammar of source arity s is
|F | = O(|w|2s+1).
3.1.2 Adding a Language Model
To integrate with a bigram language model, we
can use the dynamic-programming algorithm of Wu
(1996), which we may think of as proceeding in
two passes. The first pass is as above, and the sec-
ond pass traverses the first-pass forest, assigning to
each node v a set of augmented items, which we call
+LM items, of the form (va?b), where a and b are
target words and ? is a placeholder symbol for an
elided part of a target-language string. This item in-
dicates that a possible translation of the part of the
input spanned by v is a target string that starts with
a and ends with b.
Here is an example deduction in the syn-
chronously binarized grammar (4), for a +LM item
for the node (PP-VP1,6) based on the ?LM Deduc-
tion (6):
(PP with ? Sharon1,3 ): (w1, t1) (VP held ? talk3,6 ): (w2, t2)
(PP-VP held ? Sharon1,6 ): (w?, t2t1)
(11)
4Actually this is true only if in any binarization scheme,
a non-contiguous item is always combined with a contiguous
item. We define both source and target binarizations to be in-
cremental (i.e., left-to-right or right-to-left), so this assumption
trivially holds. More general binarization schemes are possible
to have even higher complexities, but also possible to achieve
better complexities. Full discussion is left for a separate paper.
where w? = w1 + w2 ? logPlm(with | talk) is
the score of the resulting +LM item: the sum of
the scores of the antecedent items, plus a combi-
nation cost which is the negative log probability of
the bigrams formed in combining adjacent boundary
words of antecedents.
Now that we keep track of target-side boundary
words, an additional complexity, called target-side
complexity, is introduced. In Deduction (11), four
target words are enumerated, and each +LM item
stores two boundary words; this is also true in gen-
eral for synchronous and target-side binarized gram-
mars where we always combine two consecutive
target strings in a deduction. More generally, this
scheme can be easily extended to work with an m-
gram model (Chiang, 2007) where m is usually ? 3
(trigram or higher) in practice. The target-side com-
plexity for this case is thus
O(|V |4(m?1))
where V is the target language vocabulary. This is
because each constituent must store its initial and
final (m ? 1)-grams, which yields four (m ? 1)-
grams in a binary combination. In practice, it is often
assumed that there are only a constant number of
translations for each input word, which reduces this
complexity into O(|w|4(m?1)).
However, for source-side binarization which
leaves gaps on the target-side, the situation becomes
more complicated. Consider Deduction (8), where
the sub-translation for the virtual node NP-PP is
gapped (t1?t2). Now if we integrate a bigram model
based on that deduction, we have to maintain the
boundary words of both t1 and t2 in the +LM node
of NP-PP. Together with the boundary words in node
VP, there are a total of six target words to enumerate
for this +LM deduction:
(NP-PPa?b?e?fi,k ) : (w1, t1 ? t2) (VPc?dk,l ) : (w2, t3)
(Sa?fi,l ) : (w?, t1t3t2)
(12)
where w? = w1 + w2 ? logPlm(c | b)Plm(e | d).
With an analysis similar to that of the source-side,
we state that, for a binarized grammar with target
arity t, the target-side complexity, denoted T , is
T = O(|w|2(t+1)(m?1))
37
scheme string-based tree-based
source-side |w|3+2(t+1)(m?1) |w|1+2(t+1)(m?1)
synchronous |w|3+4(m?1) |w|1+4(m?1)
target-side |w|(2s+1)+4(m?1) |w|1+4(m?1)
Table 2: Worst-case decoding complexities of the
three binarization schemes in the two approaches
(excluding the O(|w|3) time for source-side parsing
in tree-based approaches).
because in the worst-case, there are t + 1 spans in-
volved in a +LM deduction (t of them from one vir-
tual antecedent and the other one non-virtual), and
for each span, there are m ? 1 target words to enu-
merate at both left and right boundaries, giving a
total of 2(t + 1)(m ? 1) words in this deduction.
We now conclude that, in a string-based system,
the combined complexities for a binarized grammar
with source arity s and target arity t is
O(|F |T ) = O(|w|(2s+1)+2(t+1)(m?1)).
The results for the three specific binarization
schemes are summarized in Table 2. Although both
source-side and target-side binarizations lead to ex-
ponential complexities, it is likely that language
model combinations (target-side complexity) dom-
inate the computation, since m is larger than 2 in
practice. In this sense, target-side binarization is still
preferable to source-side binarization.
It is also worth noting that with the hook trick
of Huang et al (2005), the target-side complex-
ity can be reduced to O(|w|(2t+1)(m?1)), making
it more analogous to its source-side counterpart:
if we consider the decoding problem as intersect-
ing the SCFG with a source-side DFA which has
|S| = |w|+1 states, and a target-side DFA which has
|T | = O(|w|m?1) states, then the intersected gram-
mar has a parsing complexity of O(|S|2s+1|T |2t+1),
which is symmetric from both sides.
3.2 Tree-based Approaches
The tree-based approaches include the tree-to-string
(also called syntax-directed) systems (Liu et al,
2006; Huang et al, 2006). This approach takes
a source-language parse tree, instead of the plain
string, as input, and tries to find the best derivation
that recursively rewrites the input tree into a target
...
S? : t1t3t2
NP??1 : t1
...
PP??2 : t2
...
VP??3 : t3
...
Figure 4: Illustration of tree-to-string deduction.
string, using the SCFG as a tree-transducer. In this
setting, the ?LM decoding phase is a tree-parsing
problem (Eisner, 2003) which aims to cover the en-
tire tree by a set of rules. For example, a deduction
of the first rule in Example 1 would be:
(NP??1) : (w1, t1) (PP??2) : (w2, t2) (VP??3) : (w3, t3)
(S?) : (w1 + w2 + w3, t1t3t2)
(13)
where ? and ? ? i(i = 1, 2, 3) are tree addresses
(Shieber et al, 1995), with ? ? i being the ith child
of ? (the address of the root node is ?). The nonter-
minal labels at these tree nodes must match those in
the SCFG rule, e.g., the input tree must have a PP at
node ? ? 2.
The semantics of this deduction is the following:
if the label of the current node in the input tree is
S, and its three children are labeled NP, PP, and VP,
with corresponding sub-translations t1, t2, and t3,
then a possible translation for the current node S is
t1t3t2 (see Figure 4). An alternative, top-down ver-
sion of this bottom-up deductive system is, at each
node, try all SCFG rules that pattern-match the cur-
rent subtree, and recursively solve sub-problems in-
dicated by the variables, i.e., synchronous nontermi-
nals, of the matching rule (Huang et al, 2006).
With the input tree completely given, this setting
has some fundamental differences from its string-
based counterpart. First, we do not need to bina-
rize the SCFG grammar before ?LM decoding. In
fact, it will be much harder to do the tree-parsing
(pattern-matching) with a binarized grammar. Sec-
ond, regardless of the number of nonterminals in a
rule, building the ?LM forest always costs time lin-
ear in the size of the input tree (times a grammar
constant, see (Huang et al, 2006, Sec. 5.1) for de-
tails), which is in turn linear in the length of the input
string. So we have:
O(|F |) = O(|w|).
38
This fast ?LM decoding is a major advantage of
tree-based approaches.
Now in +LM decoding, we still need binariza-
tion of the hyperedges, as opposed to rules, in the
forest, but the analysis is almost identical to that of
string-based approach. For example, the tree-based
version of Deduction (12) for source-side binariza-
tion is now notated
(NP??1-PP??2a?b?e?f ) : (w1, t1 ? t2) (VP??3c?d) : (w2, t3)
(S?a?f ) : (w?, t1t3t2)
(14)
In general, the target-side complexity of a bina-
rized grammar with target arity t is still T =
O(|w|2(t+1)(m?1)) and the combined decoding com-
plexity of the tree-based approach is
O(|F |T ) = O(|w|1+2(t+1)(m?1)).
Table 2 shows that in this tree-based setting,
target-side binarization has exactly the same perfor-
mance with synchronous binarization while being
much simpler to implement and does not have the
problem of non-binarizability. The fact that simple
binarization works (at least) equally well, which is
not possible in string-based systems, is another ad-
vantage of the tree-based approaches.
4 Experiments
Section 3 shows that target-side binarization
achieves the same polynomial decoding complexity
as the more sophisticated synchronous binarization
in the tree-based systems. We now empirically com-
pare target-side binarization with an even simpler
variant, on-the-fly generation, where the only dif-
ference is that the latter does target-side left-to-right
binarization during +LM decoding on a hyperedge-
per-hyperedge basis, without sharing common vir-
tual nonterminals across hyperedges, while the for-
mer binarizes the whole ?LM forest before the
+LM decoding.
Our experiments are on English-to-Chinese trans-
lation in the tree-to-string system of Huang et al
(2006), which takes a source-language parse tree as
input and tries to recursively convert it to a target-
language string according to transfer rules in a syn-
chronous grammar (Galley et al, 2006). For in-
stance, the following rule
 0
 100
 200
 300
 400
 500
 600
 5  10  15  20  25  30  35  40
n
u
m
be
r o
f n
od
es
 in
 th
e 
fo
re
st
length of the input sentence
original forest
target-side binarization
on-the-fly generation
Figure 5: Number of nodes in the forests. Input
sentences are grouped into bins according to their
lengths (5-9, 10-14, 15-20, etc.).
VP
VBD
was
VP-C
x1:VBN PP
IN
by
x2:NP-C
? bei x2 x1
translates an English passive construction into Chi-
nese. Although the rules are actually in a syn-
chronous tree-substitution grammar (STSG) instead
of an SCFG, its derivation structure is still a hy-
pergraph and all the analysis in Section 3.2 still
applies. This system performs slightly better than
the state-of-the-art phrase-based system Pharaoh
(Koehn, 2004) on English to Chinese translation. A
very similar system for the reverse direction is de-
scribed in (Liu et al, 2006).
Our data preparation follows (Huang et al, 2006):
the training data is a parallel corpus of 28.3M words
on the English side, from which we extracted 24.7M
tree-to-string rules using the algorithm of (Galley et
al., 2006), and trained a Chinese trigram model on
the Chinese side. We test our methods on the same
test-set as in (Huang et al, 2006) which is a 140 sen-
tence subset of NIST 2003 MT evaluation with 9?36
words on the English side. The weights for the log-
linear model is tuned on a separate development set.
Figure 5 compares the number of nodes in the bi-
narized forests against the original forest. On-the-fly
generation essentially works on a larger forest with
39
 25
 25.2
 25.4
 25.6
 25.8
 26
 26.2
 5  10  15  20
 0
 20000
 40000
 60000
 80000
 100000
 120000
BL
EU
 s
co
re
a
ve
ra
ge
 #
 o
f +
LM
 it
em
s 
pe
r s
en
te
nc
e
beam size
BLEU score
on-the-fly generation
target-side binarization
Figure 6: Decoding speed and BLEU scores under
beam search.
duplicate nodes due to the lack of sharing, which is
on average 1.85 times bigger than the target-side bi-
narized forest. This difference is also reflected in the
decoding speed, which is illustrated in Figure 6 un-
der various beam settings and where the amount of
computation is measured by the number of +LM
items generated. At each individual beam setting,
the two methods produce exactly the same set of
translations (i.e., there is no relative search error),
but the target-side binarization is consistently 1.3
times faster thanks to the sharing. In terms of transla-
tion quality, the final BLEU score at the largest beam
setting is 0.2614, significantly higher than Pharaoh?s
0.2354 as reported in (Huang et al, 2006).
5 Conclusion
This paper introduces a simple binarization scheme,
target-side binarization, and presents a systematic
study of the theoretical properties of the three bina-
rization schemes in both string-based and tree-based
systems using syncrhonous grammars. In particular,
we show that target-side binarization achieves the
same polynomial complexity as synchronous bina-
rization while being much simpler to implement and
universally applicable to arbitrary SCFGs. We also
demonstrate the empirical effectiveness of this new
scheme on a large-scale tree-to-string system.
References
David Chiang. 2005. A hierarchical phrase-based model
for statistical machine translation. In Proceedings of
ACL.
David Chiang. 2007. Hierarchical phrase-based trans-
lation. In Computational Linguistics, volume 33. To
appear.
Jason Eisner. 2003. Learning non-isomorphic tree map-
pings for machine translation. In Proceedings of ACL
(poster), pages 205?208.
Michel Galley, Jonathan Graehl, Kevin Knight, Daniel
Marcu, Steve DeNeefe, Wei Wang, and Ignacio
Thayer. 2006. Scalable inference and training of
context-rich syntactic translation models. In Proceed-
ings of COLING-ACL.
Liang Huang, Hao Zhang, and Daniel Gildea. 2005. Ma-
chine translation as lexicalized parsing with hooks. In
Proceedings of the Ninth International Workshop on
Parsing Technologies (IWPT-2005).
Liang Huang, Kevin Knight, and Aravind Joshi. 2006.
Statistical syntax-directed translation with extended
domain of locality. In Proc. of AMTA.
Philipp Koehn. 2004. Pharaoh: a beam search decoder
for phrase-based statistical machine translation mod-
els. In Proceedings of AMTA, pages 115?124.
Yang Liu, Qun Liu, and Shouxun Lin. 2005. Log-linear
models for word alignment. In Proceedings of ACL.
Yang Liu, Qun Liu, and Shouxun Lin. 2006. Tree-to-
string alignment template for statistical machine trans-
lation. In Proceedings of COLING-ACL.
I. Dan Melamed. 2003. Multitext grammars and syn-
chronous parsers. In Proceedings of NAACL.
Giorgio Satta and Enoch Peserico. 2005. Some computa-
tional complexity results for synchronous context-free
grammars. In Proc. of HLT-EMNLP 2005.
Stuart Shieber, Yves Schabes, and Fernando Pereira.
1995. Principles and implementation of deductive
parsing. Journal of Logic Programming, 24:3?36.
Benjamin Wellington, Sonjia Waxmonsky, and I. Dan
Melamed. 2006. Empirical lower bounds on the com-
plexity of translational equivalence. In Proceedings of
COLING-ACL.
Dekai Wu. 1996. A polynomial-time algorithm for sta-
tistical machine translation. In Proceedings of ACL.
Hao Zhang, Liang Huang, Daniel Gildea, and Kevin
Knight. 2006. Synchronous binarization for machine
translation. In Proc. of HLT-NAACL.
40
