Hypothesis Selection in Machine Transliteration: A Web Mining Approach
Jong-Hoon Oh and Hitoshi Isahara
Computational Linguistics Group
National Institute of Information and Communications Technology (NICT)
3-5 Hikaridai,Seika-cho, Soraku-gun, Kyoto, 619-0289, Japan
{rovellia,isahara}@nict.go.jp
Abstract
We propose a new method of selecting hy-
potheses for machine transliteration. We
generate a set of Chinese, Japanese, and Ko-
rean transliteration hypotheses for a given
English word. We then use the set of translit-
eration hypotheses as a guide to finding rel-
evant Web pages and mining contextual in-
formation for the transliteration hypotheses
from the Web page. Finally, we use the
mined information for machine-learning al-
gorithms including support vector machines
and maximum entropy model designed to
select the correct transliteration hypothesis.
In our experiments, our proposed method
based on Web mining consistently outper-
formed systems based on simple Web counts
used in previous work, regardless of the lan-
guage.
1 Introduction
Machine transliteration has been a great challenge
for cross-lingual information retrieval and machine
translation systems. Many researchers have devel-
oped machine transliteration systems that accept a
source language term as input and then output its
transliteration in a target language (Al-Onaizan and
Knight, 2002; Goto et al, 2003; Grefenstette et al,
2004; Kang and Kim, 2000; Li et al, 2004; Meng et
al., 2001; Oh and Choi, 2002; Oh et al, 2006; Qu
and Grefenstette, 2004). Some of these have used
the Web to select machine-generated transliteration
hypotheses and have obtained promising results (Al-
Onaizan and Knight, 2002; Grefenstette et al, 2004;
Oh et al, 2006; Qu and Grefenstette, 2004). More
precisely, they used simple Web counts, estimated as
the number of hits (Web pages) retrieved by a Web
search engine.
However, there are several limitations imposed on
the ability of Web counts to select a correct translit-
eration hypothesis. First, the assumption that hit
counts approximate the Web frequency of a given
query usually introduces noise (Lapata and Keller,
2005). Moreover, some Web search engines disre-
gard punctuation and capitalization when matching
search terms (Lapata and Keller, 2005). This can
cause errors if such Web counts are relied on to se-
lect transliteration hypotheses. Second, it is not easy
to consider the contexts of transliteration hypothe-
ses with Web counts because Web counts are esti-
mated based on the number of retrieved Web pages.
However, as our preliminary work showed (Oh et
al., 2006), transliteration or translation pairs often
appear as parenthetical expressions or tend to be in
close proximity in texts; thus context can play an im-
portant role in selecting transliteration hypotheses.
For example, there are several Chinese, Japanese,
and Korean (CJK) transliterations and their counter-
parts in a parenthetical expression, as follows.
1) 
1

2
(Adrienne
1
Clarkson
2
)
2) ?
1
	?

2
(glucose
1
oxidase
2
)
3) 
1
	

2
(diphenol
1
oxidase
2
)
Note that the subscripted numbers in all examples
represent the correspondence between the English
word and its CJK counterpart. These parentheti-
cal expressions are very useful in selecting translit-
233
eration hypotheses because it is apparent that they
are translation pairs or transliteration pairs. How-
ever, we cannot fully use such information with Web
counts.
To address these problems, we propose a new
method of selecting transliteration hypotheses. We
were interested in how to mine information relevant
to the selection of hypotheses and how to select cor-
rect transliteration hypotheses using the mined in-
formation. To do this, we generated a set of CJK
transliteration hypotheses for a given English word.
We then used the set of transliteration hypotheses
as a guide to finding relevant Web page and min-
ing contextual information for the transliteration hy-
potheses from the Web page. Finally, we used
the mined information for machine-learning algo-
rithms including support vector machines (SVMs)
and maximum entropy model designed to select the
correct transliteration hypothesis.
This paper is organized as follows. Section 2 de-
scribes previous work based on simple Web counts.
Section 3 describes a way of generating transliter-
ation hypotheses. Sections 4 and 5 introduce our
methods of Web mining and selecting transliteration
hypotheses. Sections 6 and 7 deal with our exper-
iments and the discussion. Conclusions are drawn
and future work is discussed in Section 8.
2 Related work
Web counts have been used for selecting translit-
eration hypotheses in several previous work (Al-
Onaizan and Knight, 2002; Grefenstette et al, 2004;
Oh et al, 2006; Qu and Grefenstette, 2004). Be-
cause the Web counts are estimated as the number of
hits by a Web search engine, they greatly depend on
queries sent to a search engine. Previous work has
used three types of queries?monolingual queries
(MQs) (Al-Onaizan and Knight, 2002; Grefen-
stette et al, 2004; Oh et al, 2006), bilingual
simple queries (BSQs) (Oh et al, 2006; Qu and
Grefenstette, 2004), and bilingual bigram queries
(BBQs) (Oh et al, 2006). If we let S be a source
language term and H = {h
1
, ? ? ? , hr} be a set of
machine-generated transliteration hypotheses of S,
the three types of queries can be defined as
MQ: hi (e.g., ,?, and	).
BSQ: s and hi without quotations (e.g., Clinton 
 , Clinton ?, and Clinton 
	).
BBQ: Quoted bigrams composed of S and hi (e.g.,
?Clinton ?, ?Clinton ??, and
?Clinton	?).
MQ is not able to determine whether hi is a counter-
part of S, but whether hi is a frequently used target
term in target-language texts. BSQ retrieves Web
pages if S and hi are present in the same document
but it does not take the distance between S and hi
into consideration. BBQ retrieves Web pages where
?S hi? or ?hi S? are present as a bigram. The rel-
ative order of Web counts over H makes it possible
to select transliteration hypotheses in the previous
work.
3 Generating Transliteration Hypotheses
Let S be an English word, P be a pronuncia-
tion of S, and T be a target language translitera-
tion corresponding to S. We implement English-
to-CJK transliteration systems based on three dif-
ferent transliteration models ? a grapheme-based
model (S ? T ), a phoneme-based model (S ? P
and P ? T ), and a correspondence-based model
(S ? P and (S, P ) ? T ) ? as described in our
preliminary work (Oh et al, 2006). P and T are seg-
mented into a series of sub-strings, each of which
corresponds to a source grapheme. We can thus
write S = s
1
, ? ? ? , sn = sn
1
, P = p
1
, ? ? ? , pn = pn
1
,
and T = t
1
, ? ? ? , tn = tn
1
, where si, pi, and ti rep-
resent the ith English grapheme, English phonemes
corresponding to si, and target language graphemes
corresponding to si, respectively. Given S, our
transliteration systems generate a sequence of ti cor-
responding to either si (in Eq. (1)) or pi (in Eq. (2))
or both of them (in Eq. (3)).
PrG(T |S) = Pr(tn
1
|sn
1
) (1)
PrP (T |S) = Pr(pn
1
|sn
1
)? Pr(tn
1
|pn
1
) (2)
PrC(T |S) = Pr(pn
1
|sn
1
)? Pr(tn
1
|sn
1
, pn
1
) (3)
The maximum entropy model was used to estimate
probabilities in Eqs. (1)?(3) (Oh et al, 2006). We
produced the n-best transliteration hypotheses using
a stack decoder (Schwartz and Chow, 1990). We
234
then created a set of transliteration hypotheses com-
prising the n-best transliteration hypotheses.
4 Web Mining
Let S be an English word and H = {h
1
, ? ? ? , hr} be
its machine-generated set of transliteration hypothe-
ses. We use S and H to generate queries sent to a
search engine1 to retrieve the top-100 snippets. A
correct transliteration and its counterpart tend to be
in close proximity on CJK Web pages. Our goal in
Web mining was to find such Web pages and mine
information that would help to select transliteration
hypotheses from these pages.
To find these Web pages, we used three kinds of
queries, Q
1
=(S and hi), Q2=S, and Q3=hi, where
Q
1
is the same as BSQ?s query and Q
3
is the same
as MQ?s. The three queries usually result in different
sets of Web pages. We categorize the retrieved Web
pages by Q
1
, Q
2
, and Q
3
into W
1
, W
2
, and W
3
. We
extract three kinds of features from Wl as follows,
where l = 1, 2, 3.
? Freq(hi,Wl): the number of occurrences of hi
in Wl
? DFreqk(hi,Wl): Co-occurrence of S and hi
with distance dk ? D in the same snippet of
Wl.
? PFreqk(hi,Wl): Co-occurrence of S and hi
as parenthetical expressions with distance dk ?
D in the same snippet of Wl. Parenthetical ex-
pressions are detected when either S or hi is in
parentheses.
We define D = {d
1
, d
2
, d
3
} with three ranges of
distances between S and hi, where d1(d < 5),
d
2
(5 ? d < 10), and d
3
(10 ? d ? 15). We counted
distance d with the total number of characters (or
words)2 between S and hi. Here, we can take the
contexts of transliteration hypotheses into account
using DFreq and PFreq; while Freq is counted
regardless of the contexts of the transliteration hy-
potheses.
Figure 1 shows examples of how to calculate
Freq, DFreqk, and PFreqk, where S = Clinton,
1We used Google (http://www.google.com)
2Depending on whether the languages had spacing units,
words (for English and Korean) or characters (for Chinese and
Japanese) were chosen to calculate d.
????????
1
(Bill Clinton1)????????????
????????????????????????????
??(My Life)????
2
?????????????????
???????????
3
(Hillary Rodham Clinton
2
)??1997
????? ...
1
(Bill Clinton1)
(My Life)
2
3
(Hillary Rodham Clinton
2
) 1997
...
W1: Q1=(Clinton ???)
::???
4
?Clinton
3
????????
1
??Kerry?::
?
2
??John Kerry???????????????????
??????????
5
?Clinton
4
????????????
?????????????????????Bush??"??
?"???? ???
6
?Clinton
5
???
3
??Kerry? ...
::
4
Clinton
3 1
Kerry ::
2
John Kerry
5
Clinton
4
Bush "
"
6
Clinton
5 3
Kerry ...
Snippet1
Snippet2
Figure 1: Web corpora collected by Clinton and 

Snippet
1

1

2

3
Clinton
1
1 41 68
Clinton
2
72 29 2
Snippet
2

4

5

6
Clinton
3
0 36 81
Clinton
4
40 0 37
Clinton
5
85 41 0
Snippet
2

1

2

3
Clinton
3
6 9 85
Clinton
4
32 29 42
Clinton
5
77 74 1
Table 1: Distance between Clinton and Chinese
transliteration hypotheses in Fig. 1
hi= in W1 collected by Q1=(Clinton 
). The subscripted numbers of Clinton and 
 were used to indicate how many times they oc-
curred in W
1
. In Fig. 1,  occurs six times
thus Freq(hi,W1) = 6. Table 1 lists the dis-
tance between Clinton andwithin each snip-
pet of W
1
. We can obtain DFreq
1
(hi,W1) =
5. PFreq
1
(hi,Wl) is calculated by detecting
parenthetical expressions between S and hi when
DFreq
1
(hi,Wl) is counted. Because all S in
W
1
(Clinton
1
to Clinton
5
) are in parentheses,
PFreq
1
(hi,W1) is the same as DFreq1(hi,W1).
We ignore Freq, DFreqk, and PFreqk when hi
is a substring of other transliteration hypotheses be-
cause hi usually has a higher Freq, DFreqk, and
PFreqk than hj if hi is a substring of hj . Let a
235
set of transliteration hypotheses for S = Clinton
be H= {h
1
= , h
2
= }. Here, h
2
is a
substring of h
1
. In Fig. 1, h
2
appears six times as
a substring of h
1
and three times independently in
Snippet
2
. Moreover, independently used h
2
(
1
,

2
, and 
3
) and S (Clinton
3
and Clinton
5
) are
sufficiently close to count DFreqk and PFreqk.
Therefore, the Freq, DFreqk, and PFreqk of h1
will be lower than those of h
2
if we do not take
the substring relation between h
1
and h
2
into ac-
count. Considering the substring relation, we ob-
tain Freq(h
2
,W
1
) = 3, DFreq
1
(h
2
,W
1
) = 1,
DFreq
2
(h
2
,W
1
) = 2, PFreq
1
(h
2
,W
1
) = 1, and
PFreq
2
(h
2
,W
1
) = 2.
5 Hypothesis Selection
We select transliteration hypotheses by ranking
them. A set of transliteration hypotheses, H =
{h
1
, h
2
, ? ? ? , hr}, is ranked to enable a correct hy-
pothesis to be identified. We devise a rank function,
g(hi) in Eq. (4), that ranks a correct transliteration
hypothesis higher and the others lower.
g(hi) : H ? {R : R is ordering of hi ? H} (4)
Let xi ? X be a feature vector of hi ? H, yi =
{+1,?1} be the training label for xi, and T D =
{td
1
=< x
1
, y
1
>, ? ? ? , tdz =< xz, yz >} be the
training data for g(hi). We prepare the training data
for g(hi) as follows.
1. Given each English word S in the training-set,
generate transliteration hypotheses H.
2. Given hi ? H, assign yi by looking for S and
hi in the training-set ? yi = +1 if hi is a cor-
rect transliteration hypothesis corresponding to
S, otherwise yi = ?1.
3. For each pair (S, hi), generate its feature vector
xi.
4. Construct a training data set, T D:
? T D = T D
+
?
T D
?
? T D
+
 tdi where yi = +1
? T D
?
 tdj where yj = ?1
We used two machine-learning algorithms, sup-
port vector machines (SVMs)3 and maximum en-
tropy model4 for our implementation of g(hi). The
SVMs assign a value to each transliteration hypoth-
esis (hi) using
gSVM (hi) = w ? xi + b (5)
where w denotes a weight vector. Here, we use the
predicted value of gSVM (hi) rather than the pre-
dicted class of hi given by SVMs because our rank-
ing function, as represented by Eq. (4), determines
the relative ordering between hi and hj in H. A
ranking function based on the maximum entropy
model assigns a probability to hi using
gMEM (hi) = Pr(yi = +1|xi) (6)
We can finally obtain a ranked list for the given H?
the higher the g(hi) value, the better the hi.
5.1 Features
We represent the feature vector, xi, with two types
of features. The first is the confidence scores of hi
given by Eqs. (1)?(3) and the second is Web-based
features ? Freq, DFreqk, and PFreqk. To nor-
malize Freq, DFreqk, and PFreqk, we use their
relative frequency over H as in Eqs. (7)?(9), where
k = 1, 2, 3 and l = 1, 2, 3.
RF (hi,Wl) =
Freq(h
i
,W
l
)
?
h
j
?H
Freq(h
j
,W
l
)
(7)
RDFk(hi,Wl) =
DFreq
k
(h
i
,W
l
)
?
h
j
?H
DFreq
k
(h
j
,W
l
)
(8)
RPFk(hi,Wl) =
PFreq
k
(h
i
,W
l
)
?
h
j
?H
PFreq
k
(h
j
,W
l
)
(9)
Figure 2 shows how to construct feature vector
xi from a given English word, Rachel, and its Chi-
nese hypotheses, H, generated from our translitera-
tion systems. We can obtain r Chinese translitera-
tion hypotheses and classify them into positive and
negative samples according to yi. Note that yi = +1
if and only if hi is registered as a counterpart of S
in the training data. The bottom of Fig. 2 shows our
feature set representing xi. There are three confi-
dence scores in P (hi|S) according to transliteration
models and the three Web-based features Web(W
1
),
Web(W
2
), and Web(W
3
).
3SVM light (Joachims, 2002)
4
?Maximum Entropy Modeling Toolkit? (Zhang, 2004)
236
??????????????????
hr?h5h4h3h2h1H
-1-1-1-1-1+1
yr?y5y4y3y2y1Y
Rachel
RF(hi,W1)
RDF1(hi,W1) 
RDF2(hi,W1)
RDF3(hi,W1)
RPF1(hi,W1) 
RPF2(hi,W1)
RPF3(hi,W1)
Web (W1)
RF(W3)
RDF1(hi,W3) 
RDF2(hi,W3)
RDF3(hi,W3)
RPF1(hi,W3) 
RPF2(hi,W3)
RPF3(hi,W3)
RF(hi,W2)
RDF1(hi,W2) 
RDF2(hi,W2)
RDF3(hi,W2)
RPF1(hi,W2) 
RPF2(hi,W2)
RPF3(hi,W2)
PrG(hi|S) 
PrP(hi|S)
PrC(hi|S)
Web (W3)Web (W2)Pr(hi|S)xi
td1 ? TD+ td2, td3,  td4, td5,?,tdr? TD-
xr?x5x4x3x2x1X
Figure 2: Feature vectors
6 Experiments
We evaluated the effectiveness of our system in se-
lecting CJK transliteration hypotheses. We used the
same test set used in Li et al (2004) (ECSet) for Chi-
nese transliterations (Xinhua News Agency, 1992)
and those used in Oh et al (2006) for Japanese
and Korean transliterations ? EJSET and EK-
SET (Breen, 2003; Nam, 1997). We divided the test
ECSet EJSet EKSet
Training Set 31,299 8,335 5,124
Development Set 3,478 1,041 1,024
Blind Test Set 2,896 1,041 1,024
Total 37,694 10,417 7,172
Table 2: Test data sets
data into training, development, and blind test sets
as in Table 2. The training set was used to train our
three transliteration models to generate the n-best
transliteration hypotheses5. The development set
was used to train hypothesis selection based on sup-
port vector machines and maximum entropy model.
We used the blind test set for evaluation. The eval-
uation was done in terms of word accuracy (WA).
WA is the proportion of correct transliterations in
the best hypothesis by a system to correct transliter-
ations in the blind test set.
System ECSet EJSet EKSet
KANG00 N/A N/A 54.1
GOTO03 N/A 54.3 N/A
LI04 70.1 N/A N/A
GM 69.0 61.6 59.0
PM 56.6 54.4 56.7
CM 69.9 65.0 65.1
Table 3: WA of individual transliteration systems
(%)
6.1 Results: Web counts vs. Web mining
We compared our transliteration system with three
previous ones, all of which were based on a
grapheme-based model (Goto et al, 2003; Kang and
Kim, 2000; Li et al, 2004). LI046 is an English-
to-Chinese transliteration system, which simultane-
ously takes English and Chinese contexts into con-
sideration (Li et al, 2004). KANG00 is an English-
to-Korean transliteration system and GOTO03 is an
English-to-Japanese one ? they segment a chunk of
English graphemes and identify the most relevant
sequence of target graphemes corresponding to the
chunk (Goto et al, 2003; Kang and Kim, 2000) 7.
GM, PM, and CM, which are respectively based
on Eqs. (1)?(3), are the transliteration systems we
used for generating transliteration hypotheses. Our
transliteration systems showed comparable or better
performance than the previous ones regardless of the
language.
We compared simple Web counts with our Web
mining for hypothesis selection. We used the same
set of transliteration hypotheses H then compared
their performance in hypothesis selection with two
measures, relative frequency and g(hi). Tables 4 and
5 list the results. Here, ?Upper bound? is a system
that always selects the correct transliteration hypoth-
esis if there is a correct one inH. ?Upper bound? can
5We set n = 10 for the n-best. Thus, n ? r ? 3? n where
H = {h
1
, h
2
, ? ? ? , h
r
}
6The WA of LI04 was taken from the literature, where the
training data were the same as the union of our training set and
the development set while the test data were the same as in our
test set. In other words, LI04 used more training data than ours
did. With the same setting as LI04, our GM, PM, and CM pro-
duced respective WAs of 70.0, 57.7, and 71.7.
7We implemented KANG00 (Kang and Kim, 2000) and
GOTO03 (Goto et al, 2003), and tested them with the same
data as ours.
237
System ECSet EJSet EKSet
WC
MQ 16.1 40.4 34.7
BSQ 45.8 74.0 72.4
BBQ 34.9 78.1 79.3
WM
RF (W
1
) 62.9 78.4 77.1
RDF (W
1
) 70.8 80.4 80.2
RPF (W
1
) 73.5 79.7 79.4
RF (W
2
) 63.5 76.2 74.8
RDF (W
2
) 67.1 79.2 78.9
RPF (W
2
) 69.6 79.1 78.4
RF (W
3
) 37.9 53.9 55.8
RDF (W
3
) 76.4 69.0 70.2
RPF (W
3
) 76.8 68.3 68.7
Upper bound 94.6 93.5 93.2
Table 4: Web counts (WC) vs. Web mining (WM):
hypothesis selection by relative frequency (%)
System ECSet EJSet EKSet
WC MEMWC 74.7 86.1 85.6
SVMWC 74.8 86.9 86.5
WM MEMWM 82.0 88.2 85.8
SVMWM 83.9 88.5 86.7
Upper bound 94.6 93.5 93.2
Table 5: Web counts (WC) vs. Web mining (WM):
hypothesis selection by g(hi) (%)
also be regarded as the ?Coverage? of H generated
by our transliteration systems. MQ, BSQ, and BBQ
in the upper section of Table 4, represent hypothesis
selection systems based on the relative frequency of
Web counts over H, the same measure used in Oh et
al. (2006):
WebCountsx(hi)
?
h
j
?H
WebCountsx(hj)
(10)
where WebCountsx(hi) is a function returning
Web counts retrieved by x ? {MQ,BSQ,BBQ}
RF (Wl), RDF (Wl), and RPF (Wl) in Table 4 rep-
resent hypothesis selection systems with their rela-
tive frequency, where RDF (Wl) and RPF (Wl) use
?
3
k=1 RDFk(hj ,Wl) and
?
3
k=1 RPFk(hj ,Wl),
respectively. The comparison in Table 4 shows
which is best for selecting transliteration hy-
potheses when each relative frequency is used
alone. Table 5 compares Web counts with fea-
tures mined from the Web when they are used
as features in g(hi) ? {Pr(hi|S), Web(Wl)} in
MEMWM and SVMWM (our proposed method),
while {Pr(hi|S), WebCountsx(hi)} in MEMWC
and SVMWC . Here, Web(Wl) is a set of mined
features from Wl as described in Fig .2.
????????(a Man To Call My Own) ??
???????????- ????????(a Man To Call 
My Own), ????ranchhouse???????????????
??????????????? ????????????
?????????????...
(a Man To Call My Own) 
- (a Man To Call 
My Own), ranchhouse
...
??????(4/03)????
???????,?????????,???????,???
??????????????????,????????,?
???? ... ???????(Academy)??????????,
???????????????...
(4/03)
, , ,
, ,
... (Academy) ,
...
Snippet1 retrieved by BSQ: Aman ????
Snippet2 retrieved by MQ: ???? (meaning Agard)
?????|Cliff De Young| ??| ??| ??| EO????
????? | The Secret Life of Zoey (TV) ?????2002 ???
????????????? , ????? , ????? , ??
???? , Avery Raskin. ??????Larry Carter. ???4.92?
|Cliff De Young| | | | EO
| The Secret Life of Zoey (TV) 2002 
, , , 
, Avery Raskin. Larry Carter. 4.92
UNESCO. General Conference; 32nd; Election of member
????????????????. ?. 1987--1991. ???????
????????????. ????. (1976). 1987--1991. ????
??????????. 2001--2005. ????. 1993--1997....
UNESCO. General Conference; 32nd; Election of e ber
? ? ? . . 1987--1991. ?
? ? . . (1976). 1987--1991. ?
? . 2001--2005. . 1993--1997....
Snippet3 retrieved by MQ: ?????? (meaning Rawcliffe)
Snippet4 retrieved by MQ: ?????? (meaning Aldersey)
Figure 3: Snippets causing errors in Web counts
The results in the tables show that our systems
consistently outperformed systems based on Web
counts, especially for Chinese. This was due to the
difference between languages. Japanese and Chi-
nese do not use spaces between words. However,
Japanese is written using three different alphabet
systems, called Hiragana, Katakana, and Kanji, that
assist word segmentation. Moreover, words written
in Katakana are usually Japanese transliterations of
foreign words. This makes it possible for a Web
search engine to effectively retrieve Web pages con-
taining given Japanese transliterations. Like En-
glish, Korean has spaces between words (or word
phrases). As the spaces in the languages reduce am-
biguity in segmenting words, a Web search engine
can correctly identify Web pages containing given
Korean transliterations. In contrast, there is a se-
vere word-segmentation problem with Chinese that
causes Chinese Web search engines to incorrectly
retrieve Web pages, as shown in Fig. 3. For example,
Snippet
1
is not related to ?Aman? but to ?a man?.
238
Snippet
2
contains a super-string of a given Chinese
query, which corresponds to ?Academy? rather than
to ?Agard?, which is the English counterpart of the
Chinese transliteration. Moreover, Web search
engines ignore punctuation marks in Chinese. In
Snippet
3
and Snippet
4
, ?,? and ?? in the under-
lined terms are disregarded, so the Web counts based
on such Web documents are noisy. Thus, noise in
the Chinese Web counts causes systems based on
Web counts to produce more errors than our sys-
tems do. Our proposed method can filter out such
noise because our systems take punctuation marks
and the contexts of transliterations in Web mining
into consideration. Thus, our systems based on fea-
tures mined from the Web were able to achieve the
best performance. The results revealed that our sys-
tems based on the Web-mining technique can effec-
tively be used to select transliteration hypotheses re-
gardless of the language.
6.2 Contribution of Web corpora
ECSet EJSet EKSet
SVM MEM SVM MEM SVM MEM
Base 73.3 73.8 67.0 66.1 66.0 66.4
W
1
81.7 79.7 87.6 87.3 86.1 85.1
W
2
80.8 79.5 86.9 86.0 83.8 82.1
W
3
77.2 76.7 83.0 82.8 79.8 77.3
W
1+2
83.8 82.3 88.5 87.9 86.3 85.9
W
1+3
81.9 80.1 87.6 87.8 86.1 84.7
W
2+3
81.4 79.8 88.0 87.7 85.1 84.3
W
All
83.9 82.0 88.5 88.2 86.7 85.8
Table 6: Contribution of Web corpora
In Web mining, we used W
1
, W
2
, and W
3
, col-
lected by respective queries Q
1
=(S and hi), Q2=S,
and Q
3
=hi. To investigate their contribution, we
tested our proposed method with different combina-
tions of Web corpora. ?Base? is a baseline system
that only uses Pr(hi|S) as features but does not use
features mined from the Web. We added features
mined from different combinations of Web corpora
to ?Base? from W
1
to WAll.
In Table 6, we can see that W
1
, a set of Web pages
retrieved by Q
1
, tends to give more relevant infor-
mation than W
2
and W
3
, because Q
1
can search
more Web pages containing both S and hi in the top-
100 snippets if S and hi are a correct transliteration
pair. Therefore, its performance tends to be superior
in Table 6 if W
1
is used, especially for ECSet. How-
ever, as W
1
occasionally retrieves few snippets, it is
not able to provide sufficient information. Using W
2
or W
3
, we can address the problem. Thus, combina-
tions of W
1
and others (W
1+2
, W
1+3
, WAll) pro-
vided better WA than W
1
.
7 Discussion
Several Web mining techniques for translitera-
tion lexicons have been developed in the last few
years (Jiang et al, 2007; Oh and Isahara, 2006).
The main difference between ours and those previ-
ous ones is in the way a set of transliteration hy-
potheses (or candidates) is created.
Jiang et al (2007) generated Chinese transliter-
ations for given English words and searched the
Web using the transliterations. They generated only
the best transliteration hypothesis and focused on
Web mining to select transliteration lexicons rather
than selecting transliteration hypotheses. The best
transliteration hypothesis was used to guide Web
searches. Then, transliteration candidates were
mined from the retrieved Web pages. Therefore,
their performance greatly depended on their abil-
ity to mine transliteration candidates from the Web.
However, this system might create errors if it can-
not find a correct transliteration candidate from the
retrieved Web pages. Because of this, their sys-
tem?s coverage and WA were relatively poor than
ours 8. However, our transliteration process was able
to generate a set of transliteration hypotheses with
excellent coverage and could thus achieve superior
WA.
Oh and Isahara (2006) searched the Web using
given source words and mined the retrieved Web
pages to find target-language transliteration candi-
dates. They extracted all possible sequences of
target-language characters from the retrieved Web
snippets as transliteration candidates for which the
beginnings and endings of the given source word
8Since both Jiang et al?s (2007) and ours used Chinese
transliterations of personal names as a test set, we can indirectly
compare our coverage and WA with theirs (Jiang et al, 2007).
Jiang et al (2007) achieved a 74.5% coverage of transliteration
candidates and 47.5% WA, while ours achieved a 94.6% cov-
erage of transliteration hypotheses and 82.0?83.9% WA
239
and the extracted transliteration candidate were pho-
netically similar. However, while this can exponen-
tially increase the number of transliteration candi-
dates, ours used the n-best transliteration hypothe-
ses but still achieved excellent coverage.
8 Conclusion
We have described a novel approach to selecting
transliteration hypotheses based on Web mining. We
first generated CJK transliteration hypotheses for a
given English word and retrieved Web pages us-
ing the transliteration hypotheses and the given En-
glish word as queries for a Web search engine. We
then mined features from the retrieved Web pages
and trained machine-learning algorithms using the
mined features. Finally, we selected transliteration
hypotheses by ranking them. Our experiments re-
vealed that our proposed method worked well re-
gardless of the language, while simple Web counts
were not effective, especially for Chinese.
Because our method was very effective in select-
ing transliteration pairs, we expect that it will also
be useful for selecting translation pairs. We plan to
extend our method in future work to selecting trans-
lation pairs.
References
Y. Al-Onaizan and Kevin Knight. 2002. Translating
named entities using monolingual and bilingual re-
sources. In Proc. of ACL ?02, pages 400?408.
J. Breen. 2003. EDICT Japanese/English dictionary .le.
The Electronic Dictionary Research and Development
Group, Monash University. http://www.csse.
monash.edu.au/
?
jwb/edict.html.
I. Goto, N. Kato, N. Uratani, and T. Ehara. 2003.
Transliteration considering context information based
on the maximum entropy method. In Proc. of MT-
Summit IX, pages 125?132.
Gregory Grefenstette, Yan Qu, and David A. Evans.
2004. Mining the Web to create a language model
for mapping between English names and phrases and
Japanese. In Proc. of Web Intelligence, pages 110?
116.
Long Jiang, Ming Zhou, Lee-Feng Chien, and Cheng
Niu. 2007. Named entity translation with Web min-
ing and transliteration. In Proc. of IJCAI, pages 1629?
1634.
Thorsten Joachims. 2002. Learning to Classify Text Us-
ing Support Vector Machines: Methods, Theory and
Algorithms. Kluwer Academic Publishers.
I. H. Kang and G. C. Kim. 2000. English-to-Korean
transliteration using multiple unbounded overlapping
phoneme chunks. In Proc. of COLING ?00, pages
418?424.
Mirella Lapata and Frank Keller. 2005. Web-based
models for natural language processing. ACM Trans.
Speech Lang. Process., 2(1):3.
H. Li, M. Zhang, and J. Su. 2004. A joint source-channel
model for machine transliteration. In Proc. of ACL
?04, pages 160?167.
H.M. Meng, Wai-Kit Lo, Berlin Chen, and K. Tang.
2001. Generating phonetic cognates to handle named
entities in English-Chinese cross-language spoken
document retrieval. In Proc. of Automatic Speech
Recognition and Understanding, 2001. ASRU ?01,
pages 311?314.
Y. S. Nam. 1997. Foreign dictionary. Sung An Dang.
Jong-Hoon Oh and Key-Sun Choi. 2002. An English-
Korean transliteration model using pronunciation and
contextual rules. In Proc. of COLING2002, pages
758?764.
Jong-Hoon Oh and Hitoshi Isahara. 2006. Mining the
Web for transliteration lexicons: Joint-validation ap-
proach. In Web Intelligence, pages 254?261.
Jong-Hoon Oh, Key-Sun Choi, and Hitoshi Isahara.
2006. A comparison of different machine transliter-
ation models. Journal of Artificial Intelligence Re-
search (JAIR), 27:119?151.
Yan Qu and Gregory Grefenstette. 2004. Finding ideo-
graphic representations of Japanese names written in
Latin script via language identification and corpus val-
idation. In Proc. of ACL ?04, pages 183?190.
Richard Schwartz and Yen-Lu Chow. 1990. The N-best
algorithm: An efficient and exact procedure for finding
the N most likely sentence hypothesis. In Procs. of
ICASSP ?90, pages 81?84.
Xinhua News Agency. 1992. Chinese transliteration of
foreign personal names. The Commercial Press.
L. Zhang. 2004. Maximum entropy model-
ing toolkit for python and C++. http:
//homepages.inf.ed.ac.uk/s0450736/
software/maxent/manual.pdf.
240
