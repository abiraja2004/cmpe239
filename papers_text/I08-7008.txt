A Multilingual Multimedia Indian Sign Language Dictionary Tool 
Tirthankar 
Dasgupta 
IIT, Kharagpur 
tirtha@iitkgp
.ernet.in 
Sambit 
Shukla 
NIT, Rourkela 
sks.at.nit
r@gmail.co
m 
Sandeep 
Kumar 
NIT, Allahabad. 
mnnit.sand
eep@gmail.
com 
Synny Diwakar 
NIT, Suratkal 
sunny.diwaka
rnitk@gmail.
com 
Anupam Basu 
IIT, Kharagpur 
Anupam-
bas@gmail.
com 
 
Abstract 
This paper presents a cross platform multi-
lingual multimedia Indian Sign Language 
(ISL) dictionary building tool. ISL is a lin-
guistically under-investigated language 
with no source of well documented elec-
tronic data. Research on ISL linguistics 
also gets hindered due to a lack of ISL 
knowledge and the unavailability of any 
educational tools. Our system can be used 
to associate signs corresponding to a given 
text. The current system also facilitates the 
phonological annotation of Indian signs in 
the form of HamNoSys structure. The gen-
erated HamNoSys string can be given as 
input to an avatar module to produce an 
animated sign representation.  
1 Introduction 
A sign language is a visual-gesture language that 
uses hand, arm, body, and face to convey thoughts 
and meanings. It is a language that is commonly 
developed in deaf communities, which includes 
deaf people, their friends and families as well as 
people who are hard of hearing. Despite common 
misconceptions, sign languages are complete natu-
ral languages, with their own syntax and grammar. 
However, sign languages are not universal. As is 
the case in spoken language, every country has got 
its own sign language with high degree of gram-
matical variations.  
 The sign language used in India is com-
monly known as Indian Sign Language (hence-
forth called ISL). However, it has been argued that 
possibly the same SL is used in Nepal, Sri Lanka, 
Bangladesh, and border regions of Pakistan 
(Zeshan et al, 2004). Different dialects of ISL 
with broad lexical variation are found in different 
parts of the Indian subcontinent. However, the 
grammatical structure is same for all dialects 
(Zeshan, 2003).  
The All India Federation of the Deaf estimates 
around 4 million deaf people and more than 10 
million hard of hearing people in India (Zeshan et 
al, 2004). Studies revealed that, one out of every 
five deaf people in the world are from India. More 
than 1 million deaf adults and around 0.5 million 
deaf children uses Indian Sign Language as a 
mode of communication (Zeshan et al 2004). 
However, an UNESCO report (1980) found that 
only 5% of the deaf get any education in India. 
The reason behind such a low literacy rate can be 
due to the following reasons: a) Till the early 20th 
century, deafness in India, is considered as a pun-
ishment for sins and signing is strictly discouraged 
(Zeshan et. al, 2004). b) Until the late 1970?s, it 
has been believed that, there were no such lan-
guage called ISL. c) Lack of research in ISL lin-
guistics. d) Unavailability of well documented and 
annotated ISL lexicon. e) Unavailability of any 
ISL learning tool. f) Difficulties in getting sign 
language interpreters. 
 Linguistic studies on ISL were started 
around 1978 and it has been found that ISL is a 
complete natural language, instigated in India, 
having its own morphology, phonology, syntax, 
and grammar (Vasishta et. al, 1978; Zeshan et.al, 
2004). The research on ISL linguistics and phono-
logical studies get hindered due to lack of linguis-
tically annotated and well documented ISL data. A 
dictionary of around 1000 signs in four different 
regional varieties was released (Vasishta et.al, 
The 6th Workshop on Asian Languae Resources, 2008
57
1978). However, these signs are based on graphi-
cal icons which are not only difficult to understand 
but also lack phonological features like move-
ments and non-manual expressions.  
As it has been specified above,  ISL is not only 
used by the deaf people but also by the hearing 
parents of the deaf children, the hearing children 
of deaf  adults and hearing deaf educators (Zeshan 
et al 2004). Therefore the need to build a system 
that can associate signs to the words of spoken 
language, and which can further be used to learn 
ISL, is significant. Further associating signs of 
different SL (like ASL1 , BSL2 and ISL) to a word 
will help the user to learn foreign SLs simultane-
ously. 
 Several works have been done on building 
multimedia-based foreign SL dictionaries as dis-
cussed in (Buttussi et. al., 2007). However no such 
system is currently available for ISL. moreover, 
most of the current systems suffer from the follow-
ing limitations:  
? Most of the systems are native language specific 
and hence, cannot be used for ISL.  
? Most of the systems provide a word-sign search 
but very few systems provide a sign-word or 
sign-sign search. 
? Very few systems are cross platform. 
? Systems lack sophisticated phonological infor-
mation like hand-shape, orientations, move-
ments, and non-manual signs.  
In order to overcome the above mentioned crisis, 
and based on the limitations of the current sys-
tems, our objective is to: 
? Build a cross platform multilingual multimedia 
SL-Dictionary tool which can be used to create a 
large SL lexicon.  
? This tool can be used to associate signs to the 
words, phrases, or sentences of a spoken lan-
guage text.  
? The sign associated with each word is composed 
of its related part-of-speech and semantic senses.  
? The input text (word, phrase, or a sentence) may 
be in any language (like English or Hindi) and 
the associated sign can be in any standard sign 
language (ASL or ISL).  
? This tool can also be used to associate complex 
SL phonological features like hand shape, palm 
                                                 
                                                
1 ASL: American Sign Language. 
2 BSL: British Sign Language. 
orientation, locations, movements, and non-
manual expressions.  
? The phonological features are expressed in terms 
of HamNoSys (Prillwitz et. al, 1989). 
? Facilitate search options like word-sign and 
search by HamNoSys. 
? The generated lexicon is exported in XML file 
format and the sign is stored in the form of digi-
tal videos.  
? The video segments are captured using webcams 
connected with the system. It is possible to at-
tach multiple webcams to the system to capture 
video segments from multiple angles. This fea-
ture enables a user to better understand some of 
the complex sign language attributes. 
 
The organization of the paper is as follows: Sec-
tion 2 gives a brief introduction to ISL phonology. 
Section 3 presents related works on ISL Diction-
ary. Section 4 presents the overall system architec-
ture of the SL-dictionary tool. Section 5 and 6 pre-
sents a brief discussion related HamNoSys repre-
sentation, and the HamNoSys editor. Section 7 
presents conclusion and future work. 
2 ISL Phonology 
Indian Sign Language (ISL) is a visual-spatial lan-
guage which provides linguistic information using 
hands, arms, face, and head/body postures. The 
signer often uses the 3D space around his body to 
describe an event (Zeshan, 2003). Unlike spoken 
languages where the communication medium is 
dependent on sound, in sign language, the com-
munication medium depends upon the visual 
channel. In spoken language, a word is composed 
of phonemes. Two words can be distinguished by 
at least one phoneme. In SL, a sign is composed of 
cheremes3 and similarly two signs can differ by at 
least one chereme (Stokoe, 1978). A sign is a se-
quential or parallel construction of its manual and 
non-manual cheremes. A manual chereme can be 
defined by several parameters like: 
? Hand shape. 
? Hand location 
? Orientation. 
? Movements (straight, circular or curved) 
 
3 The term chereme (originally proposed by William 
Stokoe (Stokoe, 1978)) in Greek means ?hand?. It is 
equivalent to the phonemes of spoken languages.   
The 6th Workshop on Asian Languae Resources, 2008
58
Non-manual cheremes are defined by: 
? Facial expressions. 
? Eye gaze and Head/body posture (Zeshan, 
2003). 
However, there exist some signs which may con-
tain only manual or non-manual components. For 
example the sign ?Yes? is signed by vertical head 
nod and it has no manual component. 
ISL signs can be generally classified into three 
classes: One handed, two handed, and non-manual 
signs. Fig. 1 shows the overall Indian sign hierar-
chy. 
 
Fig. 1: ISL Type Hierarchy 
 
One handed signs: the one handed signs are repre-
sented by a single dominating hand. One handed 
signs can be either static or movement related. 
Each of the static and movement signs is further 
classified into manual and non-manual signs. Fig. 
2 shows examples of one handed static signs with 
non-manual and manual components.  
                 
Fig. 2: One Handed static manual sign (Ear) and 
non-manual sign (Headache).   
      
Two hand signs: As in the case of one hand signs, 
similar classification can be applied to two handed 
signs. However, two handed signs with move-
ments can be further distinguished as:  
Type0: Signs where both hands are active (see Fig 
3). 
Type1: Signs where one hand (dominant) is more 
active compared to the other hand (non-dominant) 
as shown in Fig 3. 
 
           
Flag 
Long 
Fig.3 : Two handed sign "long"(both the hands are 
moving) and ?Flag? (only the dominant right hand 
is moving) 
3 Related works on ISL dictionary 
Linguistic studies on ISL are in their infancy as 
compared to other natural languages like English, 
Hindi, or Bengali and also to other SLs. Linguistic 
work on ISL began during late 1970?s. Before that, 
the existence of ISL was not acknowledged. In 
1977 a survey was conducted (see Vasistha et. al., 
1998 for documentation) and it was revealed that 
ISL is a complete natural language instigated at 
the Indian subcontinent. Vasistha collected signs 
from four major states of India (Delhi, Mumbai, 
Kolkata, and Bangalore) and released four diction-
aries of ISL regional varieties. The Ramkrishna 
Mission vidyalaya, Coimbatore has published an-
other ISL dictionary in 2001. However, all these 
dictionaries are based on iconic representations of 
signs. As a result some of the important phono-
logical information like, movements and non-
manual expression gets lost. No other work of its 
kind has so far been reported (Zeshan, 2004).  
 Several works have been done in building 
ASL and BSL dictionary tools. Some of the sys-
tems are briefly discussed below: 
Headache Ear 
? (Wilcox et. al, 1994) developed a multimedia 
ASL dictionary tool, which prerecorded digital 
video frames. 
? (Geitz et.al, 1996) developed a VRML based 
ASL finger spelled system, which ran on inter-
net. 
? Sign Smith (VCOM3D, 2004) is a 3D illustrated 
dictionary of ASL. It is also used as educational 
software as well as an authoring tool to create 
ASL content.  
? (Buttussi et. al, 2007) proposes an Italian Sign 
Language dictionary tool. This tool uses H-
animator to generate signing avatar. This tool 
provides multiple search functionality like word-
sign, sign-word, and sign-sign search. This tool 
also facilitates association of one or more SL for 
a given input word.     
The 6th Workshop on Asian Languae Resources, 2008
59
4 SL-Dictionary 
The primary objective of the SL-dictionary tool is 
to provide an easy to use GUI to create a multilin-
gual multimedia SL dictionary by which a user can 
associate signs as well as the parameters defining a 
sign, corresponding to a given text. The overall 
architecture of the system is shown in Fig. 4. The 
system has been divided into two modules: a) Ex-
pert module and b) User Module.  
 The expert module has got three main 
units: a) Input Text Processing Unit b) Visual Data 
Capture Unit (VDCU) c) Sign Storage Unit and d) 
HamNoSys Editor.  
Input Text Processing Unit: In this unit a SL ex-
pert chooses the input spoken language (like, Eng-
lish, or Hindi) and the target sign language (like, 
ISL, or ASL) and then enters a text. The input to 
the system may be word, phrase, or sentences. If 
the text is a word the system generates all possible 
meanings, with the help of WordNet4, along with 
the part of speech (POS)5 of that particular word. 
In order to get the exact part-of-speech of a word, 
the SL expert has to enter an example sentence 
corresponding to that word. This sentence is given 
as an input to the POS-tagger to get the correct 
POS of the word. A word may have multiple 
senses as returned by WordNet. The user can se-
lect one or more senses from the list. 
Visual Data Capture Unit: Sign corresponding to a 
word sense is signed by the user which is captured 
by the Visual Data Capture Unit (VDCU). The 
VDCU is connected through multiple webcams, 
placed at different angular positions with respect 
to the signer. As a result different articulation 
points of a signs are getting stored with in the da-
tabase. This will enable the SL learner to under-
stand a particular sign easily. Fig.5 shows how a 
sign from multiple angles is getting captured. 
Storage Unit: The input text along with its anno-
tated information, the digital video sign, and the 
phonological parameters defining the sign are 
stored with in a database which is further exported 
into an XML formatted file (see Fig. 6). The pho-
nological parameters are expressed in the form of 
HamNoSys (discussed in section 5). 
                                                 
4 wordnet.princeton.edu/ 
5 We have used the Stanford Part-of-Speech tagger 
(nlp.stanford.edu/software/tagger.shtml) 
 
Fig. 4: System Architecture of ISL-Dictionary 
 
 
 
 
 
 
 
 
 
 
 
 
Fig.5: capturing video signs from multiple angle 
 
 
Fig.6: The ISL-dictionary XML Format 
 
Searching: The search engine of the current sys-
tem takes a spoken language text as input parses 
the XML formatted dictionary and sequentially 
searches the dictionary. If a match is found, then 
The 6th Workshop on Asian Languae Resources, 2008
60
the sign corresponding to the lexical entry is being 
displayed. 
5 Sign language notation systems 
As it has been mentioned above, Sign language 
does not have any written form. Hence, In order to 
define a sign we need some notation system. There 
are a number of phonological notation systems for 
the representation of SL as discussed in (Smith 
et.al, 2003). One of the popular among them is 
Stokoe notation (Stokoe, 2003; Smith et.al, 2003). 
Stokoe defines a sign by three parameters: a) 
Hand-shape or designator (dez) b) location or 
place of articulation with respect to the body (tab) 
and c) movements or signation (sig). 
 HamNoSys (Prillwitz et. al, 1989) is a 
phonetic transcription system, based on Stokoe 
notation, used to transcribe signing gestures. It is a 
syntactic representation of a sign to facilitate com-
puter processing. HamNoSys extends the tradi-
tional Stokoe based notation system by further 
expanding sign representation by some more pa-
rameters. These parameters can be defined as: 
? Dominant hand?s shape. 
? Location of the dominant and the non-dominant 
hand with respect to the body. 
? Extended finger orientation of both dominant 
and non-dominant hand. 
? Palm orientation of both hands. 
? Movements (straight, circular, or curved) 
? Non-manual signs. 
Fig. 7 shows examples of different HamNoSys 
symbols and their descriptions. 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
Fig. 8 shows an example where HamNoSys repre-
sentation of the word ?WOMAN? is explained. 
Here, the parameters like movement and non-
manual signs are not present, as the sign 
?WOMAN? in ISL does not have these expres-
sions. Fig.9 shows the ISL representation of 
?WOMAN?.  
 
 
             
 
 
 
 
Fig. 8: HamNoSys representation of ?WOMAN? 
                            
 
 
 
  
           
6 HamNoSys Editor 
Transcribing a sign by HamNoSys is not a trivial 
task. A user who is transcribing a sign should be 
an expert in both HamNoSys as well as ISL. 
Moreover he has to remember all the HamNoSys 
symbols and their corresponding meanings in or-
der to define a sign. In India it is very difficult to 
find such a person. Hence our main goal behind 
building a HamNoSys editor is that, it can be used 
by an ISL expert with little or no knowledge in 
HamNoSys. The tool should provide an easy to 
use GUI that can be used to transcribe 
phonological information of a sign. 
 The HamNoSys editor provides a set of 
graphical images (most of the images are collected 
from www.sign-lang.uni-amburg.de/Projekte/ 
HamNoSys) for most of the phonological parame-
ters of a sign, like, Hand-shape, orientation, loca-
tion and movements. Based on the parameters, an 
ISL expert can choose a set of images and the sys-
tem will automatically generate the corresponding 
HamNoSys of the sign. This HamNoSys string can 
be given as an input to a signing avatar module to 
generate animated sign representation. 
 A signing avatar is a virtual human char-
acter that performs sign language. However, this 
character needs a set of instructions which will 
guide its movement. These instructions can be 
provided in the form of HamNoSys (Marshall and 
S?f?r, 2001). 
Fig.7: HamNoSys symbols and there descriptions
Palm 
Extended Finger orientation 
?? \  ???  H   f  v?? 
Handshape 
Location 
Fig.9: Sign of ?WOMAN? 
The 6th Workshop on Asian Languae Resources, 2008
61
   
 
Fig, 11: Twelve basic hand-shape classes 
 
Fig.10: HamNoSys Parameters
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Fig.12: GUI to express finger and palm orientations 
Fig.13: GUI to choose various hand locations     
near the human face 
The 6th Workshop on Asian Languae Resources, 2008
62
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Fig 14: GUI showing various straight movement parameters
 
Fig.10 shows the five basic parameters of Ham-
NoSys. For each of these parameters there exist 
interfaces through which a SL expert can choose 
the desired parameters to define a sign. For exam-
ple, the right hand side of Fig.11 shows the twelve 
basic hand-shape classes. Each of these base hand-
shapes may contain several derived hand-shapes as 
defined in HamNoSys (version 4.0). If a particular 
hand-shape is selected, then the HamNoSys sym-
bol corresponding to the hand-shape gets stored in 
the XML database (see Fig.6). Similarly, separate 
interfaces have been provided to identify palm 
orientation (see Fig,12), hand location (see 
Fig.13), movements (see Fig.14), and non-manual 
signs.   
 Due to its symbolic structure, HamNoSys 
is fairly easy to write, and understand. However, 
there are some drawbacks on this notation system 
that make it difficult to be used universally for all 
sign languages (Smith and Edmondson, 2004). For 
example, HamNoSys uses some fixed set of sym-
bols to define a sign however it is possible that a 
particular sign in any sign language may not be 
defined by 'the fixed set of symbols. For example 
HamNoSys does not have well defined symbols 
for non-manual expressions. Consider the sign 
?BITTER?, in ISL the representation is shown in 
Fig.15. It can be observed that it is very difficult to 
represent the facial expressions like eyebrow by 
HamNoSys. Currently we have a collection of 
around 979 sign icons (published by Vasistha et. al 
1998), which we are trying to transcribe in Ham-
NoSys. Out of these, 16% of the signs contain 
non-manual features which we are unable to repre-
sent in HamNoSys.  
 
  
Fig.15: ISL representation of 
"BITTER" 
 
7 Conclusion and Future works 
The paper presents an approach towards building a 
multimedia SL dictionary tool. This tool can be 
used to prepare a well documented ISL dictionary. 
The system is intended to take any Indian lan-
guage text as input and can store signs in any SL. 
Currently the system takes English, Hindi and 
Bengali texts as input and can store signs in ISL 
only. The system also provides an easy to use GUI 
The 6th Workshop on Asian Languae Resources, 2008
63
to include phonological information of a sign in 
the form of HamNoSys string. The generated 
HamNoSys string can then be used as an input to 
the signing avatar module to produce animated 
sign output. 
 In the next phase of our work we will im-
prove the system so that it can associate signs in 
any other SL (like, ASL and BSL). Further, 
WordNet as well as POS Tagger corresponding to 
Hindi and Bengali languages should also be inte-
grated with the system. Also, support has to be 
built so that system can perform sign-to-word and 
sign to sign search.  We will also perform proper 
evaluation of the HamNoSys editor in order to 
understand its utility to the SL user. 
References 
Buttussi F., Chittaro L., Coppo M. 2007. Using Web3D 
technologies for visualization and search of signs in 
an international sign language dictionary. Proceed-
ings of the twelfth international conference on 3D 
web technology. Perugia, Italy Pages: 61 ? 70 Year 
of Publication: 2007 ISBN:978-1-59593-652-3  
Geitz, S., Hanson, T., Maher, S. 1996. Computer gener-
ated 3-dimensional models of manual alphabet hand-
shapes for the World Wide Web. In Assets ?96: 
Proceedings of the second annual ACM confer-
ence on Assistive technologies, ACM Press, New 
York, NY, USA, 27?31. 
Marshall I. and S?f?r ?. 2001.Extraction of semantic 
representations from syntactic SMU link grammar 
linkages.. In G. Angelova, editor, Proceedings of 
Recent Advances in Natural Lanugage Processing, 
pp: 154-159, Tzigov Chark, Bulgaria, September. 
Prillwitz P., Regina Leven, Heiko Zienert, Thomas 
Hamke, and Jan Henning. 1989. HamNoSys Version 
2.0: Hamburg Notation System for Sign Languages: 
An Introductory Guide, volume 5 of International 
Studies on Sign Language and Communication of 
the Deaf. Signum Press, Hamburg, Germany,  
Smith G., Angus. 1999. English to American Sign Lan-
guage machine translation of weather reports. Pro-
ceedings of the Second High Desert Student Confer-
ence in Linguistics. 
Smith,K.C., Edmondson, W. 2004. The Development 
of a Computational Notation for Synthesis of Sign 
and Gesture, GW03(312-323). 
Speers, A. 1995. SL-Corpus: A computer tool for sign 
language corpora., Georgetown University.  
Stokoe W. C., 1960. Sign language structure: an out-
line of the visual communication systems of the 
American deaf. 2nd edition, 1978. Silver Spring, 
MD: Linstok Press. 
VCOM3D,2004. Sign smith products. 
http://www.vcom3d.com. 
Wilcox, S., Scheibman, J., Wood, D., Cokely, D., and 
stokoe, w. c. 1994. Multimedia dictionary of Ameri-
can Sign Language. In Assets ?94: Proceedings of 
the first annual ACM conference on Assistive tech-
nologies, ACM Press, New York, NY, USA, 9?16. 
Vasishta M., Woodward J., DeSantis S. 1998, ?An In-
troduction to Indian Sign Language?, All India Fed-
eration of the Deaf (Third Edition). 
Zeshan U., 2003,?Indo-Pakistani Sign Language 
Grammar: A Typological Outline?, Sign Language 
Studies - Volume 3, Number 2, , pp. 157-212  
Zeshan U., Madan M. Vasishta, Sethna M. 2004, ?im-
plementation of indian sign language in educational 
settings?- Volume 15, Number 2, Asia Pacific Dis-
ability Rehabilitation Journal, , pp. 15-35 
 
The 6th Workshop on Asian Languae Resources, 2008
64
