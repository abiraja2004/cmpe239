Proceedings of the 1st Workshop on Speech and Multimodal Interaction in Assistive Environments, pages 28?33,
Jeju, Republic of Korea, 8-14 July 2012. c?2012 Association for Computational Linguistics
Reduction of Non-stationary Noise for a Robotic Living Assistant using
Sparse Non-negative Matrix Factorization
Benjamin Cauchi 1, Stefan Goetze 1, Simon Doclo 1,2
1Fraunhofer Institute for Digital Media Technology (IDMT), Project group
Hearing, Speech and Audio Technology (HSA), 26129 Oldenburg, Germany
2University of Oldenburg, Signal Processing group, 26129 Oldenburg, Germany
{benjamin.cauchi,s.goetze,simon.doclo}@idmt.fraunhofer.de
Abstract
Due to the demographic changes, support by
means of assistive systems will become in-
evitable for home care and in nursing homes.
Robot systems are promising solutions but
their value has to be acknowledged by the pa-
tients and the care personnel. Natural and in-
tuitive human-machine interfaces are an es-
sential feature to achieve acceptance of the
users. Therefore, automatic speech recogni-
tion (ASR) is a promising modality for such
assistive devices. However, noises produced
during movement of robots can degrade the
ASR performances. This work focuses on
noise reduction by a non-negative matrix fac-
torization (NMF) approach to efficiently sup-
press non stationary noise produced by the
sensors of an assisting robot system.
1 Introduction
The amount of older people in today?s societies con-
stantly grows due to demographic changes (Euro-
pean Commision Staff, 2007). Technical systems
become more and more common to support for rou-
tine tasks of care givers or to assist older persons
living alone in their home environments (Alliance,
2009). Various technical assistive systems have been
developed recently (Lisetti et al., 2003), ranging
from reminder systems (Boll et al., 2010; Goetze
et al., 2010) to assisting robots (Chew et al., 2010;
Goetze et al., 2012). If robot systems are supposed
to navigate autonomously they usually rely on vision
sensors (Aragon-Camarasa et al., 2010) or acous-
tic sensors (Youssef et al., ). Acoustic signals are
usually picked up by microphones mounted on the
robot. In real-world scenarios not only the desired
signal part is picked up by these microphones as pre-
sented in Figure 1.
spectrum speech
NRFilter
y[k]=s[k]+n[k]
h[k]
hats[k]
0.5 1 1.5 2
0
1
2
3
4
-25
-20
-15
-10
-5
0
0.5 1 1.5 2
0
1
2
3
4
-25
-20
-15
-10
-5
0
0.5 1 1.5 2
0
1
2
3
4
-25
-20
-15
-10
-5
0
n[k]
0.5 1 1.5 2
0
1
2
3
4
-25
-20
-15
-10
-5
0
fre
que
ncy
s[k]
time
fre
que
ncy
spectrum noise
time time
time
fre
que
ncy
fre
que
ncy
spectrum mic spectrum outputspectrum outputspectrum output
spectrum output
spectrum output
time
time
time
time
y(k)=s(k)+n(k)
h(k)
( )
^
n(k)
s(k)
Figure 1: General denoising scheme
The desired signal part is usually superposed with
disturbing noise originating from the environment or
the robot system itself. This disturbance has to be
removed from the microphone signal before it can
be further processed, e.g. for navigation, position
estimation, acoustic event detection, speaker detec-
tion or automatic speech recognition. This contri-
bution focuses on acoustic input for a robot system
and more specifically on the noise reduction pre-
processing which is needed to clean up noisy sound
signals.
Automatic speech recognition (Huang et al.,
2001; W?lfel et al., 2009) is a convenient way to in-
teract with robot assistants since speech is the most
natural form of communication. However, to en-
sure acceptance of speech recognition systems a suf-
28
ficiently high recognition rate has to be achieved
(Pfister and T., 2008). Today?s speech recognition
systems succeed in achieving this recognition rate
for environments with low amount of noise and re-
verberation. Unfortunately, while moving, robots
can produce noise degrading the reliability of the
ASR.
This work focuses on a specific application, sup-
pressing the non stationary noise produced by the
ultra-sonic sensors of a robotic assistant while mov-
ing. Please note that although in theory ultrasonic
sensors do not produce sound disturbances in the au-
dible range, artefacts due to the fast activation and
deactivation of the sensors are present in the audible
range and are clearly perceivable as a disturbance in
the picked up microphone signal as shown later in
Figure 6.
Ultrasonic
Sensors
Figure 2: Lower part of the robot with ultrasonic sen-
sors (Metralabs, 2010).
Non-negative Matrix Factorization (NMF) is an
approach introduced by Lee & Seung (Lee and Se-
ung, 2001) in which the data is described as the
product of a set of basis and of a set of activation co-
efficients both being non-negative. We will apply the
NMF approach to remove the disturbances caused
by the ultrasonic sensors from the microphone input
signal in the following. NMF and its various exten-
sions have been proven efficient in sources separa-
tion (Cichocki et al., ; Virtanen, 2007), supervised
detection of acoustic events (Cotton and Ellis, 2011)
or to wind noise reduction (Schmidt et al., ). As
the NMF algorithm can be fed with prior informa-
tion about the content to identify, it is a handy way
to suppress the non stationary noise produced by the
sensors of the considered robotic assistant.
The remainder of this paper is organized as fol-
lows: The general NMF algorithm is presented in
Section 2 and the proposed denoising method is
described in Section 3. An experiment using the
TIMIT (Zue et al., 1990) speech corpus is presented
in Section 4 and finally the performances are eval-
uated in terms of achieved signal enhancement in
Section 5 before Section 6 concludes the paper.
2 Sparse Non-negative Matrix
Factorization
2.1 NMF algorithm
NMF is a low-rank approximation technique for
multivariate data decomposition. Given a real val-
ued non-negative matrix V of size n?m and a pos-
itive integer r < min(n,m), it aims to find a factor-
ization of V into a n? r real matrix W and a r ?m
real matrix H such that:
V ?W ?H (1)
The multivariate data to decompose is stacked into
V, whose columns represent the different observa-
tions, and whose rows represent the different vari-
ables. In the case of information extraction from au-
dio files, V could be the amplitude of the spectro-
gram and therefore, W would be a basis of spectral
features when H would represent the levels of acti-
vation of each of those features along time. The rank
r of the factorization corresponds to the number of
elements present in the dictionary W, and thereof, to
the number of rows within H.
NMF is an iterative process that can be fed with
information about the contents to extract. As an il-
lustration of this ability, an artificial spectrogram of
a mixture of two chords, C and D, has been created.
Figure 3 shows the initialization of the NMF algo-
rithm. V is the spectrogram of the mixture in which
the two chords contain only notes?fundamentals and
overlap each other. The Algorithm is fed with the
spectral content of the C chord.
Figure 4 shows that during the iterative process,
the elements of W corresponding to the C chord
remain unchanged while the other elements of W
have been updated to fit the spectral content of the
D chord. The output time activations within H cor-
29
respond to the presence of both chords within the
matrix V.
Figure 3: Illustration of the initialization of the NMF al-
gorithm. The spectral content of the C chord is input into
W while the other element of dictionary and activation
coefficients in H are randomly initialized.
Figure 4: Illustration of the output of the NMF algorithm.
The spectral content of the D chord has been learned
while the updated H corresponds to the activations of the
chords C and D along time.
2.2 Sparseness Constraint
The very definition of sparseness (or sparsity) is that
a vector is sparse when most of its elements are zero.
In its application to NMF, the addition of a sparse-
ness constraint ? permits to trade off between the
fitness of the factorization and the sparseness of H.
At each iteration, the process aims at reducing a
cost function C. In this paper, a generalized version
of the Kullback Leibler divergence is used as cost
function:
D(V,WH) =
?
?
?
?V? log
V
W ?H
? V + W ?H
?
?
?
? (2)
In 2 the multiplication ? and the division are
element-wise. The sparseness constraint results in
the new cost function:
C(V,WH) = D(V,WH) + ?
?
ij
Hij (3)
The norm of each of the objects within W is fixed to
unity.
3 Supervised NMF denoising
3.1 Method overview
The method is supervised in the sense that it uses
a noise dictionary Wn built from a recording of the
known noise to be reduced. The noise spectrogram
?n, i.e. the short-term fourier transform (STFT), is
computed using a hamming window of 32ms and a
50% overlap. The magnitude Vn of ?n is input to
the NMF algorithm with a sparseness constraint ?
and an order rn, providing the noise dictionary of rn
spectral vectors. The spectrogram Vs of the noisy
speech is then input to the NMF algorithm along
with Wn in order to obtain the denoised speech spec-
trogram.
3.2 Separation of the speech signal
H
s
H
n
Spectrogram
W
n
W
s
Noisy Denoised
Synthesis
NMF
Figure 5: Overview of the NMF based denoising.
The denoising is summarized in Figure 5. The
spectrum ?s of the noisy speech and its amplitude
Vs are computed as in Section 3.1. Vs is input to
the NMF algorithm along with Wn. The order of
factorization r is equal to rn + rs, rs being the num-
ber of spectral vector used in the speech dictionary
Ws. Different sparseness constraint ?n and ?s can
30
be applied to the activation matrices Hn and Hs.
Given V ? Rn?m+ , r ? N
? s.t. r < min(n,m)
minimize C(V,WH) w.r.t.W,H (4)
subject to W ? Rn?r+ , H ? R
r?m
+
The update rules on W and H can be expressed as
multiplicative updates:
Ws ?Ws ?
V
WsHs
?HTs
1?HTs
H? H?
WT ? VWH
WT ?1
(5)
The NMF algorithm provides thereof Ws and Hs to
be used to approximate the spectrogram of the de-
noised speech. Therefore, ? being the matrix prod-
uct:
V?s = Ws ?Hs V?n = Wn ?Hn
??s = ?s ? V?sV?s+V?n
(6)
The denoised speech signal is finally obtained by
applying ISTFT on the spectrogram S?s. The inter-
ested reader is referred to (O?Grady and Pearlmutter,
2006) for a more detailed discussion of the needed
derivations for Eqs. (5)-(6).
4 Experiment
4.1 Context
The robot platform Scitos A5 (Metralabs, 2012) can
be used as a robotic assistant for elderly care. Its
built-in microphones allow to interact with the robot
using if their signal is analysed by an ASR sys-
tem. However, while in motion, the robot uses ul-
trasonic sensors (c.f. Figure 2) to detect potential
obstacles. Their constant activation and deactivation
produces artifacts that can sever the ASR reliability.
The following experiment aims to evaluate the effi-
ciency of the denoising method proposed in Section
3 on speech signals corrupted by this specific sen-
sors noise. The Figure 6 examplarily presents the
spectrogram of a corrupted speech signal.
4.2 Protocol
The noise produced by the sensors and the room
impulse response (RIR) have been recorded in a
quiet office room using the robot?s microphone. The
test data has been built from the test portion of the
 
Freq
uenc
y in 
Hz
 
 8000
7000
6000
5000
4000
3000
2000
1000
?30
?25
?20
?15
?10
?5
0
 Time in s
 
Freq
uenc
y in 
Hz
 
 
0 1 2 3 4 5
8000
7000
6000
5000
4000
3000
2000
1000
?30
?25
?20
?15
?10
?5
0
Figure 6: Spectrogram of a speech sentence from the
TIMIT corpora: ?She had your dark suit in greasy wash
water all year.?, clean (top) and with added sensors noise
at SNR=10dB.
TIMIT corpus (Zue et al., 1990). The clean speech
files have been built concatenating a silent period of
0.5 seconds in their beginning, to allow for compari-
son with methods relying on a voice activity detector
(VAD), and convolving it with the measured RIR.
From those prepared clean files, noisy corpora have
been built by adding the recorded sensors noise with
a SNR set to 10, 5, 0 and -5 dB. In real scenarios, the
SNR of the speech corrupted by the sensors noise
vary between 5 and 10 dB depending on the loud-
ness of the speaker and the distance between him
and the robot.
When applying the NMF algorithm the cost func-
tion (3) has been used but no stop criterion has been
set and a fixed number of 25 iterations has been
run. Wn has been built by applying the NMF al-
gorithm with rn = 64 and ? = 0 to a 10 seconds
noise recording. When applying the algorithm to the
speech samples denoising, r has been set to 128. A
different sparseness constraint has been applied to
Hn and Hs with ?n = 0 and ?s = 0.2.
As a reference, the noisy sound samples have as
31
well been processed using a state-of-the-art single-
channel noise reduction scheme, i.e. the decision-
directed approach according to (Ephraim and Malah,
1985) based on two different noise estimation
schemes, i.e. the minimum statistics approach (MS)
as described in (Martin, 2001) and the minimum
mean square error (MMSE) approach according
to (Gerkmann and Hendriks, 2011).
5 Results
The achieved denoising is evaluated with the SNR
of the denoised samples and with the noise reduc-
tion (NR) as described in (Loizou, 2007). For both
scores, the presented values are the mean of the
achieved scores on all tested speech samples and
the standard deviation along the corpus. The results
are presented in Figure 7 for varying input SNR and
spectrograms of a denoised speech sample using the
three methods is shown in Figure 8. It appears that
the NMF based method provides better results, both
in term of signal enhancement and of reliability.
10 5 0 ?5?8
?4
0
4
8
SNR of noisy signal in dB
NR 
of d
enoi
sed 
sign
al in
 dB
12
16
20
24
28
SNR
 of d
enoi
sed 
sign
al in
 dB
 
 NMFMMSEMS
10 5 0 ?5?8
?4
0
4
8
SNR of noisy signal in dB
NR 
of d
enoi
sed 
sign
al in
 dB
12
16
20
24
28
SNR
 of d
enoi
sed 
sign
al in
 dB
 
 NMFMMSEMS
Figure 7: Mean and standard deviation of the achieved
SNR and NR for the three tested methods and for differ-
ent noise levels (SNR).
 
Freq
uenc
y in 
Hz
 
 8000
7000
6000
5000
4000
3000
2000
1000
?30
?25
?20
?15
?10
?5
0
 
Freq
uenc
y in 
Hz
 
 8000
7000
6000
5000
4000
3000
2000
1000
?30
?25
?20
?15
?10
?5
0
 Time in s
 
Freq
uenc
y in 
Hz
 
 
0 1 2 3 4 5
8000
7000
6000
5000
4000
3000
2000
1000
?30
?25
?20
?15
?10
?5
0
Figure 8: Spectrogram of a denoised signal using the
three different methods, MS (top), MMSE (middle) and
NMF.
6 Conclusion
A NMF based method to enhance speech signal
when provided with spectral knowledge of the noise
has been presented. This method has been applied to
the reduction of the non stationary noise produced
by the sensors of a robotic assistant. When tested
on a corpus of speech signals, the proposed method
achieved better performances than well known VAD
based denoising.
Further works would include fine tuning of the
method, such as determining the optimal number of
iterations to obtain the best trade off between en-
hancement and computing cost, as well as the use of
spectro temporal patches as elements of dictionary.
32
7 Acknowledgement
This work was partially supported by the "Adapt-
able Ambient Living Assistant" (ALIAS) project co-
funded by the European Commission and the Fed-
eral Ministry of Education and Research (BMBF).
References
