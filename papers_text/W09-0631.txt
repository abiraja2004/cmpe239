Proceedings of the 12th European Workshop on Natural Language Generation, pages 185?186,
Athens, Greece, 30 ? 31 March 2009. c?2009 Association for Computational Linguistics
Generation of Referring Expression with an Individual Imprint
Bernd Bohnet
International Computer Science Institute
1947 Center Street, CA 94704 Berkeley
bohnet@icsi.berkeley.edu
Abstract
A major outcome of the last Shared Tasks
for Referring Expressions Generation was
that each human prefers distinct proper-
ties, syntax and lexical units for building
referring expressions. One of the reasons
for this seems to be that entities might
be identified faster since the conversation
partner has already some knowledge about
how his conversation partner builds refer-
ring expressions. Therefore, artificial re-
ferring expressions should provide such
individual preferences as well so that they
become human like. With this contribu-
tion to the shared task, we follow this idea
again. For the development set, we got a
very good DICE score of 0.88 for the fur-
niture domain and of 0.79 for the people
domain.
1 Introduction
We expect that the test set does not provide the
information to which human a referring expres-
sion belongs. Therefore, we implemented a fall
back strategy in order to get still acceptable DICE
scores. In such cases, we select among all sets the
set of referring expressions which is most similar
to all others. We compute the similarity between
two sets as the average DICE score between all re-
ferring expression of two sets. The basis for our
algorithm is an extended full brevity implementa-
tion, cf. (Bohnet and Dale, 2005). IS-FP uses also
the nearest neighbor technique like the IS-FBN al-
gorithm that was introduced by Bohnet (2007).
With the nearest neighbor technique, IS-FP se-
lects the expressions which are most similar to
the referring expressions of the same human and
a human that builds referring expressions similar
or in the case that the human is unknown it uses
the most similar one to all others referring expres-
sions. The similarity is computed as the average of
all DICE scores between all combinations of the
available trails for two humans. From the result
of the nearest neighbor evaluation, FP selects the
shortest and if still more than one expressions re-
main then it computes the similarity among them
and chooses the most typical and finally, if still al-
ternatives remain, it selects one with the attributes
having the highest frequency. Table 1 shows the
results for IS-FP trained on the training set and ap-
plied to the development set.
Set Dice MASI Accuracy .
Furniture 0.880 0.691 51.25%
People 0.794 0.558 36.8%
Total 0.837 0.625 44%
Table 1: Results for the IS-FP algorithm
2 IS-GT: Realization with Graph
Transducers
We build the input dependency tree for the text
generator due to the statistical information that we
collect from the training data for each person. This
procedure is consistent with our referring expres-
sion generator IS-FP that reproduces the individ-
ual imprint in a referring expression for the target
person. We start with the realization of the refer-
ring expressions from a surface syntactic depen-
dency tree, cf. (Mel?c?uk, 1988). For the realiza-
tion of the text, we use the Text Generator and Lin-
guistic Environment MATE.
185
3 The Referring Expression Models
An algorithm learns a Referring Expression Model
for each person that contributed referring expres-
sion to the corpus. The model contains the follow-
ing information:
(1) The lexicalization for the values of a attribute
such as couch for the value sofa, man for
value person, etc.
(2) The preferred usage of determiners for the
type that can be definite (the), indefinite (a),
no article.
(3) The syntactic preferences such as the top left
chair, the chair at the bottom to the left, etc.
The information about the determiner and the
lexicalization is collected from the annotated word
string and the word string itself. We collect the
most frequent usage for each person in the corpus.
In order to collect the preferred syntax, we anno-
tated the word strings with syntactic dependency
trees. Each of the dependency tress contains ad-
ditional attributes, which describe the information
content of a branch outgoing from the root as well
as the possible value of the attribute at the nodes
which carry the information. The learning pro-
gram cuts the syntactic tree at edges starting at the
root node and stores the branches in the referring
expression model for the person.
4 Realization
For the realization, we use a handcrafted grammar
that generates out of the dependency trees topo-
logic graphs. The main task of the grammar is to
determine the word order. The system was devel-
oped only by using the training data without any
consideration of the development data. We used
as guide for the optimization cross validation of
training data.
5 IS-FP-GT: The Combination of
Attribute Selection and Realization
For the combination of the both methods, we com-
bine the two procedure in a pipeline architecture.
Table 2 shows the results.
6 Conclusion
The IS-FP algorithm reproduces the imprint of hu-
man referring expressions. When the test set con-
tains the reference to the human then the scores are
exceptional high.
Set Accuracy String ED Mean SED Blue 3
Furniture 15 % 3,8625 0.3826 0.3684
People 4,41 % 4,764 0.4817 0.2263
Total 9,71 4,313 0.4321 0.297
Table 2: Results for the TUNA-REG Task
References
B. Bohnet and R. Dale. 2005. Viewing referring
expression generation as search. In IJCAI, pages
1004?1009.
B. Bohnet. 2007. IS-FBN, IS-FBS, IS-IAC: The Adap-
tation of Two Classic Algorithms for the Generation
of Referring Expressions in order to Produce Ex-
pressions like Humans Do. In MT Summit XI, UC-
NLG+MT, pages 84?86.
I.A. Mel?c?uk. 1988. Dependency Syntax: Theory and
Practice. State University of New York Press, Al-
bany.
186
