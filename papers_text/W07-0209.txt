TextGraphs-2: Graph-Based Algorithms for Natural Language Processing, pages 61?64,
Rochester, April 2007 c?2007 Association for Computational Linguistics
Semi-supervised Algorithm for Human-Computer Dialogue Mining
Calkin S. Montero and Kenji Araki
Graduate School of Information Science and Technology
Hokkaido University, Kita 14-jo Nishi 9-chome
Kita-ku, Sapporo 060-0814 Japan
{calkin,araki}@media.eng.hokudai.ac.jp
Abstract
This paper describes the analysis of weak
local coherence utterances during human-
computer conversation through the appli-
cation of an emergent data mining tech-
nique, data crystallization. Results reveal
that by adding utterances with weak local
relevance the performance of a baseline
conversational partner, in terms of user
satisfaction, showed betterment.
1 Introduction
Data mining can be defined as the process of find-
ing new and potentially useful knowledge from data.
An enhanced trend of data mining is chance discov-
ery, which in spite of being an emergent field of re-
search has been applied to different branches of sci-
ence. Recently, data crystallization (Ohsawa, 2005)
has been proposed as a chance discovery extension
devoted to find desired unobservable events within
a given data. This method of data mining has been
intended for revealing events that are significant but
are not included in the analyzed data (sparseness).
The knowledge database of a conversational part-
ner computer program is a good example of data
sparseness, making very difficult to realize a human-
like conversation between a user and a computer,
since the database is missing relevant or coherent
answers for a given user input, e.g., ELIZA sys-
tem (Weizenbaum, 1966), corpus-based dialogue
systems (Inui et al, 2003), and so forth. Herring
(1999) noticed the weak sequential coherence dur-
ing human-computer interaction that is caused by
weak local relevance, pointing out the violation of
the Gricean maxim of local relevance during the di-
alogue. However, we argue that conversational re-
sponses - often of very weak local relevance - gener-
ated by a conversational partner computer program
(or ?chatbot?) could successfully simulate human-
like coherent dialogue (see example given by (Her-
ring, 1999), where topical coherence is stated in
spite of violation of local relevance Gricean maxim).
Moreover, we argue that weak local relevance utter-
ances could be regarded as topic-shifting utterances.
These utterances are vital in order to keep the flow of
the dialogue and its overall coherence. Determining
the moment when the topic-shifting utterances are
needed is hence essential to the success of a chatbot.
In this paper KeyGraph and data crystallization
techniques are applied to analyze human-computer
trivial dialogue, chat, considering as chances to dis-
cover the missing topic-shifting utterances, used to
improve the overall sequential coherence and the
flow of the computer dialogue.
2 Human-Computer Conversation
Analysis Approach
During the process of dialogue mining, in order to
analyze the behavior of human-computer conversa-
tional interaction, the interrelationship of utterances
of a dialogue section was obtained. The following is
a fragment of an analyzed dialogue section between
a user and ALICE chatbot (Wallace, 2005):
[1] User: hi
[2] Chatbot: hello there! what is your name?
[3] User: Joe
[4] Chatbot: Ok, I will call you Joe
61
[5] User: what should I call you?
[6] Chatbot: my name is Alice
[7] User: cool [....]
(Conversation continues)
[17] User: what do you mean by robot? there are lots of differ-
ent robots
[18] Chatbot: It is a good question. Have you tried a web
search? Would you like to know more?
[19] User: sure
[20] Chatbot: Ok let?s do it. What would you like to know?
[21] User: what Alice thinks a robot means
[22] Chatbot: is that a rhetorical question? I would search for it
[23] User: when I hear robot, I think of something that moves
[24] Chatbot: you never know what to expect from life. Why?
oh yeah, we are talking about something that moves [....]
For the analysis, the application of data crystal-
lization is introduced in order to identify the miss-
ing topic-shifting utterances. The interrelationship
of utterances (user-chatbot) is represented in a co-
occurrence document created as described below.
2.1 The KeyGraph
The KeyGraph has been used as a data-mining tool
for extracting patterns of the appearance of chance
events (Ohsawa et al(2003)). The KeyGraph iden-
tifies relationships between terms in a document
particularly focusing on co-occurrence relationships
of both high-probability and low-probability events.
Montero et al (2005) have applied this tool for ana-
lyzing the dynamic behavior of human-human chat,
identifying criticality.
In this paper the KeyGraph is applied in combi-
nation with data crystallization in order to visual-
ized utterances that do not appear during human-
computer chat. The interrelationship of utterances
(user-chatbot) is represented in a co-occurrence doc-
ument created by the following algorithm: a) Each ut-
terance (from both, the user and the chatbot) was considered as
one sentence. b) Each sentence was segmented into words. c)
High frequency words were eliminated, i.e., I, you, is, follow-
ups and the like, as to avoid false co-occurrence. d) A vectorial
representation of each sentence (at word level) was obtained and
sentences co-occurrence relationship was determined as1:
D= w1:: S1, S2, S4 .../ w2:: S9, S25 .../
w3:: S1, S3, S10 .../ ... / wn:: S24, S25, ... Sm
1Since follow-ups were eliminated, the number of sentences
in D might be smaller than the actual number of sentences in
the dialogue.
where: wk (k = 1, 2, 3, ..., n), represents a word in a sentence.
Sl (l = 1, 2, 3, ..., m), represents a sentence.
Then it could be said that the obtained D docu-
ment contains the co-occurrence relationship of the
utterances during the analyzed dialogue section. In
the graph, the most frequent items in D are shown
as black nodes and the most strongly co-occurring
item-pairs are linked by black lines according to the
Jaccard coefficient:
J(Sx, Sy) = p(Sx ? Sy)/p(Sx ? Sy)
where p(Sx ? Sy) is the probability that both el-
ements Sx and Sy co-occur in a line in D, and
p(Sx ? Sy) is the probability that either Sx or Sy
appears in a line. In the graph, nodes are interpreted
as sentences (from D) and clusters of nodes as par-
ticular topics (Figure 1).
2.2 Data Crystallization
Data crystallization (Ohsawa, 2005), is dedicated to
experts working in real domains where discoveries
of events that are important but are not included in
the analyzed data are desired. The process of data
crystallization involves to insert dummy items in
the given data in order to represent unobservable
events. In this paper, each dummy item inserted in
the D document (one in each vector of D) is named
XY , where X represents the level of the insertion
and Y represents the line where the dummy item
was inserted. The KeyGraph is applied to the new D
document and all of the dummy nodes that did not
appear linking clusters in the graph are eliminated
from the data, and then the cycle is iterated to higher
levels. In the case of the D document of Sec.2.1,
after the first level of insertion it becomes:
D?= w1:: S1, S2, S4 ...11 / w2:: S9, S25 ...12 /
w3:: S1, S3, S10 ...13 / ... / wn:: S24, S25, ... Sm 1n
where 1 o (o = 1, 2, 3, ..., n), represents each dummy item
inserted in each vector of D.
After feeding the KeyGraph with D?, all the
dummy items that did not appear linking clusters as
bridges in the outputted graph are deleted. At this
point new dummy items with higher hierarchy (2x)
are inserted in D?, and the cycle iterates. Unobserv-
able events and their relations with other events are
to be visualized by the application of KeyGraph iter-
atively to the data that is been crystallized (Figure 2).
62
Figure 1: User-Computer Chat Graph Figure 2: Crystallized Data Graph
3 Experiment and Visual Results
The performed experiment was carried out in three
stages. In the first stage of the experiment, three dif-
ferent dialogue sections (including the one shown in
Sec.2) between three native English speakers and a
chatbot (Wallace, 2005) were analyzed in order to
find co-occurrence between the users? utterance and
the chatbot replies, i.e., D document. This D docu-
ment was then examined by the KeyGraph (unsuper-
vised process). Figure 1 shows the graphical view of
the dialogue in Sec.2 (48 turns, user - chatbot, in to-
tal). A characteristic of the KeyGraph is the visual-
ization of co-occurring events by means of clusters.
In Figure 1, the nodes represent sentences from the
D document, the clusters represent the relationship
among those sentences, i.e., a specific topic, and the
nodes that link the clusters represent the transition
from one topic to the next. It can be observed that
the main clusters are not interconnected, leading to
the conclusion that the chatbot in many cases could
not keep a smooth and natural flow of the dialogue.
In the second stage of the experiment, a crystal-
lized document of utterance co-occurrence, i.e., D?
document, was obtained for the same dialogue sec-
tions, following the process described in Sec.2.2.
The graphical output of the dialogue in Sec.2, af-
ter crystallization, can be observed in Figure 2. It
can be seen in this figure how the two main clusters
appear to be interconnected by the dummy item 1 3.
Although this dummy item was inserted in the third
line of the D document, it appears in the graph con-
necting the two main clusters. The dummy item 1 3
branches from utterance [24]. This interconnecting
point can be regarded as the system considering it
appropriate to insert a topic-shifting utterance at this
point of the conversation. In doing so, a well in-
terconnected graph is obtained (Figure 2). This in-
formation is valuable for making the chatbot to ask
?intelligent questions? as a mean of conversational
responses to keep the interest from the user.
In the third stage of the experiment, the informa-
tion yielded by the previous analysis, i.e., regard-
ing the timing where a topic-shifting utterance might
be needed, was used to feed the chatbot database.
Topic-shifting responses were inserted by hand (su-
pervised process) as general patterns (around one
hundred patterns) for smoothly change the topic
when there is not a pattern that matches a given ut-
terance. In this way a bridge, represented in Figure
2 by the dummy item, is created giving to the di-
alogue the desired smoothness. Seven users (four
native English speakers, three non native speakers)
were requested to perform a chat with the plain chat-
bot and with the enhanced chatbot (the users did
not know which chatbot was plain or which was en-
hanced). The time set up was maximum 30 minutes-
chat with each program, the user was free to stop
at any time before the time limit. The evaluation of
the chatbots performances was made through a ques-
63
Turns % V.R.* Accuracy/relevance
Baseline 74 21.11% fair
Enhanced 128 7.37% good
V.R.* = Vague Reply (This table contains the average of Turns and VR)
Table 1: Chatbots Overall Performance
tionnaire given to the users. In the questionnaire the
degree of satisfaction of the user was surveyed based
on the accuracy/relevance of the chatbot responses
and its ability to keep the dialogue flowing. The ac-
curacy/relevance had a ranking scale: 1. excellent, 2.
good, 3. average, 4. fair, and 5. poor, while the user satis-
faction ranked : 1. very satisfied, 2. satisfied, 3. not sure, 4.
dissatisfied, and 5. very dissatisfied.
The four native English speaker users globally
agreed ranking enhanced chatbot as having ?good?
accurate/relevant responses during the overall dia-
logue, giving remarks like ?interesting to talk with?,
?better at keeping the conversation going?, ?easier
to talk to?, and ?more impression of consciousness?.
In the case of the plain chatbot, the native speakers
showed ?dissatisfied? at its performance, giving re-
marks like ?loop responses?, ?slow in keeping the
conversation going?, ?no so nice responses?, ?no
constant memory?. Table 1 shows a resume of the
average performance of the chatbot for all of the
users. An example of a vague reply is given in the
following fragment:
Chatbot: What is like living in Sapporo?
User: sweet as
Chatbot: In the context of living in Sapporo I don?t under-
stand ?what is like living in Sapporo?? [vague reply]
Two non native English speaker users ranked the
enhanced chatbot as having ?fair? and ?average?
accurate/relevant responses while the plain chat-
bot was ranked as having ?poor? and ?fair? accu-
rate/relevant responses. The third non native En-
glish speaker user ranked both chatbots as ?poor?
due to ?the chatbots lack of understanding deixis,
and anaphor?.
As a mean of discussion, in Figure 2 it could be
expected that the dummy item 1 3 would branch
from utterance [25] {User: no, you asked me who is the
best robot}, which is in the same cluster with utterance
[24]. However, under closer examination it becomes
clear that utterance [24] has stronger co-occurrence
with utterance [38] {Chatbot: I know you are but what am
I} than utterance [25]. Hence, the algorithm suggests
to link the clusters via utterance [24].
In other aspect, based on the feedback given by
the seven users of the experiment, the overall per-
formance of the enhanced chatbot can be considered
better than the plain chatbot. It is worth noticing
that the evaluation of the non native English speaker
users tended to emphasize the grammatical aspect
of the chatbots responses. On the other hand, the
evaluation of the native English speaker users tended
to emphasize the smoothness of the dialogue. Al-
though there is still plenty of room for improve-
ment and research a betterment in the chatbot per-
formance could be seen through this approach.
4 Conclusion
In this paper the application of a novel data mining
method, data crystallization, for visualizing missing
topic-shifting utterances during human-computer
chat has been described. Based on this informa-
tion, during the experiment, the use of weak local
relevance utterances, i.e., topic-shifting responses,
despite of violation of Grecian maxim of local rel-
evance, showed to meliorate the overall dialogue
flow. Future research will be oriented to the ex-
tended implementation of the obtained results for
enhancing the chat flow modeling of a conversa-
tional partner program.
References
Susan Herring. 1999. Interactional coherence in cmc. Journal
of Computer Mediated Communication, 4(1).
Nobuo Inui, Takuya Koiso, Junpei Nakamura, and Yoshiyuki
Kotani. 2003. Fully corpus-based natural language dia-
logue system. In Natural Language Generation in Spoken
and Written Dialogue, AAAI Spring Symposium.
Yukio Ohsawa and Peter McBurney, editors. 2003. Chance
Discovery. Springer, Berlin Heidelberg New York.
Yukio Ohsawa. 2005. Data crystallization: Chance discovery
extended for dealing with unobservable events. New Mathe-
matics and Natural Computation, 1(3):373?392.
Calkin S Montero and Kenji Araki. 2005. Human chat and self-
organized criticality: A chance discovery application. New
Mathematics and Natural Computation, 1(3):407?420.
Richard Wallace. 2005. A.l.i.c.e. artificial intelligence founda-
tion. http://www.alicebot.org.
Joseph Weizenbaum. 1966. Eliza a computer program for the
study of natural language communication between man and
machine. Commun. ACM, 9(1):36?45.
64
