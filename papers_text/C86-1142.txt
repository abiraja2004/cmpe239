The procedure to construct a word predictor in a speech understanding system 
from a task-specific grammar defined ill a CFG or a DCG 
Yasuhisa Nilmi, Shigeru Uzuhara and Yutaka Kobayashi 
Department of Computer Science 
Kyoto Institute of Technology 
Matsugasaki, Sakyo-ku, Kyoto 606, Japan 
Abstract 
This paper describes a method for converting a 
task-dependent grammar into a word predictor of a 
speech understanding system, Since tile word 
prediction is a top-down operation, left  recursive 
rules induces an in f in i te  looping. We have solved 
this problem by applying an algorithm for bottom-up 
parsing, 
1. Introduction 
which tile ends terminate at different portions on the 
phonetic sequence, and the other represents the se- 
quences of syntactic categories (called category 
sequences), each of which is associated with one of 
the word strings, ln this situation, the controller 
chooses the word string with tile highest score, 
sends tile associated category sequence to the word 
predictor and asks i t  to predict those syntactic 
categories which can syntactically follow the se- 
lected sequence. 
In this paper we present a method for converting a 
task-specific gravmnar into a word predictor, an im- 
portant component of a speech understanding system. 
A context free grammar (CFG) or an augmented transi- 
tion network grammar (ATNG) have been used to des- 
cribe task-speclfic constraint. When a CFG is used, 
Early's algorithm\[l\], one of the most eff icient top- 
down parsing algorithms, has been used to make word 
prediction\[2\]. When an ATNG is used, word prediction 
is simply made by tentatively traveling along arcs 
going out freln a state in an ATNG\[3\],\[4\],\[5\]. Since 
the word prediction is a top-down operation, i t  is 
d i f f i cu l t  to avoid fal l ing into an inf inite loop i f  
the task-specific grammar includes a left  recurslve 
rule. 
F. Perelra and D. Warren have developed a definite 
clause grammar (DCG)\[6\]. The rules described in a DCG 
are directly converted into a set of Pro\]og clauses, 
which works as a parser with an aid of tile powerful 
pattern matching mechanism of Prolog. Thus syntactic 
analysis can be done without writing a specia\] parser 
working on the rules of the grammar. Since tile syn- 
tactic analysis based on a DCG parser also works in 
top-down fashion, i t  shares the same d i f f i cu l ty  as 
the top-down parsers have. ?. Matsumoto et at. have 
developed a method for converting a set of rules 
described in a DCG into a bottom-up parser which has 
overcome thls d i f f i cu l ty  without any loss of the 
advantages of a DCG\[7\]. 
We discuss an application of this method to a word 
predictor, that is, the method for transforming task- 
specific l inguistic constraint defined in a CFG or a 
DCG into a Prolog program which acts as a lef t - to-  
right word predictor. 
2. Word predictlon in a ~eech understandlnq~sj(stem 
Fig.l shows a typical configuration of a speech 
understanding system based on a hierarchical model. 
An acoustic-phonetic processor analyzes of an input 
uttereance and transforms i t  into a sequence of pho- 
netically labeled segments. Provided that a part of 
an utterance has been dealt with, the controller 
manages its interpretations in the two kinds of trees 
i l lustrated in Fig.2; one represents word strings, of 
l inguistic processor 
predicted categor ies~tegory  sequence 
~ . r o l  ler ) 
predicted words T- rocog, i ed words 
I lexlcal processor \] 
Phonetic latt ice 
I ac?ustic-ph?netic 
processor I 
speec~ wave 
Fig. I A typical configuration of a speech 
understanding system. 
category 
tree 
word tree 
sequence 
of 
phonetic 
segments 
C3 #3 
Cl #I 
' ~ C2 '~ ~ , 
I \  ! t % i ~  I "?', /'r" i,l~ .L ~ \ \ I 
W1 
i 
'1 ' I \ 
Fig. 2 A search space of a speech understanding 
system. 
605 
The word predictor could parse a given category 
sequence and predict the categories which can follow 
i t .  I t  is, however, inefficient to analyze the given 
sequence whenever asked to predict. In fact, each 
node of the category tree is associated with a par- 
sing history on how rules of the grammar have been 
applied to analyze the category sequence. The word 
predictor receives a node and its parsing history 
from the controller and predicts the syntactic cate~ 
gories following the node. 
3_. The bottom-up parser and its application to word 
prediction 
We give a br ie f  explanatlon of the bottom-up par- 
ser proposed by Y. Matsumoto e ta l .  Assume simply 
that the rules of the grammar are described in a CFG. 
Then, without loss of general i ty  each of the rules 
can be expressed as e i ther  of the fol lowings. 
c -> Cl,C2,..,c n 
(c, c i (i=l . . . .  n): nonterminals) l) 
c -> w (w: a terminal) 2) 
( l )  These rules are transformed into the following 
Prolog clauses. 
cI(G,XI,X ) : -  link(c,G),goal(c2,Xi,X2) . . . .  
goal(cn,Xn_l,Xn), c(G,Xn, X). l ' )  
dict(c,\[wJX\],X). ?') 
X and X~ (i=l . . . .  n) are arguments to denote 
word strifig to be analyzed as a l i s t .  'link(C,G) 
is a predicate to express that a string of which 
the left  most symbol is a nonterminal C can be 
reduced to a nonterminal G. G is called a goal 
argument in this sense. ' l ink '  is defined as 
follows: i f  the rule I) is included in the gram- 
mar, then ' l ink (c l , c ) '  holds, and i f  ' l ink(a,b) '  
and ' l ink(b,c) '  &old, then ' l ink(a,c) '  holds 
(transitive law), and ' l ink(c,c) '  holds for every 
nonterminal c (reflective law). A predicate 
'dict(C,X,Y)', searching the dictionary for the 
f i r s t  word of a word string X, unifies C with its 
syntactic category and Y with the remaining 
string. 
(2) A predicate goal(G,X,Z) is defined as follows. 
goal(G,X,Z) :-  dict(C,X,Y),link(C,G), 
exec(C,G,Y,Z). 3) 
where 'exec' is a predicate to execute a predi- 
cate 'c(G,Y,Z)'. 
(3) Furthermore, fGr any nonterminal C, the fol-  
lowing assertion called a terminal condition 
holds: 
c(c,X,X). 4) 
The parser for the given grammar consists of al l  
these Prolog clauses. 
In order to use the bottom-up parser as a lef t -  
to-right word predictor, we change the predicate 
'goal' as follows: 
goal(G,\[ \] , \ [ \ ])  : -  llnk(C,G),terminal(C), 
output(C),fai}. 3 ' - I )  
606 
goal(G,X,Z) : -  dict(C,X,Y),link(C,G), 
exec(C,G,Y,Z). 3'-2) 
where 'terminal(C)' is a predicate to be true when a 
nonterminal C appears in the left-hand side of a 
productlonof 2). 
The modified parser, receiving a word string from 
the controller, executes the second of 'goal' clauses 
in which the second argument X is unified with the 
given word string. Syntactic analysis of X is con- 
tinued until X becomes empty. Then, the f i r s t  of 
'goal' clauses is invoked and predicts all the syn- 
tactic categories which make both 'link(C,G)' and 
'terminal(C)' hold. 
4. Word grediction under a le f t - to - r i~  
In this section we discuss the method for conver- 
tion of a set of productions defined in a CFG into a 
set of Prolog clauses which acts as a lef t - to-r ight  
word predictor. In order that this predictor can work 
without re-analyzing a given category sequence, we 
must )lave a table (named a history table) which 
contains an association of a category sequence with 
its parsing history, that is, a history on how pro- 
ductions are used to parse the sequence. 
Considering a transition network depicted in Fig.3 
for a production 'c->clc~..c ', we express a parsing 
history with a l i s t  of Lpai~s of a state name in a 
transition network and a goal argument appearing in 
bottom-up parsing. For the grammar shown in Fig.4, a 
category sequence 'N N' is parsed as shown in 
Fig.5(a) and the corresponding state transition is 
shown in Fig.5(b). A parsing history for this se- 
quence can be expressed as a l i s t  \[nps2,s\]. The 
state name 'nps2' indicates that the last 'N' of the 
C l C 2 C n 
Fig. 3 A transition network for a rule 
C - ,  C I C 2 . . .  C n. 
S -> NP VP NP -> N 
NP -> NP N VP -> V NP 
NP -> ART NP 
Fig. 4 An example of context free grammar. 
. ~.>_>-.s / 
I 
N N 
(a) (b) 
Fig. 5 The parse tree of 'N N' and the 
corresponding state transition. 
sequence 'N N' has been parsed as 'N' in the produc- 
Lion 'NP->NP N', and the goal a rgument ' s '  indicates 
that the sequence is the le f t  most part of the str ing 
derived by the s tar t  symbol ' s ' .  
Now we shal l  describe the procedure to transform a 
set of productions described in a CFG into  a word 
predictor .  
( I )  For a production 'c ->c.c~. .c  ', tile fo l lowing set 
? / L: n of Prolog clauses Is generated: 
cI(\[GIH\]) :- link(c,G),al(\[GIHI). 
al(E ) :-. pred(c2,\[a21E\]). 
a2(E ) :-- pred(c3,\[a31E\]), 
an~l(E) : -  pred(cn,\[anJE\]) ,  
an(E) : - c (E ) .  4 - I )  
where H and E are the arguments to store parsing 
h i s to r ies ,  the f i r s t  element of H is a state name 
and that of E is a goal argument. 
(2) For a nonterminal c, the fo l lowing terminal con- 
d i t ion  holds: 
c(\[c,alE\]) :- exec(a,E), 4-2) 
(3) Corresponding to 'goal '  in the bottom-up parser, 
a predicate 'pred' is defined as fo l lows:  
pred(G,H) : -  l ink(C,G) , terminal (C) ,  
newface(No),hand to(No,C), 
makenode(No,C,\[GTH\]),fail. 4-3) 
A predicate 'newface(No)' generates a new node 
number in 'No', 'hand_to(No,C)' sends a pair  of a 
node number 'No' and a predicted syntact ic  cate- 
gory C to the cont ro l le r ,  and 'makenode()' stores 
a node number and i t s  corresponding parsing his-  
tory  expressed as 'C(\[GIN\]) '  in the h i s to ry  
table.  
(4) The cont ro l le r  in a speech understanding system 
communicates the word predictor  through a predi -  
cate 'wantword' which sends to the word predictor  
a node number associated with a category sequence 
which the cont ro l le r  has selected, whi le the word 
predictor  returns through 'hand to '  a set of the 
syntact ic  categories which can fo l low the se- 
lected category sequence. The de f in i t ion  of 
'wantword' is as follows: 
wantword(O) : -  ! ,p red(s , \ [ \ ] ) .  4-4) 
wantword(No) : -  p ick_up(No,Z) , ! ,ca l l (Z) .  4-5) 
The symbol s in 4-4) s ign i f ies  the s tar t  symbol, 
and the clause 4-4) is used to make a pred ict ion 
at the le f t  most part  of an utterance. The 
predicate 'pick up(No,Z)' looks up the h is tory  
table  for  a node number 'No', and picks up i ts  
associated h is tory  expressed as 'C( \ [GIH\] ) ' ,  the 
execution of which invokes the clause of 4 - I )  or 
4-2). 
5. Conclusions 
In this paper we have proposed the procedure to 
convert a grammar defined in a CFG or a DCG into a 
Prolog program which functions as a word predictor .  
The procedure is give@ for the le f t - to - r ight  contro l ,  
but i t  is not d i f f i cu l t  to expand i t  for the is land- 
driven contro l .  
To s impl i fy  the descr ipt ion,  we have given the 
conversion procedure for a grammar defined in a CFG, 
but i t  is easy to expand i t  for  a grammar defined in 
a DCG, As long as one concernes on a speech under- 
standing system in which syntax and semantics are 
well defined, one could take an advantage of a DCG in 
which a nonterminal can have some arguments as para- 
meters, and could use semantic res t r i c t ions  e f fec -  
t i ve ly  to in terpret  an utterance. In developing a 
speech understanding system of which the task is to 
access a database, we use semantic markers to des- 
cribe semantic res t r i c t ions  between an ad ject ive  and 
a noun, a noun phrase and a postposit ion ( in  Japan- 
ese), and case slots of a verb and i ts  f i l l e rs .  In 
th is  case a rule can be expressed as fol lows: 
C(So) -> \[Po(So, S I )}CI (S I ){PI (S I ,S2)}C2(S2) . . .  
{Pn_l(Sn_l,Sn))Cn(Sn), 
where S~ ( i=O,l  . . . .  n) is a l i s t  of semantic markers, 
Pi ( i= l ,2  . . . .  n) is a predicate to denote a constra int  
among semantic markers. Considering a t rans i t ion  
network for  th is  DCG rule,  we associate P. with i ts  \] 
i - th  state and le t  Pi function as a converter of 
semantic markers. Since Pi would be defined in the 
form of a table,  this converter could work 
b id i rec t iona l ly .  In addit ion,  stacking a pair" of a 
syntact ic goal var iab le  and a l i s t  of semantic 
markers in the parsing h is tory ,  we can develop a 
procedure to transform a grammar described in a DCG 
into a word predictor .  
Acknowledgement 
This research was supported by the grant - in -a id  
for the special pro ject  research ' In te l l igent  Proces- 
sing and Integrat ion of Knowledge Informations in 
Mult i -Media'  by the Min is t ry  of Education, Science 
and Culture of Japan. 
References 
\ [ I \ ]  J. Early: An e f f i c ient  context - f ree parsing algo- 
rithm, Comm, ACM, 13--2 (1970). 
\[2\] T. Sakai and S. Nakagawa: A speech understanding 
system of simple Japanese sentences in a task 
domain, Trans. of IECEJ, E60-1 (1977). 
\[3\] W.A. Woods et a l . :  Speech understanding systems 
- -  Final technical progress report 30 October 
1974 to 29 October 1976, BBN Tech. Rep.  3438, 
vol .  4 (1976). 
\[4\] D.R. Reddy et a l . ;  Speech understanding system 
- -  Summary of results  of tile f i ve  year research 
e f fo r t  at Carnegie-Me\]Ion Univ., Carnegie-Mellon 
Univ. Tech. Rep. (1977). 
\[5\] Y. Niimi and Y. Kobayashi: A vo ice- input  program- 
ming system using BASIC-like language, Proc. IEEE 
Int .  Conf. ASSP (1978). 
\[6\] F.C.N. Pereira and D.II.D. Warren: Def in i te  clause 
grammar for language analysis - -  A survey of the 
formalism and comparison with augmented t rans i -  
t ion networks, Ar t i f i c ia l  In te l l igence,  13 
(1980). 
\[7\] Y. Matsumoto et a l . :  BUP ---A bottom-up parser 
embedded in Prolog, New Generation Computing, I -2 
(1983). 
607 
