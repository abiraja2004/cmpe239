Proceedings of the 7th Linguistic Annotation Workshop & Interoperability with Discourse, pages 149?158,
Sofia, Bulgaria, August 8-9, 2013. c?2013 Association for Computational Linguistics
Developing Parallel Sense-tagged Corpora with Wordnets
Francis Bond, Shan Wang,
Eshley Huini Gao, Hazel Shuwen Mok, Jeanette Yiwen Tan
Linguistics and Multilingual Studies, Nanyang Technological University
bondieee.org
Abstract
Semantically annotated corpora play an
important role in natural language pro-
cessing. This paper presents the results
of a pilot study on building a sense-tagged
parallel corpus, part of ongoing construc-
tion of aligned corpora for four languages
(English, Chinese, Japanese, and Indone-
sian) in four domains (story, essay, news,
and tourism) from the NTU-Multilingual
Corpus. Each subcorpus is first sense-
tagged using a wordnet and then these
synsets are linked. Upon the completion
of this project, all annotated corpora will
be made freely available. The multilingual
corpora are designed to not only provide
data for NLP tasks like machine transla-
tion, but also to contribute to the study
of translation shift and bilingual lexicogra-
phy as well as the improvement of mono-
lingual wordnets.
1 Introduction
Large scale annotated corpora play an essen-
tial role in natural language processing (NLP).
Over the years with the efforts of the commu-
nity part-of-speech tagged corpora have achieved
high quality and are widely available. In com-
parison, due to the complexity of semantic an-
notation, sense tagged parallel corpora develop
slowly. However, the growing demands in more
complicated NLP applications such as informa-
tion retrieval, machine translation, and text sum-
marization suggest that such corpora are in great
need. This trend is reflected in the construc-
tion of two types of corpora: (i) parallel cor-
pora: FuSe (Cyrus, 2006), SMULTRON (Volk
et al, 2010), CroCo ( ?Culo et al, 2008), German-
English parallel corpus (Pad? and Erk, 2010), Eu-
roparl corpus (Koehn, 2005), and OPUS (Ny-
gaard and Tiedemann, 2003; Tiedemann and Ny-
gaard, 2004; Tiedemann, 2009, 2012) and (ii)
sense-tagged monolingual corpora: English cor-
pora such as Semcor (Landes et al, 1998); Chi-
nese corpora, such as the crime domain of Sinica
Corpus 3.0 (Wee and Mun, 1999), 1 million word
corpus of People?s Daily (Li et al, 2003), three
months? China Daily (Wu et al, 2006); Japanese
corpora, such as Hinoki Corpus (Bond et al, 2008)
and Japanese SemCor (Bond et al, 2012) and
Dutch Corpora such as the Groningen Meaning
Bank (Basile et al, 2012). Nevertheless, almost no
parallel corpora are sense-tagged. With the excep-
tion of corpora based on translations of SemCor
(Bentivogli et al, 2004; Bond et al, 2012) sense-
tagged corpora are almost always monolingual.
This paper describes ongoing work on the con-
struction of a sense-tagged parallel corpus. It com-
prises four languages (English, Chinese, Japanese,
and Indonesian) in four domains (story, essay,
news, and tourism), taking texts from the NTU-
Multilingual Corpus (Tan and Bond, 2012). For
these subcorpora we first sense tag each text
monolingually and then link the concepts across
the languages. The links themselves are typed and
tell us something of the nature of the translation.
The annotators are primarily multilingual students
from the division of linguistics and multilingual
studies (NTU) with extensive training. In this pa-
per we introduce the planned corpus annotation
and report on the results of a completed pilot: an-
notation and linking of one short story: The Ad-
venture of the Dancing Men in Chinese, English
and Japanese. All concepts that could be were
aligned and their alignments annotated.
The paper is structured as follows. Section 2
reviews existing parallel corpora and sense tagged
corpora that have been built. Section 3 introduces
the resources that we use in our annotation project.
The annotation scheme for the multilingual cor-
pora is laid out in Section 4. In Section 5 we report
149
in detail the results of our pilot study. Section 6
presents our discussion and future work.
2 Related Work
In recent years, with the maturity of part-of-speech
(POS) tagging, more attention has been paid to
the practice of getting parallel corpora and sense-
tagged corpora to promote NLP.
2.1 Parallel Corpora
Several research projects have reported annotated
parallel corpora. Among the first major efforts in
this direction is FuSe (Cyrus, 2006), an English-
German parallel corpus extracted from the EU-
ROPARL corpus (Koehn, 2005). Parallel sen-
tences were first annotated mono-lingually with
POS tags and lemmas; related predicates (e.g.
a verb and its nominalization are then linked).
SMULTRON (Volk et al, 2010) is a parallel tree-
bank of 2,500 sentences from different genres:
a novel, economy texts from several sources, a
user manual and mountaineering reports. Most
of the corpus is German-English-Swedish paral-
lel text, with additional texts in French and Span-
ish. CroCo ( ?Culo et al, 2008) is a German-
English parallel and comparable corpus of a dozen
texts from eight genres, totaling approximately
1,000,000 words. Each sentence is annotated with
phrase structures and grammatical functions, and
words, chunks and phrases are aligned across par-
allel sentences. This resource is limited to two
languages, English and German, and is not sys-
tematically linked to any semantic resource. Pad?
and Erk (2010) have conducted a study of transla-
tion shifts on a German-English parallel corpus of
1,000 sentences from EUROPARL annotated with
semantic frames from FrameNet and word align-
ments. Their aim was to measure the feasibility of
frame annotation projection across languages.
The above corpora have been used for study-
ing translation shift. Plain text parallel corpora are
also widely used in NLP. The Europarl corpus col-
lected the parallel text in 11 official languages of
the European Union (i.e. Danish, German, Greek,
English, Spanish, Finnish, French, Italian, Dutch,
Portuguese, and Swedish) from proceedings of the
European Parliament. Each language is composed
of about 30 million words (Koehn, 2005). Newer
versions have even more languages. OPUS v0.1
contains the documentation of the office package
OpenOffice with a collection of 2,014 files in En-
glish and five translated texts, namely, French,
Spanish, Swedish, German and Japanese. This
corpus consists of 2.6 million words (Nygaard and
Tiedemann, 2003; Tiedemann and Nygaard, 2004;
Tiedemann, 2012). However, when we examined
the Japanese text, we found the translations are of-
ten from different versions of the software and not
synchronized very well.
2.2 Sense Tagged Corpora
Surprisingly few languages have sense tagged cor-
pora. In English, Semcor was built by annotat-
ing texts from the Brown Corpus using the sense
inventory of WordNet 1.6 (Fellbaum, 1998) and
has been mapped to subsequent WordNet versions
(Landes et al, 1998). The Defense Science Or-
ganization (DSO) corpus annotated the 191 most
frequent and ambiguous nouns and verbs from the
combined Brown Corpus and Wall Street Journal
Corpus using WordNet 1.5. The 191 words com-
prise of 70 verbs with an average sense number of
12 and 121 nouns with an average sense number
of 7.8. The verbs and nouns respectively account
for approximately 20% of all verbs and nouns in
any unrestricted English text (Ng and Lee, 1996).
The WordNet Gloss Disambiguation Project uses
Princeton WordNet 3.0 (PWN) to disambiguate its
own definitions and examples.1
In Chinese, Wee and Mun (1999) reported the
annotation of a subset of Sinica Corpus 3.0 using
HowNet. The texts are news covering the crime
domain with 30,000 words. Li et al (2003) an-
notated the semantic knowledge of a 1 million
word corpus from People?s Daily with dependency
grammar. The corpus include domains such as
politics, economy, science, and sports. (Wu et al,
2006) described the sense tagged corpus of Peking
University. They annotated three months of the
People?s Daily using the Semantic Knowledge-
base of Contemporary Chinese (SKCC)2. SKCC
describes the features of a word through attribute-
value pairs, which incorporates distributional in-
formation.
In Japanese, the Hinoki Corpus annotated 9,835
headwords with multiple senses in Lexeed: a
Japanese semantic lexicon (Kasahara et al, 2004)
To measure the conincidence of tags and difficulty
degree in identifying senses, each word was anno-
tated by 5 annotators (Bond et al, 2006).
1
http://wordnet.prineton.edu/glosstag.
shtml
2
http://l.pku.edu.n/l_sem_dit/
150
We only know of two multi-lingual sense-
tagged corpora. One is MultiSemCor, which is
an English/Italian parallel corpus created based
on SemCor (Landes et al, 1998). MultiSemCor
is made of 116 English texts taken from SemCor
with their corresponding 116 Italian translations.
There are 258,499 English tokens and 267,607
Italian tokens. The texts are all aligned at the word
level and content words are annotated with POS,
lemma, and word senses. It has 119,802 English
words semantically annotated from SemCor and
92,820 Italian words are annotated with senses au-
tomatically transferred from English (Bentivogli
et al, 2004). Japanese SemCor is another transla-
tion of the English SemCor, whose senses are pro-
jected across from English. It takes the same texts
in MultiSemCor and translates them into Japanese.
Of the 150,555 content words, 58,265 are sense
tagged either as monosemous words or by pro-
jecting from the English annotation (Bond et al,
2012). The low annotation rate compared to Mul-
tiSemCor reflects both a lack of coverage in the
Japanese wordnet and the greater typological dif-
ference.
Though many efforts have been devoted to the
construction of sense tagged corpora, the major-
ity of the existing corpora are monolingual, rel-
atively small in scale and not all freely available.
To the best of our knowledge, no large scale sense-
tagged parallel corpus for Asian languages exists.
Our project will fill this gap.
3 Resources
This section introduces the wordnets and corpora
we are using for the annotation task.
3.1 Wordnets
Princeton WordNet (PWN) is an English lexical
database created at the Cognitive Science Labo-
ratory of Princeton University. It was developed
from 1985 under the direction of George A. Miller.
It groups nouns, verbs, adjective and adverbs into
synonyms (synsets), most of which are linked to
other synsets through a number of semantic rela-
tions. (Miller, 1998; Fellbaum, 1998). The version
we use in this study is 3.0.
A number of wordnets in various languages
have been built based on and linked to PWN. The
Open Multilingual Wordnet (OMW) project3 cur-
3
http://www.asta-net.jp/~kuribayashi/
multi/
rently provides 22 wordnets (Bond and Paik, 2012;
Bond and Foster, 2013). The Japanese and Indone-
sian wordnets in our project are from OMW pro-
vided by the creators (Isahara et al, 2008, Nurril
Hirfana et al, 2011).
The Chinese wordnet we use is a heavily re-
vised version of the one developed by Southeast
University (Xu et al, 2008). This was automat-
ically constructed from bilingual resources with
minimal hand-checking. It has limited coverage
and is somewhat noisy, we have been revising it
and use this revised version for our annotation.
3.2 Multilingual Corpus
The NTU-multilingual corpus (NTU-MC) is com-
piled at Nanyang Technological University. It
contains eight languages: English (eng), Man-
darin Chinese (cmn), Japanese (jpn), Indonesian
(ind), Korean, Arabic, Vietnamese and Thai (Tan
and Bond, 2012). We selected parallel data
for English, Chinese, Japanese, and Indonesian
from NTU-MC to annotate. The data are from
four genres, namely, short story (two Sherlock
Holmes? Adventures), essay (Raymond, 1999),
news (Kurohashi and Nagao, 2003) and tourism
(Singapore Tourist Board, 2012). The corpus sizes
are shown in Table 1. We show the number of
words and concepts (open class words tagged with
synsets) only for English, the other languages are
comparable in size.
4 Annotation Scheme for Multilingual
Corpora
The annotation task is divided into two phases:
monolingual sense annotation and multilingual
concept alignment.
4.1 Monolingual Sense Annotation
First, the Chinese, Japanese and Indonesian cor-
pora were automatically tokenized and tagged
with parts-of-speech. Secondly, concepts were
tagged with candidate synsets, with multiword ex-
pressions allowing a skip of up to 3 words. Any
match with a wordnet entry was considered a po-
tential concept.
These were then shown to annotators to either
select the appropriate synset, or point out a prob-
lem. The interface for doing sense annotation is
shown in Figure 1.
In Figure 1, the concepts to be annotated are
shown as red and underlined. When clicking on
151
Genre Text Sentences Words Concepts
Eng Cmn Jpn Ind Eng Eng
Story The Adventure of the Dancing Men 599 606 698 ? 11,200 5,300
The Adventure of the Speckled Band 599 612 702 ? 10,600 4,700
Essay The Cathedral and the Bazaar 769 750 773 ? 18,700 8,800
News Mainichi News 2,138 2,138 2,138 ? 55,000 23,200
Tourism Your Singapore (web site) 2,988 2,332 2,723 2,197 74,300 32,600
Table 1: Multilingual corpus size
Figure 1: Tagging the sense of cane.
a concept, its WordNet senses appear to the right
of a screen. The annotator chooses between these
senses or a number of meta-tags: e, s, m, p, u.
Their meaning is explained below.
e error in tokenization
??? should be??
three-toed should be three - toed
s missing sense (not in wordnet)
I program in python ?the computer language?
COMMENT: add link to existing synset
<06898352-n ?programming language?
m bad multiword
(i) if the lemma is a multiword, this tag means
it is not appropriate
(ii) if the lemma is single-word, this tag
means it should be part of a multiword
p POS that should not be tagged (article,
modal, preposition, . . . )
u lemma not in wordnet but POS open class
(tagged automatically)
COMMENT: add or link to existing synset
Missing senses in the wordnets were a major
issue when tagging, especially for Chinese and
Japanese. We allowed the annotators to add candi-
date new senses in the comments; but these were
not made immediately available in the tagging in-
terface. As almost a third of the senses were miss-
ing in Chinese and Japanese, this slowed the anno-
tators down considerably.
Our guidelines for adding new concepts or link-
ing words to existing cover four cases:
= When a word is a synonym of an exist-
ing word, add =synset to the comment:
e.g. for laidback, it is a synonym of
02408011-a ?laid-back, mellow?, so we add
=02408011-a to the comment for laidback.
< When a word is a hyponym/instance of
152
an existing word, mark it with <synset:
For example, python is a hyponym of
06898352-n programming language, so we
add <06898352-n to python
! Mark antonyms with !synset.
? If you cannot come up with a more specific
relationship, just say the word is related in
some way to an existing synset with ?synset;
and add more detail in the comment.
Finally, we have added more options for the
annotators: prn (pronouns) and seven kinds of
named entities: org (organization); loc (location);
per (person); dat (date/time); num (number); oth
(other) and the super type nam (name). These ba-
sically follow Landes et al (1998, p207), with the
addition of number, date/time and name. Name is
used when automatically tagging, it should be spe-
cialized later, but is useful to have when aligning.
Pronouns include both personal and indefinite-
pronouns. Pronouns are not linked to their mono-
lingual antecedents, just made available for cross-
lingual linking.
4.2 Multilingual Concept Alignment
We looked at bitexts: the translated text and its
source (in this case English). Sentences were
already aligned as part of the NTU-Multilingual
Corpus. The initial alignment was done automat-
ically: concepts that are tagged with the same
synset or related synsets (one level of hyponymy)
are directly linked. Then the sentence pairs are
presented to the annotator, using the interface
shown in Figure 2.
In the alignment interface, when you hover over
a concept, its definition from PWN is shown in a
pop-up window at the top. Clicking concepts in
one language and then the other produces a can-
didate alignment: the annotator then choses the
kind of alignment. After concepts are aligned they
are shown in the same color. Both bell and ?
? m?nl?ng ?door bell? have the same synset, so
they are linked with =. Similarly, Watson and ?
? Hu?she?ng ?Watson? refer to the same person,
so they are also connected with =. However, ring
in the English sentence is a noun while the corre-
sponding Chinese word? xia?ng ?ring? is a verb;
so they are linked with the weaker type ?.
We found three issues came up a lot during the
annotation: (i) Monolingual tag errors; (ii) mul-
tiword expression not tagged; (iii) Pronouns not
tagged.
(i) In some cases, the monolingual tag was
not the best choice. Looking at the tagging in
both languages often made it easier to choose be-
tween similar monolingual tags, and the annota-
tors found themselves wanting to retag a number
of entries.
(ii) It was especially common for it to become
clear that things should have been tagged as mul-
tiword expressions. Consider kuchi-wo hiraku
?speak? in (1).
(1) Said he suddenly
a. ????
ho-muzu
Holmes
?
ga
NOM
??
totsuzen
suddenly
?
kuchi
mouth
?
wo
ACC
??
hiraku
open
?Holmes opens his mouth suddenly?
This was originally tagged as ?open mouth? but
in fact it is a multiword expression with the mean-
ing ?say?, and is parallel in meaning to the original
English text. As this concept is lexicalized, the an-
notator grouped the words together and tagged the
new concept to the synset 00941990-v ?express in
speech?. The concepts were then linked together
with ?. It is hard for the monolingual annotator
to consistently notice such multiword expressions:
however, the translation makes them more salient.
(iii) It was often the case that an open class
word in one language would link to a closed class
word in the other, especially to a pronoun. We
see this in (1) where he in English links to ho-
muzu ?Holmes? in Japanese. In order to capture
these correspondences, we allowed the annotator
to also tag named entities, pronouns and interrog-
atives. From now on we will tag these as part of
the initial monolingual alignment.
We tagged the links between concepts with the
types shown in Table 2.
5 Pilot Study Results
A pilot study was conducted using the first story
text: The Adventure of the Dancing Men, a Sher-
lock Holmes short story (Conan Doyle, 1905).
The Japanese version was translated by Otokichi
Mikami and Yu Okubu;4 we got the translated ver-
sion of Chinese from a website which later disap-
peared. Using English text as the source language,
the Japanese and Chinese texts were aligned and
4
http://www.aozora.gr.jp/ards/000009/
ard50713.html
153
Figure 2: Interface for aligning concepts.
manually sense-tagged with reference to their re-
spective wordnets. The number of words and con-
cepts for each language is shown in Table 3.
English Chinese Japanese
Sentences 599 680 698
Words 11,198 11,325 13,483
Concepts 5,267 4,558 4,561
Excluding candidate concepts rejected by the annotators.
Table 3: Concepts in Dancing Men
The relationships between words were tagged
using the symbols in in Table 2. The difficult cases
are similar relation and translation equivalent rela-
tion. Due to translation styles and language diver-
gence, some concepts with related meaning can-
not be directly linked. We give examples in (2)
through (4).
(2) ?How on earth do you know that?? I asked.
a. ?
?
?
????
ittai
on+earth
?
?
,
????
doushite
why
??
sono
that
??=?
koto=wo
thing=ACC
?
?
?
?
?
?
?
to
QUOT
?=?
watashi=wa
me=TOP
??=??
kiki=kaesu
ask=return
?Why on earth do you know that thing?? I ask
in return.
In (2), compared to ask in English, the Japanese
kikikaesu has the additional meaning of ?in re-
turn?: it is a hyponym. We marked their relation
as ? (similar in meaning).
We introduced a new class ? to indicate com-
binations of words or phrases that are translation
equivalents of the original source but are not lex-
icalized enough to be linked in the wordnet. One
example is shown in (3).
(3) be content with my word
154
Type Example
= same concept say ??? iu ?say?
? hypernym wash ?????? araiotosu ?wash out?
?2 2nd level dog ??? doubutsu ?animal?
? hyponym sunlight ?? hikari ?light?
?n nth level
? similar notebook ???? memochou ?notepad?
dulla ???? kusumu ?darken?
? equivalent be content with my word ?
??????????-? ?believe in my words?
! antonym hot ???=?? samu=ku nai ?not cold?
# weak ant. not propose to invest ?
?????? omoi=todomaru ?hold back?
Table 2: Translation Equivalence Types
a. ????=?
watakushi=no
me=of
??=?
kotoba=wo
word=ACC
??=?
shinji=te
believe=ing
?believe in my words?
In this case shinjite ?believe? is being used to
convey the same pragmatic meaning as content
with but they are not close enough in meaning that
we want to link them in the lexicon.
(4) shows some further issues in non-direct
translation.
(4) I am sure that I shall sayh noithing j of the kindk .
a. ????
iyaiya
by+no+means
?
,
,
???
sonnak
that+kindk+of
??
koto j
thing j
?
wa
TOP
??-?
iwah-ni
sayh-NEGi
?
yo
yo
?no no, I will not say that kind of thing?
Sayh noithing j of the kindk becomes roughly
?noti sayh that kindk of thing j?. All the elements
are there, but they are combined in quite a different
structure and some semantic decomposition would
be needed to link them. Chinese and Japanese do
not use negation inside the NP, so this kind of dif-
ference is common. Tagging was made more com-
plicated by the fact that determiners are not part of
wordnet, so it is not clear which parts of the ex-
pression should be tagged.
Though there are many difficult cases, the most
common case was for two concepts to share the
same synset and be directly connected. For
example, notebook is tagged with the synset
06415419-n, defined as ?a book with blank pages
for recording notes or memoranda?. In the
Japanese version, this concept is translated into?
?? bibouroku ?notebook?, with exactly the same
synset (06415419-n). Hence, we linked the words
with the = symbol.
The number of link types after the first round
of cross-lingual annotation (eng-jpn, eng-cmn) is
summarized in Table 4. In the English-Japanese
and English-Chinese corpora, 51.38% and 60.07%
of the concepts have the same synsets: that is,
slightly over half of the concepts can be directly
translated. Around 5% of the concepts in the two
corpora are linked to words close in the hierar-
chy (hyponym/hypernym). There were very few
antonyms (0.5%). Similar relations plus transla-
tion equivalents account for 42.85% and 34.74%
in the two corpora respectively. These parts are
the most challenging for machine translation.
In this first round, when the annotator attempted
to link concepts, it was sometimes the case that
the translation equivalent was a word not excluded
from wordnet by design. Especially common was
cases of common nouns in Japanese and Chinese
being linked to pronouns in English. In studying
how concepts differ across languages, we consider
these of interest. We therefore expanded our tag-
ging effort to include pronouns.
6 Discussion and Future Work
The pilot study showed clearly that cross-lingual
annotation was beneficial not just in finding inter-
esting correspondences across languages but also
in improving the monolingual annotation. In par-
ticular, we found many instances of multiword ex-
pressions that had been missed in the monolingual
annotation. Using a wordnet to sense tag a corpus
is extremely effective in improving the quality of
the wordnet, and tagging and linking parallel text
155
Type Eng-Jpn Eng-Cmn
linked 2,542 2,535
= 1,416 51.58 1,712 60.07
? 990 36.07 862 30.25
? 186 6.78 128 4.49
? 75 2.73 94 3.30
?2 8 0.81 13 1.51
? 63 2.30 39 1.37
?2 10 1.01 18 2.09
! 1 0.04 2 0.07
# 14 0.51 13 0.46
unlinked 2,583 1,898
Table 4: Analysis of links
is an excellent way to improve the quality of the
monolingual annotation. Given how many prob-
lems we found in both wordnet and corpus when
we went over the bilingual annotation, we hypoth-
esize that perhaps one of the reasons WSD is cur-
rently so difficult is that the gold standards are not
yet fully mature. They have definitely not yet gone
through the series of revisions that many syntactic
corpora have, even though the tagging scheme is
far harder.
For this project, we improved our annotation
process in two major ways:
(i) We expanded the scope of the annotation
to include pronouns and named entities interrog-
atives. These will now be tagged from the mono-
lingual annotation stage.
(ii) We improved the tool to make it possible to
add new entries directly to the wordnets, so that
they are available for tagging the remaining text.
Using the comments to add new sense was a bad
idea: synset-ids were cut and pasted, often with a
character missing, and annotators often mistyped
the link type. In addition, for words that appeared
many times, it was tedious to redo it for each word.
We are now testing an improved interface where
annotators add new words to the wordnet directly,
and these then become available for tagging. As a
quality check, the new entries are reviewed by an
expert at the end of each day, who has the option
of amending the entry (and possibly re-tagging).
We are currently tagging the remaining texts
shown in Table 1, with a preliminary release
scheduled for September 2013. For this we are
also investigating ways of improving the auto-
matic cross-lingual annotation: using word level
alignments; using global translation models and
by relaxing the mapping criteria (in particular
allowing linking across parts of speech through
derivational links). When we have finished, we
will also link the Japanese to the Chinese, using
English as a pivot. Finally, we will go through the
non-aligned concepts, and analyze why they can-
not be aligned.
In future work we intend to also add struc-
tural semantic annotation to cover issues such as
quantification. Currently we are experimenting
with Dependency Minimal Recursion Semantics
(DMRS: Copestake et al, 2005; Copestake, 2009)
and looking at ways to also constrain these cross-
linguistically (Frermann and Bond, 2012).
An interesting further extension would be to
look at a level of discourse marking. This would
be motivated by those translations which cannot
be linked at a lower level. In this way we would
become closer to the Groningen Meaning Bank,
which annotates POS, senses, NE, thematic roles,
syntax, semantics and discourse (Basile et al,
2012).
7 Conclusions
This paper presents preliminary results from an
ongoing project to construct large-scale sense-
tagged parallel corpora. Four languages are cho-
sen for the corpora: English, Chinese, Japanese,
and Indonesia. The annotation scheme is divided
into two phrases: monolingual sense annotation
and multilingual concept alignment. A pilot study
was carried out in Chinese, English and Japanese
for the short story The Adventure of the Danc-
ing Men. The results show that in the English-
Japanese and English-Chinese corpora, over half
of the concepts have the same synsets and thus
can be easily translated. However, 42.85% and
34.74% of the concepts in the two corpora can-
not be directly linked, which suggests it is hard for
machine translation. All annotated corpora will be
made freely available through the NTU-MC, in ad-
dition, the changes made to the wordnets will be
released through the individual wordnet projects.
Acknowledgments
This research was supported in part by the MOE
Tier 1 grant Shifted in Translation ? An Empirical
Study of Meaning Change across Languages.
156
References
Valerio Basile, Johan Bos, Kilian Evang, and
Noortje Venhuizen. 2012. Developing a large
semantically annotated corpus. In Proceedings
of the Eighth International Conference on Lan-
guage Resources and Evaluation (LREC 2012),
pages 3196?3200. Istanbul, Turkey.
Luisa Bentivogli, Pamela Forner, and Emanuele
Pianta. 2004. Evaluating cross-language an-
notation transfer in the MultiSemCor corpus.
In 20th International Conference on Computa-
tional Linguistics: COLING-2004, pages 364?
370. Geneva.
Francis Bond, Timothy Baldwin, Richard
Fothergill, and Kiyotaka Uchimoto. 2012.
Japanese SemCor: A sense-tagged corpus of
Japanese. In Proceedings of the 6th Global
WordNet Conference (GWC 2012), pages
56?63. Matsue.
Francis Bond and Ryan Foster. 2013. Linking and
extending an open multilingual wordnet. In 51st
Annual Meeting of the Association for Compu-
tational Linguistics: ACL-2013. Sofia.
Francis Bond, Sanae Fujita, and Takaaki Tanaka.
2006. The Hinoki syntactic and semantic
treebank of Japanese. Language Resources and
Evaluation, 40(3?4):253?261. URL http://
dx.doi.org/10.1007/s10579-007-9036-6,
(Special issue on Asian language technology;
re-issued as DOI s10579-008-9062-z due to
Springer losing the Japanese text).
Francis Bond, Sanae Fujita, and Takaaki Tanaka.
2008. The Hinoki syntactic and semantic
treebank of Japanese. Language Resources and
Evaluation, 42(2):243?251. URL http://
dx.doi.org/10.1007/s10579-008-9062-z,
(Re-issue of DOI 10.1007/s10579-007-9036-6
as Springer lost the Japanese text).
Francis Bond and Kyonghee Paik. 2012. A survey
of wordnets and their licenses. In Proceedings
of the 6th Global WordNet Conference (GWC
2012). Matsue. 64?71.
Arthur Conan Doyle. 1905. The Return of Sher-
lock Homes. George Newnes, London. Project
Gutenberg www.gutenberg.org/files/108/
108-h/108-h.htm.
Ann Copestake. 2009. Slacker semantics: Why
superficiality, dependency and avoidance of
commitment can be the right way to go. In
Proceedings of the 12th Conference of the Eu-
ropean Chapter of the ACL (EACL 2009), pages
1?9. Athens.
Ann Copestake, Dan Flickinger, Carl Pollard, and
Ivan A. Sag. 2005. Minimal Recursion Seman-
tics. An introduction. Research on Language
and Computation, 3(4):281?332.
Oliver ?Culo, Silvia Hansen-Schirra, Stella Neu-
mann, and Mihaela Vela. 2008. Empirical
studies on language contrast using the English-
German comparable and parallel CroCo corpus.
In Proceedings of Building and Using Com-
parable Corpora, LREC 2008 Workshop, Mar-
rakesh, Morocco, volume 31, pages 47?51.
Lea Cyrus. 2006. Building a resource for studying
translation shifts. In Proceedings of The Sec-
ond International Conference on Language Re-
sources and Evaluation (LREC-2006).
Christine Fellbaum, editor. 1998. WordNet: An
Electronic Lexical Database. MIT Press.
Lea Frermann and Francis Bond. 2012. Cross-
lingual parse disambiguation based on seman-
tic correspondence. In 50th Annual Meeting of
the Association for Computational Linguistics:
ACL-2012, pages 125?129. Jeju, Korea.
Hitoshi Isahara, Francis Bond, Kiyotaka Uchi-
moto, Masao Utiyama, and Kyoko Kanzaki.
2008. Development of the Japanese WordNet.
In Sixth International conference on Language
Resources and Evaluation (LREC 2008). Mar-
rakech.
Kaname Kasahara, Hiroshi Sato, Francis Bond,
Takaaki Tanaka, Sanae Fujita, Tomoko Kana-
sugi, and Shigeaki Amano. 2004. Construc-
tion of a Japanese semantic lexicon: Lexeed.
In IPSG SIG: 2004-NLC-159, pages 75?82.
Tokyo. (in Japanese).
Philipp Koehn. 2005. Europarl: A parallel corpus
for statistical machine translation. In MT Sum-
mit X.
Sadao Kurohashi and Makoto Nagao. 2003. Build-
ing a Japanese parsed corpus ? while improv-
ing the parsing system. In Anne Abeill?, edi-
tor, Treebanks: Building and Using Parsed Cor-
pora, chapter 14, pages 249?260. Kluwer Aca-
demic Publishers.
Shari Landes, Claudia Leacock, and Christiane
Fellbaum. 1998. Building semantic concor-
157
dances. In Fellbaum (1998), chapter 8, pages
199?216.
Mingqin Li, Juanzi Li, Zhendong Dong, Zuoy-
ing Wang, and Dajin Lu. 2003. Building a
large Chinese corpus annotated with seman-
tic dependency. In Proceedings of the sec-
ond SIGHAN workshop on Chinese language
processing-Volume 17, pages 84?91. Associa-
tion for Computational Linguistics.
George Miller. 1998. Foreword. In Fellbaum
(1998), pages xv?xxii.
Nurril Hirfana Mohamed Noor, Suerya Sapuan,
and Francis Bond. 2011. Creating the open
Wordnet Bahasa. In Proceedings of the 25th Pa-
cific Asia Conference on Language, Information
and Computation (PACLIC 25), pages 258?267.
Singapore.
Hwee Tou Ng and Hian Beng Lee. 1996. Inte-
grating multiple knowledge sources to disam-
biguate word sense: An exemplar-based ap-
proach. In Proceedings of the 34th annual meet-
ing on Association for Computational Linguis-
tics, pages 40?47.
Lars Nygaard and J?rg Tiedemann. 2003. OPUS
? an open source parallel corpus. In Proceed-
ings of the 13th Nordic Conference on Compu-
tational Linguistics.
Sebastian Pad? and Katrin Erk. 2010.
Translation shifts and frame-semantic
mismatches: A corpus analysis. Ms:
http://www.nlpado.de/~sebastian/
pub/papers/ijl10_pado_preprint.pdf.
Eric S. Raymond. 1999. The Cathedral & the
Bazaar. O?Reilly.
Singapore Tourist Board. 2012. Your Singapore.
Online: www.yoursingapore.om. [Accessed
2012].
Liling Tan and Francis Bond. 2012. Building and
annotating the linguistically diverse NTU-MC
(NTU-multilingual corpus). International Jour-
nal of Asian Language Processing, 22(4):161?
174.
J?rg Tiedemann. 2009. News from OPUS ?
a collection of multilingual parallel corpora
with tools and interfaces. In N. Nicolov,
K. Bontcheva, G. Angelova, and R. Mitkov,
editors, Recent Advances in Natural Language
Processing, volume 5, pages 237?248. John
Benjamins, Amsterdam/Philadelphia.
J?rg Tiedemann. 2012. Parallel data, tools and
interfaces in OPUS. In Proceedings of the
Eight International Conference on Language
Resources and Evaluation (LREC?12), pages
2214?2218.
J?rg Tiedemann and Lars Nygaard. 2004. The
OPUS corpus ? parallel and free. In In Pro-
ceeding of the 4th International Conference on
Language Resources and Evaluation (LREC-4).
Martin Volk, Anne G?hring, Torsten Marek, and
Yvonne Samuelsson. 2010. SMULTRON (ver-
sion 3.0) ? The Stockholm MULtilingual par-
allel TReebank. http://www.l.uzh.h/
researh/paralleltreebanks_en.html.
Gan Kok Wee and Tham Wai Mun. 1999. General
knowledge annotation based on how-net. Com-
putational Linguistics and Chinese Language
Processing, 4(2):39?86.
Yunfang Wu, Peng Jin, Yangsen Zhang, and Shi-
wen Yu. 2006. A chinese corpus with word
sense annotation. In Computer Processing of
Oriental Languages. Beyond the Orient: The
Research Challenges Ahead, pages 414?421.
Springer.
Renjie Xu, Zhiqiang Gao, Yuzhong Qu, and
Zhisheng Huang. 2008. An integrated approach
for automatic construction of bilingual Chinese-
English WordNet. In 3rd Asian Semantic Web
Conference (ASWC 2008), pages 302?341.
158
