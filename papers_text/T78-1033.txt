A Heur ist ic  
for Paradigms 
Joseph E. Gr imes 
Cornel l  Un ivers i ty  and 
Summer Inst i tute of L inguist ics  
This paper helps c lar i fy  one of the 
pervas ive problems of l inguist ic  analysis:  
the interact ion between the paradigmat ic  
and syntagmat ic  d imens ions  of language. 
Paradigms are sets of a l ternat ives:  the 
speaker must dec ide on one member of the 
set to use, and the hearer must f igure out 
which he used. In a syntagm or 
construct ion,  an element chosen out of one 
paradigm is put together with e lements  
chosen out of others. Thus far all 
grammars  of all languages agree. 
The problem comes when we put the 
grammar together.  The choices avai lab le  
in one paradigm turn out often to be 
l imited by those made in some other 
paradigm that is part of the same 
construct ion.  Grammar is never as s imple 
as a Cartes ian product  of paradigms. 
Var ious forms of grammar have var ious 
means, none of them quite sat is fy ing,  to 
express these l imitat ions.  A common one is 
footnotes about i r regular i t ies;  ad hoc 
features to tr igger or block special  rules 
when needed are also used. 
Grammar ought to h ighl ight  the mutual  
constra ints  between paradigms and 
construct ions ,  not downplay  them. 
Hal l iday's  systemic grammar has done well 
in this regard (Hal l iday 1961, Hudson 
1971) . It is a l ready known to 
computat ional  l inguists  through Winograd 's  
work (1972). The heur ist ic ,  based on work 
by Lowe, Dooley, and mysel f  (in press),  is 
expressed within Hall iday' s f ramework 
here, though it is appl icab le  within any 
other model of language as well. 
In systemic terms a paradigm is known 
as a 'system'. A choice in one system can 
be the entry condi t ion for another system, 
one part of a system can have d i f ferent  
propert ies  of combinat ion  from another 
part, and two or more systems can be 
act ivated together as the basis  for a 
construct ion.  The heur ist ic  is intended to 
c lar i fy  something that is more often 
guessed at than proved: what e lement 
be longs to what system. 
What I find, on looking at languages 
other than English, is that membersh ip  in 
a Hal l idayan system is by no means obvious 
in all cases. This is true for two 
reasons: f irst, some elements have 
propert ies  that permit us to ass ign them 
to more than one system, and second, some 
elements are art i facts  of the mapping 
relat ion between systems and forms, rather 
than d i rect  man i fes ta t ions  of choices 
within systems. 
The Data  
Table (i) gives some data which 
i l lustrate this general  point by means of 
a l imited example. It reports 
cooccur rences  among a par t icu lar ly  complex 
subset of the pref ixes to the verb in 
Huichol,  a Uto-Aztecan language spoken in 
the Mexican Sierra Madre. A 1 in the table 
means that the prefix at the head of the 
column has been observed in the 
combinat ion  that the row reports.  For this 
language there are exact ly  15 observable  
combinat ions  of these pref ixes,  each 
represented by one row in Table (i). The 
order in which the rows are wr i t ten down 
makes no d i f ference,  nor does the order in 
which the co lumns appear,  kal-  and ka2- 
are homophonous forms that occupy 
d i f ferent  pos i t ions  in the prefix str ing 
and have d i f ferent  meanings.  ~ stands for 
a h igh back unrounded vowel.  
(i) kalke p& m& ka2ni 
i 0 1 0 1 0 
1 0 1 0 0 0 
1 0 0 0 1 1 
1 0 0 0 0 1 
0 1 0 0 0 1 
0 1 0 0 0 0 
0 0 1 0 1 0 
0 0 1 0 0 0 
0 0 0 1 1 1 
0 0 0 1 1 0 
0 0 0 1 0 1 
0 0 0 1 0 0 
0 0 0 0 1 0 
0 0 0 0 0 1 
0 0 0 0 0 0 
The simple fact that two forms cannot  
cooccur with each other is the most 
obvious basis for saying that those two 
232 
are members  of a s ingle system, that they 
are in oppos i t ion  as a l ternat ives  in a 
paradigm, that the choice of one as over 
against the other has l inguist ic  
s igni f icance.  In Table (I), for example, 
p&- does not occur in any combinat ion  
where ni- occurs, and vice versa. 
Noncooccurrence patterns 
The patterns of noncooccurrence are 
der ived from Table (i) by a s imple 
algorithm: 
For each column: 
Create a vector of as many 0's as 
there are columns 
For each row that has a 1 in the 
column in question: 
Unite that row with the 
vector. 
Complement the vector. 
Each of the uncomplemented vectors  
represents the union of all the 
combinat ions  which the form at the head of 
its co lumn enters into. The l's in its 
complement  therefore identi fy the elements 
with which it cannot cooccur.  
The Huichol data -- and this is true 
of other languages, poss ib ly  of all 
languages -- do not a l low us to draw 
immediate conc lus ions  about mutual  
exc lus iveness or s imple comembersh ip  in 
systems. The pref ixes represented by the 
complement vectors of each form are 
(2) kal: ke, m& 
ke: kal, p&, m&, ka2 
p&: ke, m&, ni 
m&: kal, ke, p& 
ka2: ke 
ni: p& 
A form like p&- can be assigned to 
one system in oppos i t ion with ni-, and to 
another in oppos i t ion with ke- and m&-; 
but kali-, which could also g--o into--a 
system with __ke and m_&&-, cooccurs  with p&- 
and therefore cannot represent an 
a l ternat ive to it. The logic of systems 
in grammar is more complex than 
independent commutat ion,  with the 
Cartes ian products that that implies, in 
which each form of one set cooccurs with 
every form of another.  
Decompos i t ion  
The true interdependency of a 
systemic network can be captured in a 
cooccurrence graph by f irst decomposing 
Table (I). The most manageable  
decompos i t ion  strategy found so far is to 
start with the column that min imizes  the 
number of l's that would be removed from 
the table if all the rows that have l's in 
that column were removed. We convert  those 
rows into a component  subgraph, then 
cont inue recurs ive ly  on the table minus 
those rows until no rows are left, or 
unti l  the zero row is left; then we also 
convert  the zero row if there is one into 
a component  subgraph. In the final step of 
the heur ist ic ,  the component  subgraphs are  
united to g ive the complete cooccurrence 
graph. That graph of forms is the aim of 
the heurist ic .  It is not a systemic 
network d iagram itself, but is rather a 
statement of a major  constra int  on the 
semantic systemic d iagram that accounts 
for the forms. 
Component  subgraphs are formed by 
putt ing a l ternat ives ver t ica l ly  in any 
order within square brackets,  and 
connect ing forms that cooccur in any order 
by hor izontal  l ines. Absence of any form 
in a part icular  combinat ion  is represented 
by ---. 
In Table (i) the two rows that 
contain l's for ke- have a total of only 
three l's in them; so those two rows are 
taken out for the first subgraph: 
(3) ke 
This subgraph, like the two rows of Table 
(i) that it represents,  says that ke- can 
occur with or without ni-. 
The full 
der ived from Table 
s imple a l te rnat ives  
products:  
set of component  subgraphs 
(i) contains only 
and their Cartes ian 
Eni (4) (a) ke , - - -  
Ek~ ~ Re2 
E ka2 (c) kal ni 
(d) m& ka2 E::_\] 
(e) ka2 
(f) m& .. E::_7 
(g) ni 
(h) 
Union of component  subgraphs 
We unite these subg raphs by 
conf lat ing what they have in common and 
symbol iz ing their d i f ferences  as 
a l ternat ives,  by the d is t r ibut ive  
property.  Four of the subgraphs, (a), (f), 
(g) , and (h) , can be combined without 
changing the picture of s imple systems and 
233 
Cartesian products: 
n i  
(5) ke ___ 
A restriction on Cartesian products 
appears, however, when we expand the 
composite diagram further. (d) has three 
out of four of its elements in common with 
elements already in the composite diagram 
(5) . The fourth element, however, has 
nothing to do with ke- or its absence, but 
only with m&-. Here is where the 
discrepancies in noncooccurrence 
properties of different forms come into 
the picture, and here is where the 
Hallidayan device of linked brackets is 
needed in order to show up those 
discrepancies. The elements in (6) are 
reordered to disrupt the graphic shape 
given by (5) as little as possible: 
I ka2  I~__m& ~ ~n i  
(6) ke 
Cooccurrence graph 
The complete cooccurrence graph is 
built up by continuing in the same way 
until all the component subgraphs are in 
it: 
2 ~ P&- 1 
The use of two null symbols in a 
single set of alternatives does not mean 
that Huichol has two zero prefixes that 
contrast with each other, but rather that 
the graph is essential ly nonplanar. 
Redundant nulls could be eliminated by 
crossing lines in an equivalent graph. 
This diagram now shows all the 
constraints on cooccurrence that there are 
for these Huichol prefixes. It is not yet 
a systemic diagram, because systemic 
diagrams give differences in meaning and 
this one gives only cooccurrences of 
forms. The systemic diagram we come up 
with will, however, have to account for 
each of the constraints on cooccurrence 
given by this diagram. 
Our scrutiny of cooccurrences and 
noncooccurrences has shown us what forms 
might be in opposition with each other in 
a semantic system, and how those forms 
interlock. That is as far as our explicit 
heuristic take us; but it narrows the 
field for semantic investigation 
considerably. 
Computational aspects 
Before I go on to show the payoff in 
terms of systems of meaningful choices, 
let me sketch the computational aspects of 
the heuristic. For a small problem like 
the one in the example, of course, no 
computing is needed. But were we to take 
in all 42 verb prefixes of Huichol, and 
state how they combine with suffixes and 
different stem types as well, the 
heuristic would never get off the ground 
with pencil and paper. It is a good 
example of how a computationally simple 
process, actually a twist on concordance 
generation, can bring order into an area 
where a linguist is otherwise all too 
likely to shrug his shoulders and define 
oversimplif ied systems, then write 
interminable footnotes about why they 
don't quite combine as he says they do. 
A linguist in the field needs a 
three-step computational aid. Step One is 
data entry: take in occurring combinations 
of forms, which could as well be function 
words or suffixes or any combination of 
closed class phenomena, and develop a 
table like Table (i). Step Two is union: 
read the table and develop a vector for 
each form that shows the union of all its 
combinations. Step Three is decomposition: 
segregate out from the table the subsets 
of its rows that facilitate making its 
component subgraphs. 
These three steps are easy to 
implement. The fourth step of the 
heuristic, forming the cooccurrence graph 
by uniting the component subgraphs, is at 
least an order of magnitude more complex, 
and may not be feasible for a small field 
computer. 
Systemic diagram 
After the heuristic procedure is gone 
through, whether with pencil or by 
computer, the construction of a semantic 
hypothesis rich enough to account for all 
the patterns of cooccurrence can go ahead. 
This is a standard linguistic undertaking, 
and has two sides. The first is to 
investigate the reasons why one or another 
member of a noncooccurring set like the 
ones in (2) gets chosen. The reasons for 
choosing either member of a pair may not 
be the same in the context of one pattern 
of choices made in other systems as it is 
in other contexts. The second part of the 
semantic inquiry is to identify or 
combinations of forms whose presence is an 
artifact of the mapping between meaning 
and form, and not an assertion o f  a 
part icu lar  meaning. 
This arbitrariness in the mapping 
relation shows up in two places in the 
example. When p&- is present, k__aal- has 
either a tentative or a very strong 
negative meaning: kaalp&m{e means 'he 
might not go' or 'he shall not go!' (the 
234 
meaning split is not too d i f ferent  from 
that of English terr ib ly in terr ib ly 
disf igured vs. terr ib ly nice). With ni-, 
however, __kal- has to be there when k_~a2-, 
the ordinary negative, is present, and may 
or may not be there when ka2- is absent. 
The requirement that kal- always go with 
ka2- in the presence of ni- e l iminates 
the possib i l i ty  of the two homophones ever 
being opposed to one another, with 
result ing confusion between negat ive and 
tentat ivn between negat ive and tentat ive 
meanings.  
The other arb i t rar iness turns up on 
trying to relate m&- with ni-. m&- by 
itself is the sign of a dependent verb, 
and ni- by itself of an independent verb 
at a partice combinat ion m&ni, however,  
has nothing to do with either of these 
meanings; it makes a statement of the 
speaker's opinion. I take it to be a 
morpholog ica l ly  complex expression of a 
separate term of the modal system. 
Taking these d iscrepancies  into 
account gives us a systemic diagram: 
(8) Ftentat ive-  
~assert ive|  kal 
p& \[_definite 
negative-- narrat ive --- 
ka2 ni 
evaluat ive !. dependent 
. m& 
positiv conjunct \[~ 
imperativ ni 
ke eneral 
\[narrative\] implies kal 
obl igatory with \[ne-gative\] 
optional with \[positive\] 
\[evaluative\] realized as m&+ni 
It is by stra ightening out kal- and 
m&ni- that it becomes possible fo-{-- us to 
give a systemic diagram plus a set of 
real izat ion rules for it. The 
straightforward real izat ion rules are 
written right into the diagram: for 
example, if you choose \[negative\] , utter 
ka2-. The more complex real izat ions are 
given at the bottom of the diagram. 
The terms of the sys temic  diagram are 
labels for semantic choices that have been 
explained elsewhere and do not concern us 
now; they do not const i tute explanat ions 
in themselves. Once the arbitrary mappings 
are def ined in real izat ion rules, the 
diagram embodies only one real restr ict ion 
on Cartesian products of paradigms, in 
that Huichol has no special negative 
imperative form. (It uses the negat ive 
declarat ive p&ka2 in its place.) The 
completeness o--f---the analysis is supported 
by the fact that the fnterconnected 
paradigms of (8) have exact ly 14 paths 
through them, and that together with the 
optional  rule for the real izat ion of kal- 
with ni-, these yield exact ly the 15 --lows 
of Table (i) with which we began. 
Bibl iog raphy 
Grimes, Joseph E., Ivan Lowe, and Robert 
A. Dooley. in press. Closed systems 
with complex restr ict ions. 
Anthropological  Linguist ics.  
Hal l iday, Michael A. K. 1961. Categor ies 
of the theory of grammar. Word 
17:241-292. 
Hudson, R. A. 1971. Engl ish complex 
sentences. Amsterdam: North-Hol land 
Publ ishing Company. 
Winograd, Terry. 1972. Understanding 
natural language. New York: Academic 
Press. 
235 
