Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics:shortpapers, pages 401?406,
Portland, Oregon, June 19-24, 2011. c?2011 Association for Computational Linguistics
Terminal-Aware Synchronous Binarization
Licheng Fang, Tagyoung Chung and Daniel Gildea
Department of Computer Science
University of Rochester
Rochester, NY 14627
Abstract
We present an SCFG binarization algorithm
that combines the strengths of early termi-
nal matching on the source language side and
early language model integration on the tar-
get language side. We also examine how dif-
ferent strategies of target-side terminal attach-
ment during binarization can significantly af-
fect translation quality.
1 Introduction
Synchronous context-free grammars (SCFG) are be-
hind most syntax-based machine translation mod-
els. Efficient machine translation decoding with an
SCFG requires converting the grammar into a bina-
rized form, either explicitly, as in synchronous bina-
rization (Zhang et al, 2006), where virtual nontermi-
nals are generated for binarization, or implicitly, as
in Earley parsing (Earley, 1970), where dotted items
are used.
Given a source-side binarized SCFG with termi-
nal set T and nonterminal set N , the time complex-
ity of decoding a sentence of length n with a m-gram
language model is (Venugopal et al, 2007):
O(n3(|N | ? |T |2(m?1))K)
where K is the maximum number of right-hand-side
nonterminals. SCFG binarization serves two impor-
tant goals:
? Parsing complexity for unbinarized SCFG
grows exponentially with the number of non-
terminals on the right-hand side of grammar
rules. Binarization ensures cubic time decod-
ing in terms of input sentence length.
? In machine translation, integrating language
model states as early as possible is essential to
reducing search errors. Synchronous binariza-
tion (Zhang et al, 2006) enables the decoder to
incorporate language model scores as soon as a
binarized rule is applied.
In this paper, we examine a CYK-like syn-
chronous binarization algorithm that integrates a
novel criterion in a unified semiring parsing frame-
work. The criterion we present has explicit consider-
ation of source-side terminals. In general, terminals
in a rule have a lower probability of being matched
given a sentence, and therefore have the effect of
?anchoring? a rule and limiting its possible applica-
tion points. Hopkins and Langmead (2010) formal-
ized this concept as the scope of a rule. A rule of
scope of k can be parsed in O(nk). The scope of a
rule can be calculated by counting the number of ad-
jacent nonterminal pairs and boundary nonterminals.
For example,
A? w1BCw2D
has scope two. Building on the concept of scope,
we define a cost function that estimates the expected
number of hyperedges to be built when a particular
binarization tree is applied to unseen data. This ef-
fectively puts hard-to-match derivations at the bot-
tom of the binarization tree, which enables the de-
coder to decide early on whether an unbinarized rule
can be built or not.
We also investigate a better way to handle target-
side terminals during binarization. In theory, differ-
ent strategies should produce equivalent translation
results. However, because decoding always involves
401
 0
 2000
 4000
 6000
 8000
 10000
 12000
 14000
 16000
 18000
1 2 3 4 5 6 7
N
um
be
r o
f r
ul
es
Number of right-hand-side nonterminals
Total
Binarizable
Monotonic
Figure 1: Rule Statistics
pruning, we show that different strategies do have a
significant effect in translation quality.
Other works investigating alternative binarization
methods mostly focus on the effect of nonterminal
sharing. Xiao et al (2009) also proposed a CYK-
like algorithm for synchronous binarization. Appar-
ently the lack of virtual nonterminal sharing in their
decoder caused heavy competition between virtual
nonterminals, and they created a cost function to
?diversify? binarization trees, which is equivalent to
minimizing nonterminal sharing.
DeNero et al (2009b) used a greedy method to
maximize virtual nonterminal sharing on the source
side during the -LM parsing phase. They show that
effective source-side binarization can improve the ef-
ficiency of parsing SCFG. However, their method
works only on the source side, and synchronous bina-
rization is put off to the +LM decoding phase (DeN-
ero et al, 2009a).
Although these ideas all lead to faster decoding
and reduced search errors, there can be conflicts in
the constraints each of them has on the form of rules
and accommodating all of them can be a challenge.
In this paper, we present a cubic time algorithm to
find the best binarization tree, given the conflicting
constraints.
2 The Binarization Algorithm
An SCFG rule is synchronously binarizable if when
simultaneously binarizing source and target sides,
virtual nonterminals created by binarizations always
have contiguous spans on both sides (Huang, 2007).
Algorithm 1 The CYK binarization algorithm.
CYK-BINARIZE(X ? ??, ??)
for i = 0 . . . |?| ? 1 do
T [i, i + 1]? cinit(i)
for s = 2 . . . |?| do
for i = 0 . . . |?|-1 do
j ? i + s
for k = i + 1 . . . j ? 1 do
t? T [i, k] + T [k, j] + c(?i, k, j?)
T [i, j]? min(T [i, j], t)
Even with the synchronous binarization constraint,
many possible binarizations exist. Analysis of our
Chinese-English parallel corpus has shown that the
majority of synchronously binarizable rules with ar-
ity smaller than 4 are monotonic, i.e., the target-side
nonterminal permutation is either strictly increasing
or decreasing (See Figure 1). For monotonic rules,
any source-side binarization is also a permissible
synchronous binarization.
The binarization problem can be formulated as a
semiring parsing (Goodman, 1999) problem. We
define a cost function that considers different bina-
rization criteria. A CYK-like algorithm can be used
to find the best binarization tree according to the
cost function. Consider an SCFG rule X ? ??, ??,
where ? and ? stand for the source side and the tar-
get side. Let B(?) be the set of all possible bina-
rization trees for ?. With the cost function c defined
over hyperedges in a binarization tree t, the optimal
binarization tree t? is
t? = argmin
t?B(?)
?
h?t
c(h)
where c(h) is the cost of a hyperedge h in t.
The optimization problem can be solved by Al-
gorithm 1. ?i, k, j? denotes a hyperedge h that con-
nects the spans (i, k) and (k, j) to the span (i, j).
cinit is the initialization for the cost function c. We
can recover the optimal source-side binarization tree
by augmenting the algorithm with back pointers.
Binarized rules are generated by iterating over the
nodes in the optimal binarization tree, while attach-
ing unaligned target-side terminals. At each tree
node, we generate a virtual nonterminal symbol by
concatenating the source span it dominates.
We define the cost function c(h) to be a
tuple of component cost functions: c(h) =
402
(c1(h), c2(h), ...). When two costs a and b are com-
pared, the components are compared piecewise, i.e.
c < c? ? c1 < c?1 ? (c1 = c?1 ? c2 < c?2) ? . . .
If the (min,+) operators on each component cost
satisfy the semiring properties, the cost tuple is also
a semiring. Next, we describe our cost functions and
how we handle target-side terminals.
2.1 Synchronous Binarization as a Cost
We use a binary cost b to indicate whether a binariza-
tion tree is a permissible synchronous binarization.
Given a hyperedge ?i, k, j?, we say k is a permissible
split of the span (i, j) if and only if the spans (i, k)
and (k, j) are both synchronously binarizable and
the span (i, j) covers a consecutive sequence of non-
terminals on the target side. A span is synchronously
binarizable if and only if the span is of length one,
or a permissible split of the span exists. The cost b
is defined as:
b(?i, k, j?) =
{
T if k is a permissible split of (i, j)
F otherwise
binit(i) = T
Under this configuration, the semiring operators
(min,+) defined for the cost b are (?,?). Using b as
the first cost function in the cost function tuple guar-
antees that we will find a tree that is a synchronously
binarized if one exists.
2.2 Early Source-Side Terminal Matching
When a rule is being applied while parsing a sen-
tence, terminals in the rule have less chance of be-
ing matched. We can exploit this fact by taking ter-
minals into account during binarization and placing
terminals lower in the binarization tree. Consider the
following SCFG rule:
VP ? PP?? JJ NN,propose a JJ NN PP
The synchronous binarization algorithm of Zhang et
al. (2006) binarizes the rule1 by finding the right-
most binarizable points on the source side:
1We follow Wu (1997) and use square brackets for straight
rules and pointed brackets for inverted rules. We also mark
brackets with indices to represent virtual nonterminals.
VP ? PP [?? [JJ NN]1]2,[[propose a JJ NN]1]2 PP
The source side of the first binarized rule ?[]1 ? JJ
NN, propose a JJ NN? contains a very frequent non-
terminal sequence ?JJ NN?. If one were to parse
with the binarized rule, and if the virtual nontermi-
nal []1 has been built, the parser needs to continue
following the binarization tree in order to determine
whether the original rule would be matched. Further-
more, having two consecutive nonterminals adds to
complexity since the parser needs to test each split
point.
The following binarization is equally valid but in-
tegrates terminals early:
VP ? PP [[?? JJ]1 NN]2,[[propose a JJ]1 NN]2 PP
Here, the first binarized rule ?[]1 ? ?? JJ, pro-
pose a JJ? anchors on a terminal and enables earlier
pruning of the original rule.
We formulate this intuition by asking the ques-
tion: given a source-side string ?, what binarization
tree, on average, builds the smallest number of hy-
peredges when the rule is applied? This is realized
by defining a cost function e which estimates the
probability of a hyperedge ?i, k, j? being built. We
use a simple model: assume each terminal or non-
terminal in ? is matched independently with a fixed
probability, then a hyperedge ?i, k, j? is derived if
and only if all symbols in the source span (i, j) are
matched. The cost e is thus defined as2
e(?i, k, j?) =
?
i?`<j
p(?`)
einit(i) = 0
For terminals, p(?`) can be estimated by counting
the source side of the training corpus. For nontermi-
nals, we simply assume p(?`) = 1.
With the hyperedge cost e, the cost of a binariza-
tion tree t is
?
h?t e(h), i.e., the expected number of
hyperedges to be built when a particular binarization
of a rule is applied to unseen data.3 The operators
2In this definition, k does not appear on the right-hand side
of the equation because all edges leading to the same span share
the same cost value.
3Although this cost function is defined as an expectation, it
does not form an expectation semiring (Eisner, 2001) because
403
for the cost e are the usual (min,+) operators on
real numbers.
2.3 Maximizing Nonterminal Sharing
During binarization, newly created virtual nontermi-
nals are named according to the symbols (terminals
and nonterminals) that they generate. For example, a
new virtual nonterminal covering two nonterminals
NP and VP is named NP+VP. To achieve maximum
virtual nonterminal sharing, we also define a cost
function n to count the number new nonterminals
generated by a binarization tree. We keep track of
all the nonterminals that have been generated when
binarizing a rule set. When the i?th rule is being
binarized, a nonterminal is considered new if it is
previously unseen in binarizing rules 1 to i?1. This
greedy approach is similar to that of DeNero et al
(2009b). The cost function is thus defined as:
n(?i, k, j?) =
{
1 if the VT for span (i, j) is new
0 otherwise
ninit(i) = 0
The semiring operators for this cost are also
(min,+) on real numbers.
2.4 Late Target-Side Terminal Attachment
Once the optimal source-side binarization tree is
found, we have a good deal of freedom to attach
target-side terminals to adjacent nonterminals, as
long as the bracketing of nonterminals is not vio-
lated. The following example is taken from Zhang
et al (2006):
ADJP ? RB?? PP? NN,RB responsible for the NN PP
With the source-side binarization fixed, we can pro-
duce distinct binarized rules by choosing different
ways of attaching target-side terminals:
ADJP ? [RB??]1 ? [PP?]3 NN ?2,[RB]1 ? resp. for the NN [PP]3 ?2
ADJP ? [RB??]1 ? [PP?]3 NN ?2,[RB]1 resp. for the ? NN [PP]3 ?2
The first binarization is generated by attaching the
target-side terminals as low as possible in a post-
it is defined as an expectation over input strings, instead of an
expectation over trees.
order traversal of the binarization tree. The conven-
tional wisdom is that early consideration of target-
side terminals promotes early language model score
integration (Huang et al, 2009). The second bina-
rization, on the contrary, attaches the target-side ter-
minals as high as possible in the binarization tree.
We argue that this late target-side terminal attach-
ment is in fact better for two reasons.
First, as in the example above, compare the fol-
lowing two rules resulting from early attachment of
target terminals and late attachment of target termi-
nals:
??2 ? []3 NN, resp. for the NN []3
??2 ? []3 NN, NN []3
The former has a much smaller chance of sharing
the same target side with other binarized rules be-
cause on the target side, many nonterminals will be
attached without any lexical evidence. We are more
likely to have a smaller set of rules with the latter
binarization.
Second, with the presence of pruning, dynamic
programming states that are generated by rules with
many target-side terminals are disadvantaged when
competing with others in the same bin because of
the language model score. As a result, these would
be discarded earlier, even if the original unbinarized
rule has a high probability. Consequently, we lose
the benefit of using larger rules, which have more
contextual information. We show in our experiment
that late target side terminal attachment significantly
outperforms early target side terminal attachment.
Although the problem can be alleviated by pre-
computing a language model score for the original
unbinarized rule and applying the heuristic to its bi-
narized rules, this still grants no benefit over late ter-
minal attachment. We show in our experiment that
late target-side terminal attachment significantly out-
performs early target side terminal attachment.
3 Experiments
3.1 Setup
We test our binarization algorithm on an Chinese-
English translation task. We extract a GHKM gram-
mar (Galley et al, 2004) from a parallel corpus with
the parsed English side with some modification so
404
-395
-390
-385
-380
-375
-370
-365
-360
-355
 10  100
M
od
el
 S
co
re
 (lo
g-p
rob
ab
ilit
y)
Seconds / Sentence (log scale)
(b,n)-early
(b,n)-late
(b,e,n)-early
(b,e,n)-late
Figure 2: Model Scores vs. Decoding Time
 17.5
 18
 18.5
 19
 19.5
 20
 20.5
 10  100
BL
EU
Seconds / Sentence (log scale)
(b,n)-early
(b,n)-late
(b,e,n)-early
(b,e,n)-late
Figure 3: BLEU Scores vs Decoding Time
as not to extract unary rules (Chung et al, 2011).
The corpus consists of 250K sentence pairs, which
is 6.3M words on the English side. A 392-sentence
test set was to evaluate different binarizations.
Decoding is performed by a general CYK SCFG
decoder developed in-house and a trigram language
model is used. The decoder runs the CYK algorithm
with cube-pruning (Chiang, 2007). In all our exper-
iments, we discard unbinarizable rules, which have
been shown by Zhang et al (2006) to have no signif-
icant effect on translation accuracy.
3.2 Results
We first discuss effects of maximizing nonterminal
sharing. Having nonterminal sharing maximization
as a part of the cost function for binarization did
yield slightly smaller grammars. However, we could
not discern any noticeable difference or trend in
terms of BLEU score, decoding speed, or model
score when comparing translation results that used
grammars that employed nonterminal sharing max-
imization and ones that did not. In the rest of this
section, all the results we discuss use nonterminal
sharing maximization as a part of the cost function.
We then compare the effects of early target-side
terminal attachment and late attachment. Figure 2
shows model scores of each decoder run with vary-
ing bin sizes, and Figure 3 shows BLEU scores
for corresponding runs of the experiments. (b,n)-
early is conventional synchronous binarization with
early target-side terminal attachment and nontermi-
nal sharing maximization, (b,n)-late is the same set-
ting with late target-side terminal attachment. The
tuples represent cost functions that are discussed in
Section 2. The figures clearly show that late attach-
ment of target-side terminals is better. Although
Figure 3 does not show perfect correlation with Fig-
ure 2, it exhibits the same trend. The same goes for
(b,e,n)-early and (b,e,n)-late.
Finally, we examine the effect of including the
source-side terminal-aware cost function, denoted
?e? in our cost tuples. Comparing (b,e,n)-late with
(b,n)-late, we see that terminal-aware binarization
gives better model scores and BLEU scores. The
trend is the same when one compares (b,e,n)-early
and (b,n)-early.
4 Conclusion
We examined binarizing synchronous context-free
grammars within a semiring parsing framework. We
proposed binarization methods that explicitly take
terminals into consideration. We have found that al-
though binarized rules are already scope 3, we can
still do better by putting infrequent derivations as
low as possible in a binarization tree to promote
early pruning. We have also found that attaching
target side terminals as late as possible promotes
smarter pruning of rules thereby improving model
score and translation quality at decoding time. Im-
provements we discuss in this paper result in better
search, and hence better translation.
Acknowledgments We thank Hao Zhang for use-
ful discussions and the anonymous reviewers for
their helpful comments. This work was supported
by NSF grants IIS-0546554 and IIS-0910611.
405
References
David Chiang. 2007. Hierarchical phrase-based transla-
tion. Computational Linguistics, 33(2):201?228.
Tagyoung Chung, Licheng Fang, and Daniel Gildea.
2011. Issues concerning decoding with synchronous
context-free grammar. In Proceedings of the ACL
2011 Conference Short Papers, Portland, Oregon, June.
Association for Computational Linguistics.
J. DeNero, A. Pauls, and D. Klein. 2009a. Asynchronous
binarization for synchronous grammars. In Proceed-
ings of the ACL-IJCNLP 2009 Conference Short Pa-
pers, pages 141?144. Association for Computational
Linguistics.
John DeNero, Mohit Bansal, Adam Pauls, and Dan Klein.
2009b. Efficient parsing for transducer grammars. In
Proceedings of Human Language Technologies: The
2009 Annual Conference of the North American Chap-
ter of the Association for Computational Linguistics,
pages 227?235, Boulder, Colorado, June. Association
for Computational Linguistics.
Jay Earley. 1970. An efficient context-free parsing algo-
rithm. Communications of the ACM, 6(8):451?455.
J. Eisner. 2001. Expectation semirings: Flexible EM
for learning finite-state transducers. In Proceedings of
the ESSLLI workshop on finite-state methods in NLP.
Citeseer.
Michel Galley, Mark Hopkins, Kevin Knight, and Daniel
Marcu. 2004. What?s in a translation rule? In Pro-
ceedings of the 2004 Meeting of the North American
chapter of the Association for Computational Linguis-
tics (NAACL-04), pages 273?280.
Joshua Goodman. 1999. Semiring parsing. Computa-
tional Linguistics, 25(4):573?605.
Mark Hopkins and Greg Langmead. 2010. SCFG decod-
ing without binarization. In Proceedings of the 2010
Conference on Empirical Methods in Natural Lan-
guage Processing, pages 646?655, Cambridge, MA,
October. Association for Computational Linguistics.
Liang Huang, Hao Zhang, Daniel Gildea, and Kevin
Knight. 2009. Binarization of synchronous
context-free grammars. Computational Linguistics,
35(4):559?595.
Liang Huang. 2007. Binarization, synchronous bina-
rization, and target-side binarization. In Proceedings
of the NAACL/AMTA Workshop on Syntax and Struc-
ture in Statistical Translation (SSST), pages 33?40,
Rochester, NY.
Ashish Venugopal, Andreas Zollmann, and Stephan Vo-
gel. 2007. An efficient two-pass approach to
synchronous-CFG driven statistical MT. In NAACL07,
Rochester, NY, April.
Dekai Wu. 1997. Stochastic inversion transduction gram-
mars and bilingual parsing of parallel corpora. Compu-
tational Linguistics, 23(3):377?403.
T. Xiao, M. Li, D. Zhang, J. Zhu, and M. Zhou. 2009.
Better synchronous binarization for machine transla-
tion. In Proceedings of the 2009 Conference on Em-
pirical Methods in Natural Language Processing: Vol-
ume 1-Volume 1, pages 362?370. Association for Com-
putational Linguistics.
Hao Zhang, Liang Huang, Daniel Gildea, and Kevin
Knight. 2006. Synchronous binarization for machine
translation. In Proceedings of the 2006 Meeting of the
North American chapter of the Association for Compu-
tational Linguistics (NAACL-06), pages 256?263, New
York, NY.
406
