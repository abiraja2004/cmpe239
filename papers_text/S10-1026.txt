Proceedings of the 5th International Workshop on Semantic Evaluation, ACL 2010, pages 129?133,
Uppsala, Sweden, 15-16 July 2010.
c?2010 Association for Computational Linguistics
COLEUR and COLSLM: A WSD approach to Multilingual Lexical
Substitution, Tasks 2 and 3 SemEval 2010
Weiwei Guo and Mona Diab
Center for Computational Learning Systems
Columbia University
{weiwei,mdiab}@ccls.columbia.edu
Abstract
In this paper, we present a word sense
disambiguation (WSD) based system for
multilingual lexical substitution. Our
method depends on having a WSD system
for English and an automatic word align-
ment method. Crucially the approach re-
lies on having parallel corpora. For Task
2 (Sinha et al, 2009) we apply a super-
vised WSD system to derive the English
word senses. For Task 3 (Lefever & Hoste,
2009), we apply an unsupervised approach
to the training and test data. Both of our
systems that participated in Task 2 achieve
a decent ranking among the participating
systems. For Task 3 we achieve the highest
ranking on several of the language pairs:
French, German and Italian.
1 Introduction
In this paper, we present our system that was ap-
plied to the cross lingual substitution for two tasks
in SEMEVAL 2010, Tasks 2 and 3. We adopt
the same approach for both tasks with some dif-
ferences in the basic set-up. Our basic approach
relies on applying a word sense disambiguation
(WSD) system to the English data that comes from
a parallel corpus for English and a language of
relevance to the task, language 2 (l2). Then we
automatically induce the English word sense cor-
respondences to l2. Accordingly, for a given test
target word, we return its equivalent l2 words as-
suming that we are able to disambiguate the target
word in context.
2 Our Detailed Approach
We approach the problem of multilingual lexical
substitution from a WSD perspective. We adopt
the hypothesis that the different word senses of
ambiguous words in one language probably trans-
late to different lexical items in another language.
Hence, our approach relies on two crucial compo-
nents: a WSD module for the source language (our
target test words, in our case these are the English
target test words) and an automatic word align-
ment module to discover the target word sense cor-
respondences with the foreign words in a second
language. Our approach to both tasks is unsuper-
vised since we don?t have real training data anno-
tated with the target words and their corresponding
translations into l2 at the onset of the problem.
Accordingly, at training time, we rely on auto-
matically tagging large amounts of English data
(target word instances) with their relevant senses
and finding their l2 correspondences based on au-
tomatically induced word alignments. Each of
these English sense and l2 correspondence pairs
has an associated translation probability value de-
pending on frequency of co-occurrence. This in-
formation is aggregated in a look-up table over
the entire training set. An entry in the table
would have a target word sense type paired with all
the observed translation correspondences l2 word
types. Each of the l2 word types has a probabil-
ity of translation that is calculated as a normal-
ized weighted average of all the instances of this
l2 word type with the English sense aggregated
across the whole parallel corpus. This process re-
sults in an English word sense translation table
(WSTT). The word senses are derived from Word-
Net (Fellbaum, 1998). We expand the English
word sense entry correspondences by adding the
translations of the members of target word sense
synonym set as listed in WordNet.
For alignment, we specifically use the GIZA++
software for inducing word alignments across the
parallel corpora (Och & Ney, 2003). We apply
GIZA++ to the parallel corpus in both directions
English to l2 and l2 to English then take only the
intersection of the two alignment sets, hence fo-
129
cusing more on precision of alignment rather than
recall.
For each language in Task 3 and Task 2, we
use TreeTagger
1
to do the preprocessing for all
languages. The preprocessing includes segmenta-
tion, POS tagging and lemmatization. Since Tree-
Tagger is independent of languages, our system
does not rely on anything that is language spe-
cific; our system can be easily applied to other
languages. We run GIZA++ on the parallel cor-
pus, and obtain the intersection of the alignments
in both directions. Meanwhile, every time a target
English word appears in a sentence, we apply our
WSD system on it, using the sentence as context.
From this information, we build a WSST from
the English sense(s) to their corresponding foreign
words. Moreover, we use WordNet as a means of
augmenting the translation correspondences. We
expand the word sense to its synset from WordNet
adding the l2 words that corresponded to all the
member senses in the synset yielding more trans-
lation variability.
At test time, given a test data target word, we
apply the same WSD system that is applied to the
training corpus to create the WSTT. Once the tar-
get word instance is disambiguated in context, we
look up the corresponding entry in the WSTT and
return the ranked list of l2 correspondences. We
present results for best and for oot which vary only
in the cut off threshold. In the BEST condition we
return the highest ranked candidate, in the oot con-
dition we return the top 10 (where available).
2
Given the above mentioned pipeline, Tasks 2
and 3 are very similar. Their main difference lies
in the underlying WSD system applied.
3 Task 2
3.1 System Details
We use a relatively simple monolingual supervised
WSD system to create the sense tags on the En-
glish data. We use the SemCor word sense anno-
tated corpus. SemCor is a subset of the Brown
Corpus. For each of our target English words
found disambiguated in the SemCor corpus, we
create a sense profile for each of its senses. A
sense profile is a vector of all the content words
that occur in the context of this sense in the Sem-
Cor corpus. The dimensions of the vector are word
1
http://www.ims.uni-stuttgart.de/projekte/corplex/TreeTagger/
2
Some of the target word senses had less than 10 l2 word
correspondences.
Corpus best oot
P R P R
T2-COLSLM 27.59 25.99 46.61 43.91
T2-COLEUR 19.47 18.15 44.77 41.72
Table 1: Precision and Recall results per corpus on
Task 2 test set
types, as in a bag of words model, and the vec-
tor entries are the co-occurrence frequency of the
word sense and the word type. At test time, given
a a target English word, we create a bag of word
types contextual vector for each instance of the
word using the surrounding context. We compare
the created test vector to the SemCor vectors and
choose the highest most similar sense and use that
for sense disambiguation. In case of ties, we return
more than one sense tag.
3.2 Data
We use both naturally occurring parallel data and
machine translation data. The data for our first
Task 2 submission, T2-COLEUR, comprises nat-
urally occurring parallel data, namely, the Span-
ish English portion of the EuroParl data provided
by Task 3 organizers. For the machine transla-
tion data, we use translations of the source En-
glish data pertaining to the following corpora:
the Brown corpus, WSJ, SensEval1, SensEval2
datasets as translated by two machine translation
systems: Global Link (GL), Systran (SYS) (Guo
& Diab, 2010). We refer to the translated corpus
as the SALAAM corpus. The intuition for creating
SALAAM (an artificial parallel corpus) is to create
a balanced translation corpus that is less domain
and genre skewed than the EuroParl data. This lat-
ter corpus results in our 2nd system for this task
T2-COLSLM.
3.3 Results
Table 1 presents our overall results as evaluated by
the organizers.
It is clear that the T2-COLSLM outperforms
T2-COLEUR.
4 Task 3
4.1 System Details
Contrary to Task 2, we apply a context based un-
supervised WSD module to the English side of the
parallel data. Our unsupervised WSD method, as
described in (Guo & Diab, 2009), is a graph based
130
unsupervised WSD method. Given a sequence of
words W = {w
1
, w
2
...w
n
}, each word w
i
with
several senses {s
i1
, s
i2
...s
im
}. A graph G = (V,E)
is defined such that there exists a vertex v for each
sense. Two senses of two different words may be
connected by an edge e, depending on their dis-
tance. That two senses are connected suggests
they should have influence on each other, accord-
ingly a maximum allowable distance is set. They
explore 4 different graph based algorithms.We fo-
cus on the In-Degree graph based algorithm.
The In-Degree algorithm presents the problem
as a weighted graph with senses as nodes and sim-
ilarity between senses as weights on edges. The
In-Degree of a vertex refers to the number of
edges incident on that vertex. In the weighted
graph, the In-Degree for each vertex is calcu-
lated by summing the weights on the edges that are
incident on it. After all the In-Degree values
for each sense are computed, the sense with max-
imum value is chosen as the final sense for that
word. In our implementation of the In-Degree
algorithm, we use the JCN similarity measure for
both Noun-Noun and Verb-Verb similarity calcu-
lation.
4.2 Data
We use the training data from EuroParl provided
by the task organizers for the 5 different language
pairs. We participate in all the language competi-
tions. We refer to our system as T3-COLEUR.
4.3 Results
Table 2 shows our system results on Task 3, spec-
ified by languages.
4.4 Error Analysis and Discussion
As shown in Table 2, our system T3-COLEUR
ranks the highest for the French, German and Ital-
ian language tasks on both best and oot. However
the overall F-measures are very low. Our system
ranks last for Dutch among 3 systems and it is
middle of the pack for the Spanish language task.
In general we note that the results for oot are nat-
urally higher than for BEST since by design it is a
more relaxed measure.
5 Related works
Our work mainly investigates the influence of
WSD on providing machine translation candi-
dates. Carpuat & Wu (2007) and Chan et al(2007)
show WSD improves MT. However, in (Carpuat
& Wu, 2007) classical WSD is missing by ignor-
ing predefined senses. They treat translation can-
didates as sense labels, then find linguistic fea-
tures in the English side, and cast the disambigua-
tion process as a classification problem. Of rele-
vance also to our work is that related to the task
of English monolingual lexical substitution. For
example some of the approaches that participated
in the SemEval 2007 excercise include the follow-
ing. Yuret (2007) used a statistical language model
based on a large corpus to assign likelihoods to
each candidate substitutes for a target word in a
sentence. Martinez et al (2007) uses WordNet to
find candidate substitutes, produce word sequence
including substitutes. They rank the substitutes by
ranking the word sequence including that substi-
tutes using web queries. In (Giuliano C. et al,
2007), they extract synonyms from dictionaries.
They have 2 ways of ranking of the synonyms:
by similarity metric based on LSA and by occur-
rence in a large 5-gram web corpus. Dahl et al
(2007) also extract synonyms from dictionaries.
They present two systems. The first one scores
substitutes based on how frequently the local con-
text match the target word. The second one in-
corporates cosine similarity. Finally, Hassan et al
(2007) extract candidates from several linguistic
resources, and combine many techniques and ev-
idences to compute the scores such as machine
translation, most common sense, language model
and so on to pick the most suitable lexical substi-
tution candidates.
6 Conclusions and Future Directions
In this paper we presented a word sense disam-
biguation based system for multilingual lexical
substitution. The approach relies on having a
WSD system for English and an automatic word
alignment method. Crucially the approach relies
on having parallel corpora. For Task 2 we apply
a supervised WSD system to derive the English
word senses. For Task 3, we apply an unsuper-
vised approach to the training and test data. Both
of our systems that participated in Task 2 achieve
a decent ranking among the participating systems.
For Task 3 we achieve the highest ranking on sev-
eral of the language pairs: French, German and
Italian.
In the future, we would like to investigate the
usage of the Spanish and Italian WordNets for the
131
Language best oot
P R rank P R rank
Dutch 10.71 10.56 3/3 21.47 21.27 3/3
Spanish 19.78 19.59 3/7 35.84 35.46 5/7
French 21.96 21.73 1/7 49.44 48.96 1/5
German 13.79 13.63 1/3 33.21 32.82 1/3
Italian 15.55 15.4 1/3 40.7 40.34 1/3
Table 2: Results of T3-COLEUR per language on Task 3 Test set
task. We would like to also expand our exami-
nation to other sources of bilingual data such as
comparable corpora. Finally, we would like to in-
vestigate using unsupervised clustering of senses
(Word Sense Induction) methods in lieu of the
WSD approaches that rely on WordNet.
References
CARPUAT M. & WU D. (2007). Improving statis-
tical machine translation using word sense disam-
biguation. In Proceedings of the 2007 Joint Con-
ference on Empirical Methods in Natural Language
Processing and Computational Natural Language
Learning (EMNLP-CoNLL), p. 61?72, Prague,
Czech Republic: Association for Computational
Linguistics.
CHAN Y. S., NG H. T. & CHIANG D. (2007). Word
sense disambiguation improves statistical machine
translation. In Proceedings of the 45th Annual Meet-
ing of the Association of Computational Linguistics,
p. 33?40, Prague, Czech Republic: Association for
Computational Linguistics.
DAHL G., FRASSICA A. & WICENTOWSKI R. (2007).
SW-AG: Local Context Matching for English Lexi-
cal Substitution. In Proceedings of the 4th workshop
on Semantic Evaluations (SemEval-2007), Prague,
Czech Republic.
FELLBAUM C. (1998). ?wordnet: An electronic lexical
database?. MIT Press.
GIULIANO C., GLIOZZO A. & STRAPPARAVA C
(2007). FBK-irst: Lexical Substitution Task Ex-
ploiting Domain and Syntagmatic Coherence. In
Proceedings of the 4th workshop on Semantic Eval-
uations (SemEval-2007), Prague, Czech Republic.
GUO W. & DIAB M. (2009). ?Improvements to mono-
lingual English word sense disambiguation?. In
ACL Workshop on Semantics Evaluations.
GUO W. & DIAB M. (2010). ?Combining orthogonal
monolingual and multilingual sources of evidence
for All Words WSD?. In ACL 2010.
HASSAN S., CSOMAI A., BANEA C., SINHA R. &
MIHALCEA R. (2007). UNT: SubFinder: Combin-
ing Knowledge Sources for Automatic Lexical Sub-
stitution. In Proceedings of the 4th workshop on Se-
mantic Evaluations (SemEval-2007), Prague, Czech
Republic.
IDE N. & V RONIS J. (1998). Word sense disambigua-
tion: The state of the art. In Computational Linguis-
tics, p. 1?40.
JIANG J. & CONRATH. D. (1997). Semantic similar-
ity based on corpus statistics and lexical taxonomy.
In Proceedings of the International Conference on
Research in Computational Linguistics, Taiwan.
LEACOCK C. & CHODOROW M. (1998). Combining
local context and wordnet sense similarity for word
sense identification. In WordNet, An Electronic Lex-
ical Database: The MIT Press.
LEFEVER C. & HOSTE V. (2009). SemEval-2010
Task 3: Cross-lingual Word Sense Disambiguation.
In Proceedings of the NAACL HLT Workshop on Se-
mantic Evaluations: Recent Achievements and Fu-
ture Directions, Boulder, Colorado.
LESK M. (1986). Automatic sense disambiguation us-
ing machine readable dictionaries: How to tell a pine
cone from an ice cream cone. In In Proceedings of
the SIGDOC Conference, Toronto.
MARTINEZ D., KIM S. & BALDWIN T. (2007).
MELB-MKB: Lexical Substitution system based
on Relatives in Context In Proceedings of the
4th workshop on Semantic Evaluations (SemEval-
2007), Prague, Czech Republic.
M. PALMER, C. FELLBAUM S. C. L. D. & DANG
H. (2001). English tasks: all-words and verb lex-
ical sample. In In Proceedings of ACL/SIGLEX
Senseval-2, Toulouse, France.
MIHALCEA R. (2005). Unsupervised large-vocabulary
word sense disambiguation with graph-based algo-
rithms for sequence data labeling. In Proceedings
of Human Language Technology Conference and
Conference on Empirical Methods in Natural Lan-
guage Processing, p. 411?418, Vancouver, British
Columbia, Canada: Association for Computational
Linguistics.
MILLER G. A. (1990). Wordnet: a lexical database for
english. In Communications of the ACM, p. 39?41.
132
NAVIGLI R. (2009). Word sense disambiguation: a
survey. In ACM Computing Surveys, p. 1?69: ACM
Press.
OCH F. J. & NEY H. (2003). A systematic compari-
son of various statistical alignment models. Compu-
tational Linguistics, 29(1), 19?51.
PEDERSEN B. & PATWARDHAN (2005). Maximizing
semantic relatedness to perform word sense disam-
biguation. In University of Minnesota Supercomput-
ing Institute Research Report UMSI 2005/25, Min-
nesotta.
PRADHAN S., LOPER E., DLIGACH D. & PALMER
M. (2007). Semeval-2007 task-17: English lexi-
cal sample, srl and all words. In Proceedings of the
Fourth International Workshop on Semantic Evalua-
tions (SemEval-2007), p. 87?92, Prague, Czech Re-
public: Association for Computational Linguistics.
SINHA R. & MIHALCEA R. (2007). Unsupervised
graph-based word sense disambiguation using mea-
sures of word semantic similarity. In Proceedings
of the IEEE International Conference on Semantic
Computing (ICSC 2007), Irvine, CA.
SINHA R., MCCARTHY D. & MIHALCEA R. (2009).
SemEval-2010 Task 2: Cross-Lingual Lexical Sub-
stitution. In Proceedings of the NAACL HLT Work-
shop on Semantic Evaluations: Recent Achieve-
ments and Future Directions, Irvine, CA.
SNYDER B. & PALMER M. (2004). The english all-
words task. In R. MIHALCEA & P. EDMONDS,
Eds., Senseval-3: Third International Workshop on
the Evaluation of Systems for the Semantic Analysis
of Text, p. 41?43, Barcelona, Spain: Association for
Computational Linguistics.
YURET D. (2007). KU: Word sense disambiguation
by substitution. In Proceedings of the 4th workshop
on Semantic Evaluations (SemEval-2007), Prague,
Czech Republic.
133
