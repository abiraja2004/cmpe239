Proceedings of the CoNLL Shared Task Session of EMNLP-CoNLL 2007, pp. 1139?1143,
Prague, June 2007. c?2007 Association for Computational Linguistics
Online learning for Deterministic Dependency Parsing
Prashanth Reddy Mannem
Language Technologies Research Center
IIIT-Hyderabad, India
prashanth@research.iiit.ac.in
Abstract
Deterministic parsing has emerged as an ef-
fective alternative for complex parsing algo-
rithms which search the entire search space
to get the best probable parse tree. In this pa-
per, we present an online large margin based
training framework for deterministic pars-
ing using Nivre?s Shift-Reduce parsing al-
gorithm. Online training facilitates the use
of high dimensional features without cre-
ating memory bottlenecks unlike the popu-
lar SVMs. We participated in the CoNLL
Shared Task-2007 and evaluated our system
for ten languages. We got an average multi-
lingual labeled attachment score of 74.54 %
(with 65.50% being the average and 80.32%
the highest) and an average multilingual un-
labeled attachment score of 80.30% (with
71.13% being the average and 86.55% the
highest).
1 Introduction
CoNLL-X had a shared task on multilingual depen-
dency parsing (Buchholz et al, 2006) by providing
treebanks for 13 languages in the same dependency
format. A look at the performance sheet in the con-
test shows that two systems with quite different ap-
proaches (one using deterministic parsing with SVM
and the other using MIRA with nondeterministic and
dynamic programming based MST approach ) per-
formed with good results (McDonald et al, 2006;
Nivre et al, 2006).
More recently, deterministic parsing has gener-
ated a lot of interest because of their simplicity
(Nivre, 2003). One of the main advantages of de-
terministic parsing lies in the ability to use the sub-
tree information in the features to decide the next
step. Parsing algorithms which search the entire
space (Eisner, 1996; McDonald, 2006) are restricted
in the features they use to score a relation. They rely
only on the context information and not the history
information to score a relation. Using history infor-
mation makes the search intractable. Whereas, since
deterministic parsers are at worst O(n2) (Yamada
and Matsumoto, 2003) (Nivre (2003) is only O(2n)
in the worst case), they can use the crucial history
information to make parsing decisions. So, in our
work Nivre?s parsing algorithm has been used to ar-
rive at the dependency parse tree.
Popular learning algorithms for deterministic
parsing like Support Vector Machines (SVM) run
into memory issues for large data since they are
batch learning algorithms. Though more informa-
tion is available in deterministic parsing in terms of
subtree information, high dimensional features can?t
be used due to the large training times for SVMs.
This is where online methods come into the picture.
Unlike batch algorithms, online algorithms con-
sider only one training instance at a time when
optimizing parameters. This restriction to single-
instance optimization might be seen as a weakness,
since the algorithm uses less information about the
objective function and constraints than batch algo-
rithms. However, McDonald (2006) argues that this
potential weakness is balanced by the simplicity of
online learning, which allows for more streamlined
training methods. This work focuses purely on on-
line learning for deterministic parsing.
1139
In the remaining part of the paper, we introduce
Nivre?s parsing algorithm, propose a framework for
online learning for deterministic parsing and present
the results for all the languages with various feature
models.
2 Parsing Algorithm
We used Nivre?s top-down/bottom-up linear time
parsing algorithm proposed in Nivre (2003). A
parser configuration is represented by triples
(S, I,E) where S is the stack (represented as a list),
I is the list of (remaining) tokens and E is the set of
edges for the dependency graph D. S is a list of par-
tially processed tokens, whose subtrees are incom-
plete i.e tokens whose parent or children have not
yet been established. top is the top of the stack S,
next is the next token in the list I .
Nivre?s algorithm consists of four elementary ac-
tions Shift, Left, Right and Reduce to build
the dependency tree from the initial configuration
(nil,W, ?), where W is the input sentence. Shift
pushes next onto the stack S. Reduce pops the
stack. Right adds an arc from top to next and
pushes next onto the stack S. Left adds an arc
from next to top and pops the stack. The parser ter-
minates when it reaches a configuration (S,nil,E)
( for any list S and set of edges E).
The labels for each relation are determined after
a new arc is formed (by left and right actions).
The parser always constructs a dependency graph
that is acyclic and projective. For non-projective
parsing, we followed the pseudo projective pars-
ing approach proposed by Nivre and Nilson (2005).
In this approach, the training data is projectivized
by a minimal transformation, lifting non-projective
arcs one step at a time, and extending the arc label
of the lifted arcs using the encoding scheme called
HEAD+PATH. The non-projective arcs can be re-
covered by applying an inverse transformation to the
output of the parser, using a left-to-right, top-down,
breadth-first search, guided by the extended arc la-
bels. This method has been used for all the lan-
guages.
3 Online Learning
McDonald (2005) applied online learning by scoring
edges in a connected graph and finding the Maxi-
mum Spanning Tree (MST) of the graph. McDonald
et al (2005) used Edge Based Factorization , where
the score of a dependency tree is factored as the sum
of scores of all edges in the tree. Let, x = x1 ? ? ? xn
represents a generic input sentence , and y represents
a generic dependency tree for sentence x. (i, j) ? y
denotes the presence of a dependency relation in y
from word xi (parent) to word xj (child).
In Nivre?s parsing algorithm the dependency
graph can be viewed as a graph resulting from a
set of parsing decisions (in this case Shift, Reduce
, Left & Right) made, starting with the initial con-
figuration (nil,W, ?) . We define this sequence of
parsing decisions as d = d1 ? ? ? dm. So, d is the se-
quence of parsing decisions made by the parser to
obtain a dependency tree y, from an input sentence
x. Lets also define c = c1 ? ? ? cm to be the config-
uration sequence starting from initial configuration
(nil,W, ?) to the final configuration (S,nil,E).
We define the score of a parsing decision for a par-
ticular configuration to be the dot product between a
high dimensional feature vector (based on both the
decision and the configuration) and a weight vector.
So,
s(di, ci) = w . f(di, ci)
where ci is the configuration at the ith instance
and di is any one of the four actions {Shift, Reduce,
Left, Right} .
The Margin Infused Relaxed Algorithm (MIRA)
proposed by Crammer et al (2003) attempts to keep
the norm of the change to the parameter vector as
small as possible, subject to correctly classifying the
instance under consideration with a margin at least
as large as the loss of the incorrect classifications.
McDonald et al (2005) defines the loss of a depen-
dency tree inferred by finding the Maximum Span-
ning Tree(MST), as the number of words that have
incorrect parent (i.e the no. of edges that have gone
wrong). This satisfies the global constraint that the
correct set of edges will have the highest weight.
However, in Nivre?s algorithm, as there is no one to
one correspondence between parsing decisions and
the graph edges, the number of errors in the edges
can?t be used as a loss function as it won?t reflect the
exact loss in the parsing decisions. In this method
of calculating the loss function based on edges, we
first get the series of decisions through inference on
1140
the training data, then concat their feature vectors
and finally run the normal updates with the edge
based loss (since the resulting decisions will produce
a parse tree). This method gave very poor results.
So we do a factored MIRA for Nivre?s algorithm
by factoring the output by decisions to obtain the
following constraints:
min?w(i+1) ? w(i)?
s.ts(di, ci) ? s(d
?
i, ci) ? 1
?ci ? dt(c) and
(di, d
?
i) ? (Shift, Left,Right,Reduce)
where di represents the correct decision and d
?
i
represents all the other decisions for the same con-
figuration ci. This states that the weight of the cor-
rect decision for a particular configuration and the
weight of all other decisions must be separated by a
margin of 1. For every sentence in the training data,
starting with the initial configuration (nil,W, ?),
weights are adjusted to satisfy the above constraints
before proceeding to the next correct configuration.
This process is repeated till we reach the final con-
figuration (S,nil,E).
4 Features
The two central elements in any configuration are
the token on the top of the stack (t) and the next input
token (n),the tokens which may be connected by a
dependency relation in the current configuration. We
categorize our features into basic, context, history
and in ? between feature sets. The basic feature
set contains information about these two tokens t
and n. This includes unigram, bigram combinations
of the word forms (FORM), root word (LEMMA),
features (FEATS) and the part-of-speech tags (both
CPOS and POS) of these words. The coarse POS tag
(CPOS) is useful and helps solve data sparseness to
some extent.
The existence or non-existence of a relation be-
tween two words is heavily dependent on the words
surrounding t and n which is the contextual infor-
mation. The context feature set has the information
about the surrounding words t?1, t+1, n?1, n+1,
n + 2, n + 3. Unigram and trigram combinations
(with t and n) of the lexical items, POS tags, CPOS
tags of these words are part of this context feature
set. We also included the second topmost element in
the stack (st? 1) word too.
The third feature set, which is the history feature
set contains the info about the subtree at a partic-
ular parser state. One of the advantages of using
deterministic parsing algorithm over nondeterminis-
tic algorithm is that history can be used as features.
History features have information about the Parent
(par), Left Sibling (ls) and Right Sibling (rs) of t.
Unigram and trigram combinations (with t and n) of
POS, CPOS, DEPREL tags of these words are in-
cluded in the History Features.
The features in the in ? between feature set
take the form of POS and CPOS trigrams: the
POS/CPOS of t, that of the word in between and
that of n.
All the features in these feature sets are conjoined
with distance between t & n and the parsing deci-
sion. We experimented with a combination of these
feature sets in our training. We define feature mod-
els ?1, ?2 and ?3 for our experiments. ?1 is a com-
bination on basic and context feature sets. ?2 is a
mixture of basic, context and in ? between fea-
ture sets whereas ?3 contains basic, context and
history feature sets. The feature models ?1?3 are
the same for all the languages.
5 Results and Discussion
The system with online learning and Nivre?s pars-
ing algorithm was trained on the data released by
CoNLL Shared Task Organizers for all the ten lan-
guages (Hajic? et al, 2004; Aduriz et al, 2003; Mart??
et al, 2007; Chen et al, 2003; Bo?hmova? et al, 2003;
Marcus et al, 1993; Johansson and Nugues, 2007;
Prokopidis et al, 2005; Csendes et al, 2005; Mon-
temagni et al, 2003; Oflazer et al, 2003). We evalu-
ated our system using the standard evaluation script
provided by the organizers (Nivre et al, 2007).
The evaluation metrics are Unlabeled Attachment
Score(UAS) and Labeled Attachment Score(LAS).
The results of our system with various feature
models are listed in Table 11. The history infor-
mation in ?3 contributed to a marginal improve-
ment in accuracy of Hungarian, Italian and Turkish.
Whereas, Arabic, Catalan, Czech, English, Greek
1Results aren?t available for the models with a ?-? mark.
1141
Language ?1 ?2 ?3
LAS UAS LAS UAS LAS UAS
Arabic 71.55 81.56 72.05 81.93 71.66 81.30
Basque 66.35 73.71 65.64 72.86 64.56 71.69
Catalan 84.45 89.65 84.47 89.81 - -
Chinese 74.06 79.09 73.76 78.84 72.93 77.52
Czech 70.49 77.05 70.68 77.20 - -
English 81.19 82.41 81.55 82.81 - -
Greek 71.52 78.77 71.69 78.89 71.46 78.48
Hungarian 70.42 75.01 70.94 75.39 71.05 75.54
Italian 78.30 82.54 78.67 82.91 79.18 83.38
Turkish 76.42 82.74 76.48 82.85 77.29 83.58
Table 1: Results of Online learning with Nivre?s parsing algorithm for feature models ?1, ?2, ?3
got their highest accuracies with feature model ?2
containing basic, context and in?between feature
sets. The rest of the languages, Basque and Chinese
achieved highest accuracies with ?1. But, a careful
look at the results table shows that there isn?t any
significant difference in the accuracies of the sys-
tem across different feature models. This is true for
all the languages. The feature models ?2 and ?3
did not show any significant difference in accuracies
even though they contain more information. Feature
model ?1 with basic and context feature sets has
achieved good accuracies.
5.1 K-Best Deterministic Parsing
The deterministic parsing algorithm does not han-
dle ambiguity. By choosing a single parser action at
each opportunity, the input string is parsed determin-
istically and a single dependency tree is built during
the parsing process from beginning to end (no other
trees are even considered). A simple extension to
this idea is to eliminate determinism by allowing the
parser to choose several actions at each opportunity,
creating different action sequences that lead to dif-
ferent parse trees. Since a score is assigned to every
parser action, the score of a parse tree can be com-
puted simply as the average of the scores of all ac-
tions that resulted in that parse tree (the derivation
of the tree). We performed a beam search by carry-
ing out a K-best search through the set of possible
sequences of actions as proposed by Johansson and
Nugues (2006). However, this did not increase the
accuracy. Moreover, with larger values of K, there
was a decrease in the parsing accuracy. The best-
first search proposed by Sagae and Lavie (2006) was
also tried out but there was similar drop in accuracy.
6 Conclusion
The evaluation shows that the labeled pseudo projec-
tive deterministic parsing with online learning gives
competitive parsing accuracy for most of the lan-
guages involved in the shared task. The level of ac-
curacy varies considerably between the languages.
Analyzing the results and the effects of various fea-
tures with online learning will be an important re-
search goal in the future.
References
A. Abeille?, editor. 2003. Treebanks: Building and Using
Parsed Corpora. Kluwer.
I. Aduriz, M. J. Aranzabe, J. M. Arriola, A. Atutxa,
A. Diaz de Ilarraza, A. Garmendia, and M. Oronoz.
2003. Construction of a Basque dependency treebank.
In Proc. of the 2nd Workshop on Treebanks and Lin-
guistic Theories (TLT), pages 201?204.
A. Bo?hmova?, J. Hajic?, E. Hajic?ova?, and B. Hladka?. 2003.
The PDT: a 3-level annotation scenario. In Abeille?
(Abeille?, 2003), chapter 7, pages 103?127.
S. Buchholz, E. Marsi, A. Dubey, and Y. Krymolowski.
2006. Conll-x shared task on multilingual dependency
parsing. In Proceedings of the Conference on Compu-
tational Natural Language Learning (CoNLL).
K. Chen, C. Luo, M. Chang, F. Chen, C. Chen, C. Huang,
and Z. Gao. 2003. Sinica treebank: Design criteria,
representational issues and implementation. In Abeille?
(Abeille?, 2003), chapter 13, pages 231?248.
1142
K. Crammer, O. Dekel, S. Shalev-Shwartz, and Y. Singer.
2003. Online passive aggressive algorithms. In Pro-
ceedings of Neural Information Processing Systems
(NIPS).
D. Csendes, J. Csirik, T. Gyimo?thy, and A. Kocsor. 2005.
The Szeged Treebank. Springer.
J. Eisner. 1996. Three new probabilistic models for de-
pendency parsing: An exploration. In Proceedings of
the 16th International Conference on Computational
Linguistics (COLING), pages 340?345.
J. Hajic?, O. Smrz?, P. Zema?nek, J. ?Snaidauf, and E. Bes?ka.
2004. Prague Arabic dependency treebank: Develop-
ment in data and tools. In Proc. of the NEMLAR In-
tern. Conf. on Arabic Language Resources and Tools,
pages 110?117.
R. Johansson and P. Nugues. 2006. Investigating
multilingual dependency parsing. In Proceedings of
the Tenth Conference on Computational Natural Lan-
guage Learning (CoNLL-X), pages 206?210.
R. Johansson and P. Nugues. 2007. Extended
constituent-to-dependency conversion for English. In
Proc. of the 16th Nordic Conference on Computational
Linguistics (NODALIDA).
M. Marcus, B. Santorini, and M. Marcinkiewicz. 1993.
Building a large annotated corpus of English: the Penn
Treebank. Computational Linguistics, 19(2):313?330.
M. A. Mart??, M. Taule?, L. Ma`rquez, and M. Bertran.
2007. CESS-ECE: A multilingual and multilevel
annotated corpus. Available for download from:
http://www.lsi.upc.edu/?mbertran/cess-ece/.
R. McDonald, K. Crammer, and F. Pereira. 2005. Online
large-margin training of dependency parsers. In Pro-
ceedings of the Annual Meeting of the Association for
Computational Linguistics (ACL).
R. McDonald, K. Lerman, and F. Pereira. 2006. Multi-
lingual dependency analysis with a two-stage discrim-
inative parser. In Proceedings of the Conference on
Computational Natural Language Learning (CoNLL).
R. McDonald. 2006. Discriminative learning and span-
ning tree algorithms for dependency parsing. Ph.D.
thesis, University of Pennsylvania.
S. Montemagni, F. Barsotti, M. Battista, N. Calzolari,
O. Corazzari, A. Lenci, A. Zampolli, F. Fanciulli,
M. Massetani, R. Raffaelli, R. Basili, M. T. Pazienza,
D. Saracino, F. Zanzotto, N. Nana, F. Pianesi, and
R. Delmonte. 2003. Building the Italian Syntactic-
Semantic Treebank. In Abeille? (Abeille?, 2003), chap-
ter 11, pages 189?210.
J. Nivre and J. Nilsson. 2005. Pseudo-projective de-
pendency parsing. In Proceedings of the 43rd Annual
Meeting of the Association for Computational Linguis-
tics (ACL), pages 99?106.
J. Nivre, J. Hall, J. Nilson, G. Eryigit, and S. Marinov.
2006. Labeled pseudo-projective dependency pars-
ing with support vector machines. In Proceedings of
the Conference on Computational Natural Language
Learning (CoNLL).
J. Nivre, J. Hall, S. Ku?bler, R. McDonald, J. Nilsson,
S. Riedel, and D. Yuret. 2007. The CoNLL 2007
shared task on dependency parsing. In Proc. of the
Joint Conf. on Empirical Methods in Natural Lan-
guage Processing and Computational Natural Lan-
guage Learning (EMNLP-CoNLL).
J. Nivre. 2003. An efficient algorithm for projective
dependency parsing. In Proceedings of International
Workshop on Parsing Technologies, pages 149?160.
K. Oflazer, B. Say, D. Zeynep Hakkani-Tu?r, and G. Tu?r.
2003. Building a Turkish treebank. In Abeille?
(Abeille?, 2003), chapter 15, pages 261?277.
P. Prokopidis, E. Desypri, M. Koutsombogera, H. Papa-
georgiou, and S. Piperidis. 2005. Theoretical and
practical issues in the construction of a Greek depen-
dency treebank. In Proc. of the 4th Workshop on Tree-
banks and Linguistic Theories (TLT), pages 149?160.
K. Sagae and A. Lavie. 2006. A best-first probabilis-
tic shift-reduce parser. In Proceedings of the COL-
ING/ACL 2006 Main Conference Poster Sessions.
H. Yamada and Y. Matsumoto. 2003. Statistical depen-
dency analysis with support vector machines. In Pro-
ceedings of IWPT-2003.
1143
