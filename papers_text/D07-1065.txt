Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational
Natural Language Learning, pp. 620?629, Prague, June 2007. c?2007 Association for Computational Linguistics
Recovery of Empty Nodes in Parse Structures
Denis Filimonov1
1University of Maryland
College Park, MD 20742
den@cs.umd.edu
Mary P. Harper1,2
2Purdue University
West Lafayette, IN 47907
mharper@casl.umd.edu
Abstract
In this paper, we describe a new algorithm
for recovering WH-trace empty nodes. Our
approach combines a set of hand-written
patterns together with a probabilistic model.
Because the patterns heavily utilize regu-
lar expressions, the pertinent tree structures
are covered using a limited number of pat-
terns. The probabilistic model is essen-
tially a probabilistic context-free grammar
(PCFG) approach with the patterns acting as
the terminals in production rules. We eval-
uate the algorithm?s performance on gold
trees and parser output using three differ-
ent metrics. Our method compares favorably
with state-of-the-art algorithms that recover
WH-traces.
1 Introduction
In this paper, we describe a new algorithm for re-
covering WH-trace empty nodes in gold parse trees
in the Penn Treebank and, more importantly, in
automatically generated parses. This problem has
only been investigated by a handful of researchers
and yet it is important for a variety of applications,
e.g., mapping parse trees to logical representations
and structured representations for language mod-
eling. For example, SuperARV language models
(LMs) (Wang and Harper, 2002; Wang et al, 2003),
which tightly integrate lexical features and syntactic
constraints, have been found to significantly reduce
word error in English speech recognition tasks. In
order to generate SuperARV LM training, a state-of-
the-art parser is used to parse training material and
then a rule-based transformer converts the parses to
the SuperARV representation. The transformer is
quite accurate when operating on treebank parses;
however, trees produced by the parser lack one im-
portant type of information ? gaps, particularly WH-
traces, which are important for more accurate ex-
traction of the SuperARVs.
Approaches applied to the problem of empty
node recovery fall into three categories. Dienes
and Dubey (2003) recover empty nodes as a pre-
processing step and pass strings with gaps to their
parser. Their performance was comparable to
(Johnson, 2002); however, they did not evaluate
the impact of the gaps on parser performance.
Collins (1999) directly incorporated wh-traces into
his Model 3 parser, but he did not evaluate gap in-
sertion accuracy directly. Most of the research be-
longs to the third category, i.e., post-processing of
parser output. Johnson (2002) used corpus-induced
patterns to insert gaps into both gold standard trees
and parser output. Campbell (2004) developed a
set of linguistically motivated hand-written rules for
gap insertion. Machine learning methods were em-
ployed by (Higgins, 2003; Levy and Manning, 2004;
Gabbard et al, 2006).
In this paper, we develop a probabilistic model
that uses a set of patterns and tree matching to guide
the insertion of WH-traces. We only insert traces of
non-null WH-phrases, as they are most relevant for
our goals. Our effort differs from the previous ap-
proaches in that we have developed an algorithm for
the insertion of gaps that combines a small set of ex-
pressive patterns with a probabilistic grammar-based
model.
620
2 The Model
We have developed a set of tree-matching patterns
that are applied to propagate a gap down a path in
a parse tree. Pattern examples appear in Figure 1.
Each pattern is designed to match a subtree (a root
and one or more levels below that root) and used to
guide the propagation of the trace into one or more
nodes at the terminal level of the pattern (indicated
using directed edges). Since tree-matching patterns
are applied in a top-down fashion, multiple patterns
can match the same subtree and allow alternative
ways to propagate a gap. Hence, we have developed
a probabilistic model to select among the alterna-
tive paths. We have created 24 patterns for WHNP
traces, 16 for WHADVP, 18 for WHPP, and 11 for
WHADJP.
Figure 1: Examples of tree-matching patterns
Before describing our model, we first introduce
some notation.
? TNij is a tree dominating the string of words be-
tween positions i and j with N being the label of
the root. We assume there are no unary chains like
N?X? ...?Y ?N (which could be collapsed to
a single node N ) in the tree, so that TNij uniquely
describes the subtree.
? A gap location gab,Ncd is represented as a tuple
(gaptype, ancstr(a, b,N), c, d), where gaptype
is the type of the gap, (e.g., whnp for a WHNP
trace), ancstr(a, b,N) is the gap?s nearest ances-
tor, with a and b being its span and N being its
label, and c and d indicating where the gap can
be inserted. Note that a gap?s location is specified
precisely when c = d. If the gap is yet to be in-
serted into its final location but will be inserted
somewhere inside ancstr(a, b,N), then we set
c = a and d = b.
? ancstr(a, b,N) in the tuple for gab,Nxy is the tree
TNab .
? p(gab,Nxy |gaptype, TNij ) is the probability that a
gap of gaptype is located between x and y, with a
and b being the span of its ancestor, and i ? a ?
x ? y ? b ? j.
Given this notation, our model is tasked to identify
the best location for the gap in a parse tree among
the alternatives, i.e.,
argmax
x,a,b,N
Pr(gab,Nxx |T, gaptype)
where gab,Nxx represents a gap location in a tree, and
T = TNij is the subtree of the parse tree whose
root node is the nearest ancestor node dominating
the WH-phrase, excluding the WH-node itself, and
gaptype is the type of the gap. In order to simplify
the notation, we will omit the root labels N in TNij
and gab,Nxy , implying that they match where appropri-
ate.
To guide this model, we utilize tree-matching pat-
terns (see Figure 1), which are formally defined as
functions:
ptrn : T ? G ? ? ? {none}
where T is the space of parse trees, G is the space
of gap types, and ? is the space of gaps gabcd ,
and none is a special value representing failure to
match1. The application of a pattern is defined as:
app(ptrn, ?, gaptype) = ptrn(?, gaptype), where
? ? T and gaptype ? G. We define application of
patterns as follows:
app(ptrn, Tij , gaptype) ? gabxy : i ? a ? x < y ? b ? j
app(ptrn, Tij , gaptype) ? gabxx : i ? a ? x ? b ? j
app(ptrn, Tij , gaptype) ? none
Because patterns are uniquely associated with spe-
cific gap types, we will omit gaptype to simplify the
notation. Application is a function defined for every
pair (ptrn, Tij) with fixed gaptype. Patterns are ap-
plied to the root of Tij , not to an arbitrary subtree.
Consider an example of pattern application shown
in Figure 2. The tree contains a relative clause such
that the WHNP-phrase that was moved from some
location inside the subtree of its sister node S.
2
viewers
3
will
4
tune
5
in
6
to
7
see
8
1Modeling conjunction requires an alternative definition for
patterns: ptrn : T ? G ? Powerset(?) ? {none}. For the
sake of simplicity, we ignore conjunctions in the following dis-
cussion, except for in the few places where it matters, since this
has little impact on the development of our model.
621
Figure 2: A pattern application example
Now suppose there is a pattern P1 that matches
the tree T28 indicating that the gap is some-
where in its subtree T38 (will tune in to see), i.e.,
app(P1, T28) ? g3838 . The process of applying pat-
terns continues until the pattern P4 proposes an ex-
act location for the gap: app(P4, T78) = g7888 .
Figure 3: Another pattern application example
Suppose that, in addition to the pattern applica-
tions shown in Figure 2, there is one more, namely:
app(P5, T48) ? g4866 . The sequence of patterns
P1, P2, P5 proposes an alternative grammatically
plausible location for the gap, as shown in Figure
3. Notice that the combination of the two sequences
produces a tree of patterns, as shown in Figure 4,
and this pattern tree covers much of the structure of
the T28 subtree.
2.1 Tree Classes
The number of unique subtrees that contain WH-
phrases is essentially infinite; hence, modeling them
directly is infeasible. However, trees with varying
details, e.g., optional adverbials, often can be char-
P1
P2
P3C
D P4,$
E
A
B
F
P5,$
Figure 4: Pattern tree
acterized by the same tree of patterns. Hence, we
can represent the space of trees by utilizing a rela-
tively small set of classes of trees that are determined
by their tree of pattern applications.
Let ? be the set of all patterns. We define the set
of patterns matching tree Tij as follows:
M(Tij) = {P | P ? ? ? app(P, Tij) 6= none}
To enable recursive application:
app(ptrn, gabxy) =
{ app(ptrn, Tab) if x < y
none if x = y
A Pattern Chain PC is a sequence of pairs
of patterns and sets of pattern sets, terminated by
$, i.e., ( p1M1 ,
p2
M2 , ...
pn
Mn , $), where ?i pi ? Mi ?
?. Mi = M(Tab), where Tab is the result of
consequent application of the first i ? 1 patterns:
app(pi?1, app(pi?2, ..., app(p1, T??))) = gabxy, and
where T?? is the subtree we started with, (T28 in the
example above). We define the application of a pat-
tern chain PC = ( p1M1 ,
p2
M2 , ...
pn
Mn , $) to a tree Tij
as:
app(PC, Tij) = app(pn, ...app(p2, app(p1, Tij)))
It is important to also define a function to map
a tree to the set of pattern chains applicable to a
particular tree. The pseudocode for this function
called FindPCs appears in Figure 52. When ap-
plied to Tij , this function returns the set of all pat-
tern chains, applications of which would result in
concrete gap locations. The algorithm is guaranteed
to terminate as long as trees are of finite depth and
each pattern moves the gap location down at least
one level in the tree at each iteration. Using this
function, we define Tree Class (TC) of a tree Tij
as TC(Tij) = FindPCs(Tij).
2list ? element means ?append element to list?.
622
function FindPCs?(Tij , PC, allPCs) {
Mij ? {P | P ? ? ? app(P, Tij) 6= none}
forall P ? Mij
gabxy ? app(P, Tij)
PC ? PC ? PMij
if x = y then // gabxy is a concrete location
allPCs ? allPCs ? {PC ? $}
else
allPCs ? FindPCs?(Tab, PC, allPCs)
return allPCs }
function FindPCs(Tij) { return FindPCs?(Tij , [ ], ?) }
Figure 5: Pseudocode for FindPCs
In the case of a conjunction, the function Find-
PCs is slightly more complex. Recall that in this
case app(P, Tij) produces a set of gaps or none. The
pseudocode for this case appears in Figure 6.
2.2 A Gap Automaton
The set of pattern chains constructed by the function
FindPCs can be represented as a pattern tree with
patterns being the edges. For example, the pattern
tree in Figure 4 corresponds to the tree displayed in
Figures 2 and 3.
This pattern tree captures the history of gap prop-
agations beginning at A. Assuming at that point only
pattern P1 is applicable, subtree B is produced. If P2
yields subtree C, and at that point patterns P3 and
P5 can be applied, this yields subtree D and exact
location F (which is expressed by the termination
symbol $), respectively. Finally, pattern P4 matches
subtree D and proposes exact gap location E. It is
important to note that this pattern tree can be thought
of as an automaton, with A,B,C,D,E, and F be-
ing the states and the pattern applications being the
transitions.
Now, let us assign meaning of the states
A,B,C, and D to be the set of matching patterns,
i.e., A = {P1}, B = {P2}, C = {P3, P5}, D = {P4}, and
E = F = ?. Given this representation, the pattern
chains for the insertion of the gaps in our example
would be as follows:
({P1}) P1? ({P2}) P2? ({P3, P5}) P3? ({P4}) P4,$?? (?)
({P1}) P1? ({P2}) P2? ({P3, P5}) P5,$?? (?)
With this representation, we can create a regular
grammar using patterns as the terminals and their
function CrossProd(PC1, PC2) {
prod ? ?
forall pci ? PC1
forall pcj ? PC2 : prod ? prod?{pci?pcj}
return prod }
function FindPCs(Tij) {
Mij ? {P | P ? ? ? app(P, Tij) 6= none}
newPCs ? ?
forall P ? Mij
PCs ? {[ ]}
forall gabxy ? app(P, Tij)
if x = y then
forall pc ? PCs : pc ? pc ? $
else
PCs ? CrossProd(PCs,FindPCs(Tab))
forall pc ? PCs : pc ? PMij ? pc
newPCs ? newPCs ? PCs
return newPCs }
The set app(P, Tij) must be ordered, so that
branches of conjunction are concatenated in a well de-
fined order.
Figure 6: Pseudocode for FindPCs in the case of
conjunction
powerset as the non-terminals (adding a few more
details like the start symbol) and production rules
such as {P2} ? P2 {P3, P5}. However, for our exam-
ple the chain of patterns applied P1, P2, P3, P4, $ could
generate a pattern tree that is incompatible with the
original tree. For example:
({P1}) P1? ({P2}) P2? ({P3, P5}) P3? ({P3, P4}) P4,$?? (?)
which might correspond to something like ?that
viewers will tune in to expect to see.? Note that this
pattern chain belongs to a different tree class, which
incidentally would have inserted the gap at a differ-
ent location (VP see gap).
To overcome this problem we add additional con-
straints to the grammar to ensure that all parses the
grammar generates belong to the same tree class.
One way to do this is to include the start state of
a transition as an element of the terminal, e.g., P2{P2} ,
P3
{P3,P5} . That is, we extend the terminals to include
the left-hand side of the productions they are emitted
from, e.g.,
{P2} ? P2{P2} {P3, P5}
623
{P3, P5} ? P3{P3, P5} {P4}
and the sequence of terminals becomes:
P1
{P1}
P2
{P2}
P3
{P3,P5}
P4
{P4} $.
Note that the grammar is unambiguous. For such
a grammar, the question ?what is the probability of a
parse tree given a string and grammar? doesn?t make
sense; however, the question ?what is the probability
of a string given the grammar? is still valid, and this
is essentially what we require to develop a genera-
tive model for gap insertion.
2.3 The Pattern Grammar
Let us define the pattern grammar more rigorously.
Let ? be the set of patterns, and ?? ? ? be the set
of terminal patterns3. Let pset(P ) be the set of all
subsets of patterns which include the pattern P , i.e.,
pset(P ) = {? ? {P} | ? ? powerset(?)}
? Let T = { Ppset(P ) | P ? ?}
?{$} be the set of
terminals, where $ is a special symbol4.
? Let N = {S}? powerset(?) be the set of non-
terminals with S being the start symbol.
? Let P be the set of productions, defined as the
union of the following sets:
1. {S ? ? | ? ? powerset(?)}.
2. {? ? P? ? | P ? ???? , ? ? pset(P ) and ? ?powerset(?)}. These are nonterminal transi-
tions, note that they emit only non-terminal pat-
terns.
3. {? ? P? $ | P ? ?? and ? ? pset(P )}. These
are the terminal transitions, they emit a termi-
nal pattern and the symbol $.
4. {? ? P? ?1 . . . ?n | P ? ? ? ?? , ? ?pset(P ) and ?i?[1..n] ?i ? powerset(?)}.
This rule models conjunction with n branches.
2.4 Our Gap Model
Given the grammar defined in the previous subsec-
tion, we will define a probabilistic model for gap in-
sertion. Recall that our goal is to find:
argmax
x,a,b
Pr(gabxx|T )
Just like the probability of a sentence is obtained by
summing up the probabilities of its parses, the prob-
ability of the gap being at gabxx is the sum of proba-
bilities of all pattern chains that yield gabxx.
3Patterns that generate exact position for a gap.
4Symbol $ helps to separate branches in strings with con-
junction.
Pr(gabxx|T ) =
?
pci??
Pr(pci|T )
where ? = {pc | app(pc, T ) = gabxx}. Note that
pci ? TC(T ) by definition.
For our model, we use two approximations. First,
we collapse a tree T into its Tree Class TC(T ), ef-
fectively ignoring details irrelevant to gap insertion:
Pr(pci|T ) ? Pr(pci|TC(T ))
Figure 7: A pattern tree with the pattern chain
ABDGM marked using bold lines
Consider the pattern tree shown in Figure 7. The
probability of the pattern chain ABDGM given the
pattern tree can be computed as:
Pr(ABDGM |TC(T )) = Pr(ABDGM,TC(T ))Pr(TC(T ))
= NR(ABDGM,TC(T ))
NR(TC(T ))
where NR(TC(T )) is the number of occurrences
of the tree class TC(T ) in the training corpus and
NR(ABDGM,TC(T )) is the number cases when
the pattern chain ABDGM leads to a correct gap in
trees corresponding to the tree class TC(T ). For
many tree classes, NR(TC(T )) may be a small
number or even zero, thus this direct approach can-
not be applied to the estimation of Pr(pci|TC(T )).
Further approximation is required to tackle the spar-
sity issue.
In the following discussion, XY will denote
an edge (pattern) between vertices X and Y in
624
the pattern tree shown in Figure 7. Note that
Pr(ABDGM |TC(T )) can be represented as:
Pr(AB|TC(T ), A)? Pr(BD|TC(T ), AB)?
?Pr(DG|TC(T ), ABD)? Pr(GM |TC(T ), ABDG)
We make an independence assumption, specifi-
cally, that Pr(BD|TC(T ), AB) depends only on
states B, D, and the edge between them, not on
the whole pattern tree or the edges above B, i.e.,
Pr(BD|TC(T ), AB) ? Pr(BD,D|B). Note that
this probability is equivalent to the probability of a
production Pr(B BD? D) of a PCFG.
Recall that the meaning assigned to a state
in pattern grammar in Section 2.2 is the set of
patterns matching at that state. Thus, accord-
ing to that semantics, only the edges displayed
bold in Figure 8 are involved in computation of
Pr(B BD? D). Written in the style we used for
our grammar, the production is {BD,BE,BF} ?
BD
{BD,BE,BF}{DG,DH}.
Figure 8: The context considered for estimation of
the probability of transition from B to D
Pattern trees are fairly shallow (partly because
many patterns cover several layers in a parse tree
as can be seen in Figures 1 and 2); therefore, the
context associated with a production covers a good
part of a pattern tree. Another important observa-
tion is that the local configuration of a node, which
is described by the set of matching patterns, is the
most relevant to the decision of where the gap is to
be propagated5. This is the reason why the states are
represented this way.
Formally, the second approximation we make is
5We have evaluated a model that only uses
Pr(BD|{BD,BE,BF}) for the probability of taking
BD and found it performs only slightly worse than the model
presented here.
as follows:
Pr(pci|TC(T )) ? Pr(pci|G)
where G is a PCFG model based on the grammar
described above.
Pr(pci|G) =
?
prodj?P(pci)
Pr(prodj |G)
where P(pci) is the parse of the pattern chain pci
which is a string of terminals of G. Combining the
formulae:
Pr(gabxx|T ) ?
?
pci??
Pr(pci|G)
Finally, since Pr(TC(T )|G) is a constant for T ,
argmax
x,a,b
Pr(gabxx|T ) ? argmaxx,a,b
?
pci??
Pr(pci|G)
To handle conjunction, we must express the fact
that pattern chains yield sets of gaps. Thus, the goal
becomes:
argmax
(x1,a1,b1),...,(xn,an,bn)
Pr({ga1b1x1x1 , . . . , ganbnxnxn}|T )
Pr({ga1b1x1x1 , . . . , ganbnxnxn}|T ) =
?
pci??
Pr(pci|T )
where ? = {pc | app(pc, T ) =
{ga1b1x1x1 , . . . , ganbnxnxn}}. The remaining equations
are unaffected.
2.5 Smoothing
Even for the relatively small number of patterns,
the number of non-terminals in the grammar can
potentially be large (2|?|). This does not happen
in practice since most patterns are mutually exclu-
sive. Nonetheless, productions, unseen in the train-
ing data, do occur and their probabilities have to be
estimated. Rewriting the probability of a transition
Pr(A ? aA B) as P(A, a,B), we use the following in-
terpolation:
P?(A, a,B) = ?1P(A, a,B) + ?2P(A, a)
+?3P(A,B) + ?4P(a,B) + ?5P(a)
We estimate the parameters on the held out data
(section 24 of WSJ) using a hill-climbing algorithm.
625
3 Evaluation
3.1 Setup
We compare our algorithm under a variety of condi-
tions to the work of (Johnson, 2002) and (Gabbard
et al, 2006). We selected these two approaches be-
cause of their availability6. In addition, (Gabbard et
al., 2006) provides state-of-the-art results. Since we
only model the insertion of WH-traces, all metrics
include co-indexation with the correct WH phrases
identified by their type and word span.
We evaluate on three metrics. The first metric,
which was introduced by Johnson (2002), has been
widely reported by researchers investigating gap in-
sertion. A gap is scored as correct only when it has
the correct type and string position. The metric has
the shortcoming that it does not require correct at-
tachment into the tree.
The second metric, which was developed by
Campbell (2004), scores a gap as correct only when
it has the correct gap type and its mother node has
the correct nonterminal label and word span. As
Campbell points out, this metric does not restrict the
position of the gap among its siblings, which in most
cases is desirable; however, in some cases (e.g., dou-
ble object constructions), it does not correctly detect
errors in object order. This metric is also adversely
affected by incorrect attachments of optional con-
stituents, such as PPs, due to the span requirement.
To overcome the latter issue with Campbell?s met-
ric, we propose to use a third metric that evaluates
gaps with respect to correctness of their lexical head,
type of the mother node, and the type of the co-
indexed wh-phrase. This metric differs from that
used by Levy and Manning (2004) in that it counts
only the dependencies involving gaps, and so it rep-
resents performance of the gap insertion algorithm
more directly.
We evaluate gap insertion on gold trees from sec-
tion 23 of the Wall Street Journal Penn Treebank
(WSJ) and parse trees automatically produced using
the Charniak (2000) and Bikel (2004) parsers. These
parsers were trained using sections 00 through 22 of
the WSJ with section 24 as the development set.
Because our algorithm inserts only traces of non-
empty WH phrases, to fairly compare to Johnson?s
and Gabbard?s performance on WH-traces alone, we
6Johnson?s source code is publicly available, and Ryan Gab-
bard kindly provided us with output trees produced by his sys-
tem.
remove the other gap types from both the gold trees
and the output of their algorithms. Note that Gab-
bard et al?s algorithm requires the use of function
tags, which are produced using a modified version
of the Bikel parser (Gabbard et al, 2006) and a sep-
arate software tool (Blaheta, 2003) for the Charniak
parser output.
For our algorithm, we do not utilize function tags,
but we automatically replace the tags of auxiliary
verbs in tensed constructions with AUX prior to in-
serting gaps using tree surgeon (Levy and Andrew,
2006). We found that Johnson?s algorithm more
accurately inserts gaps when operating on auxified
trees, and so we evaluate his algorithm using these
modified trees.
In order to assess robustness of our algorithm, we
evaluate it on a corpus of a different genre ? Broad-
cast News Penn Treebank (BN), and compare the re-
sult with Johnson?s and Gabbard?s algorithms. The
BN corpus uses a modified version of annotation
guidelines, with some of the modifications affecting
gap placement.
Treebank 2 guidelines (WSJ style):
(SBAR (WHNP-2 (WP whom))
(S (NP-SBJ (PRP they))
(VP (VBD called)
(S (NP-SBJ (-NONE- *T*-2))
(NP-PRD (NNS exploiters))))))
Treebank 2a guidelines (BN style):
(SBAR-NOM (WHNP-1 (WP what))
(S (NP-SBJ (PRP they))
(VP (VBP call)
(NP-2 (-NONE- *T*-1))
(S-CLR (NP-SBJ (-NONE- *PRO*-2))
(NP-PRD (DT an) (NN epidemic))))))
Since our algorithms were trained on WSJ, we ap-
ply tree transformations to the BN corpus to convert
these trees to WSJ style. We also auxify the trees as
described previously.
3.2 Results
Table 1 presents gap insertion F measure for John-
son?s (2002) (denoted J), Gabbard?s (2006) (denoted
G), and our (denoted Pres) algorithms on section 23
gold trees, as well as on parses generated by the
Charniak and Bikel parsers. In addition to WHNP
and WHADVP results that are reported in the liter-
ature, we also present results for WHPP gaps even
though there is a small number of them in section
23 (i.e., 22 gaps total). Since there are only 3 non-
empty WHADJP phrases in section 23, we omit
them in our evaluation.
626
Gold Trees Charniak Parser Bikel Parser
Metric J G Pres J G Pres J G Pres
WHNP Johnson 94.8 90.7 97.9 89.8 86.3 91.5 90.2 86.8 92.6
Campbell 94.8 97.0 99.1 81.9 83.8 83.5 80.7 81.5 82.2
Head dep 94.8 97.0 99.1 88.8 90.6 91.0 89.1 91.4 92.3
WHADVP Johnson 75.5 91.4 96.5 61.4 78.0 80.0 61.0 77.9 77.2
Campbell 74.5 89.1 95.0 61.4 71.7 78.4 60.0 71.5 74.8
Head dep 75.5 89.8 95.8 64.4 78.0 84.7 63.0 77.1 80.3
WHPP Johnson 58.1 N/R 72.7 35.7 N/R 55.0 42.9 N/R 53.7
Campbell 51.6 N/R 86.4 28.6 N/R 60.0 35.7 N/R 63.4
Head dep 51.6 N/R 86.4 35.7 N/R 70.0 35.7 N/R 73.2
Table 1: F1 performance on section 23 of WSJ (N/R indicates not reported)
Compared to Johnson?s and Gabbard?s algorithm,
our algorithm significantly reduces the error on
gold trees (table 1). Operating on automatically
parsed trees, our system compares favorably on
all WH traces, using all metrics, except for two
instances: Gabbard?s algorithm has better perfor-
mance on WHNP, using Cambpell?s metric and trees
generated by the Charniak parser by 0.3% and on
WHADVP, using Johnson?s metric and trees pro-
duces by the Bikel parser by 0.7%. However, we
believe that the dependency metric is more appropri-
ate for evaluation on automatically parsed trees be-
cause it enforces the most important aspects of tree
structure for evaluating gap insertion. The relatively
poor performance of Johnson?s and our algorithms
on WHPP gaps compared that on WHADVP gaps
is probably due, at least in part, to the significantly
smaller number of WHPP gaps in the training corpus
and the relatively wider range of possible attachment
sites for the prepositional phrases.
Table 2 displays how well the algorithms trained
on WSJ perform on BN. A large number of the er-
rors are due to FRAGs which are far more com-
mon in the speech corpus than in WSJ. WHPP and
WHADJP, although more rare than the other types,
are presented for reference.
3.3 Error Analysis
It is clear from the contrast between the results based
on gold standard trees and the automatically pro-
duced parses in Table 1 that parse error is a major
source of error. Parse error impacts all of the met-
rics, but the patterns of errors are different. For WH-
NPs, Campbell?s metric is lower than the other two
across all three algorithms, suggesting that this met-
ric is adversely affected by factors that do not im-
pact the other metrics (most likely the span of the
gap?s mother node). For WHADVPs, the metrics
show a similar degradation due to parse error across
the board. We are reluctant to draw conclusions for
the metrics on WHPPs; however, it should be noted
that the position of the PP should be less critical for
evaluating these gaps than their correct attachment,
suggesting that the head dependency metric would
more accurately reflect the performance of the sys-
tem for these gaps.
Campbell?s metric has an interesting property: in
parse trees, we can compute the upper bound on re-
call by simply checking whether the correct WH-
phrase and gap?s mother node exist in the parse tree.
We present recall results and upper bounds in Table
3. Clearly the algorithms are performing close to the
upper bound for WHNPs when we take into account
the impact of parse errors on this metric. Clearly
there is room for improvement for the WHPPs.
Metric J G Pres
WHNP Johnson 88.0 90.3 92.0
Campbell 88.2 94.0 95.3
Head dep 88.3 94.0 95.3
WHADVP Johnson 76.4 92.0 94.3
Campbell 76.3 88.2 92.4
Head dep 76.3 88.5 92.5
WHPP Johnson 56.6 N/R 75.7
Campbell 60.4 N/R 91.9
Head dep 60.4 N/R 91.9
WHADJP Johnson N/R N/R 89.8
Campbell N/R N/R 85.7
Head dep N/R N/R 85.7
Table 2: F1 performance on gold trees of BN
In addition to parser errors, which naturally have
the most profound impact on the performance, we
found the following sources of errors to have impact
on our results:
? Annotation errors and inconsistency in PTB,
which impact not only the training of our system,
but also its evaluation.
627
Charniak Parser J G Pres UB
WHNP 81.9 82.8 83.5 84.0
WHADVP 61.4 71.7 78.4 81.1
WHPP 28.6 N/R 60.0 86.4
Bikel Parser J G Pres UB
WHNP 77.0 80.5 81.5 82.0
WHADVP 47.2 70.1 74.8 78.0
WHPP 22.7 N/R 59.1 81.8
Table 3: Recall on trees produced by the Charniak
and Bikel parsers and their upper bounds (UB)
1. There are some POS labeling errors that con-
fuse our patterns, e.g.,
(SBAR (WHNP-3 (IN that))
(S (NP-SBJ (NNP Canada))
(VP (NNS exports)
(NP (-NONE- *T*-3))
(PP ...))))
2. Some WHADVPs have gaps attached in the
wrong places or do not have gaps at all, e.g.,
(SBAR (WHADVP (WRB when))
(S (NP (PRP he))
(VP (VBD arrived)
(PP (IN at)
(NP ...))
(ADVP (NP (CD two)
(NNS days))
(JJ later)))))
3. PTB annotation guidelines leave it to annota-
tors to decide whether the gap should be at-
tached at the conjunction level or inside its
branches (Bies et al, 1995) leading to incon-
sistency in attachment decisions for adverbial
gaps.
? Lack of coverage: Even though the patterns we
use are very expressive, due to their small number
some rare cases are left uncovered.
? Model errors: Sometimes despite one of the appli-
cable pattern chains proposes the correct gap, the
probabilistic model chooses otherwise. We be-
lieve that a lexicalized model can eliminate most
of these errors.
4 Conclusions and Future Work
The main contribution of this paper is the de-
velopment of a generative probabilistic model for
gap insertion that operates on subtree structures.
Our model achieves state-of-the-art performance,
demonstrating results very close to the upper bound
on WHNP using Campbell?s metric. Performance
for WHADVPs and especially WHPPs, however,
has room for improvement.
We believe that lexicalizing the model by adding
information about lexical heads of the gaps may re-
solve some of the errors. For example:
(SBAR (WHADVP-3 (WRB when))
(S (NP (NNP Congress))
(VP (VBD wanted)
(S (VP (TO to)
(VP (VB know) ...)))
(ADVP (-NONE- *T*-3)))))
(SBAR (WHADVP-1 (WRB when))
(S (NP (PRP it))
(VP (AUX is)
(VP (VBN expected)
(S (VP (TO to)
(VP (VB deliver) ...
(ADVP (-NONE- *T*-1)))))))))
These sentences have very similar structure, with
two potential places to insert gaps (ignoring re-
ordering with siblings). The current model inserts
the gaps as follows: when Congress (VP wanted (S
to know) gap) and when it is (VP expected (S to
deliver) gap), making an error in the second case
(partly due to the bias towards shorter pattern chains,
typical for a PCFG). However, deliver is more likely
to take a temporal modifier than know.
In future work, we will investigate methods for
adding lexical information to our model in order to
improve the performance on WHADVPs and WH-
PPs. In addition, we will investigate methods for
automatically inferring patterns from a treebank cor-
pus to support fast porting of our approach to other
languages with treebanks.
5 Acknowledgements
We would like to thank Ryan Gabbard for provid-
ing us output from his algorithm for evaluation. We
would also like to thank the anonymous reviewers
for invaluable comments. This material is based
upon work supported by the Defense Advanced Re-
search Projects Agency (DARPA) under Contract
No. HR0011-06-C-0023. Any opinions, findings
and conclusions or recommendations expressed in
this material are those of the authors and do not nec-
essarily reflect the views of DARPA.
References
A. Bies, M. Ferguson, K. Katz, and R. MacIntyre. 1995.
Bracketing guidelines for treebank II style Penn Tree-
bank project. Technical report.
D. M. Bikel. 2004. On the Parameter Space of Gen-
628
erative Lexicalized Statistical Parsing Models. Ph.D.
thesis, University of Pennsylvania.
D. Blaheta. 2003. Function Tagging. Ph.D. thesis,
Brown University.
R. Campbell. 2004. Using linguistic principles to re-
cover empty categories. In Proceedings of the Annual
Meeting of the Association for Computational Linguis-
tics.
E. Charniak. 2000. A maximum-entropy-inspired parser.
In Proceedings of the North American Chapter of the
Association for Computational Linguistics.
M. Collins. 1999. Head-driven Statistical Models for
Natural Language Parsing. Ph.D. thesis, University
of Pennsylvania.
P. Dienes and A. Dubey. 2003. Antecedent recovery:
Experiments with a trace tagger. In Proceedings of
the 2003 Conference on Empirical Methods in Natural
Language Processing.
R. Gabbard, S. Kulick, and M. Marcus. 2006. Fully pars-
ing the Penn Treebank. In Proceedings of the North
American Chapter of the Association for Computa-
tional Linguistics.
D. Higgins. 2003. A machine-learning approach to the
identification of WH gaps. In Proceedings of the An-
nual Meeting of the European Chapter of the Associa-
tion for Computational Linguistics.
M. Johnson. 2002. A simple pattern-matching algorithm
for recovering empty nodes and their antecedents. In
Proceedings of the Annual Meeting of the Association
for Computational Linguistics.
R. Levy and G Andrew. 2006. Tregex and Tsurgeon:
Tools for querying and manipulating tree data struc-
tures. In Proceedings of LREC.
R. Levy and C. Manning. 2004. Deep dependencies
from context-free statistical parsers: Correcting the
surface dependency approximation. In Proceedings of
the Annual Meeting of the Association for Computa-
tional Linguistics.
W. Wang and M. P. Harper. 2002. The SuperARV lan-
guage model: Investigating the effectiveness of tightly
integrating multiple knowledge sources in language
modeling. In Proceedings of the Empirical Methods
in Natural Language Processing.
W. Wang, M. P. Harper, and A. Stolcke. 2003. The ro-
bustness of an almost-parsing language model given
errorful training data. In Proceedings of the IEEE In-
ternational Conference on Acoustics, Speech, and Sig-
nal Processing.
629
