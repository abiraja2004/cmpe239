Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the ACL, pages 697?700,
Los Angeles, California, June 2010. c?2010 Association for Computational Linguistics
Integrating Joint n-gram Features
into a Discriminative Training Framework
Sittichai Jiampojamarn? and Colin Cherry? and Grzegorz Kondrak?
?Department of Computing Science ?National Research Council Canada
University of Alberta 1200 Montreal Road
Edmonton, AB, T6G 2E8, Canada Ottawa, ON, K1A 0R6, Canada
{sj,kondrak}@cs.ualberta.ca Colin.Cherry@nrc-cnrc.gc.ca
Abstract
Phonetic string transduction problems, such
as letter-to-phoneme conversion and name
transliteration, have recently received much
attention in the NLP community. In the past
few years, two methods have come to dom-
inate as solutions to supervised string trans-
duction: generative joint n-gram models, and
discriminative sequence models. Both ap-
proaches benefit from their ability to consider
large, flexible spans of source context when
making transduction decisions. However, they
encode this context in different ways, provid-
ing their respective models with different in-
formation. To combine the strengths of these
two systems, we include joint n-gram fea-
tures inside a state-of-the-art discriminative
sequence model. We evaluate our approach
on several letter-to-phoneme and translitera-
tion data sets. Our results indicate an improve-
ment in overall performance with respect to
both the joint n-gram approach and traditional
feature sets for discriminative models.
1 Introduction
Phonetic string transduction transforms a source
string into a target representation according to its
pronunciation. Two important examples of this task
are letter-to-phoneme conversion and name translit-
eration. In general, the problem is challenging be-
cause source orthography does not unambiguously
specify the target representation. When consider-
ing letter-to-phoneme, ambiguities and exceptions
in the pronunciation of orthography complicate con-
version. Transliteration suffers from the same ambi-
guities, but the transformation is further complicated
by restrictions in the target orthography that may not
exist in the source.
Joint n-gram models (Bisani and Ney, 2002;
Chen, 2003; Bisani and Ney, 2008) have been
widely applied to string transduction problems (Li et
al., 2004; Demberg et al, 2007; Jansche and Sproat,
2009). The power of the approach lies in building
a language model over the operations used in the
conversion from source to target. Crucially, this al-
lows the inclusion of source context in the generative
story. Smoothing techniques play an important role
in joint n-gram models, greatly affecting their per-
formance. Although joint n-gram models are capa-
ble of capturing context information in both source
and target, they cannot selectively use only source
or target information, nor can they consider arbitrary
sequences within their context window, as they are
limited by their back-off schedule.
Discriminative sequence models have also been
shown to perform extremely well on string transduc-
tion problems. These begin with a Hidden Markov
Model architecture, augmented with substring op-
erations and discriminative training. The primary
strength of these systems is their ability to include
rich indicator features representing long sequences
of source context. We will assume a specific in-
stance of discriminative sequence modeling, DI-
RECTL (Jiampojamarn et al, 2009), which achieved
the best results on several language pairs in the
NEWS Machine Transliteration Shared Task (Li et
al., 2009). The same system matches or exceeds the
performance of the joint n-gram approach on letter-
to-phoneme conversion (Jiampojamarn et al, 2008).
Its features are optimized by an online, margin-
697
based learning algorithm, specifically, the Margin
Infused Relaxed Algorithm, MIRA (Crammer and
Singer, 2003).
In this paper, we propose an approach that com-
bines these two different paradigms by formulating
the joint n-gram model as a new set of features in the
discriminative model. This leverages an advantage
of discriminative training, in that it can easily and
effectively incorporate arbitrary features. We eval-
uate our approach on several letter-to-phoneme and
transliteration data sets. Our results demonstrate an
improvement in overall performance with respect to
both the generative joint n-gram approach and the
original DIRECTL system.
2 Background
String transduction transforms an input string x into
the desired output string y. The input and output are
different representations of the same entity; for ex-
ample, the spelling and the pronunciation of a word,
or the orthographic forms of a word in two different
writing scripts.
One approach to string transduction is to view
it as a tagging problem where the input charac-
ters are tagged with the output characters. How-
ever, since sounds are often represented by multi-
character units, the relationship between the input
and output characters is often complex. This pre-
vents the straightforward application of standard
tagging techniques, but can be addressed by sub-
string decoders or semi-Markov models.
Because the relationship between x and y is hid-
den, alignments between the input and output char-
acters (or substrings) are often provided in a pre-
processing step. These are usually generated in an
unsupervised fashion using a variant of the EM al-
gorithm. Our system employs the many-to-many
alignment described in (Jiampojamarn et al, 2007).
We trained our system on these aligned examples by
using the online discriminative training of (Jiampo-
jamarn et al, 2009). At each step, the parameter
update is provided by MIRA.
3 Features
Jiampojamarn et al (2009) describe a set of indica-
tor feature templates that include (1) context features
(2) transition features and (3) linear-chain features.
context xi?c yi
. . .
xi+c yi
xi?cxi?c+1 yi
. . .
xi+c?1xi+c yi
. . . . . .
xi?c . . . xi+c yi
transition yi?1 yi
linear-chain xi?c yi?1 yi
. . .
xi+c yi?1 yi
xi?cxi?c+1 yi?1 yi
. . .
xi+c?1xi+c yi?1 yi
. . . . . .
xi?c . . . xi+c, yi?1 yi
joint n-gram xi+1?nyi+1?nxiyi
. . .
xi?1yi?1xiyi
xi+1?nyi+1?nxi+2?nyi+2?nxiyi
. . .
xi?2yi?2xi?1yi?1xiyi
. . . . . .
xi+1?nyi+1?n . . . xi?1yi?1xiyi
Table 1: Feature template
Table 1 summarizes these features and introduces
the new set of joint n-gram features.
The context features represent the source side ev-
idence that surrounds an input substring xi as it gen-
erates the target output yi. These features include
all possible n-grams that fit inside a source-side con-
text windows of size C, each conjoined with yi. The
transition features enforce the cohesion of the gen-
erated output with target-side bigrams. The linear-
chain features conjoin context and transition fea-
tures.
The set of feature templates described above
has been demonstrated to achieve excellent perfor-
mance. The context features express rich informa-
tion on the source side, but no feature template al-
lows target context beyond yi?1,yi. Target and
source context are considered jointly, but only in a
very limited fashion, as provided by the linear chain
features. Jiampojamarn et al (2008) report that con-
text features contribute the most to system perfor-
mance. They also report that increasing the Markov
order in the transition features from bigram to tri-
698
Figure 1: System accuracy as a function of the beam size
gram results in no significant improvement. Intu-
itively, the joint information of both source and tar-
get sides is important in string transduction prob-
lems. By integrating the joint n-gram features into
the online discriminative training framework, we en-
able the system to not only enjoy rich context fea-
tures and long-range dependency linear-chain fea-
tures, but we also take advantage of joint informa-
tion between source and target substring pairs, as
encoded by the joint n-gram template shown in the
bottom of Table 1.
An alternative method to incorporate a joint n-
gram feature would compute the generative joint n-
gram scores, and supply them as a real-valued fea-
ture to the model. As all of the other features in
the DIRECTL framework are indicators, the training
algorithm may have trouble scaling an informative
real-valued feature. Therefore, we represent these
joint n-gram features as binary features that indi-
cate whether the model has seen particular strings
of joint evidence in the previous n ? 1 operations
when generating yi from xi. In this case, the sys-
tem learns a distinct weight for each substring of the
joint n-gram.
In order to accommodate higher-order joint n-
grams, we replace the exact search algorithm of Ji-
ampojamarn et al (2008) with a beam search. Dur-
ing our development experiments, we observed no
significant decrease in accuracy after introducing
this approximation. Figure 1 shows the system per-
formance in terms of the word accuracy as a function
of the beam size on a development set. The perfor-
mance starts to converge quickly and shows no fur-
ther improvement for values grater than 20. In the
remaining experiments we set the beam size to 50.
We also performed development experiments
Figure 2: System accuracy as a function of n-gram size
with a version of the system that includes only joint
n-gram indicators. Figure 2 shows the word ac-
curacy with different values of n. The accuracy
reaches its maximum for n = 4, and actually falls
off for larger values of n. This anomaly is likely
caused by the model using its expanded expressive
power to memorize sequences of operations, overfit-
ting to its training data. Such overfitting is less likely
to happen in the generative joint n-gram model,
which smooths high-order estimates very carefully.
4 Experiments and Results
We evaluate our new approach on two string trans-
duction applications: (1) letter-to-phoneme conver-
sion and (2) name transliteration. For the letter-to-
phoneme conversion, we employ the English Celex,
NETtalk, OALD, CMUdict, and the French Brulex
data sets. In order to perform direct comparison with
the joint n-gram approach, we follow exactly the
same data splits as Bisani and Ney (2008). The train-
ing sizes range from 19K to 106K words. For the
transliteration task, we use three data sets provided
by the NEWS 2009 Machine Transliteration Shared
Task (Li et al, 2009): English-Russian (EnRu),
English-Chinese (EnCh), and English-Hindi (EnHi).
The training sizes range from 10K to 30K words.
We set n = 6 for the joint n-gram features; other pa-
rameters are set on the respective development sets.
Tables 2 and 3 show the performance of our new
system in comparison with the joint n-gram ap-
proach and DIRECTL. The results in the rightmost
column of Table 2 are taken directly from (Bisani
and Ney, 2008), where they were evaluated on the
same data splits. The results in the rightmost col-
umn of Table 3 are from (Jansche and Sproat, 2009),
which was the best performing system based on joint
699
Data set this work DIRECTL joint n-gram
Celex 89.23 88.54 88.58
CMUdict 76.41 75.41 75.47
OALD 85.54 82.43 82.51
NETtalk 73.52 70.18 69.00
Brulex 95.21 95.03 93.75
Table 2: Letter-to-phoneme conversion accuracy
Data set this work DIRECTL joint n-gram
EnRu 61.80 61.30 59.70
EnCh 74.17 73.34 64.60
EnHi 50.30 49.80 41.50
Table 3: Name transliteration accuracy
n-grams at NEWS 2009. We report all results in
terms of the word accuracy, which awards the sys-
tem only for complete matches between system out-
puts and the references.
Our full system outperforms both D IRECTL and
the joint n-gram approach in all data sets. This
shows the utility of adding joint n-gram features to
the DIRECTL system, and confirms an advantage of
discriminative approaches: strong competitors can
simply be folded into the model.
Comparing across tables, one can see that the gap
between the generative joint n-gram and the DI-
RECTL methods is much larger for the transliter-
ation tasks. This could be because joint n-grams
are a poor fit for transliteration, or the gap could
stem from differences between the joint n-gram im-
plementations used for the two tasks. Looking at
the improvements to DIRECTL from joint n-gram
features, we see further evidence that joint n-grams
are better suited to letter-to-phoneme than they are
to transliteration: letter-to-phoneme improvements
range from relative error reductions of 3.6 to 17.3,
while in transliteration, the largest reduction is 3.1.
5 Conclusion
We have presented a new set of joint n-gram features
for the DIRECTL discriminative sequence model.
The resulting system combines two successful ap-
proaches for string transduction ? D IRECTL and
the joint n-gram model. Joint n-gram indicator fea-
tures are efficiently trained using a large margin
method. We have shown that the resulting system
consistently outperforms both DIRECTL and strong
joint n-gram implementations in letter-to-phoneme
conversion and name transliteration, establishing a
new state-of-the-art for these tasks.
Acknowledgements
This research was supported by the Alberta Ingenu-
ity Fund and the Natural Sciences and Engineering
Research Council of Canada.
References
Maximilian Bisani and Hermann Ney. 2002. Investi-
gations on joint-multigram models for grapheme-to-
phoneme conversion. In Proc. ICSLP, pages 105?108.
Maximilian Bisani and Hermann Ney. 2008. Joint-
sequence models for grapheme-to-phoneme conver-
sion. Speech Communication, 50(5):434?451.
Stanley F. Chen. 2003. Conditional and joint mod-
els for grapheme-to-phoneme conversion. In Proc.
Eurospeech-2003.
Koby Crammer and Yoram Singer. 2003. Ultraconserva-
tive online algorithms for multiclass problems. Jour-
nal of Machine Learning Research, 3:951?991.
Vera Demberg, Helmut Schmid, and Gregor Mo?hler.
2007. Phonological constraints and morphological
preprocessing for grapheme-to-phoneme conversion.
In Proc. ACL, pages 96?103.
Martin Jansche and Richard Sproat. 2009. Named entity
transcription with pair n-gram models. In Proc. ACL-
IJCNLP Named Entities Workshop, pages 32?35.
Sittichai Jiampojamarn, Grzegorz Kondrak, and Tarek
Sherif. 2007. Applying many-to-many alignments
and Hidden Markov Models to letter-to-phoneme con-
version. In Proc. HLT-NAACL, pages 372?379.
Sittichai Jiampojamarn, Colin Cherry, and Grzegorz
Kondrak. 2008. Joint processing and discriminative
training for letter-to-phoneme conversion. In Proc.
ACL, pages 905?913.
Sittichai Jiampojamarn, Aditya Bhargava, Qing Dou,
Kenneth Dwyer, and Grzegorz Kondrak. 2009. Di-
recTL: a language independent approach to translitera-
tion. In Proc. ACL-IJCNLP Named Entities Workshop,
pages 28?31.
Haizhou Li, Min Zhang, and Jian Su. 2004. A joint
source channel model for machine transliteration. In
Proc. ACL, pages 159?166.
Haizhou Li, A Kumaran, Vladimir Pervouchine, and Min
Zhang. 2009. Report of NEWS 2009 machine translit-
eration shared task. In Proc. ACL-IJCNLP Named En-
tities Workshop, pages 1?18.
700
