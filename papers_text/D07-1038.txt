Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational
Natural Language Learning, pp. 360?368, Prague, June 2007. c?2007 Association for Computational Linguistics
Syntactic Re-Alignment Models for Machine Translation
Jonathan May
Information Sciences Institute
University of Southern California
Marina del Rey, CA 90292
jonmay@isi.edu
Kevin Knight
Information Sciences Institute
University of Southern California
Marina del Rey, CA 90292
knight@isi.edu
Abstract
We present a method for improving word
alignment for statistical syntax-based ma-
chine translation that employs a syntacti-
cally informed alignment model closer to
the translation model than commonly-used
word alignment models. This leads to ex-
traction of more useful linguistic patterns
and improved BLEU scores on translation
experiments in Chinese and Arabic.
1 Methods of statistical MT
Roughly speaking, there are two paths commonly
taken in statistical machine translation (Figure 1).
The idealistic path uses an unsupervised learning
algorithm such as EM (Demptser et al, 1977)
to learn parameters for some proposed translation
model from a bitext training corpus, and then di-
rectly translates using the weighted model. Some
examples of the idealistic approach are the direct
IBM word model (Berger et al, 1994; Germann
et al, 2001), the phrase-based approach of Marcu
and Wong (2002), and the syntax approaches of Wu
(1996) and Yamada and Knight (2001). Idealistic
approaches are conceptually simple and thus easy to
relate to observed phenomena. However, as more
parameters are added to the model the idealistic ap-
proach has not scaled well, for it is increasingly dif-
ficult to incorporate large amounts of training data
efficiently over an increasingly large search space.
Additionally, the EM procedure has a tendency to
overfit its training data when the input units have
varying explanatory powers, such as variable-size
phrases or variable-height trees.
The realistic path also learns a model of transla-
tion, but uses that model only to obtain Viterbi word-
for-word alignments for the training corpus. The
bitext and corresponding alignments are then used
as input to a pattern extraction algorithm, which
yields a set of patterns or rules for a second trans-
lation model (which often has a wider parameter
space than that used to obtain the word-for-word
alignments). Weights for the second model are then
set, typically by counting and smoothing, and this
weighted model is used for translation. Realistic ap-
proaches scale to large data sets and have yielded
better BLEU performance than their idealistic coun-
terparts, but there is a disconnect between the first
model (hereafter, the alignment model) and the sec-
ond (the translation model). Examples of realistic
systems are the phrase-based ATS system of Och
and Ney (2004), the phrasal-syntax hybrid system
Hiero (Chiang, 2005), and the GHKM syntax sys-
tem (Galley et al, 2004; Galley et al, 2006). For
an alignment model, most of these use the Aachen
HMM approach (Vogel et al, 1996), the implemen-
tation of IBM Model 4 in GIZA++ (Och and Ney,
2000) or, more recently, the semi-supervised EMD
algorithm (Fraser and Marcu, 2006).
The two-model approach of the realistic path has
undeniable empirical advantages and scales to large
data sets, but new research tends to focus on devel-
opment of higher order translation models that are
informed only by low-order alignments. We would
like to add the analytic power gained from mod-
ern translation models to the underlying alignment
model without sacrificing the efficiency and empiri-
cal gains of the two-model approach. By adding the
360
u n s u p e r v i s e d
l
e a r n i n g
t
a r g e
t
s e n
t
e n c e s
s o u r c e
s e n
t
e n c e s
u n w e i g h
t
e d
m o d e
l
w e i g h
t
e d
m o d e
l
p a
t t
e r n s
(
u n w e i g h
t
e d
m o d e
l )
c o u n
t
i n g
a n d
s m o o
t
h i n g
w e i g h
t
e d
m o d e
l
d e c o d e r
s o u r c e
s e n
t
e n c e s
t
a r g e
t
s e n
t
e n c e s
p a
t t
e r n
e x
t
r a c
t
i o n
t
a r g e
t
s e n
t
e n c e s
s o u r c e
s e n
t
e n c e s
V
i
t
e r b i
a
l
i g n m e n
t
s
I d e a l i s t i c
S y
s t e m
R e a l i s t i c
S y
s t e m
d e c o d e r
s o u r c e
s e n
t
e n c e s
t
a r g e
t
s e n
t
e n c e s
Figure 1: General approach to idealistic and realistic statistical MT systems
syntactic information used in the translation model
to our alignment model we may improve alignment
quality such that rule quality and, in turn, system
quality are improved. In the remainder of this work
we show how a touch of idealism can improve an
existing realistic syntax-based translation system.
2 Multi-level syntactic rules for syntax MT
Galley et al (2004) and Galley et al (2006) de-
scribe a syntactic translation model that relates En-
glish trees to foreign strings. The model describes
joint production of a (tree, string) pair via a non-
deterministic selection of weighted rules. Each rule
has an English tree fragment with variables and a
corresponding foreign string fragment with the same
variables. A series of rules forms an explanation (or
derivation) of the complete pair.
As an example, consider the parsed English and
corresponding Chinese at the top of Figure 2. The
three columns underneath the example are different
rule sequences that can explain this pair; there are
many other possibilities. Note how rules specify ro-
tation (e.g. R10, R5), direct translation (R12, R8),
insertion and deletion (R11, R1), and tree traversal
(R7, R15). Note too that the rules explain variable-
size fragments (e.g. R6 vs. R14) and thus the possi-
ble derivation trees of rules that explain a sentence
pair have varying sizes. The smallest such deriva-
tion tree has a single large rule (which does not ap-
pear in Figure 2; we leave the description of such
a rule as an exercise for the reader). A string-to-
tree decoder constructs a derivation forest of deriva-
tion trees where the right sides of the rules in a tree,
taken together, explain a candidate source sentence.
It then outputs the English tree corresponding to the
highest-scoring derivation in the forest.
3 Introducing syntax into the alignment
model
We now lay the ground for a syntactically motivated
alignment model. We begin by reviewing an align-
ment model commonly seen in realistic MT systems
and compare it to a syntactically-aware alignment
model.
3.1 The traditional IBM alignment model
IBM Model 4 (Brown et al, 1993) learns a set of 4
probability tables to compute p(f |e) given a foreign
sentence f and its target translation e via the follow-
ing (greatly simplified) generative story:
361
NP-C
NPB
NPB
NNP
taiwan
POS
?s
NN
surplus
PP
IN
in
NP-C
NPB
NN
trade
PP
IN
between
NP-C
NPB
DT
the
CD
two
NNS
shores
? l ? ? ? ? 4 ? ~ ?
TAIWAN IN TWO-SHORES TRADE MIDDLE SURPLUS
R1: NP-C
NPB
x0:NPB x1:NN
x2:PP
? x0 x2 ? x1 R10: NP-C
NPB
x0:NPB x1:NN
x2:PP
? x0 x2 x1 R10: NP-C
NPB
x0:NPB x1:NN
x2:PP
? x0 x2 x1
R2: NPB
NNP
taiwan
POS
?s
? ? l R11: NPB
x0:NNP POS
?s
? x0 R17: NPB
NNP
taiwan
x0:POS
? x0
R12: NNP
taiwan
? ? l R18: POS
?s
? ? l
R3: PP
x0:IN x1:NP-C
? x0 x1 R13: PP
IN
in
x0:NP-C
? ? x0 ? R19: PP
IN
in
x0:NP-C
? x0
R4: IN
in
? ?
R5: NP-C
x0:NPB x1:PP
? x1 x0 R5: NP-C
x0:NPB x1:PP
? x1 x0 R20: NP-C
x0:NPB PP
x1:IN x2:NP-C
? x2 x0 x1
R6: PP
IN
between
NP-C
NPB
DT
the
CD
two
NNS
shores
? ? ? R14: PP
IN
between
x0:NP-C
? x0 R21: IN
between
? ?
R15: NP-C
x0:NPB
? x0 R15: NP-C
x0:NPB
? x0
R16: NPB
DT
the
CD
two
NNS
shores
? ? ? R22: NPB
x0:DT CD
two
x1:NNS
? x0 x1
R23: NNS
shores
? ? ? R24: DT
the
? ?
R7: NPB
x0:NN
? x0 R7: NPB
x0:NN
? x0 R7: NPB
x0:NN
? x0
R8: NN
trade
? ? 4 R9: NN
surplus
? ~ ? R8: NN
trade
? ? 4 R9: NN
surplus
? ~ ? R8: NN
trade
? ? 4 R9: NN
surplus
? ~ ?
Figure 2: A (English tree, Chinese string) pair and three different sets of multilevel tree-to-string rules that
can explain it; the first set is obtained from bootstrap alignments, the second from this paper?s re-alignment
procedure, and the third is a viable, if poor quality, alternative that is not learned.
362
S-C
NP-C
NPB
NNP
guangxi
POS
?s
VP
VBG
opening
PRT
RP
up
PP
TO
to
NP-C
NPB
DT
the
JJ
outside
NN
world
 ? ? i  8
GUANGXI OUTSIDE-WORLD OPENING-UP
R24: S-C
NP-C
NPB
x0:NNP POS
?s
VP
VBG
opening
PRT
RP
up
PP
TO
to
NP-C
NPB
DT
the
JJ
outside
NN
world
? x0 ? i  8 R25: NNP
guangxi
?  ?
R26: S-C
x0:NP-C x1:VP
? x0 x1 R15: NP-C
x0:NPB
? x0 R11: NPB
x0:NNP POS
?s
? x0 R27: VP
VBG
opening
PRT
RP
up
x0:PP
? x0  8
R28: PP
TO
to
x0:NP-C
? x0 R15: NP-C
x0:NPB
? x0 R29: NPB
DT
the
JJ
outside
NN
world
? ? i R25: NNP
guangxi
?  ?
Figure 3: The impact of a bad alignment on rule extraction. Including the alignment link indicated by the
dotted line in the example leads to the rule set in the second row. The re-alignment procedure described in
Section 3.2 learns to prefer the rule set at bottom, which omits the bad link.
1. A fertility y for each word ei in e is chosen
with probability pfert(y|ei).
2. A null word is inserted next to each
fertility-expanded word with probability
pnull.
3. Each token ei in the fertility-expanded
word and null string is translated into
some foreign word fi in f with probability
ptrans(fi|ei).
4. The position of each foreign word
fi that was translated from ei is
changed by ? (which may be posi-
tive, negative, or zero) with probability
pdistortion(?|A(ei),B(fi)), where A and
B are functions over the source and target
vocabularies, respectively.
Brown et al (1993) describes an EM algorithm
for estimating values for the four tables in the gener-
ative story. However, searching the space of all pos-
sible alignments is intractable for EM, so in practice
the procedure is bootstrapped by models with nar-
rower search space such as IBM Model 1 (Brown et
al., 1993) or Aachen HMM (Vogel et al, 1996).
363
3.2 A syntax re-alignment model
Now let us contrast this commonly used model for
obtaining alignments with a syntactically motivated
alternative. We recall the rules described in Section
2. Our model learns a single probability table to
compute p(etree, f) given a foreign sentence f and
a parsed target translation etree. In the following
generative story we assume a starting variable with
syntactic type v.
1. Choose a rule r to replace v, with proba-
bility prule(r|v).
2. For each variable with syntactic type vi in
the partially completed (tree, string) pair,
continue to choose rules ri with probabil-
ity prule(ri|vi) to replace these variables
until there are no variables remaining.
In Section 5.1 we discuss an EM learning proce-
dure for estimating these rule probabilities.
As in the IBM approach, we must miti-
gate intractability by limiting the parameter space
searched, which is potentially much wider than in
the word-to-word case. We would like to supply to
EM all possible rules that explain the training data,
but this implies a rule relating each possible tree
fragment to each possible string fragment, which is
infeasible. We follow the approach of bootstrapping
from a model with a narrower parameter space as is
done in, e.g. Och and Ney (2000) and Fraser and
Marcu (2006).
To reduce the model space we employ the rule ac-
quisition technique of Galley et al (2004), which
obtains rules given a (tree, string) pair as well as
an initial alignment between them. We are agnos-
tic about the source of this bootstrap alignment and
in Section 5 present results based on several differ-
ent bootstrap alignment qualities. We require an ini-
tial set of alignments, which we obtain from a word-
for-word alignment procedure such as GIZA++ or
EMD. Thus, we are not aligning input data, but
rather re-aligning it with a syntax model.
4 The appeal of a syntax alignment model
Consider the example of Figure 2 again. The left-
most derivation is obtained from the bootstrap align-
ment set. This derivation is reasonable but there are
some poorly motivated rules, from a linguistic stand-
point. The Chinese word ? ? roughly means ?the
SENTENCE PAIRS
DESCRIPTION CHINESE ARABIC
TUNE NIST 2002 short 925 696
TEST NIST 2003 919 663
Table 1: Tuning and testing data sets for the MT
system described in Section 5.2.
two shores? in this context, but the rule R6 learned
from the alignment incorrectly includes ?between?.
However, other sentences in the training corpus have
the correct alignment, which yields rule R16. Mean-
while, rules R13 and R14, learned from yet other
sentences in the training corpus, handle the ? ... ?
structure (which roughly translates to ?in between?),
thus allowing the middle derivation.
EM distributes rule probabilities in such a way as
to maximize the probability of the training corpus.
It thus prefers to use one rule many times instead
of several different rules for the same situation over
several sentences, if possible. R6 is a possible rule
in 46 of the 329,031 sentence pairs in the training
corpus, while R16 is a possible rule in 100 sentence
pairs. Well-formed rules are more usable than ill-
formed rules and the partial alignments behind these
rules, generally also well-formed, become favored
as well. The top row of Figure 3 contains an exam-
ple of an alignment learned by the bootstrap align-
ment model that includes an incorrect link. Rule
R24, which is extracted from this alignment, is a
poor rule. A set of commonly seen rules learned
from other training sentences provide a more likely
explanation of the data, and the consequent align-
ment omits the spurious link.
5 Experiments
In this section, we describe the implementation of
our semi-idealistic model and our means of evaluat-
ing the resulting re-alignments in an MT task.
5.1 The re-alignment setup
We begin with a training corpus of Chinese-English
and Arabic-English bitexts, the English side parsed
by a reimplementation of the standard Collins model
(Bikel, 2004). In order to acquire a syntactic rule set,
we also need a bootstrap alignment of each training
sentence. We use an implementation of the GHKM
364
BOOTSTRAP GIZA CORPUS RE-ALIGNMENT EXPERIMENT
ENGLISH WORDS CHINESE WORDS TYPE RULES TUNE TEST
9,864,294 7,520,779
baseline 19,138,252 39.08 37.77
initial 18,698,549 39.49 38.39
adjusted 26,053,341 39.76 38.69
Table 2: A comparison of Chinese BLEU performance between the GIZA baseline (no re-alignment), re-
alignment as proposed in Section 3.2, and re-alignment as modified in Section 5.4
algorithm (Galley et al, 2004) to obtain a rule set for
each bootstrap alignment.
Now we need an EM algorithm for learn-
ing the parameters of the rule set that maximize
?
corpus
p(tree, string). Such an algorithm is pre-
sented by Graehl and Knight (2004). The algorithm
consists of two components: DERIV, which is a pro-
cedure for constructing a packed forest of derivation
trees of rules that explain a (tree, string) bitext cor-
pus given that corpus and a rule set, and TRAIN,
which is an iterative parameter-setting procedure.
We initially attempted to use the top-down DE-
RIV algorithm of Graehl and Knight (2004), but as
the constraints of the derivation forests are largely
lexical, too much time was spent on exploring dead-
ends. Instead we build derivation forests using the
following sequence of operations:
1. Binarize rules using the synchronous bina-
rization algorithm for tree-to-string trans-
ducers described in Zhang et al (2006).
2. Construct a parse chart with a CKY parser
simultaneously constrained on the foreign
string and English tree, similar to the
bilingual parsing of Wu (1997) 1.
3. Recover all reachable edges by traversing
the chart, starting from the topmost entry.
Since the chart is constructed bottom-up, leaf lex-
ical constraints are encountered immediately, result-
ing in a narrower search space and faster running
time than the top-down DERIV algorithm for this
application. Derivation forest construction takes
around 400 hours of cumulative machine time (4-
processor machines) for Chinese. The actual run-
ning of EM iterations (which directly implements
the TRAIN algorithm of Graehl and Knight (2004))
1In the cases where a rule is not synchronous-binarizable
standard left-right binarization is performed and proper permu-
tation of the disjoint English tree spans must be verified when
building the part of the chart that uses this rule.
takes about 10 minutes, after which the Viterbi
derivation trees are directly recoverable. The Viterbi
derivation tree tells us which English words produce
which Chinese words, so we can extract a word-
to-word alignment from it. We summarize the ap-
proach described in this paper as:
1. Obtain bootstrap alignments for a training
corpus using GIZA++.
2. Extract rules from the corpus and align-
ments using GHKM, noting the partial
alignment that is used to extract each rule.
3. Construct derivation forests for each (tree,
string) pair, ignoring the alignments, and
run EM to obtain Viterbi derivation trees,
then use the annotated partial alignments
to obtain Viterbi alignments.
4. Use the new alignments as input to the MT
system described below.
5.2 The MT system setup
A truly idealistic MT system would directly apply
the rule weight parameters learned via EM to a ma-
chine translation task. As mentioned in Section 1,
we maintain the two-model, or realistic approach.
Below we briefly describe the translation model, fo-
cusing on comparison with the previously described
alignment model. Galley et al (2006) provides a
more complete description of the translation model
and DeNeefe et al (2007) provides a more complete
description of the end-to-end translation pipeline.
Although in principle the re-alignment model and
translation model learn parameter weights over the
same rule space, in practice we limit the rules used
for re-alignment to the set of smallest rules that ex-
plain the training corpus and are consistent with the
bootstrap alignments. This is a compromise made
to reduce the search space for EM. The translation
model learns multiple derivations of rules consistent
with the re-alignments for each sentence, and learns
365
(a) Chinese re-alignment corpus has 9,864,294 English and 7,520,779 Chinese words
BOOTSTRAP GIZA CORPUS RE-ALIGNMENT EXPERIMENT
ENGLISH WORDS CHINESE WORDS TYPE RULES TUNE TEST
9,864,294 7,520,779 baseline 19,138,252 39.08 37.77
re-alignment 26,053,341 39.76 38.69
221,835,870 203,181,379 baseline 23,386,535 39.51 38.93
re-alignment 33,374,646 40.17 39.96
(b) Arabic re-alignment corpus has 4,067,454 English and 3,147,420 Arabic words
BOOTSTRAP GIZA CORPUS RE-ALIGNMENT EXPERIMENT
ENGLISH WORDS ARABIC WORDS TYPE RULES TUNE TEST
4,067,454 3,147,420 baseline 2,333,839 47.92 47.33
re-alignment 2,474,737 47.87 47.89
168,255,347 147,165,003 baseline 3,245,499 49.72 49.60
re-alignment 3,600,915 49.73 49.99
Table 3: Machine Translation experimental results evaluated with case-insensitive BLEU4.
weights for these by counting and smoothing. A
dozen other features are also added to the rules. We
obtain weights for the combinations of the features
by performing minimum error rate training (Och,
2003) on held-out data. We then use a CKY decoder
to translate unseen test data using the rules and tuned
weights. Table 1 summarizes the data used in tuning
and testing.
5.3 Initial results
An initial re-alignment experiment shows a reason-
able rise in BLEU scores from the baseline (Table
2), but closer inspection of the rules favored by EM
implies we can do even better. EM has a tendency
to favor few large rules over many small rules, even
when the small rules are more useful. Referring to
the rules in Figure 2, note that possible derivations
for (taiwan ?s, ? l)2 are R2, R11-R12, and R17-
R18. Clearly the third derivation is not desirable,
and we do not discuss it further. Between the first
two derivations, R11-R12 is preferred over R2, as
the conditioning for possessive insertion is not re-
lated to the specific Chinese word being inserted.
Of the 1,902 sentences in the training corpus where
this pair is seen, the bootstrap alignments yield the
R2 derivation 1,649 times and the R11-R12 deriva-
tion 0 times. Re-alignment does not change the re-
sult much; the new alignments yield the R2 deriva-
tion 1,613 times and again never choose R11-R12.
The rules in the second derivation themselves are
2The Chinese gloss is simply ?taiwan?.
not rarely seen ? R11 is in 13,311 forests other than
those where R2 is seen, and R12 is in 2,500 addi-
tional forests. EM gives R11 a probability of e?7.72
? better than 98.7% of rules, and R12 a probability
of e?2.96. But R2 receives a probability of e?6.32
and is preferred over the R11-R12 derivation, which
has a combined probability of e?10.68.
5.4 Making EM fair
The preference for shorter derivations containing
large rules over longer derivations containing small
rules is due to a general tendency for EM to pre-
fer derivations with few atoms. Marcu and Wong
(2002) note this preference but consider the phe-
nomenon a feature, rather than a bug. Zollmann
and Sima?an (2005) combat the overfitting aspect
for parsing by using a held-out corpus and a straight
maximum likelihood estimate, rather than EM. We
take a modeling approach to the phenomenon.
As the probability of a derivation is determined by
the product of its atom probabilities, longer deriva-
tions with more probabilities to multiply have an in-
herent disadvantage against shorter derivations, all
else being equal. EM is an iterative procedure and
thus such a bias can lead the procedure to converge
with artificially raised probabilities for short deriva-
tions and the large rules that comprise them. The
relatively rare applicability of large rules (and thus
lower observed partial counts) does not overcome
the inherent advantage of large coverage. To com-
bat this, we introduce size terms into our generative
story, ensuring that all competing derivations for the
366
LANGUAGE PAIR TYPE RULES TUNE TEST
CHINESE-ENGLISH baseline 55,781,061 41.51 40.55EMD re-align 69,318,930 41.23 40.55
ARABIC-ENGLISH baseline 8,487,656 51.90 51.69EMD re-align 11,498,150 51.88 52.11
Table 4: Re-alignment performance with semi-supervised EMD bootstrap alignments
same sentence contain the same number of atoms:
1. Choose a rule size s with cost csize(s)s?1.
2. Choose a rule r (of size s) to replace the
start symbol with probability prule(r|s, v).
3. For each variable in the partially com-
pleted (tree, string) pair, continue to
choose sizes followed by rules, recur-
sively to replace these variables until there
are no variables remaining.
This generative story changes the derivation com-
parison from R2 vs R11-R12 to S2-R2 vs R11-R12,
where S2 is the atom that represents the choice of
size 2 (the size of a rule in this context is the number
of non-leaf and non-root nodes in its tree fragment).
Note that the variable number of inclusions implied
by the exponent in the generative story above en-
sures that all derivations have the same size. For ex-
ample, a derivation with one size-3 rule, a derivation
with one size-2 and one size-1 rule, and a deriva-
tion with three size-1 rules would each have three
atoms. With this revised model that allows for fair
comparison of derivations, the R11-R12 derivation
is chosen 1636 times, and S2-R2 is not chosen. R2
does, however, appear in the translation model, as
the expanded rule extraction described in Section 5.2
creates R2 by joining R11 and R12.
The probability of size atoms, like that of rule
atoms, is decided by EM. The revised generative
story tends to encourage smaller sizes by virtue of
the exponent. This does not, however, simply ensure
the largest number of rules per derivation is used in
all cases. Ill-fitting and poorly-motivated rules such
as R22, R23, and R24 in Figure 2 are not preferred
over R16, even though they are smaller. However,
R14 and R16 are preferred over R6, as the former
are useful rules. Although the modified model does
not sum to 1, it leads to an improvement in BLEU
score, as can be seen in the last row of Table 2.
5.5 Results
We performed primary experiments on two different
bootstrap setups in two languages: the initial exper-
iment uses the same data set for the GIZA++ initial
alignment as is used in the re-alignment, while an
experiment on better quality bootstrap alignments
uses a much larger data set. For each bootstrap-
ping in each language we compared the baseline
of using these alignments directly in an MT sys-
tem with the experiment of using the alignments ob-
tained from the re-alignment procedure described in
Section 5.4. For each experiment we report: the
number of rules extracted by the expanded GHKM
algorithm of Galley et al (2006) for the translation
model, converged BLEU scores on the tuning set,
and finally BLEU performance on the held-out test
set. Data set specifics for the GIZA++ bootstrapping
and BLEU results are summarized in Table 3.
5.6 Discussion
The results presented demonstrate we are able to
improve on unsupervised GIZA++ alignments by
about 1 BLEU point for Chinese and around 0.4
BLEU point for Arabic using an additional unsu-
pervised algorithm that requires no human aligned
data. If human-aligned data is available, the EMD
algorithm provides higher baseline alignments than
GIZA++ that have led to better MT performance
(Fraser and Marcu, 2006). As a further experi-
ment we repeated the experimental conditions from
Table 3, this time bootstrapped with the semi-
supervised EMD method, which uses the larger
bootstrap GIZA corpora described in Table 3 and
an additional 64,469/48,650 words of hand-aligned
English-Chinese and 43,782/31,457 words of hand-
aligned English-Arabic. The results of this advanced
experiment are in Table 4. We show a 0.42 gain in
BLEU for Arabic, but no movement for Chinese. We
believe increasing the size of the re-alignment cor-
pora will increase BLEU gains in this experimental
367
condition, but leave those results for future work.
We can see from the results presented that the im-
pact of the syntax-aware re-alignment procedure of
Section 3.2, coupled with the addition of size param-
eters to the generative story from Section 5.4 serves
to remove links from the bootstrap alignments that
cause less useful rules to be extracted, and thus in-
crease the overall quality of the rules, and hence the
system performance. We thus see the benefit to in-
cluding syntax in an alignment model, bringing the
two models of the realistic machine translation path
somewhat closer together.
Acknowledgments
We thank David Chiang, Steve DeNeefe, Alex
Fraser, Victoria Fossum, Jonathan Graehl, Liang
Huang, Daniel Marcu, Michael Pust, Oana Pos-
tolache, Michael Pust, Jason Riesa, Jens Vo?ckler,
and Wei Wang for help and discussion. This re-
search was supported by NSF (grant IIS-0428020)
and DARPA (contract HR0011-06-C-0022).
References
Adam Berger, Peter Brown, Stephen Della Pietra, Vin-
cent Della Pietra, John Gillett, John Lafferty, Robert
Mercer, Harry Printz, and Lubos? Ures?. 1994. The
candide system for machine translation. In Proc. HLT,
pages 157?162, Plainsboro, New Jersey, March.
Daniel Bikel. 2004. Intricacies of Collins? parsing
model. Computational Linguistics, 30(4):479?511.
Peter F. Brown, Vincent J. Della Pietra, Stephen A. Della
Pietra, and Robert L. Mercer. 1993. The mathemat-
ics of statistical machine translation: parameter esti-
mation. Computational Linguistics, 19(2):263?311.
David Chiang. 2005. A hierarchical phrase-based model
for statistical machine translation. In Proc. ACL, pages
263?270, Ann Arbor, Michigan, June.
Arthur P. Demptser, Nan M. Laird, and Donald B. Ru-
bin. 1977. Maximum likelihood from incomplete data
via the EM algorithm. Journal of the Royal Statistical
Society, Series B, 39(1):1?38.
Steve DeNeefe, Kevin Knight, Wei Wang, and Daniel
Marcu. 2007. What can syntax-based MT learn from
phrase-based MT? In Proc. EMNLP/CONLL, Prague,
June.
Alexander Fraser and Daniel Marcu. 2006. Semi-
supervised training for statistical word alignment. In
Proc. COLING-ACL, pages 769?776, Sydney, July.
Michel Galley, Mark Hopkins, Kevin Knight, and Daniel
Marcu. 2004. What?s in a translation rule? In Proc.
HLT-NAACL, pages 273?280, Boston, May.
Michel Galley, Jonathan Graehl, Kevin Knight, Daniel
Marcu, Steven DeNeefe, Wei Wang, and Ignacio
Thayer. 2006. Scalable inference and training of
context-rich syntactic models. In Proc. COLING-
ACL, pages 961?968, Sydney, July.
Ulrich Germann, Michael Jahr, Kevin Knight, Daniel
Marcu, and Kenji Yamada. 2001. Fast decoding and
optimal decoding for machine translation. In Proc.
ACL, pages 228?235, Toulouse, France, July.
Jonathan Graehl and Kevin Knight. 2004. Training tree
transducers. In Proc. HLT-NAACL, pages 105?112,
Boston, May.
Daniel Marcu and William Wong. 2002. A phrase-based,
joint probability model for statistical machine transla-
tion. In Proc. EMNLP, pages 133?139, Philadelphia,
July.
Franz Och and Hermann Ney. 2000. Improved statisti-
cal alignment models. In Proc. ACL, pages 440?447,
Hong Kong, October.
Franz Och and Hermann Ney. 2004. The alignment tem-
plate approach to statistical machine translation. Com-
putational Linguistics, 30(4):417?449.
Franz Och. 2003. Minimum error rate training for sta-
tistical machine translation. In Proc. ACL, pages 160?
167, Sapporo, Japan, July.
Stephan Vogel, Hermann Ney, and Christoph Tillmann.
1996. HMM-based word alignment in statistical trans-
lation. In Proc. COLING, pages 836?841, Copen-
hagen, August.
Dekai Wu. 1996. A polynomial-time algorithm for sta-
tistical machine translation. In Proc. ACL, pages 152?
158, Santa Cruz, California, June.
Dekai Wu. 1997. Stochastic inversion transduction
grammars and bilingual parsing of parallel corpora.
Computational Linguistics, 23(3):377?404.
Kenji Yamada and Kevin Knight. 2001. A syntax-based
statistical translation model. In Proc. ACL, pages 523?
530, Toulouse, France, July.
Hao Zhang, Liang Huang, Daniel Gildea, and Kevin
Knight. 2006. Synchronous binarization for machine
translation. In Proc. HLT-NAACL, pages 256?263,
New York City, June.
Andreas Zollmann and Khalil Sima?an. 2005. A consis-
tent and efficient estimator for data-oriented parsing.
Journal of Automata, Languages and Combinatorics,
10(2/3):367?388.
368
