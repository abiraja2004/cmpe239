An Efficient Kernel for Multilingual Generation in 
Speech-to-Speech Dialogue Translation 
T i lman Becker  and Wol fgang F ink le r  and Anne K i lger  and Peter  Po l le r  
German Research Center for Artificial Intelligence (DFKI  GmbH) 
Stuhlsatzenhausweg 3 
D-66123 Saarbriicken 
Germany 
becker~dfk i .de ,  f ink le r~dfk i .de ,  k i lgerOdfk i .de ,  po l le r~dfk i .de  
Abst rac t  
We present core aspects of a fully implemented 
generation component in a multilingual speech- 
to-speech dialogue translation system. Its de- 
sign was particularly influenced by the neces- 
sity of real-time processing and usability for 
multiple languages and domains. We devel- 
oped a general kernel system comprising a mi- 
croplanning and a syntactic realizer module. 
Tile microplanner performs lexical and syntac- 
tic choice, based on constraint-satisfaction tech- 
niques. The syntactic realizer processes HPSG 
grammars reflecting the latest developments of
the underlying linguistic theory, utilizing their 
pre-processing into the TAG formalism. The 
declarative nature of the knowledge bases, i.e., 
the microplanning constraints and the HPSG 
grammars allowed an easy adaption to new do- 
mains and languages. The successful integra- 
tion of our component into the translation sys- 
tem Verbmobil proved the fulfillment of the spe- 
cific real-time constraints. 
1 In t roduct ion  
In this paper we present core aspects of the mul- 
tilingual natural language generation compo- 
nent VM-GECO 1 that has been integrated into 
the research prototype of Verbmobil (Wahlster, 
1993; Bub et al, 1997), a system for sponta- 
neous speech-to-speech dialog translation. 
In order to achieve multilinguality as ele- 
gantly as possible we found that a clear modu- 
lar separation between a language-independent 
general kernel generator and language-specific 
parts which consist of syntactic and lexical 
knowledge sources was a very promising ap- 
proach. Accordingly, our generation component 
1VM-GECO is an acronym for "VerbMobil GEnera- 
tion COmponents." 
consists of one kernel generator and language- 
specific knowledge sources for the languages 
used in Verbmobih German and English with 
current work on Japanese. 
Additionally, the kernel generator itself can 
be modularized furthermore into two separate 
components. The task of the so-called mi- 
eroplanning component is to plan an utterance 
on a phrase- or sentence-level (Hovy, 1996) in- 
cluding word-choice (section 2). It generates an 
annotated ependency structure which is used 
by the syntactic generation component to re- 
alize an appropriate surface string for it (sec- 
tion 3). The main goal of this further modular- 
ization is a stepwise constraining of the search- 
space of alternative linguistic realizations, using 
abstracted views on different choice criteria. 
Multilingual generation in dialog translation 
imposes trong requirements on the generation 
module. A very prominent problem is the non- 
wellformedness (incorrectness, irrelevance, and 
inconsistency) of spontaneous input. It forces 
the realization of robust generation to be able 
to cope with erroneous and incomplete input 
data so that the quality of the generated out- 
put may vary between syntactically correct sen- 
tences and semantically understandable utter- 
ances. On the level of knowledge sources this 
is achieved by using a highly declarative HPSG 
grammar which very closely reflects the latest 
developments of the underlying linguistic the- 
ory (Pollard and Sag, 1994) and covers phe- 
nomena of spoken language. This HPSG is 
compiled into a TAG grammar in an offtine 
pre-Processing step (Kasper et al, 1995) which 
keeps the declarative nature of the grammar in- 
tact (section 3). 
Maybe the most important requirement on 
the generation module of a speech-to-speech 
translation system is real-time processing. The 
110 
above mentioned features of VM-GECO con- 
tribute to the efficiency of the generation com- 
ponent. The TAG-formalism is well known for 
the existence of efficient syntactic generation al- 
gorithms (Kilger and Finkler, 1995). 
In general, all knowledge sources of all mod- 
ules are declarative. The main advantage is 
that this allows for an easier adaptation of the 
generation component to other domains, lan- 
guages and semantic representation languages 
besides the easier extendability of the current 
system. The feasibility of the language adap- 
tation was proved in the Verbmobil project it- 
self where the (originally English) generator was 
recently extended to cover German and is cur- 
rently adapted for Japanese. The adaptation 
to another domain and also to another specifi- 
cation language for intermediate structures was 
shown in another translation project which uses 
in contrast o Verbmobil an interlingua based 
approach (section 4.1). 
2 The  Mic rop lanner  
A generation system for target language utter- 
ances in an approach to speech-to-speech trans- 
lation has to work on input elements represent- 
ing intermediate results of recognition, analy- 
sis, and transfer components. In that setting, 
several of the tasks of a complete natural an- 
guage generation system such as selection and 
organization of the contents to be expressed are 
outside of the control of our generator. They 
have been decided by the human user of the 
translation system or they have been negoti- 
ated and computed by a transfer component. 
Nevertheless, there remain a number of different 
but highly interrelated subtasks of the genera- 
tion process where decisions have to be made 
in order to determine and realize the trans- 
lation result to be sent to a speech synthesis 
component. The diverse subtasks - -  often col- 
lectively denoted as microplanning (cf. (Levelt, 
1989; Hovy, 1996)) - -  comprise the planning 
of a rough structure of the target language ut- 
terance, the determination of sentence borders, 
sentence type, topicalization, theme-rheme or- 
ganization of sentential units, focus control, uti- 
lization of nominalized, or infinitival style, as 
well as triggering the generation of anaphora 
and lexical choice. In addition, they have to 
address the problem of expressibility of the se- 
lected contents in a text realization component, 
i.e., bridging the generation gap (see (Meteer, 
1990)). 
The input to our microplanning component 
consists of semantic representations encoded in 
a minimal recursive structure following a vari- 
ant of UDRT. Each individual indicated by 
some input utterance is formally represented by 
a discourse referent. Information about the in- 
dividual is encoded within the DRS-conditions. 
Relations between descriptions of different dis- 
course referents lead to a hierarchical semantic 
structure (see Figure 1 for a graphical represen- 
tation of fragments of an example input to the 
generator). Discourse referents are depicted as 
boxes headed by individual names in; conditions 
are illustrated within those boxes. 
\[ \]  
mm _ \[\]  / Im 
==> {1151416 IS} 
\ [ \ ]  
temp_loc {i213} 
workjcceptable 12 
arg3 {i214} 
perspective {i2 I1) 
;em_Groul 
1,3 I,,o. 13 I ~ ~ ' ~  
Itll demonstrative {i3 It2 ht 1) J 
Figure 1: Example Input to the Generator 
Besides these input terms from the transfer 
component, the generator may access knowl- 
edge about the dialogue act, the dialogue his- 
tory as well as some prosodic information of the 
user's utterance. 
The output of the microplanner is a sentence 
plan that serves as input for the syntactic real- 
ization component. It describes a dependency 
tree over lexical items annotated with syntac- 
tic, semantic, and pragmatic information which 
is relevant o produce an acceptable utterance 
and guide the speech synthesis component. 
2.1 Des ign of the  M ic rop lann ing  Kerne l  
An important design principle of our generator 
is the demand to cope with multidirectional de- 
pendencies among decisions of the diverse sub- 
tasks of microplanning without preferring one 
111 
order of decisions over others. E.g., the choice 
of an interrogative sentence requires an (at least 
elliptical) verbal phrase as a major constituent 
of the sentence; nominalization or the choice 
of passive voice depends on the result of word 
choice, etc. Therefore, we conceived microplan- 
ning as a constraint-satisfaction problem (Ku- 
mar, 1992) representing undirected relations be- 
tween variables. Thereby, variables are created 
for elements in the input to the generator. They 
are connected by means of weighted constraints. 
The domains of the variables correspond to ab- 
stractions of possible alternatives for syntactic 
realizations of the semantic elements including 
sets of specifications of lexical items and syntac- 
tic features. A solution of the constraint system 
is a globally consistent instantiation of the vari- 
ables and is guaranteed to be a valid input for 
the syntactic generation module. Since there 
might be locally optimal mappings that lead to 
contradiction on a global level, the microplan- 
net generally uses these weighted constraints to 
direct a backtracking or propagation process. 
One the one hand, the advantages of utiliz- 
ing a constraint system lie in the declarativ- 
ity of the knowledge sources allowing for an 
easier adaptation of the system to other do- 
mains and languages. We benefited from this 
design decision and realized microplanning for 
English and German by means of merely estab- 
lishing new rule sets for lexical and syntactic 
choice. The core engine for constraint process- 
ing was reused without modification. On the 
other hand, having defined a suitable represen- 
tation of the problem to be solved, a constraint- 
based approach also establishes a testbed for 
examining the pros and cons of different eval- 
uation methods, including backtracking, con- 
straint propagation, heuristics for the order of 
the instantiation of variable values, to name a 
few means of dealing with competition among 
alternatives and to find a solution. 
The microplanner makes use of the minimal 
recursive structure of its semantic input term 
(see Fig. 1) by triggering activities by bundles of 
conditions, discourse referents, and holes repre- 
senting underspecified scope relations in the in- 
put. These three input categories are reflected 
by different microplanning rule sets that are ap- 
plied conjointly during the process of microplan- 
ning. The rules are represented as pattern- 
condition-action triples. A pattern is to be 
matched with part of the input, a condition 
describes additional context-dependent require- 
ments to be fulfilled by the input, and the ac- 
tion part describes a bundle of syntactic features 
realizing lexical entities and their relations to 
complements and modifiers. 
A microplanning rule for the combination of 
the semantic predicates WORK_ACCEPTABLE, ARG3, 
and PERSPECTIVE which get realized as a finite 
verb, i.e., representing a 3:1 mapping of se- 
mantic predicates to a syntactic specification is
shown in Figure 2. 
; ;  s tandard  f in i te  verb  w i th  2 complements  
((WORK_ACCEPTABLE (L I) ARG3 (L 1 12) ;; pattern 
PERSPECTIVE (L% I I3)) 
($not ($sem-match NOM (L I))) ;; condition 
(WORK_ACCEPTABLE (CAT V) ;; action 
(HEAD (OR SUIT_V1 SUIT_V2)) (FORM ordinary) 
(TENSE Sget-tense I) (VOICE Sget-voice I)) 
(I2 (GENDER (NOT MAS FEM))) 
(REGENT-DEP-FUNC WORK_ACCEPTABLE 12 AGENT) 
(REGENT-DEP-FUNC WORK_ACCEPTABLE 13 PATIENT) 
(KEY KEY-V) ) 
; ; nominalized form . . . 
Figure 2: Example Microplanning Content Rule 
In the condition part of the verbal mapping 
the existence of a NOM-condition within the se- 
mantic input information is tested. It would 
forbid the verbal form by demanding a nomi- 
nalized form. The action part describes the re- 
sult of lexical selection (the lemma "suit") plus 
generic functions for computing relevant syntac- 
tic features like tense and voice. I2 which stands 
for the ARG3 of WORK_ACCEPTABLE, defined by a 
database of linking-information as the semantic 
agent is characterized as neither allowing gen- 
der masc(uline) nor fem(inine) for preventing 
"he suits" in the sense of "he is okay". En- 
tries starting with KEY define identifiers used for 
computing the preference value of a microplan- 
ning rule with respect to the given situation. 
In an additional database, KEYs are associated 
with weights for predefined situation character- 
istics such as time pressure, or register. The 
microplanning content rules are not directly en- 
tered by a rule writer but are compiled off-line 
from several knowledge sources for lexical choice 
rules, rules for syntactic decisions and linking 
rules, thereby filtering out contradictory combi- 
nations without requiring on-line runtime. 
Regarding the sets of alternatives that result 
112 
from the application of the microplanning rules, 
the most direct way of realizing a constraint 
net seems to be the definition of one variable 
for each condition, discourse referent, and hole, 
leading to a variable net as shown in Figure 3. 
Figure 3: Variable Net for Microplanning 
For our task, it is not enough to define bi- 
nary matching constraints between each pair 
of variables that purely test the compatibility 
of the described syntactic features. Some syn- 
tactic specifications may contain identifications 
of further entities, e.g., discourse referents and 
syntactic identifiers which influence the result 
of the compatibility test between a pair of vari- 
ables referring to these identifiers. Thus, the 
constraint net is not easily subdivided into sub- 
nets that can be efficiently evaluated. The large 
number of combinations of alternative values is 
handled by known means for CSP such as unit- 
ing variables with 1-value domains and apply- 
ing matching mechanisms to their values, com- 
putation of 2-consistency by matching value 
pairs and filtering out inconsistent ones, storing 
and reusing knowledge about binary incompat- 
ibility and performing intelligent backtracking. 
The result of the constraint solving process 
for the input shown in Fig. 1 is given in Fig. 4. 
L21-QUEST 
(intention w/i-question) ~clau=e 
(real hs) (cat utt.par) 
L -WORK_ACCEP+AB'E 
\ 
/ ==gent/(voice active) \ .. ~ temp =pe? 
~'/ / (head(  . . . .  it_vl ~patient "~- - '  
L6-TEMP_LOC / suit2)) "~ "~ 
(head whenl) / (tensefut.) L10-PRON L15-TEMP_LOC 
(wh-focus t) / (cat v) (pers 2a) (head then adv) 
(cat adv) ~ (cat ppron) (cat adv) 
L13-PRON (aura s$) 
(pers 3) 
(cat ppron) 
(hum sg) 
Figure 4: Microplanning Result for the Example 
3 The  Rea l i zer  
The syntactic realizer 2 proceeds from the mi- 
croplanning result as shown in Figure 5. It pro- 
duces a derived phrase structure from which the 
output string is read off. The realizer is based 
on a fully lexicalized grammar in the sense that 
every lexical item selects for a finite set of possi- 
ble phrase structures (called elementary trees). 
In particular, we use a Feature-Based Lexical- 
ized Tree-Adjoining Grammar (FB-LTAG, see 
(Vijay-Shanker and Joshi, 1988; Schabes et at., 
1988)) that is derived from an HPSG grammar 
(see section 4 for some more details). The el- 
} ementary trees (see Figure 9) can be seen as 
maximal partial projections. A derivation of an 
utterance is constructed by combining appro- 
priate elementary trees with the two elementary 
TAG operations of adjunction and substitution. 
For each node (i.e., lexical item) in the de- 
pendency tree, the tree selection phase deter- 
mines the set of relevant TAG trees. A first 
tree retrieval step maps every object of the 
dependency tree into a set of applicable ele- 
mentary TAG trees. The main tree selection 
phase uses information from the microplanner 
output to further refine the set of retrieved 
trees. The combination phase finds a success- 
ful combination of trees to build a (derived) 
phrase structure tree. The final inflection phase 
uses the information in the feature structures 
of the leaves (i.e., the words) to apply appro- 
priate morphological functions. An initial pre- 
processing phase is needed to accommodate he 
handling of auxiliaries which are not determined 
in microplanning. They are derived from the 
tense, aspect and sentence mood information as 
supplied by microplanning. 
(expand ,vxiliazi=s) (adj~lining ~id ~ubstiIUilOll) 
l ~ g 
- 'AG 
Figure 5: Steps of the syntactic generator. 
The two core phases are the tree selection and 
2A more detailed escription iscontained in (Becker, 
1998). 
113 
the combination phase. The tree selection is 
driven by the HPSG instance or word class that 
is supplied by the microplanner. It is mapped to 
a lexical type by a lexicon that is automatically 
compiled from the HPSG grammar. The lexi- 
cal types are then mapped to a tree family, i.e., 
a set of elementary TAG trees representing all 
possible minimally complete phrase structures 
that can be build from the instance. The ad- 
ditional information in the dependency tree is 
then used to add further feature values to the 
trees. This additional information acts as a fil- 
ter for selecting appropriate trees in two stages: 
Some values are incompatible with values al- 
ready present in the trees. These trees can 
therefore be filtered immediately from the set. 
E.g., a syntactic structure for an imperative 
clause is marked as such by a feature and can 
be discarded if a declarative sentence is to be 
generated. Additional features can prevent he 
combination with other trees during the combi- 
nation phase. This is the case, e.g., with agree- 
ment features. 
The combination phase completely belongs to 
the core machinery. It can be exchanged with 
more efficient algorithms without change of the 
grammar or lexicon. It explores the search space 
of all possible combinations of trees from the 
candidate sets for each lexical item (instance). 
Since there is sufficient information available 
from the microplanner result and from the trees, 
a well-guided best-first search strategy can be 
employed in the current system. 
As part of the tree selection phase, based on 
the rich annotation of the input structure, the 
tree sets are sorted locally such that preferred 
trees are tested first. Then a modified back- 
tracking algorithm traverses the dependency 
tree in a bottom-up fashion a. At each node and 
for each subtree in the dependency tree, a can- 
didate for the phrase structure of the subtree 
is constructed. Then all possible adjunction or 
substitution sites are computed, possibly sorted 
(e.g., allowing for preferences in word order) and 
the best candidate for a combined phrase struc- 
ture is returned. Since the combination of two 
partial phrase structures by adjunction or sub- 
stitution might fail due to incompatible feature 
structures, a backtracking algorithm must be 
3The algorithm stores intermediate r sults with a 
memoization technique. 
used. A partial phrase structure for a subtree of 
the dependency is finally checked for complete- 
ness. These tests include the unifiability of all 
top and bottom feature structures and the satis- 
faction of all other constraints (e.g., obligatory 
adjunctions or open substitution odes) since 
no further adjunctions or substitutions will oc- 
cur in this subtree. 
The necessity of a spoken dialog translation 
system to robustly produce output calls for 
some relaxations in these tests. E.g., 'obliga- 
tory' arguments may be missing in the utter- 
ance. This can be caused by ellipsis in sentences 
such as "Ok, we postpone." or by false segmen- 
tations in the analysis uch as segmenting "Wit 
soIlten (we should) das Treffen verschieben (the 
meeting postpone)." into two segments "Wit 
sollten" and "das Treffen verschieben". In order 
to generate "postpone the meeting" for the sec- 
ond segment, the tests in the syntactic genera- 
tor must accept a phrase with a missing subject 
if no other complete phrase can be generated. 
Figure 6 shows a combination of the tree 
retrieval and the tree selection phases. In 
the tree retrieval phase for L5-WORK.ACCEPTABLE, 
first the HEAD information is used to determine 
the lexical types of the possible realizations 
SUIT_Vl and SUIT_V2, namely MV_NP_TRANS_LE 
and MV_EXPL_PREP_TRANSIE respectively 4. These 
types are then mapped to their respective sets of 
elementary trees, a total of 25 trees. In the tree 
selection phase, this number is reduced to six. 
For example, the tree MV_NP_TRANS_LE.2 in 
Figure 9 has a feature C\[_-MODE with the value 
IMPERATIVE. Now, the microplanner output 
for the root entity LGVI contains the informa- 
tion (INTENTION WH-QUESTION). The INTENTION 
information is unified with all appropriate CL- 
MODE features, which in this case fails. There- 
fore the tree MV_NP_TRANS_LE.2 is discarded 
in the tree selection phase. 
The combination phase uses the best-first 
bottom-up algorithm described above to deter- 
mine one suitable tree for every entity and also 
a target node in the tree that is selected for the 
governing entity. For the above example, the 
selected trees and their combination odes are 
4MV_NP_TRANS_LE is an abbreviation for "Main Verb, 
NP object, TRANSitive Lexical Entry" used in sentences 
like "Monday suits me." 
114 
; ;  traverse for: LS-WORK_ACCEPTABLE 
returned MV_NP_TRANS_LE 
returned MV_EXPL_PREP_TRANS_LE 
total: 6 trees 
;; traverse for: LI3-PRON 
returned PERS_PRO_LE 
total: 1 tree 
;; traverse for: LIO-PRON 
returned PERS_PR0_LE 
total: I tree 
; traverse for: L6-TEMP L0C 
returned WH_ADVERB_W0RD_LE 
total: 2 trees 
traverse for: LI5-TEMP_LOC 
returned NP_ADV_WORD LE 
total: 5 trees 
; traverse for: LGVI 
returned WILL_AUX_P0S_LE 
total: 2 trees 
Figure 6: An excerpt from the tree retrieval and 
selection phase. 
shown in Figure 75 . 
s o. - - - - - .  
,"  S/ADV " ' .  " ' ,  A DV 
-" 
' -::: . . - I , -  . . . . . . . . . . .  ', 
" VP VP 
: v/%,4, ADV . " "  NP , 
I I ',--'" I I v l  I 
w~tesl ~vill il xldl you then 
L6 -'rEMP_LOC I~ lY l  LZ3-PRON L5-~JZT  LZO-Pl ION L15 -T I4(P_LOC 
Figure 7: The trees finally selected for the enti- 
ties of the example sentence. 
Figure 8 shows the final phrase structure for 
the example. The inflection function selects 
the base form of "suit" according to the BSE 
value of the VFORM feature and correctly uses 
"will." Information about the sentence mode 
WH-QUESTION can be used to annotate the re- 
sulting string for the speech-synthesis module. 
4 Resu l ts  
Our approach to separate a generation mod- 
ule into a language-independent kernel and 
language-specific knowledge sources has been 
successfully implemented in a dialogue trans- 
lation system. Furthermore, the mentioned 
adaptability to other generation tasks has also 
been proved by an adaptation of the generation 
module to a new application domain and also to 
a completely different semantic representation 
5Note that the node labels hown in Figures 7 and 8 
are only a concession toreadability. The TAG require- 
ment hat in an auxiliary tree the foot node must have 
the same category label as the root node is fulfilled. 
S 
ADV S/ADV 
I 
v.'he. V VPIADV 
I 
V NP VP 
I I 
wi l l  i t  VP ADV 
V NP then 
I i 
suit  you  
Figure 8: The final phrase structure for "When 
will it suit you then?" 
MV_NP TRANS LF - !  MV_NP_TRANS LF~2 MV NP TRANS_LE.3 MV NP TRANS LEA 
VP S S S 
MV NP_TRANS L| V NP J, 
l I I 
MV_NP TRAN$ LE MV NP_TRANS LE MV NP TRANS_LE 
Figure 9: Some of the trees for transitive verbs. 
They are compiled from the corresponding lex- 
ical type MV_NP_TRANS_LE as defined in the 
HPSG grammar. Trees 3 and 4 differ only with 
respect to their feature structures which are not 
shown in this figure. 
language by adapting the microplanning knowl- 
edge sources to the new formalism. 
VM-GECO is fully implemented (in Common 
Lisp) and integrated into the speech-to-speech 
translation system Verbmobil for two output 
languages, English and German. The adapta- 
tion to Japanese generation will be performed in
the current project phase. Our experience from 
adding German makes us confident hat this 
can be done straightforwardly b creating the 
appropriate knowledge sources without modi- 
fications of the kernel generator. To give the 
reader a more detailed impression of the im- 
plementation of the generation component we 
present some characteristic data of the English 
generator. The numbers for the German sys- 
tem, especially for lexicon and processing time, 
are similar. 
The underlying English grammar is a lexical- 
ized TAG which consists of 2844 trees. These 
trees were transformed uring an of\[line pre- 
processing step from 2961 HPSG lexical en- 
tries of the linguistically well motivated En- 
glish HPSG grammar written at CSLI. On 
the other hand the microplanner's knowledge 
sources consist of 2730 partially pre-processed 
microplanning rules which are utilized in an in- 
115 
tegrated handling of structural and lexical de- 
cisions based on constraint propagation. The 
microplanning rules are of course especially 
adapted to the underlying semantic represen- 
tation formalism. Furthermore, the underlying 
lexicon covers the word list that has been con- 
structed from a large corpus of the application 
domain of the Verbmobil system, i.e., negotia- 
tion dialogues in spontaneous speech. 
The TAG grammar esulting from the com- 
pilation step allows for highly efficient lexically 
driven robust syntactic generation mainly con- 
sisting of tree adjoinings, substitutions, and fea- 
ture unifications. The average overall genera- 
tion time per sentence (up to length 24) is 0.7 
seconds on a SUN ULTRA-1 machine, 68 % of 
the runtime are needed for the microplanning 
while the remaining 32 % of the runtime are 
needed for syntactic generation. 
4.1 Reus ing the Kerne l  
Beside the usability for multiple languages in 
Verbmobil our kernel generation component has 
also proven its adaptability to a very differ- 
ent semantic representation language (system- 
atically and terminologically) in another still 
ongoing multilingual (currently 12 languages) 
translation project. The project utilizes an 
interlingua-based approach to semantic rep- 
resentations of utterances. The goal of this 
project is to overcome the international lan- 
guage barrier which is exemplarily realized by a 
large corpus improvement ofthe transparency of 
consisting of international law texts. Our part 
in this project is the realization and implemen- 
tation of the German generation component. 
Because of our language-independent core gen- 
erator the adaptation of the generation compo- 
nent to this semantic representation decreased 
to the adaptation of the structural and lexi- 
cal knowledge bases of the microplanning com- 
ponent and appropriate domain-specific exten- 
sions on the lexicon of the syntactic generator. 
With an average sentence length of 15 words 
the average runtime per sentence on a SUN 
ULTRA-2 is less than 0.5 seconds. Currently, 
even the longest sentence (40 words) needs un- 
der 2 seconds runtime. 
Within Verbmobil, the generation component 
will also be used for text generation when pro- 
ducing protocols as described in (Alexandersson 
and Poller, 1998). 
References  
J. Alexandersson and P. Poller. 1998. Towards 
multilingual protocol generation for spon- 
taneous speech dialogues. In 9th INLGW, 
Niagara-on-the-lake, Canada. 
T. Becker. 1998. Fully lexicalized head- 
driven syntactic generation. In 9th INLGW, 
Niagara-on-the-lake, Canada. 
Th. Bub, W. Wahlster, and A. Waibel. 1997. 
Verbmobil: The combination of deep and 
shallow processing for spontaneous peech 
translation. In Proceedings of ICASSP '97. 
E. Hovy. 1996. An overview of automated natu- 
ral language generation. In X. Huang, editor, 
Proc. of the Intl. Symposium on NL Genera- 
tion and the Processing of the Chinese Lan- 
guage, INP(C)-96, Shanghai, China. 
R. Kasper, B. Kiefer, K. Netter, and K. Vijay- 
Shanker. 1995. Compilation of HPSG to 
TAG. In 33rd A CL, Cambridge, Mass. 
A. Kilger and W. Finkler. 1995. Incremen- 
tal generation for real-time applications. 
Research Report RR-95-11, DFKI GmbH, 
Saarbrficken, Germany, July. 
V. Kumar. 1992. Algorithms for constraint- 
satisfaction problems: A survey. AI Maga- 
zine, 13(1):32-44. 
W.J.M. Levelt. 1989. Speaking: From Intention 
to Articulation. The MIT Press, Cambridge, 
MA. 
M.W. Meteer. 1990. The "Generation Gap"- 
The Problem of Expressibility in Text Plan- 
ning. Ph.D. thesis, Amherst, MA. BBN Re- 
port No. 7347. 
C. Pollard and I. A. Sag. 1994. Head-Driven 
Phrase Structure Grammar. Studies in Con- 
temporary Linguistics. University of Chicago 
Press, Chicago. 
Y. Schabes, A. Abeill~, and A. K. Joshi. i988. 
Parsing strategies with 'lexicalized' gram- 
mars: Application to tree adjoining gram- 
mars. In COLING-88, pages 578-583, Bu- 
dapest, Hungary. 
K. Vijay-Shanker and A. K. Joshi. 1988. Fea- 
ture structure based tree adjoining rammars. 
In COLING-88, pages 714-719, Budapest, 
Hungary. 
W. Wahlster. 1993. Verbmobih Translation 
of face-to-face dialoges. In MT Summit IV, 
Kobe, Japan. 
116 
