A New Approach to Automatic Document Summarization 
Xiaofeng Wu 
National Laboratory of Pattern Recognition,  
Institute of Automation, 
Chinese Academy of Sciences 
Beijing, China 
xfwu@nlpr.ia.ac.cn 
Chengqing Zong 
National Laboratory of Pattern Recognition, 
Institute of Automation, 
Chinese Academy of Sciences 
Beijing, China 
cqzong@nlpr.ia.ac.cn 
 
 
Abstract 
In this paper we propose a new approach 
based on Sequence Segmentation Models 
(SSM) to the extractive document summa-
rization, in which summarizing is regarded 
as a segment labeling problem. Comparing 
with the previous work, the difference of 
our approach is that the employed features 
are obtained not only from the sentence 
level, but also from the segment level. In 
our approach, the semi-Markov CRF model 
is employed for segment labeling. The pre-
liminary experiments have shown that the 
approach does outperform all other tradi-
tional supervised and unsupervised ap-
proaches to document summarization. 
1 Introduction 
Document summarization has been a rapidly 
evolving subfield of Information Retrieval (IR) 
since (Luhn, 1958). A summary can be loosely 
defined as a text that is produced from one or more 
texts and conveys important information of the 
original text(s). Usually it is no longer than half of 
the original text(s) or, significantly less (Radev et 
al., 2002). Recently, many evaluation competitions 
(like the Document Understanding Conference 
DUC ?http://duc.nist.gov?, in the style of NIST?s 
TREC), provided some sets of training corpus. It is 
obvious that, in the age of information explosion, 
document summarization will be greatly helpful to 
the internet users; besides, the techniques it uses 
can also find their applications in speech tech-
niques and multimedia document retrieval, etc. 
The approach to summarizing can be catego-
rized in many ways. Some of them are: 1) indica-
tive, informative and evaluative, according to func-
tionality; 2) single-document and multi-document, 
according to the amount of input documents; 3) 
generic and query-oriented, according to applica-
tions. Yet the taxonomy currently widely em-
ployed is to categorize summarization into abstrac-
tive and extractive. 
According to (Radev et al, 2002), all methods 
that are not explicitly extractive are categorized as 
abstractive. These approaches include ontological 
information, information fusion, and compression. 
Abstract-based summarization never goes beyond 
conceptual stage, though ever since the dawn of 
summarization it has been argued as an alternative 
for its extract-based counterpart. On the other hand, 
extractive summarization is still attracting a lot of 
researchers (Yeh et al, 2005) (Daum?e III and 
Marcu, 2006) and many practical systems, say, 
MEAD ?http://www.summarization.com/mead/?, 
have been produced. Using supervised or unsuper-
vised machine learning algorithms to extract sen-
tences is currently the mainstream of the extractive 
summarization. However, all pervious methods 
focus on obtaining features from the sentence gra-
nularity. 
In this paper we focus on generating summariza-
tion by using a supervised extractive approach in 
which the features are obtained from a larger gra-
nularity, namely segment. The remainder of the 
paper is organized as follows: Section 2 introduces 
the related work concerning the extract-based 
summarization. Section 3 describes our motiva-
tions. Our experiments and results are given in 
Section 4, and Section 5 draws the conclusion and 
mentions the future work. 
126
2 Related Work 
Early researchers approached the summarization 
problem by scoring each sentence with a combina-
tion of the features like word frequency and distri-
bution, some proper names (Luhn, 1958), sentence 
positions in a paragraph (Baxendale, 1958), and 
sentence similarity (Gong, 2001) etc. The results 
were comparatively good. Most supervised extrac-
tive methods nowadays focus on finding powerful 
machine learning algorithms that can properly 
combine these features. 
Bayesian classifier was first applied to summari-
zation by (Pedersen and Chen, 1995), the authors 
claimed that the corpus-trained feature weights 
were in agreement with (Edmundson, 1969), which 
employed a subjective combination of weighted 
features. Another usage of the na?ve Bayesian 
model in summarization can be found in (Aone et 
al., 1997). Bayesian model treats each sentence 
individually, and misses the intrinsic connection 
between the sentences. (Yeh et al, 2005) employed 
genetic algorithm to calculate the belief or score of 
each sentence belonging to the summary, but it 
also bears this shortcoming. 
To overcome this independence defect, (Conroy 
and O?leary, 2001) pioneered in deeming this prob-
lem as a sequence labeling problem. The authors 
used HMM, which has fewer independent assump-
tions. However, HMM can not handle the rich lin-
guistic features among the sentences either. Re-
cently, as CRF (Lafferty and McCallum, 2001) has 
been proved to be successful in part-of-speech tag-
ging and other sequence labeling problems, (Shen 
et al, 2007) attempted to employ this model in 
document summarization. CRF can leverage all 
those features despite their dependencies, and ab-
sorb other summary system?s outcome. By intro-
ducing proper features and making a comparison 
with SVM, HMM, etc., (Shen et al, 2007) claimed 
that CRF could achieve the best performance. 
All these approaches above share the same 
viewpoint that features should be obtained at sen-
tence level. Nevertheless, it can be easily seen that 
the non-summary or summary sentences tend to 
appear in a consecutive manner, namely, in seg-
ments. These rich features of segments can surely 
not be managed by those traditional methods.  
Recently, Sequence Segmentation Model (SSM) 
has attracted more and more attention in some 
traditional sequence learning tasks. SSM builds a 
direct path to encapsulate the rich segmental 
features (e.g., entity length and the similarity with 
other entities, etc., in entity recognition). Semi-
CRF (Sarawagi and Cohen, 2004) is one of the 
SSMs, and generally outperforms CRF. 
3 Motivations 
According to the analysis in Section 2, our basic 
idea is clear that we regard the supervised summa-
rizing as a problem of sequence segmentation. 
However, in our approach, the features are not only 
obtained on the sentence level but also on the seg-
ment level.  
Here a segment means one or more sentences 
sharing the same label (namely, non-summary or 
summary), and a text is regarded as a sequence of 
segments. Semi-CRF is a qualified model to ac-
complish the task of segment labeling, besides it 
shares all the virtues of CRF. Using semi-CRF, we 
can easily leverage the features both in traditional 
sentence level and in the segment level. Some fea-
tures, like Log Likelihood or Similarity, if obtained 
from each sentence, are inclined to give unex-
pected results due to the small granularity. Fur-
thermore, semi-CRF is a generalized version of 
CRF. The features designed for CRF can be used 
in semi-CRF directly, and it has been proved that 
semi-CRF outperforms CRF in some Natural Lan-
guage Processing (NLP) problems (Sarawagi and 
Cohen, 2004).  
In the subsections below, we first introduce 
semi-CRF then describe the features we used in 
our approach. 
3.1 Semi-CRF 
CRF was first introduced in (Lafferty and 
McCallum, 2001). It is a conditional model P(Y|X), 
and here both X and Y may have complex structure. 
The most prominent merits of CRF are that it 
offers relaxation of the strong independence 
assumptions made in HMM or Maximum Entropy 
Markov Models (MEMM) (McCallum, 2000) and 
it is no victim of the label bias problem. Semi-CRF 
is a generalization version of sequential CRF. It 
extends CRF by allowing each state to persist for a 
non-unit length of time. After this time has elapsed, 
the system might transmit to a new state, which 
only depends on its previous one. When the system 
is in the ?segment of time?, it is allowed to behave 
non-Markovianly. 
127
3.1.1 CRF vs. Semi-CRF 
Given an observed sentence sequence 
X=(x1,x2,?,xM). The corresponding output labels 
are Y=(y1,y2,?,yM), where yi gets its value from a 
fixed set ?. For document summarization, 
?={0,1}. Here 1 for summary and 0 for non-
summary. The goal of CRF is to find a sequence of 
Y, that maximize the probability: 
      
1
( | , ) exp( ( , ))
( )
P Y X W W F X Y
Z X
= ?          (1) 
Here?  is a vertical vector of 
size T. The vertical vector 
1
( , ) f ( , , )
M
i
F X Y i X Y==?
1 2
'f ( , , ..., )Tf f f= means 
there are T feature functions, and each of them can 
be written as ft(i,X,Y)?R,t?(1,?,T),i?(1,?,M). 
For example, in our experiment the 10th feature 
function is expressed as: [if the length of current 
sentence is bigger than the predefined threshold 
value]&[if the current sentence is a summary]. 
When this feature function is acting upon the third 
sentence in text_1 with label_sequence_1, the fol-
lowing feature equation f10(3,text_1, la-
bel_sequence_1) means: in text_1 with la-
bel_sequence_1, [if the length of the third sentence 
is bigger than the predefined threshold value]&[if 
the third sentence is a summary]. W is a horizontal 
vector of size T that represents the weights of these 
features respectively. Equation (2) gives the defini-
tion of Z(X), which is a normalization constant that 
makes the probabilities of all state sequences sum 
to 1. 
'( ) exp( ( , '))YZ X W F X= ?? Y
|
     (2) 
If we change the sequence vector X to 
S=<s1,s2,?,sN>, which means one way to split X 
into N segments, we have the semi-CRF. Each 
element in S is a triple: Sj=<tj,uj,yj>, which de-
notes the jth segment in this way of segmentation. 
In the triple, tj denotes the start point of the jth seg-
ment, uj denotes its end position, and yj is the out-
put label of the segment (recall the example at the 
beginning of this subsection that there is only one 
output for a segment). Under this definition, seg-
ments should have no overlapping, and satisfy the 
following conditions: 
1
| | |
N
j
js X=
=?                                    (3) 
    (4) 1 11, | |,1 | |, 1N j j jt u X t u X t u+= = ? ? ? = +
Here, |?| denotes the length of?. 
 
Figure 1  A 10-sentences text with label sequence 
 
For example, one way to segment a text of 10 sen-
tences in Figure 1 is S=<(1,1,1),(2,4,0),(5,5,1), 
(6,9,0),(10,10,1)> . The circles in the second row 
represent sentences, and actually are only some 
properties of the corresponding sentences. 
Consequently, the feature function f in CRF 
converts to the segmental feature function 
g=(g1,g2,?,g T?). Like f, gt(i,x,s) ?R also maps a 
triple (i,x,s) to a real number. Similarly, we may 
define . Now we give the 
final equation used to estimate the probability of S.           
Given a sequence X and feature weight W, we have 
1
( , ) g( , , )
N
i
G X S i X S== ?
1
( | , ) exp( ( , ))
( )
P S X W W G X S
Z X
= ?          (5) 
Here,  
'
( ) exp( ( , '))
S
Z X W G X
??
= ? S?                 (6) 
Where, { }all segmentations allowed? = ? ? . 
3.1.2 Inference 
The inference or the testing problem of semi-CRF 
is to find the best S that maximizes Equation (5). 
We use the following Viterbi-like algorithm to cal-
culate the optimum path. 
Suppose the longest segment in corpus is K, let 
S1:i,y represent all possible segmentations starting 
from 1 to i , and the output of the last segment is y. 
V(i,y) denotes the biggest value of P(S?|X,W). Note 
that it?s also the largest value of W?G(X,S?), 
S??S1:i,y. 
Compared with the traditional Viterbi algorithm 
used in CRF, the inference for semi-CRF is more 
time-consuming. But by studying Algorithm 1, we 
can easily find out that the cost is only linear in K. 
j
128
      
3.1.3 Parameter Estimation 
Define the following function 
log ( | , )
( ( , ) log (    
lW l l
l l l l
L P S X W
W G X S Z X
= ?
= ? ?? ))   (8) 
In this approach, the problem of parameter estima-
tion is to find the best weight W that maximizes LW. 
According to (Bishop, 2006), the Equation (8) is 
convex. So it can be optimized by gradient ascent. 
Various methods can be used to do this work (Pie-
tra et al 1997). In our system, we use L-BFGS, a 
quasi-Newton algorithm (Liu and Nocedal. 1989), 
because it has the fast converging speed and effi-
cient memory usage. APIs we used for estimation 
and inference can be found in website 
?http:\\crf.sourcefourge.net?. 
3.2 Features 
(Shen et al 2007) has made a thorough investiga-
tion of the performances of CRF, HMM, and SVM. 
So, in order to simplify our work and make it com-
parable to the previous work, we shape our desig-
nation of features mainly under their framework.  
The mid column in Table 1 lists all of the fea-
tures we used in our semi-CRF approach. For the 
convenience of comparison, we also list the name 
of the features used in (Shen et al 2007) in the 
right column, and name them Regular Features. 
The features in bold-face in the mid column are the 
corresponding features tuned to fit for the usage of 
semi-CRF. We name them Extended Features. 
There are some features that are not in bold-face in 
the mid column. These features are the same as the 
Regular Features in the right column. We also 
used them in our approach. The mark star denotes 
that there is no counterpart. We number these fea-
tures in the left column.  Algorithm 1: 
Step1. Initialization: 
 Let V i  ( , ) 0,  0
 
No. semi-CRF CRF 
1 Ex_Position        Position 
2 Ex_Length         Length 
3 Ex_Log_Likelihood  Log Likeli-hood 
 
4 
Ex_Similarity_to_ 
Neighboring_   
Segments           
Similarity to 
Neighboring 
Sentences 
5 Ex_Segment_ 
Length     * 
6 Thematic           Thematic  
7 Indicator           Indicator  
8 Upper Case         Upper Case  
y for i= =
Step2. Induction: 
 0for i >   
', 1,...,( , ) max ( , ')
           g( , ', , 1, )
y k KV i y V i k y
W y y x i d i
== ?
+ ? ? +         (7)  
Step3. Termination and path readout: 
       max (| |, )ybestSegment V X y=
               Table 1. Features List 
The details of the features we used in semi-
CRF are explained as follow. 
Extended Features: 
Ex_Position: is an extended version of the Po-
sition feature. It gives the description of the po-
sition of a segment in the current segmentation. 
If the sentences in the current segment contain 
the beginning sentence of a paragraph, the value 
of this feature will be 1, 2 if it contains the end 
of a paragraph; and 3 otherwise; 
Ex_Length: the number of words in the cur-
rent segment after removing some stop-words. 
Ex_Log_Likelihood: the log likelihood of the 
current segment being generated by the docu-
ment. We use Equation (9) below to calculate 
this feature. N(wj,si) denotes the number of oc-
currences of the word wj in the segment si, and 
we use ( , ) / ( , )
k
j w k
N w D N w D?  to estimate the 
probability of a word being generated by a doc-
ument. 
log ( | ) ( , ) log ( | )
j
i j iw j
P s D N w s p w D=?      (9) 
Ex_Similarity_to_Neighboring_Segments: 
we define the cosine similarity based on the 
TF*IDF (Frakes &Baeza-Yates, 1992) between 
a segment and its neighbors. But unlike (Shen et 
al. 2007), in our work only the adjacent neighbors 
of the segment in our work are considered. 
EX_Segment_Length: this feature describes 
the number of sentences contained in a segment. 
129
All these features above are actually an ex-
tended version used in the regular CRF (or in 
other supervised model). It is easy to see that, if 
the segment length is equal to 1, then the fea-
tures will degrade to their normal forms.  
There are some features that are also used in 
semi-CRF but we don?t extend them like those 
features above. Because the extended version of 
these features leads to no improvement of our 
result. These features are: 
Regular features we used: 
Thematic: with removing of stop words, we 
define the words with the highest frequency in 
the document to be the thematic words. And this 
feature gives the count of these words in each 
sentence. 
Indicator: indicative words such as ?conclu-
sion? and ?briefly speaking? are very likely to be 
included in summary sentences, so we define 
this feature to signal if there are such words in a 
sentence. 
Upper Case: some words with upper case are 
of high probability to be a name, and sentences 
with such words together with other words 
which the author might want to emphasize are 
likely to be appeared in a summary sentence. So 
we use this feature to indicate whether there are 
such words in a sentence. 
It should be noted that theoretically the num-
ber of extended features obtained from the cor-
pus goes linearly with K in Equation (7). 
 
4 Experiments 
4.1 Corpus & Evaluation Criteria 
To evaluate our approach, we applied the widely 
used test corpus of (DUC2001), which is spon-
sored by ARDA and run by NIST 
?http://www.nist.gov?. The basic aim of DUC 
2001 is to further progress of summarization and 
enable researchers to participate into large-scale 
experiments. The corpus DUC2001 we used con-
tains 147 news texts, each of which has been la-
beled manually whether a sentence belongs to a 
summary or not. Because in (Shen et al 2007) all 
the experiments were conducted upon DUC2001, 
we may make a comparison between the sequence 
labeling models and the sequence segmentation 
modes we used. The only preprocessing we did is 
to remove some stop words according to a stop 
word list.  
We use F1 score as the evaluation criteria which is 
defined as: 
2*Precesion*Recall
1
Precesion+Recall
F =                 (10) 
We used 10-fold cross validation in order to reduce 
the uncertainty of the model we trained. The final 
F1 score reported is the average of all these 10 ex-
periments. 
All those steps above are strictly identical to the 
work in (Shen et al 2007), and its result is taken as 
our baseline. 
4.2 Results & Analysis 
As we mentioned in Sub-Section 3.2, those ex-
tended version of features only work when seg-
ment length is bigger than one. So, each of these 
extended version of features or their combination 
can be used together with all the other regular fea-
tures listed in the right column in Table 1. In order 
to give a complete test of the capacity of all these 
extended features and their combinations, we do 
the experiments according to the power set of {1, 2, 
3, 4, 5} (the numbers are the IDs of these extended 
features as listed in Table 1), that is we need to do 
the test 25-1 times with different combinations of 
the extended features. The results are given in Ta-
ble 2. The rows with italic fonts (1, 3, 5, 7, 9, 11, 
13), in Table 2 denote the extended features used. 
For example, ?1+2? means that the features 
Ex_Positon and the Ex_Length are together used 
with all other regular features are used.  
Table 2. Experiment results. 
 1 2 3 4 5 
F1 0.395 0.391 0.398 0.394 0.392 
 1+2 1+3 1+4 1+5 2+3 
F1 0.395 0.396 0.396 0.395 0.382 
 2+4 2+5 3+4 3+5 4+5 
F1 0.389 0.384 0.398 0.399 0.380 
 1+2+3 1+2+4 1+2+5 1+3+4 1+3+5
F1 0.398 0.397 0.393 0.403 0.402 
 1+4+5 2+3+4 2+3+5 2+4+5 3+4+5
F1 0.402 0.403 0.401 0.403 0.404 
 1+2 +3+4 
1+2 
+3+5 
1+2 
+4+5 
1+3 
+4+5 
2+3 
+4+5 
F1 0.407 0.404 0.406 0.402 0.404 
 All CRF 
F1 0.406 0.389 
130
Other rows (2, 4, 6, 8, 10, 12, 14) give F1 scores 
corresponding to the features used. 
     In Table 3 we compare our approach with some 
of the most popular unsupervised methods, includ-
ing LSA (Frakes & Baeza-Yates, 1992) and HITS 
(Mihalcea 2005). The experiments were conducted 
by (Shen et al 2007). 
Table 3 Comparison with unsupervised methods 
 
From the results in Table 2 we can see that indi-
vidually applying these extended features can im-
prove the performance somewhat. The best one of 
these extended features is feature 3, as listed in the 
2nd row, the 5th column. The highest improvement, 
1.8%, is obtained by combining the features 1, 2, 3 
and 4. Although a few of the combinations hurt the 
performance, most of them are helpful. This veri-
fies our hypothesis that the extended features under 
SSM have greater power than the regular features. 
The results in Table 3 demonstrate that our ap-
proach significantly outperforms the traditional 
unsupervised methods. 8.3% and 4.9% improve-
ments are respectively gained comparing to LSA 
and HITS models 
Currently, the main problem of our method is 
that the searching space goes large by using the 
extended features and semi-CRF, so the training 
procedure is time-consuming. However, it is not so 
unbearable, as it has been proved in (Sarawagi and 
Cohen, 2004). 
5 Conclusion and Future Work 
In this paper, we exploit the capacity of semi-CRF , 
we also make a test of most of the common fea-
tures and their extended version designed for doc-
ument summarization. We have compared our ap-
proach with that of the regular CRF and some of 
the traditional unsupervised methods. The com-
parison proves that, because summary sentences 
and non-summary sentences are very likely to 
show in a consecutive manner, it is more nature to 
obtain features from a lager granularity than sen-
tence.  
In our future work, we will test this approach on 
some other well known corpus, try the complex 
features used in (Shen et al 2007), and reduce the 
time for training. 
 
Acknowledgements 
The research work described in this paper has been 
funded by the Natural Science Foundation of Chi-
na under Grant No. 60375018 and 60121302. 
     
References 
C.Aone, N. Charocopos, J. Gorlinsky. 1997. An 
Intelligent Multilingual Information Browsing and 
Retrieval System Using Information Extraction. In 
ANLP, 332-339. 
P.B. Baxendale. 1958. Man-made Index for Tech-
nical Literature -An Experiment. IBM Journal of 
Research and Development, 2(4):354-361.  
C.M. Bishop. 2006. Linear Models for Classifica-
tion, Pattern Recognition and Machine Learning, 
chapter 4, Springer. 
J. M. Conroy and D. P. O?leary. 2001. Text Sum-
marization via Hidden Markov Models. In SIGIR, 
406-407. 
Hal Daum?e III, and D. Marcu.  2006. Bayesian 
Query- Focused Summarization, In ACL 
H. P. Edmundson. 1969. New Methods in Auto-
matic Extracting. Journal of the Association for 
Computing Machinery, 16(2):264-285. 
W. B. Frakes, R. Baeza-Yates, 1992, Information 
Retrieval Data Structures & Algorithms. Prentice 
Hall PTR, New Jersey  
Y. H. Gong and X. Liu. 2001. Generic text summa-
rization using relevance measure and latent seman-
tic analysis. In SIGIR, 19-25 
J. Kupiec, J. Pedersen, and F. Chen. 1995. A 
Trainable Document Summarizer. Research and 
Development in Information Retrieval, 68-73 
J. D. Lafferty, A. McCallum and F. C. N. Pereira. 
2001. Conditional random fields: probabilistic 
models for segmenting and labeling sequence data. 
ICML, 282-289. 
D. C. Liu and J. Nocedal. 1989. On the limited 
memory BFGS method for large-scale optimiza-
tion. Mathematic Programming, 45:503-528. 
H. P. Luhn. 1958. The Automatic Creation of Lit-
erature Abstracts. IBM Journal of Research and 
Development, 2(2): 159 -165. 
 LSA HITS Seim-CRF 
F1 0.324 0.368 0.407 
131
A. McCallum, D. Freitag, and F. Pereira. 2000. 
Maximum entropy Markov models for information 
extraction and segmentation. In ICML, 591-598 
Mihalcea R. Mihalcea. 2005. Language independ-
ent extractive summarization. In AAAI, 1688-1689 
S. D. Pietra, V. D. Pietra, and J. D. Lafferty. 1997. 
Inducing features of random fields. IEEE Tran. on 
Pattern Analysis and Machine Intelligence, 
19(:)380?393. 
D. R. Radev, E. Hovy and K. McKeown. 2002. 
Introduction to the Special Issue on Summarization. 
Computational Linguistics, 28(4): 399-408.  
S. Sarawagi and W.W. Cohen. 2004. Semi-markov 
conditional random fields for information extrac-
tion.In NIPS 
D. Shen, J. T. Sun, H. Li, Q. Yang, Z. Chen. 2007. 
Document Summarization using Conditional Ran-
dom Fields? In IJCAI, 1805-1813 
J. Y. Yeh, H. R. Ke, W. P. Yang and I. H. Meng. 
2005. Text summarization using trainable summar-
izer and latent semantic analysis. IPM, 41(1): 75?
95  
 
132
