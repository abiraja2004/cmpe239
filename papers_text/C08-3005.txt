Coling 2008: Companion volume ? Posters and Demonstrations, pages 161?164
Manchester, August 2008
?Build Your Own? Spoken Dialogue Systems:
Automatically Generating ISU Dialogue Systems from Business User
Resources
Oliver Lemon, Xingkun Liu, and Helen Hastie
School of Informatics
University of Edinburgh
Informatics Forum
10 Crichton Street
Edinburgh, EH8 9AB
{olemon,xliu4,hhastie}@inf.ed.ac.uk
Abstract
Building effective spoken dialogue sys-
tems (SDS) is currently a complex task
requiring expert knowledge. Our tools
give control of SDS application develop-
ment to non-experts, who need only use
a Graphical User Interface or GUI to de-
velop state-of-the-art ?Information State
Update? (ISU) dialogue systems. Behind
the GUI is a set of Advanced Dialogue
Tools (ADT) that generate complete SDS
based on Business User Resources. These
resources include a database and a Pro-
cess Model that captures the structure of
an application, for example, banking or
restaurant information. Also generated
are speech recognition Language Models
and grammars for robust interpretation of
spontaneous speech. We will demonstrate
how our simple GUI allows developers to
easily and quickly create and modify SDS
without the need for expensive speech ap-
plication service providers. This demon-
stration shows the interface, the ADT com-
ponents, and discusses some of the re-
search issues involved. We also show an
example application built with the tools: a
tourist information system running on an
ultra-mobile PC.
1 Introduction
As automated call centres are becoming more and
more commonplace, new challenges are emerg-
ing such as having to rely on expensive service
c
? 2008. Licensed under the Creative Commons
Attribution-Noncommercial-Share Alike 3.0 Unported li-
cense (http://creativecommons.org/licenses/by-nc-sa/3.0/).
Some rights reserved.
providers to build systems, the inability to quickly
and easily modify live systems, and the time and
cost needed to create new SDS applications. This
paper describes a solution to these problems using
our Advanced Dialogue Tools (ADT). This pro-
totype system allows developers to take already
established business user resources such as Busi-
ness Process Models (BPM) and databases, and
use them to automatically generate spoken dia-
logue systems. Simple customisations can then
be made through the easy-to-use ADT interface or
GUI, which is example-driven. This radically new
way of creating spoken dialogue systems will put
control into the hands of the business user who is
familiar with customer needs and business goals,
thus improving usability and making spoken dia-
logue systems more widely and rapidly available.
Currently, VoiceXML is widely used for such
tasks. However, VoiceXML applications are dif-
ficult to build and maintain, because develop-
ers must anticipate and represent every possi-
ble dialogue path in the finite-state VoiceXML
model. ADT will generate VoiceXML dynami-
cally, but the easy-to-use interface allows devel-
opers to select, deploy, and monitor different ad-
vanced dialogue strategies without needing to code
VoiceXML directly. We apply the ?Information
State Update? (ISU) approach (Lemon, 2004) that
enables more robust, flexible and natural conver-
sations than VoiceXML. ISU uses a more concise
and maintainable representation of dialogue flow,
based on rules operating over dialogue contexts,
which can generalise to unforeseen states.
2 The ADT Architecture
Figure 1 shows the ADT architecture whereby the
main algorithm takes business user resources and
databases as input and uses these to automatically
161
generate the spoken dialogue system. Figure 2
shows part of one such resource, namely a BPM
for hotel bookings. First the caller will hear an
introduction, then they will be asked what price
range they want, and then whether they want a ho-
tel in the centre of town or not. Advantages of us-
ing BPMs include the fact that graphical interfaces
and authoring environments are widely available
for them, for example: Eclipse, IBM Websphere-
Process Server, BEA WeblogicWorkshop etc.. In
addition, Business User Resources can contain a
lot of additional information as well as call flows
including context, multi-media, and multiple cus-
tomer interactions.
Figure 1: The ADT Architecture
Figure 2: Part of an example Business Process
Model for searching for Hotels
The resulting spoken dialogue system deploys
the following main modules:
? Speech Recogniser module, e.g. ATK/HTK
(Young, 2007; Young, 1995) or Nuance (Nu-
ance, 2002)
? Spoken Language Understanding module,
e.g. Grammatical Framework (GF) parser
(Ranta, 2004)
? BPM and Database modules
? Speech synthesiser e.g. Festival (Taylor et al,
1998) or Cereproc (Aylett and Pidcock, 2007)
2.1 Generic Dialogue Modelling
Sophisticated research systems have been devel-
oped only for specific applications and cannot be
easily transferred to another, even very similar task
or domain. The problem of components being do-
main specific is especially prevalent in the core
area of dialogue management. For example MIT?s
Pegasus and Mercury systems (Seneff, 2002) have
dialogue managers (DM) that use approximately
350 domain-specific hand-coded rules each. The
sheer amount of labour required to construct sys-
tems prevents them from being more widely and
rapidly deployed. Our solution uses BPMs and
related authoring tools to specify domain-specific
dialogue interactions which are combined with a
domain-general dialogue manager. Specifically,
the DM consults the BPM to determine what task-
based steps to take next, such as asking for a cin-
ema name. General aspects of dialogue, such as
confirmation and clarification strategies, are han-
dled by the domain-general DM. Values for con-
straints on transitions and branching in the BPM,
for example ?present insurance option if the user is
business-class?, are compiled into domain-specific
parts of the DM?s update rules. XML format is
used for BPMs, and they are compiled into finite
state machines consulted by the spoken dialogue
system through the BPM module. The domain-
general DM was mostly abstracted from the TALK
system (Lemon et al, 2006).
2.2 Compiling Grammars for Business User
Resources and Databases
For Spoken Language Understanding, ADT cur-
rently uses Grammatical Framework (GF) (Ranta,
2004) which is a language for writing multilingual
grammars, on top of which various applications
such as machine translation and human-machine
interaction have been built. A GF grammar not
only defines syntactic well-formedness, but also
semantic content.
Using ADT, system developers do not have to
write a single line of GF grammar code. The sys-
162
tem compiles all database entries and their proper-
ties into the appropriate ?slot-filling? parts of the
GF grammar for each specific BPM.
For example, a generated GF rule is:
Bpm generalTypeRule 4:
town info hotels name->Utt=>{ s = np.s}
This rule was generated because ?name? is a
database field for the subtask hotels in the
?town info? BPM. It specifies that all hotel names
are valid utterances.
A core GF grammar has been developed to cover
basic information-seeking interactions. This is
combined with a domain-specific grammar which
is automatically generated from the BPM, database
and the example utterances provided by the devel-
oper in the GUI. Finally, GF is a robust parser ? it
skips all disfluencies and unknown words to pro-
duce an interpretation of the user input if one ex-
ists.
2.3 Speech Recognition and Text To Speech
The grammars for Spoken Language Understand-
ing generated by ADT are also compiled to
grammar-based language models (LM) for speech
recognition. ADT is plug-and-play and adheres to
industry standards such as GSML, GrXML. This
allows for greater flexibility since the application
developer is not tied to one recogniser or TTS en-
gine. For this demonstration, the speech recog-
niser is ATK (Young, 2007; Young, 1995) and
the speech synthesiser is Cereproc (Aylett and Pid-
cock, 2007). Future work will involve automati-
cally generating context sensitive language models
(Lemon and Gruenstein, 2004).
2.4 ADT GUI
As mentioned above, the prototype ADT GUI can
be used to define system prompts and add likely
user responses to the grammar. Figure 3 shows the
developer associating ?spotter? phrases with sub-
tasks in the BPM. Here the developer is associating
the phrases ?hotels, hotel, stay, room, night, sleep?
and ?rooms? with the hotels task. This means that,
for example, if the user says ?I need a place to
stay?, the hotel-booking BPM will be triggered.
Note that multi-word phrases may also be defined.
The defined spotters are automatically compiled
into the GF grammar for parsing and speech recog-
nition. By default all the lexical entries for answer-
types for the subtasks will already be present as
Figure 3: Example: using the ADT GUI to define
?spotter? phrases for different BPM subtasks
spotter phrases. ADT also checks for possible am-
biguities, for example whether ?pizza? is a spot-
ter for both cuisine type for a restaurant task and
food type for a shopping task, and it uses clarifica-
tion sub-dialogues to resolve them at runtime.
Figure 4 shows the developer?s overview of the
subtasks of a BPM, in this case hotel information.
The developer can navigate this representation and
edit it to define prompts and manipulate the asso-
ciated databases.
Figure 4: Sub-dialogue structure generated from
the Hotel booking BPM
Figure 5 shows the developer specifying the
required linguistic information to automate the
ask price subtask of the hotels BPM. Here the de-
veloper specifies the system prompt for the infor-
mation ?Do you want something cheap or expen-
sive??; a phrase for implicit confirmation of pro-
vided values ?a [X] hotel?, where [X] is the seman-
tics of the speech recognition hypothesis for the
user input; and a clarifying phrase for this subtask
163
Figure 5: Example: using ADT to define prompts,
answer sets, and database mappings for the
ask price subtask of the BPM in Figure 4
?Do you mean the hotel price?? for use when dis-
ambiguating between two or more tasks. The de-
veloper also specifies here the answer type that will
resolve the system prompt. There are many pre-
defined answer-types extracted from the databases
associated with the BPM, and the developer can
select and/or edit these. Optionally, they can give
additional example phrases that users might say
to answer the prompt, and these are automatically
added to the GF grammar.
2.5 Usability
Several demonstration systems have been built us-
ing ADT with an average development time of un-
der an hour. However, our planned evaluation will
test the ability of novice users, with some knowl-
edge of BPMs and databases, to iteratively develop
their own ISU dialogue systems.
3 Summary
This paper describes the Advanced Dialogue Tools
for creating Information State Update based dia-
logue systems automatically from Business User
Resources such as BPMs and databases. The tools
include automatic generation of grammars for ro-
bust interpretation of spontaneous speech, and uses
the application databases and BPMs to generate
lexical entries and grammar rules for speech recog-
nition language modelling. We also demonstrate
an easy-to-use prototype interface that allows the
user to easily and quickly modify aspects of the
dialogue, thus eliminating the need for third party
service providers. This paper describes ADT, its
main components, and some of the research issues
involved in its development.
4 Acknowledgement
This project is funded by a Scottish Enterprise
Proof of Concept Grant (project number 8-ELM-
004).
References
Aylett, Matthew P. and Christopher J. Pidcock. 2007.
The cerevoice characterful speech synthesiser sdk.
In AISB, pages 174?8.
Lemon, Oliver and Alexander Gruenstein. 2004. Mul-
tithreaded context for robust conversational inter-
faces: context-sensitive speech recognition and in-
terpretation of corrective fragments. ACM Trans-
actions on Computer-Human Interaction (ACM
TOCHI), 11(3):241? 267.
Lemon, Oliver, Kallirroi Georgila, James Henderson,
and Matthew Stuttle. 2006. An ISU dialogue system
exhibiting reinforcement learning of dialogue poli-
cies: generic slot-filling in the TALK in-car system.
In Proceedings of EACL, pages 119?122.
Lemon, Oliver. 2004. Context-sensitive speech recog-
nition in Information-State Update dialogue systems:
results for the grammar switching approach. In Pro-
ceedings of the 8th Workshop on the Semantics and
Pragmatics of Dialogue, CATALOG?04, pages 49?
55.
Nuance, 2002. http://www.nuance.com. As of 1 Feb
2002.
Ranta, A. 2004. Grammatical framework. a type-
theoretical grammar formalism. Journal of Func-
tional Programming, 14(2):145?189.
Seneff, Stephanie. 2002. Response Planning and Gen-
eration in the Mercury Flight Reservation System.
Computer Speech and Language, 16.
Taylor, P., A. Black, and R. Caley. 1998. The architec-
ture of the the Festival speech synthesis system. In
Third International Workshop on Speech Synthesis,
Sydney, Australia.
Young, Steve. 1995. Large vocabulary continuous
speech recognition: A review. In Proceedings of
the IEEE Workshop on Automatic Speech Recogni-
tion and Understanding, pages 3?28.
Young, Steve. 2007. ATK: An Application Toolkit
for HTK, Version 1.6. Technical report, Cambridge
University Engineering Department.
164
