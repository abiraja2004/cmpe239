Identifying Terms by their Family and Friends 
Diana Maynard  
Dept. of Computer Science 
University of Sheffield 
Regent Court, 211 Portobello St 
Sheffield, $1 4DP, UK 
d. maynard0dcs, shef. ac. uk 
Sophia Anan iadou 
Computer Science, School of Sciences 
University of Saltbrd, Newton Building 
Saltbrd, M5 4WT, U.K. 
s. ananiadou@salf ord. ac. uk 
Abstract 
Multi-word terms are traditionally identified using 
statistical techniques or, more recently, using hybrid 
techniques combining statistics with shallow linguis- 
tic information. Al)proaches to word sense disam- 
biguation and machine translation have taken ad- 
vantage of contextual information in a more mean- 
ingflfl way, but terminology has rarely followed suit. 
We present an approach to term recognition which 
identifies salient parts of the context and measures 
their strength of association to relevant candidate 
terms. The resulting list of ranked terms is shown 
to improve on that produced by traditional method- 
s, in terms of precision and distribution, while the 
information acquired in the process can also be used 
for a variety of other applications, such as disam- 
biguation, lexical tuning and term clustering. 
1 Introduction 
Although statistical approaches to automatic term 
recognition, e.g. (Bourigault, 1992; Daille et al, 
1994; Enguehard and Pantera, 1994; 3usteson and 
Katz, 1995; Lauriston, 1996), have achieved rela- 
tive success over the years, the addition of suitable 
linguistic information has the potential to enhance 
results still further, particularly in the case of small 
corpora or very specialised omains, where statis- 
tical information may not be so accurate. One of 
the main reasons for the current lack of diversity in 
approaches to term recognition lies in the difficul- 
ty of extracting suitable semantic information from 
speeialised corpora, particularly in view of the lack 
of appropriate linguistic resources. The increasing 
development of electronic lexieal resources, coupled 
with new methods for automatically creating and 
fine-tuning them from corpora, has begun to pave 
the way for a more dominant appearance of natural 
language processing techniques in the field of termi- 
nology. 
The TRUCKS approach to term recognition (Ter- 
m Recognition Using Combined Knowledge Sources) 
focuses on identifying relevant contextual informa- 
tion from a variety of sources, in order to enhance 
traditional statistical techniques of term recognition. 
Although contextual information has been previous- 
ly used, e.g. in general language (Grefenstette, 1994) 
mid in the NC-Value method for term recognition 
(Frantzi, 1998; Frantzi and Ananiadou, 1999), only 
shallow syntactic information is used in these cas- 
es. The TRUCKS approach identifies different; el- 
ements of the context which are combined to form 
the Information Weight, a measure of how strong- 
ly related the context is to a candidate term. The 
hffbrmation Weight is then combined with the sta- 
tistical information about a candidate term and its 
context, acquired using the NC-Value method, to 
form the SNC-Value. Section 2 describes the NC- 
Value method. Section 3 discusses the importance 
of contextual information and explains how this is 
acquired. Sections 4 and 5 describe the hffbrmation 
Weight and the SNC-VMue respectively. We finish 
with an evaluation of the method and draw some 
conclusions about the work and its fllture. 
2 The NC-Value method 
The NC-Value method uses a combination of lin- 
guistic and statistical information. Terms are first 
extracted from a corpus using the C-Value method 
(Frantzi and Ananiadou, 1999), a measure based on 
frequency of occurrence and term length. This is 
defined formally as: 
is not nested 
C-Value(a) = Zo.q~l(~l l~('n,) ~b~T~ f(b)) 
a is nested 
where 
a is the candidate string, 
f(a) is its frequency in the corpus, 
eT, is the set of candidate terms that contain a, 
P(Ta) is the number of these candidate terms. 
Two different cases apply: one for terms that are 
found as nested, and one for terms that are not. If a 
candidate string is not found as nested, its termhood 
is calculated from its total frequency and length. If 
it is found as nested, termhood is calculated from its 
total frequency, length, frequency as a nested string, 
530 
and the tmmber of longer candidate terms it; ai)l)ears 
in. 
The NC-Value metho(1 builds oil this by incorl)o- 
rating contextual information in the form of a con- 
text factor for each candidate term. A context word 
can be any noun, adjective or verb apI)earing with- 
in a fixed-size window of tim candidate term. Each 
context word is assigned a weight, based on how fre- 
quently it appears with a ca lldidate term. Ttmse 
weights m'e titan SUllslned for all colltext words rel- 
ative to a candidate term. The Context l"actor is 
combined with the C-Value to form tlm NC-Value: 
NCvaluc(a) = 0.8 * Cvalue(a) + 0.2 * C l,'(a) (1) 
where 
a is tile candidate term, 
Cvahte(a) is the Cvalue fin' tlm candidate term, 
CF(a) is the context factor tbr the candidate 
term. 
3 Contextua l  In fo rmat ion :  a Term's  
Social Life 
Just as a person's social life can provide valuable 
clues al)out their i)ersonality, so we can gather much 
information about the nature of a term by investi- 
gating the coral)any it keeps. We acquire this knowl- 
edge by cxtra{:ting three different ypes of contextual 
information: 
1. syntactic; 
2. terminologic~fl; 
3. semantic. 
3.1 Syntact i c  knowledge  
Syntactic knowledge is based on words in the con- 
text which occur immediately t)efore or afl;er a can- 
didatc term, wtfich we call boundary words. Follow- 
ing "barrier word" al)proaches to term recoglfition 
(Bourigault, 1992; Nelson et al, 1995), where par- 
titular syntactic ategories are used to delimit era> 
didate terms, we develop this idea fllrther by weight- 
ing boundary words according to tlmir category. The 
weight for each category, shown in Table 1, is all{)- 
cate(1 according to its relative likelihood of occur- 
ring with a term as opposed to a non-term. A verb, 
therefore, occurring immediately before or after a 
candidate, term, is statistically a better indicator of 
a term than an adjective is. By "a better indica- 
tor", we mean that a candidate term occurring with 
it is more likely to be valid. Each candidate term is 
assigned a syntactic weight, calculated by summing 
the category weights tbr the context bomsdary words 
occurring with it. 
Category Weight 
Verb 1.2 
Prep 1.1 
Noun 0.9 
Adj 0.7 
Table 1: We.ights for categories of boundary words 
3.2 Termino log ica l  knowledge  
Ternfinological knowledge concerns the terminologi- 
cal sta.tus of context words. A context word whicll 
is also a term (whicll we call a context erm) is like- 
ly to 1)e a better indicator than one wlfich is not. 
The terminological status is determined by applying 
the NC-Value at)proach to the corlms, and consider- 
ing tile top third of the list; of ranked results as valid 
terms. A context erm (CT) weight is then produced 
fin" each candidate term, based on its total frequency 
of occurrence with all relewmt context terms. The 
CT weight is formally described as follows: 
where 
a is the candidate term, 
7', is the set: of context erms of a, 
d is a word from Ta, 
fa(d) is the frequency of d as a context term of a. 
3.3 Semant ic  knowledge  
Semantic knowledge is obtained about context erms 
using the UMLS Metathesaurus and Semantic Net- 
work (NLM, 1997). The former provides a seman- 
tic tag for each term, such as Acquired Abnormality. 
The latte, r provides a hierarchy of semantic type- 
s, from wlfich we compute the similarity between a 
candidate term and the context I;erms it occurs with. 
An example of part of tim network is shown in Figure 
\]. 
Similarity is measured because we believe that a 
context erm which is semantically similar to a can- 
didate term is more likely to be significant han one 
wlfieh is less similar. We use tim method for seman- 
tic distance described in (M~\ynard and Ananiadou, 
1999a), wtfich is based on calculating the vertical 
position and horizontal distance between odes in a 
hierarchy. Two weights are cMculated: 
? positionah measured by the combined istance 
from root to each node 
? commonality: measured by the number of 
shared common ancestors multiplied by the 
munber of words (usuMly two). 
Similarity between the nodes is calculated by divid- 
ing tim commomflity weight by the 1)ositional weight 
to t)roduce a figure between 0 and 1, I being the ease 
531 
1'1'1 
\['rM 
ENTII'? 
\[ 'rAi l  
PIIYSICM, ()IHECr 
/ ,  
/ 
\[TAIII 
OIIGANISM 
ITAIItl rrAtl21 
PI,ANT I"UN(;US 
ITAIIlll 
ALGA 
\['rlq 
EVI,:NT 
\[TA2I 
CONCEI~I'UAI, ~N'I'I'I'Y 
ITAI21 
ANATOMII2AL STIIUCTURI,: 
/ /  
ITAI211 \[TAI221 
EMIIRYONIC ANA'I'OM \[IUA 1, 
STllUC'I'UItE AIINOILMALrI'Y 
Figure 1: Fragment of the Semantic Network 
where tile two nodes are identical, and 0 being the 
case where there is no common ancestor. This is 
formally defined as follows: 
sim(w,. . .w, , )  - com(w,...w,,) (3) 
pOS(~Ul...Wn) 
where 
corn(w1 ...w,~) is the commonality weight of words 
1. . .n  
pos('wl...w,~) is the positional weight of words 
l...n. 
Let us take an example from the UMLS. The sim- 
ilarity between a term t)elonging to the semantic 
category Plant and one belonging to the category 
Fungus would be calculated as follows:- 
? Plant has the semantic ode TA l l l  and Fungus 
has the semantic ode TAl l2.  
? The commonality weight is the number of nodes 
in common, multiplied by the number of terms 
we are considering. TA l l l  and TA l l2  have 4 
nodes in common (T, TA, TA1 and TAl l ) .  So 
the weight will be 4 * 2 = 8. 
? The positional weight is the total height of each 
of the terms (where tile root node has a height of 
1). TA l l l  has a height of 5 (T, TA, TA1, TA l l  
and TAl l1) ,  and TAl12 also has a height of 5 
(T, TA, TA1, TA l l  and TAl l2) .  The weight 
will therefore be 5 + 5 = 10. 
? The similarity weight is tile comlnonality 
weight divided by the positional weight, i.e. 
8/10 = 0.8. 
4 The  In fo rmat ion  Weight  
The three individual weights described above are 
calculated for all relevant context words or context 
terms. The total weights for the context are then 
combined according to the following equation: 
IW(a) = ~ .syria(b) + ~ f,(d) . sim,(d) (4) 
beC. (l~7~ 
where 
a is the candidate term, 
Cais the set of context words of a, 
b is a word from C,,  
f,(b) is tlm frequency of b as a context word of a, 
syn~(b) is the syntactic weight of b as a context 
word of a, 
T. is the set of context terms of a, 
d is a word fl'om T., 
fi,(d) is the frequency of d as a context erm of a, 
sims(d) is the similarity weight of d as a context 
term of a. 
This basically means that the Infornlation Weight 
is composed of the total terminological weight, 511151- 
tiplied by tile total semantic weight, and then added 
to the total syntactic weight of all the context words 
or context erms related to the candidate term. 
5 The  SNC-Va lue  
Tile Information Weight gives a score for each candi- 
date term based on the ilnt)ortance of the contextual 
intbrmation surrounding it. To obtain the final SNC- 
Value ranking, the Information Weight is combined 
with the statistical information obtained using the 
NC-Vahm nmthod, as expressed formally below: 
SlVCV,a.,c(a) = NCVal~u~(a) + IW(a) (5) 
where  
a is the candidate term 
NCValue(a) is the NC-Value of a 
IW is the Inqmrtance Weight of a 
For details of the NC-Value, see (l:5'antzi and Ana- 
niadou, 1999). 
An example of the final result is shown in Table 
2. This corot)ares tile top 20 results from the SNC- 
Value list with the top 20 from the NC-Value list. 
The terms in italics are those which were considered 
as not valid. We shall discuss the results in more de- 
tail in the next section, but we can note here three 
points. Firstly, the weights for the SNC-Value are 
substantially greater than those for the NC-Vahm. 
This, in itself, is not important, since it, is the posi- 
tion in the list, i.e. the relative weight, rather than 
the absolute weight, which is important. Secondly, 
we can see that there are more valid terms in the 
SNC-Value results than in the NC-Value results. It 
532 
Term SNC '\].L'rm NC 
l)owlllall ~S_lllelllbralle 
\]nalignant_melanoma 
hyaline_fibrous_tissue 
planes_of_section 
tral) ecularJneshwork 
keratinous_del)ris 
l)ruch~s_inenll)r &lie 
plane_of_section= 
mclanoma_of_choroid 
lymphocytieAnfiltration 
ciliary_processes 
cellularAibrous_tissue 
squamous_ct)ithelium 
oI)tic_nerve_head 
l)Ul)illary_border 
(:orlmal_el)ithelium 
seleraldnw~sion 
granulation_tissue 
stratified_squamous_epithelium 
ocular~structures 
605782 
231237 
215843 
170016 
157353 
101644 
94996.2 
90109.4 
71.615.1 
53822 
52355.7 
51486.8 
46928.9 
39054.5 
36510.8 
31.335.9 
31017.4 
28010.1 
27445.5 
26143.6 
pla'ne_@section 
dencelnel;~s_ill(~.llll)r~/iEe 
basal_cell_carcinoma 
stump_of_optic_nerve 
1)asal_cell_l)at)illoma 
planc_of_section= 
rnclano,na_of_ch, oroid 
pla'ncs_@scction 
malignant _melanoma 
optic_nerveAmad 
ciliaryq)rocesses 
1)ruth's_membrane 
keratinous_eyst 
ellipse_of_skin 
wcdgc_of_lid_ma~yin 
scaT"_tT'ack 
conImctive_tissue 
vertical_plane 
carcinoma_of_lid 
excision_biopsy 
1752.71 
1.345.76 
1.268.21 
993.15 
616.614 
506.517 
497.673 
453.716 
448.591 
422.211 
421.204 
413.027 
392.944 
267.636 
211.41.4 
228.217 
167.053 
167.015 
164 
155.257 
Table 2: Top 20 results for the SNC-VaIue and NC-Value 
in hard to make flu:ther judgements based on this 
list alone, 1)ecause we cmmot s~3; wlmther on(; ter- 
\]u is 1)etter than another, if tiE(; two terms are both 
valid. Thirdly, we can nee that more of the top 20 
terms are valid tin' tim SNC-Vahm than for the NC- 
Value: 17 (851X,) as ot)t)osed to 10 (50%). 
6 Eva luat ion  
The SNC-Value method wan initially t(;sted on a eor- 
l)US of 800,000 eye t)athoh)gy reI)ortn , which had 
1)een tagged with the Brill t)art-of-nl)eeeh tagger 
(Brill, 1992). The ca.ndidate terms we,'e first ex- 
tracted using the NC-Value method (lhantzi, 1998), 
and the SNC-Value was then (:alculated. To exvdu- 
ate the results, we examined the p(.'rformanee of the 
similarity weight alone, and the overall 1)erformance 
of the system. 
6.1 Evaluation methods 
The main evaluation i)rocedure was carried out with 
resl)ect o a manual assessment of tim list of terms 
l)y 2 domain exI)erts. There are, however, 1)roblems 
associated with such an evaluation. Firstly, there ix 
no gold standm:d of evaluation, and secondly, man- 
ual evaluation is both fallil)le and sul)jective. To 
avoid this 1)rol)lem, we measure the 1)erformance of
the system ill relative termn rather than in abso- 
lute terms, by measuring the improveln(mt over the 
results of tile NC-Value as eomt)ared with mmmal 
evahlation. Although we could have used the list 
of terms 1)rovided in the UMLS, instead of a manu~ 
ally evahlated list, we found that there was a huge 
discrei)an(:y 1)etween this lint and the lint validated 
by the manual experts (only 20% of the terms they 
judged valid were fOtlEl(1 ill the UMLS). There are 
also further limitations to the UMLS, such as the 
fact that it is only nl)e(:ific to medicine in general, 
1)ut not to eye t)athology, and the fact that it; is or- 
ganised ill nllch a way that only the preferred terms, 
and not lexical variants, m'e actively and (:onnistent- 
ly 1)r(~sent. 
We first evaluate the similarity weight individu- 
ally, since this is the main 1)rinciple on which the 
SNC-\Sflue method relies. We then ewduate the 
SNC-VaIue as a whole t)y comparing it with the NC- 
Value, so I;hat we can ewfluate the impact of tile ad- 
dition of the deel)er forms of linguistic information 
incorl)orated in {:he hnI)ortance Weight. 
6.2 Similarity Weight 
One of the 1)roblems with our method of calculat- 
ing similarity is that it relies on a 1)re-existing lexi- 
(:al resource, which Eneans it is 1)rone to errors and 
omissions. Bearing in mind its innate inadequacies, 
we can nevertheless evaluate the expected theoretical 
performance of tilt measure by concerning ourselves 
only with what is covered by the thesaurus. This 
means that we assume COml)leteness (although we 
know that this in not the case) and evahtate it ac- 
cordingly, ignoring anything which may be inissing. 
The semantic weight ix based on the premise that 
tile more similar a context term is to the candidate 
term it occurs with, the better an indicator that con- 
text term is. So the higher the total semantic weight 
533 
Section Term Non-Term 
top set 76% 24% 
middle set 56% 44% 
bottom set 49% 51% 
Table 3: Semantic weights of terms and non-terms 
for the candidate term, the higher the ranking of the 
term and the better the chance that the candidate 
term is a valid one. To test the performmme of the 
semantic weight, we sorted the terms in descending 
order of their semantic weights and divided the list 
into 3, such that the top third contained the terms 
with the highest semantic weights, and the bottom 
third contained those with the lowest. We then com- 
pared how many valid and non-valid terms (accord- 
ing to the manual evaluation) were contained in each 
section of the list,. 
Tile results, depicted in Table 3, can be interpret- 
ed as follows. In the top third of the list;, 76% were 
terms and 24% were non-terms, whilst in the middle 
third, 56% were terms and 44% were non-terms, and 
so on. This means that most of the valid terms are 
contained in the top third of tile list mid the fewest 
valid terms are contained in the bottom third of the 
list. Also, the proportion of terms to non-terms in 
tile top of tile list is such that there are more terms 
than non-terms, whereas in the bottom of the list; 
there are more non-terms than ternis. This there- 
fore demonstrates two things: 
? more of' the terms with the highest semantic 
weights are valid, and fewer of those with the 
lowest semmitic weights are valid; 
? more valid terms have high semantic weights 
than non-terms, mid more non-terms have lower 
semantic weights than valid terms. 
We also tested the similarity measure to see 
whether adding sosne statistical information would 
improve its results, and regulate any discrepancies 
in tile uniformity of the hierarchy. The method- 
s which intuitively seem most plausible are based 
on information content, e.g.(Resnik, 1995; Smeaton 
and Quigley, 1996). The informatiosl content of a n- 
ode is related to its probability of occurrence in the 
corpus. Tile snore fi'equently it appears, the snore 
likely it is to be important in terms of conveying 
information, and therefore the higher weighting it 
should receive. We performed experiments to cosn- 
pare two such methods with our similarity measure. 
The first considers the probability of the MSCA of 
the two terms (the lowest node which is an ancestor 
of both), whilst the second considers the probability 
of the nodes of the terms being colnpared. However, 
the tindings showed a negligible difference between 
the three methods, so we conchlde that there is no 
SNC-Value NC-Vahm 
Section Valid Precision Valid Precision 
1 163 64% 160 62% 
2 84 aa% 98 38% 
3 89 35% 69 27% 
4 89 35% 78 30% 
5 76 30% 87 34% 
6 57 22% 78 30% 
7 66 26% 92 36% 
8 75 29% 100 39% 
9 70 27% 42 16% 
10 59 23% 68 27% 
Table 4: Precision of SNC-Vahle and NC-Value 
advantage to be gained by adding statistical int'or- 
mation, fbr this particular corpus. It; is possible that 
with a larger corlms or different hierarchy, this might 
slot be the case. 
6.3 Overall Evaluat ion of the SNC-Value 
We first; compare the precision rates for the SNC- 
Value and the NC-Value (Table 4), by dividing tile 
ranked lists into 10 equal sections. Each section con- 
tains 250 terms, marked as valid or invalid by the 
manual experts. In the top section, the precision is 
higher for the SNC-Value, and in the bottom section, 
it is lower. This indicates that the precision span is 
greater fl~r the SNC-Value, and therefore that the 
ranking is improved. The distribution of valid terms 
is also better for the SNC-Value, since of the valid 
terms, more appear at the top of the list than at the 
bottom. 
Looking at Figure 2, we can see that the SNC- 
Value graph is smoother than that of the NC-Vahle. 
We can compare the graphs niore accurately using 
a method we call comparative upward trend. Be- 
cruise there is no one ideal graph, we instead mea- 
sure how much each graph deviates from a mono- 
tonic line downwards. This is calculated by dividing 
the total rise in precision percentage by the length 
of the graph. A graph with a lower upward trend 
will therefore be better than a graph with a higher 
upward trend. If we compare the upward trends of 
the two graphs, we find that the trend for the SNC- 
Value is 0.9, whereas the trend for the NC-Value is 
2.7. This again shows that the SNC-Value rmiking 
is better thmi the NC-Value ranking, since it is more 
consistent. 
Table 5 shows a more precise investigation of the 
top portion of the list, (where it is to be expected 
that ternis are most likely to be wflid, and which 
is therefore the inost imi)ortant part of the list) We 
see that the precision is most iml)roved here, both 
in terms of accuracy and in terms of distribution 
of weights. At the I)ottom of the top section, the 
534 
9O 
U{} 
71} 
60 
PlccJshm 50 
,111 
30 
211 
10 
SN{" Vah,c 
. . . .  NC-Vah,c 
\ 
\ 
T ~  T T I 
I 3 4 ~ 6 7 8 9 10 
Scct iono l l i s t  
Figure 2: Precision of SNC-Value and NC-Vatue 
SNC-\Sflue 
Section Valid I Precision 
1 21 184% 
2 19 176% 
3 ~" '68% i i 
4: 16 164% 
5 1.8 172% 
6 12 148% 
7 13 152% 
8 : 7 : 68{/{) 
9 \] 3 I 52% 
10 \] 4 i 56% 
\] N C-Value 
Valid Precision 
z 
19 76% 
23 92% 
21 84% 
13 52% 
13 52% 
19 76% 
18 72% 
14 56% 
10 40% 
8 32% 
Table 5: Precision of SNC-\Sdue and NC-Vahm for 
top 250 terms 
precision is much higher for the SNC-Value. This is 
important because ideally, all the terms in this part 
of the list should be valid, 
7 Conc lus ions  
In this paper, we have described a method for multi- 
word term extraction which improves on traditional 
statistical at)proaches by incorporating more specific 
contextual information. It focuses particularly on 
measuring the strength of association (in semantic 
terms) l)etween a candidate term and its context. 
Evahlation shows imi)rovement over the NC-Vahm 
approach, although the percentages are small. This 
is largely l)ecmlse we have used a very small corpus 
for testing. 
The contextuM information acquired can also be 
used for a mmlber of other related tasks, such as 
disambiguation and clustering. At present, the se- 
mantic information is acquired from a 1)re-existing 
domain-slmcitic thesaurus, but there m:c 1)ossibili- 
tics for creating such a thesaurus automatically, or 
entrancing an existing one, using the contextual in- 
formation we acquire (Ushioda, 1996; MaynaM and 
Anmfiadou, 1999b). 
There is much scope tbr filrther extensions of this 
research. Firstly, it; could be extended to other (lo- 
mains and larger corpora, in order to see the true 
benefit of such a.n apl)roach. Secondly, the thesaurus 
could be tailored to the corpus, as we have men- 
tioncd. An incremental approach might be possible, 
whereby the similarity measure is combined with s- 
tatistical intbrmation to tune an existing ontology. 
Also, the UMLS is not designed as a linguistic re- 
source, but as an information resource. Some kind 
of integration of the two types of resource would be 
usefifl so that, for example, lexical variation could 
be more easily handled. 
References  
D. Bourigault. 1992. Surface grammatical analysis 
for tile extraction of terminological noun phras- 
es. In Proc. of l~th International Co~@rcncc 
on Computational Linguistics (COL\[NG), pages 
977-981, Nantes, bYance. 
Eric Brill. 1992. A simple rule-based part of speech 
tagger. In Pwc. of 3rd Confc~vnce of Applied Nat- 
ural Language Processing. 
B. l)aille, E. Gaussicr, and J.M. Lang5. 1994. To- 
wards automatic extraction of monolingual and 
t)ilingual terminology. In Proc. of iSth Interna- 
tional Conference on Computational Linguistics 
(COLIN(;), pages 515-521. 
Chantal Enguehard and Lmu'ent Pantera. 1994. 
Autoumtic natural a(:quisition of a terminology. 
Journal of Quantitative Linguistics, 2(1):27-32. 
K.T. li'r;mtzi and S. Ananiadou. 1.999. The C- 
Value/NC-Vahm domain independent method ~br 
multi-word term extraction. Journal of Natural 
Language PTvccssing, 6(3):1.45 179. 
K.T. Frantzi. 1.998. Automatic Recognition of 
Multi-Word Terms. Ph.D. thesis, Manchester 
Metropolitan University, England. 
G. Grefenstette. 1994. E:rplorations in Automatic 
Thesaurus Discovcry. Kluwer Aca(temic Publish- 
ers .  
J.S. Justcson and S.M. Katz. 1995. Technical ter- 
minology: some linguistic properties and an algo- 
rithm for identification in text. Natural Language 
Engineering, 1:9-27. 
Andy Lauriston. 1996. Automatic term recognition: 
performance of lin9uistic and statistical learning 
techniques. Ph.D. thesis, UMIST, Manchester, 
UK. 
D.G. Maynard and S. Anmfiadou. 1999a. hlentify- 
ing contextual information tbr term extraction. In 
i}Tvc, of 5th International Congress on 7~rminol- 
535 
ogy and Knowlc@c Engineering (TKE '99), pt~ges 
212-221, Innsbruck, Austria. 
D.G. Maynard and S. Anmfiadou. 1999b. A linguis- 
tic ~I)proach to context clustering. In Proc. of Nat- 
n~nl Language Proecssinfl Pacific \]~im Symposium 
(NLPRS), pages 346-351, Beijing, China. 
S.J. Nelson, N.E. Olson, L. Fuller, M.S. Turtle, W.G. 
Cole, and D.D. Sherertz. 1995. Identifying con- 
cepts in medical knowledge. In Proc. of 8th World 
Congress on Medical Informatics (MEDINFO), 
1)~ges 33-36. 
NLM, 1997. UMLS K?wwlcdgc Sourccs. National 
Library of Medicine, U.S. Dept. of Health and Hu- 
man Services, 8th edition, January. 
P. Resnik. 1995. Disambiguating noun groupings 
with respect o WordNet senses. In Proc. of 3rd 
Workshop on Very Large Corpora. MIT. 
A. Smeaton and I. Quigley. 1996. Experiments on 
using semantic distances between words in image 
caption retrieval. In Proc. of 19t.h htternationaI 
Conferc'ncc on Research and Development i~. I'n- 
formation Retrieval, Zurich, Switzerland. 
Akira Ushioda. 1996. IIierarchical clustering of 
words. In Proc. of 16th I'ntcrnational ConfcT~cncc 
on Computational Linguistics (COLING), pages 
1159 1162. 
536 
