ROBUST PROCESSING IN MACHINE TRANSLATION 
Doug Arnold, Rod Johnson, 
Centre for Cognitive Studies, 
University of Essex, 
Colchester, CO4 3SQ, U.K. 
Centre for Computational Linguistics 
UMIST, Manchester, 
M60 8QD, U.K. 
ABSTRACT 
In this paper  we prov ide  an abst rac t  
character i sa t ion  of d i f ferent kinds of robust 
process ing in Mach ine Trans lat ion  and Natural  
Language Processing systems in terms of the kinds 
of problem they are supposed to solve. We focus 
on one problem which is typically exacerbated by 
robust processing, and for which we know of no 
exist ing solutions. We discuss two possible 
approaches to this, emphas is ing  the need to 
correct or repair processing malfunctions. 
ROBUST PROCESSING IN MACHINE TRANSLATION 
This paper is an at tempt  to provide part 
of the basis for a general theory of robust 
process ing in Machine Trans lat ion  (MT) wi th 
relevance to other areas of Natural  Language 
Process ing (NLP). That is, process ing which is 
resistant to ma l funct ion ing  however  caused. The 
background to the paper is work on a general  
purpose fully automatic mul t i - l lngua l  MT system 
wi th in  a highly decentra l i sed organ isat iona l  
framework (specifically, the Eurotra system under 
deve lopment  by the EEC). This inf luences us in a 
number of ways. 
Decentra l i sed development,  and the fact 
that the system is to be general purpose motivate 
the fo rmulat ion  of a senera l  theory ,  wh ich  
abstracts away from matters of purely local 
relevance, and does not e.g. depend on explo i t ing 
special properties of a part icular  subject f ield 
(compare \[7\], e.g.). 
The fact that we consider  robustness at 
all can be seen as a result of the d i f f icu l ty  of 
MT, and the aim of full automation is reflected in 
our concentrat ion  on a theory of robust process-  
ins, rather than "developmental  robustness'. We 
wil l  not be concerned here with problems that 
arise in des igning systems so that they are 
capable of extension and repair (e.g. not being 
prone  to un forseen  "r ipp le  e f fec ts"  under  
modif icat ion).  Deve lopmenta l  robustness  is 
clearly essential, and such problems are serious, 
but no system which relies on this kind of robust- 
ness can ever be fully automatic.  For the same 
reason,  we w i l l  not cons ider  the use of 
"interactive" approaches to robustness such as 
that of \[I0\]. 
F inal ly,  the fact that we are concerned 
with t rans lat ion mi l i ta tes  against the kind of 
disregard for input that is characteristic of some 
robust systems (PARRY \[4\] is an extreme example), 
and mot ivates  a concern  w i th  the repa i r  or 
correct ion of errors. It is not enough that a 
t rans la t ion  sys tem produces  super f i c ia l l y  
acceptable output for a wide class of inputs, it 
should aim to produce outputs which represent as 
nearly as possible translations of the inputs. If 
it cannot do this, then in some cases it wi l l  be 
better if it indicates as much, so that other 
action can be taken. 
From the point of view we adopt, it is 
possible to regard MT and NLP systems generally as 
sets of processes implementing relations between 
representat ions  ( texts  can be cons idered  
representat ions  of themselves). It is important 
to distinguish: 
(i) R: the correct, or intended relation that 
holds between representat ions  (e.g. the re lat ion 
"is a (cor rec t )  t rans la t ion  of', or "is t~e 
surface const i tuent  structure of'): we have only 
fair ly vague, pre- theoret ica l  ideas about Rs, in 
virtue of being bi - l ingual  speakers, or having 
some in tu i t i ve  grasp  of the semant ics  of 
artificial representations; 
(ii) T: a theoret ica l  construct  which is 
supposed to embody R; 
( i i i )  P: a p rocess  or p rogram that is 
supposed to implement 
By a robust process P, we mean one which 
operates error free for all inputs. Clearly, the 
notion of error or correctness of P depends on the 
independent standard provided by T and R. If, for 
the sake of simplicity we ignore the possibility 
of ambiguous  inputs  here,  we can de f ine  
correctness thus: 
(1) Given P(x)=y, and a set W such that ~or 
all w in W, R(w)=y, then y is correct with respect 
to R and w iff x is a member of W. 
Intuitively, W is the set of items for which 
y is the correct representat ion  accord ing to R. 
One possible source of errors in P would be if P 
correct ly  imp lemented  T, but T did not embody R. 
Clearly, in this case, the only sensible solution 
is to modify T. Since we can imagine no automatic 
way of finding such errors and doing this, we will 
472  
ignore this possibi l i ty,  end assume that T is a 
we11-defined, correct and complete embodiment of 
R. We can thus replace R by T in (I), and treat T 
as the standard of correctness below. 
There appear to be two possible sources of 
error in P: 
Problem (1):  where P is not a correct 
imp lementat ion  of T. One would expect this to be 
common where (as often in MT and NLP) T is very 
complex, and serious problems arise in devis ing 
implementations for them. 
P rob lem (i i):  where  P is a cor rec t  
imp lementat ion  so far as it goes, but is incom- 
plete, so that the domain of P is a proper-subset 
of the domain of T. This will also be very common: 
in reality processes are often faced with inputs 
that violate the expectat ions impl ic i t  in an 
implementation. 
If we disregard hardware errors, low level 
bugs and such malfunctions as non-termlnatlon of 
P (for which there are we l l -known solutions), 
there are three poss ib le  man i fes ta t ions  of 
malfunction. We will discuss them in tur~ 
case (a): P(x)=@, where T(x)~@ 
i.e. P halts producing ~ output for input x, where 
this is not the intended output. This would be a 
typical response to unforseen or illformed input, 
and is the case of process fragility that is most 
o f ten  dea l t  with.  
There are two obvious solutions: (1) to 
manipu late  the input so that it conforms to the 
expectat ions impl ic i t  in P (cf. the LIFER \[8\] 
approach to ell ipsis), or to change P Itself, 
modi fy ing (general ly relaxing) its expectat ions  
(cf. e.g. the approaches of \[7\], \[9\], \[10\] and 
\[Ii\]). If successful,  these guarantee that P 
produces some output for input x. However, there 
is of course no guarantee that it is correct with 
respect to T. It may be that P plus the input 
manipulation process, or P with relaxed expectat- 
ions is simply a more correct or complete implem- 
entat ion of T, but this wil l  be fortuitous. It is 
more llkely that making P robust in these ways 
will lead to errors of another kind: 
case (b): P(x)=z where z is not a legal 
output for P according to T (i.e. z is not in the 
range of T. 
Typically, such an error will show itself by 
malfunctioning in a process that P feeds. Detec- 
tion of such errors is s t ra ight forward:  a wel l -  
formedness check on the output of P is sufficient. 
By i tse l f ,  of course ,  this w i l l  lead to a 
pro l i ferat ion of case-(a) errors in P. These can 
be avoided by a number of methods, in particular: 
(1) introducing some process to manipu late  the 
output of P to make it well-formed according to T, 
or (ii) a t tempt ing to set up processes that feed 
on P so that they can use 'abnormal" or "non- 
standard" output from P (e.g. partial representat- 
ions, or complete in termediate  representat ions  
produced within P, or alternative representations 
constructed wi th in  P which can be more rel iably 
computed than the "normal" intended output of P 
(the representational theories of GETA and Eurotra 
are designed with this in mind: cf. \[2\], \[3\], \[5\], 
\[6\], and references there, and see \[i\] for fuller 
d i scuss ion  of these issues) .  Aga in ,  it is 
conceivable that the result of this may be to 
produce a robust P that implements T more correct- 
ly or completely, but again this will be fortuit- 
ous. The most likely result will he robust P will 
now produce errors of the third type: 
case (c): P(x)=y, where y is a legal output 
for P according to T, but is not the intended 
output according to T. i.e. y is in the range of 
T, but yqT(x). 
Suppose both input x and output y of some 
process are legal objects, it nevertheless does 
not follow that they have been correctly paired by 
the process: e.g.in the case of a parsing process, 
x may be some sentence and y some representatiom 
Obviously, the fact that x and y are legal objects 
for the parsing process and that y is the output 
of the parser for input x does not guarantee that 
y is a correct representat ion of x. Of course, 
robust processing should be resistant to this kind 
of malfunctloning also. 
Case-(c) errors are by far the most serious 
and resistant to solut ion because they are the 
hardest to detect, and because in many cases no 
output  is p re ferab le  to super f l c la l l y  
(mis leadingly)  we l l - fo rmed but incorrect output. 
Notice also that while any process may be subject 
to this kind of error, making a system robust in 
response to case-(a) and case-(b) errors will make 
this class of errors more widespread:  we have 
suggested that the likely result of changing P to 
make it robust wil l  be that it no longer pairs 
respresentatlons in the manner required by T, but 
since any process that takes the output of P 
should be set up so as to expect inputs that 
conform to T ( s ince  this is the "correct"  
embod iment  of R, we have assumed), we can expect 
that in general making a process robust will lead 
to cascades of errors. If we assume that a system 
is resistant to case-(a) and case-(b) errors, then 
it follows that inputs for which the system has to 
resort to robust processing will be likely to lead 
to case-(c) errors. 
Moreover, we can expect that making P robust 
will have made case-(c) errors more difficult to 
deal with. The l ikely result of mak ing P robust 
is that it no longer imp lements  T, but some T" 
which is dist inct from T, and for which assump-  
tlons about correctness in relatlon to R no longer 
hold. It is obvious that the poss ib i l i ty  of 
detect ing  case- (c )  e r ro rs  depends  on the 
poss ib i l i ty  of d i s t ingu ish ing  T f rom T'. 
Theoretically, this is unproblematlc. However, in 
a domain such as MT it will be rather unusual for 
T and T" to exist separate ly  from the processes 
that implement them. Thus, if we are to have any 
chance of detect ing case-(c) errors, we must be 
able to c lear ly d is t inguish those aspects of a 
process that relate to "normal' process ing from 
473 
those that relate to robust processing. This 
distinction is not one that is made in most robust 
systems, 
We know of no existing solutions to case-(c) 
mal funct ions.  Here we wil l  out l ine two poss ib le 
approaches. 
To begin wi th we might consider  a part ial  
solut ion der ived from a we l l -known technique in 
systems theory: insur ing against the effect of 
faulty components in crucial parts of a system by 
computing the result for a given input by a number 
of different routes. For our purposes, the method 
would consist essentially in implementing the same 
theory  T as a number  of d i s t inc t  p rocesses  
P1,...Pn, etc. to be run in parallel,  compar ing  
outputs  and us ing  s ta t i s t i ca l  c r i te r ia  to  
determine the correctness of processing. We will 
call this the "statistical solution'. (Notice that 
certa in kinds of system arch i tecture  make this 
quite feasible, even given real time constraints). 
Clearly, whi le  this should s ign i f i cant ly  
improve the chances that output will be correct, 
it can provide no guarantee. Moreover,  the kind 
of s i tuat ion we are cons ider ing is more complex  
than that ar is ing given fai lure of re lat ively 
simple pieces of hardware. In particular, to make 
this worthwhi le ,  we must be able to ensure that 
the different Ps are genuinely distinct, and that 
they are reasonab ly  complete  and cor rec t  
imp lementat ions  of T, at the very  least  
suf f ic ient ly  complete  and correct that their 
outputs can be sensibly compared. 
Unfortunately, this will be very difficult to 
ensure, particularly in a field such as MT, where 
Ts are genera l ly  very complex,  and (as we have 
noted) are often not stated separate ly  from the 
processes that implement them. 
The stat ist ica l  approach is at t ract ive  
because it seems to provide a simultaneous solut- 
ion to both the detect ion and repair of case-(c) 
e r ro rs ,  and we cons ider  such so lu t ions  are 
certain ly worth further considerat ion.  However,  
realistically, we expect the normal situation to 
be that it is d i f f icult  to produce reasonably  
correct and compelete distinct implementations, so 
that we are forced to look for an a l ternat ive  
approach to the detection of case-(c) errors. 
It is obvious that reliable detection of (e)- 
type errors requires ~he imp lementat ion  of a 
relation that pairs representations in exactly the 
same way as T: the obvious candidate is a process 
p-l, implementing T -I, the inverse of T. 
The basic method here would be to compute an 
enumerat ion  of the set of all possible inputs W 
that could have y ie lded the actual output, g iven 
T, and some hypothetical ideal P which correctly 
imp lements  it. (Again, this is not unreal ist ic ;  
certain system architectures would allow forward 
computat ion  to procede  wh i le  this inverse  
processing is carried out). 
To make this wor thwh i le  would involve two 
assumptions: 
(1) That p-I te rminates  in reasonable  time. 
This cannot be guaranteed, but the assumption can 
be rendered  more  reasonab le  by observ ing  
characteristics of the input, and thus restricting 
W (e.g. restricting the members of W in relation 
to the length of the input to p-I). 
(ii) That construction of p-1 is somehow more 
straightforward than construction of P, so that 
p-i is l ikely to be more re l iable (correct and 
complete) than P. In fact this is not implausible 
for some appl icat ions  (e.g. consider  the case 
where P is a parser: it is a widely held idea that 
generators are easier to build than parsers). 
Granted these assumptions, detection of case- 
(c) errors is straightforward given this "inverse 
mapp ing"  approach:  one s imp ly  examines  the 
enumeration for the actual input if it  is present. 
If it is present, then given that p-i is likely to 
be more re l iab le  than P, then it is l ikely that 
the output of P was T-correct,  and hence did not 
const i tu te  a ease- (c )  error .  At least ,  the 
chances of the output of P being correct have been 
increased. If the input is not present, then it 
is l ikely that P has produced a case-(c) error. 
The response to this will depend on the domain and 
app l icat ion  -- e.g. on whether  incorrect but 
superficially well-formed output is preferable to 
no output at all. 
In the nature of things, we wil l  u l t imate ly  
be lead to the original  problems of robustness,  
but now in connect ion  with p-l. For this reason 
we cannot forsee any complete solution to problems 
of robustness general ly.  What we have seen is 
that solut ions to one sort of f ragi l i ty  are 
normally only partly successful, leading to errors 
of another kind elsewhere. Clearly, what we have 
to hope is that each attempt to eliminate a source 
of error nevertheless  leads to a net decrease in 
the overall number of errors. 
On the one hand, this hope is reasonable, 
since somet imes  the faults that give rise to 
process ing errors are actual ly  fixed. But there 
can be no general  guarantee of this, so that it 
seems c lear  that  mere ly  mak ing  sys tems or 
processes robust in the ways descr ibed provides 
on ly  a par t ia l  so lu t ion  to the prob lem of 
processing errors. 
This should not be surprising. Because our 
primary, concern is with automatic error detection 
and repair, we have assumed throughout that T 
cou ld  be cons idered  a cor rec t  and complete  
embodiment of ~ Of course, this is unrealistic, 
and in fact it is p robab le  that for many  
processes, at least as many processing errors will 
arise from the inadequacy of T with respect to R 
as arise from the inadequacy of P with respect to 
T. Our pre- theoret ica l  and intuit ive abi l i ty  to 
relate representations far exceeds our ability to 
formulate clear theoretical statements about these 
relations. Given this, it would seem that error 
free process ing depends at least as much on the 
correctness of theoretical models as the capacity 
474 
of a system to take advantage of the techniques 
described above. 
We shou ld  emphas ise  th is  because  it 
somet imes  appears  as though techn iques  for 
ensur ing process robustness might  have a wider  
importance. We assumed above that T was to be 
regarded as a correct embod iment  of R. Suppose 
this assumpt ion  is relaxed, and in addi t ion that 
(as we have argued is l ikely to be the case) the 
robust version of P implements a relation T" which 
is d ist inct  f rom T. Now, it could, in pr inciple,  
turn out that T' is a better embod iment  of R than 
T. It is worth  saying that this poss ib l i l i ty  is 
remote, because it is a possibility that seems to 
be taken ser iously elsewhere: a lmost  all the 
strategies we have mentioned as enhancing process 
robustness were originally proposed as theoretical 
devices to increase the adequacy of Ts in relation 
to Rs (e.g. by prov id ing  an account  of 
metaphorical or other "problematic" usage). There 
can be no question that apart from improvements of 
T, such theoretical developments can have the side 
effect of increasing robustness. But notice that 
the i r  jus t i f i ca t ion  is then not to do w i th  
robustness,  but wi th  theoretical adequacy. What 
must be emphas ised is that the chances that a 
mod i f i ca t ion  of a process to enhance robustness 
(and improve rel iabi l i ty)  wi l l  also have the 
effect of improving the quality of its performance 
are ext remely  slim. We cannot expect robust 
processing to produce results which are as good as 
those that would result from 'ideal" (optimal/non- 
robust) processing. In fact, we have suggested 
that exist ing techniques for ensur ing process 
robustness typical ly  have the effect of changing 
the theory the process implements ,  changing the 
re l i t ionship  between representat ions that the 
system defines in ways which do not preserve the 
relationship relationship between representations 
that the designers intended, so that processes 
that have been made robust by existing methods can 
be expected to produce output of lower than 
intended quality. 
These remarks are intended to emphas ise  
the importance of clear, complete,  and correct 
theoret i ca l  mode ls  of the pre - theoret l ca l  
relationships between the representations involved 
in systems for which error free 'robust' operation 
impor tant ,  and to emphas ise  the need for 
approaches to robustness (such as the two we have 
out l ined above) that make it more l ikely that 
robust processes wi l l  ma inta in  the re lat ionsh ip  
between representations that the designers of the 
"normal /opt lmal"  processes intended. That is, 
to emphas lse  the need to detect  and repa i r  
malfunctions, so as to promote correct processing. 
of the ideas in this paper were first aired in 
Eurot ra  repor t  ETL -3  (\[4\]), and in a paper  
presented at the Cranf ie ld conference on MT 
earlier this year. We would like to thank all our 
fr iends and col leagues in the project and our 
institutions. The views (and, in particular, the 
errors) in this paper are our own responsibility, 
and shou ld  not be in terpreted  as "o f f i c ia l '  
Eurotra doctrine. 
REFE RENCE S 
i. ARNOLD, D.J. & JOHNSON, R. (1984) "Approaches 
to Robust Process ing in Machine Translat ion" 
Cognitive Studies Memo, University of Essex. 
2. BOITET, CH. (1984) "Research and Development on 
MT and Related Techniques at Grenoble University' 
paper presented at Lugano MT tutorial April 1984. 
3. BOITET, CH. & NEDOBEJKINE,  N. (1980) "Russ ian-  
F rench  at GETA:  an out l ine  of method and a 
detailed example" RR 219, GETA, Grenoble. 
4. COLBY, K. (1975) Ar t i f i c ia l  Parano ia  Pergamon 
Press, Oxford. 
5. ETL- I -NL/B "Transfer  (Taxonomy, Safety Nets, 
Strategy), Report  by the Belgo-Dutch Eurotra 
Group, August 1983. 
6. ETL -3  F ina l  'Trio' Repor t  by the Eurot ra  
Central  L inguis t ics  Team (Arnold, Jaspaert,  Des 
Tombe), February 1984. 
7. HAYES, P.J .  and MOURADIAN,  G.V. (1981): 
"Flexible parsing", AJCL 7, 4:232-242. 
8. HENDRIX, G.G. (1977) "Human Eng ineer ing  for 
Appl ied Natura l  Language Process ing" Proc. 5th 
IJCAI, 183-191, MIT Press. 
9. KWASNY,  S.C. and SONDHEIMER,  N.K. (1981):  
"Relaxat ion Techniques for Parsing Grammatically 
Ill-formed Input in Natural Language Understanding 
Systems". AJCL 7, 2:99-108. 
I0. WEISCHEDEL,  R.M, and BLACK,  J. (1980)  
'Responding In te l l igent ly  to Unparsab le  Inputs" 
AJCL 6.2: 97-109. 
II. WILKS, Y. (1975): "A Preferent ia l  Pat tern  
Match ing  Semant ics  for Natura l  Language". A.I. 
6:53-74. 
AKNOWLEDGEMENTS 
Our debt to the Eurotra project is great: 
collaboration on this paper developed out of work 
on Eurotra and has only been poss ib le because of 
opportunities made available by the project. Some 
475 
