Proceedings of the BioNLP Shared Task 2013 Workshop, pages 109?115,
Sofia, Bulgaria, August 9 2013. c?2013 Association for Computational Linguistics
Improving Feature-Based Biomedical Event Extraction System by In-
tegrating Argument Information 
Lishuang Li, Yiwen Wang, Degen Huang 
School of Computer Science and Technology 
Dalian University of Technology 
116023 Dalian, China 
lilishuang314@163.com yeevanewong@gmail.com 
huangdg@dlut.edu.cn 
 
Abstract 
We describe a system for extracting biomedi-
cal events among genes and proteins from 
biomedical literature, using the corpus from 
the BioNLP?13 Shared Task on Event Extrac-
tion. The proposed system is characterized by 
a wide array of features based on dependency 
parse graphs and additional argument informa-
tion in the second trigger detection. Based on 
the Uturku system which is the best one in the 
BioNLP?09 Shared Task, we improve the per-
formance of biomedical event extraction by 
reducing illegal events and false positives in 
the second trigger detection and the second ar-
gument detection. On the development set of 
BioNLP?13, the system achieves an F-score of 
50.96% on the primary task. On the test set of 
BioNLP?13, it achieves an F-score of 47.56% 
on the primary task obtaining the 5th place in 
task 1, which is 1.78 percentage points higher 
than the baseline (following the Uturku sys-
tem), demonstrating that the proposed method 
is efficient. 
1 Introduction 
Extracting knowledge from unstructured text is 
one of the most important goals of Natural Lan-
guage Processing and Artificial Intelligence. Re-
sources in the internet are expanding at an expo-
nential speed, especially in the biomedical do-
main. Due to the astronomical growth of biomed-
ical scientific literature, it is very important and 
urgent to develop automatic methods for know-
ledge extraction system. 
In the past few years, most researchers in the 
field of Biomedical Natural Language Processing 
focused on extracting information with simple 
structure, such as named entity recognition 
(NER), protein-protein interactions (PPIs) (Air-
ola et al, 2008; Miwa et al, 2009) and disease-
gene association (Chun et al, 2006). While PPIs 
concern the flat relational schemas with no 
nested structures, bio-molecular events describe 
the detailed behavior of bio-molecules, which 
capture the biomedical phenomena from texts 
well. The BioNLP?09 shared task (Kim et al, 
2009) provides the first entry to bio-event extrac-
tion. As described in BioNLP?09, a bio-event 
consists of a trigger and one or more arguments, 
where a trigger is a contiguous textual string con-
taining one or more tokens and an argument is a 
participant (event or protein) with a correspond-
ing type. For example, in the snippet ?interferon 
regulatory factor 4 gene expression?, the event 
trigger is ?expression? which is tagged by the 
event type ?Gene_expression? and the event ar-
gument is ?interferon regulatory factor 4?. Not-
ably, bio-events may have arbitrary arguments 
and even contain other events as arguments, re-
sulting in nested events. 
The complex event structure makes this task 
particularly attractive, drawing initial interest 
from many researchers. Bj?rne et al's (2009) 
system (referred to hereinafter as Uturku system) 
was the best pipeline system in BioNLP?09, 
achieving an F-score of 51.95% on the test data 
sets. After that, Miwa et al (2010a, 2010b) com-
pared different parsers and dependency represen-
tations on bio-event extraction task and obtained 
an F-score of 57.79% on development data sets 
and 56.00% on test data sets with parser ensem-
ble. In contrast to the pipeline system which di-
vided the event process into three stages, triggers 
detection, arguments detection and post 
processing, Poon and Vanderwende?s (2010) and 
Riedel et al?s (2009) joint models combined 
trigger recognition and argument detection by 
using a Markov logic network learning approach. 
After the BioNLP?09, the Genia event task (Bi-
oNLP?11 task 1, hereafter) in the BioNLP?11 
Shared Task (Kim et al, 2011) introduced a 
same event extraction task on a new dataset. 
There were still some pipeline systems applied to 
Genia task 1, e.g. Bj?rne et al?s (2011) system 
and Quirk et al?s (2011) system. To the best of 
109
our knowledge, Miwa et al?s (2012) pipeline 
system incorporating domain adaptation and co-
reference resolution, is the best biomedical event 
extraction system on BioNLP'11 task 1 so far. 
The Genia event extraction task (BioNLP'13 
task 1, hereafter) (Kim et al, 2013) in Bi-
oNLP'13 Shared Task is consistent with the Ge-
nia task in BioNLP'11 Shared task. Nevertheless, 
BioNLP'13 task 1 focuses on event extraction 
from full texts while BioNLP?11 task 1 contains 
abstracts and full texts. Furthermore, the corefe-
rence resolution task separated from event ex-
traction task in BioNLP'11 is integrated to Bi-
oNLP'13 task 1, and there are more event types 
in the BioNLP'13 task 1 than those in BioNLP'11 
task 1. The BioNLP?13 shared task contains 
three parts, the training corpus, the development 
corpus and the test corpus. The training corpus 
consists of 10 full texts containing 2792 events. 
The development corpus for optimizing the pa-
rameters involves 10 full texts containing 3184 
events, while the test corpus is composed of 14 
full texts including 3301 events. To avoid the 
researchers optimizing parameters on the test 
corpus, it is not published, and we have the per-
mission to combine the training corpus and the 
development corpus as training set. However, we 
extend BioNLP'13 training set by adding the ab-
stracts of training set and development set in Bi-
oNLP'11 task 1 rather than merging the devel-
opment set of BioNLP'13 into the training set.  
Our system generally follows the Uturku sys-
tem reported by Bj?rne et al (2009), and uses a 
simple but efficient way to reduce the cascading 
errors. The Uturku system was a pipeline of trig-
ger detection, argument detection and post-
processing. Each of its components was simple  
to implement by reducing event extraction task 
into independent classification of triggers and 
arguments. Moreover, the Uturku system devel-
oped rich features and made extensive use of 
syntactic dependency parse graphs, and the rules 
in the post-processing step were efficient and 
simple. However, the stages of the pipeline in-
troduced cascading errors, meaning that the trig-
ger missed in the trigger detection would never 
be recalled in the following stages. By changing 
the pipeline and adding argument information in 
trigger detection, we construct a model for ex-
tracting complex events using rich features and 
achieve better performance than the baseline sys-
tem implemented according to Bj?rne et al's 
(2009) paper. 
2 Our Event Extraction System  
Fig.1 shows the overall architecture of the pro-
posed system. Since 97% of all annotated events 
are fully contained within a single sentence, our 
system deals with one sentence at a time, which 
does not incur a large performance penalty but 
greatly reduces the size and complexity of the 
machine learning problems (Bj?rne et al, 2009). 
The system?s components are different from 
those of the Uturku system by adding a second 
trigger detection component and a second edge 
detection component (argument detection). Trig-
ger detection component is used to recognize the 
trigger words that signify the event, and edge 
detection component is used to identify the ar-
guments that undergo the change. Semantic post-
processing component generates events consis-
tent with the restrictions on event argument types 
and combinations defined in the shared task. 
 
Input data
Sentence splitting
Token zation
Parsing
First Trigger 
detection
(multi-class SVM)
First Edge detection
(multi-class SVM)
Second Trigger 
detection
(multi-class SVM)
Second Edge 
detection
(multi-class SVM)
Semantic
 post-processing
(Rule based)
Output data
 
Figure 1. The flow chart of our system. 
In the following sections, we present the im-
plementation for these stages in our biomedical 
event extraction system in detail and evaluate our 
system on the BioNLP?13 data sets. 
2.1 Trigger Detection 
nuclear extracts showed decreased or absent p65 protein levels
Neg_reg Pro
Theme
 
Figure 2. An example of the trigger consisting of two 
head tokens 
Trigger detection assigns each token an event 
class or a negative class (if the token is not a 
trigger). The head token is chosen when the real 
trigger consists of several tokens, which does not
110
Type Feature 
Primary features The token 
Part-Of-Speech of the token 
Base form 
The rest part of the token, getting rid of the stem word 
Token feature Token has a capital letter 
Token has a first letter of the sentence 
Token has a number 
Token has a symbol like ?-?,?/?,?\? 
N-grams (n = 2, 3) of characters 
Govern and Dependent feature Dependency type 
Part-Of-Speech (POS) of the other token 
Combine the POS and the dependency type 
The word form of the other token 
Frequency features Number of named entities in the sentence 
Bag-of-word counts of token texts in the sentence 
Shortest path Token features of the token in the path 
N-grams of dependencies (n =2, 3, 4) 
N-grams of words (base form + POS) (n =2, 3, 4) 
N-grams of consecutive words (base form + POS) representing 
Governor-dependent relationships (n =1, 2, 3) 
Table 1: Features for the first trigger detection 
Type Feature 
Path feature The token in the path 
The POS of the token in the path 
The dependency type of edges in the path 
(all these features are combined with direction, length and the entity type) 
Table 2: Added feature for the second trigger detection 
incur performance penalty with the approximate 
span matching/approximate recursive matching 
mode (Kim et al, 2009).  Two head tokens may 
be chosen from one trigger when the trigger con-
sists of two appositives. For example, for the 
snippets ?decreased or absent p65 protein le-
vels?, both ?decreased? and ?absent? are the 
head token of the trigger ?decreased or absent?, 
shown in Fig 2. Rich features are extracted for 
the first trigger detection, shown in Table 1. 
To remove the erroneous events and correct 
the event type assigned in the first trigger detec-
tion, a second trigger detection is added in our 
system. Thus the second trigger detection is dif-
ferent from the first one. Uturku system shows 
that the trigger information improves the edge 
detection because of the constraints on the type 
of arguments. Naturally, the edge information is 
helpful for trigger detection with the same reason. 
As a result, this method can improve the preci-
sion of trigger performance. 
In order to leverage the argument information, 
we explore a lot of features of the edges which 
are the arguments detected in the first edge de-
tection. The edge information concerns the fea-
tures of the edges attached to the token. In the 
second trigger detection, we add all the path fea-
tures between the candidate trigger and argu-
ments attached to the candidate trigger detected 
in the first edge detection. These features contain 
the entity information of the argument, the de-
pendency path between the trigger and the argu-
ment and so on. Specially, the added features 
cannot contain any trigger type information ob-
tained in the first trigger detection, or the added 
features cannot do any help. The reason is that 
SVM classifier will classify samples only relying 
on the label feature if it is in the feature set. The 
added features are shown in Table 2. 
 
 
111
Type Features 
N-grams N-grams of consecutive tokens(n=2,3,4) in the path 
N-grams of vertex walks 
Terminal node feature Token feature of the terminal nodes 
The entity type of the terminal nodes 
Re-normalized confidences of all event class 
Frequency feature The length of the path 
The number of entities in the sentence 
Edges feature in the path Dependency type of the edges in the path 
The POS of the tokens in the path 
The tokens in the path 
Table 3: Features for edge detection 
2.2 Edge Detection 
Similar to the trigger detector, the edge detector 
is based on a multi-class SVM classifier. An 
edge is from a trigger to a trigger or from a trig-
ger to a protein. The edge detector classifies each 
candidate edge as a theme, a cause, or a negative 
denoting the absence of an edge between the two 
nodes in the given direction. The features in edge 
detection are shown in Table 3. As the trigger 
information is helpful in edge detection, the ter-
minal node feature contains it. Additionally?the 
first edge detection is completely the same as the 
second one, that is, they share the same features 
and machine learning strategy. 
2.3 Semantic Post-processing 
After the trigger detection and edge detection, 
the biomedical event cannot be produced directly. 
Some simple events may be attached with sever-
al proteins, and complex events may form circles. 
We develop a custom rule-based method to gen-
erate events that are consistent with the restric-
tions on event argument types and combinations 
defined in the shared task. For details, Bj?rne et 
al.?s (2009) paper can be referred to. 
3 Tools and Component Combination  
We use the support vector machine (SVM) mul-
ti-class classifier (Crammer and Singer (2002),  
Tsochantaridis et al (2004)) in the trigger detec-
tion and edge detection. Besides, the dependency 
parser used in our system is McClosky-Charniak 
domain-adapted parser (McClosky and  Charniak 
(2008)) and the dependency parse was provided 
in the share task1 . To optimize the precision-
recall trade-off, we introduce ? that decreases the 
classifier confidence score given to the negative 
                                                 
1 http://2013.bionlp-st.org/supporting-resources 
trigger class as formula (1) as the Uturku system 
does (2009).  
score = score-(1-?)*abs(score)       (1) 
where abs(score) means the absolute value of 
score and ??[0,1]. 
4 Evaluations and Discussion 
4.1 Evaluations 
Firstly, our system is evaluated on the develop-
ment set. Table 4 compares the performance be-
tween our system and the baseline. The baseline 
is implemented based on Bj?rne et al?s (2009) 
paper. Compared to baseline, the precision of our 
system is 6.08 percentage points higher while the 
recall increases 0.91 percentage points. From 
Table 4 we can see that our system is 2.85 F-
score higher than the baseline system. 
 
 Recall  Precision F-score 
Baseline  43.15 54.37 48.12 
Ours 44.06 60.45 50.97 
Table 4: Performance comparison on the development 
set using approximate span and recursive matching 
Secondly, the performance of our system is 
evaluated on the test data set with online evalua-
tion2. Table 5 shows the results for the baseline 
and the proposed system with argument informa-
tion to evaluate the importance of argument in-
formation. Integrating argument information, our 
system archives 1.78% F-score improvement. 
Compared to the baseline, the performance for 
complex events is very encouraging with about 
7.5 percentage points improvement in the Phos-
phorylation events, 1.77 percentage points im-
provement in the regulation events, 2.91 percen- 
                                                 
2 http://bionlp-st.dbcls.jp/GE/2013/eval-test/ 
112
Event type # Our system Baseline 
R/P/F-score R/P/F-score 
Gene_expression 619 77.54/82.76/80.07 79.48/78.10/78.78 
Transcription 101 49.50/65.79/56.50 53.47/62.79/57.75 
Protein_catabolism 14 78.57/55.00/64.71 78.57/45.83/57.89 
Localization 99 35.35/89.74/50.72 38.38/84.44/52.78 
=[SIMPLE ALL]= 833 69.15/80.56/74.42 71.43/75.80/73.55 
Binding 333 40.84/44.16/42.43 42.64/44.65/43.63 
Protein_modification 1 0.00/0.00/0.00 0.00/0.00/0.00 
Phosphorylation 160 75.00/77.42/76.19 69.38/68.10/68.73 
Ubiquitination 30 0.00/0.00/0.00 0.00/0.00/0.00 
Acetylation 0 0.00/0.00/0.00 0.00/0.00/0.00 
Deacetylation 0 0.00/0.00/0.00 0.00/0.00/0.00 
=[PROT-MOD ALL]= 191 62.83/77.42/69.36 58.12/68.10/62.71 
Regulation 288 15.28/42.72/22.51 14.58/35.90/20.74 
Positive_regulation 1130 29.20/44.47/35.26 26.11/42.51/32.35 
Negative_regulation 526 26.81/41.47/32.56 25.10/35.11/29.27 
=[REGULATION ALL]= 1944 26.49/43.46/32.92 24.13/39.51/29.96 
==[EVENT TOTAL]== 3301 40.81/57.00/47.56 39.90/53.69/45.78 
Table 5: Approximate span matching/approximate recursive matching on test data set. 
Th(E1)
Triggering of the human interleukin-6 gene by interferon-gamma and tumor necrosis factor-alpha 
Binding Pro Pro Pro
Th(E2) Th(E1)Th(E2)
  
(a) Th(E1)
Triggering of the human interleukin-6 gene by interferon-gamma and tumor necrosis factor-alpha 
Pos-Reg Pro Pro Pro
Cause(E2) Cause(E1)Th(E2)
 
(b) 
Figure 3: (a) A result of a fragment using the first trigger detection. (b) A result of a fragment using the second 
trigger detection. 
tage points improvement in the positive regula-
tion events and 3.29 percentage points increase 
in the negative regulation events, but not much 
loss in other events. As a consequence, the total 
F-score of our system is 47.56%, 1.78 percentage 
points higher than the baseline system and ob-
tains the 5th place in BioNLP'13 task 1. 
4.2 Discussion 
Our system achieves better performance than the 
baseline thanks to the second trigger detection. 
The second trigger detection improves the per-
formance of event extraction in two ways. Firstly, 
the triggers that cannot form events are directly 
deleted, and therefore the corresponding errone-
ous events are deleted. Secondly, since the erro-
neous triggers are deleted or the triggers recog-
nized in the first trigger detection are given the 
right types in the second trigger detection, the 
corresponding arguments are reconstructed to 
form right events. Fig.3 shows an example. In 
the first trigger detection, the trigger ?triggering? 
is recognized as the illegal type of ?binding? so 
that ?interferon-gamma? and ?tumor necrosis 
factor-alpha? are illegally detected as theme ar-
guments of ?triggering?, resulting in erroneous 
events. However, in the second trigger detection, 
113
?triggering? is correctly revised as the type of 
positive regulation, so the arguments are recon-
structed, which makes the positive regulation 
events (E1 and E2) right. As a result, the preci-
sion of event detection increases as well as the 
recall. 
The proposed method is an efficient way to 
reduce cascading errors in pipeline system. 
Moreover, Riedel and McCallum (2011) pro-
posed a dual decomposition-based model, anoth-
er efficient method to get around cascading er-
rors. Following Riedel et al?s (2011) paper, we 
implement a dual decomposition-based system 
using the same features in our system. Table 6 
shows the performance comparison on the devel-
opment set of BioNLP?09 between our system 
and dual decomposition-based system. The com-
parison indicates that the proposed method is 
comparable to the stat-of-the-art systems.  
 
 Recall  Precision F-score 
Dual Decom-
position 
50.08 63.66 56.06 
Ours 53.88 59.67 56.63 
Table 6: Performance comparison on the development 
set of BioNLP?09 using approximate span and recur-
sive matching based on different methods 
5 Conclusions 
We proposed a simple but effective method to 
improve event extraction by boosting the trigger 
detection. The added edge information in the 
second trigger detection improves the perfor-
mance of trigger detection. Features from the 
dependency parse graphs are the main features 
we use for event extraction. 
The future work includes: the first trigger de-
tection should classify a token into three classes: 
simple event type, complex event type and none 
event type; discovering some more helpful edge 
features in the second trigger detection; solving 
coreference problem with coreference resolution 
approach. Besides, the dual decomposition-based 
method will be improved and further compared 
with the pipeline system. 
 
Acknowledgments 
 
This work is supported by grant from the Nation-
al Natural Science Foundation of China (no. 
61173101, 61173100). 
References  
Antti Airola, Sampo Pyysalo, Jari Bj?rne, Tapio Pa-
hikkala, Filip Ginter, and Tapio Salakoski. 2008. 
All-paths graph kernel for protein-protein interac-
tion extraction with evaluation of cross-corpus 
learning. BMC Bioinformatics, 9(Suppl 11):S2. 
Chris Quirk, Pallavi Choudhury, Michael Gamon, and 
Lucy Vanderwend. 2011. MSR-NLP Entry in Bi-
oNLP Shared Task 2011. In Proceedings of the Bi-
oNLP 2011 Workshop Companion Volume for 
Shared Task, Portland, Oregon, June. Association 
for Computational Linguistics. 
David McClosky and Eugene Charniak. 2008. Self-
training for biomedical parsing. In Proceedings of 
ACL-08: HLT, Short Papers, pages 101?104. Asso-
ciation for Computational Linguistics. 
Hoifung Poon, Lucy Vanderwende. 2010. Joint Infe-
rence for Knowledge Extraction from Biomedical 
Literature. In Proceedings of the North American 
Chapter of the Association for Computational Lin-
guistics-Human Language Technologies 2010 con-
ference. 
Hong-Woo Chun, Yoshimasa Tsuruoka, Jin-Dong 
Kim, Rie Shiba, Naoki Nagata, Teruyoshi Hishiki, 
and Jun?ichi Tsujii. 2006. Extraction of gene-
disease relations from medline using domain dic-
tionaries and machine learning. In Proceedings of 
the Pacific Symposium on Biocomputing (PSB?06), 
pages 4?15. 
Ioannis Tsochantaridis, Thomas Hofmann, Thorsten 
Joachims, and Yasemin Altun. 2004. Support vec-
tor machine learning for interdependent and struc-
tured output spaces. In Proceedings of the Twenty-
first International Conference on Machine Learn-
ing (ICML?04), pages 104?111. ACM. 
Jari Bj?rne, Juho Heimonen, Filip Ginter, Antti Airola, 
Tapio Pahikkala, and Tapio Salakoski. 2009. Ex-
tracting complex biological events with rich graph-
based feature sets. In Proceedings of the BioNLP 
2009 Workshop Companion Volume for Shared 
Task, pages 10?18, Boulder, Colorado, June. Asso-
ciation for Computational Linguistics.  
Jari Bj?rne and Tapio Salakoski. 2011. Generalizing 
biomedical event extraction. In Proceedings of the 
BioNLP 2011 Workshop Companion Volume for 
Shared Task, Portland, Oregon, June. Association 
for Computational Linguistics. 
Jin-Dong Kim, Tomoko Ohta, Sampo Pyysalo, Yo-
shinobu Kano, and Junichi Tsujii. 2009. Overview 
of BioNLP?09 Shared Task on event extraction. In 
Proceedings of the NAACL-HLT 2009 Workshop 
on Natural Language Processing in Biomedicine 
(BioNLP?09). ACL. 
Jin-Dong Kim, Sampo Pyysalo, Tomoko Ohta, Robert 
Bossy, and Jun?ichi Tsujii. 2011. Overview of Bi-
114
oNLP Shared Task 2011. In Proceedings of the Bi-
oNLP 2011 Workshop Companion Volume for 
Shared Task, Portland, Oregon, June. Association 
for Computational Linguistics. 
Jin-Dong Kim, Yue Wang and Yamamoto Yasunori. 
2013. The Genia Event Extraction Shared Task, 
2013 Edition - Overview. In Proceedings of the Bi-
oNLP Shared Task 2013 Workshop, Sofia, Bulgaria, 
Aug. Association for Computational Linguistics. 
Koby Crammer and Yoram Singer. 2002. On the al-
gorithmic implementation of multiclass kernel-
based vector machines. Journal of Machine Learn-
ing Research, 2:265?292. 
Makoto Miwa, Rune S?tre, Yusuke Miyao, and-
Jun?ichi Tsujii. 2009. A rich feature vector for 
protein?protein interaction extraction from mul-
tiple corpora. In EMNLP?09: Proceedings of the 
2009 Conference on Empirical Methods in Natu-
ral Language Processing, pages 121?130, Morris-
town, NJ, USA. Association for Computational 
Linguistics. 
Makoto Miwa, Sampo Pyysalo, Tadayoshi Hara, and 
Jun?ichi Tsujii. 2010a . A comparative study of 
syntactic parsers for event extraction. In Proceed-
ings of BioNLP?10  p. 37?45. 
Makoto Miwa, Sampo Pyysalo, Tadayoshi Hara, and 
Jun?ichi Tsujii. 2010b. Evaluating dependency re-
presentation for event extraction. In Proceedings of 
the 23rd International Conference on Computa-
tional Linguistics, COLING ?10, Association for 
Computational Linguistics, 2010; p. 779?787. 
Makoto Miwa, Paul Thompson, and Sophia Anania-
dou. 2012. Boosting automatic event extraction 
from the literature using domain adaptation and co-
reference resolution. Bioinformatics.  
Sebastian Riedel, Hong-Woo Chun, Toshihisa Taka-
gi,and Jun?ichi Tsujii. 2009. A Markov logic ap-
proach to bio-molecular event extraction. In Bi-
oNLP?09: Proceedings of the Workshop on BioNLP, 
pages 41-49, Morristown, NJ, USA. Association 
for Computational Linguistics. 
Sebastian Riedel and Andrew McCallum. 2011. Ro-
bust Biomedical Event Extraction with Dual De-
composition and Minimal Domain Adaptation. In 
Proceedings of the BioNLP 2011 Workshop Com-
panion Volume for Shared Task, Portland, Oregon, 
June. Association for Computational Linguistics. 
115
