A PRODUCTION SYSTEM MODEL OF FIRST LANGUAGE ACQUISITION 
Pat Langley 
Department of Psychology 
Carnegie-Mellon University 
Pittsburgh, Pennsylvania USA 15213 
Abstract 
AMBER is a model of first language 
acquisit ion that improves its 
performance through a process of error 
recovery. The model is implemented in 
ACTG, an adaptive production system 
language. AMBER starts with the abil ity 
to say only one word at a time, but adds 
rules for inserting additional words in 
the correct order, based on comparisons 
between predicted and observed 
sentences. These insertion rules may be 
overly general and lead to errors of 
commission; in turn, these lead to more 
conservative rules with additional 
conditions. AMBER's learning mechanisms 
account for many of the developments 
observed in children's speech. 
Introduction 
The acquisit ion of language has been 
a popular topic among researchers in 
Artif icial Intelligence. Impressive 
language learning programs have been 
developed by Siklossy \[i\], Hedrick \[2\], 
Anderson \[3\], Selfridge \[4\], and Berwick 
\[5\]. The general ity and power of these 
systems vary greatly, but they share one 
characteristic: none of the programs 
provide a psychological ly plausible 
model of children's language learning. 
In this paper I describe the 
beginnings of a more realistic model of 
first language acquisition. This model 
is called AMBER, an acronym for 
Acquisit ion Model Based on Error 
Recovery. As its name implies, the 
model simulates the incremental nature 
of the child's language learning 
process. AMBER is concerned with the 
production component of children's 
speech, since most of the reliable data 
relate to production rather than the 
understanding process. 
Below I summarize the major 
developments found during this period. 
After this, I present an overview of 
ACTG, the production system language in 
which the model is stated. Next I 
consider some assumptions about the 
child's l inguistic knowledge at various 
stages during the learning process. 
After considering the initial and final 
stages of AMBER, I discuss the learning 
mechanisms leading to the transition 
process. Finally, I consider the 
l imitations of the model and propose 
directions for future research. 
The Mayor Phenomena 
Children do not learn language in an 
all-or-none fashion. They begin their 
l inguistic careers uttering one word at 
a time, and slowly evolve through a 
number of stages, each co~taining speech 
more like that of the adult than the one 
before. In this section I discuss the 
features of the three stages which AMBER 
attempts to explain. I discuss these 
stages in their order of occurrence, 
dealing only with the major phenomena in 
each case. 
The One-Word Stage 
Around the age of one year, most 
children begin to produce words in 
isolation, and continue this strategy 
for some months. Presumably tile child 
spends much of this period connecting 
particular words to particular concepts; 
once this has been done, he can produce 
these words under the appropriate 
circumstances. AMBER does not attempt 
to explain the word-learning process. 
Like Anderson's LAS \[3\], it assumes that 
links between words and concepts have 
already been established. 
Bloom \[6\] has examined this period in 
detail, with an eye to understanding the 
relation between the one-word stage and 
those which follow it. Early in this 
stage, successive one-word utterances 
seem entirely disconnected; the child 
randomly comments on anything that 
happens to be in the environment. 
Later, he begins to name in succession 
different aspects of the same event or 
object; words are still separated by 
noticeable pauses and no regular order 
can be detected, but conceptual 
continuity seems present. Moreover, 
this development occurs only a few 
months before the child begins to 
combine words into very simple 
sentences. AMBER's starting point lies 
somewhere within this later part of the 
one-word stage. 
-183 
Teleg \[.#phi c Speech 
Around the age of 18 months, the 
chi ld begins to combine words into 
meaningfu l  sequences. In order -based 
languages such as Engl ish, the chi ld 
usual ly  fo l lows the adult  order. 
In i t ia l ly  only pairs of words are 
produced, but these are fol lowed by 
three-word and later by four-word 
utterances.  The simple sentences 
occurr ing in this stage consist  almost 
ent i re ly  of content words. Brown \[7\] 
has descr ibed speech during this period 
as te legraphic,  s ince g rammatical  
morphemes such as tense endings and 
prepos i t ions  are absent, as they would 
be in a telegram. 
Brown has also noted that the 
major i ty  of two-word utterances express 
a rather small set of pairwise semantic  
relat ions. AMBER assumes a small number 
of case re lat ions such as agent,  action, 
and possess ion from which Brown's 
pairwise re lat ions can be derived. In 
addit ion,  tile chi ld uses a few funct ion 
words l ike "there", "more", and 
"al l -gone" to express s imple forms of 
nominat ion,  recurrence,  and negation. 
AMBER attempts to learn the relat ive 
word orders for express ing these 
recurr ing relat ions. 
The Acqu is i t ion  of Grammat ica l  Morphemes 
Brown \[7\] has also studied the period 
from about 24 to 40 months, during which 
the chi ld masters  the grammat ica l  
morphemes which were absent during the 
previous stage. Brown pointed out that 
these morphemes modulate  the major 
meanings of sentences which are 
expressed through content words. AMBER 
ref lects this d is t inct ion  by 
represent ing the informat ion expressed 
by contents  words and grammat ica l  
morphemes in d i f ferent  ways. These 
morphemes are learned gradual ly;  the 
time between the init ial  product ion of a 
morpheme and its mastery  (i.e., when it 
is correct ly  used in all required 
contexts) may be as long as 16 months. 
In addit ion, Brown has examined the 
order in which 14 Engl ish morphemes are 
acquired,  and has found this order to be 
remarkably  cons istent  across chi ldren. 
For example, present  progress ive 
(eating) and plural (dogs) were always 
learned quite early, whi le third person 
s ingular (eats) and copulas (is, are) 
took longer. He found that the 
syntact ic  and semantic complex i t ies  of 
the morphemes were h ighly  corre lated 
with their order of mastery.  Since the 
current  vers ion of AMBER cannot deal 
with except ions,  I wil l  consider only 
regular const ruct ions  in this paper. 
The ACTG Formal ism 
AMBER is implemented in ACTG, an 
adapt ive product ion system language. 
Below I present  an overv iew of AC%G, 
beginning with a d iscuss ion of its 
propos i t ional  network. After this I 
consider the representat ion  of 
procedures as product ions.  Final ly,  I 
examine ACTG's fac i l i t ies for changing 
its own behavior  through the creat ion of 
new product ions.  
The Propos i t ional  Network 
ACTG stores its factual,  dec larat ive  
knowledge in a long-term propos i t ional  
network.  Individual  facts are stored as 
propos i t ions ,  which may be arb i t rary  
l ist structures.  As we wil l  see in more 
detai l  below, AMBER incorporates  two 
main types of propos i t ions.  One sort 
expresses a goal to say a part icular  
word in a certa in posit ion.  The second 
type of propos i t ion  expresses  var ious 
kinds of relat ions,  including facts l ike 
x possesses y, y is a *ball, and "ball" 
is the word for *ball (where concepts 
are preceded by "*" to d is t ingu ish  them 
from their assoc iated words). 
At any given time, some subset of the 
propos i t ional  network is active. Many 
of the act ive propos i t ions  have been 
recent ly  added to the network by 
product ions.  Others, after lying 
dormant for a time, have been 
react ivated through their assoc iat ion 
(i.e., sharing of symbols) with other 
recent ly act ivated facts. AMBER uses 
this process of spreading act ivat ion 
pr imar i ly  to retr ieve informat ion about 
the words assoc iated with part icu lar  
concepts.  The level of act ivat ion for a 
propos i t ion  natura l ly  decays over time, 
unless it is of fset  by other factors. 
The Product ion System 
ACTG represents procedural  knowledge 
as a set of cond i t ion -act ion  rules 
cal led product ions.  The condi t ions and 
act ions of these rules can be quite 
general ,  s ince they may contain 
var iab les  that match against  arb i t rary  
structures.  When all the condi t ions of 
a product ion match against  some port ion 
of act ive memory, its act ions may be 
carr ied out. These may interact with 
the environment,  or add new propos i t ions  
to the act ive part of the network. 
Structures matching var iab les  in the 
condi t ions remain bound to these 
var iab les  in the actions. After a 
product ion has been appl ied, the state 
of memory is reexamined and the system 
cycles. 
184- 
If two or more product ions  are found 
to be true, one must be selected in 
preference to the others. Th is  dec is ion 
is based on the relat ive strength ~ of 
the product ions,  and on the summed 
act ivat ions of the propos i t ions  matched 
by each. The product  of these two 
numbers is computed,  and the product ion 
with the h ighest  value is selected. 
Since a s ingle product ion can match 
against  a set of propos i t ions  in 
d i f ferent  ways, ties may somet imes 
occur. In such cases, one of the 
matches is selected at random. 
The ACTG Learning Mechanisms 
ACTG incorporates a powerful  set of 
mechanisms for model ing learning 
phenomena. The most basic of these is 
the des ignat ion process, which al lows 
the creat ion of a new product ion  as one 
of the act ions of an exist ing rule. 
Var iab les  bound in the condi t ions of the 
learning rule are passed to the 
of fspr ing,  making the new rule more 
speci f ic  than its creator.  Most of 
AMBER'S learning heur is t ics  rely on the 
des ignat ion  process. 
A second mechan ism leads to the 
st rengthening of a product ion each time 
it is recreated. Since the strength of 
a rule plays an important role in the 
select ion phase, product ions  which have 
been relearned many times will be 
preferred.  On the other hand, the 
strength of a rule can be decreased if 
it leads to an error, lowering its 
chances for select ion. 
The d iscovery  of an error also leads 
to a call on the d iscr iminat ion  process. 
Here the recent f i r ings of the 
responsib le product ion are examined. If 
one or more propos i t ions  have been 
present  at successful  f i r ings and absent 
at faulty ones, they are added as extra 
condi t ions on a new, more conservat ive  
vers ion of the rule. Together with the 
st rengthening and weakening processes,  
this mechanism gives ACTG the abi l i ty  to 
recover from overgenera l i zat ions .  
AMBER's  L inguist ic  Knowledge 
Learning is the result of an 
interact ion between a set of re lat ive ly  
general  techniques for acquir ing 
knowledge and the envi ronment  in which 
they find themselves.  In this sect ion I 
consider AMBER's representat ion of that 
environment.  After this I examine the 
procedures the model assumes at the 
outset,  as well as the form of the rules 
at which it eventual ly  arr ives. 
Represent ing Sentences 
Before AMBER can learn how to 
generate  legal sentences,  it must be 
exposed to examples of such sentences.  
One might  represent  a sentence as a 
simple l ist of words in the order they 
are said. However, though chi ldren 
learn to produce words in the correct  
order very ear ly on, they also omit many 
words that an adult  would include. For 
example, the utterance "Daddy ball" 
omits informat ion about the act ion being 
carr ied out, as well as tense 
information.  AMBER's  representat ion of 
the sentences it hears ref lects this 
abi l i ty  to note order in the absence of 
informat ion about adjacency.  
The model represents the occurrence 
of each morphem e as a separate 
proposi t ion,  each conta in ing informat ion 
about the speaker, the word being 
produced, and the relat ive order of 
occurrence.  Thus, the fact that Mommy 
said the sentence "Daddy bounces the 
ball" would be stored as a set of seven 
propos i t ions:  (said 1 Mommy pause); 
(said 2 Mommy Daddy); (said 3 Mommy 
bounce); (said 4 Mommy s) ; (said 5 Mommy 
the); (said 6 Mommy ball); and (said 7 
Mommy pause). The first and last 
propos i t ions  act as de l imi tors  which 
mark the beginning and end of the 
sentence. This representat ion,  combined 
with ACTG's pat tern-match ing capabi l i ty ,  
a l lows the statement of learning rules 
which focus on relat ive word order but 
ignore ad jacency information.  The 
result ing product ion rules omit words, 
just as the chi ld does. 
Represent ing Meaning 
Adults  convers ing with a chi ld almost 
invar iably  d iscuss recent or ongoing 
events, so that the chi ld can associate 
some event with every sentence he hears. 
The language acquis i t ion  process does 
not consist  solely of learning to 
produce or parse legal word 
combinat ions;  it consists  of learning 
the mapping between meanings and words. 
Accordingly ,  AMBER is presented not with 
isolated sentences as its data, but with 
sentence/meaning pairs.  
AMBER represents the meaning of a 
sentence as a number of propos i t ions,  
each incorporat ing one of a small set of 
relat ions. The most prevalent  of these 
is the type relat ion, which connects  
tokens to the var ious concepts of which 
they are examples.  There is no 
restr ic t ion on the number of type 
relat ions which may come off a token; 
-185--- 
thus, the propos i t ions  (token-i type 
red) and (token-i type ball) state that 
the object  token-i  is both red and a 
ball. Events are represented with 
re lat ions such as a ~ ,  act ion, and 
object.  The propos i t lons  (event-i agent 
token-2), (event-i act ion token-3),  and 
(event-i object token-4) represent an 
event with an agent, action, and object 
whose types have yet to be specif ied.  
AMBER's  representat ion makes a strong 
d is t inct ion  between the main meaning of 
a sentence as expressed through its 
content words and the modulat ions  of 
this meaning as expressed through its 
grammat ica l  morphemes.  The model 
assumes that a type re lat ion point ing to 
a part icu lar  concept (e.g., *ball) is 
present  for every content word (e.g., 
ball) found in the assoc iated sentence. 
Moreover,  a word- for  re lat ion is assumed 
present to establ ish the connect ion 
between word  and concept. The presence 
of these two relat ions tel ls AMBER when 
a word contr ibutes to the major meaning 
of a sentence. 
Modulat ions  on this meaning are 
represented by a d i f ferent  set of 
relat ions,  such as number, 
t ime-of -act ion,  possess ion,  and so 
forth. Some of these relat ions connect  
tokens to var ious values, as in token-i 
number singular) and token-2 
t ime-of -act ion  past). Others, as in 
(token-4 possesses token-5) and token-5 
in token-6),  actua l ly  relate tokens. 
AMBER's  Init ial  Per formance System 
AMBER starts with the abi l i ty  to 
produce single words in isolat ion. But 
even at this stage, the model draws on a 
set of general  heur is t ics  for generat ing 
utterances which w i l l  sti l l  be useful 
after its learning is complete.  AMBER 
does not say words as soon as they  come 
to mind; f irst there is an act ive 
planning stage during which sequent ia l  
goals  are set. 
The model starts with rules for 
in i t ia l iz ing and ending this p lanning 
phase, and for implement ing its plans 
once they are complete (that is, 
actua l ly  saying the words in the planned 
order). The goals  which result  from the 
planning process look very l ike the data 
from which AMBER learns. The two-word 
utterance "Daddy ball" would be 
represented by the propos i t ions  (goal 1 
AMBER pause),  (goal 2 AMBER Daddy),  
(goal 3 AMBER ball),  and (goal 4 AMBER 
pause), in which the model is the 
speaker. 
At the outset,  AMBER has only a 
single rule for insert ing such goals in 
memory; stated in Engl ish for the sake 
of c lar i ty  and with its var iab les  
underl ined,  it is: 
If you have no goals  yet, 
and you see vtoken with type v type, 
and vword is the word for vtype, 
then set up a goal to pause, 
fol lowed by a goal to say vwo~d, 
fol lowed by a goal to pause. 
This rule separates the goal utterance 
from others by init ial  and final pauses. 
Thus, even though success ive words may 
descr ibe d i f ferent  aspects of the same 
event, they will be separated by 
not iceable  gaps just as Bloom observed. 
Only after addit ional  rules have been 
formed for insert ing sounds between the 
init ial  word and the pauses can 
mul t i -word  utterances begin to occur. 
AMBER at Later Stages 
On the basis of compar isons between 
sentences it hears and those it 
predicts,  AMBER creates and modi f ies  
rules for saying mul t ip le  words at a 
time. These rules lead to the insert ion 
of new goals between exist ing ones. 
Thus, they are dependent  on the innate 
rules descr ibed above for in i t ia l iz ing 
the goal insert ion process and for 
carrying out goals  once they have been 
set. 
Imagine a s i tuat ion in which AMBER 
sees Daddy bouncing a ball. Also 
suppose that the one-word rule we saw 
above happens to select "bounce" as the 
word that should be said. This would 
lead to three goals: (goal 1 AMBER 
pause),  (goal 2 AMBER bounce),  and (goal 
3 AMBER pause). After some exper ience 
with English, the model will have 
generated a rule like: 
If you have a goal to pause, 
fol lowed by a goal to say vword2, 
and you have no intermediate goals,  
and vword2 is the word for vtype2, 
and vtoken2 is of type vtype2, 
and vtoken2 is the act ion of vevent, 
and vtokenl  is the agent of vevent,  
and Vtokenl  is of type vty~el, 
and vwordl  is the word for vtypel, 
then insert a goal to say vwordl 
between the other goa ls - -  
This rule would add a goal to say the 
agent "Daddy" after the f irst pause and 
before "bounce", using the propos i t ion  
(goal 1.5 AMBER Daddy). S imi lar  rules 
lead to the product ion of two- and 
three-word sentences express ing the 
major relat ions descr ibed by Brown. 
-186 
Later, AMBER also acquires rules for 
inserting grammatical morphemes. Since 
most grammatical morphemes are adjacent 
to the word whose meaning they modulate, 
they are general ly inserted directly 
before or after the content word with 
which they occur. For example, a rule 
for regular plural ization might be 
stated: 
If you have a goal to say vword, 
and vword is the word for vtype, 
and vtoken is of type vtype, 
and vtoken is the agent of vevent, 
and the number of vtoken is plural, 
then insert a goal to say S 
directly after vword 
This rule is specific to the agent of an 
event, but similar rules could be 
learned for objects and locations. Some 
morphemes express a relation between two 
content words, such as the preposit ions 
"in" and "on" and the morpheme for 
possession. In these cases, the 
morpheme is inserted between the two 
related content words. 
The Acquisit ion Process 
For a system to learn from its 
mistakes, it must be able to compare its 
own actions to the desired ~ones, note 
the differences between them, and modify 
its behavior accordingly. In this 
section I describe AMBER's error 
correction mechanisms. First I examine 
the model's prediction mechanism and its 
relation to the goal structures 
mentioned earlier. Next I discuss 
AMBER's response to errors of omission, 
first for content words and then for 
grammatical morphemes. Finally, I 
consider errors of commission and the 
resulting call on the discr imination 
mechanism. 
The Equivalence of Goals and Predictions 
AMBER learns by comparing its 
predictions about what will be said in a 
given situation to what it actually 
hears. However, a learning system must 
do more than improve its abil ity to 
predict; it must also improve its 
ability to perform. AMBER accomplishes 
this by using the same productions for 
making predictions and for planning its 
speech acts. As we saw above, these 
rules add goal structures such as (goal 
3 AMBER bounce) when AMBER is the 
speaker. When another person is the 
speaker, the resulting structures, such 
as (goal 3 Mommy bounce) if Mommy is the 
speaker, are treated as predictions 
instead of goals. Learning occurs only 
when someone else is speaking and the 
system is in prediction mode, while 
sentences are produced only in 
performance mode. 
Correcting Content Word Omissions 
AMBER's transition from the one-word 
to the multi-word stage is primari ly due 
to the actions of a single learning 
heuristic. This rule applies when a 
content word is heard between two other 
words (or pauses) but was not predicted 
there; the result is a new performance 
rule for inserting analogous words in 
analogous positions in the future. 
AMBER knows enough about the nature of 
language to generalize across the 
particular words and concepts involved. 
However, it retains information about 
case relations and shared tokens (e.g., 
two of the words may have described 
aspects of the same object). 
As an example, suppose AMBER sees 
Daddy bouncing a ball. The model 
predicts the one-word sentence "Daddy" 
(preceded and followed by pauses), while 
it actually hears "Daddy is bounce ing 
the ball" (again bounded by pauses). 
Since the grammatical morphemes "is", 
"ing", and "the" are not connected to 
concepts by word-for links, they are 
ignored by the current learning 
heuristic. However, the words "bounce" 
and "ball" each have associated concepts 
which occurred in the observed event. 
An insertion rule is created for each, 
the first inserting the action word 
after the agent word and before the 
final pause. The second is very 
similar, inserting the object word after 
the agent and before the pause. 
These rules give AMBER the abii ity to 
generate agent-action and agent-object 
combinations, but no more. The new 
rules cannot cooperate to produce 
agent-action-object combinations, for 
once one of the rules has fired, the 
conditions of the other are no longer 
met. But once this has happened, the 
system can learn additional insertion 
rules, such as that for inserting the 
object word between the action and the 
final pause. Yet even after this has 
occurred, the performance rules are 
dependent on the selection of the agent 
word as the initial goal. Additional 
insertion rules must be learned to deal 
with cases in which the action or object 
is the first goal to be inserted. 
- 187-- 
Correct ing Morpheme Omiss ions 
As it is improving its abi l i ty  to 
produce str ings of content  words, AMBER 
is also learning to insert grammat ica l  
morphemes.  Some of the morphemes which 
modi fy  a s ingle token, such as tense and 
p lu ra l i za t ion  endings,  occur after the 
words descr ib ing the token. Others, 
such as copulas (is, are, were) and 
art ic les  (a, the), occur before the 
modi f ied words. Separate learning 
heur is t ics  are necessary  for these two 
cases, but there forms are near ly  
identical .  
These learning rules are evoked when 
a part icu lar  morpheme is heard before or 
after a content  word, but was not 
predicted in that posit ion.  The result  
is a per formance rule which inserts the 
morpheme either before or after words 
playing s imi lar  roles in the future 
(e.g., "ing" after the word for the 
action).  AMBER knows that the 
part icu lar  content  word is i r re levant;  
however,  the case re lat ion f i l led by 
that word and the morpheme are retained. 
AMBER also knows that several  content  
words may be used to descr ibe the same 
object  (e.g., "the big red ball s") , and 
that these words wil l  occur together  in 
any legal sentence. This is analogous 
to an assumpt ion made by Anderson 's  LAS 
\[3\], which he has cal led the 9raph 
deformat ion  condit ion.  AMBER incorpor-  
ates this assumpt ion into its morpheme 
insert ion rules, ensur ing that a 
morpheme will  be inserted either before 
the ear l iest  or after the latest  content  
word descr ib ing a token (thus, "big the 
red s ball" would never be produced).  
The acqu is i t ion  of re lat ional  
morphemes,  such as those express ing 
possess ion and locat ion,  is handled by a 
d i f ferent  rule. This heur is t ic  is 
evoked in the same s i tuat ions  as the 
heur is t ic  for content  words, except that 
the unpredicted morpheme must not be 
assoc iated with any concept  via a 
word- for  link. In addit ion,  the objects  
descr ibed by the two correct ly  predicted 
words  must be d i rect ly  related (e.g., a 
token of milk is on a token of table). 
The result ing per formance rule inserts 
the morpheme between the sets of words 
descr ib ing objects in the observed 
relation. Note that A~BER cannot 
acquire such re lat ional  morphemes until 
it can cor rect ly  predict  the order of 
the words to be related. 
Correct ing Errors of Commiss ion 
Once AMBER has learned a number of 
rules for insert ing goals,  it can make a 
new sort of error: the model can 
incorrect ly  predict  that a word wil l  
occur in a certa in posit ion.  A s ingle 
learning heur ist ic  is suf f ic ient  to deal 
with all such errors of commiss ion.  Its 
condi t ion is simple, but in addi t ion to 
weakening the of fending rule, its act ion 
cal ls on the d i sc r iminat ion  mechan ism to 
produce a more conservat ive  var iant.  
To reiterate,  this technique compares 
the last successfu l  app l i cat ion  of a 
rule to the more recent faul ty  
app l icat ion  in the hope of f inding 
addit ional  condi t ions  to constra in  it in 
the future. Thus, if AMBER predicted 
the sequence "ball red" when "red ball" 
was heard, the d i sc r iminat ion  process 
would be evoked. Compar ing this case to 
an ear l ier  one in which "blue block" was 
cor rect ly  predicted,  AMBER would note 
that "blue" is a color whi le "ball" is 
not. Thus, the new rule would insert 
one word before another descr ib ing the 
same object  only if the former were a 
color l ike "blue" or "red" 
A l though d isc r iminat ion  is useful in 
learning some content  word orders,  its 
major import l ies with grammat ica l  
morphemes.  Since the init ial rules for 
nonre lat iona l  morphmemes are too 
general ,  their use qu ick ly  leads to 
wrong predict ions.  For instance, if the 
morpheme "ed" was incor rect ly  expected 
to fol low an act ion word, AMBER would 
note that correct  pred ic t ions  of "ed" 
occurred only when the time of the 
act ion was past. S imi lar ly,  AMBER would 
qu ick ly  learn to insert "s" after the 
word for the agent only when its number 
was plural.  
The condi t ions  under which some 
morphemes are appl ied can be more 
compl icated.  Thus, the morpheme "were" 
is inserted before the act ion word only 
when the time of the act ion is past, and 
when the nu~er  of the agent assoc iated 
with that act ion is plural.  AMBER would 
be forced to learn these condi t ions  in 
two stages, f irst creat ing a var iant  
with one condi t ion and later a vers ion 
including both. 
As a result, the more complex the 
condi t ions  under which a morpheme 
occurs,  the longer AMBER wil l  take to 
master  its use. If one equates the 
188 
number of condi t ions with semantic  
complexity,  then the d isc r iminat ion  
process provides an elegant explanat ion 
of Brown's data on the order of 
acquis i t ion for grammat ica l  morphemes.  
Semant ica l ly  more complex morphemes are 
mastered later because they require more 
condit ions,  and these condi t ions can be 
learned only one at a time. 
Suggest ions  for Future Research 
In summary, AMBER does a fine job of 
account ing for the major phenomena 
descr ibed at the beginning of the paper. 
However,  the model makes a number of 
s impl i fy ing assumpt ions and stops 
improving after it has reached a certa in 
level of expert ise.  In this sect ion I 
suggest  some d i rect ions in which AMBER 
should be extended. 
Learning Word/Concept  Assoc iat ions  
AMBER assumes that words and concepts 
are a lready connected through word- for  
l inks stored in long- term dec larat ive  
memory. These connect ions  play an 
important  role in lett ing the system 
d is t ingu ish  between content words and 
grammat ica l  morphemes.  At least some of 
these connect ions  must be present  before 
any order ing rules can be learned, but 
the model provides no explanat ion of 
their or igin.  Extending AMBER to let it 
make its own word/concept  assoc iat ions  
is c lear ly  a d i rect ion for future work. 
Select ing a Representat ion  
AMBER rel ies heavi ly  on the 
representat ional  d is t inct ion  between 
major meanings (expressed by type links) 
and modulat ions  of those meanings 
(expressed by others).  Unfor tunate ly  
for the model,  some languages express 
through content  words what others 
express through grammat ica l  morphemes.  
This suggests that the child does not 
start with a representat ion  like 
AMBER's,  though it may arr ive at the 
same point as the result  of exper ience 
with a part icu lar  language. Future 
research should consider how the chi ld 
comes to treat some meanings as major 
and some as minor as a funct ion of his 
nat ive language. 
Deal ing With Except ions 
In its current  version,  AMBER cannot 
deal with i r regular  grammat ica l  
construct ions.  Some past forms, such as 
"ate", require a special  word for past 
events, but this cannot be expressed in 
the current  formal ism for word/concept  
associat ions.  Some plural forms r.equire 
d i f ferent  endings than most, such as 
"oxen". These can be expressed in 
product ion form, but no condi t ions exist 
to d is t inguish these s i tuat ions  from the 
major i ty .  Future vers ions of AMBER 
should have extended representat ions  
which address these issues. 
Expla in ing Later Stage s 
AMBER's  progress ion stops after it 
has mastered the grammat ica l  morphemes.  
It never learns how to ask quest ions,  or 
how to generate sentences with re lat ive 
clauses. In fact, to present the model 
with other than simple dec larat ive  
sentences would be an inv i tat ion to 
disaster.  Future incarnat ions of the 
system should begin with the basic 
not ions of recurs ion and t ransformat ion.  
Coupled with the exist ing learning 
mechanisms and the extens ions d iscussed 
above, this should a l low AMBER to 
progress far beyond its present level of 
expert ise,  and to become a true language 
user. 
References 
\[i\] S ik lossy,  L. Natural  language 
learning by computer.  In H. A. Simon 
and L. S ik lossy (eds.) , Representat ion  
and Meaning: Exper iments  with Infor- 
mat ion Processing Systems. Englewood 
Cl i f fs,  N. J.: Prent ice-Hal l ,  1972. 
\[2\] Hedrick,  C. Dissertat ion,  Carnegie-  
Mel lon Univers i ty,  1974. 
\[3\] Anderson,  J. R. Induct ion of 
augmented transi t ion networks.  Cogni-  
tive Science, 1977, i, 125-157. 
\[4\] Sel fr idge,  M. Dissertat ion,  Yale 
Univers i ty,  1979. 
\[5\] Berwick, R. Dissertat ion,  Massa-  
chusetts  Inst i tute of Technology,  1980. 
\[6\] Bloom, L. One Word at a Time. The 
Hague: Mouton, 1976. 
\[7\] Brown, R. A First Language : The 
Early Stages. Cambridge,  Massachusetts :  
Harvard Univers i ty  Press, 1973. 
Acknowledgements  
This research was supported by Grants 
SPI-7914852 and IST-7918266 from the 
National Science Foundation. I would 
like to thank John R. Anderson for 
useful discussions which led to many of 
the ideas presented in this paper. 
189 
