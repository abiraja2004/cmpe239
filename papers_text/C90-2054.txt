A POLYNOMIAL- -ORDER ALGORITHM 
FOR 
OPT IMAL  PHRASE SEQUENCE SELECT ION FROM A PHRASE LATT ICE  
AND ITS  PARALLEL  LAYERED IMPLEMENTATION 
Kazuh i ko  OZEKI  
The Un ivens  i ty  o f  E lec t  co - -Gommunica< ions  
Cho ' f fu ,  Tokyo ,  \] 82 ,  Japan  
Abst ract  
This paper deals  with a problem of se lec t -  
ing an opt imal  phrase sequence from a phrase 
la t t i ce ,  which is  o f ten  encountered  in 
language process ing  such as word process ing  
and post -process ing  for  speech recogn i t ion .  
The problem is formulated as one of combina- 
to r ia l  opt imizat ion ,  and a polynomial  order 
a lgor i thm is der ived .  This a lgor i thm f inds  
an opt imal  phrase sequence and i t s  dependen- 
cy s t ruc ture  s imu l taneous ly ,  and is there -  
fore par t i cu la r ly  su i ted  for  an in ter face  
between speech  recogn i t ion  and var ious  
language process ing .  What the a lgor i thm does 
is numer ica l  opt imizat ion  ra ther  than sym- 
bo l i c  operat ion  un l ike  convent iona l  pars -  
e rs .  A para l le l  and layered  s t ruc ture  to 
implement the a lgor i thm is a lso presented ,  
Although the language taken up here is Japa- 
nese,  the a lgor i thm can be extended to cover 
a wider :family of languages.  
1. In t roduct ion  
In Japanese language process ing  re la ted  to 
speech recogn i t ion  and word process ing ,  we 
o f ten  encounter  a prob lem of se lec t ing  a 
phrase :sequence which const i tu tes  the most 
acceptab le  sentence from a phrase la t t i ce ,  
that  i s ,  a se t  of phrases  w i th  var ious  
s tar t ing  and end ing pos i t ions ,  By so lv ing  
th i s  problem, l ingu is t i c  ambigu i t ies  and/or  
uncer ta in t ies  coming from the inaccuracy  in 
speech : recogn i t ion  are expected to be re -  
so lved.  
This problem can be so lved,  in p r inc ip le ,  
by enumerat ing a l l  the poss ib le  combinat ions  
of the phrases and measuring the syntact i c  
and semant ic  acceptab i l i ty  of each phrase 
sequence as a sentence .  Obviously,  however, 
the amount of computat ion in th i s  enumera- 
t i ve  method grows exponent ia l l y  with respect  
to the length of the sequence and becomes in -  
t rac tab le  even for a moderate problem s ize .  
In th i s  paper we formulate  th i s  task as a 
combinator ia l  opt imizat ion  prob lem and 
der ive  a set  of recur rence  equat ions ,  which 
leads to an a lgor i thm of polynomial  order in 
t ime and space .  We ut i l i ze  the idea  of 
dependency grammar \[Hays 64\] for  de f in ing  
the acceptab i l i ty  of a phrase sequence as a 
Japanese sentence .  
With a review of recent  theoret i ca l  deve l -  
opment on th i s  top ic ,  a para l le l  and layered 
implementat ion  of the a lgor i thm is p resent -  
ed. 
2. Dependency St ructure  of Japanese 
In Japanese,  words and morphemes are con- 
catenated  to form a l ingu is t i c  un i t  ca l led  
'bnnsetsu ' ,  which is re fe r red  to as simply 
'phrase '  here.  h typ ica l  phrase cons is ts  of 
a content  word fol lowed by some funct iona l  
morphemes, h Japanese sentence is a sequence 
of phrases with a s t ruc ture  which can be de- 
sc r ibed  by a d iagram as in  F ig .  1 
\[Hashimoto 463. For a sequence of phrases  
X lXZ. . .x  n to be a we l l - fo rmed Japanese  
sentence ,  i t  must have a s t ruc ture  sat i s fy -  
ing the fo l low ing  const ra in ts  \[Yoshida 72\]: 
(e l )  For any i ( l< i<n-1) ,  there  ex is ts  
unique j ( i<j<n)  such that  x i modi f ies  xj in 
a wide sense.  
(c2) For any i , j , k ,1  ( l< i< j<k<l<n) ,  i t  
never  occurs  that  x i mod i f ies  x k and xj 
modifies x I. 
A s t ruc ture  sat i s fy ing  these const ra in ts  
is ca l led  a dependency s t ruc ture  here. Mere 
formal ly  we def ine  a dependency s t ruc ture  as 
fo l lows \ [Ozek i  86a\], 
Def in i t ion  1 
(1) I f  x 0 is  a phrase ,  then <x0> is a de- 
pendency s t ruc ture ,  
(2) If  X 1 . . . . .  X n are dependency s t ruc tures  
and x 0 is  a phrase,  then <Xl. . .X n x0> is a 
dependency s t ruc ture .  
A dependency  s t ruc ture  <XI . . .X  n x0> 
(X i=<. . .x i>)  impl ies  that  each x i ,  which is 
the las t  phrase in X i ,  mod i f ies  x 0, I t  is  
eas i ly  ver i f ied  that  a s t ruc ture  sat i s fy ing  
the const ra in ts  (e l )  and (c2) is a dependen- 
cy s t ruc ture  in the sense of Def in i t ion  1 
and v ice versa \[Ozeki 86a3. 
When a dependency s t ruc ture  X is composed 
of phrases Xl,X 2 . . . . .  x n we say that  X is a 
dependency s t ruc ture  on XlX2. . .x  n. The set 
of a l l  the  dependency  s t ruc tures  on 
X lX2 . . .x  n is  denoted as K (X lX2 . . .Xn) :  and 
for a sequence of phrase sets  A1,A 2 . . . . .  A n , 
we def ine  
KB(A 1 ,A 2 . . . . .  A n) 
={X\[XeK(XlX2...Xn), xieh i (l<i<n)}. 
Fig.1 Example of dependency s t ruc ture  
in Japanese.  A,B . . . .  are phrases.  
311 
I 
3. Acceptabi l i ty  of a Dependency Structure 
For a pair  of phrases x 1 and x 0' we can 
think of a penalty  imposed on a modi f ier -  
modificant re la t ion  between x 1 and x 0. This 
non-negative value is denoted as pen(xl ;x0).  
The smaller value of pen(xl;x 0) represents 
the more natura l  l i ngu is t i c  re la t ion .  Al- 
though it  is very important to estab l i sh  a 
way of computing pen(xl ;x0),  we wil l  not go 
into that problem in th is  paper. Based on 
the ' l oca l '  penalty,  a 'g loba l '  penalty P(X) 
of a dependency s t ruc ture  X is de f ined  
recurs ive ly  as fol lows \[0zeki 86a\]. 
Def in i t ion 2 
(1) For X=<x>, P(X)=O. 
(2) For X=<Xl...X n xo>, where X i=<. . .x i>  
(I<i<n) is a dependency s t ructure ,  
P(X)= P(Xl)+...+P(X n) 
+pen(xl;xo)+...?pen(xn;XO). 
Note that P(X) is the sum of the penalty  
of a l l  the phrase pairs which are supposed 
to be in modif ier-modif icant re la t ion  in the 
dependency s t ruc ture  X. This funct ion  is 
invar iant under permutation of X 1 . . . . .  X n in 
accordance with the character i s t i c  of Japa- 
nese. 
4. Formulation of the Problem 
For s imp l i c i ty ,  l e t  us begin  with a 
special  type of phrase la t t i ce  composed of a 
sequence of phrase sets  BI,B 2 . . . . .  B N as 
shown in F ig.2,  which we ca l l  phrase ma- 
t r ix .  Suppose we are given a phrase matrix 
and a re l iab i l i ty  funct ion 
s :  BIUB2U...UB N --> R+, 
where R+ denotes the set  of non-negat ive  
real  numbers. The smal ler  value of s(x)  
represents the higher re l iab i l i ty  of x. We 
encounter th is  special  type of phrase la t -  
t ice in iso lated phrase speech recognit ion.  
In that case B i is the set of output candi- 
dates for the ith utterance,  and s(x) is the 
recognit ion score for a candidate phrase x. 
For a dependency s t ruc ture  X on a phrase 
sequence XlX2...x N, the tota l  re l iab i l i ty  
of X is defined as 
S(X)= S(Xl)+...+S(XN). 
Combining the acceptab i l i ty  and the re l i -  
ab i l i ty ,  we def ine  an ob jec t ive  funct ion  
F(X) as 
F(X)= P(X) +S(X) . 
B 1 B 2 ? ? ? B N 
X l l  x21 - XN1 
x12  x22  .- _ XN2 
X l3  x23  XN3 
Fig.2 Phrase matrix. B 1 . . . . .  B N are 
phrase sets .  
Then the centra l  problem here is formulat-  
ed as the fol lowing combinatorial  optimiza- 
t ion problem \[Matsunaga 86, 0zeki 86a\]. 
Problem Find a dependency st ructure  
XeKB(B1,B 2 . . . . .  B N) 
which minimizes the ob ject ive funct ion F(X). 
By solving this  problem, we can obtain the 
opt imal  phrase sequence and the opt imal  
dependency s t ructure  on the sequence simul- 
taneously. 
When \[Bll=\[B2I=...=IBN\] : M, 
we have 
\[KB(B1,B 2 . . . . .  BN)\[= (2(N_I)C(N-1))/N)MN, 
where C denotes combination. This oecomes a 
huge number even for  a moderate problem 
size,  rendering an enumerative method prac- 
t i ca l l y  impossible. 
5. Recurrence equat ions  and a resu l t ing  
algorithm 
Combining two dependency s t ructures  X and 
Y=<YI . . . . .  Ym,Y>, a new dependency s t ructure  
<X,Y 1 . . . . .  Ym,y> is obtained which is denoted 
as X O V. Conversely, any dependency s t ruc-  
ture Z with length greater  than 1 can be 
decomposed as Z= X@ Y, where X is the top 
dependency s t ructure  in Z. Moreover, it  is 
eas i ly  ver i f ied  from the de f in i t ion  of the 
ob ject ive funct ion that 
F(Z)= F(X) ? F(Y) ? pen(x;y),  
where x and y are the last  phrases in X and 
Y, respect ive ly .  The fol lowing argument is 
based on this  fact .  
We denote elements in B i as Xjl,Xi2 . . . . .  
For l<i<j<N and l<p<lBj\[ , 'where \ [B j \ [ 'denotes 
the number of elements in Bj, we define 
opt ( i , j ;p )  
=min{F(X) XeKB(B i . . . . .  Bj_l{Xjp})} 
and 
opts ( i , j  p) 
=argminCF(X)\[X~KB(B i . . . . .  Bj_l{Xjp})}. 
Then the fo l lowing recurrence equat ions 
hold for opt ( i , j ;p )  and opts ( i , j ;p ) ,  respec- 
t i ve ly  \[Ozeki 86a\]. 
Proposi t ion 1 For l<i~jJN and I~p<\[Bj\[ 
(1) i f  i=j,  then opt ( i , j ;p )=s(X jp ) ,  
(2) and if  i<j,  then 
opt ( i , j ;p )  
=min{f(k,q)\[iJk<j-l,l~q~\]Bk\[}, 
where 
f (k ,q )=opt ( i , k ;q )?opt (k+l , j ;p )  
?pen(xkq;Xjp). 
Proposi t ion 1' For l~i<j<N and lJp<\]Bj , 
(1) i f  i=j,  then opts( i , j ;p)=<Xjp>,  
(2) and if  i<j,  then 
opts ( i , j ;p )  
=opts( i ,*k;*q)  O opts (*k+l , j ;p ) ,  
where *k is the best segmentation point and 
*q is the best phrase number in Bgk: 
(*k,*q)=argmin{f(k,q) \ [ i~k<j- l , l<q~\[Bk\[}.  
According to Proposit ion 1, i f  the values 
of opt ( i , k ;q )  and opt (k?l , j ;p )  are known for 
l~k<j-1 and l<q<\[Bk\[,  i t  is poss ib le  to 
ca lcu la te  the value of opt ( i , j :p )  by search- 
ing the best segmentation point and the best 
phrase number at the segmentat ion  po in t .  
This fact  enables us to ca lcu late  the value 
312  2 
of opt (1 ,N 'p )  recurs ive ly ,  s ta r t ing  with 
opt ( i , i ;q )  (lJi<N,lJqJlBiI). This is the 
pr inc ip le  of dynamic programming \ [Be l l -  
man 57\]. 
Let *p= argmin{opt(1,N'p) ll<p<lBN\[}, 
then we have the f ina l  so lut ion 
opt (1 ,Ngp)=min{F(X) \ [XeKB(B  1 . . . . .  BN)} 
and 
opts(1,N;gp) 
=argmin{F(X) lXeKB(B 1 . . . . .  BN)}. 
The opts (1 ,N '*p)  can be ca lcu la ted  recur -  
s ive ly  using Propos i t ion  2. F ig.3 i l l us -  
t ra tes  an a lgor i thm t rans la ted  from these 
recur rence  equat ions  \[Ozeki  86a\] .  This 
a lgor i thm uses  two tab les ,  tab le l  and 
table2, of upper t r iangu lar  matrix form as 
shown in F ig .4 .  The ( i , j )  element of the 
matrix has \[Bil 'p igeon-ho les ' .  The value 
of opt ( i , j ;p )  ts " s tored in tab le l  and the 
pair  of the best segmentation point and the 
best phrase number is stored in tableZ. It 
should be noted that there is much freedom 
in the order of scanning i , j  and p, which 
wil l  be u t i l i zed  when we discuss a para l le l  
implementation of the algorithm. 
Optimal Dependency_Structure; 
begin 
/* Analysis Phase */ 
for j :=l  to N do 
for i :=j  downto 1 do 
for  p:=l to IBjl do 
if i=j then 
tablel(i,j;p):=s(Xjp); 
else 
begin 
tablel(i,j;p) 
:=min{tablel(i,k;q)+tablel(k+!,j;p) 
+pen(xkq;Xip) 
ll<k<j-l,l<q<\[Bkl}" 
tab le2( i , j ;p )  
:=argmin{tab le l ( i ,k ;q)  
+tab le l (k+l , j ;p )  
+pen(xkq;Xip) 
Ii~k<j-l,t<q<|gkl\[: 
end: 
/* Composition Phase */ 
*p:=argmin{tablel(1,N;p) 
\]I<p<IBNI}: 
resu l t :=opts (1 ,N :#p) :  
end. 
funct ion opts( i  j ;p ) : char  s t r ing;  
begin 
if  i=j then 
opts:='<Xjp>'  
else 
begin 
( *k , *q) :=tab le2( i , j ;p ) ;  
opts :=opts ( i , *k ; *q)  (~)opts (*k i l , j ;p ) ;  
end; 
end. 
Fig.3 Algorithm to se lect  an optimal 
dependency s t ructure  from a phrase 
matrix. 
(T,3T. ~') . . . . . . . . . . . . . . . . . . . .  
{r -, = . . . . . . . .  _ _?  - -22  -_-? _-.7 Z - {2, 5; \]), 
I I . . . . . . . . . .  ? g-2K . . . .  :.17? 2--21 , ;-# 7_-.77 
: - - : :  22221--_-2 :-_: J 
Fig.4 Tr iangular matrix table . . . . . . . . .  
for tab le l  and table2. - . . . . . . .  
In th is  example, N=7 and ~ - ~  
IBII=...:IBTI:3. ~77523 
character  pos i t ion 
1 2 3 4 5 '6 7 8 9 10 11 12 13 14 151 
~ 1 A) I B(S,8) B(12) B(35) \[ B(68) ~ B(11,15) --1 B(9,13) 
Fig.5 Example of phrase la t t i ce .  
When IB1\]=...=IBNI=M, the number of opera- 
t ions (add i t ions  and comparisons) necessary 
to f i l l  table l  is O(M2N3). 
These recurrence equat ions and algor i thm 
can be eas i ly  extended so that  they can 
handle a general  phrase la t t i ce .  A Phrase 
la t t i ce  is a set of phrase sets,  which looks 
l i ke  F ig .5 .  B ( i , j )  denotes  the set  of 
phrases beginning at character  pos i t ion  i 
and ending at j. A phrase la t t i ce  is oh-- 
rained, for example, as the output of a con- 
tinuous speech recognit ion system, and also 
as the resu l t  of a morphological analys is  of 
non-segmented Japanese text spel led in kana 
characters  only. We denote the elements of 
B (~ j~ as X i j l ,X i j  2 . . . . .  and in para l le l  
wi be de f in i t ion  of opt and opts ,  we 
define opt '  and opts '  as fol lows. 
For l<i<m<j(N and Xmj p, 
opt ' ( i , j ,m;p)  
=the minimum value of \ [P(X) iS(X) \ ]  as X 
runs over a l l  the dependency s t ruc tures  
on a l l  the poss ib le  phrase sequences  
beginning at i and ending at j with the 
last  phrase being fixed as Xmj p, 
and 
opts ' ( i , j ,m;p)  
=the dependency s t ructure  which gives the 
above minimum. 
Then recur rence  equat ions  s imi la r  to 
P ropos i t ion  1 and Propos i t ion  1' hold for 
opt '  and opts ' \ [Ozek i  86bJ: 
Proposi t ion 2 For l ! i Jm! j !S  and 
l Jp<lB(m,j) \ [ ,  
(1) if i=m, then opt ' ( i , j ,m;p)=S(Xmjp) ,  
313  
3 
(2) and if i<m, then 
opt ' ( i , j ,m;p)  
=min{f' (k ,n,q)  l i<n<k<m-1, l Jq J lB(n,k)  l}, 
where 
f ' (k , r l ,q )= ept ' ( i , k ,n ;q )?opt ' (k+l , j ,m;p)  
?pen(xnkq:Xmjp) 
Propo~;ition 2' For \[<i<mi3~N and 
lJpJIB(m,J)l, 
(I) if i=m then opts'(i,j,m;p)=<Xmjp>, 
(2) and if i<m, then 
opts'(i j,m;p) 
=opts ' ( i  *k,gn;gq) O opts ' (gk+l , j ,m;p) ,  
where *k is the best segmentation point ,  *n 
is the top pos i t ion  of the best phrase at 
the segmentation point and *q is the best 
phrase number in B(*n,*k): 
(~k,$n,*q) 
=argmin{f(k,n,q)  l i<n<k<m-l , l Jq J IB(n ,k) \ [} .  
The minimum is searched on 3 var iab les  in 
th is  case. I t  is a s t ra ight  forward matter 
to t rans la te  these recurrence equations into 
an a lgor i thm s imi la r  to Fig.3 \[Ozeki 88b, 
Kohda 86\] .  In th i s  case ,  the order  of 
amount of computat ion  is O(M2NS), where 
M=IB( i , j ) I  and N is the number of s ta r t ing  
and end ing pos i t ions  of phrases  in the 
top layer  
node( I ,1)  bottom layer  node(7,7) 
Fig.6 2-dimensional  array of computing 
elements.  
lattice. 
Also, we can modify the algorithm in such 
a way that up to kth optimal solutions are 
obtained. 
6. Para l le l  and Layered Implementation 
When only one processor  is ava i lab le ,  the 
amount of computation dominates the proc- 
ess ing time. On the other  hand, when there 
is no l imi t  as to the number of processors ,  
the process ing time depends on how much of 
the computation can be executed in para l le l .  
There ex is ts  a t idy  para l le l  and layered  
s t ruc ture  to implement the above algor i thm. 
For s imp l i c i ty ,  le t  us conf ine ourse lves  
to a phrase matr ix case here. Furthermore, 
let  us f i r s t  consider the case where there 
is on ly  one e lement  x i in each of the 
phrase set B i .  I f  we def ine 
opt ' ' ( i , j )=min{P(X) lXeK(x  i . . . . .  xj)} 
then Propos i t ion  1 is reduced to the fo l low- 
ing s impler form. 
Propos i t ion  3 For l J i J j JN ,  
(1) i f  i=j ,  then opt" ( i , j )=O,  
(2) and i f  i<j ,  then 
opt" ( i , j )  
=min{opt" ( i , k ) iopt" (k+l , j )  
+pen(xk;x j ) \ [ i<k<j -1},  
I t  i s  easy  to see that  opt ' ' ( i , j )  and 
opt" ( i?m, j?m)  (m~O) can be ca lcu la ted  inde- 
pendently of each other .  This mot ivates us 
to devise a para l le l  and layered computa- 
t ion s t ruc ture  in which process ing elements 
are a r ranged in a 2 -d imens iona l  a r ray  as 
shown in F ig.6.  There are N(N+I)/2 process-  
ing elements in to ta l .  The node( i , j )  has an 
in terna l  s t ruc ture  as shown in F ig.7,  and is 
connected with node( i , k )  and node(k?l , j )  
( l Jk<j -1)  as in Fig.8.  The bottom elements,  
node( i , i ) ' s  ( l< i<N) ,  hold va lue 0 and do 
nothing e lse .  The node( i , j )  ca lcu la tes  the 
value of opt" ( i , j )  and holds the resu l t  in 
memory i together  with the optimal segmenta- 
t ion point in memory 2. Within a layer  a l l  
the nodes work independently in para l le l  and 
the computation proceeds from the lower to 
upper layer .  An upper node rece ives  informa- 
t ion  about a longer  sub-sequence  than a 
lower node: an upper node processes  more 
global  in fo rmat ion  than a lower node. When 
\[. oinio;zatio. 
. . .  
x,  '"ut t on 
J 0 node(i?l.j' / 0 node(i+g,J) 
0 node(i.i) 0 node(i.i+l) 
memory I o~ut  p 
min ; ut 1 
, , L \ ]~  
~ u t a t i o n  of 
Fig.7 In terna l  s t ruc ture  of node( i , j ) .  
314 4 
e( i , j )  
node( i , j -1 )  node( i+ l , j )  
/ \ 
1 \ 
1 \ 
node ( i  , i+ l) node( j - I ,  j )  
dnode( i , i )  node( j , j )~  
F ig .8  Nodes connected to node( i , j ) .  
(1, 6;5) 
d:  C~ / / "//C~"/3C~\ >3 2nd (~aver/(D\\ 'C )x  
(\], i;!) bottom layer (6,6:1) 
F ig .9  3--dimendional  a r ray  of computing 
e lements .  
the top e lement ,  node(1 ,N) ,  f in i shes  i t s  
iob,  each node holds in fo rmat ion  which is  
uecessary  to compose the opt ima l  dependency 
' .~t ructure  on X lX2 . . .x  N. Th is  computat ion  
~;t ructure ,  having many s imple in ter - re la ted  
computing e lements ,  might be remin iscent  of 
a conneet ion is t  model or a neura l  network.  
This resu l t  can be eas i ly  extended,  based 
,:)n P ropos i t ion  1, to the case in which each 
phrase  set  has more than one e lements .  In 
i:his case process ing  e lements  are ar ranged 
in a 3 -d imens iona l  a r ray  as shown in F ig .9 .  
The bottom e lements ,  node( i , i ;p ) ' s ,  hold the 
va lue of s (X ip ) .  The node( i , jp )  ca lcu la tes  
I:he va lue  of  opt ( i , j ;p ) .  The computat ion  
i , roceeds from tile lower to upper layer  jus t  
as in the prev ious  s impler  case .  Fur ther  
extens ion  of th i s  s t r .uc ture  is  a l so  poss ib le  
:',o that  i t  can handle a genera l  phrase la t -  
l ; ice. 
?. Re la ted  Works 
The prob lem of se lec t ing  an appropr ia te  
?hrase  sequence from a phrase  la t t i ce  has 
been t reated  in the f ie ld  of Japanese word 
? recess ing ,  where a non-segmented Japanese 
t:ext spe \ ] . led  in kana character  must be 
conver ted  in to  an or thograph ic  s ty le  spe l led  
in kana and kan j i .  Severa l  p ract i ca l  methods 
have been dev ised  so fa r .  Among them, the 
approach in \[Oshima 86\] is  c lose  in idea to 
the present  one in that  i t  u t i l i zes  the 
Japanese case grammar in o rder  to d i sambi -  
guate  a phrase  la t t i ce .  However ,  the i r  
method i s  enumerat ion -or iented  and some 
kind of heur i s t i c  p rocess  i s  necessary  to 
reduce the s i ze  of the phrase la t t i ce  before  
syntact i c  ana lys i s  is  per formed.  
In o rder  to d i sambiguate  the resu l t  of 
speech recogn i t ion ,  an app l i ca t ion  of de-  
pendency ana lys i s  was a t tempted  \[Matsunaga 
86, Matsunaga 87\].  The a lgor i thm used is  a 
bot tom-up,  depth - f i r s t  search ,  and i t  i s  
repor ted  that  i t  takes  cons iderab le  process -  
ing t ime.  By in t roduc ing  a beam search  
techn ique ,  computing time can be very much 
reduced \[Nakagawa 87\ ] ,  but  w i th  loss  of 
g loba l  opt ima l i ty .  
Perhaps  ti le most c lose ly  re la ted  a lgo -  
r i thm wi l l  be (extended)CYK a lgor i thm with 
probab i l i s t i c  rewr i t ing  ru les  \ [Levinson 85, 
Ney 87, Nakagawa 87\].  In sp i te  of the d i f -  
fe rence  in the in i t ia l  ideas  and the formu- 
la t ions ,  both  approaches  lead  to s imi la r  
bot tom-up,  b readth - f i r s t  a lgor i thms based on 
the pr inc ip le  of dynamic programming. 
In F ig .2 ,  i f  each phrase  set  has only one 
phrase ,  and the  va lue  of  between-phrase  
pena l ty  i s  0 or 1, then the a lgor i thm re -  
duces to the convent iona l  Japanese dependen- 
cy ana lyzer  \ [H i taka  80\]. Thus, the a lgor i thm 
presented  here is  a twofold extens ion  of the 
convent iona l  Japanese dependency ana lyzer :  
the va lue  of  between-phrase  pena l ty  can 
take  an arb i t ra ry  rea l  number and i t  can 
ana lyze  not  on ly  a phrase  sequence  but a 
phrase matr ix  and a phrase la t t i ce  in po ly -  
nomial t ime. 
We have cons idered  a spec ia l  type of de-  
pendency s t ructure  ill th i s  paper ,  in which a 
mod i f i cant  never precedes  the mod i f ie r  as i s  
normal ly  the case in Japanese.  I t  has been 
shown that  the a lgor i thm can be extended to 
cover  a more genera l  dependency  s t ructure  
\[Katoh 893. 
The fundamental  a lgor i thm presented  here 
has been modi f ied  and extended,  and ut i l i zed  
for  speech recogn i t ion  \[Matsunaga 88\]. 
8. Concluding Remarks 
In the method presented  here ,  the l ingu is -  
t i c  data  and the a lgor i thm are  complete ly  
separated .  The l ingu is t i c  data  are condensed 
in the pena l ty  funct ion  which measures the 
natura lness  of mod i f ie r -mod i f i cant  re la t ion  
between two phrases .  No heur i s t i cs  has 
s l ipped  in to  the a lgor i thm.  This makes the 
whole procedure  very t ransparent .  
The essent ia l  par t  of  the a lgor i thm is  
execut ion  of numer ica l  opt imizat ion  ra ther  
than symbol ic  matching un l ike  convent iona l  
parsers .  There fore  i t  can be eas i ly  imple-  
mented on an ar i thmet ic  p rocessor  such as 
DSP (D ig i ta l  S igna l  P rocessor ) .  The para l le l  
5 315 
and layered s t ructure  wi l l  f i t  LSI imple- 
mentation. 
An obvious l im i ta t ion  of th is  method is 
that  i t  takes account of only pa i r -w ise  
re la t ion  between phrases. Because of th is ,  
the c lass  of sentences  which have a low 
penalty in the present c r i te r ion  tends to be 
broader than the c lass of sentences which we 
normally consider acceptable.  Nevertheless, 
th i s  method is use fu l  in reduc ing  the 
number of candidates so that a more sophis-  
t icated l ingu is t i c  analys is  becomes possible 
within rea l i s t i c  computing time in a la ter  
stage. 
A reasonable way of computing the penalty 
for a phrase pair  is yet to be establ ished.  
There seems to be two approaches to th i s  
problem: a determin is t i c  approach tak ing 
syntact ic  and semantic re la t ion  between two 
phrases into cons iderat ion,  and a s ta t i s t i -  
cal one based on the frequency of co-occu- 
fence of two phrases. 
Acknowledgement 
The author is g ra te fu l  to the support of 
Hose Bunka Foundation for this work. 
References 
\[Bellman 573 Bellman,R.: 'Dynamic Program- 
ming', Princeton Univ. Press, 1957. 
\[Hashimoto 46\] Hashimoto,S.: 'Kokugo-gaku 
Gairon' ,  lwanami. 1946. 
\[Hays 64\] llays,D.G,: 'Dependency Theory: A 
Formalism and Some Observat ions ' ,  Lan- 
guage, Vol.40, No.4, pp.511-525, 1964. 
\ [Hitaka 80\] n i taka ,T ,  and Yosh ida ,S .  'A 
Syntax Parser Based on the Case Dependency 
and I t s  E f f i c iency '  Prec .  COLING'80, 
pp.15-20, 1980. 
\[Katoh 89\] Katoh,N. and Ehara,T. ? 'A fast  
algorithm for dependency st ructure  analy- 
s i s '  Prec.  39th Annual Convention IPS 
Japan, 1989. 
EKohda 86\] Kohda,M.'  'An a lgor i thm for  
optimum se lect ion  of phrase sequence from 
phrase la t t i ce ' ,Paper  Tech. Group, IECE 
Japan, SP86-72, pp.9-16, 1986. 
\ [Levinson 853 Lev inson ,S .E . '  'S t ruc tura l  
Methods in Automatic Speech Recognit ion'  
Prec.  of IEEE, Vol .?3,  No . l l ,  pp.1625- 
1649, 1985. 
\[Matsunaga 86\] Matsunaga,S. and Kohda,M.' 
' Pos t -p rocess ing  using dependency s t ruc -  
ture of inter -phrases for speech recogni-  
t ion ' ,  Prec.  Acoust .  Soc. Jpn. Spr ing 
Meeting, pp.45-46, 1986. 
\[Matsunaga 87\] Matsunaga,S. and Kohda,M,: 
'Speech Recognition. of Minimal Phrase Se- 
quence Taking Account of Dependency Rela- 
t ionsh ips  between Minimal Phrases ' ,  
Trans. IEICE Vol. JTO-D,No.ll, pp.2102-2107, 
1987. 
\[Matsunaga 88\] Matsunaga,S. and Kohda,M." 
' L ingu is t i c  processing using a dependency 
s t ruc ture  grammar for speech recogn i t ion  
and unders tand ing '  Prec .  COLING'88, 
pp.402-407, 1988. 
\[Nakagawa 873 Nakagawa,S. and I to ,T .  : 
'Recognit ion of Spoken Japanese Sentences 
Using Menu-Syl lab le  Units and Backward 
Kakar i -Uke Pars ing  A lgor i thm' ,  Trans.  
IEICE Vol. J70-D,No.12, pp.2469-2478, 1987. 
\[Nakagawa 87\] Nakagawa. S : 'Un i f i cat ion  of 
Kakar i -Uke Ana lys i s  and Context -F ree  
Pars ing by CYK Algorithm for  Continuous 
Speech Recogn i t ion ' ,  Prec. Acoust. Soc. 
Jpn. Spring Meeting, pp.131-13Z, 1987. 
\[Ney 87\] Ney,H.: 'Dynamic Programming Speech 
Recognition Using a Context-Free Grammar', 
Prec. ICASSP'87, pp,69-72, 1987. 
\[Oshima 86\] Oshima,Y., Abe,M,, Yuura,K. and 
Takeichi,N. : 'A Disambiguation Method in 
Kana-Kanj i  Convers ion Using Case Frame 
Grammar' ,  Trans.  IPSJ,  Vo l .27,  No.7, 
pp.679-687, 1986. 
\[Ozeki 86a\] Ozeki,K.: 'A mult i -stage deci -  
sion a lgor i thm for optimum bunsetsu se- 
quence selection', Paper Tech. Group, IECE 
Japan, SP86-32, pp.41-48, 1986. 
\[Ozeki 86b\] Ozeki,K.: 'A multi-stage deci- 
sion algorithm for optimum bunsetsu se- 
quence selection from bunsetsu la t t i ce ' ,  
Paper Tech. Group, IECE Japan, COMP86-47, 
pp.47-57, 1986. 
\[Yoshida 72\] Yoshida,S.: 'Syntax analys is  of 
Japanese sentence based on kakariuke re la -  
t ion between two bunsetsu ' .  Trans. IECE 
Japan, Vol. J55-D, No.4, 1972. 
316 6 
