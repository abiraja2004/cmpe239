SOME I 33UE3 IH P&RSING AHD NATURAL L INGUAGE UNDERSTANDING 
Rober t  J. Bobrow 
Bo l t  Beranek  and ~ewman Inc. 
Bonn ie  L. Webber  
Depar tment  of Computer  & In format ion  Sc ience  
Un ivers i ty  of  Pennsy lvan ia  
Lan&ua~e is a system for ancodln~ and 
trans~tttlnK ideas. A theory that seeks to 
explain llnKulstlc phenomena in terme of this 
fact is a fun~t~1 theory. One that does not 
? ?sses the point. \[10\] 
PREAMBLE 
Our response to the questions posed to this panel is 
influenced by a number of beliefs (or biasesl) which we 
have deve loped in  the  course  o f  bu i ld ing  and ana lyz in~ 
the operation of several natural language understanding 
(NLU) systems. \[I, 2, 3, 12\] While the emphasis of the 
panel i~ on parslnK, we feel that the recovery of the 
syntactic structure of a natural lan~unKe utterance 
must be viewed as part of a larger process of 
reeoverlnK the meaning, intentions and goals underlying 
its generation. Hence it is inappropriate to consider 
designing or evaluatln~ natural language parsers or 
Erem,~ra without taking into account the architecture 
of the whole ~LU system of which they're a part. I This 
is the premise from which Our beliefs arise, beliefs 
which concern two thinks: 
o the distribution of  various types of 
knowledge, in particular syntactic knowledge, 
amonK the  modules  o f  an NLU sys tem 
o the  in format ion  and cont ro l  Flow emonK those  
modules. 
As to the first belief, in the HLU systems we have 
worked on, most syntactic information is localized in a 
"syntactic module", although that module does not 
produce a rallied data structure representing the 
syntactlo description of an utterance. Thus, if 
"parslnK" is taken as requlrln~ the production of such 
a rallied structure, then we do not believe in its 
necessity. However we do believe in the existence of a 
module which provides syntactic information to those 
other parts of the system whose decisions ride on it. 
As to  the second belief, we feel that syntax, semantics 
and prat t les  effectively constitute parallel but 
interacting processors, and that information such as 
local syntactic relations is determined by Joint 
decisions -monk them. Our experience shows that with 
mlnir"al loss of efficiency, one can design these 
processors to interface cleanly with one another, so as 
to allow independent design, implementatlon and 
modification. We spell out these beliefs in slightly 
more detail below, and at greater length in \[~\]. 
1We are  not  c la iming  that  the on ly  fac tors  shap ing  a 
parser or a gr~-mar, beyond syntaotlo conslderatlofls, 
are thlrLKs llke meanlng, intention, etc. There are 
clearly mechanical and memory factors, aa well an 
laziness - a speoXer's penchant for trylnK to get away 
with the mdniEal level of effort needed to accomplish 
the task f  
97  
The Comoutatiom~l Persneetive 
The f i r s t  se t  o f  quest ion~ to  th i s  pane l  concern  the  
computat iona l  perspect ive ,  and the use fu l  purposes  
served  by d is t ingu ish ing  pars ing  f rom in terpretat ion .  
We be l ieve  that  syntact i c  knowledge p lays  an impor tant  
ro le  in  NLU. In  par t i cu la r ,  we be l ieve  that  there  i s  a 
s ign i f i cant  type  o f  u t terance  descr ip t ion  that  can be 
determined on pure ly  syntact i c  g rounds  2,  a lbe i t  not  
necessar i l y  un ique ly .  Th is  descr ip t ion  can  be used  to  
gu ide  semant ic  and d iscourse  leve l  s t ructure  recovery  
processes  such  as in terpretat ion ,  anaphor ic  reso lu t ion ,  
focus  t rack ing ,  g iven/new d is t inc t ions ,  e l l ips i s  
reso lu t ion ,  e tc .  in  a manner that  i s  independent  o f  the  
lex ica l  and conceptua l  content  o f  the  u t terance .  There  
are  severa l  advantages  to  fac tor ing  out  such  knowledge 
f rom the re ,~-~nder  o f  the  NLU sys tem and prowld ing  a 
? syntact i c  modu le"  whose in teract ions  w i th  the  res t  o f  
the system prov ide  information on the syntactic 
structure of an utterance. The first advantage is to 
simplify system building, an we know fl-om 
experience \[I, 2, 3, 4, 5, 12\]. Once the pattern of 
communication between processors is settled, it is 
easier to attach a new semnntlcs to the hooks already 
provided in the Kr~,mar than to build a new semantic 
processor. In addition, because each module ban only 
to consider a portion of the constraints implicit in 
the data (e.g. syntactic constraints, semantic 
constraints and discourse context), each module can be 
designed to optimize its own processing and provide an 
efficient system. 
The panel has also been charged wlth _ ~oslder lng 
paa'allel processing as a challenge to its views on 
parsing. Thls touches on our beliefs about the 
Interaction among the modules that comprise the HLU 
system. To respond to this issue, we first want to 
dlstlngulsh between two types of parallelism: one, in  
which many instances of the same thin6 are done at once ~ 
(an in an array of parallel adders-) and another, in 
which the many thinks done slmul~aneously can be  
different. Supporting this latter type of parallelism 
doesn*t change our view of parsing, but rather 
underlies it. We believe that the Interconnected 
processes involved in NLU must support a banjo 
o~eratinK pr i~ip le  that Herman and Bobrow \[14\] have 
called "The Principle of Continually Available Output":, 
(CAO). This states that the Interactlng processes muat~ 
ben in  to  prov ide  output  over  a wide range  o f  resource  
allocations, even before their analyses are complete, 
and even before all input data is available. We take 
this position for two rensons: one, it facilitates 
computational efficiency, and two, it seems to be 
closer to human parsing ~rocesses (a point which we 
will get to in answerlnK the next question). 
The requirement that syntactic analysis, semantic 
interpretation and discourse processlng must be able to 
operate in (pseudo-)parallel, obeying the CAO 
2that  i s ,  so le ly  on the baa?s  o f  syntact i c  
categor ies / features  and order ing  In format ion  
principle, has sparked our interest in the design of 
calrs of processes which can pass forward and backward 
unet~Ll In/ormatlon/advlce/questlons as soon as 
possible. The added potential for interaction of such 
processors can increase the capab i l i ty  and efficiency 
of the overall HLU process. Thus, for example, if the 
syntactic module makes its intermediate decisions 
ava i lab le  to semantics and~or pragmatlcs, then those 
processors can evaluate those decisions, guide syntax's 
fu ture  behav ior  and ,  in  add i t ion ,  deve lop  in  para l le l  
the i r  own ana lyses .  Hav ing  sent  on i t s  la tes t  
assertlon/advlce/question, whether syntax then decides 
to  continue on with something else or  walt fo r  a 
response will depend on the  particular k ind  o f  message 
sent. Thus, the parsers and grammars that concern us 
are ones able to work with other appropriately designed 
compoconts to  support CAO. While the equipment we are 
USing to implement and tes t  our ideas is serial, we 
take very seriously the notion of parallelism. 
Finally under the heading of "Computational 
Perspect ive" ,  we are  anked about  what  might  mot ivate  
our  t ry ing  to  make pars ing  procedures  s imulate  what  we 
suspect human parsing processes to be like. One 
motivation for us is the belief that natural language 
is so tuned to the part extraordinary, part banal 
cognitive capabilities of human beings that only by 
simulating human parsing processes can we cover all and 
on ly  the language phenomena that  we are  called upon to  
process. A particular (extraordinary) aspect of hu~an 
cognitive (and hence, parsing) behavior that we want to 
explore and eventually simulate is people's ability to 
respond even under  degraded data  or  resource  
l im i ta t ions .  There  are  examples  o f  l i s teners  
in i t ia t ing  reasonab le  responses  to  an ut terance  even 
before the utterance is complete, and in some case even 
before a complete syntactic unit has been heard. 
Simultaneous translation is ode notable example \[8\], 
and another  i s  p rov ided  by the  per fo rmance  o f  sub jects  
in  a verba l ly  gu ided  assembly  task  repor ted  by P. Cohen 
\ [6 \ ] .  Such an ab i l i ty  to  produce  output  be fore  a l l  
input  data  is available (or before enough processing 
resources  have  been made ava i lab le  to  produce  the  best  
poss ib le  response)  i s  what  led  Norman and Bobrow to  
fo rmulate  the i r  CAO Pr inc ip le .  Our in teres t  i s  in  
architectures for NLU systems which support CAO and in 
? search  strategies through such architectures fo r  an 
opti~"l interpretation. 
The LimnLiStlC ~rs~et lve  
We have been asked to comment on legitimate inferences 
about human linsulstic competence and performance that 
we can draw from our experiences with mechanical 
pars ing  o f  formal grammar. Our response is that 
whatever parsing is for natural languages, it is still 
only part of a larger process. Just because we know 
what parsing is in formal language systems, we do not 
secsssarily know what role it plays is in the context 
Of total communication. S imply  put, formal notions of 
parsing underconstraln the goals of  the syntactic 
component of an NLU system. Efficiency meanures, based 
on  the resources required for generation of one or all 
complete  parses for s sentence, without  semantic or  
pra~e~-tlc Intera~tlon, do not secessarily specify 
desirable properties o f  a natural language syntactic 
analysis component. 
As for whether the efficiency of parsing algorlthm~ for 
CF or regular grammars suggest that the core of NL 
igremmars la CF or regular, we want to dlstlngulsh that 
part of perception (and hence, syntactic analysis) 
which groups the stimulus into recognizable units from 
that  part which fills in gaps in in/ormatlon 
(inferentially) on the baals of such groups. Results 
in CF grammar theory says that grouping is not best 
dose  pure ly  bot tom-up,  that there are advantages to  
t ~ 
us lng  predictive mechanlsms a~ well \[9, 7\]. Thls 
snggests two things for parsing natural language: 
I. There is a level of evidence and a process 
for using it that is worEing to suggest 
groups .  
2. There is another filtering, inferenclng 
mechanism that maEes predictions and 
diagnoses on the basis of those groups. 
It is possible that the grouping mechanism may make use 
of strategies applicable to CF parsing, such as well- 
formed substrlng tables or charts, without requiring 
the overall language specification be CF. In our 
current RUS/PSI-ELONE system, grouping is a function of 
the syntactic module: its output consists of suggested 
groupings. These snggestlons may be at abstract, 
specific or disjunctive. For example, an abstract 
description m~ht  be "this is the head of an NP, 
everyth ing  to  i t s  le f t  i s  a pre -mod i f le r " .  Here there  
i s  co comment about  exact ly  how these  pre -mod l f le rs  
g roup .  A d i s junct ive  descr ip t ion  wou ld  cons is t  o f  an 
exp l i c i t  enumerat ion  o f  a l l  the  poss ib i l i t ies  a t  some 
po in t  (e .g . ,  " th i s  i s  e i ther  a t ime prepos i t iona l  
phrase  (PP) o r  an agent ive  PP or  a locat ive  PP, e tc . " ) .  
Disjunctive descriptions allow us to  prune .  
possibilities via cane a~alysls. 
In short, we believe in using as much evidence from 
formal systemn a~ seems understandable and reasonable, 
to const ra in  what the  system should be do ing .  
The Interaetlons 
F ina l ly ,  we have  been asked  about  the  nature  o f  the 
re la t ionsh ip  between a gr~mar  and a procedure  fo r  
app ly ing  i t .  On the  sys tems bu i ld ing  s ide ,  cur  fee l ing  
is that while one should be able to take a grammar and 
convert it to a recognition or generation 
procedure \[I0\], it is likely that such procedures will 
embody a whole set of principles that are control 
structure related, and not part of the grammar. For 
example, a gr',-mr seed not specify in what order to 
look for thln~s or  in  what order decisions should be 
made. Thus, one may not be able to reconstruct the 
grammar unlcuelv from a procedure for applying it. 
On the other hand, on the b ,m-  parsing side, we 
definitely feel that natural language is strongly tuned 
to both people's means of production and their means of 
recognition, and that principles llke MnDonalds ' 
Znde l ib l l l ty  Pr"Inoiple \[13\] or  Marcus' Determinism 
Hypothesis \[11\] shape what are (and are not) seen an 
sentences of the language. 
REFERENCES 
I. Bobrow, R. J. The RUS System. BEN Report 3878, 
Bolt Beranek and Rewman Inc., 1978. 
2. Bobrow, R. J. & Webber, B. L. PS I -ELONE-  Parsing 
and Semantic Interpretation in the BBN Natural Language 
Understanding System. CSCSI/C~EI0 Annual Conference, 
CSC3I/CSEIO, 1980. 
3.  Bobrow, R. J .  & Webber,  B. L. Knowledge 
Representat ion  fo r  Syntact i c /Semant ic  P rocess ing .  
P roceed ings  o f  The F i r s t  Annual  Nat iona l  Conference  on 
Ar t i t i c ia l  In te l l igence ,  Amer ican  Assoc ia t ion  fo r  
Artif icial Intelligence, 1980. 
98 
~. Bobrow, R.J. & Webber, B.L. Pars ing and Semantic 
In terpretat ion  as an Incremental  Recognit ion Process. 
Proceedings of  a Symposium on Modelling Human Parsing 
St ra teg ies ,  Center for  Cognitive Science, Univers i ty  o\[ 
Texas, Austin TZ, 1981. 
5. Bobrow, R.J. & Webber, B.L. Systems Considerat ions 
for  Search by Cooperating Processes:  Providing 
Continual ly Ava/lable Output. Proceedings of the Sixth 
IJCAI, In ternat iona l  Jo in t  Conference on Ar t i f i c ia l  
In te l l igenoe ,  1981. 
6. Cohen, P. personal  communication, videotape of 
experimental task 
7. Eau-ley, J .  An e f f i c ient  context- f l 'ee pars ing 
algor i thm. ~ of the ACM /~ (February 
1970), 9~',- 102. 
8. Gold~an-Eisler, F. Psyohologloal Heohanisms of 
Speech Produotlon as SSudled through the Analysis of 
Simultaneous Translation. In B. Butterworth, Ed., 
Lan~rn~e Production, Aoademlc Press, 1980. 
9. Graham, S., Harrison, M. and Ruzzo, W. An Improved 
Context-Free Recognizer. ACM ~ on 
Pnom,-mm4,~ Lana~es  and Systems (July 1980), "16- 
@63. 
10. Kay, M. An Algorithm for Compiling Parsing Tables 
f~om a Grammar. Prooeedings of a Symposium on 
Modelling Human Parsing Strate~Les, Center for 
Cognitive Science, University of Texas, Austin TX, 
1981. 
11. MaPcus, M. A Theory of .qvntactic ~ for 
Mat~a l  Lan~e.  MIT Press, 1980. 
12. Mark, W. S. & Barton, G. E. The RUSGrammar 
Parsing System. GMR 32"3, General Motors Research 
Laboratories, 1980. 
13. MoDonald, D. ???. Ph.D. Th., Massachusetts 
Institute o? Technology, 1980. 
I,. ~orman, D. & Bobrow, D. On Data- i i~ted and 
Resource-llmlted ProoesSes. CSL7,-2, Xerox PARC, Msy, 
197,. 
99 

