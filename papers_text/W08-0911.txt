Proceedings of the Third ACL Workshop on Innovative Use of NLP for Building Educational Applications, pages 89?97,
Columbus, Ohio, USA, June 2008. c?2008 Association for Computational Linguistics
Real-Time Web Text Classification and Analysis of Reading Difficulty
Eleni Miltsakaki
Graduate School of Education
Universisty of Pennsylvania,
Philadelphia, PA 19104, USA.
elenimi@seas.upenn.edu
Audrey Troutt
Computer and Information Science
University of Pennsylvania
Philadelphia, PA 19104, USA
atroutt@seas.upenn.edu
Abstract
The automatic analysis and categorization of
web text has witnessed a booming interest due
to the increased text availability of different
formats, content, genre and authorship. We
present a new tool that searches the web and
performs in real-time a) html-free text extrac-
tion, b) classification for thematic content and
c) evaluation of expected reading difficulty.
This tool will be useful to adolescent and adult
low-level reading students who face, among
other challenges, a troubling lack of reading
material for their age, interests and reading
level.
1 Introduction
According to the National Center for Education
Statistics, 29% of high school seniors in public
schools across America were below basic achieve-
ment in reading in 2005 (U.S. Department of Edu-
cation 2005). Once these students enter high school,
their reading problems, which began much earlier
in their education, are compounded by many fac-
tors including a lack of suitable reading material for
their age, interests and reading level. Most mate-
rial written at a lower reading level is designed for
much younger students; high-school students find it
boring or embarrassing. On the other hand material
designed for older students, while probably more in-
teresting, is incomprehensible to such a student and
leads to frustration and self-doubt. The internet is
a vast resource for potential reading material and is
often utilized by educators in the classroom, but it is
not currently possible to filter the results of a search
engine query by levels of readability. Instead, the
software that some schools have adopted restricts
students to lists and directories of hand-selected edu-
cational sites. This severely limits the content avail-
able to students and requires near-constant mainte-
nance to keep current with new information avail-
able on the web.
We are developing a new system, Read-X, that
searches the web and performs in real-time a) html-
free text extraction, b) classification for thematic
content and c) evaluation of expected reading dif-
ficulty. For the thematic classification task we col-
lected a manually labeled corpus to train and com-
pare three text classifiers. Our system is part of
larger research effort to improve existing readabil-
ity metrics by taking into account the profile of the
reader. As a first step in this direction, we computed
vocabulary frequencies per thematic area. We use
these frequencies to predict unknown words for the
reader relative to her familiarity with thematic areas
(Toreador). These tools (Read-X and Toreador) will
be useful to adolescent and adult low-level reading
students who face, among other challenges, a trou-
bling lack of reading material for their age, interests
and reading level.
The remainder of the paper is organized as fol-
lows: first we will describe our motivation for cre-
ating Read-X and Toreador, which is based on stud-
ies that show that older struggling readers can make
improvements in literacy and that those improve-
ments can have a profound impact on their lives.
Next we will describe existing technologies for liter-
acy improvement and research related to our current
project. Finally, we will give a detailed description
89
of Read-X and Toreador, including our methods of
evaluating the readability of texts, thematically clas-
sifying the texts and modeling reader profiles into
readability predictions, before concluding with an
outline of future work.
2 Educational motivation
Low reading proficiency is a widespread problem
evident in the performance of adolescents in U.S.
schools. The National Center for Education Statis-
tics (NCES) in 2005, the latest year for which data
is available, reports that only 29% of eight graders
in the United States achieved proficient or above
reading, meaning the remaining 71% of students
had only part of the reading skills needed for pro-
ficient work at their level or less (Snyder et al,
2006). (Hasselbring and Goin, 2004) reported that
?as many as 20 percent of 17-year-olds have been
estimated to be functionally illiterate, and 44 per-
cent of all high-school students have been described
as semi-literate?. Reading below grade level is a se-
rious problem for adolescents as it may hinder com-
prehension of textbooks and classroom materials in
all fields. (Denti, 2004) mentions that ?most high
school textbooks are written at the tenth through
twelfth grade levels with some textbooks used for
U. S. government written at the seventeenth grade
level?. Reading skills are tied to academics suc-
cess and are highly correlated with with ?higher in-
come and less unemployment, increased access to
lifelong learning, greater amounts of personal read-
ing for pleasure, and increased civic participation?
(Strucker et al, 2007).
Recent research has shown that it is possible
to identify adult literacy students on the brink of
achieving reading fluency in order to provide them
with concentrated instruction, dramatically improv-
ing their chances of attaining a high quality of life
(Strucker et al, 2007). (Weinstein and Walberg,
1993) studied the factors related to achievement in
reading and found that ?frequent and extensive en-
gagement in literacy-promoting activities as a young
adult was associated with higher scores on literacy
outcomes (independent of earlier-fixed characteris-
tics and experiences),? which implies that through
ample reading exercise students can achieve literacy
regardless of their background.
The current and future versions of the system that
we are developing uses natural language processing
techniques to provide learning tools for struggling
readers. The web is the single most varied resource
of content and style, ranging from academic papers
to personal blogs, and is thus likely to contain in-
teresting reading material for every user and reading
ability. The system presented here is the first to our
knowledge which performs in real time a)keyword
search, b)thematic classification and c)analysis of
reading difficulty. We also present a second sys-
tem which analyzes vocabulary difficulty according
to reader?s prior familiarity with thematic content.
3 Related work
In this section we discuss two main systems that are
most closely related to our work on text classifica-
tion and analysis of readability.
NetTrekker is a commercially available search
tool especially designed for K-12 students and ed-
ucators.1 NetTrekker?s search engine has access to
a database of web links which have been manually
selected and organized by education professionals.
The links are organized thematically per grade level
and their readability level is evaluated on a scale of
1-5. Level 1 corresponds to reading ability of grades
1-3 and 5 to reading ability of grades 11-13. Net-
trekker has been adopted by many school districts
in the U.S., because it offers a safe way for K-12
students to access only web content that is age ap-
popriate and academically relevant. On the other
hand, because the process of web search and classi-
fication is not automated, it is practically impossible
for NetTrekker to dynamically update its database so
that new material posted on the web can be included.
However, Nettrekker?s manual classification of web
links is a valuable resource of manually labeled data.
In our project, we use this resource to build labeled
dataset for training statistical classifiers. We discuss
the construction and use of this corpus in more detail
in Section 5.1).
The REAP tutor, developed at the Language Tech-
nologies Institute at Carnegie Mellon, is designed to
assist second language learners to build new vocabu-
lary and facilitates student specific practice sessions
(Collins-Thompson and Callan, 2004), (Heilman et
1Available at http://www.nettrekker.com.
90
al., 2006). The tutor allows the user to search for
textual passages as well as other text retrieved from
the web that contains specific vocabulary items. The
educational gain for students practicing with the tu-
tor has been shown in several studies (e.g., (Heil-
man et al, 2006)). Like NetTrekker, REAP retrieves
and classifies web text off-line. Unlike, Nettrekker,
however, textual analysis is automated. REAP?s in-
formation retrieval system (Collins-Thompson and
Callan, 2004) contains material from about 5 million
pages gathered with web crawling methods. The
data have been annotated and indexed off-line. An-
notations include readability level computed with an
earlier version of the method developed by (Heilman
et al, 2007), (Heilman et al, 2006) described be-
low, rough topic categorizations (e.g., fiction, non-
fiction) and some elements of grammatical structure
(e.g., part-of-speech tagging).
(Heilman et al, 2007) experiment with a system
for evaluation of reading difficulty which employs
both grammatical features and vocabulary. The
grammatical features built in the model were iden-
tified from grammar books used in three ESL lev-
els. (Heilman et al, 2007) find that while the vo-
cabulary model alone outperformed the grammar-
based model, the combined model performed best.
All models performed better in English text and less
well in ESL text. It would be very interesting to in-
tegrate this system with Read-X and evaluate its per-
formance.
To address issues specific to struggling read-
ers, (Hasselbring and Goin, 2004) developed
the Peabody Literacy Lab (PLL), a completely
computer-based program, using a variety of tech-
nologies to help students improve their ability to
read. We will not elaborate further on this work
because the PPL?s focus in not in developing new
technologies. PLL develops experimental programs
using existing technologies.
4 Read-X project overview
In the Read-X project, we have developed two tools
which are currently independent of each other. The
first tool Read-X, performs a web search and classi-
fies text as detailed in (5.1). The second tool Tore-
ador, analyzes input text and predicts vocabulary dif-
ficulty based on grade or theme-specific vocabulary
frequencies. The vocabulary predicted to be unfa-
miliar can be clicked on. This action activates a dic-
tionary look-up search on Wordnet whose display is
part of the tool?s interface. More details and screen-
shots are given in (??).
5 Description of Read-X
Below we describe in detail the technical compo-
nents of Read-X: internet search, text extraction and
analysis of readability.
5.1 Read-X: Web search and text classification
Internet search. Read-X performs a search of the
internet using the Yahoo! Web Services. When
the search button is clicked or the enter key de-
pressed after typing in a keyword, Read-X sends a
search request to Yahoo! including the keywords
and the number of results to return and receives re-
sults including titles and URLs of matching web-
sites in an XML document. The Yahoo! Web
Service is freely available for non-commercial use
with a limit of 5000 requests per day. If Read-X
is deployed for use by a wide number of users, it
may be necessary to purchase the ability to process
more requests with Yahoo or another search engine.
Read-X is currently available at http://net-
read.blogspot.com.
Text extraction. Read-X then retrieves the html,
xml, doc or PDF document stored at each URL
and extracts the human-readable text.2 text is ex-
tracted from html and xml documents using the
scraper provided by Generation Java by Henri Yan-
dell, see www.generationjava.com. The Microsoft
Word document scraper is part of the Apache Jakarta
project by the Apache Software Foundation, see
www.apache.org. The PDF scraper is part of the
Apache Lucene project, see www.pdfbox.org. All
three of these external tools are available under a
common public license as open source software un-
der the condition that any software that makes use of
the tools must also make the source code available to
users.
2Being able to identify appopriate web pages whose content
is reading material and not ?junk? is a non-trivial task. (Petersen
and Ostendorf, 2006) use a classifier for this task with moderate
success. We ?read? the structure of the html text to decide if the
content is appropriate and when in doubt, we err on the side of
throwing out potentially useful content.
91
Readability analysis. For printed materials, there
are a number of readability formulas used to mea-
sure the difficulty of a given text; the New Dale-
Chall Readability Formula, The Fry Readability
Formula, the Gunning-Fog Index, the Automated
Readability Index, and the Flesch Kincaid Reading
Ease Formula are a few examples. Usually these for-
mulas count the number of syllables, long sentences,
or difficult words in randomly selected passages
of the text. To automate the process of readabil-
ity analysis, we chose three Readability algorithms:
Lix, Rix, see (Anderson, 1983), and Coleman-Liau,
(Coleman and Liau, 1975), which were best suited
for fast calculation and provide the user with either
an approximate grade level for the text or a readabil-
ity classification of very easy, easy, standard, diffi-
cult or very difficult. When each text is analyzed by
Read-X the following statistics are computed: to-
tal number of sentences, total number of words, to-
tal number of long words (seven or more characters,
and total number of letters in the text. Below we de-
scribe how each of the three readability scores are
calculated using these statistics. Steps taken to de-
velop more sophisticated measures for future imple-
mentations are presented in Section 7).
Lix readability formula: The Lix readability al-
gorithm distinguishes between five levels of read-
ability: very easy, easy, standard, difficult, or very
difficult. If W is the number of words, LW is the
number of long words (7 or more characters), and
S is the number of sentences, them the Lix index is
LIX = W/S + (100 * LW) / W. An index of 0-24
corresponds to a very easy text, 25-34 is easy, 35-44
standard, 45-54 difficult, and 55 or more is consid-
ered very difficult.
Rix readability formula: The Rix readability
formula consists of the ratio of long words to sen-
tences, where long words are defined as 7 or more
characters. The ratio is translated into a grade level
as indicated in Table (1).
Coleman-Liau readability formula: The
Coleman-Liau readability formula is similar to the
Rix formula in that it gives the approximate grade
level of the text. Unlike the Lix and Rix formulas,
the Coleman-Liau formula requires the random
selection of a 100 word excerpt from the text.
Before the grade level can be calculated, the cloze
percent must be estimated for this selection. The
Ratio GradelLevel
7.2 and above College
6.2 and above 12
5.3 and above 11
4.5 and above 10
3.7 and above 9
3.0 and above 8
2.4 and above 7
1.8 and above 6
1.3 and above 5
0.8 and above 4
0.5 and above 3
0.2 and above 2
Below 0.2 1
Table 1: Rix translation to grade level
Classifier Supercategories Subcategories
Naive Bayes 66% 30%
MaxEnt 78% 66%
MIRA 76% 58%
Table 2: Performance of text classifiers.
cloze percent is the percent of words that, if deleted
from the text, can be correctly filled in by a college
undergraduate. If L is the number of letters in the
100 word sample and S is the number of sentences,
then the estimated cloze percent is C = 141.8491
- 0.214590 * L + 1.079812 * S. The grade level
can be calculated using the Coleman-Liau formula,
where grade level is -27.4004 * C + 23.06395. In
the SYS display we round the final result to the
nearest whole grade level.
6 Text classification
The automated classification of text into predefined
categories has witnessed strong interest in the past
ten years. The most dominant approach to this prob-
lem is based on machine learning techniques. Clas-
sifiers are built which learn from a prelabeled set of
data the characteristics of the categories. The perfor-
mance of commonly used classifiers varies depend-
ing on the data and the nature of the task. For the text
classification task in Read-X, we a) built a corpus of
prelabeled thematic categories and b)compared the
performance of three classifiers to evaluate their per-
92
formance on this task.
We collected a corpus of approximately 3.4 mil-
lion words and organized it into two sets of label-
ing categories. We hand collected a subset of labels
(most appropriate for a text classification task) from
the set of labels used for the organization of web text
in NetTrekker (see 3). We retrieved text for each
category by following the listed web links in Net-
Trekker and manually extracting text from the sites.
Our corpus is organized into a small hierarchy, with
two sets of labels: a)labels for supercategories and
b)labels for subcategories. There are 8 supercate-
gories (Arts, Career and business, Literature, Phi-
losophy and religion, Science, Social studies, Sports
and health, Technology) and 41 subcategories (e.g.,
the subcategories for Literature are Art Criticism,
Art History, Dance, Music, Theater). Subcategories
are a proper subset of supercategories but in the clas-
sification experiments reported below the classifiers
trained independently in the two data sets.
We trained three classifiers for this task: a Naive
Bayes classifier, a Maximum Entropy classifier and
MIRA, a new online learning algorithm that incor-
porates a measure of confidence in the algorithm(for
details see (Crammer et al, 2008)). 3 The perfor-
mance of the classifiers trained on the supercate-
gories and subcategories data is shown in Table (2).
All classifiers perform reasonably well in the super-
categories classification task but are outperformed
by the MaxEnt classifier in both the supercategories
and subcategories classifications. The Naive Bayes
classifiers performs worst in both tasks. As ex-
pected, the performance of the classifiers deterio-
rates substantially for the subcategories task. This
is expected due to the large number of labels and the
small size of data available for each subcategory. We
expect that as we collect more data the performance
of the classifiers for this task will improve. In an ear-
lier implementation of Read-X, thematic classifica-
tion was a coarser three-way classificaition task (lit-
erature, science, sports). In that implementation the
MaxEnt classifier performed at 93% and the Naive
Bayes classifier performed at 88% correct. In future
implementations of the tool, we will make available
3We gratefully acknowledge MALLET, a collection of
statistical NLP tools written in Java, publicly available at
http://mallet.cs.umass.edu and Mark Dredze for
his help installing and running MIRA on our data.
all three levels thematic classification.
6.1 Runtime and interface
The first implementation of Read-X, coded in Java,
has been made publicly available. The jar file is
called from the web through a link and runs on Win-
dows XP or Vista with Java Runtime Environment 6
and internet connection. Search results and analysis
are returned within a few seconds to a maximum of a
minute or two depending on the speed of the connec-
tion. The Read-X interface allows the user to con-
strain the search by selecting number of returned re-
sults and level of reading difficulty. A screenshot of
Read-X (cropped for anonymity) is shown in Figure
(1). The rightmost column is clickable and shows
the retrieved html-free text in an editor. From this
editor the text can be saved and further edited on the
user?s computer.
7 Description of Toreador
The analysis of reading difficulty based on standard
readability formulas gives a quick and easy way to
measure reading difficulty but it is problematic in
several ways. First, readability formulas compute
superficial features of word and sentence length. It
is easy to show that such features fail to distin-
guish between sentences which have similar word
and sentence lengths but differ in ease of interpreta-
tion. Garden path sentences, bountiful in the linguis-
tic literature, demonstrate this point. Example (1) is
harder to read than example (2) although the latter is
a longer sentence.
(1) She told me a little white lie will come back
to haunt me.
(2) She told me that a little white lie will come
back to haunt me.
Secondly, it is well known that there are aspects
of textual coherence such as topic continuity and
rhetorical structure which are not captured in counts
of words and sentences (e.g., (Higgins et al, 2004),
(Miltsakaki and Kukich, 2004))
Thirdly, readability formulas do not take into ac-
count the profile of the reader. For example, a reader
who has read a lot of literary texts will have less dif-
ficulty reading new literary text than a reader, with a
similar educational background, who has never read
93
Figure 1: Search results and analysis of readability
any literature. In this section, we discuss the first
step we have taken towards making more reliable
predictions on text readability given the profile of
the reader.
Readers who are familiar with specific thematic
areas, are more likely to know vocabulary that is
recurring in these areas. So, if we have vocabu-
lary frequency counts per thematic area, we are in a
better position to predict difficult words for specific
readers given their reading profiles. Vocabulary fre-
quency lists are often used by test developers as an
indicator of text difficulty, based on the assumption
that less frequent words are more likely to be un-
known. However, these lists are built from a variety
of themes and cannot be customized for the reader.
We have computed vocabulary frequencies for all
supercategories in the thematically labeled corpus.
The top 10 most frequent words per supercategory
are shown in Table (3). Vocabulary frequencies per
grade level have also been computed but not shown
here.
Toreador is a tool which runs independently of
Read-X and it?s designed to predict unknown vocab-
ulary for specific reader and grade profiles currently
specified by the user. A screenshot of Toreador is
shown in Figure (2). The interface shows two tabs
labeled ?Enter text here? and ?Read text here?. The
?Enter text here? tab allows the user to customize
vocabulary difficulty predictions by selecting the de-
sired grade or theme.4 Then, text can be copied from
another source and pasted in the window of the tool.
The tool will analyze the text and in a few seconds
return the results fo the analysis in the tab labeled
?Read text here?, shown in Figure (3). Toreador
checks the vocabulary frequency of the words in the
pasted text and returns the text highlighted with the
words that do not rank high in the vocabulary fre-
quency index for the chosen categories (grade or
theme). The highlighted words are clickable. When
they are clicked, they entry information from Word-
Net appears on the right panel. The system has
not been evaluated yet so some tuning will be re-
quired to determine the optimal cut-off frequency
point for highlighting words. An option is also avail-
able to deactivate highlights for ease of read or read-
ing for global meaning. Words that the system has
4The screenshot in Figure (2) shows an earlier version of the
tool where only three thematic categories were available.
94
Figure 2: Text analysis of vocabulary difficulty
Arts Career and Business Literature Philosophy Science Social Studies Sports, Health Technology
Word Freq Word Freq Word Freq Word Freq Word Freq Word Freq Word Freq Word Freq
musical 166 product 257 seemed 1398 argument 174 trees 831 behavior 258 players 508 software 584
leonardo 166 income 205 myself 1257 knowledge 158 bacteria 641 states 247 league 443 computer 432
instrument 155 market 194 friend 1255 augustine 148 used 560 psychoanalytic 222 player 435 site 333
horn 149 price 182 looked 1231 belief 141 growth 486 social 198 soccer 396 video 308
banjo 128 cash 178 things 1153 memory 130 acid 476 clemency 167 football 359 games 303
american 122 analysis 171 caesar 1059 truth 130 years 472 psychology 157 games 320 used 220
used 119 resources 165 going 1051 logic 129 alfalfa 386 psychotherapy 147 teams 292 systems 200
nature 111 positioning 164 having 1050 things 125 crop 368 united 132 national 273 programming 174
artist 104 used 153 asked 1023 existence 115 species 341 society 131 years 263 using 172
wright 98 sales 151 indeed 995 informal 113 acre 332 court 113 season 224 engineering 170
Table 3: 10 top most frequent words per thematic category.
not seen before, count as unknown and can be erro-
neously highlighted (for example, the verb ?give? in
the screenshot example). We are currently running
evaluation studies with a group of volunteers. While
we recognize that the readability formulas currently
implemented in Read-X are inadequate measures of
expected reading difficulty, Toreador is not designed
as an improvement over Read-X but as a component
measuring expected vocabulary difficulty. Other
factors contributing to reading difficulty such as syn-
tactic complexity, propositional density and rhetor-
ical structure will be modeled separately in the fu-
ture.
8 Summary and future work
In this paper we presented preliminary versions of
two tools developed to assist struggling readers iden-
tify text that is at the desired level of reading diffi-
culty while at the same time interesting and relevant
to their interests. Read-X is, to our knowledge, the
first system designed to locate, classify and analyze
reading difficulty of web text in real time, i.e., per-
forming the web search and text analysis in seconds.
Toreador analyzes the vocabulary of given text and
predicts which words are likely to be difficult for the
reader. The contribution of Toreador is that its pre-
dictions are based on vocabulary frequencies calcu-
lated per thematic area and are different depending
on the reader?s prior familiarity with the thematic ar-
eas.
We emphasize the shortcomings of the exist-
ing readability formulas, currently implemented in
Read-X, and the need to develop more sophisticated
measures of reading difficulty. We recognize that
perceived difficulty is the result of many factors,
which need to be analyzed and modeled separately.
95
Figure 3: Text analysis of vocabulary difficutly
Our goal in this research project is not to provide a
single readability score. Instead, we aim at buidling
models for multiple factors and provide individual
evaluation for each, e.g., measures of syntactic com-
plexity, ambiguity, propositional density, vocabu-
lary difficulty, required amount of inference to iden-
tify discourse relations and prior knowledge of the
reader.
In future work, several studies are needed. To
achieve satisfactory performance for the fine grained
thematic categories, we are collecting more data. We
also plan to run the subcategories classification not
as an independent classificaition task but as subclas-
sification task on supercategories. We expect that the
accuracy of the classifier will improve but we also
expect that for very fine thematic distinctions alter-
native approaches may be be required (e.g., give spe-
cial weights for key vocabulary that will distinguish
between sports subthemes) or develop new classi-
fication features beyond statistical analysis of word
distributions.
More sophisticated textual, semantic and dis-
course organization features need to be explored
which will reflect the perceived coherence of the text
beyond the choice of words and sentence level struc-
ture. The recently released Penn Discourse Tree-
bank 2.0 (Prasad et al, 2008)) 5 is a rich source with
annotations of explicit and implicit discourse con-
nectives and semantic labels which can be used to
identify useful discourse features. Finally, more so-
phisticated models are needed of reader profiles and
how they impact the perceived reading difficulty of
the text.
9 Acknowledgments
We are grateful to Mark Dredze for his help run-
ning MIRA and Ani Nenkoca for useful discussions
on readability. We thank the CLUNCH group at
the Computer and Information Science department
at the University of Pennsylvaniaand and two re-
viewers for their very useful feedback. This work is
partially funded by the GAPSA/Provosts Award for
Interdisciplinary Innovation to Audrey Troutt, Uni-
versity of Pennsylvania.
References
Jonathan Anderson. 1983. Lix and rix: Variations of
a little-known readability index. Journal of Reading,
26(6):490?496.
M Coleman and T. Liau. 1975. A computer readabil-
ity formula designed for machine scoring. Journal of
Applied Psychology, 60:283?284.
5Project site, http://www.seas.upenn.edu/?pdtb
96
K. Collins-Thompson and J. Callan. 2004. Informa-
tion retrieval for language tutoring: An overview of
the REAP project. In Proceedings of the Twenty Sev-
enth Annual International ACM SIGIR Conference on
Research and Development in Information Retrieval
(poster descritpion.
Koby Crammer, Mark Dredze, John Blitzer, and Fer-
nando Pereira. 2008. Batch performance for an on-
line price. In The NIPS 2007 Workshop on Efficient
Machine Learning.
Lou Denti. 2004. Introduction: Pointing the way: Teach-
ing reading to struggling readers at the secondary level.
Reading and Writing Quarterly, 20:109?112.
Ted Hasselbring and Laura Goin. 2004. Literacy instruc-
tion for older struggling readers: What is the role of
technology? Reading and Writing Quarterly, 20:123?
144.
M. Heilman, K. Collins-Thompson, J. Callan, and M. Es-
kenazi. 2006. Classroom success of an intelligent
tutoring system for lexical practice and reading com-
prehension. In Proceedings of the Ninth International
Conference on Spoken Language Processing.
M. Heilman, K. Collins-Thompson, J. Callan, and M. Es-
kenazi. 2007. Combining lexical and grammatical
features to improve readability measures for first and
second language texts. In Proceedings of the Human
Language Technology Conference. Rochester, NY.
Derrick Higgins, Jill Burstein, Daniel Marcu, and Clau-
dia Gentile. 2004. Evaluating multiple aspects of co-
herence in student essays. In Proceedings of the Hu-
man Language Technology and North American As-
sociation for Computational Linguistics Conference
(HLT/NAACL 2004).
Eleni Miltsakaki and Karen Kukich. 2004. Evaluation
of text coherence for electronic essay scoring systems.
Natural Language Engineering, 10(1).
Sarah Petersen and Mari Ostendorf. 2006. Assessing the
reading level of web pages. In Proceedings of Inter-
speech 2006 (poster), pages 833?836.
Rashmi Prasad, Nikhil Dinesh, Alan Lee, Eleni Milt-
sakaki, Livio Robaldo, Aravind Joshi, and Bonnie
Webber. 2008. The penn discourse treebank 2.0. In
Proceedings of the 6th International Conference on
Language Resources and Evaluation (LREC 2008).
T. D. Snyder, A.G. Tan, and C.M. Hoffman. 2006. Digest
of education statistics 2005 (nces 2006-030). In U.S.
Department of Education, National Center for Edu-
cation Statistics. Washington, DC: U.S. Government
Printing Office.
John Strucker, Yamamoto Kentaro, and Irwin Kirsch.
2007. The relationship of the component skills of
reading to ials performance: Tipping points and five
classes of adult literacy learners. In NCSALL Reports
29. Boston: National Center for the Study of Adult
Learning and Literacy (NCSALL).
Thomas Weinstein and Herbert J. Walberg. 1993. Practi-
cal literacy of young adults: educational antecedents
and influences. Journal of Research in Reading,
16(1):3?19.
97
