TextGraphs-2: Graph-Based Algorithms for Natural Language Processing, pages 1?8,
Rochester, April 2007 c?2007 Association for Computational Linguistics
Analysis of the Wikipedia Category Graph for NLP Applications
Torsten Zesch and Iryna Gurevych
Ubiquitous Knowledge Processing Group
Telecooperation Division
Darmstadt University of Technology, Hochschulstra?e 10
D-64289 Darmstadt, Germany
{zesch,gurevych} (at) tk.informatik.tu-darmstadt.de
Abstract
In this paper, we discuss two graphs in
Wikipedia (i) the article graph, and (ii)
the category graph. We perform a graph-
theoretic analysis of the category graph,
and show that it is a scale-free, small
world graph like other well-known lexi-
cal semantic networks. We substantiate
our findings by transferring semantic re-
latedness algorithms defined on WordNet
to the Wikipedia category graph. To as-
sess the usefulness of the category graph
as an NLP resource, we analyze its cover-
age and the performance of the transferred
semantic relatedness algorithms.
1 Introduction
Wikipedia1 is a free multi-lingual online encyclo-
pedia that is constructed in a collaborative effort
of voluntary contributors and still grows exponen-
tially. During this process, Wikipedia has proba-
bly become the largest collection of freely available
knowledge. A part of this knowledge is encoded in
the network structure of Wikipedia pages. In par-
ticular, Wikipedia articles form a network of seman-
tically related terms, while the categories are orga-
nized in a taxonomy-like structure calledWikipedia
Category Graph (WCG).
In this paper, we perform a detailed analysis of
the WCG by computing a set of graph-theoretic pa-
rameters, and comparing them with the parameters
reported for well-known graphs and classical lexical
semantic networks. We show that the WCG, which
is constructed collaboratively, shares many proper-
ties with other lexical semantic networks, such as
1http://www.wikipedia.org
C 1
C 2
C 3
C 4
C 5
A 1
A 2
A 3
A 4
WC
G
Artic
le G
raph
Figure 1: Relations between article graph andWCG.
WordNet (Fellbaum, 1998) or Roget?s Thesaurus2
that are constructed by expert authors. This implies
that the WCG can be used as a resource in NLP ap-
plications, where other semantic networks have been
traditionally employed.
To further evaluate this issue, we adapt algorithms
for computing semantic relatedness on classical se-
mantic networks like WordNet to the WCG. We
evaluate their performance on the task of computing
semantic relatedness using three German datasets,
and show that WCG based algorithms perform very
well.
Article graph Wikipedia articles are heavily
linked, as links can be easily inserted while editing
an article. If we treat each article as a node, and
each link between articles as an edge running from
one node to another, then Wikipedia articles form
a directed graph (see right side of Figure 1). The
article graph has been targeted by numerous stud-
ies, and is not addressed in this paper. Buriol et al
(2006) analyze the development of the article graph
over time, and find that some regions are fairly sta-
ble, while others are advancing quickly. Zlatic et al
2http://thesaurus.reference.com
1
Figure 2: Structures of semantic networks after Steyvers and Tenenbaum (2005). a) a taxonomy, b) an
arbitrary graph, c) scale-free, small-world graph.
(2006) give a comprehensive overview of the graph
parameters for the largest languages in Wikipedia.
Capocci et al (2006) study the growth of the article
graph and show that it is based on preferential at-
tachment (Barabasi and Albert, 1999). Voss (2005)
shows that the article graph is scale-free and grows
exponentially.
Category graph Categories in Wikipedia are or-
ganized in a taxonomy-like structure (see left side of
Figure 1 and Figure 2-a). Each category can have an
arbitrary number of subcategories, where a subcate-
gory is typically established because of a hyponymy
or meronymy relation. For example, a category ve-
hicle has subcategories like aircraft or watercraft.
Thus, the WCG is very similar to semantic word-
nets like WordNet or GermaNet (Kunze, 2004). As
Wikipedia does not strictly enforce a taxonomic cat-
egory structure, cycles and disconnected categories
are possible, but rare. In the snapshot of the Ger-
manWikipedia3 fromMay 15, 2006, the largest con-
nected component in the WCG contains 99,8% of all
category nodes, as well as 7 cycles.
In Wikipedia, each article can link to an arbitrary
number of categories, where each category is a kind
of semantic tag for that article. A category back-
links to all articles in this category. Thus, article
graph and WCG are heavily interlinked (see Fig-
ure 1), and most studies (Capocci et al, 2006; Zlatic
et al, 2006) have not treated them separately. How-
ever, the WCG should be treated separately, as it
differs from the article graph. Article links are es-
tablished because of any kind of relation between
3Wikipedia can be downloaded from http:
//download.wikimedia.org/
articles, while links between categories are typically
established because of hyponymy or meronymy re-
lations.
Holloway et al (2005) create and visualize a cat-
egory map based on co-occurrence of categories.
Voss (2006) pointed out that the WCG is a kind of
thesaurus that combines collaborative tagging and
hierarchical indexing. Zesch et al (2007a) identified
the WCG as a valueable source of lexical semantic
knowledge, but did not analytically analyze its prop-
erties. However, even if the WCG seems to be very
similar to other semantic wordnets, a graph-theoretic
analysis of the WCG is necessary to substantiate this
claim. It is carried out in the next section.
2 Graph-theoretic Analysis of the WCG
A graph-theoretic analysis of the WCG is required
to estimate, whether graph based semantic related-
ness measures developed for semantic wordnets can
be transferred to the WCG. This is substantiated in
a case study on computing semantic relatedness in
section 4.
For our analysis, we treat the directed WCG as
an undirected graph G := (V,E),4 as the relations
connecting categories are reversible. V is a set of
vertices or nodes. E is a set of unordered pairs of
distinct vertices, called edges. Each page is treated
as a node n, and each link between pages is modeled
as an edge e running between two nodes.
Following Steyvers and Tenenbaum (2005), we
characterize the graph structure of a lexical semantic
resource in terms of a set of graph parameters: The
4Newman (2003) gives a comprehensive overview about the
theoretical aspects of graphs.
2
PARAMETER Actor Power C.elegans AN Roget WordNet WikiArt WCG
|V | 225,226 4,941 282 5,018 9,381 122,005 190,099 27,865
D - - - 5 10 27 - 17
k 61.0 2.67 14.0 22.0 49.6 4.0 - 3.54
? - - - 3.01 3.19 3.11 2.45 2.12
L 3.65 18.7 2.65 3.04 5.60 10.56 3.34 7.18
Lrandom 2.99 12.4 2.25 3.03 5.43 10.61 ? 3.30 ? 8.10
C 0.79 0.08 0.28 0.186 0.87 0.027 ? 0.04 0.012
Crandom 0.0003 0.005 0.05 0.004 0.613 0.0001 ? 0.006 0.0008
Table 1: Parameter values for different graphs.
Values for Actor (collaboration graph of actors in feature films), Power (the electrical power grid of the western United
States) andC.elegans (the neural network of the nematode worm C. elegans) are fromWatts and Strogatz (1998). Values
for AN (a network of word associations by Nelson et al (1998)), Roget?s thesaurus and WordNet are from Steyvers
and Tenenbaum (2005). Values for Wikiart (German Wikipedia article graph) are from Zlatic et al (2006). We took
the values for the page set labelled M on their website containing 190,099 pages for German, as it comes closest to a
graph of only articles. Values marked with ?-? in the table were not reported in the studies. The values for the WCG are
computed in this study.
degree k of a node is the number of edges that are
connected with this node. Averaging over all nodes
gives the average degree k. The degree distribution
P (k) is the probability that a random node will have
degree k. In some graphs (like the WWW), the de-
gree distribution follows a power law P (k) ? k??
(Barabasi and Albert, 1999). We use the power law
exponent ? as a graph parameter.
A path pi,j is a sequence of edges that connects
a node ni with a node nj . The path length l(pi,j)
is the number of edges along that path. There can
be more than one path between two nodes. The
shortest path length L is the minimum of all these
paths, i.e. Li,j = min l(pi,j). Averaging over all
nodes gives the average shortest path length L.
The diameterD is the maximum of the shortest path
lengths between all pairs of nodes in the graph.
The cluster coefficient of a certain node ni can
be computed as
Ci =
Ti
ki(ki?1)
2
=
2Ti
ki(ki ? 1)
where Ti refers to the number of edges between the
neighbors of node ni and ki(ki ? 1)/2 is the maxi-
mum number of edges that can exist between the ki
neighbors of node ni.5 The cluster coefficient C for
the whole graph is the average of all Ci. In a fully
connected graph, the cluster coefficient is 1.
5In a social network, the cluster coefficient measures how
many of my friends (neighboring nodes) are friends themselves.
For our analysis, we use a snapshot of the German
Wikipedia fromMay 15, 2006. We consider only the
largest connected component of the WCG that con-
tains 99,8% of the nodes. Table 1 shows our results
on the WCG as well as the corresponding values for
other well-known graphs and lexical semantic net-
works. We compare our empirically obtained values
with the values expected for a random graph. Fol-
lowing Zlatic et al (2006), the cluster coefficient C
for a random graph is
Crandom =
(k
2
? k)2
|V |k
The average path length for a random network can
be approximated as Lrandom ? log |V | / log k
(Watts and Strogatz, 1998).
From the analysis, we conclude that all graphs
in Table 1 are small world graphs (see Figure 2-c).
Small world graphs (Watts and Strogatz, 1998) con-
tain local clusters that are connected by some long
range links leading to low values of L and D. Thus,
small world graphs are characterized by (i) small
values of L (typically L & Lrandom), together with
(ii) large values of C (C  Crandom).
Additionally, all semantic networks are scale-free
graphs, as their degree distribution follows a power
law. Structural commonalities between the graphs
in Table 1 are assumed to result from the growing
process based on preferential attachment (Capocci
et al, 2006).
3
Our analysis shows that WordNet and the WCG
are (i) scale-free, small world graphs, and (ii) have a
very similar parameter set. Thus, we conclude that
algorithms designed to work on the graph structure
of WordNet can be transferred to the WCG.
In the next section, we introduce the task of com-
puting semantic relatedness on graphs and adapt ex-
isting algorithms to the WCG. In section 4, we eval-
uate the transferred algorithms with respect to corre-
lation with human judgments on SR, and coverage.
3 Graph Based Semantic Relatedness
Measures
Semantic similarity (SS) is typically defined via the
lexical relations of synonymy (automobile ? car)
and hypernymy (vehicle ? car), while semantic re-
latedness (SR) is defined to cover any kind of lexi-
cal or functional association that may exist between
two words (Budanitsky and Hirst, 2006). Dissimi-
lar words can be semantically related, e.g. via func-
tional relationships (night ? dark) or when they are
antonyms (high ? low). Many NLP applications re-
quire knowledge about semantic relatedness rather
than just similarity (Budanitsky and Hirst, 2006).
We introduce a number of competing approaches
for computing semantic relatedness between words
using a graph structure, and then discuss the changes
that are necessary to adapt semantic relatedness al-
gorithms to work on the WCG.
3.1 Wordnet Based Measures
A multitude of semantic relatedness measures work-
ing on semantic networks has been proposed.
Rada et al (1989) use the path length (PL) be-
tween two nodes (measured in edges) to compute
semantic relatedness.
distPL = l(n1, n2)
Leacock and Chodorow (1998, LC) normalize the
path-length with the depth of the graph,
simLC(n1, n2) = ? log
l(n1, n2)
2? depth
where depth is the length of the longest path in the
graph.
Wu and Palmer (1994, WP) introduce a measure
that uses the notion of a lowest common subsumer of
two nodes lcs(n1, n2). In a directed graph, a lcs is
the parent of both child nodes with the largest depth
in the graph.
simWP =
2 depth(lcs)
l(n1, lcs) + l(n2, lcs) + 2 depth(lcs)
Resnik (1995, Res), defines semantic similarity be-
tween two nodes as the information content (IC)
value of their lcs. He used the relative corpus fre-
quency to estimate the information content value.
Jiang and Conrath (1997, JC) additionally use the
IC of the nodes.
distJC(n1, n2) = IC(n1) + IC(n2)? 2IC(lcs)
Note that JC returns a distance value instead of a
similarity value.
Lin (1998, Lin) defined semantic similarity using
a formula derived from information theory.
simLin(n1, n2) = 2?
IC(lcs)
IC(n1) + IC(n2)
Because polysemous words may have more than
one corresponding node in a semantic wordnet, the
resulting semantic relatedness between two words
w1 and w2 can be calculated as
SR =
?
??
??
min
n1?s(w1),n2?s(w2)
dist(n1, n2) path
max
n1?s(w1),n2?s(w2)
sim(n1, n2) IC
where s(wi) is the set of nodes that represent senses
of word wi. That means, the relatedness of two
words is equal to that of the most related pair of
nodes.
3.2 Adapting SR Measures to Wikipedia
Unlike other wordnets, nodes in the WCG do not
represent synsets or single terms, but a general-
ized concept or category. Therefore, we cannot use
the WCG directly to compute SR. Additionally, the
WCG would not provide sufficient coverage, as it is
relatively small. Thus, transferring SR measures to
the WCG requires some modifications. The task of
estimating SR between terms is casted to the task
of SR between Wikipedia articles devoted to these
terms. SR between articles is measured via the cate-
gories assigned to these articles.
4
OR
X X+1 X X+1
X
X+1
X+1
X
X+1
X+1
X
X+1
X+1
Figure 3: Breaking cycles in the WCG.
We define C1 and C2 as the set of categories as-
signed to article ai and aj , respectively. We then de-
termine the SR value for each category pair (ck, cl)
with ck ? C1 and cl ? C2. We choose the best
value among all pairs (ck, cl), i.e. the minimum for
path based and the maximum for information con-
tent based measures.
SRbest =
?
?
?
min
ck?C1,cl?C2
(sr(ck, cl)) path based
max
ck?C1,cl?C2
(sr(ck, cl)) IIC based
See (Zesch et al, 2007b) for a more detailed descrip-
tion of the adaptation process.
We substitute Resnik?s information content with
the intrinsic information content (IIC) by Seco et
al. (2004) that is computed only from structural in-
formation of the underlying graph. It yields better
results and is corpus independent. The IIC of a node
ni is computed as a function of its hyponyms,
IIC(n) = 1?
log(hypo(ni) + 1
log(|C|)
where hypo(ni) is the number of hyponyms of node
ni and |C| is the number of nodes in the taxonomy.
Efficiently counting the hyponyms of a node re-
quires to break cycles that may occur in a WCG.
We perform a colored depth-first-search to detect cy-
cles, and break them as visualized in Figure 3. A
link pointing back to a node closer to the top of the
graph is deleted, as it violates the rule that links in
the WCG typically express hyponymy or meronymy
relations. If the cycle occurs between nodes on the
same level, we cannot decide based on that rule and
simply delete one of the links running on the same
level. This strategy never disconnects any nodes
from a connected component.
4 Semantic Relatedness Experiments
A commonly accepted method for evaluating SR
measures is to compare their results with a gold stan-
dard dataset based on human judgments on word
pairs.6
4.1 Datasets
To create gold standard datasets for evaluation, hu-
man annotators are asked to judge the relatedness of
presented word pairs. The average annotation scores
are correlated with the SR values generated by a par-
ticular measure.
Several datasets for evaluation of semantic re-
latedness or semantic similarity have been created
so far (see Table 2). Rubenstein and Goodenough
(1965) created a dataset with 65 English noun pairs
(RG65 for short). A subset of RG65 has been
used for experiments by Miller and Charles (1991,
MC30) and Resnik (1995, Res30).
Finkelstein et al (2002) created a larger dataset
for English containing 353 pairs (Fin353), that has
been criticized by Jarmasz and Szpakowicz (2003)
for being culturally biased. More problematic is that
Fin353 consists of two subsets, which have been an-
notated by a different number of annotators. We per-
formed further analysis of their dataset and found
that the inter-annotator agreement7 differs consider-
ably. These results suggest that further evaluation
based on this data should actually regard it as two
independent datasets.
As Wikipedia is a multi-lingual resource, we are
not bound to English datasets. Several German
datasets are available that are larger than the exist-
ing English datasets and do not share the problems
of the Finkelstein datasets (see Table 2). Gurevych
(2005) conducted experiments with a German trans-
lation of an English dataset (Rubenstein and Good-
enough, 1965), but argued that the dataset is too
small and only contains noun-noun pairs connected
6Note that we do not use multiple-choice synonym question
datasets (Jarmasz and Szpakowicz, 2003), as this is a different
task, which is not addressed in this paper.
7We computed the correlation for all annotators pairwise and
summarized the values using a Fisher Z-value transformation.
5
CORRELATION r
DATASET YEAR LANGUAGE # PAIRS POS TYPE SCORES # SUBJECTS INTER INTRA
RG65 1965 English 65 N SS continuous 0?4 51 - .850
MC30 1991 English 30 N SS continuous 0?4 38 - -
Res30 1995 English 30 N SS continuous 0?4 10 .903 -
Fin353 2002 English 353 N, V, A SR continuous 0?10 13/16 - -
153 13 .731 -
200 16 .549 -
Gur65 2005 German 65 N SS discrete {0,1,2,3,4} 24 .810 -
Gur350 2006 German 350 N, V, A SR discrete {0,1,2,3,4} 8 .690 -
ZG222 2006 German 222 N, V, A SR discrete {0,1,2,3,4} 21 .490 .647
Table 2: Comparison of German datasets used for evaluating semantic relatedness.
by either synonymy or hyponymy. Thus, she cre-
ated a larger German dataset containing 350 word
pairs (Gur350). It contains nouns, verbs and ad-
jectives that are connected by classical and non-
classical relations (Morris and Hirst, 2004). How-
ever, word pairs for this dataset are biased to-
wards strong classical relations, as they were man-
ually selected. Thus, Zesch and Gurevych (2006)
used a semi-automatic process to create word pairs
from domain-specific corpora. The resulting ZG222
dataset contains 222 word pairs that are connected
by all kinds of lexical semantic relations. Hence, it
is particularly suited for analyzing the capability of
a measure to estimate SR.
4.2 Results and Discussion
Figure 4 gives an overview of our experimental re-
sults of evaluating SR measures based on the WCG
on three German datasets. We use Pearson?s prod-
uct moment correlation r to compare the results with
human judgments. From each dataset, we only use
word pairs where Wikipedia articles corresponding
to these words are available (see section 4.3 for a de-
tailed discussion of word pair coverage). For com-
parison, we give the best results obtained by Ger-
maNet based measures (abbreviated as GN).8
Our results show that the graph-based SR mea-
sures have been successfully transferred to the
WCG. Results on the Gur65 dataset (containing only
word pairs connected by strong classical relations)
are lower than values computed using GermaNet.
This is to be expected, as the WCG is created col-
laboratively without strictly enforcing a certain type
8Additionally, Table 2 gives the inter annotator agreement
for each subset. It constitutes an upper bound of a measure?s
performance on a certain dataset.
0.000.200.400.600.80
Correl
ation 
r0.75
0.500.42
0.510.34
0.450.35
GN
Res
JC
Lin
PLW
PLC
Gur65
0.000.200.400.600.80
Correl
ation 
r0.50
0.440.41
0.450.55
0.520.39
GN
Res
JC
Lin
PLW
PLC
Gur350
0.000.200.400.600.80
Correl
ation 
r0.30
0.320.43
0.350.50
0.450.36
GN
Res
JC
Lin
PLW
PLC
ZG222
Figure 4: Correlations on different datasets.
6
of semantic relation between categories, while Ger-
maNet is carefully modelled to represent the strong
classical relations captured by Gur65. Results on the
two other datasets, which contain a majority of word
pairs connected by non-classical semantic relations,
show that the WCG is better suited than GermaNet
to estimate SR.
Performance of WCG based measures depends on
the dataset and the kind of knowledge used. IIC
based measures (Res, JC and Lin) outperform path
based measures (PL, LC and WP ) on the Gur65
dataset, while path based measures are clearly bet-
ter on SR datasets (Gur350 and ZG222). The im-
pressive performance of the simple PL measure on
the SR datasets cannot be explained with the struc-
tural properties of the WCG, as they are very similar
to those of other semantic networks. Semantically
related terms are very likely to be categorized un-
der the same category, resulting in short path lengths
leading to high SR. The generalization process that
comes along with classification seems to capture the
phenomenon of SR quite well. As each article can
have many categories, different kinds of semantic
relations between terms can be established, but the
type of relation remains unknown.
4.3 Coverage of Word Pairs
If the WCG is to be used as a lexical semantic re-
source in large scale NLP applications, it should
provide broad coverage. As was described in sec-
tion 3.2, computing SR using the WCG relies on
categories assigned to articles. Thus, we consider
a word to be covered by the WCG, if there is a cate-
gorized article with matching title.
Table 3 gives an overview of the number of word
pairs covered in GermaNet or the WCG. Only few
words from Gur65 were not found in one of the re-
sources. This proportion is much higher for Gur350
and ZG222, as these datasets contain many domain
specific terms that are badly covered in GermaNet,
and many word pairs containing verbs and adjectives
that are badly covered in the WCG.9 A number of
word pairs (mostly containing combinations of verbs
or adjectives) were found neither in GermaNet nor
9Resulting from an editorial decision, Wikipedia only con-
tains articles devoted to terms of encyclopedic interest - mainly
nouns. Adjectives and verbs redirect to their corresponding
nouns, if they are covered at all.
Wikipedia (see GN ? WCG). If we consider only
noun-noun pairs (NN), the coverage of Wikipedia
exceeds that of GermaNet. The high proportion of
word pairs that are either only found in GermaNet
or in the WCG indicates that they are partially com-
plementary with respect to covered vocabulary.
5 Conclusion
In this paper, we performed a graph-theoretic anal-
ysis of the Wikipedia Category Graph and showed
that it is a scale-free, small-world graph, like other
semantic networks such as WordNet or Roget?s the-
saurus. From this result, we concluded that the
WCG can be used for NLP tasks, where other se-
mantic networks have been traditionally employed.
As Wikipedia is a multi-lingual resource, this en-
ables the transfer of NLP algorithms to languages
that do not have well-developed semantic wordnets.
To substantiate this claim, we described howmea-
sures of semantic relatedness operating on seman-
tic wordnets, like WordNet or GermaNet, can be
adapted to work on the WCG. We showed that the
WCG is well suited to estimate SR between words.
This is due to the categorization process that con-
nects terms which would not be closely related in
a taxonomic wordnet structure. Consequently, Ger-
maNet outperforms the WCG on the task of estimat-
ing semantic similarity. Furthermore, the WCG can-
not be used for tasks that require knowledge about
the exact type of semantic relation.
We performed an analysis of the coverage of
Wikipedia. It covers nouns very well, but is less
suited to compute semantic relatedness across parts-
of-speech. In this case, conventional semantic word-
nets are likely to provide a better knowledge source.
In Zesch et al (2007b), we show that knowledge
from wordnets and from Wikipedia is complemen-
tary, and can be combined to improve the perfor-
mance on the SR task. As the simple PL measure
performs remarkably well on the SR datasets, in our
future work, we will also consider computing SR us-
ing the path length on the Wikipedia article graph
rather than on the WCG.
Acknowledgments
This work was supported by the German Research
Foundation under the grant "Semantic Information
7
DATASET # PAIRS GN WCG GN ? WCG GN \ WCG WCG \ GN GN ? WCG
Gur65 65 57 61 65 4 8 53
Gur350 350 208 161 248 87 40 121
Gur350 NN 173 109 115 129 14 20 95
ZG222 222 86 86 118 32 30 56
ZG222 NN 119 57 61 73 12 16 45
Table 3: Number of covered word pairs based on GermaNet (GN) and the WCG on different datasets.
Retrieval from Texts in the Example Domain Elec-
tronic Career Guidance" (SIR), GU 798/1-2.
References
A. Barabasi and R. Albert. 1999. Emergence of scaling in
random networks. Science, 286:509?512.
A. Budanitsky and G. Hirst. 2006. Evaluating WordNet-based
Measures of Semantic Distance. Computational Linguistics,
32(1).
L. Buriol, C. Castillo, D. Donato, S. Leonardi, and S. Millozzi.
2006. Temporal Analysis of the Wikigraph. In Proc. of Web
Intelligence, Hong Kong.
A. Capocci, V. D. P. Servedio, F. Colaiori, L. S. Buriol, D. Do-
nato, S. Leonardi, and G. Caldarelli. 2006. Preferential at-
tachment in the growth of social networks: The internet en-
cyclopedia Wikipedia. Physical Review E, 74:036116.
C. Fellbaum. 1998. WordNet An Electronic Lexical Database.
MIT Press, Cambridge, MA.
L. Finkelstein, E. Gabrilovich, Y. Matias, E. Rivlin, Z. Solan,
and G. Wolfman. 2002. Placing Search in Context: The
Concept Revisited. ACM TOIS, 20(1):116?131.
I. Gurevych. 2005. Using the Structure of a Conceptual Net-
work in Computing Semantic Relatedness. In Proc. of IJC-
NLP, pages 767?778.
T. Holloway, M. Bozicevic, and K. B?rner. 2005. Analyzing
and Visualizing the Semantic Coverage of Wikipedia and Its
Authors. ArXiv Computer Science e-prints, cs/0512085.
M. Jarmasz and S. Szpakowicz. 2003. Roget?s thesaurus and
semantic similarity. In Proc. of RANLP, pages 111?120.
J. J. Jiang and D. W. Conrath. 1997. Semantic Similarity Based
on Corpus Statistics and Lexical Taxonomy. In Proc. of
the 10th International Conference on Research in Compu-
tational Linguistics.
C. Kunze, 2004. Computerlinguistik und Sprachtechnologie,
chapter Lexikalisch-semantische Wortnetze, pages 423?431.
Spektrum Akademischer Verlag.
C. Leacock and M. Chodorow, 1998. WordNet: An Elec-
tronic Lexical Database, chapter Combining Local Context
andWordNet Similarity for Word Sense Identification, pages
265?283. Cambridge: MIT Press.
D. Lin. 1998. An Information-Theoretic Definition of Similar-
ity. In Proc. of ICML.
G. A. Miller and W. G. Charles. 1991. Contextual Correlates
of Semantic Similarity. Language and Cognitive Processes,
6(1):1?28.
J. Morris and G. Hirst. 2004. Non-Classical Lexical Seman-
tic Relations. In Proc. of the Workshop on Computational
Lexical Semantics, NAACL-HLT.
D. L. Nelson, C. L. McEvoy, and T. A. Schreiber. 1998. The
University of South Florida word association, rhyme, and
word fragment norms. Technical report, U. of South Florida.
M. E. J. Newman. 2003. The structure and function of complex
networks. SIAM Review, 45:167?256.
R. Rada, H. Mili, E. Bicknell, and M. Blettner. 1989. Develop-
ment and Application of a Metric on Semantic Nets. IEEE
Trans. on Systems, Man, and Cybernetics,, 19(1):17?30.
P. Resnik. 1995. Using Information Content to Evaluate Se-
mantic Similarity. In Proc. of IJCAI, pages 448?453.
H. Rubenstein and J. B. Goodenough. 1965. Contextual
Correlates of Synonymy. Communications of the ACM,
8(10):627?633.
N. Seco, T. Veale, and J. Hayes. 2004. An Intrinsic Information
Content Metric for Semantic Similarity inWordNet. In Proc.
of ECAI.
M. Steyvers and J. B. Tenenbaum. 2005. The Large-Scale
Structure of Semantic Networks: Statistical Analyses and a
Model of Semantic Growth. Cognitive Science, 29:41?78.
J. Voss. 2005. Measuring Wikipedia. In Proc. of the 10th In-
ternational Conference of the International Society for Sci-
entometrics and Informetrics, Stockholm, Sweden.
J. Voss. 2006. Collaborative thesaurus tagging the Wikipedia
way. ArXiv Computer Science e-prints, cs/0604036.
D. J. Watts and S. H. Strogatz. 1998. Collective Dynamics of
Small-World Networks. Nature, 393:440?442.
Z. Wu and M. Palmer. 1994. Verb Semantics and Lexical Se-
lection. In Proc. of ACL, pages 133?138.
T. Zesch and I. Gurevych. 2006. Automatically Creating
Datasets for Measures of Semantic Relatedness. In Proc.
of the Workshop on Linguistic Distances, ACL, pages 16?24.
T. Zesch, I. Gurevych, and M. M?hlh?user. 2007a. Analyzing
and Accessing Wikipedia as a Lexical Semantic Resource.
In Proc. of Biannual Conference of the Society for Compu-
tational Linguistics and Language Technology, pages 213?
221.
T. Zesch, I. Gurevych, and M. M?hlh?user. 2007b. Compar-
ing Wikipedia and German Wordnet by Evaluating Semantic
Relatedness on Multiple Datasets. In Proc. of NAACL-HLT,
page (to appear).
V. Zlatic, M. Bozicevic, H. Stefancic, and M. Domazet. 2006.
Wikipedias: Collaborative web-based encyclopedias as com-
plex networks. Physical Review E, 74:016115.
8
