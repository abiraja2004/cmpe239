Proceedings of the NAACL HLT 2012 Student Research Workshop, pages 35?40,
Montre?al, Canada, June 3-8, 2012. c?2012 Association for Computational Linguistics
Domain-Specific Semantic Relatedness From Wikipedia:
Can A Course Be Transferred?
Beibei Yang
University of Massachusetts Lowell
Lowell, MA 01854
byang1@cs.uml.edu
Jesse M. Heines
University of Massachusetts Lowell
Lowell, MA 01854
heines@cs.uml.edu
Abstract
Semantic relatedness, or its inverse, seman-
tic distance, measures the degree of close-
ness between two pieces of text determined by
their meaning. Related work typically mea-
sures semantics based on a sparse knowledge
base such as WordNet1 or CYC that requires
intensive manual efforts to build and main-
tain. Other work is based on the Brown cor-
pus, or more recently, Wikipedia. Wikipedia-
based measures, however, typically do not
take into account the rapid growth of that re-
source, which exponentially increases the time
to prepare and query the knowledge base. Fur-
thermore, the generalized knowledge domain
may be difficult to adapt to a specific domain.
To address these problems, this paper pro-
poses a domain-specific semantic relatedness
measure based on part of Wikipedia that ana-
lyzes course descriptions to suggest whether a
course can be transferred from one institution
to another. We show that our results perform
well when compared to previous work.
1 Introduction
Many NLP techniques have been adapted to the ed-
ucation field for building systems such as automated
scoring, intelligent tutoring, and learner cognition.
Few, however, address the identification of transfer
course equivalencies. A recent study by the Na-
tional Association for College Admission Counsel-
ing2 reveals that 1/3 of US college students trans-
1http://wordnet.princeton.edu/
2Special Report on the Transfer Admission Process:
http://www.nacacnet.org/research/research-data/Documents/
TransferFactSheet.pdf
fer to another institution. Correspondingly, Univer-
sity of Massachusetts Lowell (UML) accepts hun-
dreds of transfer students every year. Each trans-
fer course must be evaluated for credits by manually
comparing its course description to courses offered
at UML. This process is labor-intensive and highly
inefficient. There is a publicly available course
transfer dictionary which lists course numbers from
hundreds of institutions and their equivalent courses
at UML, but the data set is sparse, non-uniform,
and always out of date. External institutions cancel
courses, change course numbers, etc., and such in-
formation is virtually impossible to keep up to date
in the transfer dictionary. Furthermore, the transfer
dictionary does not list course descriptions. From
our experience, course descriptions change over the
years even when course numbers do not, and this of
course affect equivalencies.
This work proposes a domain-specific semantic
relatedness measure using Wikipedia that automat-
ically suggests whether two courses from different
institutions are equivalent by analyzing their course
descriptions. The goal is to assist transfer coordina-
tors by suggesting equivalent courses within a rea-
sonable amount of time on a standard laptop system.
Our model is a mapping function: f : (C1, C2) ?
n, n ? [0, 1], where C1 is a Computer Science (CS)
course from an external institution, and C2 is a CS
course offered at UML. Output n is the semantic re-
latedness score, where a bigger value indicates C1
and C2 are more related. Each course description is
a short text passage:
? C1: [Analysis of Algorithms] Discusses basic methods
for designing and analyzing efficient algorithms empha-
35
sizing methods used in practice. Topics include sorting,
searching, dynamic programming, greedy algorithms, ad-
vanced data structures, graph algorithms (shortest path,
spanning trees, tree traversals), matrix operations, string
matching, NP completeness.
? C2: [Computing III] Object-oriented programming.
Classes, methods, polymorphism, inheritance. Object-
oriented design. C++. UNIX. Ethical and social issues.
# nodes: 25
WordNet  [Root: synset(??technology??), #depth: 2]
# nodes: 3583
Wikipedia  [Centroid: ??Category:Technology??, #steps: 2]
Fragments of WordNet and Wikipedia Taxonomies
Figure 1. Fragments of WordNet 3.0 (top) and
English Wikipedia of 2011/7 (bottom) taxonomies.
The root/centroid node is shown in red.
1992 1996 2000 2004 2008 2012
Year
500000
1000000
1500000
2000000
2500000
3000000
3500000
4000000
A
r
t
i
c
l
e
/
S
y
n
s
e
t
 
c
o
u
n
t
Growth of English Wikipedia and WordNet
Articles in Wikipedia
Synsets in WordNet
Figure 2. Growth of Wikipedia and WordNet
We choose Wikipedia as the knowledge base
due to its rich contents (Figure 1) and continu-
ously coalescent growth (Bounova, 2011). Although
Wikipedia was launched 10 years later, it grew much
faster than WordNet over the last decade (Figure 2).
The contributions of this paper are twofold. First,
we address the problem of domain-specific semantic
relatedness using Wikipedia. We propose a method
to suggest course equivalencies by computing se-
mantic relatedness among Computer Science course
descriptions. Our approach can be easily modified
for other majors and even other languages. Second,
we evaluate the correlation of our approach and a hu-
man judgment data set we built. Both accuracy and
correlation indicate that our approach outperforms
previous work.
2 Related Research
Semantic relatedness has been used in applications
such as word sense disambiguation, named entity
disambiguation, text summarization and annotation,
lexical selection, automatic spelling correction, and
text structure evaluation. WordNet is commonly
used as a lexicographic resource to calculate se-
mantic relatedness (Budanitsky and Hirst, 2006).
A WordNet-based method uses one or more edge-
counting techniques in theWordNet taxonomy (Lea-
cock and Chodorow, 1998; Hirst and St-Onge,
1998). The relatedness of two concept nodes is a
function of the minimum number of hops between
them.
Some related work calculates co-occurrence on
one or more large corpora to deduce semantic re-
latedness (Sahami and Heilman, 2006; Cilibrasi and
Vitanyi, 2007). Two words are likely to be related if
they co-occur within similar contexts (Lin, 1998).
Others combine lexicographic resources with cor-
pus statistics (Jiang and Conrath, 1997). It has been
shown that these composite methods generally out-
perform lexicographic resource- and corpus- based
methods (Budanitsky and Hirst, 2006; Curran, 2004;
Mohammad, 2008). Li et al. (2006) propose a hybrid
method based on WordNet and the Brown corpus to
incorporate semantic similarity between words, se-
mantic similarity between sentences, and word order
similarity to measure the overall sentence similarity.
Yang and Heines (2011) modify this work to suggest
transfer course equivalencies, but the experiment is
based on non-technical courses. Due to theWordNet
sparsity on technical terms, the experiment does not
perform well on Computer Science courses.
36
In recent years, there has been increasing interest
in applying Wikipedia and related resources to ques-
tion answering (Buscaldi and Rosso, 2006), word
sense disambiguation (WSD) (Mihalcea and Cso-
mai, 2007), name entity disambiguation (Ni et al.,
2010), ontology evaluation (Yu et al., 2007), seman-
tic web (Wu, 2010), and computing semantic relat-
edness (Ponzetto and Strube, 2007). Ponzetto and
Strube (2007) deduce semantic relatedness of words
by modeling relations on the Wikipedia category
graph. Gabrilovich and Markovitch (2009) intro-
duce the Explicit Semantic Analysis (ESA) model
which calculates TF-IDF (Manning et al., 2008) val-
ues for every word in Wikipedia and further uses lo-
cal linkage information to build a second-level se-
mantic interpreter.
Our approach is different from prior work on
Wikipedia. While Mihalcea and Csomai (2007)
use the annotation in the page title of a concept to
perform WSD, our approach uses a page?s parent
category as a cue to the correct sense. Ponzetto
and Strube (2007) limit their measurement to word
pairs, while our work focuses on text of any length.
Gabrilovich and Markovitch (2009) computes TF-
IDF statistics for every word and every document
of Wikipedia which is highly inefficient. They also
remove category pages and disambiguation pages.
In contrast, our model is mainly based on the cate-
gory taxonomy and the corpus statistics are limited
to metadata that are mostly available in Wikipedia.
Furthermore, we compute concept relatedness on
a domain-specific hierarchy that weighs both path
lengths and diversions from the topic. The domain-
specific hierarchy is much smaller than the entire
Wikipedia corpus. As a result, our algorithm is more
efficient3 than previous work.
3In our experiment, the average time needed to compare
one pair of course descriptions ranged from 0.16 second (with
partial caching) to 1 minute (without caching) on a 2.6Ghz
Quad-Core PC. The most time-consuming part before compar-
ing courses was to index all the Wikipedia tables in a MySQL
database, which took overnight (same for ESA). It only took
us 15 minutes to go through 19K pages to build a hierarchy
of D = 4. In contrast, ESA?s first level semantic interpreter
(which tokenizes every Wikipedia page to compute TF-IDF)
took 7 days to build over the same 19K pages. Both imple-
mentations were single-threaded, coded in Python, and tested
over the English Wikipedia of July 2011.
3 Proposed Method
Our method contains four modules. Section 3.1 ex-
plains how to construct a domain-specific hierarchy
fromWikipedia. Section 3.2 presents semantic relat-
edness between concepts. Section 3.3 describes the
steps to generate features from course descriptions.
And section 3.4 evaluates course relatedness.
3.1 Extract a Lexicographical Hierarchy
When a domain is specified (e.g., CS courses), we
start from a generic Wikipedia category in this do-
main, choose its parent as the root, and use a depth-
limited search to recursively traverse each subcate-
gory (including subpages) to build a lexicographical
hierarchy with depth D. For example, to find CS
course equivalencies, we built a hierarchy using the
parent of ?Category:Computer science,? i.e., ?Cat-
egory:Applied sciences,? as the root. The generic
category?s parent is chosen as the root to make sure
the hierarchy not only covers the terms in this do-
main, but also those in neighbor domains. The hier-
archy of ?Category:Applied sciences? not only cov-
ers Computer Science, but also related fields such as
Computational Linguistics and Mathematics.
Both the number of nodes and number of edges
in the hierarchy grow exponentially4 as the depth
increases. Therefore, D need not be a big number
to cover most terms in the domain. We have found
the hierarchy speeds up the semantic measurement
dramatically and covers almost all the words in the
specific domain. In our experiment on CS courses
(D=6), we eliminated over 71% of Wikipedia arti-
cles,5 yet the hierarchy covered over 90% of CS ter-
minologies mentioned in the course descriptions.
3.2 Semantic Relatedness Between Concepts
Similar to the work of Li et al. (2006), the seman-
tic relatedness between two Wikipedia concepts,6 t1
and t2 in the hierarchy is defined as:
f ?(t1, t2) = e??p ?
e?d ? e??d
e?d + e??d
(?, ? ? [0, 1]), (1)
where p is the shortest path between t1 and t2, and
d is the depth of the lowest common hypernym of t1
4In the hierarchy we built with ?Category:Applied sciences?
as the root, the number of edges grows from 177,955 at D=4 to
494,039 at D=5 and 1,848,052 at D=6.
5The hierarchy contains 1,534,267 unique articles, as op-
posed to 5,329,186 articles in Wikipedia.
6Each concept corresponds to a Wikipedia page.
37
and t2 in the hierarchy (Section 3.1). This is differ-
ent from related work on semantic relatedness from
Wikipedia (Ponzetto and Strube, 2007) in that we
not only consider the shortest path (p) between two
concepts but also their common distance (d) from
the topic, which in turn emphasizes domain aware-
ness.
3.3 Generate Course Description Features
The built-in redirection in Wikipedia is useful for
spelling corrections because variations of a term
redirect to the same page. To generate features from
a course description C, we start by generating n-
grams (n ? [1, 3]) from C. We then query the redi-
rection data to fetch all pages that match any of the
n-grams.
The identified pages are still sparse. We therefore
query the title data to fetch those that match any of
the n-grams. Page topics are not discriminated in
this step. For example, unigram ?Java? returns both
?Java (software platform)? and ?Java (dance).?
Wikipedia contains a collection of disambigua-
tion pages. Each disambiguation page includes a list
of alternative uses of a term. Note that there are two
different Wikipedia disambiguation pages: explicit
and implicit. A page is explicit when the page ti-
tle is annotated by Wikipedia as ?disambiguation,?
such as ?Oil (disambiguation).? A page is implicit
when it is not so annotated, but points to a category
such as ?Category:Disambiguation pages,? or ?Cat-
egory:All disambiguation pages.? We iterate over
the pages fetched from the last step, using disam-
biguation pages to enrich and refine the features of a
course description.
Unlike the work of Mihalcea and Csomai (2007)
which uses the annotation in the page title of a con-
cept to perform WSD, our approach uses a page?s
parent category as a cue to the correct sense. Typi-
cally, the sense of a concept depends on the senses of
other concepts in the context. For example, a para-
graph on programming languages and data types
ensures that ?data? more likely corresponds to a
page under ?Category:Computer data? than one un-
der ?Category:Star Trek.?
Algorithm 1 explains the steps to generate fea-
tures for a course C.
Given the C1 and C2 in section 1, their generated
features F1 and F2 are:
F1: Shortest path problem, Tree traversal, Spanning tree, Tree,
Analysis, List of algorithms, Completeness, Algorithm, Sort-
ing, Data structure, Structure, Design, Data.
F2: Unix, Social, Ethics, Object-oriented design, Computer
programming, C++, Object-oriented programming, Design.
Algorithm 1 Feature Generation (F ) for Course C
1. Tc ? ? (clear terms), Ta ? ? (ambiguous terms).
2. Generate all possible n-grams (n ? [1, 3]) G from C.
3. Fetch the pages whose titles match any of g ? G
from Wikipedia redirection data. For each page pid
of term t, Tc ? Tc ? {t : pid}.
4. Fetch the pages whose titles match any of g ? G
from Wikipedia page title data. If a disambiguation
page, include all the terms this page refers to. If a
page pid corresponds to a term t that is not ambigu-
ous, Tc ? Tc ? {t : pid}, else Ta ? Ta ? {t : pid}.
5. For each term ta ? Ta, find the disambiguation that
is on average most related (Equation 1) to the set of
clear terms. If a page pid of ta is on average the most
related to the terms in Tc, and the relatedness score is
above a threshold ? (? ? [0, 1]), set Tc ? Tc ? {ta :
pid}. If ta and a clear term are different senses of the
same term, keep the one that is more related to all the
other clear terms.
6. Return clear terms as features.
Algorithm 2 Semantic Vector SV1 for F1 and J
1. for all words ti ? J do
2. if ti ? F1, set SV1i = 1 where SV1i ? SV1.
3. if ti /? F1, the semantic relatedness between ti and
each term t1j ? F1 is calculated (Equation 1). Set
SV1i to the highest score if the score exceeds the
preset threshold ?, otherwise SV1i = 0.
4. end for
3.4 Determine Course Relatedness
Given two course descriptions C1 and C2, we use
Algorithm 1 to generate features F1 for C1, and F2
forC2. Next, the two feature lists are joined together
into a unique set of terms, namely J . Similar to pre-
vious work (Li et al., 2006), semantic vectors SV1
(Algorithm 2) and SV2 are computed for F1 and F2.
Each value of an entry of SV1 for features F1 is
reweighed as:
SV1i = SV1i ? I(ti) ? I(tj), (2)
where SV1i is the semantic relatedness between ti ?
F1 and tj ? J . I(ti) is the information content of ti,
and I(tj) is the information content of tj . Similarly,
we reweigh each value for the semantic vector SV2
of F2.
38
The information content I(t) of a term t is a
weighed sum of the category information content
Ic(t) and the linkage information content Il(t):
I(t) = ? ? Ic(t) + (1? ?) ? Il(t). (3)
Inspired by related work (Seco et al., 2004), the
category information content of term t is redefined
as a function of its siblings:
Ic(t) = 1?
log(siblings(t) + 1)
log(N)
, (4)
where siblings(t) is the number of siblings for t on
average, and N is the total number of terms in the
hierarchy (Section 3.1).
The linkage information content is a function of
outlinks and inlinks of the page pid that t corre-
sponds to:
Il(t) = 1?
inlinks(pid)
MAXIN
? outlinks(pid)
MAXOUT
, (5)
where inlinks(pid) and outlinks(pid) are the
numbers of inlinks and outlinks of a page pid.
MAXIN and MAXOUT are the maximum num-
bers of inlinks and outlinks that a page has in
Wikipedia.7
Finally, the relatedness of two courses is a cosine
coefficient of the two semantic vectors:
f(C1, C2) =
SV1 ? SV2
||SV1|| ? ||SV2||
. (6)
4 Experimental Results
Wikipedia offers its content as database backup
dumps (wikidumps) freely available to download.
Our application is based on the English wikidump8
of July 2011. We have extracted redirections, ti-
tles, categories, and links from the wikidump into
separate tables in MySQL. Using the steps outlined
in Section 3.1, we built a table for the hierarchy
with ?Category:Applied sciences? as the root. The
attributes of each table were indexed to speed up
queries. Our experiment used ? = 0.2, ? = 0.5,
? = 0.2, and ? = 0.6. These values were found
7The computation of MAXIN and MAXOUT could
be time-consuming. They are therefore based on the entire
Wikipedia instead of the constructed hierarchy to avoid the re-
calculation when the domain changes. This also ensures the
maximum linkage information is unbiased for every domain.
For the July 2011 wikidump, page ?Geographic coordinate sys-
tem? has the most in-links, a total of 575,277. Page ?List of Ital-
ian communes (2009)? has the most out-links, a total of 8,103.
8http://dumps.wikimedia.org/enwiki/20110722/
empirically to perform well over randomly selected
samples.
We randomly selected 25 CS courses from 19
universities that can be transferred to University
of Massachusetts Lowell (UML) according to the
transfer dictionary. Each transfer course was com-
pared to all 44 CS courses offered at UML, a to-
tal of 1,100 comparisons. The result was consid-
ered correct for each course if the real equivalent
course in UML appears among the top 3 in the list
of highest scores. We excluded all Wikipedia pages
whose titles contained specific dates or were anno-
tated as ?magazine?, ?journal?, or ?album.? We re-
moved both general and domain stop words (such
as ?course,? ?book,? and ?student?) from course de-
scriptions. If a course description contains the key-
words ?not? or ?no,? e.g., ?This course requires no
computer programming skills,? the segment after
such keyword is ignored.
We tested our approach against the work by Li
et al. (2006) and TF-IDF on the same data set of
course descriptions. The accuracy of our proposed
approach is 72%, compared to 52% using Li et al.
(2006), and 32% using TF-IDF.
Algorithm Pearson?s correlation p-value
Our approach 0.85 6.6 ? 10?10
Li et al. (2006) 0.57 0.0006
TF-IDF 0.73 2 ? 10?6
Table 1. Pearson?s correlation of course relatedness
scores with human judgments.
Since the transfer dictionary is always out of date,
we found a few equivalent course pairs that were un-
intuitive. To make a more meaningful evaluation,
we set up a human judgment data set. We gave
6 annotators (CS students and professors) a list of
32 pairs of courses, with only course titles and de-
scriptions. They independently evaluated whether
each pair is equivalent on a scale from 1 to 5. We
averaged their evaluations for each pair and con-
verted the scale from [1,5] to [0,1]. Next, we ran
our approach, the work by Li et al. (2006), and TF-
IDF on the same 32 course pairs. Table 1 reports
the Pearson?s correlation coefficient of course relat-
edness scores with human judgment, and statistical
significances. Our approach has a higher correlation
to the human judgment data set compared to previ-
39
ous work. Furthermore, a smaller p-value indicates
our approach is more likely to correlate with human
judgment.
During the experiment, we have found some mis-
classified categories in the wikidump.9 For example,
?Category:Software? has over 350 subcategories
with names similar to ?Category:A-Class Britney
Spears articles,? or ?Category:FA-Class Coca-Cola
articles.? None of these appears in the Wikipedia
website or the Wikipedia API10 as a subcategory
of ?Category:Software.? More study is required on
how they are formed.
5 Conclusion
This paper presents a domain-specific algorithm to
suggest equivalent courses based on analyzing their
semantic relatedness using Wikipedia. Both accu-
racy and correlation suggest our approach outper-
forms previous work. Future work includes com-
paring our approach with ESA, experimenting on
more courses from more universities, and adapting
our work to courses in other languages.
Acknowledgments
The authors thank Dr. Karen M. Daniels for review-
ing drafts of this paper. We also appreciate the in-
sightful suggestions from Dr. Saif Mohammad at the
early stage of our work. Last, but not least, we thank
the reviewers for their comments that guided im-
provement of the contents of this paper.
References
