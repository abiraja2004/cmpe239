Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational
Natural Language Learning, pp. 571?580, Prague, June 2007. c?2007 Association for Computational Linguistics
Cross-lingual Distributional Profiles of Concepts
for Measuring Semantic Distance
Saif Mohammad? Iryna Gurevych? Graeme Hirst? Torsten Zesch?
?Dept. of Computer Science
University of Toronto
Toronto, Canada
{smm,gh}@cs.toronto.edu
?Ubiquitous Knowledge Processing Group
Darmstadt University of Technology
Darmstadt, Germany
{gurevych,zesch}@tk.informatik.tu-darmstadt.de
Abstract
We present the idea of estimating seman-
tic distance in one, possibly resource-poor,
language using a knowledge source in an-
other, possibly resource-rich, language. We
do so by creating cross-lingual distributional
profiles of concepts, using a bilingual lexi-
con and a bootstrapping algorithm, but with-
out the use of any sense-annotated data or
word-aligned corpora. The cross-lingual
measures of semantic distance are evaluated
on two tasks: (1) estimating semantic dis-
tance between words and ranking the word
pairs according to semantic distance, and
(2) solving Reader?s Digest ?Word Power?
problems. In task (1), cross-lingual mea-
sures are superior to conventional monolin-
gual measures based on a wordnet. In task
(2), cross-lingual measures are able to solve
more problems correctly, and despite scores
being affected by many tied answers, their
overall performance is again better than the
best monolingual measures.
1 Introduction
Accurately estimating the semantic distance be-
tween concepts or between words in context has per-
vasive applications in computational linguistics, in-
cluding machine translation, information retrieval,
speech recognition, spelling correction, and text cat-
egorization (see Budanitsky and Hirst (2006) for dis-
cussion), and it is becoming clear that basing such
measures on a combination of corpus statistics with
a knowledge source, such as a dictionary, published
thesaurus, or WordNet, can result in higher accu-
racies (Mohammad and Hirst, 2006b). This is be-
cause such knowledge sources capture semantic in-
formation about concepts and, to some extent, world
knowledge. They also act as sense inventories for
the words in a language.
However, applying algorithms for semantic dis-
tance to most languages is hindered by the lack of
linguistic resources. In this paper, we propose a
new method that allows us to compute semantic dis-
tance in a possibly resource-poor language by seam-
lessly combining its text with a knowledge source
in a different, preferably resource-rich, language.
We demonstrate the approach by combining German
text with an English thesaurus to create English?
German distributional profiles of concepts, which in
turn will be used to measure the semantic distance
between German words.
Two classes of methods have been used in deter-
mining semantic distance. Semantic measures of
concept-distance, such as those of Jiang and Con-
rath (1997) and Resnik (1995), rely on the structure
of a knowledge source, such as WordNet, to deter-
mine the distance between two concepts defined in
it (see Budanitsky and Hirst (2006) for a survey).
Distributional measures of word-distance1, such
as cosine and ?-skew divergence (Lee, 2001), deem
1Many distributional approaches represent the sets of con-
texts of the target words as points in multidimensional co-
occurrence space or as co-occurrence distributions. A measure,
such as cosine, that captures vector distance or a measure, such
as ?-skew divergence, that captures distance between distribu-
tions is then used to measure distributional distance. We will
therefore refer to these measures as distributional measures.
571
two words to be closer or less distant if they occur in
similar contexts (see Mohammad and Hirst (2005)
for a comprehensive survey).
Distributional measures rely simply on raw text
and possibly some shallow syntactic processing.
They do not require any other manually-created re-
source, and tend to have a higher coverage. How-
ever, by themselves they perform poorly when com-
pared to semantic measures (Mohammad and Hirst,
2006b) because when given a target word pair
we usually need the distance between their closest
senses, but distributional measures of word-distance
tend to conflate the distances between all possible
sense pairs. Latent semantic analysis (LSA) (Lan-
dauer et al, 1998) has also been used to measure dis-
tributional distance with encouraging results (Rapp,
2003). However, it too measures the distance be-
tween words and not senses. Further, the dimen-
sionality reduction inherent to LSA has the effect of
making the predominant sense more dominant while
de-emphasizing the other senses. Therefore, an
LSA-based approach will also conflate information
from the different senses, and even more emphasis
will be placed on the predominant senses. Given the
semantically close target nouns play and actor, for
example, a distributional measure will give a score
that is some sort of a dominance-based average of
the distances between their senses. The noun play
has the predominant sense of ?children?s recreation?
(and not ?drama?), so a distributional measure will
tend to give the target pair a large (and thus erro-
neous) distance score. Also, distributional word-
distance approaches need to create large V ?V co-
occurrence and distance matrices, where V is the
size of the vocabulary (usually at least 100,000).2
Mohammad and Hirst (2006b) proposed a way
of combining written text with a published the-
saurus to measure distance between concepts (or
word senses) using distributional measures, thereby
eliminating sense-conflation and achieving results
better than the simple word-distance measures and
indeed also most of the WordNet-based semantic
measures. We called these measures distributional
measures of concept-distance. Concept-distance
2LSA is especially expensive as singular value decomposi-
tion, a key component for dimensionality reduction, requires
computationally intensive matrix operations; making it less
scalable to large amounts of text (Gorman and Curran, 2006).
measures can be used to measure distance between
a word pair by choosing the distance between their
closest senses. Thus, even though ?children?s recre-
ation? is the predominant sense of play, the ?drama?
sense is much closer to actor and so their dis-
tance will be chosen. These distributional concept-
distance approaches need to create only V ?C co-
occurrence and C?C distance matrices, where C is
the number of categories or senses (usually about
1000). It should also be noted that unlike the best
WordNet-based measures, distributional measures
(both word- and concept-distance ones) can be used
to estimate not just semantic similarity but also se-
mantic relatedness?useful in many tasks includ-
ing information retrieval. However, the high-quality
thesauri and (to a much greater extent) WordNet-like
resources that these methods require do not exist for
most of the 3000?6000 languages in existence today
and they are costly to create.
In this paper, we introduce cross-lingual distri-
butional measures of concept-distance, or simply
cross-lingual measures, that determine the distance
between a word pair belonging to a resource-poor
language using a knowledge source in a resource-
rich language and a bilingual lexicon3. We will use
the cross-lingual measures to calculate distances be-
tween German words using an English thesaurus and
a German corpus. Although German is not resource-
poor per se, Gurevych (2005) has observed that the
German wordnet GermaNet (Kunze, 2004) (about
60,000 synsets) is less developed than the English
WordNet (Fellbaum, 1998) (about 117,000 synsets)
with respect to the coverage of lexical items and lex-
ical semantic relations represented therein. On the
other hand, substantial raw corpora are available for
the German language. Crucially for our evaluation,
the existence of GermaNet alows comparison of our
cross-lingual approach with monolingual ones.
2 Monolingual Distributional Measures
In order to set the context for cross-lingual concept-
distance measures (Section 3), we first summarize
monolingual distributional approaches, with a focus
on distributional concept-distance measures.
3For most languages that have been the subject of academic
study, there exists at least a bilingual lexicon mapping the core
vocabulary of that language to a major world language and a
corpus of at least a modest size.
572
2.1 Word-distance
Words that occur in similar contexts tend to be se-
mantically close. In our experiments, we defined the
context of a target word, its co-occurring words, to
be ?5 words on either side (but not crossing sen-
tence boundaries). The set of contexts of a target
word is usually represented by the strengths of as-
sociation of the target with its co-occurring words,
which we refer to as the distributional profile (DP)
of the word. Here is a constructed example DP of
the word star:
DP of a word
star: space 0.28, movie 0.2, famous 0.13,
light 0.09, rich 0.04, . . .
Simple counts are made of how often the target word
co-occurs with other words in text and how often
the words occur individually. A suitable statistic,
such as pointwise mutual information (PMI), is then
applied to these counts to determine the strengths
of association between the target and co-occurring
words. The distributional profiles of two target
words represent their contexts as points in multi-
dimensional word-space. A suitable distributional
measure (for example, cosine) gives the distance be-
tween the two points, and thereby an estimate of the
semantic distance between the target words.
2.2 Concept-distance
In Mohammad and Hirst (2006b), we show how dis-
tributional profiles of concepts (DPCs) can be used
to measure semantic distance. Below are the DPCs
or DPs of two senses of the word star (the senses
or concepts themselves are glossed by a set of near-
synonymous words, placed in parentheses):
DPs of concepts
?celestial body? (celestial body,
sun, . . . ): space 0.36, light 0.27,
constellation 0.11, . . .
?celebrity? (celebrity, hero, . . . ):
famous 0.24, movie 0.14, rich 0.14, . . .
Thus the profiles of two target concepts represent
their contexts as points in multi-dimensional word-
space. A suitable distributional measure (for exam-
ple, cosine) can then be used to give the distribu-
tional distance between the two concepts in the same
way that distributional word-distance is measured.
But to calculate the strength of association of
a concept with co-occurring words, in order to
create DPCs, we must determine the number of
times a word used in that sense co-occurs with
surrounding words. In Mohammad and Hirst
(2006a), we proposed a way to determine these
counts without the use of sense-annotated data.
Briefly, a word?category co-occurrence matrix
(WCCM) is created having English word types
wen as one dimension and English thesaurus cat-
egories cen as another. We used the Macquarie
Thesaurus (Bernard, 1986) both as a very coarse-
grained sense inventory and a source of possibly
ambiguous English words that together unam-
biguously represent each category (concept). The
WCCM is populated with co-occurrence counts
from a large English corpus (we used the British
National Corpus (BNC)). A particular cell mi j,
corresponding to word weni and concept cenj , is
populated with the number of times weni co-occurs
(in a window of ?5 words) with any word that has
cenj as one of its senses (i.e., weni co-occurs with any
word listed under concept cenj in the thesaurus).
cen1 c
en
2 . . . c
en
j . . .
wen1 m11 m12 . . . m1 j . . .
wen2 m21 m22 . . . m2 j . . .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
weni mi1 mi2 . . . mi j . . .
.
.
.
.
.
.
.
.
. . . .
.
.
.
.
.
.
This matrix, created after a first pass of the cor-
pus, is the base word?category co-occurrence ma-
trix (base WCCM) and it captures strong associa-
tions between a sense and co-occurring words.4 This
is similar to how Yarowsky (1992) identifies words
that are indicative of a particular sense of the target.
We know that words that occur close to a target
word tend to be good indicators of its intended sense.
Therefore, we make a second pass of the corpus, us-
ing the base WCCM to roughly disambiguate the
words in it. For each word, the strength of associ-
ation of each of the words in its context (?5 words)
4From the base WCCM we can determine the number of
times a word w and concept c co-occur, the number of times
w co-occurs with any concept, and the number of times c co-
occurs with any word. A statistic such as PMI can then give the
strength of association between w and c.
573
with each of its senses is summed. The sense that
has the highest cumulative association is chosen as
the intended sense. A new bootstrapped WCCM
is created such that each cell mi j, corresponding to
word weni and concept cenj , is populated with the
number of times weni co-occurs with any word used
in sense cenj .
Mohammad and Hirst (2006a) used the DPCs cre-
ated from the bootstrapped WCCM to attain near-
upper-bound results in the task of determining word
sense dominance. Unlike the McCarthy et al (2004)
dominance system, our approach can be applied
to much smaller target texts (a few hundred sen-
tences) without the need for a large similarly-sense-
distributed text5. In Mohammad and Hirst (2006a),
the DPC-based monolingual distributional measures
of concept-distance were used to rank word pairs
by their semantic similarity and to correct real-
word spelling errors, attaining markedly better re-
sults than monolingual distributional measures of
word-distance. In the spelling correction task, the
distributional concept-distance measures performed
better than all WordNet-based measures as well, ex-
cept for the Jiang and Conrath (1997) measure.
3 Cross-lingual Distributional Measures
We now describe how distributional measures of
concept-distance can be used in a cross-lingual
framework to determine the distance between words
in (resource-poor) language L1 by combining its text
with a thesaurus in (resource-rich) language L2, us-
ing an L1?L2 bilingual lexicon. We will compare
this approach with the best monolingual approaches;
the smaller the loss in performance, the more ca-
pable the algorithm is of overcoming ambiguities
in word translation. An evaluation, therefore, re-
quires an L1 that in actuality has adequate knowl-
edge sources. Therefore we chose German to stand
in as the resource-poor language L1 and English as
the resource-rich L2; the monolingual evaluation in
German will use GermaNet. The remainder of the
paper describes our approach in terms of German
and English, but the algorithm itself is language in-
dependent.
5The McCarthy et al (2004) system needs to first gener-
ate a distributional thesaurus from the target text (if it is large
enough?a few million words) or from another large text with a
distribution of senses similar to the target text.
3.1 Concept-distance
Given a German word wde in context, we use a
German?English bilingual lexicon to determine its
different possible English translations. Each En-
glish translation wen may have one or more possi-
ble coarse senses, as listed in an English thesaurus.
These English thesaurus concepts (cen) will be re-
ferred to as cross-lingual candidate senses of the
German word wde.6 Figure 1 depicts examples.7
As in the monolingual distributional measures,
the distance between two concepts is calculated by
first determining their DPs. However, in the cross-
lingual approach, a concept is now glossed by near-
synonymous words in an English thesaurus, whereas
its profile is made up of the strengths of associ-
ation with co-occurring German words. Here are
constructed example cross-lingual DPs of the two
senses of star:
Cross-lingual DPs of concepts
?celestial body? (celestial body, sun,
. . . ): Raum 0.36, Licht 0.27,
Konstellation 0.11, . . .
?celebrity? (celebrity, hero, . . . ):
beru?hmt 0.24, Film 0.14, reich 0.14, . . .
In order to calculate the strength of association, we
must first determine individual word and concept
counts, as well as their co-occurrence counts.
3.2 Cross-lingual word?category
co-occurrence matrix
We create a cross-lingual word?category co-
occurrence matrix with German word types wde as
one dimension and English thesaurus concepts cen
6Some of the cross-lingual candidate senses of wde might
not really be senses of wde (e.g., ?celebrity?, ?river bank?, and
?judiciary? in Figure 1). However, as substantiated by experi-
ments in Section 4, our algorithm is able to handle the added
ambiguity.
7Vocabulary of German words needed to understand this dis-
cussion: Bank: 1. financial institution, 2. bench (furniture);
beru?hmt: famous; Film: movie (motion picture); Himmels-
ko?rper: heavenly body; Konstellation: constellation; Licht:
light; Morgensonne: morning sun; Raum: space; reich: rich;
Sonne: sun; Star: star (celebrity); Stern: star (celestial body)
574
}
star bank
river
bank
bench
furniture
judiciary
celestial body
celebrity
}
institution
financial }
Stern Bank wde
cen
wen
Figure 1: The cross-lingual candidate senses of Ger-
man words Stern and Bank.
as another.
cen1 c
en
2 . . . c
en
j . . .
wde1 m11 m12 . . . m1 j . . .
wde2 m21 m22 . . . m2 j . . .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
wdei mi1 mi2 . . . mi j . . .
.
.
.
.
.
.
.
.
. . . .
.
.
.
.
.
.
The matrix is populated with co-occurrence counts
from a large German corpus; we used the newspaper
corpus, taz8 (Sep 1986 to May 1999; 240 million
words). A particular cell mi j, corresponding to word
wdei and concept cenj , is populated with the number
of times the German word wdei co-occurs (in a win-
dow of ?5 words) with any German word having cenj
as one of its cross-lingual candidate senses. For ex-
ample, the Raum??celestial body? cell will have the
sum of the number of times Raum co-occurs with
Himmelsko?rper, Sonne, Morgensonne, Star, Stern,
and so on (see Figure 2). We used the Macquarie
Thesaurus (Bernard, 1986) (about 98,000 words)
for our experiments. The possible German trans-
lations of an English word were taken from the
German?English bilingual lexicon BEOLINGUS9
(about 265,000 entries).
This base word?category co-occurrence matrix
(base WCCM), created after a first pass of the cor-
pus captures strong associations between a category
(concept) and co-occurring words. For example,
even though we increment counts for both Raum?
?celestial body? and Raum??celebrity? for a particu-
lar instance where Raum co-occurs with Star, Raum
will co-occur with a number of words such as Him-
melsko?rper, Sonne, and Morgensonne that each have
the sense of celestial body in common (see Figure
2), whereas all their other senses are likely different
8http://www.taz.de
9http://dict.tu-chemnitz.de
... }
... }
}
sun
Sonne Morgensonne Star
celestial body
celestial body
Stern
star wen
wde
cen
Himmelsko?rper
Figure 2: Words having ?celestial body? as one of
their cross-lingual candidate senses.
and distributed across the set of concepts. There-
fore, the co-occurrence count of Raum and ?celestial
body? will be relatively higher than that of Raum and
?celebrity?.
As in the monolingual case, a second pass of
the corpus is made to disambiguate the (German)
words in it. For each word, the strength of associ-
ation of each of the words in its context (?5 words)
with each of its cross-lingual candidate senses is
summed. The sense that has the highest cumula-
tive association with co-occurring words is chosen
as the intended sense. A new bootstrapped WCCM
is created by populating each cell mi j, correspond-
ing to word wdei and concept cenj , with the number of
times the German word wdei co-occurs with any Ger-
man word used in cross-lingual sense cenj . A statistic
such as PMI is then applied to these counts to deter-
mine the strengths of association between a target
concept and co-occurring words, giving the distri-
butional profile of the concept.
Following the ideas described above, Mohammad
et al (2007) created Chinese?English DPCs from
Chinese text, a Chinese?English bilingual lexicon,
and an English thesaurus. They used these DPCs to
implement an unsupervised na??ve Bayes word sense
classifier that placed first among all unsupervised
systems taking part in the Multilingual Chinese?
English Lexical Sample Task (task #5) of SemEval-
07 (Jin et al, 2007).
4 Evaluation
We evaluated the newly proposed cross-lingual dis-
tributional measures of concept-distance on the tasks
of (1) measuring semantic distance between German
words and ranking German word pairs according to
semantic distance, and (2) solving German ?Word
Power? questions from Reader?s Digest. In order
to compare results with state-of-the-art monolingual
approaches we conducted experiments using Ger-
575
(Cross-lingual) Distributional Measures (Monolingual) GermaNet Measures
Information Content?based Lesk-like
?-skew divergence (Lee, 2001) (ASD) Jiang and Conrath (1997) (JC) hypernym pseudo-gloss (HPG)
cosine (Schu?tze and Pedersen, 1997) (Cos) Lin (1998b) (LinGN) radial pseudo-gloss (RPG)
Jensen-Shannon divergence (JSD) Resnik (1995) (Res)
Lin?s measure (1998a) (Lindist)
Table 1: Distance measures used in our experiments.
Dataset Year Language # pairs PoS Scores # subjects Correlation
Gur65 2005 German 65 N discrete {0,1,2,3,4} 24 .810
Gur350 2006 German 350 N, V, A discrete {0,1,2,3,4} 8 .690
Table 2: Comparison of datasets used for evaluating semantic distance in German.
maNet measures as well. The specific distributional
measures10 and GermaNet-based measures we used
are listed in Table 1. The GermaNet measures are
of two kinds: (1) information content measures,11
and (2) Lesk-like measures that rely on n-gram over-
laps in the glosses of the target senses, proposed by
Gurevych (2005)12.
The cross-lingual measures combined the German
newspaper corpus taz with the English Macquarie
Thesaurus using the German?English bilingual lex-
icon BEOLINGUS. Multi-word expressions in the
thesaurus and the bilingual lexicon were ignored.
We used a context of ?5 words on either side of the
target word for creating the base and bootstrapped
WCCMs. No syntactic pre-processing was done,
nor were the words stemmed, lemmatized, or part-
of-speech tagged.
4.1 Measuring distance in word pairs
4.1.1 Data
A direct approach to evaluate distance measures is
to compare them with human judgments. Gurevych
10JSD and ASD calculate the difference in distributions of
words that co-occur with the targets. Lindist (distributional
measure) and LinGN (GermaNet measure) follow from Lin?s
(1998b) information-theoretic definition of similarity.
11Information content measures rely on finding the lowest
common subsumer (lcs) of the target synsets in a hypernym hi-
erarchy and using corpus counts to determine how specific or
general this concept is. In general, the more specific the lcs is
and the smaller the difference of its specificity with that of the
target concepts, the closer the target concepts are.
12As GermaNet does not have glosses for synsets, Gurevych
(2005) proposed a way of creating a bag-of-words-type pseudo-
gloss for a synset by including the words in the synset and in
synsets close to it in the network.
(2005) and Zesch et al (2007) asked native German
speakers to mark two different sets of German word
pairs with distance values. Set 1 (Gur65) consists
of a German translation of the English Rubenstein
and Goodenough (1965) dataset. It has 65 noun?
noun word pairs. Set 2 (Gur350) is a larger dataset
containing 350 word pairs made up of nouns, verbs,
and adjectives. The semantically close word pairs
in Gur65 are mostly synonyms or hypernyms (hy-
ponyms) of each other, whereas those in Gur350
have both classical and non-classical relations (Mor-
ris and Hirst, 2004) with each other. Details of these
semantic distance benchmarks13 are summarized
in Table 2. Inter-subject correlations are indicative
of the degree of ease in annotating the datasets.
4.1.2 Results and Discussion
Word-pair distances determined using different
distance measures are compared in two ways with
the two human-created benchmarks. The rank order-
ing of the pairs from closest to most distant is evalu-
ated with Spearman?s rank order correlation ?; the
distance judgments themselves are evaluated with
Pearson?s correlation coefficient r. The higher the
correlation, the more accurate the measure is. Spear-
man?s correlation ignores actual distance values af-
ter a list is ranked?only the ranks of the two sets
of word pairs are compared to determine correla-
tion. On the other hand, Pearson?s coefficient takes
into account actual distance values. So even if two
lists are ranked the same, but one has distances be-
13The datasets are publicly available at:
http://www.ukp.tu-darmstadt.de/data/semRelDatasets
576
tween consecutively-ranked word-pairs more in line
with human-annotations of distance than the other,
then Pearson?s coefficient will capture this differ-
ence. However, this makes Pearson?s coefficient
sensitive to outlier data points, and so one must in-
terpret the Pearson correlations with caution.
Table 3 shows the results.14 Observe that on both
datasets and by both measures of correlation, cross-
lingual measures of concept-distance perform not
just as well as the best monolingual measures, but in
fact better. In general, the correlations are lower for
Gur350 as it contains cross-PoS word pairs and non-
classical relations, making it harder to judge even
by humans (as shown by the inter-annotator corre-
lations for the datasets in Table 2). Considering
Spearman?s rank correlation, ?-skew divergence and
Jensen-Shannon divergence perform best on both
datasets. The correlations of cosine and Lindist are
not far behind. Amongst the monolingual GermaNet
measures, radial pseudo-gloss performs best. Con-
sidering Pearson?s correlation, Lindist performs best
overall and radial pseudo-gloss does best amongst
the monolingual measures. Thus, we see that on
both datasets and as per both measures of correla-
tion, the cross-lingual measures perform not just as
well as the best monolingual measures, but indeed
slightly better.
4.2 Solving word choice problems from
Reader?s Digest
4.2.1 Data
Issues of the German edition of Reader?s Digest
include a word choice quiz called ?Word Power?.
Each question has one target word and four alter-
native words or phrases; the objective is to pick the
alternative that is most closely related to the target.
The correct answer may be a near-synonym of the
target or it may be related to the target by some other
classical or non-classical relation (usually the for-
mer). For example:15
Duplikat (duplicate)
a. Einzelstu?ck (single copy) b. Doppelkinn (double chin)
c. Nachbildung (replica) d. Zweitschrift (copy)
Our approach to evaluating distance measures fol-
14In Table 3, all values are statistically significant at the 0.01
level (2-tailed), except for the one in italic (0.212), which is
significant at the 0.05 level (2-tailed).
15English translations are in parentheses.
lows that of Jarmasz and Szpakowicz (2003), who
evaluated semantic similarity measures through their
ability to solve synonym problems (80 TOEFL (Lan-
dauer and Dumais, 1997), 50 ESL (Turney, 2001),
and 300 (English) Reader?s Digest Word Power
questions). Turney (2006) used a similar approach
to evaluate the identification of semantic relations,
with 374 college-level multiple-choice word anal-
ogy questions.
The Reader?s Digest Word Power (RDWP)
benchmark for German consists of 1072 of these
word-choice problems collected from the January
2001 to December 2005 issues of the German-
language edition (Wallace and Wallace, 2005). We
discarded 44 problems that had more than one cor-
rect answer, and 20 problems that used a phrase in-
stead of a single term as the target. The remaining
1008 problems form our evaluation dataset, which is
significantly larger than any of the previous datasets
employed in a similar evaluation.
We evaluate the various cross-lingual and mono-
lingual distance measures by their ability to choose
the correct answer. The distance between the target
and each of the alternatives is computed by a mea-
sure, and the alternative that is closest is chosen. If
two or more alternatives are equally close to the tar-
get, then the alternatives are said to be tied. If one
of the tied alternatives is the correct answer, then
the problem is counted as correctly solved, but the
corresponding score is reduced. We assign a score
of 0.5, 0.33, and 0.25 for 2, 3, and 4 tied alterna-
tives, respectively (in effect approximating the score
obtained by randomly guessing one of the tied al-
ternatives). If more than one alternative has a sense
in common with the target, then the thesaurus-based
cross-lingual measures will mark them each as the
closest sense. However, if one or more of these tied
alternatives is in the same semicolon group of the
thesaurus16 as the target, then only these are chosen
as the closest senses.
The German RDWP dataset contains many
phrases that cannot be found in the knowledge
sources (GermaNet or Macquarie Thesaurus via
translation list). In these cases, we remove stop-
16Words in a thesaurus category are further partitioned into
different paragraphs and each paragraph into semicolon groups.
Words within a semicolon group are more closely related than
those in semicolon groups of the same paragraph or category.
577
Gur65 Gur350
Measure ? r ? r
Monolingual
HPG 0.672 0.702 0.346 0.331
RPG 0.764 0.565 0.492 0.420
JC 0.665 0.748 0.417 0.410
LinGN 0.607 0.739 0.475 0.495
Res 0.623 0.722 0.454 0.466
Cross-lingual
ASD 0.794 0.597 0.520 0.413
Cos 0.778 0.569 0.500 0.212
JSD 0.793 0.633 0.522 0.422
Lindist 0.775 0.816 0.498 0.514
Table 3: Correlations of distance measures with hu-
man judgments.
words (prepositions, articles, etc.) and split the
phrase into component words. As German words
in a phrase can be highly inflected, we lemmatize
all components. For example, the target ?imagina?r?
(imaginary) has ?nur in der Vorstellung vorhanden?
(?exists only in the imagination?) as one of its alter-
natives. The phrase is split into its component words
nur, Vorstellung, and vorhanden. We compute se-
mantic distance between the target and each phrasal
component and select the minimum value as the dis-
tance between target and potential answer.
4.2.2 Results and Discussion
Table 4 presents the results obtained on the Ger-
man RDWP benchmark for both monolingual and
cross-lingual measures. Only those questions for
which the measures have some distance information
are attempted; the column ?Att.? shows the number
of questions attempted by each measure, which is
the maximum score that the measure can hope to
get. Observe that the thesaurus-based cross-lingual
measures have a much larger coverage than the
GermaNet-based monolingual measures. The cross-
lingual measures have a much larger number of cor-
rect answers too (column ?Cor.?), but this number is
bloated due to the large number of ties.17 ?Score?
is the score each measure gets after it is penalized
for the ties. The cross-lingual measures Cos, JSD,
and Lindist obtain the highest scores. But ?Score?
by itself does not present the complete picture ei-
17We see more ties when using the cross-lingual measures
because they rely on the Macquarie Thesaurus, a very coarse-
grained sense inventory (around 800 categories), whereas the
cross-lingual measures operate on the fine-grained GermaNet.
Reader?s Digest Word Power benchmark
Measure Att. Cor. Ties Score P R F
Monolingual
HPG 222 174 11 171.5 .77 .17 .28
RPG 266 188 15 184.7 .69 .18 .29
JC 357 157 1 156.0 .44 .16 .23
LinGN 298 153 1 152.5 .51 .15 .23
Res 299 154 33 148.3 .50 .15 .23
Cross-lingual
ASD 438 185 81 151.6 .35 .15 .21
Cos 438 276 90 223.1 .51 .22 .31
JSD 438 276 90 229.6 .52 .23 .32
Lindist 438 274 90 228.7 .52 .23 .32
Table 4: Performance of distance measures on word
choice problems. (Att.: Attempted, Cor.: Correct)
ther as, given the scoring scheme, a measure that at-
tempts more questions may get a higher score just
from random guessing. We therefore present pre-
cision, recall, and F-scores (P = Score/Att; R =
Score/1008; F = 2?P?R/(P + R)). Observe that
the cross-lingual measures have a higher coverage
(recall) than the monolingual measures but lower
precision. The F scores show that the best cross-
lingual measures do slightly better than the best
monolingual ones, despite the large number of ties.
The measures of Cos, JSD, and Lindist remain the
best cross-lingual measures, whereas HPG and RPG
are the best monolingual ones.
5 Conclusion
We have proposed a new method to determine se-
mantic distance in a possibly resource-poor lan-
guage by combining its text with a knowledge
source in a different, preferably resource-rich, lan-
guage. Specifically, we combined German text with
an English thesaurus to create cross-lingual distri-
butional profiles of concepts?the strengths of as-
sociation between English thesaurus senses (con-
cepts) of German words and co-occurring German
words?using a German?English bilingual lexicon
and a bootstrapping algorithm designed to overcome
ambiguities of word-senses and translations. No-
tably, we do so without the use of sense-annotated
text or word-aligned parallel corpora. We did not
parse or chunk the text, nor did we stem, lemmatize,
or part-of-speech-tag the words.
We used the cross-lingual DPCs to estimate se-
mantic distance by developing new cross-lingual
578
distributional measures of concept-distance. These
measures are like the distributional measures of
concept-distance (Mohammad and Hirst, 2006a,
2006b), except they can determine distance between
words in one language using a thesaurus in a differ-
ent language. We evaluated the cross-lingual mea-
sures against the best monolingual ones operating
on a WordNet-like resource, GermaNet, through an
extensive set of experiments on two different Ger-
man semantic distance benchmarks. In the process,
we compiled a large German benchmark of Reader?s
Digest word choice problems suitable for evaluating
semantic-relatedness measures. Most previous se-
mantic distance benchmarks are either much smaller
or cater primarily to semantic similarity measures.
Even with the added ambiguity of translating
words from one language to another, the cross-
lingual measures performed better than the best
monolingual measures on both the word-pair task
and the Reader?s Digest word-choice task. Fur-
ther, in the word-choice task, the cross-lingual mea-
sures achieved a significantly higher coverage than
the monolingual measure. The richness of En-
glish resources seems to have a major impact, even
though German, with GermaNet, a well-established
resource, is in a better position than most other lan-
guages. This is indeed promising, because achieving
broad coverage for resource-poor languages remains
an important goal as we integrate state-of-the-art ap-
proaches in natural language processing into real-
life applications. These results show that our algo-
rithm can successfully combine German text with an
English thesaurus using a bilingual German?English
lexicon to obtain state-of-the-art results in measur-
ing semantic distance.
These results also support the broader and far-
reaching claim that natural language problems in
a resource-poor language can be solved using a
knowledge source in a resource-rich language (e.g.,
Cucerzan and Yarowsky?s (2002) cross-lingual PoS
tagger). Our future work will explore other tasks
such as information retrieval and text categoriza-
tion. Cross-lingual DPCs also have tremendous po-
tential in tasks inherently involving more than one
language, such as machine translation and multi-
language multi-document summarization. We be-
lieve that the future of natural language process-
ing lies not in standalone monolingual systems but
in those that are powered by automatically created
multilingual networks of information.
Acknowledgments
We thank Philip Resnik, Michael Demko, Suzanne
Stevenson, Frank Rudicz, Afsaneh Fazly, and Afra
Alishahi for helpful discussions. This research is fi-
nancially supported by the Natural Sciences and En-
gineering Research Council of Canada, the Univer-
sity of Toronto, the German Research Foundation
under the grant ?Semantic Information Retrieval?
(SIR), GU 798/1-2.
References
J.R.L. Bernard, editor. 1986. The Macquarie Thesaurus.
Macquarie Library, Sydney, Australia.
Alexander Budanitsky and Graeme Hirst. 2006. Evalu-
ating WordNet-based measures of semantic distance.
Computational Linguistics, 32(1):13?47.
Silviu Cucerzan and David Yarowsky. 2002. Boot-
strapping a multilingual part-of-speech tagger in one
person-day. In Proceedings of the 6th Conference
on Computational Natural Language Learning, pages
132?138, Taipei, Taiwan.
Christiane Fellbaum. 1998. WordNet An Electronic Lex-
ical Database. MIT Press, Cambridge, MA.
James Gorman and James R. Curran. 2006. Scaling dis-
tributional similarity to large corpora. In Proceedings
of the 21st International Conference on Computational
Linguistics and the 44th annual meeting of the Associ-
ation for Computational Linguistics, pages 361?368,
Sydney, Australia.
Iryna Gurevych. 2005. Using the Structure of a Concep-
tual Network in Computing Semantic Relatedness. In
Proceedings of the 2nd International Joint Conference
on Natural Language Processing, pages 767?778, Jeju
Island, Republic of Korea.
Mario Jarmasz and Stan Szpakowicz. 2003. Roget?s
Thesaurus and semantic similarity. In Proceedings of
the International Conference on Recent Advances in
Natural Language Processing (RANLP-2003), pages
212?219.
Jay J. Jiang and David W. Conrath. 1997. Semantic
similarity based on corpus statistics and lexical tax-
onomy. In Proceedings of International Conference
on Research on Computational Linguistics (ROCLING
X), Taiwan.
579
Peng Jin, Yunfang Wu, and Shiwen Yu. 2007. SemEval-
2007 task 05: Multilingual Chinese-English lexical
sample task. In Proceedings of the Fourth Inter-
national Workshop on the Evaluation of Systems for
the Semantic Analysis of Text (SemEval-07), Prague,
Czech Republic.
Claudia Kunze, 2004. Lexikalisch-semantische Wort-
netze, chapter Computerlinguistik und Sprachtech-
nologie, pages 423?431. Spektrum Akademischer
Verlag.
Thomas K. Landauer and Susan T. Dumais. 1997. A so-
lution to Plato?s problem: The latent semantic analysis
theory of acquisition, induction, and representation of
knowledge. Psychological Review, 104:211?240.
Thomas K. Landauer, Peter W. Foltz, and Darrell Laham.
1998. Introduction to latent semantic analysis. Dis-
course Processes, 25(2?3):259?284.
Lillian Lee. 2001. On the effectiveness of the skew di-
vergence for statistical language analysis. In Artificial
Intelligence and Statistics 2001, pages 65?72.
Dekang Lin. 1998a. Automatic retreival and cluster-
ing of similar words. In Proceedings of the 17th In-
ternational Conference on Computational Linguistics
(COLING-98), pages 768?773, Montreal, Canada.
Dekang Lin. 1998b. An information-theoretic definition
of similarity. In Proceedings of the 15th International
Conference on Machine Learning, pages 296?304, San
Francisco, CA. Morgan Kaufmann.
Diana McCarthy, Rob Koeling, Julie Weeds, and John
Carroll. 2004. Finding predominant senses in un-
tagged text. In Proceedings of the 42nd Annual Meet-
ing of the Association for Computational Linguistics
(ACL-04), pages 280?267, Barcelona, Spain.
Saif Mohammad and Graeme Hirst. 2005.
Distributional measures as proxies for
semantic relatedness. In submission,
http://www.cs.toronto.edu/compling/Publications.
Saif Mohammad and Graeme Hirst. 2006a. Determining
word sense dominance using a thesaurus. In Proceed-
ings of the 11th Conference of the European Chap-
ter of the Association for Computational Linguistics
(EACL), Trento, Italy.
Saif Mohammad and Graeme Hirst. 2006b. Distribu-
tional measures of concept-distance: A task-oriented
evaluation. In Proceedings of the Conference on
Empirical Methods in Natural Language Processing
(EMNLP-2006), Sydney, Australia.
Saif Mohammad, Graeme Hirst, and Philip Resnik. 2007.
Distributional profiles of concepts for unsupervised
word sense disambigution. In Proceedings of the
Fourth International Workshop on the Evaluation of
Systems for the Semantic Analysis of Text (SemEval-
07), Prague, Czech Republic.
Jane Morris and Graeme Hirst. 2004. Non-classical lex-
ical semantic relations. In Proceedings of the Work-
shop on Computational Lexical Semantics, Human
Language Technology Conference of the North Ameri-
can Chapter of the Association for Computational Lin-
guistics, Boston, Massachusetts.
Reinhard Rapp. 2003. Word sense discovery based on
sense descriptor dissimilarity. In Proceedings of the
Machine Translation Summit IX, pages 315?322, New
Orleans, Louisiana.
Philip Resnik. 1995. Using information content to evalu-
ate semantic similarity. In Proceedings of the 14th In-
ternational Joint Conference on Artificial Intelligence
(IJCAI-95), pages 448?453, Montreal, Canada.
Herbert Rubenstein and John B. Goodenough. 1965.
Contextual Correlates of Synonymy. Communications
of the ACM, 8(10):627?633.
Hinrich Schu?tze and Jan O. Pedersen. 1997. A
cooccurrence-based thesaurus and two applications to
information retreival. Information Processing and
Management, 33(3):307?318.
Peter Turney. 2001. Mining the Web for synonyms:
PMI-IR versus LSA on TOEFL. In Proceedings of the
Twelfth European Conference on Machine Learning
(ECML-2001), pages 491?502, Freiburg, Germany.
Peter Turney. 2006. Expressing implicit semantic rela-
tions without supervision. In Proceedings of the 21st
International Conference on Computational Linguis-
tics and the 44th annual meeting of the ACL, pages
313?320, Sydney, Australia.
DeWitt Wallace and Lila Acheson Wallace. 2005.
Reader?s Digest, das Beste fu?r Deutschland. Jan
2001?Dec 2005. Verlag Das Beste, Stuttgart.
David Yarowsky. 1992. Word-sense disambiguation us-
ing statistical models of Roget?s categories trained on
large corpora. In Proceedings of the 14th International
Conference on Computational Linguistics (COLING-
92), pages 454?460, Nantes, France.
Torsten Zesch, Iryna Gurevych, and Max Mu?hlha?user.
2007. Comparing Wikipedia and German WordNet by
evaluating semantic relatedness on multiple datasets.
In Proceedings of Human Language Technologies:
The Annual Conference of the North American Chap-
ter of the Association for Computational Linguistics
(NAACL HLT 2007), pages 205?208, Rochester, New
York.
580
