Proceedings of the 22nd International Conference on Computational Linguistics (Coling 2008), pages 737?744
Manchester, August 2008
Translating Queries into Snippets for Improved Query Expansion
Stefan Riezler and Yi Liu and Alexander Vasserman
Google Inc.
1600 Amphitheatre Parkway
Mountain View, CA 94043
{riezler,yliu,avasserm}@google.com
Abstract
User logs of search engines have recently
been applied successfully to improve var-
ious aspects of web search quality. In this
paper, we will apply pairs of user queries
and snippets of clicked results to train a
machine translation model to bridge the
?lexical gap? between query and document
space. We show that the combination of
a query-to-snippet translation model with
a large n-gram language model trained
on queries achieves improved contextual
query expansion compared to a system
based on term correlations.
1 Introduction
In recent years, user logs of search engines have at-
tracted considerable attention in research on query
clustering, query suggestions, query expansion, or
general web search. Besides the sheer size of these
data sets, the main attraction of user logs lies in
the possibility to capitalize on users? input, either
in form of user-generated query reformulations, or
in form of user clicks on presented search results.
However noisy, sparse, incomplete, and volatile
these data may be, recent research has presented
impressive results that are based on simply taking
the majority vote of user clicks as a signal for the
relevance of results.
In this paper we will apply user logs to the prob-
lem of the ?word mismatch? or ?lexical chasm?
(Berger et al, 2000) between user queries and
documents. The standard solution to this prob-
lem, query expansion, attempts to overcome this
c
? 2008. Licensed under the Creative Commons
Attribution-Noncommercial-Share Alike 3.0 Unported li-
cense (http://creativecommons.org/licenses/by-nc-sa/3.0/).
Some rights reserved.
mismatch in query and document vocabularies by
adding terms with similar statistical properties to
those in the original query. This will increase the
chances of matching words in relevant documents
and also decrease the ambiguity of the overall
query that is inherent to natural language. A suc-
cessful approach to this problem is local feed-
back, or pseudo-relevance feedback (Xu and Croft,
1996), where expansion terms are extracted from
the top-most documents that were retrieved in an
initial retrieval round. Because of irrelevant results
in the initial retrieval, caused by ambiguous terms
or retrieval errors, this technique may cause expan-
sion by unrelated terms, leading to query drift. Fur-
thermore, the requirement of two retrieval steps is
computationally expensive.
Several approaches have been presented that de-
ploy user query logs to remedy these problems.
One set of approaches focuses on user reformu-
lations of queries that differ only in one segment
(Jones et al, 2006; Fonseca et al, 2005; Huang
et al, 2003). Such segments are then identified
as candidate expansion terms, and filtered by var-
ious signals such as cooccurrence in similar ses-
sions or log-likelihood ratio of original and ex-
pansion phrases. Other approaches focus on the
relation of queries and retrieval results, either by
deploying the graph induced by queries and user
clicks in calculating query similarity (Beeferman
and Berger, 2000; Wen et al, 2002; Baeza-Yates
and Tiberi, 2007), or by leveraging top results from
past queries to provide greater context in find-
ing related queries (Raghavan and Sever, 1995;
Fitzpatrick and Dent, 1997; Sahami and Heilman,
2006). Cui et al (2002) present an all together dif-
ferent way to deploy user clickthrough data by ex-
tracting expansion terms directly from clicked re-
sults. They claim significant improvements over
737
the local feedback technique of Xu and Croft
(1996).
Cui et al?s (2002) work is the closest to ours.
We follow their approach in extracting expansion
terms directly from clicked results, however, with a
focus on high precision of query expansion. While
expansion from the domain of document terms has
the advantage that expansion terms are guaranteed
to be in the search domain, expansion precision
may suffer from the noisy and indirect ?approval?
of retrieval results by user clicks. Thus expansion
terms from the document domain are more likely
to be generalizations, specifications, or otherwise
related terms, than terms extracted from query sub-
stitutions that resemble synonyms more closely.
Furthermore, if the model that learns to correlate
document terms to query terms is required to ig-
nore context in order to generalize, finding appro-
priate expansions for ambiguous query terms is
difficult.
Our approach is to look at the ?word mismatch?
problem as a problem of translating from a source
language of queries into a target language of docu-
ments, represented as snippets. Since both queries
and snippets are arguably natural language, sta-
tistical machine translation technology (SMT) is
readily applicable to this task. In previous work,
this has been done successfully for question an-
swering tasks (Riezler et al, 2007; Soricut and
Brill, 2006; Echihabi and Marcu, 2003; Berger et
al., 2000), but not for web search in general. Cui et
al.?s (2002) model is to our knowledge the first to
deploy query-document relations for direct extrac-
tion of expansion terms for general web retrieval.
Our SMT approach has two main advantages over
Cui et al?s model: Firstly, Cui et al?s model re-
lates document terms to query terms by using sim-
ple term frequency counts in session data, with-
out considering smoothing techniques. Our ap-
proach deploys a sophisticated machine learning
approach to word alignment, including smooth-
ing techniques, to map query phrases to snippet
phrases. Secondly, Cui et al?s model only indi-
rectly uses context information to disambiguate
expansion terms. This is done by calculating the
relationship of an expansion term to the whole
query by multiplying its contributions to all query
terms. In our SMT approach, contextual disam-
biguation is done by deploying an n-gram lan-
guage model trained on queries to decide about the
appropriateness of an expansion term in the con-
text of the rest of the query terms. As shown in
an experimental evaluation, together the orthogo-
nal information sources of a translation model and
a language model provide significantly better con-
textual query expansion than Cui et al?s (2002)
correlation-based approach.
In the following, we recapitulate the essentials
of Cui et al?s (2002) model, and contrast it with
our SMT-based query expansion system. Further-
more, we will present a detailed comparison of the
two systems on a real-world query expansion task.
2 Query-Document Term Correlations
The query expansion model of Cui et al (2002)
is based on the principle that if queries containing
one term often lead to the selection of documents
containing another term, then a strong relationship
between the two terms is assumed. Query terms
and document terms are linked via clicked docu-
ments in user sessions. Formally, Cui et al (2002)
compute the following probability distribution of
document words w
d
given query words w
q
from
counts over clicked documents D:
P (w
d
|w
q
) =
?
D
P (w
d
|D)P (D|w
q
) (1)
The first term in the righthandside of equation 1 is
a normalized tfidf weight of the the document term
in the clicked document, and the second term is the
relative cooccurrence of document and query term
in sessions.
Since equation 1 calculates expansion probabil-
ities for each term separately, Cui et al (2002)
introduce the following cohesion formula that re-
spects the whole query Q by aggregating the ex-
pansion probabilities for each query term:
CoWeight
Q
(w
d
) = ln(
?
w
q
?Q
P (w
d
|w
q
) + 1) (2)
In contrast to local feedback techniques (Xu
and Croft, 1996), Cui et al?s algorithm allows to
precompute term correlations offline by collecting
counts from query logs. This reliance on pure fre-
quency counting is both a blessing and a curse: On
the one hand it allows for efficient non-iterative es-
timation, on the other hand it makes the implicit
assumption that data sparsity will be overcome by
counting from huge datasets. The only attempt at
smoothing that is made in this approach is a recur-
rence to words in query context, using equation 2,
when equation 1 assigns zero probability to unseen
pairs.
738
3 Query-Snippet Translation
The SMT system deployed in our approach is
an implementation of the alignment template ap-
proach of Och and Ney (Och and Ney, 2004). The
basic features of the model consist of a translation
model and a language model which go back to the
noisy channel formulation of machine translation
in Brown et al (1993). Their ?fundamental equa-
tion of machine translation? defines the job of a
translation system as finding the English string
?
e
that is a translation of a foreign string f such that
?
e = argmax
e
P (e|f)
= argmax
e
P (f |e)P (e) (3)
Equation 3 allows for a separation of a language
model P (e), and a translation model P (f |e). Och
and Ney (2004) reformulate equation 3 as a lin-
ear combination of feature functions h
m
(e, f) and
weights ?
m
, including feature functions for trans-
lation models h
i
(e, f) = P (f |e) and language
models h
j
(e) = P (e):
?
e = argmax
e
M
?
m=1
?
m
h
m
(e, f) (4)
The translation model used in our approach is
based on the sequence of alignment models de-
scribed in Och and Ney (2003). The relationship of
translation model and alignment model for source
language string f = f
J
1
and target string e = e
I
1
is via a hidden variable describing an alignment
mapping from source position j to target position
a
j
:
P (f
J
1
|e
I
1
) =
?
a
J
1
P (f
J
1
, a
J
1
|e
I
1
) (5)
The alignment a
J
1
contains so-called null-word
alignments a
j
= 0 that align source words to the
empty word. The different alignment models de-
scribed in Och and Ney (2003) each parameter-
ize equation 5 differently so as to capture differ-
ent properties of source and target mappings. All
models are based on estimating parameters ? by
maximizing the likelihood of training data con-
sisting of sentence-aligned, but not word-aligned
strings {(f
s
, e
s
) : s = 1, . . . , S}. Since each sen-
tence pair is linked by a hidden alignment variable
a = a
J
1
, the optimal
?
? is found using unlabeled-
data log-likelihood estimation techniques such as
the EM algorithm (Dempster et al, 1977):
?
? = argmax
?
S
?
s=1
?
a
p
?
(f
s
,a|e
s
) (6)
The final translation model is calculated from rel-
ative frequencies of phrases, i.e. consecutive se-
quences of words occurring in text. Phrases are
extracted via various heuristics as larger blocks of
aligned words from best word alignments, as de-
scribed in Och and Ney (2004).
Language modeling in our approach deploys an
n-gram language model that assigns the following
probability to a string w
L
1
of words (see Brants et
al. (2007)):
P (w
L
1
) =
L
?
i=1
P (w
i
|w
i?1
1
) (7)
?
L
?
i=1
P (w
i
|w
i?1
i?n+1
) (8)
Estimation of n-gram probabilities is done by
counting relative frequencies of n-grams in a cor-
pus of user queries. Remedies against sparse data
problems are achieved by various smoothing tech-
niques, as described in Brants et al (2007).
For applications of the system to translate un-
seen queries, a standard dynamic-programming
beam-search decoder (Och and Ney, 2004) that
tightly integrates translation model and language
model is used. Expansion terms are taken from
those terms in the 5-best translations of the query
that have not been seen in the original query string.
In our opinion, the advantages of using an
alignment-based translation model to correlate
document terms with query terms, instead of rely-
ing on a term frequency counts as in equation 1, are
as follows. The formalization of translation mod-
els as involving a hidden alignment variable allows
us to induce a probability distribution that assigns
some probability of being translated into a target
word to every source word. This is a crucial step
towards solving the problem of the ?lexical gap?
described above. Furthermore, various additional
smoothing techniques are employed in alignment
to avoid overfitting and improved coping with rare
words (see Och and Ney (2003)). Lastly, estima-
tion of hidden-variable models can be based on
the well-defined framework of statistical estima-
tion via the EM algorithm.
Similar arguments hold for the language model:
N-gram language modeling is a well-understood
739
sentence source target
pairs words words
tokens 3 billion 8 billion 25 billion
avg. length - 2.6 8.3
Table 1: Statistics of query-snippet training data
for translation model.
problem, with a host of well-proven smoothing
techniques to avoid data sparsity problems (see
Brants et al (2007).)
In combination, translation model and language
model provide orthogonal sources of information
to the overall translation quality. While the trans-
lation model induces a smooth probability distri-
bution that relates source to target words, the lan-
guage model deploys probabilities of target lan-
guage strings to assess the adequacy of a target
word as a translation in context. Reliance on or-
dering information of the words in the context of a
source word is a huge advantage over the bag-of-
words aggregation of context information in Cui et
al?s (2002) model. Furthermore, in the SMT model
used in our approach, translation model and lan-
guage model are efficiently integrated in a beam-
search decoder.
In our application of SMT to query expansion,
queries are considered as source language sen-
tences and snippets of clicked result documents
as target sentences. A parallel corpus of sentence-
aligned data is created by pairing each query with
each snippet of its clicked results. Further adjust-
ments to system parameters were applied in or-
der to adapt the training procedure to this special
data set. For example, in order to account for the
difference in sentence length between queries and
snippets, we set the null-word probability to 0.9.
This allows us to improve precision of alignment
of noisy data by concentrating the alignment to a
small number of key words. Furthermore, extrac-
tion of phrases in our approach is restricted to the
intersection of alignments from both translation di-
rections, thus favoring precision over recall also in
phrase extraction. The only major adjustment of
the language model to the special case of query-
snippet translation is the fact that we train our n-
gram model on queries taken from user logs, in-
stead of on standard English text.
1-grams 2-grams 3-grams
9 million 1.5 billion 5 billion
Table 2: Statistics of unique query n-grams in lan-
guage model.
items disagreements
w/ agreement included
# items 102 125
mean item score 0.333 0.279
95% conf. int. [0.216, 0.451] [0.176, 0.381]
Table 3: Comparison of SMT-based expan-
sion with correlation-based expansion on 7-point
Likert-type scale.
4 Experimental Evaluation
4.1 Data
The training data for the translation model and
the correlation-based model consist of pairs of
queries and snippets for clicked results taken from
anonymized query logs. Using snippets instead of
full documents makes iterative training feasible
and also reduces noise considerably. This parallel
corpus of query-snippet pairs is fed into a standard
SMT training pipeline (modulo the adjustments to
word and phrase alignment discussed above). The
parallel corpus consists of 3 billion query-snippet
pairs that are input to training of word and phrase
alignment models. The resulting phrase translation
table that builds the basis of the translation model
consists 700 million query-snippet phrase transla-
tions. A collection of data statistics for the training
data is shown in table 1.
The language model used in our experiment is a
trigram language model trained on English queries
in user logs. N-grams were cut off at a minimum
frequency of 4. Data statistics for resulting unique
n-grams are shown in table 2.
4.2 Experimental Comparison
Our experimental setup for query expansion de-
ploys a real-world search engine, google.com, for
a comparison of expansions from the SMT-based
system and the correlation-based system. The ex-
perimental evaluation was done as direct compari-
son of search results for queries where both exper-
imental systems suggested expansion terms. Since
expansions from both experimental systems are
done on top of the same underlying search engine,
this allows us to abstract away from interactions
with the underlying system. The queries used for
evaluation were extracted randomly from 3+ word
740
query SMT-based expansions corr-based expansions score
applying U.S. passport passport - visa applying - home -1.0
configure debian to use dhcp debian - linux configure - configuring -1.0
configure - install
how many episodes of 30 rock? episodes - season how many episodes - tv -0.83
episodes - series many episodes - wikipedia
lampasas county sheriff department department - office department - home -0.83
sheriff - office
weakerthans cat virtue chords chords - guitar cat - tabs -0.83
chords - lyrics chords - tabs
chords - tab
Henry VIII Menu Portland, Maine menu - restaurant portland - six 1.3
menu - restaurants menu - england
ladybug birthday parties parties - ideas ladybug - kids 1.3
parties - party
political cartoon calvin coolidge cartoon - cartoons political cartoon - encyclopedia 1.3
top ten dining, vancouver dining - restaurants dining vancouver - 10 1.3
international communication communication - communications international communication - college 1.3
in veterinary medicine communication - skills
Table 4: SMT-based versus correlation-based expansions with mean item score.
queries in user logs in order to allow the systems
to deploy context information for expansion.
In order to evaluate Cui et al?s (2002)
correlation-based system in this setup, we required
the system to assign expansion terms to particu-
lar query terms. This could be achieved by using
a linear interpolation of scores in equation 2 and
equation 1. Equation 1 thus introduces a prefer-
ence for a particular query term to the whole-query
score calculated by equation 2. Our reimplementa-
tion uses unigram and bigram phrases in queries
and expansions. Furthermore, we use Okapi BM25
instead of tfidf in the calculation of equation 1 (see
Robertson et al (1998)).
Query expansion for the SMT-based system is
done by extracting terms introduced in the 5-best
list of query translations as expansion terms for the
respective query terms.
The evaluation was performed by three in-
dependent raters. The raters were given task-
specific rating guidelines, and were shown queries
and 10-best search results from both systems,
anonymized, and presented randomly on left or
right sides. The raters? task was to evaluate the re-
sults on a 7-point Likert-type
1
scale, defined as:
-1.5: much worse
-1.0: worse
-0.5: slightly worse
1
Likert?s (1932) original rating system is a 5-point scale
using integer scores 1 through 5. Our system uses average
scores over three raters for each item, and uses a 7-point in-
stead of a 5-point scale. See Dawes (2008) on the compara-
bility of 5-, 7-, or 10-point scales.
0: about the same
0.5: slightly better
1.0: better
1.5: much better
Results on 125 queries where both systems sug-
gested expansion terms are shown in table 3. For
each query, rating scores are averaged over the
scores assigned by three raters. The overall mean
item score for a comparison of SMT-based ex-
pansion against correlation-based expansion was
0.333 for 102 items with rater agreement, and
0.279 for 125 items including rater disagreements.
All result differences are statistically significant.
Examples for SMT-based and correlation-based
expansions are given in table 4. The first five ex-
amples are losses for the SMT-based system. In
the first example, passport is replaced by the re-
lated, but not synonymous term visa in the SMT-
based expansion. The second example is a loss for
SMT-based expansion because of a replacement of
the specific term debian by the more general term
linux. The correlation-based expansions tv 30 rock
in the third example, lampasas county sheriff home
in the fourth example, and weakerthans tabs in the
fifth example directly hit the title of relevant web
pages, while the SMT-based expansion terms do
not improve retrieval results. However, even from
these negative examples it becomes apparent that
the SMT-based expansion terms are clearly related
to the query terms, and for a majority cases this
has a positive effect. Such examples are shown in
741
(herbs , herbs) ( for , for) ( chronic , chronic) ( constipation , constipation)
(herbs , herb) ( for , for) ( chronic , chronic) ( constipation , constipation)
(herbs , remedies) ( for , for) ( chronic , chronic) ( constipation , constipation)
(herbs , medicine) ( for , for) ( chronic , chronic) ( constipation , constipation)
(herbs , supplements) ( for , for) ( chronic , chronic) ( constipation , constipation)
(herbs , herbs) ( for , for) ( mexican , mexican) ( cooking , cooking)
(herbs , herbs) ( for , for) ( cooking , cooking) ( mexican , mexican)
(herbs , herbs) ( for , for) ( mexican , mexican) ( cooking , food)
(mexican , mexican) ( herbs , herbs) ( for , for) ( cooking , cooking)
(herbs , spices) ( for , for) ( mexican , mexican) ( cooking , cooking)
Table 5: Unique 5-best phrase-level translations of queries herbs for chronic constipation and herbs for
mexican cooking.
query terms n-best expansions
herbs com treatment encyclopedia
chronic interpret treating com
constipation interpret treating com
herbs for medicinal support women
for chronic com gold encyclopedia
chronic constipation interpret treating
herbs cooks recipes com
mexican recipes com cooks
cooking cooks recipes com
herbs for medicinal women support
for mexican cooks com allrecipes
Table 6: Correlation-based expansions for queries herbs for chronic constipation and herbs for mexican
cooking.
the second set of expansions. SMT-based expan-
sions such as henry viii restaurant portland, maine,
or ladybug birthday ideas, or top ten restaurants,
vancouver achieve a change in retrieval results that
does not result in a query drift, but rather in im-
proved retrieval results. In contrast, the terms in-
troduced by the correlation-based system are either
only vaguely related or noise.
5 Discussion
We attribute the experimental result of a signif-
icant preference for SMT-based expansions over
correlation-based expansions to the fruitful com-
bination of translation model and language model
provided by the SMT system. The SMT approach
can be viewed as a combined system that proposes
candidate expansion via the translation model, and
filters them by the language model. Thus we may
find a certain amount of non-sensical expansion
candidates at the phrase translation level. This can
be seen from inspecting table 7 which shows the
most probable phrase translations that are applica-
ble to the queries herbs for chronic constipation
and herbs for mexican cooking. The phrase table
includes identity translations and closely related
terms as most probable translations for nearly ev-
ery phrase, however, it also clearly includes noisy
and non-related terms. More importantly, an ex-
traction of expansion terms from the phrase table
alone would not allow to choose the appropriate
term for the given query context. This can be at-
tained by combining the phrase translations with a
language model: As shown in table 5, the 5-best
translations of the full queries attain a proper dis-
ambiguation of the senses of herbs by replacing
the term by remedies, medicine, and supplements
for the first query, and with spices for the second
query. Expansion terms highlighted in bold face.
The fact that the most probable translation for
the whole query mostly is the identity translation
can be seen as a feature, not as a bug, of the SMT-
based approach: By the option to prefer identity
translations or word reorderings over translations
of source words, the SMT model effectively can
choose not to generate any expansion terms. This
will happen if none of the candidate phrase trans-
lations fit with high enough probability into the
context of the whole query, as assessed by the lan-
guage model.
In contrast to the SMT model, the correlation-
based model cannot fall back onto the ordering in-
formation of the language model, but aggregates
information for the whole query from a bag-of-
words of query terms. Table 6 shows the top three
742
correlation-based expansion terms assigned to uni-
grams and bigrams in the queries herbs for chronic
constipation and herbs for mexican cooking. Ex-
pansion terms are chosen by overall highest weight
and shown in bold face. Relevant expansion terms
such as treatment or recipes that would disam-
biguate the meaning of herbs are in fact proposed
by the correlation-based model, however, the cohe-
sion score also promotes terms such as interpret or
com as best whole-query expansions, thus leading
to query drift.
6 Conclusion
We presented an approach to contextual query ex-
pansion that deploys natural language technology
in form of statistical machine translation. The key
idea of our approach is to consider the problem
of the ?lexical gap? between queries and docu-
ments from a linguistic point of view, and at-
tempt to bridge this gap by translating from the
query language into the document language. Us-
ing search engine user logs, we could extract large
amounts of parallel data of queries and snippets
from clicked documents. These data were used to
train an alignment-based translation model, and
an n-gram based language model. The same data
were used to train a reimplementation of Cui
et al?s (2002) term-correlation based query ex-
pansion system. An experimental comparison of
the two systems showed a considerable prefer-
ence for SMT-based expansions over correlation-
based expansion. Our explanation for this result
is the fruitful combination of the orthogonal in-
formation sources from translation model and lan-
guage model. While in the SMT approach expan-
sion candidates proposed by the translation model
are effectively filtered by ordering information
on the query context from the language model,
the correlation-based approach resorts to an in-
ferior bag-of-word aggregation of scores for the
whole query. Furthermore, each component of the
SMT model takes great care to avoid sparse data
problems by various sophisticated smoothing tech-
niques. In contrast, the correlation-based model re-
lies on pure counts of term frequencies.
An interesting task for future work is to dis-
sect the contributions of translation model and
language model, for example, by combining a
correlation-based system with a language model
filter. The challenge here is a proper integration of
n-gram lookup into correlation-based expansion.
References
Baeza-Yates, Ricardo and Alessandro Tiberi. 2007.
Extracting semantic relations from query logs. In
Proceedings of the 13th ACM SIGKDD Confer-
ence on Knowledge Discovery and Data Mining
(KDD?07), San Jose, CA.
Beeferman, Doug and Adam Berger. 2000. Agglom-
erative clustering of a search engine query log. In
Proceedings of the 6th ACM SIGKDD International
Conference on Knowledge Discovery and Data Min-
ing (KDD?00), Boston, MA.
Berger, Adam L., Rich Caruana, David Cohn, Dayne
Freitag, and Vibhu Mittal. 2000. Bridging the lexi-
cal chasm: Statistical approaches to answer-finding.
In Proceedings of SIGIR?00, Athens, Greece.
Brants, Thorsten, Ashok C. Popat, Peng Xu, Franz J.
Och, and Jeffrey Dean. 2007. Large language mod-
els in machine translation. In Proceedings of the
Conference on Empirical Methods in Natural Lan-
guage Processing (EMNLP?07), Prague, Czech Re-
public.
Brown, Peter F., Stephen A. Della Pietra, Vincent
J. Della Pietra, and Robert L. Mercer. 1993.
The mathematics of statistical machine translation:
Parameter estimation. Computational Linguistics,
19(2):263?311.
Cui, Hang, Ji-Rong Wen, Jian-Yun Nie, and Wei-Ying
Ma. 2002. Probabilistic query expansion using
query logs. In Proceedings of WWW 2002, Hon-
olulu, Hawaii.
Dawes, John. 2008. Do data characteristics change ac-
cording to the number of scale points used? An ex-
periment using 5-point, 7-point and 10-point scales.
International Journal of Market Research, 50(1):61?
77.
Dempster, A. P., N. M. Laird, and D. B. Rubin. 1977.
Maximum Likelihood from Incomplete Data via the
EM Algorithm. Journal of the Royal Statistical So-
ciety, 39(B):1?38.
Echihabi, Abdessamad and Daniel Marcu. 2003. A
noisy-channel approach to question answering. In
Proceedings of the 41st Annual Meeting of the As-
sociation for Computational Linguistics (ACL?03),
Sapporo, Japan.
Fitzpatrick, Larry and Mei Dent. 1997. Automatic
feedback using past queries: Social searching? In
Proceedings of SIGIR?97, Philadelphia, PA.
Fonseca, Bruno M., Paulo Golgher, Bruno Possas,
Berthier Ribeiro-Neto, and Nivio Ziviani. 2005.
Concept-based interactive query expansion. In Pro-
ceedings of the 14th Conference on Information and
Knowledge Management (CIKM?05), Bremen, Ger-
many.
743
Huang, Chien-Kang, Lee-Feng Chien, and Yen-Jen
Oyang. 2003. Relevant term suggestion in interac-
tive web search based on contextual information in
query session logs. Journal of the American Society
for Information Science and Technology, 54(7):638?
649.
Jones, Rosie, Benjamin Rey, Omid Madani, and Wi-
ley Greiner. 2006. Generating query substitutions.
In Proceedings of the 15th International World Wide
Web conference (WWW?06), Edinburgh, Scotland.
Likert, Rensis. 1932. A technique for the measurement
of attitudes. Archives of Psychology, 140:5?55.
Och, Franz Josef and Hermann Ney. 2003. A system-
atic comparison of various statistical alignment mod-
els. Computational Linguistics, 29(1):19?51.
Och, Franz Josef and Hermann Ney. 2004. The align-
ment template approach to statistical machine trans-
lation. Computational Linguistics, 30(4):417?449.
Raghavan, Vijay V. and Hayri Sever. 1995. On the
reuse of past optimal queries. In Proceedings of SI-
GIR?95, Seattle, WA.
Riezler, Stefan, Alexander Vasserman, Ioannis
Tsochantaridis, Vibhu Mittal, and Yi Liu. 2007.
Statistical machine translation for query expansion
in answer retrieval. In Proceedings of the 45th An-
nual Meeting of the Association for Computational
Linguistics (ACL?07), Prague, Czech Republic.
Robertson, Stephen E., Steve Walker, and Micheline
Hancock-Beaulieu. 1998. Okapi at TREC-7. In
Proceedings of the Seventh Text REtrieval Confer-
ence (TREC-7), Gaithersburg, MD.
Sahami, Mehran and Timothy D. Heilman. 2006. A
web-based kernel function for measuring the sim-
ilarity of short text snippets. In Proceedings of
the 15th International World Wide Web conference
(WWW?06), Edinburgh, Scotland.
Soricut, Radu and Eric Brill. 2006. Automatic question
answering using the web: Beyond the factoid. Jour-
nal of Information Retrieval - Special Issue on Web
Information Retrieval, 9:191?206.
Wen, Ji-Rong, Jian-Yun Nie, and Hong-Jiang Zhang.
2002. Query clustering using user logs. ACM Trans-
actions on Information Systems, 20(1):59?81.
Xu, Jinxi and W. Bruce Croft. 1996. Query expansion
using local and global document analysis. In Pro-
ceedings of SIGIR?96, Zurich, Switzerland.
herbs herbs
herbal
medicinal
spices
supplements
remedies
herbs for herbs for
herbs
herbs and
with herbs
herbs for chronic herbs for chronic
and herbs for chronic
herbs for
for for
for chronic for chronic
chronic
of chronic
for chronic constipation for chronic constipation
chronic constipation
for constipation
chronic chronic
acute
patients
treatment
chronic constipation chronic constipation
of chronic constipation
with chronic constipation
constipation constipation
bowel
common
symptoms
for mexican for mexican
mexican
the mexican
of mexican
for mexican cooking mexican food
mexican food and
mexican glossary
mexican mexican
mexico
the mexican
mexican cooking mexican cooking
mexican food
mexican
cooking
cooking cooking
culinary
recipes
cook
food
recipe
Table 7: Phrase translations applicable to source
strings herbs for chronic constipation and herbs
for mexican cooking.
744
