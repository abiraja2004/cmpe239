Proceedings of the 7th Workshop on Asian Language Resources, ACL-IJCNLP 2009, pages 171?178,
Suntec, Singapore, 6-7 August 2009. c?2009 ACL and AFNLP
 
Using Search Engine to Construct a Scalable Corpus for 
Vietnamese Lexical Development for Word Segmentation 
 
 Doan Nguyen 
Hewlett-Packard Company 
doan.nguyen@hp.com 
 
 
 
 
 
  
 
Abstract 
As the web content becomes more accessible 
to the Vietnamese community across the 
globe, there is a need to process Vietnamese 
query texts properly to find relevant informa-
tion. The recent deployment of a Vietnamese 
translation tool on a well-known search en-
gine justifies its importance in gaining popu-
larity with the World Wide Web. There are 
still problems in the translation and retrieval 
of Vietnamese language as its word recogni-
tion is not fully addressed. In this paper we 
introduce a semi-supervised approach in 
building a general scalable web corpus for 
Vietnamese using search engine to facilitate 
the word segmentation process. Moreover, 
we also propose a segmentation algorithm 
which recognizes effectively Out-Of-
Vocabulary (OOV) words. The result indi-
cates that our solution is scalable and can be 
applied for real time translation program and 
other linguistic applications.  This work is 
here is a continuation of the work of Nguyen 
D. (2008). 
1 Introduction 
The Vietnamese language as a minority language 
is gaining popularity including content and au-
dience. It is important to emphasize a need for 
natural language such as search engines or trans-
lation tools to process the data correctly.  With 
this emphasis, we need to have a way to improve 
and automate the training process as well as ex-
panding its training data. Previous works in con-
structing segmentation systems for the Vietnam-
ese language relied on single source of informa-
tion such as newspapers or electronic dictionaries 
(Le H. Phuong et al 2008, Dinh Dien and Vu 
Thuy, 2006, Le T. Ha et al, 2005).  Mono-source 
corpora would work best within their domain, 
and might not work well externally per O?Neil 
(2007).  Le A. Ha, (2003) described the dictio-
nary based approach as problematic due to the 
lack of consistency and completeness. This 
speaks to the need of standardizations between 
dictionaries, concrete grammar theories, and be-
ing up-to-date with the arrival of new words. In 
the work of Nguyen C. T. et al (2007), corpus 
training was done manually by linguists. This 
was very time-consuming and costly. Because 
the task is performed only once, a corpus will go 
stale and will get out-of-date. Dinh et al (2008), 
in a comparison with major Vietnamese segmen-
tation approaches, concluded that the handling of 
unknown compound words is a much greater 
source of segmenting errors and underscored that 
future effort should be geared at prioritizing to-
wards the automatic detection of new com-
pounds.   
 
In this paper, we first present the main issues 
with the Vietnamese word segmentation prob-
lem. We describe the two approaches in obtain-
ing raw text from the Web. Then, we present our 
approach in building a large web corpus for a 
word segmentation function and compare our 
result against a sophisticated algorithm built on a 
human trained corpus. Finally, we provide our 
conclusion and offer suggestions for future re-
search directions. 
2 Vietnamese Word Segmentation 
Problems 
Vietnamese (Ti?ng Vi?t) is the official language 
of Vietnam. The current writing system origi-
nates from the Latin alphabet, with diacritics for 
tones and certain letters. Vietnamese is often 
mistakenly judged as a ?monosyllabic? language. 
However, the majority of the words are disyllab-
ic (Le A. Ha, 2003) covering reduplication and 
adjectives. Its grammar depends on word order-
ing and sentence structure rather than morpholo-
gy.  Even though there is a space separating 
171
 sound units, there is nothing used to identify 
word boundary.   
Examples in Figure 1. are used to illustrate the 
difficulty of Vietnamese word segmentation 
when compared it to English.  There are 256 
possible sequences (2n-1) of segmentation in this 
example. 
 
Figure 1. Ambiguity of word segmentation 
 
The major segmentation problems with the 
Vietnamese word segmentation include: the han-
dling of word ambiguities, detection of unknown 
words, and recognition of named entities. 
2.1 Addressing Words Ambiguities 
In a sequence of Vietnamese syllables, S, com-
posing of two syllables A and B occurring next 
to one another, if S, A, and B are each words, 
then there is a conjunctive ambiguity in S.  In 
contrast, in a sequence of Vietnamese syllables, 
S, composing of three syllables A, B, and C ap-
pearing contiguously, if A B and B C are each 
words, then there is a disjunctive ambiguity in S. 
In order to attain a higher precision rating, word 
ambiguity must be addressed. 
2.2 Detection of Unknown Words 
In a dictionary word segmentation based ap-
proach, only the words that are in the dictionary 
can be identified.  The unknown words might 
belong to one of the following categories: (1) 
Morphologically Derived Word (MDW). There 
are some lexical elements that never stand alone, 
which express negation such as: ?b?t? in ?b?t 
quy t?c? (irregular) or transformation such as 
?ho?? in ?c?ng nghi?p ho?? (industrialize). (2) 
Interchanging usage of vowels i and y and 
changing in position of tone. For example: ?du?c 
s?? and ?du?c s??. Both mean ?pharmacist?. (3) 
Phonetically transcribed words. This can be seen 
in naturalized words like: ?ph? mai? (fromage), 
?h?p h?p? (hip hop music), or ?iPh?ne? (Apple 
iPhone). 
2.3 Recognition of Named Entities 
Unlike other Asian languages, Vietnamese per-
sonal, location, and organizational names all 
have the initial letter capitalized. For example: 
?Nguy?n Du? (a famous Vietnamese poet). Due 
to the language syntax standardization, a proper 
name could be written in many different forms. 
The following organizational name has three ac-
ceptable forms: B? N?ng Nghi?p, B? N?ng 
nghi?p, or B? n?ng nghi?p (Department of Agri-
culture).  We use the following shape features 
(pattern) to assist with the recognition process: 
 
Word Shape  Examples 
Capitalized S?i G?n (Location ) 
All Caps WTO (World Trade 
Organization) 
Containing digit H5N1 (Bird flu) 
Containing hyphen Vn-Index (Securities 
market of Vi?t Nam) 
Mixed case VnExpress (Vietnam 
News Daily) 
Table 1.  Word Shape features for identifying  
Vietnamese Name Entities 
3 Using World Wide Web as a Resource 
to Build Corpora  
There are two approaches to obtain linguistics 
data from the Web.  The first approach is to 
crawl the web (Baroni et al, 2006 and O?Neil, 
2007). This option gives flexibility in choosing 
or restricting sites to crawl upon. To have good 
coverage, it requires extensive hardware resource 
to support storage of content documented in the 
work of Baroni et al (2006). Other complexities 
include a filtering capability to recognize content 
of a target language from crawling data, remov-
ing html code, and handling page duplication. 
The work of Le V. B (2003) indicated that it is 
very difficult to crawl on Web pages located in 
Vietnam due to a low network communication 
bandwidth.   
A second approach is to use search engines via 
a web service API to find linguistic data. In the 
work of Ghani et al (2001), a term selection me-
thod is used to select words from documents to 
use for a query. Documents from a search result 
list are downloaded locally to process and build 
corpus data.  The technical challenges of this 
approach are: (1) Corpus being biased and being 
dictated by a ranking of a search engine. (2) Li-
172
 mited number of search queries is allowed by a 
search engine per day.     
4 Our Approach to build corpus 
We are structuring our system with two main 
components.  The first component works as a 
word training and recognition system. The 
second component utilizes the training informa-
tion provided from the first component to per-
form just a word segmentation task by leveraging 
the computed lexical statistics. This is a clear 
distinction between our work and Nguyen D. 
(2008). Because there is a limited number of 
search request imposed by commercial search 
engines each day, this approach is not practical 
for a condition where there is constant usage of 
search requests, for word segmentation purpose. 
Aside from this limitation, lexical statistics have 
to be recomputed for each new word segmenta-
tion request. 
 
Figure 2. depicts the overall system consists of 
two components: The training Processing in-
cludes a new word discovery function and Nor-
mal Segmentation process. The training process 
would execute continuously and feed the lexical 
statistics to the second process for segmentation 
task purely. 
 
Figure 2. Vietnamese Words Corpus Construc-
tion Process  
4.1 Word Training and Recognition System  
This component trains identified words inside a 
Vietnamese Word Database with its frequency of 
occurrences. Newly encountered OOV words are 
recognized by the system then verified by a 
check against the Vietnamese Wikipedia pro-
grammatically. We do not wish to include all 
words from the Vietnamese Wikipedia as there 
are many foreign words. For examples:  St. He-
lens, Oregon. The remained frequently found 
OOV words are evaluated by linguists for validi-
ty and will be included into the word database as 
confirmed.  Unlike the work of Ghani (2001), in 
our work, a query to submit to an engine is a sen-
tence derived from an unknown document title. 
The reason here is to enable the system to dis-
cover the unknown words and their frequencies 
naturally. This system performs: 
 
? Seed the queries database with an initial set 
of queries, Qn.  
? Randomly select a query from Qn and send to 
a search engine. 
? From a search result list, process on docu-
ment titles and snippet texts directly.   
? Perform Vietnamese word segmentation on 
recognized sentences using question mark, 
exclamation mark, periods as separators. 
Update the word database with recognized 
segmented words and their computed fre-
quencies and weights.  
? Recognize and validate OOV words, using 
the Vietnamese Wikipedia or through mor-
phological rules programmatically.  
? Bootstrap Qn with retrieved document titles.  
? Return to step 2 above. 
5 Word Segmentation System 
In the Vietnamese language, as the white space 
cannot be used to denote word boundary, the 
function of a word segmentation system is to 
segment a sentence into a sequence of segmented 
words such that a context (or meaning) of a sen-
tence is preserved.  
5.1 Data Gathering and Words Extraction  
In the first step, a search query is submitted to a 
search engine API and requests for N returned 
documents. The engine returns a search result 
list, which consists of document titles and their 
summary text.  We parse the data and extract the 
required text.  Syllables in the search query are 
then matched against the parsed text to extract 
potential words covering both monosyllabic and 
polysyllabic words. This function keeps track 
and counts their occurrences. At this stage, we 
also determine if a word is a proper name. We 
use the various word shape features in capitaliza-
tion forms to assist with the recognition process. 
We compute the likelihood of extracted words to 
be proper names by taking the account of the 
number of identified capitalized words over the 
173
 total of the same words in appearing the docu-
ments set, N documents. Once the extraction 
process is complete, we perform additional vali-
dation steps to discard incorrect generated words. 
To be accepted as a potential word, a word must 
satisfy one of the following rules: (1) It appears 
in the word database. (2) It is recognized as a 
proper name word. (3) It is a MDR word.  (4) It 
is an OOV word with strong world collocation as 
defined below. 
An OOV word is identified when there is a 
strong collocation (cohesion) attached between 
its syllables. That is the following condition(s) 
is/are met: (1) For two syllable words to collo-
cate: P(s? s?) > P(s?)P(s?), (2) For three syllable 
words to collocate: P(s? s? s?) > MAX{ 
P(s?)P(s?)P(s?), P(s?)P(s?s?), P(s?s?)P(s?) } where 
w = s? s? s?, P(s??sn) = Freq(s??sn 
)/N, and N is 
the number of documents returning from a search 
engine.  
Collocation concept has been utilized in the 
merging syllables to determine the best possible 
segment in the work of Wirote (2002).
Suffix Translation 
Result Lexi-
cal Category Morphological Rules  Examples  
h?c "'-logy, -ics" Noun  IF Syllable_Suffix("h?c") AND Pre-
fix_With_Word((Noun(W))  THEN 
WORD(W+ " "+ "h?c") 
ng?n ng? (lan-
guage) + h?c ? 
ng?n ng?  h?c 
(linguistics) 
h?a "-ize, -ify" Verb IF Syllable_Suffix("h?a") AND (Pre-
fix_With_Word((NOUN(W) )  OR 
Prefix_With_Word((ADJECTIVE(W) 
)  ) THEN WORD(W+ " " +"h?a") 
c?ng nghi?p (in-
dustry) + h?a ? 
c?ng nghi?p h?a 
(industrialize) 
Prefix Translation 
Result Lexi-
cal Category Morphological Rules  Examples  
s? "Action-" Noun IF Syllable_Prexix("s?") AND (Suf-
fix_With_Word((Verb(W)) OR Suf-
fix_With_Word((Adjective(W))) 
THEN WORD(s?+ " "+ W) 
s? + th?o lu?n 
(discuss, debate) 
? s? th?o lu?n 
(discussion) 
b?t "Un-" Noun IF Syllable_Prexix("b?t") AND (Suf-
fix_With_Word((Verb(W)) OR Suf-
fix_With_Word((Adjective(W))) 
THEN WORD(b?t+ " "+ W) 
b?t + h?p ph?p 
(legal, lawful) 
?b?t h?p ph?p 
(Not legal) 
Table 2. Examples of derivational morphology and morphological rules  
to construct compound words 
 
To recognize for morphological derived words 
(MDW), we have identified a range of prefixes 
and suffixes (Goddard, 2005). When a mor-
pheme modifies another morpheme, it produc-
es a subordinate compound word (Ngo, 2001). 
For example: nh? (as a prefix) + b?o (newspa-
per) ? nh? b?o (journalist). The table 2. pro-
vides a few examples of Vietnamese suffixes, 
prefixes, and Morphological Rules to derive 
subordinate compound words.  
5.2 Sentences Construction  
Given a set of potential segmented words ob-
tained from step 5.1, applied only for training 
process or for a normal segmentation process 
(Figure 2.), the task of sentences constructor is to 
assemble the identified words in such a way that 
they appear in the same order as the original 
query.  We use Greedy algorithm to construct 
sentences using the following heuristic strate-
gies: (1) Selection of polysyllabic words over 
monosyllabic words whenever possible. (2) Eli-
minating segments which have already ex-
amined. (3) Declaring a solution when a con-
structed sentence has all of segmented words 
appearing in the same order as in the original 
query text. 
5.3 Sentences Refinement and Reduction 
through Ambiguity Resolution  
Since there is only a single solution to present to 
a user, we need to have an algorithm to improve 
upon proposed sentences and reduce them to a 
manageable size. The algorithm Sen-
tences_Refine_Reduce below describes the 
174
 steps in refining the sentences to a finer solu-
tion(s). 
 
Definition: Let the pipe symbol, |, be designated 
as a boundary of a segment. Two segments, in 
two sentences, are overlapped if their first and 
last syllables are: (1) located next to a segmented 
boundary. (2) Identical and positioned at the 
same location.  For example, in the following 
two sentences: 
 
Sentence #1: t?c ?? | truy?n | th?ng tin | s? | t?ng | 
cao 
Sentence #2: t?c ?? | truy?n th?ng | tin | s? | t?ng | 
cao 
 
The overlapped segments are: ?t?c ???, ?s??, 
?t?ng?, and ?cao?. We are now describing an 
algorithm to perform sentences refinement and 
reduction as follows: 
 
Algorithm : Sentences_Refine_Reduce() 
Input: SBuffer - for input sentences 
Output: SBuffer - for output sentences 
1: 
2: 
3: 
4: 
 
5: 
 
 
6: 
 
7: 
 
Until Converged(SBuffer) Do: 
    Itr_Sentences_Buf = {} 
    For si in SBuffer Do: 
       Find sj such that Max {|Overlapped_Segment 
(si,sj)|} for sj ?  SBuffer  and si != sj 
        Res_Segments=Overlapped_Segments(si,sj)   
           U Conjunctive_Segments_Resolutions(si,sj)  
           U Disjunctive_Segments_Resolutions(si,sj) 
        Itr_Sentences_Buf = Itr_Sentences_Buf U  
             Sentence(Res_Segments) 
    SBuffer=(SBuffer!=Itr_Sentences_Buf) 
          ? Itr_Sentences_Buf : SBuffer  
 
For conjunctive ambiguity resolution, to de-
termine if all syllables should be classified as a 
single word or appeared as individual words, we 
utilize word collocation strength. We define col-
locating strength as follows. 
)2()...()...ss( 1n1 N
ssFreq P n?
 
We compare it against a probability of finding 
the syllables occur independently in N docu-
ments as shown in equation (3). The outcome 
determines if the syllables should be collocated 
or separately appeared: 
)3()(...)()(s)...s( 1n1 N
sFreq
N
sFreq PP n???
 
For disjunctive ambiguity resolution, because 
a determination involves multiple words with 
overlapping text, we determine the best possible 
segments by computing their probability distri-
bution of word segments to find out which one 
has the highest probability of success.  This is 
discussed further in the section ?Sentences Scor-
ing and Ordering? below. Figure 3 illustrates a 
process where sentences are refined through dis-
ambiguating words.   
 
Figure 3. An Example of Sentences Refinement  
 
After the 1st iteration, the sentences 1 and 2 are 
combined through a resolution of conjunctive 
ambiguity between ?t?c ??? vs. ?t?c | 
 ??? .  After the 2nd iteration, sentences 1 and 2 
are combined through a resolution of disjunctive 
ambiguity between ?truy?n | th?ng tin? vs. 
?truy?n th?ng | tin?. The process exits when a 
converged condition is reached. The final seg-
mented sentence is translated in English as ?The 
speed of information transmission will increase?. 
5.4 Sentences Scoring and Ordering  
The task in this phase is to score and order the 
candidates. A language model is usually formu-
lated as a probability distribution p(s) over 
strings s that attempts to reflect how frequently a 
string s occurs as a sentence in a corpus, Chen et 
al. (1998). For a segmented sentence S 
=
nwww ...21 , where w is an identified segmented 
word, using a bigram model, we compute the 
probability distribution of a sentence s as fol-
lows: 
)4()| ()...| (  p(s)
1 11 11 ?? ? ?? ? ??
n
i ii
n
i ii
wwPwwwP
 
However, there is an event such that 
)| ( 1?ii wwP  = 0. To handle this condition, we 
applied Additive Smoothing to estimate its prob-
ability. The formula was experimented and 
slightly modified to fit our needs and defined as 
follows: 
)5()(
)()|(
1
1
1_ ? ??? ?
??
iw ii
ii
iiThetaAdd wwFreqW
wFreqwwP ?
?
 
We define ? parameter as Freq( iw )/|W| 
where |W| is an estimate number of the total 
words appears in N returned documents and 0 < 
? < 1. 
175
 6 Experimental Results 
With no restriction, there were 167,735 searches 
performed using the Yahoo! Boss Web Service 
API. We bootstrapped the initial core lexicons 
from Ho?s Word List (2004) and built up to 
gather lexical statistics and discovered new OOV 
words. The corpus syllables classifications and 
their occurrences are shown in Figure 4. 
 
Figure 4. Syllables Types by Frequency 
 
We compared our collected lexical data, using 
our approach, against VietLex (Dinh et al, 2008) 
and found a resembling to one, three, four, and 
five syllables. For the two syllables, there is a big 
difference: roughly about 19,000 words.  This 
contributes to the fact that the original Ho?s word 
list had already covered 49,583 two-syllable 
words to begin with. On top of it, we have in-
cluded 3,000 additional new OOV words includ-
ing MDW and proper names words. According 
to the Wiki?s - Vietnamese_morphology, it esti-
mates about 80% of the lexicon being disyllabic. 
In our corpus, we have 72% of disyllabic words.   
 
 
Table 3. The top 20th one-syllable words compar-
ing with corpus of Le A. H1 (2003) 
                                               
1 The star marker indicates the same word is co-occurred in 
Le?s of top unigram listing. 
 
Table 3 provides a top 20 one-syllable words 
obtained from our word database. The star mark-
er indicates the same word is also co-occurred in 
Le?s of top unigram listing. 
The following disyllabic words, in Table 4, 
are a few of the new OOV words identified by 
our approach and absent from Ho?s Word List 
(2004) . 
  
Common 
Disyllabic 
Words   
Fre-
quency 
Uncom-
mon 
Disyllab-
ic Words   
Fre-
quency 
Vi?t Nam 
(Viet Nam) 
206704 lan r?ng 
(spread) 
263 
Ng??i Vi?t 
(Vietnam-
ese) 
41260 ga l?ng 
(gallon) 
14 
Trung Qu?c 
(China) 
35345 C?n 
Ph?ng 
(Island) 
9 
Ti?ng Vi?t 
(Vietnam-
ese) 
28460 ngh? s? 
(congress
gress-
man) 
22 
Hoa K? 
(America) 
21262 c?ng x?n 
(console) 
2 
Table 4. Some OOV disyllabic words 
 
We evaluated our segmentation system against 
a popular Vietnamese word segmentation tool - 
the JVnSegmenter (Nguyen C. T, 2007): A Java-
based Vietnamese Word Segmentation Tool 
(SVM).  This tool was also a part of Dinh et al 
(2008) evaluation aforementioned. With a source 
data provided by a neutral evaluator, and about 
9600 sentences with an estimate of 100K words, 
we ran an experiment. The texts were input into 
both methods.  To keep the fairness of the evalu-
ation, the segmented output texts were sent out to 
a neutral assessor to analyze for results. The per-
formance results are presented in Table 5. below. 
 
Evaluation 
Areas 
JVnSegmenter Our Ap-
proach 
Recall 0.814 0.821 
Precision 0.883 0.897 
F-Measure 0.847 0.857 
OOV Rate 0.06 0.06 
OOV Recall 0.921 0.951 
IV Recall 0.807 0.813 
Table 5. Performance Results Comparison 
 
176
 From the data above, the low OOV rate and 
high OOV recall in both systems could be ex-
plained by the nature of the testing corpus: Viet-
namese novels/stories chosen by a neutral evalu-
ator. With this type of content, the numbers of 
OOV words are much lesser when compared to 
other areas such as news, technology.  Even 
though the results don?t seem much higher than 
those obtained by JVnSegmenter, given the fact 
that JVnSegmenter used a manual trained corpus,  
our result is worth encouragements.  Table 6 
provides a few examples of the segmentation 
results. 
 
Q1: t?c ?? truy?n 
th?ng tin s? t?ng cao 
(Ambiguity) 
JVnSegmenter: [t?c ??] 
[truy?n th?ng tin] [s?] 
[t?ng] [cao] 
Our Approach: t?c ?? | 
truy?n | th?ng tin | s? | 
t?ng | cao 
Q2: h?n m?c t? l? m?t 
nh? th? n?i ti?ng 
(Proper Name) 
JVnSegmenter: [h?n 
m?c] [t?] [l?] [m?t] 
[nh? th?] [n?i ti?ng] 
Our Approach: h?n 
m?c t? | l? | m?t | nh? 
th? | n?i ti?ng 
Q3:  m?t ng??i ??n b? 
l?m ngh?  b?n n??c 
tr? ven ???ng (Ambi-
guity) 
JVnSegmenter: [m?t] 
[ng??i ??n b?] [l?m 
ngh?] [b?n n??c] [tr?] 
[ven ???ng] 
Our Approach: m?t | 
ng??i ??n b? | l?m ngh? 
| b?n | n??c tr? | ven 
???ng 
Q4: th? t??ng trung 
qu?c ?n gia b?o 
(Proper name) 
JVnSegmenter: [th? 
t??ng] [trung] [qu?c] 
[?n] [gia b?o] 
Our Approach: th? 
t??ng | trung qu?c | ?n 
gia b?o 
Table 6.  Sample outputs of the two approaches: 
Our approach vs. JVnSegmenter  
7 Conclusion 
We presented our approach to segment Viet-
namese text and to build a web corpus for the 
function.  We made use of the web document 
titles and their snippet text to build a scalable 
corpus for segmenting query text.  The results so 
far have shown that this approach has the follow-
ing benefits: 
 
? From a practical and performance perspective, 
this approach does not require extended ma-
nual effort in building a corpus. The learning 
from the training engine, running continuously, 
discovers new OOV words and feeds them into 
a normal word segmentation process where it 
supplies solutions to requesters efficiently. 
? The approach discovers new OOV words and 
disambiguates words. Additionally, we discov-
ered new proper nouns which are not a part of 
any dictionaries continuously. We integrated 
the finding knowledge from the Vietnamese 
Wikipedia into our OOV words confirmation 
process automatically. This makes the valida-
tion of new words much easier as suppose to 
rely on word adjudicators manually as per 
O?Neil (2007).  And last, the evaluation result 
is a better edge when comparing to a popular 
Vietnamese segmentation tool in all the me-
trics considered. This tool has a corpus trained 
manually. 
? Frequently found OOV words identified by our 
process which are not available in the Viet-
namese Wikipedia can be suggested to Wiki 
authors? communities to create content and 
make them available for the worldwide au-
diences for their benefit. 
 
For future works, we would like to look into 
the possibility of applying grammatical rules in 
conjunction with our current statistical based sys-
tem to obtain a higher identification rate. Spel-
ling suggestion and cross-lingual search are other 
interesting aspects, as now words can be identi-
fied along with their lexical statistics. 
Acknowledgement 
Our work is credited from the works of Nguyen 
Bon et al (2006), Ho Ngoc Duc (The Free Viet-
namese Dictionary Project), Cam T Nguyen et al 
(JVnSegmenter - 2007), O?Neil (2007), and Ya-
hoo! Boss Web Service, which made the API 
available limitlessly during the course of the 
work, and many anonymous contributors and 
reviewers. A Special thank to Mr. Thuy Vu who 
contributed to an assessment of our approach and 
the JVnSegmenter. 
Reference 
C. T. Nguyen, T. K. Nguyen, X. H. Phan, L. M. 
Nguyen, and Q. T. Ha. 2006. Vietnamese word 
segmentation with CRFs and SVMs: An investiga-
tion. In Proceedings of the 20th Pacific Asia Confe-
rence on Language, Information and Computation 
(PACLIC 2006), Wuhan, CH. 
 
Cliff Goddard. 2005. The Languages of East and 
Southeast Asia (pages 70-71) 
Dinh Dien, Vu Thuy. 2006. A Maximum Entropy 
Approach for Vietnamese Word Segmentation. In 
Proceedings of the 4th IEEE International Confe-
177
 rence on Computer Science- Research, Innovation 
and Vision of the Future 2006, HCM City, Viet-
nam, pp.247?252. 
Dinh Quan Thang, et al 2008. Word Segmentation of 
Vietnamese Texts: a comparison of approaches. 
LREC : 2008 
Ghani, R., Jones, R., Mladenic, D. 2001. Using the 
Web to create minority language corpora?. Pro-
ceedings of the 10th International Conference on 
Information and Knowledge Management 
Ho Ngoc Duc, 2004: Vietnamese word list:  Ho Ngoc 
Duc?s word list ? http://www.informatik.uni-
leipzig.de/~duc/software/misc/wordlist.html 
John O?Neil. 2007. Large Corpus Construction for 
Chinese Lexical Development, Government Users 
Conference: http://www.basistech.com/knowledge-
center/unicode/emerson-iuc29.pdf 
Le Thanh Ha,  Huynh Quyet Thang,  Luong Chi Mai. 
2005. A Primary Study on Summarization of Doc-
uments in Vietnamese. The First International 
Congress of the International Federation for Sys-
tems Research, Japan. 
L. H. Phuong and H. T. Vinh, 2008, Maximum Entro-
py Approach to Sentence Boundary Detection of 
Vietnamese Texts, IEEE International Conference 
on Research, Innovation and Vision for the Future 
RIVF 2008, Vietnam. 
L. A. Ha. 2003. A method for word segmentation in 
Vietnamese. In Proceedings of the International 
Conference on Corpus Linguistics, Lancaster, UK. 
Marco Baroni, Motoko Ueyama. 2006. Building gen-
eral and special-purpose corpora by Web Crawling. 
Proceedings of the 13th NIJL International Sympo-
sium, Language Corpora: Their Compilation and 
Application. 31-40. 
Ngo. N. Binh, B. H. Tran. 2001. Vietnamese Lan-
guage Learning Framework ? Part One: s Linguis-
tic. 
Nguyen D. 2008. Query preprocessing: improving 
web search through a Vietnamese word tokeniza-
tion approach. SIGIR 2008: 765-766. 
Stanley F. Chen, J. Goodman. 1998. An empirical 
study of smoothing techniques for language model-
ing.  Center Research in Computing Technology, 
Harvard University, TR-10-98 
Thanh Bon Nguyen, Thi Minh Huyen Nguyen, Lau-
rent Romary, Xuan Luong Vu. 2006. A lexicon for 
Vietnamese language processing. Language Re-
sources and Evaluation. Springer Netherlands  
V-B. Le, B. Bigi, L. Besacier, E. Castelli, 2003. Using 
the Web for fast language model construction in 
minority languages", Eurospeech'03, Geneva, 
Switzerland, September 2003 
Wirote Aroonmanakun. 2002. Collocation and Thai 
Word Segmentation, Proceedings of SNLP-
Oriental COCOSDA 2002 
Vietnamese morphology: From Wikipedia: 
http://en.wikipedia.org/wiki/Vietnamese_morpholo
gy 
Yahoo! Boss Web Service API 
http://developer.yahoo.com/search/boss 
178
