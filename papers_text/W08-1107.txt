Referring Expressions as Formulas of Description Logic
Carlos Areces
INRIA Nancy Grand Est
Nancy, France
areces@loria.fr
Alexander Koller
University of Edinburgh
Edinburgh, UK
a.koller@ed.ac.uk
Kristina Striegnitz
Union College
Schenectady, NY, US
striegnk@union.edu
Abstract
In this paper, we propose to reinterpret the
problem of generating referring expressions
(GRE) as the problem of computing a formula
in a description logic that is only satisfied by
the referent. This view offers a new unifying
perspective under which existing GRE algo-
rithms can be compared. We also show that
by applying existing algorithms for computing
simulation classes in description logic, we can
obtain extremely efficient algorithms for rela-
tional referring expressions without any dan-
ger of running into infinite regress.
1 Introduction
The generation of referring expressions (GRE) is
one of the most active and successful research ar-
eas in natural language generation. Building upon
Dale and Reiter?s work (Dale, 1989; Dale and Reiter,
1995), various researchers have added extensions
such as reference to sets (Stone, 2000), more expres-
sive logical connectives (van Deemter, 2002), and
relational expressions (Dale and Haddock, 1991).
Referring expressions (REs) involving relations,
in particular, have received increasing attention re-
cently; especially in the context of spatial refer-
ring expressions in situated generation (e.g. (Kelle-
her and Kruijff, 2006)), where it seems particularly
natural to use expressions such as ?the book on the
table?. However, the classical algorithm by Dale and
Haddock (1991) was recently shown to be unable
to generate satisfying REs in practice (Viethen and
Dale, 2006). Furthermore, the Dale and Haddock al-
gorithm and most of its successors (such as (Kelle-
her and Kruijff, 2006)) are vulnerable to the prob-
lem of ?infinite regress?, where the algorithm jumps
back and forth between generating descriptions for
two related individuals infinitely, as in ?the book on
the table which supports a book on the table . . . ?.
In this paper, we propose to view GRE as the
problem of computing a formula of description logic
(DL) that denotes exactly the set of individuals that
we want to refer to. This very natural idea has been
mentioned in passing before (Krahmer et al, 2003;
Gardent and Striegnitz, 2007); however, we take it
one step further by proposing DL as an interlingua
for comparing the REs produced by different ap-
proaches to GRE. In this way, we can organize ex-
isting GRE approaches in an expressiveness hierar-
chy. For instance, the classical Dale and Reiter al-
gorithms compute purely conjunctive formulas; van
Deemter (2002) extends this language by adding the
other propositional connectives, whereas Dale and
Haddock (1991) extends it by allowing existential
quantification.
Furthermore, the view of GRE as a problem of
computing DL formulas with a given extension al-
lows us to apply existing algorithms for the lat-
ter problem to obtain efficient algorithms for GRE.
We present algorithms that compute such formulas
for the description logics EL (which allows only
conjunction and existential quantification) andALC
(which also allows negation). These algorithms ef-
fectively compute REs for all individuals in the do-
main at the same time, which allows them to system-
atically avoid the infinite regress problem. The EL
algorithm is capable of generating 67% of the rela-
tional REs in the Viethen and Dale (2006) dataset, in
about 15 milliseconds. The ALC algorithm is even
faster; it computes relational REs for all 100 indi-
viduals in a random model in 140 milliseconds.
The paper is structured as follows. In Section 2,
42
we will first define description logics. We will then
show how to generate REs by computing DL sim-
ilarity sets for ALC and EL in Section 3. In Sec-
tion 4, we evaluate our algorithms and discuss our
results. Section 5 compares our approach to related
research; in particular, it shows how various promi-
nent GRE algorithms fit into the DL framework.
Section 6 concludes and points to future work.
2 Description logics and similarity
In this paper, we will represent referring expres-
sions as formulas of description logic (Baader et al,
2003). In order to make this point, we will now de-
fine the two description logics we will be working
with: ALC and EL.
Formulas (or concepts) ? of ALC are generated
by the following grammar:
?,?? ::= > | p | ?? | ? u ?? | ?R.?
where p is in the set of propositional symbols prop,
and R is in the set of relational symbols rel. EL is
the negation-free fragment of ALC.
Formulas of both ALC and EL are interpreted in
ordinary relational first-order modelsM = (?, || ? ||)
where ? is a non-empty set and || ? || is an interpreta-
tion function such that:
||p|| ? ? for p ? prop
||R|| ? ??? for R ? rel
||??|| = ?? ||?||
||? u ??|| = ||?|| ? ||??||
||?R.?|| = {i | for some i?, (i, i?) ? ||R||
and i? ? ||?||}.
Every formula of a description logic denotes a
set of individuals in the domain; thus we can use
such formulas to describe sets. For instance, in the
model in Fig. 1b, the formula flower denotes the set
{f1, f2}; the formula floweru?in.hat denotes {f2};
and the formula flower u ??in.hat denotes {f1}.
Different description logics differ in the inventory
of logical connectives they allow: While ALC per-
mits negation, EL doesn?t. There are many other
description logics in the literature; some that we
will get back to in Section 5 are CL (EL without
existential quantification, i.e., only conjunctions of
atoms); PL (ALC without existential quantification,
i.e., propositional logic); and ELU (?) (EL plus dis-
junction and atomic negation).
Below, we will use a key notion of formula preser-
vation that we call similarity. For any DL L, we
will say that an individual i is L-similar to i? in a
given modelM if for any formula ? ? L such that
i ? ||?||, we also have i? ? ||?||. Equivalently, there
is no L-formula that holds of i but not of i?. We say
that the L-similarity set of some individual i is the
set of all individuals to which i is L-similar.
Notice that similarity is not necessarily a symmet-
rical relation: For instance, f1 is EL-similar to f2 in
Fig. 1b, but f2 is not EL-similar to f1 (it satisfies the
formula ?in.hat and f1 doesn?t). However, ALC-
similarity is a symmetrical relation because the lan-
guage contains negation; and indeed, f1 is notALC-
similar to f2 either because it satisfies ??in.hat. Be-
causeALC is more expressive than EL, it is possible
for some individual a to be EL-similar but notALC-
similar to some individual b, but not vice versa.
3 Generating referring expressions
Now we apply description logic to GRE. The core
claim of this paper is that it is natural and useful to
view the GRE problem as the problem of computing
a formula of some description logic L whose exten-
sion is a given target set A of individuals.
L-GRE PROBLEM
Input: A modelM and a target set A ? ?.
Output: A formula ? ? L such that ||?|| = A
(if such a formula exists).
In the examples above, it is because flower u
?in.hat denotes exactly {f2} that we can say ?the
flower in the hat? to refer to f2. This perspective pro-
vides a general framework into which many existing
GRE approaches fit: Traditional attribute selection
(Dale and Reiter, 1995) corresponds to building DL
formulas that are conjunctions of atoms; relational
REs as in Dale and Haddock (1991) are formulas of
EL; and so on. We will further pursue the idea of or-
ganizing GRE approaches with respect to the variant
of DL they use in Section 5.
For the rest of this paper, we assume that we are
generating a singular RE, i.e., the target set A will
be a singleton. In this case, we will only be able
to generate a formula that denotes exactly A = {a}
(i.e., a RE that uniquely refers to a) if there is no
43
f1
floor
t
2
table
t
1
table
b
2
c
2
bowl
cup
b
1
bowl
c
1
cup
on
on
on
on
in
in
(a) (b)
r
1
rabbit
r
2
rabbit
r
3
rabbit
r
4
rabbith
1
hat
h
4
hat
h
2
hat
h
3
hat
f
1
flower
f
2
flower
b
1
bathtub
in
in
in
Figure 1: (a) The Dale and Haddock (1991) scenario; (b)
the Stone and Webber (1998) scenario.
other individual b to which a is similar; otherwise,
any formula that is satisfied by a is also satisfied by
b. Conversely, if we know that a is not similar to any
other individual, then there is a formula that is satis-
fied by a and not by anything else; this formula can
serve as a unique singular RE. In other words, we
can reduce the L-GRE problem for a given model
to the problem of computing the L-similarity sets of
this model. Notice that this use of similarity sets can
be seen as a generalization of van Deemter?s (2002)
?satellite sets? to relational descriptions.
In the rest of this section, we will present algo-
rithms that compute the similarity sets of a given
model for ALC and EL, together with characteris-
tic formulas that denote them. In the ALC case,
we adapt a standard algorithm from the literature
for computing simulation classes; we will then fur-
ther adapt this algorithm for EL. In effect, both al-
gorithms compute REs for all individuals in some
model at the same time ? very efficiently and with-
out any danger of infinite regress.
3.1 Computing similarity sets
It can be shown that for ALC, the similarity sets
of a finite model coincide exactly with the simu-
lation classes of this model. Simulation classes
have been studied extensively in the literature (see
e.g., Blackburn et al (2001); Kurtonina and de Ri-
jke (1998)), and there are several efficient algorithms
for computing ALC-simulation classes (Hopcroft,
1971; Paige and Tarjan, 1987; Dovier et al, 2004).
However, these algorithms will only compute the
simulation classes themselves. Here we extend the
Hopcroft (1971) algorithm such that it computes,
along with each set, also a formula that denotes ex-
actly this set. We can then use these formulas as
representations of the referring expressions.
The pseudocode for our ALC algorithm is shown
as Algorithm 1 (with L = ALC) and Algorithm 2.
Given a modelM = (?, || ? ||), the algorithm com-
putes a set RE of ALC formulas such that {||?|| |
? ? RE} is the set of ALC-similarity sets of
M. The algorithm starts with RE = {>} (where
||>|| = ?), and successively refines RE by mak-
ing its elements denote smaller and smaller sets. It
maintains the invariant that at the start and end of ev-
ery iteration, {||?|| | ? ? RE} is always a partition
of ?. The algorithm iterates over all propositional
and relational symbols in prop and rel to construct
new formulas until either all formulas in RE denote
singletons (i.e., there is only one individual that sat-
isfies them), or no progress has been made in the
previous iteration. In each iteration, it calls the pro-
cedure addALC(?, RE ), which intersects ? with any
formula ? ? RE which does not denote a singleton
and which is not equivalent to ? and to ??. In this
case, it replaces ? in RE by ? u ? and ? u ??.
TheALC algorithm computes theALC-similarity
sets of the model in timeO(n3), where n is the num-
ber of individuals in the domain. However, it will
freely introduce negations in the case distinctions,
which can make the resulting formula hard to realize
(see also Section 4.3). This is why we also present
an algorithm for the EL-similarity sets; EL corre-
sponds to positive relational REs, which are gener-
ally much easier to realize.
We obtain the EL algorithm by replacing the call
to addALC in Algorithm 1 by a call to addEL, which
is defined in Algorithm 3. As before, the algo-
rithm maintains a set RE = {?1, . . . , ?n} of for-
mulas (this time of EL) such that ||?1|| ? . . . ?
||?n|| = ?, and which it refines iteratively. However,
where the ALC algorithm maintains the invariant
that ||?1||, . . . , ||?n|| is a partition of ?, we weaken
this invariant to the requirement that there are no
m ? 2 pairwise different indices 1 ? i1, . . . , im ?
n such that ||?i1 || = ||?i2 || ? . . .? ||?im ||. We call ?i1
subsumed if such a decomposition exists.
Because it maintains a weaker invariant, the set
RE may contain more formulas at the same time in
the EL algorithm than in the ALC algorithm. Given
that ? has an exponential number of subsets, there is
a risk that the EL algorithm might have worst-case
44
Algorithm 1: Computing the L-similarity sets
Input: A modelM = (?, || ? ||)
Output: A set RE of formulas such that
{||?|| | ? ? RE} is the set of
L-similarity sets ofM.
RE ? {>}1
for p ? prop do2
addL(p,RE )3
while exists some ? ? RE , |||?|||M > 1 do4
for ? ? RE , R ? rel do5
addL(?R.?,RE )6
if made no changes to RE then7
exit8
exponential runtime (although we are not aware of
such worst-case examples). We leave a more careful
complexity analysis for future work.
We presented both algorithms as first refining RE
according to propositional symbols, and then by re-
lational expressions of increasing depth. But actu-
ally, propositional symbols can be encoded using
new relational symbols (e.g., we could represent that
f1 is a flower in Fig. 1 as a relation labeled flower
from f1 to an additional dummy element d). In this
way, we don?t need to distinguish between proposi-
tions and relations, and any arbitrary preference or-
dering of properties can be used.
3.2 Some examples
Let?s try our algorithms on some examples. We
first run the EL algorithm on the model shown in
Fig. 1a, which is taken from Dale and Haddock
(1991). The algorithm starts with RE = {>}. In
the first loop, it adds the formulas floor, bowl, cup,
and table, and then removes > because it is now
subsumed. Not all of these formulas denote single-
tons; for instance, ||cup|| contains two individuals.
So we iterate over the relations to refine our for-
mulas. After the first iteration over the relations,
we have RE = {floor, bowl u ?on.floor, bowl u
?on.table, cup, table}. Notice that bowl has become
subsumed, but we haven?t distinguished the cups
and tables further.
Now we can use the split between the bowls to
distinguish the cups in the second iteration. The re-
sult of this is RE = {floor, bowlu?on.floor, bowlu
Algorithm 2: addALC(?,RE )
for ? ? RE with |||?||| > 1 do1
if ||? u ?|| 6= ? and ||? u ??|| 6= ? then2
add ? u ? and ? u ?? to RE ;3
remove ? from RE ;4
Algorithm 3: addEL(?, RE )
for ? ? RE with |||?||| > 1 do1
if ? u ? is not subsumed in RE and2
||? u ?|| 6= ? and ||? u ?|| 6= ||?|| then
add ? u ? to RE3
remove subsumed formulas from RE4
?on.table, cup u ?in.(bowl u ?on.floor), cup u
?in.(bowl u ?on.table), table}. At this point, all
formulas except table denote singletons, and further
iterations don?t allow us to refine table; so the al-
gorithm terminates. Each formula with a singleton
extension {a} is a unique description of a; for in-
stance, cup u ?in.(bowl u ?on.table) is only satis-
fied by c2, so we may refer to c2 as ?the cup in the
bowl on the table?. Notice that the algorithm didn?t
focus on any particular individual; it simultaneously
generated REs for all individuals except for the two
tables (which are similar to each other).
The EL algorithm has a harder time with the ex-
ample in Fig. 1b (Stone and Webber, 1998). While
it will correctly identify r1 as ?the rabbit in the hat?
and f2 as ?the flower in the hat?, it will not be able to
compute a RE for f1 because f1 is EL-similar to f2.
Indeed, the algorithm terminates with RE contain-
ing both flower and floweru?in.hat. This is a typical
pattern for asymmetrical cases of similarity in EL: If
there are two formulas ?1 and ?2 in the output set
with ||?1|| ? ||?2||, then there is generally some in-
dividual b ? ||?2|| ? ||?1|| such that all individuals in
||?1|| are similar to b, but not vice versa. By contrast,
theALC algorithm can exploit the greater expressiv-
ity of ALC to split flower into the two new formulas
floweru?in.hat and floweru??in.hat, generating a
unique RE for f1 as well.
4 Discussion
We will now describe two experiments evaluating
the quality of the EL algorithm?s output and the effi-
45
Figure 2: A schematic view of the filing cabinets.
ciency of both of our algorithms, and we discuss the
interface between our algorithms and realization.
4.1 Evaluation: Output quality
To compare the descriptions generated by our al-
gorithm to those humans produce, we use a cor-
pus of human-generated referring expressions col-
lected and made available by Jette Viethen and
Robert Dale.1 They asked human subjects to de-
scribe one of 16 filing cabinet drawers. The draw-
ers had different colors and were arranged in a
four-by-four grid (see Fig. 2). The human subjects
used four non-relational properties (the drawer?s
color, its column and row number, and whether
it is in a corner) and five relational properties
(above, below, next to, left of, right of). Of the 118
referring expressions obtained in the experiment,
only 15 use relations.
Viethen and Dale (2006) describe the data in
more detail and present results of evaluating the Full
Brevity algorithm, the Incremental Algorithm (both
by Dale and Reiter (1995)), and the Relational Al-
gorithm (Dale and Haddock, 1991) on this corpus.
The Incremental Algorithm is dependent on a pre-
defined ordering in which properties are added to
the description. Viethen and Dale, therefore, try all
possible orderings and evaluate what percentage of
descriptions an algorithm can generate with any of
them. The Full Brevity and the Relational Algo-
rithms choose properties based on their discrimina-
tory power and only use the orderings as tie break-
ers. Viethen and Dale found that the Incremental
Algorithm is capable of generating 98 of the 103
non-relational descriptions. However, the Relational
Algorithm was unable to generate even a single one
of the human-generated relational descriptions.
We replicated Viethen and Dale?s experiment for
1http://www.ics.mq.edu.au/?jviethen/drawers
the EL algorithm presented above. In the non-
relational case, our results are the same as theirs for
the Incremental Algorithm: the EL algorithm gener-
ates 98 of the 103 non-relational descriptions, using
four (of the possible) orderings. This is because the
two algorithms perform essentially the same compu-
tations if there are no relations.
When we add relations, our algorithm is able to
generate 10 of the 15 human-produced relational
descriptions correctly (in addition to the 98 non-
relational descriptions). Fig. 3 gives example out-
puts of the EL algorithm for three different order-
ings, which together achieve this coverage. Of the
five human-produced descriptions that the EL algo-
rithm cannot generate, three involve references to
sets (the two blues ones in horizontal sequence/the
two yellow drawers), and two contain so much re-
dundant information that our algorithm cannot re-
produce them: Similarly to the Incremental Algo-
rithm, our algorithm allows for some redundancy,
but stops once it has found a distinguishing descrip-
tion. It does, however, generate other, simpler de-
scriptions for these referents.
4.2 Evaluation: Efficiency
Both the EL and the ALC algorithms took about 15
milliseconds to compute distinguishing formulas for
all 16 individuals in the Viethen and Dale dataset.2
In order to get a more comprehensive picture
of the algorithms? efficiency, we ran them on ran-
dom models with increasing numbers of individu-
als. Each model had random interpretations for ten
different propositional and four relational symbols;
each individual had a 10% chance to be in the exten-
sion of each propositional symbol, and each pair of
individuals had a 10% chance to be related by a re-
lational symbol. The results (averaged over 10 runs
for each model size) are shown in Fig. 4. The EL al-
gorithm takes about 350 ms on average to generate
relational REs for all individuals in the model of size
100, i.e., less than 4 ms on average for each individ-
ual. The ALC algorithm is even faster, at about 140
ms for the model of size 100. As far as we know,
these are by far the fastest published runtimes for
2Runtimes were measured on a MacBook Pro (Intel Core 2
Duo, 2.16 GHz) running Java 1.6 beta. We allowed the Java
VM to warm up, i.e., just-in-time compile all bytecode, before
taking the measurements.
46
id
human-produced description
output of the EL algorithm
2
the orange drawer above the blue drawer
orangeu ?above.blue / orange u ?above.(?below.(orange) u blue) / orange u ?next.(blue) u ?next.(pink)
4
the yellow drawer on the top of the pink one
yellow u ?above.pink / yellow u corner u ?above.pink / yellow u corner u ?above.(?next.(yellow) u pink)
5
? the pink drawer in the fourth column below the yellow one
pink u ?above.orange / pink u ?below.yellow / pink u ?next.(yellow) u ?above.(?next.(yellow) u orange)
6
the yellow drawer on top of the yellow drawer (2?) / ? the drawer after the two blue ones in horizontal sequence
yellow u ?above.yellow / yellow u ?below.pink / yellow u ?next.(blue) u ?next.(pink)
7
the blue drawer below the orange one / ? the blue drawer below the orange drawer in the second column
blueu?above.(blue)u?next.(?above.(orange)ublue) / blueu?below.(orange) / blueu?next.(blue)u?next.(yellow)
10
the blue drawer above the pink drawer (2?)
blueu ?above.(pink) / blue u ?above.(pink) u ?below.(blue) / blue u ?next.(orange) u ?next.(yellow)
11
the yellow drawer next to the orange drawer (2?)
yellow u ?above.orange / yellow u ?below.yellow / yellow u ?next.orange
12
the orange drawer below the pink drawer
orange u ?above.(pink u corner) / orangeu ?below.pink / orange u ?next.yellow
14
? the orange drawer below the two yellow drawers (2?)
orange u ?next.(pink u corner) u ?next.(pink) / orange u ?below.yellow / orange u ?next.(pink u corner)
Figure 3: The relational descriptions from Viethen and Dale (2006), annotated with the drawer id and the outputs of the
EL algorithm using three different orderings. Notice that four descriptions occurred twice in the corpus. Descriptions
that the EL algorithm cannot generate with any ordering are marked by ?. Generated descriptions that match one
produced by humans are in boldface.
any relational GRE algorithm in the literature.
4.3 Interface to realization
Our GRE algorithms do not guarantee that the for-
mula they compute can actually be realized in lan-
guage. For example, none of the formulas our al-
gorithms computed in the Viethen and Dale domain
contained an atom that would commonly be realized
as a noun; the property drawer is never used be-
cause it applies to all individuals in the domain. This
particular problem could easily be worked around
in a post-processing step. However, another prob-
lem arises from the massive use of negation in the
ALC algorithm; it will be hard for any realizer to
find a reasonable way of expressing a formula like
??R.(?Pu?Q) as a smooth noun phrase. Although
we agree with van Deemter (2002) and others that
the careful use of negation and disjunction can im-
prove REs, these connectives must not be overused.
Thus we consider the formulas computed by the EL
algorithm ?safer? with respect to realization.
Of course, we share the problem of interfacing
GRE and realization with every other approach that
separates these two modules, i.e., almost the en-
tire GRE literature (notable exceptions are, e.g., Ho-
racek (1997) and SPUD (Stone and Webber, 1998)).
0
100
200
300
400
10 20 30 40 50 60 70 80 90 100
EL ALC
Figure 4: Average runtimes (in ms) of the two algorithms
on random models with different numbers of individuals.
In principle, we believe that it is a good idea to
handle sentence planning and realization in a single
module; for instance, SPUD can use its awareness
of the syntactic context to generate succinct REs as
in ?take the rabbit from the hat?. We hope that the
ideas we have explored here for efficient and ex-
pressive RE generation can eventually be combined
with recent efficient algorithms for integrated sen-
tence planning and realization, such as in Koller and
Stone (2007).
One problem that arises in our approach is that
47
both algorithms derive some measure of efficiency
from their freedom to build formulas without hav-
ing to respect any linguistic constraints. It seems
straightforward, for instance, to extend Krahmer et
al.?s (2003) approach such that it only considers sub-
graphs that can actually be realized, because their al-
gorithm proceeds by a genuine search for uniquely
identifying subgraphs, and will simply take a differ-
ent branch of the search if some subgraph is useless.
This would be harder in our case. Our algorithms
don?t search in the same way; if we disallow certain
refinements of a partition, we have to allow the al-
gorithms to backtrack and thus jeopardize the worst-
case polynomial runtime. Investigating this inter-
play between efficiency and linguistic constraints is
an interesting avenue for future research.
5 A unified perspective on GRE
Viewing GRE as a problem of generating DL for-
mulas offers a unified perspective: It is the prob-
lem of computing a DL formula with a given exten-
sion. Many existing approaches can be subsumed
under this view; we have summarized this for some
of them in Fig. 5, along with the DL fragment they
use. We already discussed some of these approaches
in Section 3. Furthermore, the non-relational but
negative and disjunctive descriptions generated by
van Deemter (2002) are simply formulas of PL;
and Gardent (2002) generalizes this into generating
formulas of ELU (?), i.e., EL plus disjunction and
atomic negation. The approach presented here fits
well into this landscape, and it completes the pic-
ture by showing how to generate REs inALC, which
combines all connectives used in any of these previ-
ous approaches.
Where our approach breaks new ground is in the
way these formulas are computed: It successively
refines a decomposition of the domain into subsets.
In this way, it is reminiscent of the Incremental Al-
gorithm, which in fact can be seen as a special case
of the EL algorithm. However, unlike Dale and
Haddock (1991) and its successors, such as Kelle-
her and Kruijff (2006), we do not have to take spe-
cial precautions to avoid infinite regress. While Dale
and Haddock?s algorithm attempts to generate a RE
for a single individual, for successive individuals in
the model, our algorithms consider all individuals in
GRE algorithm DL variant
Dale and Reiter (1995) CL
van Deemter (2002) PL
Dale and Haddock (1991) EL
Kelleher and Kruijff (2006) EL
Gardent (2002) ELU (?)
Figure 5: DL variants used by different GRE algorithms.
parallel. It monotonically refines a partition of the
model and never needs to backtrack, and therefore
is always guaranteed to terminate.
Perhaps closest in spirit to our approach is Krah-
mer et al?s graph algorithm (2003), which also com-
putes REs by extending them successively. How-
ever, their subgraphs go beyond the expressive
power of ALC in that they can distinguish between
?the dog that bites a dog? and ?the dog that bites it-
self?. The price they pay for this increase in expres-
sive power is an NP-complete worst-case complex-
ity. Interestingly, Krahmer et al themselves discuss
the possibility of seeing their subgraphs as formu-
las of hybrid logic which are satisfied at the points
where the subgraph can be embedded; and hybrid
logics can be seen as very expressive description
logics (Areces and ten Cate, 2006).
6 Conclusion
In this paper, we have explored the idea of view-
ing the generation of singular REs as the problem
of computing a DL formula with a given extension.
We have shown how such formulas can be computed
efficiently (for ALC and EL) by adapting existing
algorithms from the literature. The EL algorithm
is able to generate 95% of the non-relational and
67% of the relational REs from Viethen and Dale
(2006). Both algorithms are extremely efficient (350
ms and 140 ms respectively to generate relational
REs for all individuals in a random model with 100
individuals); to our knowledge, these are by far the
fastest runtimes for relational GRE reported in the
literature. We have made our implementation avail-
able online at http://code.google.com/p/
crisp-nlg/wiki/DlGre.
Because they compute referring expressions for
all individuals in the domain at once, our algorithms
will perform especially strongly in static settings,
such as the generation of descriptions for museum
48
exhibits, in which the individuals and their proper-
ties don?t change much. However, even in more dy-
namic settings, our algorithms have a chance to out-
perform search algorithms like Dale and Haddock?s
in the average case because they can?t get stuck in
unproductive branches of the search space. Never-
theless, one interesting question for future research
is how to incrementally update simulation classes
when the model changes. Similarly, it would be
interesting to explore how different linguistic con-
straints and attribute orderings can be taken into ac-
count efficiently, how our algorithms could be in-
tegrated with more standard DL T-Box inferences,
and how they can be adapted to use inverse relations
or to compute REs for sets. In exploring these ex-
tensions we will be able to draw on a rich body of
literature that has already considered many variants
of simulation algorithms addressing similar issues.
In experimenting with the Viethen and Dale data,
we found that there is no single ordering that covers
all human-produced descriptions, which seems to be
in contrast to Dale and Reiter?s (1995) assumption
that there is only one ordering for each given do-
main. In fact, it is not even the case that each speaker
consistently uses just one ordering. An interesting
open research question is thus what factors deter-
mine which ordering is used. Unfortunately, both
in the Viethen and Dale dataset and in the TUNA
corpus (van Deemter et al, 2006), only a minor-
ity of referring expressions is relational, maybe be-
cause these domains lend themselves very well to
row/column style propositional REs. We are cur-
rently collecting REs in a domain in which propo-
sitional REs are less preferred.
Acknowledgments. We are grateful to Hector
Geffner (who independently suggested to view GRE as
computation of DL formulas), Kees van Deemter, and
Emiel Krahmer for interesting discussions. We also
thank Jette Viethen and Robert Dale for making their
corpus available, and the reviewers for their comments.
References
C. Areces and B. ten Cate. 2006. Hybrid logics. In
P. Blackburn, F. Wolter, and J. van Benthem, editors,
Handbook of Modal Logics. Elsevier.
F. Baader, D. McGuiness, D. Nardi, and P. Patel-
Schneider, editors. 2003. The Description Logic
Handbook: Theory, implementation and applications.
Cambridge University Press.
P. Blackburn, M. de Rijke, and Y. Venema. 2001. Modal
Logic. Cambridge University Press.
R. Dale and N. Haddock. 1991. Generating referring
expressions involving relations. In Proc. of the 5th
EACL.
R. Dale and E. Reiter. 1995. Computational interpreta-
tions of the Gricean maxims in the generation of refer-
ring expressions. Cognitive Science, 19.
R. Dale. 1989. Cooking up referring expressions. In
Proc. of the 27th ACL.
A. Dovier, C. Piazza, and A. Policriti. 2004. An ef-
ficient algorithm for computing bisimulation equiva-
lence. Theoretical Computer Science, 311(1?3).
C. Gardent and K. Striegnitz. 2007. Generating bridg-
ing definite descriptions. In H. Bunt and R. Muskens,
editors, Computing Meaning, Vol. 3. Springer.
C. Gardent. 2002. Generating minimal definite descrip-
tions. In Proc. of the 40th ACL.
J. Hopcroft. 1971. An n log(n) algorithm for minimizing
states in a finite automaton. In Z. Kohave, editor, The-
ory of Machines and computations. Academic Press.
H. Horacek. 1997. An algorithm for generating refer-
ential descriptions with flexible interfaces. In Proc. of
the 35th ACL.
J. Kelleher and G.-J. Kruijff. 2006. Incremental genera-
tion of spatial referring expressions in situated dialog.
In Proc. of COLING/ACL.
A. Koller and M. Stone. 2007. Sentence generation as
planning. In Proc. of the 45th ACL.
E. Krahmer, S. van Erk, and A. Verleg. 2003. Graph-
based generation of referring expressions. Computa-
tional Linguistics, 29(1).
N. Kurtonina and M. de Rijke. 1998. Expressiveness
of concept expressions in first-order description logics.
Artificial Intelligence, 107.
R. Paige and R. Tarjan. 1987. Three partition refinement
algorithms. SIAM Journal on Computing, 16(6).
M. Stone and B. Webber. 1998. Textual economy
through close coupling of syntax and semantics. In
Proc. of the 9th INLG workshop.
M. Stone. 2000. On identifying sets. In Proc. of the 1st
INLG.
K. van Deemter, I. van der Sluis, and A. Gatt. 2006.
Building a semantically transparent corpus for the gen-
eration of referring expressions. In Proc. of the 4th
INLG.
K. van Deemter. 2002. Generating referring expres-
sions: Boolean extensions of the incremental algo-
rithm. Computational Linguistics, 28(1):37?52.
J. Viethen and R. Dale. 2006. Algorithms for generating
referring expressions: Do they do what people do? In
Proc. of the 4th INLG.
49
