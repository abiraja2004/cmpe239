Proceedings of the ACL-2012 Special Workshop on Rediscovering 50 Years of Discoveries, pages 42?54,
Jeju, Republic of Korea, 10 July 2012. c?2012 Association for Computational Linguistics
Discourse Structure and Computation: Past, Present and Future
Bonnie Webber
School of Informatics
University of Edinburgh
Edinburgh UK EH8 9AB
bonnie.webber@ed.ac.uk
Aravind Joshi
Dept of Computer & Information Science
University of Pennsylvania
Philadelphia PA 19104-6228
joshi@seas.upenn.edu
Abstract
The discourse properties of text have long
been recognized as critical to language tech-
nology, and over the past 40 years, our un-
derstanding of and ability to exploit the dis-
course properties of text has grown in many
ways. This essay briefly recounts these de-
velopments, the technology they employ, the
applications they support, and the new chal-
lenges that each subsequent development has
raised. We conclude with the challenges faced
by our current understanding of discourse, and
the applications that meeting these challenges
will promote.
1 Why bother with discourse?
Research in Natural Language Processing (NLP) has
long benefitted from the fact that text can often be
treated as simply a bag of words or a bag of sen-
tences. But not always: Position often matters ?
e.g., It is well-known that the first one or two sen-
tences in a news report usually comprise its best ex-
tractive summary. Order often matters ? e.g., very
different events are conveyed depending on how
clauses and sentences are ordered.
(1) a. I said the magic words, and a genie ap-
peared.
b. A genie appeared, and I said the magic
words.
Adjacency often matters ? e.g., attributed mate-
rial may span a sequence of adjacent sentences,
and contrasts are visible through sentence juxtaposi-
tion. Context always matters ? e.g., All languages
achieve economy through minimal expressions that
can only convey intended meaning when understood
in context.
Position, order, adjacency and context are intrin-
sic features of discourse, and research on discourse
processing attempts to solve the challenges posed by
context-bound expressions and the discourse struc-
tures that give rise, when linearized, to position, or-
der and adjacency.
But challenges are not why Language Technol-
ogy (LT) researchers should care about discourse:
Rather, discourse can enable LT to overcome known
obstacles to better performance. Consider auto-
mated summarization and machine translation: Hu-
mans regularly judge output quality in terms that in-
clude referential clarity and coherence. Systems can
only improve here by paying attention to discourse
? i.e., to linguistic features above the level of n-
grams and single sentences. (In fact, we predict that
as soon as cheap ? i.e., non-manual ? methods are
found for reliably assessing these features ? for ex-
ample, using proxies like those suggested in (Pitler
et al., 2010) ? they will supplant, or at least com-
plement today?s common metrics, Bleu and Rouge
that say little about what matters to human text un-
derstanding (Callison-Burch et al., 2006).)
Consider also work on automated text simplifica-
tion: One way that human editors simplify text is
by re-expressing a long complex sentence as a dis-
course sequence of simple sentences. Researchers
should be able to automate this through understand-
ing the various ways that information is conveyed
in discourse. Other examples of LT applications
already benefitting from recognizing and applying
discourse-level information include automated as-
sessment of student essays (Burstein and Chodorow,
2010); summarization (Thione et al., 2004), infor-
42
mation extraction (Patwardhan and Riloff, 2007;
Eales et al., 2008; Maslennikov and Chua, 2007),
and more recently, statistical machine translation
(Foster et al., 2010). These are described in more
detail in (Webber et al., 2012).
Our aim here then, on this occasion of ACL?s 50th
Annual Meeting, is to briefly describe the evolution
of computational approaches to discourse structure,
reflect on where the field currently stands, and what
new challenges it faces in trying to deliver on its
promised benefit to Language Technology.
2 Background
2.1 Early Methods
The challenges mentioned above are not new.
Question-Answering systems like LUNAR (Woods,
1968; Woods, 1978) couldn?t answer successive
questions without resolving context-bound expres-
sions such as pronouns:
(2) What is the concentration of silicon in brec-
cias?
?breccia1, parts per million?
?breccia2, parts per million?
? . . . ?
What is it in volcanics? (Woods, 1978)
Early systems for human interaction with animated
agents, including SHRDLU (Winograd, 1973) and
HOMER (Vere and Bickmore, 1990), faced the
same challenge. And early message understand-
ing systems couldn?t extract relevant information
(like when a sighted submarine submerged ? ?went
sinker?) without recognizing relations implicit in the
structure of a message, as in
(3) VISUAL SIGHTING OF PERISCOPE FOL-
LOWED BY ATTACK WITH ASROC AND TOR-
PEDO. WENT SINKER. LOOSEFOOT 722/723
CONTINUE SEARCH. (Palmer et al., 1993)
The same was true of early systems for processing
narrative text (under the rubric story understanding).
They took on the problem of recognizing events that
had probably happened but hadn?t been mentioned
in the text, given the sequence of events that had
been (Lehnert, 1977; Rumelhart, 1975; Schank and
Abelson, 1977; Mandler, 1984).
Since these early systems never saw more than
a handful of examples, they could successfully em-
ploy straight-forward, but ad hoc methods to handle
the discourse problems the examples posed. For ex-
ample, LUNAR used a single 10-position ring buffer
to store discourse entities associated with both the
user?s and the system?s referring expressions, resolv-
ing pronouns by looking back through the buffer
for an appropriate entity and over-writing previous
buffer entries when the buffer was full.
The next wave of work in computational dis-
course processing sought greater generality through
stronger theoretical grounding, appealing to then-
current theories of discourse such as Centering The-
ory (Grosz et al., 1986; Grosz et al., 1995), used as
a basis for anaphor resolution (Brennan et al., 1987;
Walker et al., 1997; Tetreault, 2001) and text genera-
tion (Kibble and Power, 2000), Rhetorical Structure
Theory (Mann and Thompson, 1988), used as a ba-
sis for text generation (Moore, 1995) and document
summarization (Marcu, 2000b), and Grosz and Sid-
ner?s theory of discourse based on intentions (Grosz
and Sidner, 1986a) and shared plans (Grosz and
Sidner, 1990), used in developing animated agents
(Johnson and Rickel, 2000). Issues related to fully
characterizing centering are explored in great detail
in (Kehler, 1997) and (Poesio et al., 2004).
The approaches considered during this period
never saw more than a few handfuls of examples.
But, as has been clear from developments in PoS-
tagging, Named Entity Recognition and parsing,
Language Technology demands approaches that can
deal with whatever data are given them. So subse-
quent work in computational discourse processing
has similarly pursued robustness through the use of
data-driven approaches that are usually able to cap-
ture the most common forms of any phenomenon
(ie, the 80% at the high end of the Zipfian distri-
bution), while giving up on the long tail. This is
described in Section 3.
2.2 Early Assumptions
While early work focussed on the correct assump-
tion that much was implicit in text and had to be
inferred from the explicit sequence of sentences that
constituted a text, work during the next period fo-
cussed on the underlying structure of discourse and
its consequences. More specificaly, it assumed that
the sequence of sentences constituting the text were
covered by a single tree structure, similar to the sin-
gle tree structure of phrases and clauses covering the
43
s1 s2
s3
condition
condition
s1
s2 s3motivation
motivation
(a) (b)
Figure 1: Proposed discourse structures for Ex. 4: (a) In
terms of informational relations; (b) in terms of inten-
tional relations
words in a sentence. At issue though was the nature
of the structure.
One issue concerned the nature of the relation be-
tween parent and child nodes in a discourse tree,
and/or the relation between siblings. While Rhetor-
ical Structure Theory (Mann and Thompson, 1988)
posited a single discourse relation holding between
any two discourse units (i.e., units projecting to ad-
jacent text spans), Moore and Pollack (1992) gave an
example of a simple discourse (Ex. 4) in which dif-
ferent choices about the discourse relation holding
between pairs of units, implied different and non-
isomorphic structures.
(4) Come home by 5:00. s1 Then we can go to the
hardware store before it closes. s2 That way we
can finish the bookshelves tonight. s3
Example 4 could be analysed purely in terms of
information-based discourse relations, in which s1
specified the CONDITION under which s2 held,
which in turn specified the CONDITION under which
s3 held. This would make s1 subordinate to s2,
which in turn would be subordinate to s3, as in Fig-
ure 1a. Alternatively, Example 4 could be analysed
purely in terms of intention-based (pragmatic) rela-
tions, in which s2 would be MOTIVATION for s1,
while s3 would be MOTIVATION for s2. This would
make s3 subordinate to s2, which in turn would be
subordinate to s1, as in Figure 1b. In short, the
choice of relation was not merely a matter of labels,
but had structural implications as well.
Another issue during this period concerned the
nature of discourse structure: Was it really a tree?
Sibun (1992), looking at people?s descriptions of the
layout of their house or apartment, argued that they
resembled different ways of linearizing a graph of
the rooms and their connectivity through doors and
halls. None of these linearizations were trees. Sim-
ilarly, Knott et al. (2001), looking at transcriptions
of museum tours, argued that each resembled a lin-
ear sequence of trees, with one or more topic-based
connections between their root nodes ? again, not
a single covering tree structure. Wiebe (1993), look-
ing at simple examples such as
(5) The car was finally coming toward him. s1
He finished his diagnostic tests, s2
feeling relief. s3
But then the car started to turn right. s4
pointed multiple lexical items explicitly relating a
clause to multiple other clauses. Here, but would
relate s4 to s3 via a CONTRAST relation, while then
would relate s4 to s2 via a temporal SUCCESSION
relation.
The most well-known of work from this period
is that of Mann and Thompson (1988), Grosz and
Sidner (1986b), Moore and Moser (1996), Polanyi
and van den Berg (1996), and Asher and Lascarides
(2003).1
The way out of these problems was also a way
to achieve the robustness required of any Language
Technology, and that lay in the growing consensus
towards the view that discourse does not have a sin-
gle monolithic hierarchical structure. Rather, dif-
ferent aspects of a discourse give rise to different
structures, possibly with different formal properties
(Stede, 2008; Stede, 2012; Webber et al., 2012).
These different structures we describe in the next
section, while the fact that this can?t be the end of
the story, we take up in Section 4.
3 The Situation Today
Recent years have seen progress to differing degrees
on at least four different types of discourse struc-
tures: topic structure, functional structure, event
structure, and a structure of coherence relations.
First we say a bit about the structures, and then about
the resources employed in recognizing and labelling
them.
3.1 Types of discourse structures
Topic structure and automated topic segmentation
aims to break a discourse into a linear sequence of
1For a historical account and assessent of work in automated
anaphora resolution in this period and afterwards, we direct the
reader to Strube (2007), Ng (2010) and Stede (2012).
44
topics such the geography of a country, followed by
its history, its demographics, its economy, its legal
structures, etc. Segmentation is usually done on a
sentence-by-sentence basis, with segments not as-
sumed to overlap. Methods for topic segmenation
emply semantic, lexical and referential similarity
or, more recently, language models (Bestgen, 2006;
Chen et al., 2009; Choi et al., 2001; Eisenstein and
Barzilay, 2008; Galley et al., 2003; Hearst, 1997;
Malioutov and Barzilay, 2006; Purver et al., 2006;
Purver, 2011).
Functional structure and automated functional
segmentation aims to identify sections within a dis-
course that serve different functions. These func-
tions are genre-specific. In the case of scien-
tific journals, high-level sections generally include
the Background (work that motivates the objec-
tives of the work and/or the hypothesis or claim
being tested), followed by its Methods, and Re-
sults, ending with a Discussion of the results or out-
comes, along with conclusions to be drawn. Finer-
grained segments might include the advantage of
a new method (method-new-advantage) or of an
old method (method-old-advantage) or the disad-
vantage of one or the other (Liakata et al., 2010).
Again, segmentation is usually done on a sentence-
by-sentence basis, with sentences not assumed to
fill more than one function. Methods for functional
segmentation have employed specific cue words and
phrases, as well as more general language models
(Burstein et al., 2003; Chung, 2009; Guo et al.,
2010; Kim et al., 2010; Lin et al., 2006; McKnight
and Srinivasan, 2003; Ruch et al., 2007; Mizuta
et al., 2006; Palau and Moens, 2009; Teufel and
Moens, 2002; Teufel et al., 2009; Agarwal and Yu,
2009). The BIO approach to sequential classica-
tion (Beginning/Inside/Outside) used in Named En-
tity Recognition has also proved useful (Hirohata
et al., 2008), recognizing that the way the start of
a functional segement is signalled may differ from
how it is continued.
Note that topic segmentation and functional seg-
mentation are still not always distinguished. For
example, in (Jurafsky and Martin, 2009), the term
discourse segmentation is used to refer to any seg-
mentation of a discourse into a ?high-level? linear
structure. Nevertheless, segmentation by function
exploits different features (and in some cases, dif-
ferent methods) than segmentation by topic, so they
are worth keeping distinct.
Attention to event structure and the identification
of events within a text is a more recent phenomena,
after a hiatus of over twenty years. Here we just
point to work by (Bex and Verheij, 2010; Cham-
bers and Jurafsky, 2008; Do et al., 2011; Finlayson,
2009).
The automated identification of discourse rela-
tions aims to identify discourse relations such as
CONDITION and MOTIVATION, as in Example 4,
and CONTRAST and SUCCESSION, as in Exam-
ple 5. These have also been called coherence re-
lations or rhetorical relations. Methods used de-
pend on whether or not a text is taken to be divisible
into a covering sequence of a non-overlapping dis-
course units related to adjacent units by discourse
relations as in Rhetorical Structure Theory (Mann
and Thompson, 1988) or to both adjacent and non-
adjacent units as in the Discourse GraphBank (Wolf
and Gibson, 2005). If such a cover is assumed,
methods involve parsing a text into units using lex-
ical and punctuational cues, followed by labelling
the relation holding between them (Marcu, 2000a;
Marcu, 2000b; Wolf and Gibson, 2005). If text is
not assumed to be divisible into discourse units, then
methods involve finding evidence for discourse re-
lations (including both explicit words and phrases,
and clausal and sentential adjacency) and their ar-
guments, and then labelling the sense of the iden-
tified relation (Elwell and Baldridge, 2008; Ghosh
et al., 2011; Lin et al., 2010; Lin, 2012; Prasad et
al., 2010a; Wellner, 2008; Wellner and Pustejovsky,
2007).
3.2 Resources for discourse structure
All automated systems for segmenting and labelling
text are grounded in data ? whether the data has
informed the manual creation of rules or has been
a source of features for an approach based on ma-
chine learning. In the case of topic structure and
high-level functional structure, there is now a sub-
stantial amount of data that is freely available. For
other types of discourse structure, manual annota-
tion has been required and, depending on the type of
structure, different amounts are currently available.
More specifically, work on topic structure and
segmentation has been able to take advantage of the
45
large, free, still-growing wikipedia, where articles
on similar topics tend to show similar explicit seg-
mentation into sub-topics. This is certainly the case
with the English wikipedia. If similar wikipedia
evolving in other languages lack explicit segmenta-
tion, it may be that cross-lingual techniques may be
able to project explicit segmentation from English-
language articles.
With respect to high-level functional structure,
some work on automated segmentation has been
able to exploit explicit author-provided indicators
of structure, such as the author-structured abstracts
now required by bio-medical journals indexed by
MedLine. Researchers have used these explicitly
structured abstracts to segment abstracts that lack
explicit structure (Chung, 2009; Guo et al., 2010;
Hirohata et al., 2008; Lin et al., 2006).
For all other kinds of discourse structures, ded-
icated manual annotation has been required, both
for segmentation and labelling, and many of these
resources have been made available for other re-
searchers. For fine-grained functional structure,
there is the ART corpus (Liakata et al., 2010)2.
For discourse relations annotated in the RST
framework, there is the RST Discourse TreeBank of
English text (Carlson et al., 2003), available through
the Linguistic Data Consortium (LDC), as well as
similarly annotated corpora in Spanish (da Cunha et
al., 2011), Portugese (Pardo et al., 2008) and Ger-
man (Stede, 2004).
For discourse relations annotated in the lexically-
grounded approach first described in (Webber and
Joshi, 1998), there is the Penn Discourse TreeBank
(Prasad et al., 2008) in English, as well as corpora
in Modern Standard Arabic (Al-Saif and Markert,
2010; Al-Saif and Markert, 2011), Chinese (Xue,
2005; Zhou and Xue, 2012), Czech (Mladova? et al.,
2008), Danish (Buch-Kromann et al., 2009; Buch-
Kromann and Korzen, 2010), Dutch (van der Vliet
et al., 2011), Hindi (Oza et al., 2009), and Turk-
ish (Zeyrek and Webber, 2008; Zeyrek et al., 2009;
Zeyrek et al., 2010). Also available are discourse-
annotated journal articles in biomedicine (Prasad et
al., 2011) and discourse-annotated dialogue (Tonelli
et al., 2010).
2http://www.aber.ac.uk/en/cs/research/cb/projects/art/art-
corpus/
4 New challenges
Although the largely empirically-grounded, multi-
structure view of discourse addresses some of the
problems that previous computational approaches
encountered, it also reveals new ones, while leaving
some earlier problems still unaddressed.
4.1 Evidence for discourse structures
The first issue has to do with what should be taken as
evidence for a particular discourse structure. While
one could simply consider all features that can be
computed reliably and just identify the most accu-
rate predictors, this is both expensive and, in the end,
unsatisfying.
With topic structure, content words do seem to
provide compelling evidence for segmentation, ei-
ther using language models or semantic relatedness.
On the other hand, this might be improved through
further evidence in the form of entity chains, as ex-
plored earlier in (Kan et al., 1998), but using to-
day?s more accurate approaches to automated coref-
erence recognition (Strube, 2007; Charniak and El-
sner, 2009; Ng, 2010).
Whatever the genre, evidence for function struc-
ture seems to come from the frequency and distri-
bution of closed-class words, particular phrases (or
phrase patterns), and in the case of speech, into-
nation. So, for example, Niekrasz (2012) shows
that what he calls participant-relational features
that indicate the participants relationships to the
text provide convincing evidence for segmenting
oral narrative by the type of narrative activity tak-
ing place. These features include the distribution
and frequency of first and second person pronouns,
tense, and intonation. But much work remains to
be done in this area, in establishing what provides
reliable evidence within a genre and what evidence
might be stable across genres.
Evidence for discourse relations is what we have
given significant thought to, as the Penn Discourse
TreeBank (Prasad et al., 2008) and related corpora
mentioned in Section 3.2 aim to ground each in-
stance of a discourse relation in the evidence that
supports it. The issue of evidence is especially
important because none of these corpora has yet
been completely annotated with discourse relations.
Completing the annotation and developing robust
46
automated segmentation techniques requires iden-
tifying what elements of the language provide evi-
dence for coherence relations, and under what con-
ditions.
The two main types of evidence for discourse re-
lations in English are the presence of a discourse
connective and sentence adjacency. Discourse con-
nectives annotated in the PDTB 2.0 come from
a list of subordinating and coordinating conjunc-
tions, and discourse adverbials ? a subset of those
identified by Forbes-Riley et al (2006). Subse-
quently, Prasad et al. (2010b) used Callison-Burch?s
technique for identifying syntax-constrained para-
phrases (Callison-Burch, 2008) to identify addi-
tional discourse connectives, some of which don?t
appear in the PDTB corpus and some of which
appear in the corpus but were not identified and
annotated as discourse connectives. English isn?t
alone in lacking a complete list of discourse con-
nectives: While German has the massive Hand-
buch de deutschen Konnektoren (Pasch et al., 2003),
even this resource has been found to be incomplete
through clever application of automated tagging and
word-alignment of parallel corpora (Versley, 2010).
Evidence for discourse relations in the PDTB also
comes from lexical or phrasal elements that are out-
side the initial set of conjunctions and discourse ad-
verbials. This evidence has been called alternative
lexicalization or AltLex (Prasad et al., 2010b), and
includes (in English) clause-initial what?s more (Ex-
ample 6) and that means (Example 7).
(6) A search party soon found the unscathed air-
craft in a forest clearing much too small to have
allowed a conventional landing. What?s more,
the seven mail personnel aboard were missing.
[wsj 0550]
(7) The two companies each produce market
pulp, containerboard and white paper. That
means goods could be manufactured closer
to customers, saving shipping costs, he said.
[wsj 0317]
The discovery of these other forms of evidence3
raises the question of when it is that a word or phrase
signals a discourse relation. For example, only 15 of
the 33 tokens of that means in the PDTB were anno-
tated as evidence of a discourse relation. While the
3which English is not alone in having, cf. (Rysova, 2012)
three paragraph-initial instances were left unanno-
tated due to resource limitations (ie, no paragraph
initial sentences were annotated unless they con-
tained an explicit discourse connective), the major-
ity were ignored because they followed an explicit
connective.
As Wiebe?s example (5) showed, there can be
multiple explicit discourse connectives in a clause,
each of which is evidence for a separate discourse re-
lation (albeit possibly between the same arguments).
All of these are annotated in the PDTB ? eg, both but
and then in
(8) Congress would have 20 days to reject the
package with a 50% majority, but then a Presi-
dent could veto that rejection. [wsj 1698]
The question is whether an AltLex in the context of
an explicit connective also provides evidence of a
distinct discourse relation ? for example, with the
conjunction with But in
(9) At a yearling sale, a buyer can go solo and get
a horse for a few thousand dollars. But that
means paying the horse?s maintenance; on av-
erage, it costs $25,000 a year to raise a horse.
[wsj 1174]
As noted above, the PDTB 2.0 also admits sen-
tence adjacency as evidence for one, or even two,
implicit discourse relations, as in
(10) And some investors fault Mr. Spiegel?s life
style; [Implicit = because, for instance] he
earns millions of dollars a year and flies
around in Columbia?s jet planes. [wsj 0179]
Here, the implicit token of because is associ-
ated with a discourse relation labelled CONTIN-
GENCY.CAUSE.REASON, while the implicit token
of for instance is associated with one labelled EX-
PANSION.RESTATEMENT.SPECIFICATION.
The question is whether sentence adjacency could
also serve as evidence for a distinct discourse rela-
tion, even when there is also an explicit discourse
adverbial, as in the following three instances of in-
stead. Here, Ex. 11 can be paraphrased as And in-
stead, Ex. 12 as But instead, and Ex.13 as So in-
stead.
(11) But many banks are turning away from strict
price competition. Instead, they are trying to
47
build customer loyalty by bundling their ser-
vices into packages and targeting them to small
segments of the population. [wsj 0085]
(12) The tension was evident on Wednesday
evening during Mr. Nixon?s final banquet
toast, normally an opportunity for reciting plat-
itudes about eternal friendship. Instead, Mr.
Nixon reminded his host, Chinese President
Yang Shangkun, that Americans haven?t for-
given China?s leaders for the military assault
of June 3-4 that killed hundreds, and perhaps
thousands, of demonstrators. [wsj 0093]
(13) Since stars are considerably more massive than
planets, such wobbles are small and hard to
see directly. Instead, Dr Marcy and others like
him look for changes that the wobbles cause in
the wavelength of the light from the star. [The
Economist, 10 November 2007]
These examples suggest that the presence of an
explicit connective should not, in all cases, be con-
sidered evidence for the absense of an implicit con-
nective. Once the set of explicit connectives have
been identified that can co-occur with each other
(including for example and for instance, as well as
instead), automated parsers for coherence relations
can be made to consider the presence of an implicit
connective whenever one of these is seen.
4.2 Variability in discourse annotation
Another issue relates to variability in annotating dis-
course structure: Inter-annotator agreement can be
very low in annotating pragmatic and discourse-
related phenomena. While we will illustrate the
point here in terms of annotating coherence rela-
tions, for other examples, the general point is illus-
trated in papers from the DGfS Workshop on Beyond
Semantics4 and in an upcoming special issue of the
journal Discourse and Dialogue devoted to the same
topic.
The Penn Wall Street Journal corpus contains
twenty-four (24) reports of errata in previously-
appearing articles. Twenty-three (23) consist of a
single pair of sentences, with no explicit discourse
connective signalling the relation between them.5
4http://www.linguistics.ruhr-uni-bochum.de/beyondsem/
5The other report contains three sentences, again with no
explicit connectives.
One sentence reports the error, and the other, the cor-
rect statement ? e.g.
(14) VIACOM Inc.?s loss narrowed to $21.7 million
in the third quarter from $56.9 million a year
ago. Thursday?s edition misstated the narrow-
ing. [wsj 1747]
In twenty of the errata (class C1), the correct
statement is given in the first sentence and the er-
ror, in the second; In the other three (class C2), it is
the other way around. One might think that the two
sentences in the twenty C1 reports would be anno-
tated as having the same discourse relation holding
between them, and the same with the two sentences
in the three C2 reports. But that is not the case: The
twenty C1 reports presented to annotators at differ-
ent times ended up being labelled with six different
discourse relations. There was even variability in
labelling the three members of the C2 class: They
were labelled with one discourse relation, and one
with a completely different one.
What should one conclude from this variability?
One possibility is that there is one right answer,
and annotators just vary in their ability to iden-
tify it. This would mean it would be beneficial to
have a large troop of annotators (so that the major-
ity view could prevail). Another possibility is that
there is more than one right answer, which would
imply multi-label classification so that multiple la-
bels could hold to different degrees. A third possi-
bility reflects the view from Beyond Semantics that
it is often very hard to transfer results from theoreti-
cal linguistics based on toy examples to naturally-
occurring texts. In this case, variability is a con-
sequence of the still exploratory nature of much
discourse annotation. In the case of errata, while
clearly some relation holds between the pair of sen-
tences, it may actually not be any of those used in
annotating the PDTB. That is, as Grosz and Sidner
(1986b) argued several years ago, the sentences may
only be related by their communicative intentions ?
one sentence intended to draw the reader?s attention
to the specific error that was made (so that the reader
knows what was mis-stated), the other intended to
correct it. One might then take the sense annotation
of discourse relations as still exploratory in the wide
range of corpora being annotated with this informa-
tion (cf. Section 3.2).
48
4.3 Systematic relations between discourse
structures
Fortunately for approaches to automated discourse
structure recognition, the lack of isomorphism be-
tween different discourse structures does not neces-
sarily mean that they are completely independent.
This belief that different aspects of discourse would
be related, is what led Grosz and Sidner (1986b) to
propose a theory that linked what they called the in-
tentional structure of discourse, with its linguistic
structure and with the reader or listener?s cognitive
attentional structure.
With respect to the different types of discourse
structure considered here, (Lin, 2012) has consid-
ered the possibility of systematic relations between
Teufel?s Argumentative Zone labelling of scientific
texts in a corpus developed for her PhD thesis
(Teufel, 1999) and PDTB-style discourse relations,
both within and across sentences. This is certainly
worth additional study, for the value it can bring to
automated methods of discourse structure recogni-
tion.
4.4 Intentional structure
When computational discourse processing turned
to machine learning methods based on reliably-
identifiable features, it abandoned (at least temporar-
ily) the centrality of pragmatics and speaker in-
tentions to discourse. That is, there were few or
no features that directly indicated or could serve
as reliable proxies for what role speaker intended
his/her utterance to play in the larger discourse. But
both Niekrasz? work on meeting segmentation (Sec-
tion 4.1) and the discussion in Section 4.2 of errata
and variability in their labelling draws new attention
to this old question, and not just to Moore and Pol-
lack?s observation (Section 3) that intentional and
informational characterizations may confer differ-
ent, non-isomorphic structures over a text. It may
also be the case that neither structure may provide a
complete cover: A new visit is warranted.
4.5 Discourse and inference
Not only were intentions abandoned in the move
to data-intensive methods, so was inference and is-
sues of how readers and listeners recover informa-
tion that isn?t explicit. What?s missing can be an
unmentioned event, with classic examples coming
from the restaurant script (Lehnert, 1977), where
someone enters a restaurant, sits down at a ta-
ble and gives their order to a waiter, where un-
mentioned inter alia is an event in which the per-
son becomes informed of what items the restaurant
has to offer, say through being given a menu. Or
it can be an unmentioned fact, such as that pro-
gram trading involves the computer-executed trad-
ing of a basket of fifteen or more stocks. The
latter explains the annotation of an implicit EX-
PANSION.RESTATEMENT.GENERALIZATION rela-
tion between the two sentences in
(15) ?You?re not going to stop the idea of trading a
basket of stocks,? says Vanderbilt?s Prof. Stoll.
?Program trading is here to stay, and computers
are here to stay, and we just need to understand
it.? [wsj 0118]
The problem here with inference is when labelling
an implicit coherence relation requires inferred in-
formation about its arguments, those arguments may
have quite different features than when all the infor-
mation needed to label the relation is explicit.
5 Conclusion
There are still large challenges ahead for compu-
tational discourse modelling. But we are hopeful
that greater openness to how information is con-
veyed through discourse, as well as richer modelling
techniques developed for other problems, will allow
needed progress to be made. If we can improve sys-
tem performance in recognizing the roles that utter-
ances are meant to play in discourse in one genre,
perhaps it will help us generalize and transport this
intention recognition between genres. We also hope
for progress in finding more ways to take advantage
of unannotated data in discourse research; in un-
derstanding more about inter-dependencies between
features of different types of discourse structure; in
continuing to carry out related computational dis-
course research and development in multiple lan-
guages and genres, so as to widen the access to the
knowledge gained; and in exploiting discourse in
Language Technology applications, including infor-
mation extraction and SMT.
49
References
