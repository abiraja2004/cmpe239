Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 656?666,
MIT, Massachusetts, USA, 9-11 October 2010. c?2010 Association for Computational Linguistics
Example-based Paraphrasing for Improved Phrase-Based
Statistical Machine Translation
Aure?lien Max
LIMSI-CNRS & Univ. Paris Sud
Orsay, France
aurelien.max@limsi.fr
Abstract
In this article, an original view on how to
improve phrase translation estimates is pro-
posed. This proposal is grounded on two main
ideas: first, that appropriate examples of a
given phrase should participate more in build-
ing its translation distribution; second, that
paraphrases can be used to better estimate this
distribution. Initial experiments provide ev-
idence of the potential of our approach and
its implementation for effectively improving
translation performance.
1 Introduction
Phrase translation estimation in Statistical Phrase-
based Translation (Koehn et al, 2003) is hampered
by the availability of both too many and too few
training instances. Recent results on tera-scale SMT
(Lopez, 2008) show that access to many training
examples1 can lead to significant improvements in
translation quality. Also, providing indirect train-
ing instances via synonyms or paraphrases for pre-
viously unseen phrases can result in gains in trans-
lation quality, which are more apparent when little
training data is originally available (Callison-Burch
et al, 2006; Marton et al, 2009; Mirkin et al, 2009;
Aziz et al, 2010). Although there is a consensus on
the importance of using more parallel data in SMT,
it has never been formally shown that all additional
training instances are actually useful in predicting
contextually appropriate translation hypotheses.
1To be more accurate, works such as that of (Lopez, 2008)
have recourse to random sampling to build models of a manage-
able size in a reasonable amount of time.
Attempts at limiting training parallel sentences to
those resembling test data through thematic adapta-
tion (Hildebrand et al, 2005) indeed confirm that
large quantities of training data cannot compen-
sate for the requirement for contextually appropriate
training instances. In fact, it is important that phrase
translation models adequatly reflect contextual pref-
erences for each phrase occurrence in a text. A vari-
ety of recent works have used dynamically adapted
translation models, where each phrase occurrence
has its own translation distribution (Carpuat and Wu,
2007; Stroppa et al, 2007; Max et al, 2008; Gim-
pel and Smith, 2008; Haque et al, 2009) derived
from local contextual information in the training ex-
amples.2 These approaches are supported by the
study of (Wisniewski et al, 2010) which shows that
phrase-based SMT systems are expressive enough to
achieve very high translation performance and there-
fore suggests a better scoring of phrases.
The apparent tradeoff between the number of
training examples and their appropriateness in each
indivual context naturally asks for means of increas-
ing the number of appropriate examples. Exploiting
comparable corpora for acquiring translation equiva-
lents (Munteanu and Marcu, 2005; Abdul-Rauf and
Schwenk, 2009) offers interesting prospects to this
issue, but so far focus has not been so much on con-
text appropriateness as on globally increasing the
number of biphrase examples.
2The study of (Carpuat, 2009) shows that the one transla-
tion per discourse hypothesis holds in some cases, but to our
knowledge no SMT systems have attempted to exploit it yet.
However, in our view, this finding does not contradict the need
for estimating translation distributions at the individual phrase
level, but they should be integrated as additional information.
656
The approach we take in this article is motivated
by the fact that natural language allows for multiple
text views on a given content, and that if two phrases
are good paraphrases in context, then considering
appropriate training examples of one of the phrases
could provide larger quantities of training data for
translating the other. In other words, we hypothe-
size that there may be more training data to learn a
phrase?s translations in a bilingual corpus than what
SMT approaches typically use.
In contrast to previous attempts at using para-
phrases to improve Statistical Machine Translation,
which require external data in the form of additional
parallel bilingual corpora (Callison-Burch et al,
2006), monolingual corpora (Marton et al, 2009),
lexico-semantic resources (Mirkin et al, 2009; Aziz
et al, 2010), or sub-sentential (Resnik et al, 2010)
or sentential paraphrases of the input (Schroeder et
al., 2009), the approach we take here can be endoge-
nous with respect to the original training data. It
also significantly departs from previous work in that
paraphrasing is not simply considered as a way of
finding alternative wordings that can be translated
given the original training data for out-of-vocabulary
phrases only (Callison-Burch et al, 2006; Marton
et al, 2009; Mirkin et al, 2009; Aziz et al, 2010),
but as a means to better estimate translations for any
possible phrase. Also, as opposed to the work by
(Schroeder et al, 2009; Onishi et al, 2010; Du et
al., 2010), we do not encode paraphrases into input
lattices to have them compete against each other to
belong to the source sentential paraphrase that will
lead to the highest scoring output sentence3. Instead,
we make use of all contextually appropriate para-
phrases of a source phrase, which collectively eval-
uate the quality of each translation for that phrase.
This work can thus be seen as a contribution to-
wards shifting from global phrase translation dis-
tributions to contextual translation distributions for
contextually equivalent source units. The remainder
of this paper is organized as followed. In section 2
we review relevant previous works and discuss how
they differ from our approach. Section 3 provides a
description of the details of our approach. We de-
scribe an experimental setup in section 4 and com-
3This highly depends on how well estimated translations for
each independent paraphrase are.
ment on our results. Finally, we discuss our future
work in section 5.
2 Relation to previous work
2.1 Contextual estimation of phrase
translations
In standard approaches to phrase-based SMT, evi-
dence of a translation is accumulated uniformely ev-
ery time it is found associated with a source phrase
in the training corpus. In addition to the fact that
errors in automatic word alignment and non literal
translations often produce useless biphrases, this re-
sults in rare but appropriate translations being very
unlikely to be considered during decoding. Some
approaches on source context modelling (Carpuat
and Wu, 2007; Stroppa et al, 2007; Max et al, 2008;
Haque et al, 2009) build classifiers offline for the
phrases in a test set, so that context similarity can
for example reinforce scores associated with rare
but appropriate translations. However, heavy offline
computation makes scaling to larger corpora an is-
sue. Other approaches (Callison-Burch et al, 2005;
Lopez, 2008) instead focus on accessing very large
corpora. Indexing by suffix arrays is used to allow
fast access to phrase instances in the corpus, and ran-
dom sampling to avoid collecting the full set of ex-
amples has been shown to perform well. However,
these approaches consider all instances of a phrase
as equivalent for the estimation of its translations.
These works converge on the need for accessing
a sufficient number of examples that are relevant for
any source phrase in context, fast enough to permit
on-the-fly phrase table building. This paper pro-
poses an intermediate step: the full set of phrase
examples is found efficiently, and a measure of the
adequacy of each example with a phrase in context
provides evidence for its translation that depends on
this value of adequacy. In this way, the translation
associated with an example for a different sense of
a polysemous word would in the best scenario only
be considered marginally when computing the trans-
lation distribution. As in most previous works, ad-
equacy can be approximated by context similarity
between phrase occurrences and training examples.
Ideally, one would stop extracting examples when
enough appropriate examples have been found to es-
timate a reliable translation distribution. (Callison-
657
sample size 100 500 1K 5K 10k 50k unlim.
BLEU score 28.8 28.8 28.8 28.9 29.1 28.9 29.0
Figure 1: Effect of number of samples on translation
quality (measured on German to English translation on
Europarl data) reported by (Callison-Burch et al, 2005)
Burch et al, 2005) measured the impact on transla-
tion quality of the sample size in random sampling
of source phrase examples in the training corpus to
estimate a phrase?s translation probabilities. As Ta-
ble 1 shows, quality (in terms of BLEU scores) al-
most remains constant for samples of size 100 or
more. This apparent confirmation of the efficiency
of random sampling is backed up by the authors
with the following possible explanations: 1) the
most probable translations remain the same for dif-
ferent sample sizes; 2) misestimated probabilities
are ruled out by the target language model; and
3) longer or less frequent phrases, which are not
affected by sampling, are preferred. However, as
said previously, random sampling cannot guarantee
that contextually-appropriate examples are selected.
In fact, (Lopez, 2008) points out to using discrimi-
natively trained models with contextual features of
source phrases in conjunction with phrase sampling
as an open problem. This work does not attempt to
directly address it, but instead resorts to complete
analysis of the training data to guarantee that all
contextually-appropriate examples are considered.
2.2 Using paraphrases for translating
For some phrases, not enough examples can be
found in the training corpus to estimate reliable
translation probabilities in context. In such cases,
one might be interested in finding more appropri-
ate examples, which seems at first impossible us-
ing the sole original bilingual corpus. We can in
fact consider the set of source phrases that have
similar translations in context. This set is roughly
made up of a subset of what can be referred to as
paraphrases. One possible approach to extract lo-
cal (i.e. phrasal) paraphrases precisely exploits sim-
ilarity on the target side in another language by ex-
tracting source phrases that share common transla-
tions (Bannard and Callison-Burch, 2005), but re-
cent approaches have combined this approach with
Source phrase Paraphrases
Balkan War Balkan war (0.25) Balkans War
(0.125) Balkans (0.125) Balkans
war (0.125) war in the Balkans
(0.125) Balkan conflict (0.125)
British forces British troops (0.29) British
armed forces (0.19)
Czech president President of the Czech Republic
(0.5)
Dalai Lama?s of the Dalai Lama (0.27)
I don?t see I do not believe (0.18) I do not think
(0.18) I do not see (0.15)
Figure 2: Examples of paraphrases obtained by pivoting
via French; values indicate paraphrase probability as de-
fined in (Bannard and Callison-Burch, 2005).
similarity computation in the ?source? (i.e. original)
language (Callison-Burch, 2008; Max, 2008; Kok
and Brockett, 2010). Figure 2 provides examples of
English paraphrases obtained by automatically piv-
oting via French. As can be seen, some examples
would be clearly useful to better estimate transla-
tions of the original source phrase: (Balkan War
? war in the Balkans) are syntactic variants that
can generally substitute with each other, (Balkan
War ? Balkans war) are character-level variants4.
Other examples, however, clearly illustrate the need
for validation in context: (Dalai Lama?s ? of the
Dalai Lama) require different syntactic contexts,
and (I don?t see ? I do not believe) are only inter-
changeable in specific semantic contexts.
Previous attempts at exploiting paraphrases in
SMT have first concentrated on obtaining transla-
tions for phrases absent from the training corpus
(Callison-Burch et al, 2006; Marton et al, 2009;
Mirkin et al, 2009)5, with modest gains in trans-
lation performance as measured by automatic met-
rics. (Callison-Burch et al, 2006) obtain para-
phrases by pivoting via additional bilingual corpora
and use the translations of known paraphrases to
translate unseen phrases, which requires that the ad-
ditional bilingual corpora contain the unseen source
phrases and that some of the extracted paraphrases
be present in the original corpus. (Marton et al,
4To our knowledge, most implementations of SMT decoders
do not integrate flexible matching of phrases.
5The work by (Mirkin et al, 2009) in fact considers both
paraphrases and entailed texts to increase the number of prop-
erly translated texts.
658
2009) proceed similarly but obtain their paraphrases
from comparatively much larger monolingual cor-
pora by following the distributionality hypothesis.
In both cases, gains are only obtained in very spe-
cific conditions where very few training data are
available and where useful additional knowledge can
be brought in from external resources. Furthermore,
the described implementations do not consider ac-
ceptability of the paraphrases in context, as their un-
derlying hypothesis is that it might be more desir-
able to translate some paraphrase than not to trans-
late a given phrase.6 In contrast, the work by (Mirkin
et al, 2009) attempts to model context when using
replacements for words (synonyms or hypernyms).
The natural next step that we take here is to
exploit the complementarity of the original bilin-
gual training corpus for finding paraphrases and the
monolingual (source) side of the same corpus for
validating them in context. Furthermore, our fo-
cus here is not on paraphrasing unseen phrases7, but
possibly any phrase, or any phrase seen less than a
given number of times, or any types of difficult-to-
translate phrases (Mohit and Hwa, 2007).
The recent work of (Resnik et al, 2010)
uses crowdsourcing to obtain paraphrases for
source phrases corresponding to mistranslated target
phrases. The spotting of the incorrect target phrases
and the paraphrasing of the source phrases can be
automated. Promising oracle figures are obtained,
validating the claim that some variations of the input
sentence might be more easily translated than oth-
ers by a given system. Paraphrases have also been
used to represent alternative inputs encoded in lat-
tices using existing (Schroeder et al, 2009) or au-
tomatically built paraphrases (Onishi et al, 2010;
Du et al, 2010). In this scenario, paraphrases are in
fact competing with each other, whereas in our pro-
posal paraphrases collectively participate in evalu-
ating the quality of each translation for a source
phrase. We believe that if two phrases are indeed
paraphrases in context, then their respective set of
translations are both relevant to translate the two
phrases. The target language model nevertheless
still has an important role to play to select appro-
6The default strategy for most decoders is to copy out-of-
vocabulary tokens into the final text.
7Doing it in conjunction with our approach for improving
the translation of known phrases is part of our future work.
priate translations among semantically-compatible
translations (i.e., target side paraphrases) in the spe-
cific context of a generated target hypothesis.
Lastly, automatic sentential paraphrasing has also
been used in SMT to build alternative reference
translations for parameter optimization (Madnani
et al, 2008) and to build alternative training cor-
pora (Bond et al, 2008).
3 Towards better exploitation of training
corpora in phrase-based SMT
In typical phrase-based SMT settings (Koehn et al,
2003), words from the source side of the corpus
are first aligned to words on the target side and
biphrases are extracted from each training sentence
using some heuristics on the word alignments. A
source phrase f in a sentence being translated may
therefore be aligned to a variety of target phrases.
In the example on Figure 3, f is aligned some num-
ber of times in the training corpus to target phrases
e1, e2, e3 and e5. Using the number of times f is
paired with some target phrase ei, count(f, ei), rela-
tive frequency estimation can be used to compute the
probability of translation ei given source phrase f :
prel(ei|f) =
count(f, ei)
?
j count(f, ej)
(1)
This value, together with other estimates of how
appropriate a translation pair (f, ei) is, are recorded
in a phrase table, which typically discards all con-
textual information.8 Therefore, the translation dis-
tribution of some phrase is globally estimated from
a training corpus independently of the actual context
of that phrase.9 On Figure 3, phrase f has at least
two distinct senses: one represented by set E , which
in our example corresponds to the appropriate sense
for a particular occurrence of f in a test sentence;
and one which corresponds to translation e5. A typ-
ical problem, due to the lack of context modeling,
8See (Carpuat and Wu, 2007; Stroppa et al, 2007; Max et
al., 2008; Gimpel and Smith, 2008; Haque et al, 2009) for no-
table exceptions.
9Context is in fact taken into account to some extent by the
target language model, which should score higher translations
that are more appropriate given a target translation hypothesis
being built. In fact, in this work we consider the target language
model as the main source of information for selecting among
acceptable target phrases (target language paraphrases).
659
Figure 3: Example of possible source equivalents and
translations for phrase occurrence f ?un bon avocat? in
the sentence ?L?embauche d?un bon avocat est cruciale
quelle que soit l?activite?? (?Hiring a good lawyer is cru-
cial to any business?). Set E represents target phrase
types that are acceptable translations given the particu-
lar context of f , and set F represents source phrase types
that can be in a paraphrasing relation to f depending on
the context they appear in.
is that in situations such as ?ei ? E , count(f, e5)
count(f, ei), it is very unlikely that a correct trans-
lation will be selected during decoding against the
incorrect but much more frequent one. Taking an
extreme view on this issue, it is in fact desirable that
when estimating phrase translation probabilities for
a phrase f , translations of incompatible senses be
not considered.10 Of course, this raises the diffi-
cult issue of sense clustering of phrases. We propose
here an intermediary solution, which consists in con-
sidering each occurrence in the training corpus as
counting a number of times that depends on its con-
textual similarity with the occurrence of f from the
test file, through the following additional translation
model :
pcont(ei|f) =
?
?fk,ei?
simcont(C(f), C(fk))
?
?fk,ej?
simcont(C(f), C(fk))
(2)
where f is some source phrase to translate and fk
an example of f in the training corpus, ?fk, ei? is a
10Put differently, is it more acceptable to copy a source word
in the target hypothesis or to incorrectly translate it when the
confidence about its being incorrect is high?
biphrase from the training corpus, C(f) the context
of some source phrase, C(fk) the context of a par-
ticular example of f in the training corpus, simphr
a function indicating the contextual similarity be-
tween two phrase contexts, and ej is any possible
translation of f .
The problem of modeling phrase translation is
however not limited to inappropriate training exam-
ples. For various reasons, legitimate occurrences of
source phrases may not be considered when building
a phrase?s translation distribution. We describe those
cases by considering the possible source phrases pi
from Figure 3:
? p1?s only translation, e1, is a common transla-
tion with f ; each contextually-appropriate ex-
ample of p1 should reinforce the probability of
e1 being a translation for f .
? Contextually-appropriate examples of p2 can
reinforce e3. Translation e6 should correspond
to contextually-inappropriate examples of p2,
so e6 should not be considered as a new po-
tential translation for f .
? Contrarily to the examples of p2 translating as
e6, examples of p3 translating as e4 are much
more likely of being contextually-appropriate
with f , meaning that f could be substituted
with most p3 examples. Therefore, e4, which
was not initially considered as a possible trans-
lation of f , could now be considered as such.
? p4 shares a translation with f , e2, but this is
due to the polysemous nature of this transla-
tion. Again, all examples of p4 should be found
contextually-inappropriate with f , and their
translations should not be considered when es-
timating the translations of f .
? Lastly, the case of the common translation e5
between f and p5 illustrates a consequence of
the polysemous nature of the source phrase cor-
responding to word sequence f : translations
corresponding to other senses of f should not
get reinforced by paraphrase examples such as
those of p5 as these examples should be found
contextually-inappropriate with f .
660
We build a separate translation model for transla-
tions estimated through paraphrases, defined as fol-
lows:
ppara(ei|f) =
?
?pk,ei?
simpara(C(f), C(pk))
?
?pk,ej?
simpara(C(f), C(pk))
(3)
where pk is a paraphrase of f , ?pk, ei? is a biphrase
from the training corpus such that ei is also a transla-
tion of f , C(f) the context of a given source phrase
for which we are estimating the translation distribu-
tion, C(pk) the context of a particular example of pk
in the training corpus, simpara a function indicat-
ing the contextual similarity between a phrase con-
text and a paraphrase context, and ej is any possible
translation of f .
Several requirements can be drawn from the pre-
vious description:
1. List of potential paraphrases: some mech-
anism for finding potential paraphrases for
source phrases is required, and several such
mechanisms could be combined. Pivoting via
bilingual corpora, a natural strategy given the
issue at hand, is just one among many different
proposed strategies (Madnani and Dorr, 2010).
2. Contextual similarity measure: a similarity
measure between the contexts of two phrases
or two potential local paraphrases is required.
This automatic measure should ideally be able
to model not only syntactic but also semantic
and pragmatic information.
3. Robust translation evaluation: our ap-
proach is designed to reinforce estimates for
any contextually-appropriate translations of a
phrase, as shown by set E on Figure 3. It is
therefore important to have some means of ac-
cepting them as subparts of valid translations.
Robustness in Machine Translation evaluation
is an active domain, and potential candidates
include using BLEU-like metrics with multiple
references, Human-targeted Translation Error
Rate (Snover et al, 2006) and the use of para-
phrases for reference translations (Kauchak and
Barzilay, 2006).
train dev. test
# sent. # tok. # sent. # tok. # sent. # tok.
en 318K 9.1M 500 14,0K 500 13,6K
fr 318K 10.3M 500 16,1K 500 15,7k
Figure 4: Statistics of the corpora used.
In this paper, we want to evaluate whether an en-
dogenous approach for finding paraphrases can lead
to some improvement in translation performance.
Note that we will not consider in this initial work
the possibility of adding new translations to phrases
(such as e4 for f on Figure 3) as it adds complexity
and should be investigated when the other simpler
cases can be handled successfully.
In the following section, we describe experiments
in which the original bilingual corpus is the only re-
source used to find potential paraphrases and to esti-
mate phrase translations in context. We chose a very
simple measure of similarity, and let to our future
work the task of improving context modeling. As
regards evaluation, we will resort to various ways to
measure the impact of our implementation on trans-
lation performance.
4 Experiments and results
4.1 Data and baseline SMT systems
We have conducted our experiments using the
MOSES11 package to build state-of-the-art phrase-
based SMT systems for phrases of up to 5 tokens,
using standard parameters and MERT for optimizing
model weights. We used a subpart of the Europarl
corpus12 in French and English as our training cor-
pus and built baseline MOSES systems (bsl) in both
directions. The target side of the training corpus
was used to train 3-gram target language model with
modified Kneser-Ney smoothing. Held-out datasets
were used for development and testing. The charac-
teristics of all corpora are described in Figure 4.
4.2 Example-based Paraphrasing SMT systems
We also built systems that exploit phrase and para-
phrase context under the form of two additional
models pcont and ppara described in section 3. These
11http://www.statmt.org/moses
12http://www.statmt.org/europarl
661
phrase table size num. entries
en?fr
baseline 240Mb 2.4M
our systems 5.0Gb 37.5M
fr?en
baseline 193Mb 1.9M
our systems 4.0Gb 30.2M
Figure 5: Statistics on the size and the number of entries
of the phrase tables filtered on the development set.
models are added to the list of models used to eval-
uate the various translations of a phrase in the ap-
propriate phrase tables, and are optimized with the
other models by standard MERT.
In order to model context, we modified the source
texts so that each phrase becomes unique in the
phrase table, i.e. it has its own translation distribu-
tion. This is done (as in other works (Carpuat and
Wu, 2007; Stroppa et al, 2007)) by transforming
each token into a unique token, e.g. token ? to-
ken@337. This therefore leads to a significant in-
crease in the size of the phrase table, as illustrated
on Figure 5, as all occurrences for the same phrase
are not factored anymore.13
We chose a very simple initial definition of con-
text similarity based on the presence of common
n-grams in the immediate vicinity of two phrases.
Let lengthleft (resp. lengthright) be the length of
the longest common n-gram in the immediate vicin-
ity on the left (resp. right) of two phrases in context
(C(f) and C(fi)). For instance, given the two fol-
lowing contexts (phrases under focus are in bold and
common n-grams are underlined):
1. the commission accepts the substance of the
amendments@11257 proposed@11258
by@11259 the committee on fisheries ...
2. this is why we shall support all of the amend-
ments put forward by the committee on agri-
culture and rural development ...
lengthleft = 2 and lengthright = 3. We further
define length as:
13These volumes of data and our available hardware facilities
for these experiments led us to initially limit the size of our data
sets. We will discuss in section 5 how we intend to address this
limitation in our future work.
length =
?
????
????
lengthleft + lengthright
if lengthleft > 0
and lengthright > 0
0 otherwise
(4)
We can now define the two similarity functions
used in Equations 2 and 3 that we used for our ex-
periments:
simcont(C(f), C(fi)) = (1 + length)
? (5)
simpara(C(f), C(pi)) = (length)
? (6)
The rationale for these functions is the follow-
ing. Exact phrase examples add at least a transla-
tion count of 1, i.e. their translation is always taken
into account to estimate pcont. Paraphrase exam-
ples add a translation count of 0 if length = 0,
i.e. their translation is not taken into account at all
if surrounding n-gram similarity is too low. We used
? = ? = 1.5. Algorithm 1 describes how the two
models are estimated from the training data.
foreach phrase f in training file do
extract C(f);
/* phrase count */
foreach unique phrase fi in test(f)) do
extract C(fi);
compute simcont(C(f), C(fi));
end
/* paraphrase count */
foreach phrase pi in para(f) do
foreach unique phrase fj in test(pi) do
extract C(fj);
compute simpara(C(f), C(fj));
end
end
end
estimate pcont and para;
Algorithm 1: Model estimation for pcont and
ppara. Function test(f) returns all unique
phrases corresponding to phrase f from the test
file. Function para(f) return all phrases for
which f is a known paraphrase.
We implemented the following strategy to find
paraphrases for phrases in the test file. We extract all
662
Left context phrase/paraphrase Right context
IS#1 at the moment it is up to each member state to decide, and practice dif-
fers considerably from country to country
PE#1 ... as regards the terminal portion in the
cycle of nuclear fuel, it is
the responsability of each member state to define its own policy .
PT#1 la responsabilite? de chaque
IS#2 that is why i find it extremely regrettable that the amendment on harmonising the re-
registration of cars that have been involved
in accidents ...
PE#2 for all these reasons and given your most
excellent statement , i find it
a pity that the new legal base for the daphne pro-
gramme is so restrictive ...
PT#2 dommage que
Figure 6: Examples of paraphrases in context from the development file. The input sentence (IS) contains a source
phrase of interest (in bold), the paraphrase example (PE) contains a paraphrase of that source phrase (in bold) for
which a paraphrase translation (PT) is known.
paraphrases p for a phrase f by pivot: all target lan-
guage phrases e aligned to f are first extracted, and
all source language phrases p aligned to e are ex-
tracted. The following constraints are then applied
to define which paraphrases are kept:
? string p is not included in string f and vice
versa (in order to minimize the impact of align-
ment errors in the training corpus);
? the paraphrasing probability is greater than a
fixed threshold: para(f, p) ? 10?2, where
para(f, p) =
?
e p(e|f)p(p|e) (Bannard and
Callison-Burch, 2005);
? the number of occurrences of phrase f and
paraphrase p are equal or less than indepen-
dent thresholds: numOccs(f) ? 100 and
numOccs(p) ? 1000.14
Figure 6 shows examples of paraphrases in con-
text with high similarity with some original phrase,
and Figure 7 provides various statistics on the para-
phrases extracted on the test file.
4.3 Results and analysis
Automatic evaluation results are reported in Table 8
for various configurations. We also wanted to focus
our measures on content words, which are known
14The first threshold value was chosen as (Callison-Burch et
al., 2005) report it to be an optimal sample size for estimating
phrase translation probabilities. The relatively low value for the
second threshold was selected to reduce computation time.
phrase # phrases # paraphrased # paraphrases
length en fr en fr en fr
1 13,620 15,707 458 725 1,824 2,684
2 13,120 15,207 4,127 4,481 18,871 19,700
3 12,620 14,707 4,782 5,715 24,111 27,377
4 12,120 14,208 2,859 4,078 15,071 20,345
5 11,623 13,711 1,171 2,275 6,077 12,132
Figure 7: Statistics on numbers of phrases, numbers
of paraphrased phrases and numbers of paraphrases per
phrase length.
to be important as regards information content in
translation. We applied the contrastive lexical eval-
uation (CLE) methodology described in (Max et
al., 2010), which indicates how many times source
words grouped into user-defined classes were cor-
rectly translated or not across systems. These addi-
tional results are reported on Figure 9.
On English to French translation, both additional
features lead to improvements over the baseline
with all metrics, including CLE, and their combi-
nation shows a strong improvement in TER (-1.55).
CLE on content words reveals that the para feature
seems particularly effective in reducing the number
of words in all categories that only the baseline sys-
tem translated correctly.
Results on French to English translation are less
positive: neither cont nor para alone improve over
the baseline with any metrics. However, their com-
bination improves over the baseline with all met-
rics except BLEU, including a reduction of -1.07
in TER. Detailed analysis of CLE results shows
that the translation of adjectives and nouns benefited
663
more from using our two additional models. Verbs,
whose translation improved slightly, are strongly in-
flected in French, so finding examples for a given
form is more difficult than for less inflected word
categories, as is finding paraphrases with the appro-
priate inflection. Also, pivoting via English is one
reason why paraphrases obtained via a low-inflected
language can be of varying quality. Furthermore, the
simplicity of our context modeling may have been
ineffective in filtering out some bad examples. Over-
all, para was more effective with the low-inflected
English as the source language, improving over the
baseline with all metrics.
These results confirm that translation perfor-
mance can be improved by exploiting context and
paraphrases in the original training corpus only. We
next attempted to measure whether some improve-
ment in the quality of the paraphrases used would
have some measurable impact on translation perfor-
mance. To this end, we devised a semi-oracle ex-
periment in the following way: the source and target
test files were automatically aligned, and for each
source phrase possible target phrases (i.e., reference
translations) were extracted, and used as pivots to
extract potential paraphrases, which were then fil-
tered with the same constraints as previously. In
this way, we exploit the information that paraphrases
can at least produce the desired translation, but they
may also propose other incorrect translations and/or
be present in very few examples. Results appear
in the inf rows of Tables 8 and 9. We obtain the
most important improvement over the baseline in
BLEU for the two language pairs (resp. +0.99 and
+0.44), though the results for the other metrics for
French to English translation are more difficult to
interpret. For this language pair, possible reasons
include again that the pivot language may not be
appropriate, and also that the limitation to a sin-
gle pivot15 may not have produced more monolin-
gual variation that might have proved useful. CLE
on English to French, however, reveals significant
gains with a relative improvement over the baseline
of +116 content words. Under this condition, this
result shows that the higher the quality of the para-
phrases used, the more translation quality can be im-
15Several pivot phrases may in fact have been automatically
extracted for a given phrase, some of which being possible bad
candidates.
BLEU NIST TER METEOR
en?fr
bsl 30.28 - 6.66 - 57.86 - 54.79 -
+cont 31.11 +0.83 6.77 +0.11 57.24 -0.62 55.22 +0.43
+para 30.97 +0.69 6.74 +0.08 57.38 -0.48 55.39 +0.60
all 30.93 +0.65 6.84 +0.18 56.31 -1.55 55.28 +0.49
inf 31.27 +0.99 6.78 +0.12 57.22 -0.64 55.80 +1.01
fr?en
bsl 29.90 - 6.90 - 54.64 - 61.36 -
+cont 29.56 -0.34 6.89 -0.01 54.95 +0.31 60.98 -0.38
+para 29.70 -0.20 6.92 +0.02 54.64 +0.00 61.10 -0.26
all 29.75 -0.15 7.03 +0.13 53.57 -1.07 61.63 +0.27
inf 30.34 +0.44 6.93 +0.03 54.90 +0.26 60.99 -0.37
Figure 8: Automatic scores for the MOSES baseline sys-
tems (bsl), systems additionnally using the contextual
feature (+cont), systems additionnally using the para-
phrasing feature (+para), systems using both features
(all), and pivot-informed systems (inf).
Adj Adv Noun Verb
?
en?fr
+cont - 74 28 113 60 275+ 55 35 114 85 289 +14
+para - 62 12 82 46 202+ 58 32 111 78 279 +77
all - 72 25 91 72 260+ 50 37 118 97 302 +42
inf - 58 20 108 56 242+ 65 43 147 103 358 +116
fr?en
+cont - 30 16 80 69 195+ 15 21 69 46 151 -44
+para - 32 19 72 60 183+ 12 18 65 43 138 -45
all - 21 18 67 61 167+ 30 18 94 48 190 +23
inf - 38 21 83 66 208+ 31 23 106 57 217 +9
Figure 9: Contrastive lexical evaluation results per part-
of-speech measured on the test file. ?-? (resp. ?+?) rows
indicate the number of source words that only bsl (resp.
the compared system) correctly translated.
proved, which is in line with works that make use
of human-made paraphrases to improve translation
quality (Schroeder et al, 2009; Resnik et al, 2010).
Table 10 presents a typology of paraphrases found
in our development set and classifies the impact of
using them for phrase translation estimation. As can
be seen, more work is needed to better understand
the characteristics of the phrases that should be para-
phrased and of their paraphrases.
664
Type Impact Examples
Morphological variants +/- (yugoslav republic? yugoslavian republic), (go far? goes far)
Synonymy + (duties? obligations), (to look into? to study)
Grammatical word substitution ?/- (states in the? the states of the), (amendments by? amendments to)
Word deletion or insertion ?/- (first reading, the? first reading the), (amendments by? amendments
proposed by)
Syntactic rewritings + (approval of the majority ? majority support), (capacity of the euro-
pean union? european union?s ability)
Phrasal idiomatic substitutions + (must be said that the? goes without saying that the), (is fully in line
? is totally coherent), (is amazing? strikes me)
Context-dependent substitu-
tions
+/- (is not right? is unacceptable), (offer my? express my)
Alignment and translation prob-
lems
- (unnecessary if ? vital if), (the crime ? organized), (ill-advised ?
wise), (to begin by thanking? to begin by congratulating)
Figure 10: Main types of paraphrase pairs found in our dev. and training corpora. Pairs shown have length > 0.
5 Conclusion and future work
We have introduced an original way of exploiting
both context and paraphrasing for the estimation
of phrase translations in phrase-based SMT. To our
knowledge, this is the first time that paraphrases ac-
quired in an endogenous manner have been shown
to improve translation performance, which shows
that bilingual corpora can be better exploited than
they typically are. Our experiments further showed
the promises of our approach when paraphrases of
higher quality are available.
In the light of our results and our initial typology
of paraphrases presented on Figure 10, as well as
previous work on paraphrasing for SMT, the diffi-
cult question of what units should be paraphrased
for what success should be addressed, taking into ac-
count parameters such as language pairs, quantity of
training data and availability of external resources.
Our future work includes three main areas: first,
we want to improve the modeling of context, by no-
tably working on techniques inspired from Informa-
tion Retrieval to quickly access contextually-similar
examples of source phrases in bilingual corpora.
Such contextual sampling on large bilingual corpora
for phrases and their paraphrases, which could inte-
grate more complex linguistic information, will al-
low us to assess our approach on more challenging
conditions. This would also allow us to build con-
textual models on-the-fly, and experiment with us-
ing lattices to encode contextually estimated para-
phrases. Second, we will combine paraphrases ob-
tained via different techniques and resources, which
will allow us to also learn translation distributions
for phrases absent from the original corpus. Lastly,
we want to also exploit paraphrases for the addi-
tional translations that they propose (such as e4 on
Figure 3) and that would be contextually similar in
the target language to other existing translations of
a given phrase or that could even represent a new
sense of the original phrase.
Acknowledgements
This work was partly supported by ANR project
Trace (ANR-09-CORD-023). The author would like
to thank the anonymous reviewers for their helpful
questions and comments.
References
Sadaf Abdul-Rauf and Holger Schwenk. 2009. On the
Use of Comparable Corpora to Improve SMT perfor-
mance. In Proceedings of EACL, Athens, Greece.
Wilker Aziz, Marc Dymetman, Shachar Mirkin, Lucia
Specia, Nicola Cancedda, and Ido Dagan. 2010.
Learning an Expert from Human Annotations in Sta-
tistical Machine Translation: the Case of Out-of-
Vocabulary Words. In Proceedings of EAMT, Saint-
Raphael, France.
Colin Bannard and Chris Callison-Burch. 2005. Para-
phrasing with Bilingual Parallel Corpora. In Proceed-
ings of ACL, Ann Arbor, USA.
Francis Bond, Eric Nichols, Darren Scott Appling, and
Michael Paul. 2008. Improving statistical machine
translation by paraphrasing the training data. In Pro-
ceedings of IWSLT, Hawai, USA.
Chris Callison-Burch, Colin Bannard, and Josh
Schroeder. 2005. Scaling Phrase-Based Statis-
665
tical Machine Translation to Larger Corpora and
Longer Phrases. In Proceedings of ACL, Ann Arbor,
USA.
Chris Callison-Burch, Philipp Koehn, and Miles Os-
borne. 2006. Improved Statistical Machine Transla-
tion Using Paraphrases. In Proceedings of NAACL,
New York, USA.
Chris Callison-Burch. 2008. Syntactic Constraints on
Paraphrases Extracted from Parallel Corpora. In Pro-
ceedings of EMNLP, Hawai, USA.
Marine Carpuat and Dekai Wu. 2007. Context-
Dependent Phrasal Translation Lexicons for Statisti-
cal Machine Translation. In Proceedings of Machine
Translation Summit XI, Copenhagen, Denmark.
Marine Carpuat. 2009. One Translation Per Discourse.
In Proceedings of the NAACL-HLT Workshop on Se-
mantic Evaluations, Boulder, USA.
Jinhua Du, Jie Jiang, and Andy Way. 2010. Facilitating
Translation Using Source Language Paraphrase Lat-
tices. In Proceedings of EMNLP, Cambridge, USA.
Kevin Gimpel and Noah A. Smith. 2008. Rich Source-
Side Context for Statistical Machine Translation. In
Proceedings of the ACL Workshop on Statistical Ma-
chine Translation, Columbus, USA.
Rejwanul Haque, Sudip Kumar Naskar, Yanjun Ma, and
Andy Way. 2009. Using Supertags as Source Lan-
guage Context in SMT. In Proceedings of EAMT,
Barcelona, Spain.
Almut Silja Hildebrand, Matthias Eck, Stephan Vogel,
and Alex Waibel. 2005. Adaptation of the Transla-
tion Model for Statistical Machine Translation Based
on Information Retrieval. In Proceedings of EAMT,
Budapest, Hungary.
David Kauchak and Regina Barzilay. 2006. Paraphras-
ing for Automatic Evaluation. In Proceedings of
NAACL HLT, New York, USA.
Philipp Koehn, Franz Josef Och, and Daniel Marcu.
2003. Statistical Phrase-Based Translation. In Pro-
ceedings of NAACL HLT, Edmonton, Canada.
Stanley Kok and Chris Brockett. 2010. Hitting the Right
Paraphrases in Good Time. In Proceedings of NAACL,
Los Angeles, USA.
Adam Lopez. 2008. Tera-Scale Translation Models
via Pattern Matching. In Proceedings of COLING,
Manchester, UK.
Nitin Madnani and Bonnie J. Dorr. 2010. Generating
Phrasal & Sentential Paraphrases: A Survey of Data-
Driven Methods. Computational Linguistics, 36(3).
Nitin Madnani, Philip Resnik, Bonnie J. Dorr, and
Richard Schwartz. 2008. Are Multiple Reference
Translations Necessary? Investigating the Value of
Paraphrased Reference Translations in Parameter Op-
timization. In Proceedings of AMTA, Waikiki, USA.
Yuval Marton, Chris Callison-Burch, and Philip Resnik.
2009. Improved Statistical Machine Translation Using
Monolingually-derived Paraphrases. In Proceedings
of EMNLP, Singapore.
Aure?lien Max, Rafik Makhloufi, and Philippe Langlais.
2008. Explorations in using grammatical dependen-
cies for contextual phrase translation disambiguation.
In Proceedings of EAMT, Hamburg, Germany.
Aure?lien Max, Josep M. Crego, and Franc?ois Yvon.
2010. Contrastive Lexical Evaluation of Machine
Translation. In Proceedings of LREC, Valletta, Malta.
Aure?lien Max. 2008. Local rephrasing suggestions for
supporting the work of writers. In Proceedings of Go-
TAL, Gothenburg, Sweden.
Shachar Mirkin, Lucia Specia, Nicola Cancedda, Ido
Dagan, Marc Dymetman, and Idan Szpektor. 2009.
Source-Language Entailment Modeling for Translat-
ing Unknown Terms. In Proceedings of ACL, Singa-
pore.
Behrang Mohit and Rebecca Hwa. 2007. Localization
of Difficult-to-Translate Phrases. In Proceedings of
the ACL Workshop on Statistical Machine Translation,
Prague, Czech Republic.
Dragos Stefan Munteanu and Daniel Marcu. 2005. Im-
proving Machine Translation Performance by Exploit-
ing Non-parallel Corpora. Computational Linguistics,
31(4).
Takashi Onishi, Masao Utiyama, and Eiichiro Sumita.
2010. Paraphrase Lattice for Statistical Machine
Translation. In Proceedings of ACL, short paper ses-
sion, Uppsala, Sweden.
Philip Resnik, Olivia Buzek, Chang Hu, Yakov Kron-
rod, Alex Quinn, and Benjamin B. Bederson. 2010.
Improving Translation via Targeted Paraphrasing. In
Proceedings of EMNLP, Cambridge, USA.
Josh Schroeder, Trevor Cohn, and Philipp Koehn. 2009.
Word Lattices for Multi-Source Translation. In Pro-
ceedings of EACL, Athens, Greece.
Matthew Snover, Bonnie J. Dorr, Richard Schwartz, Lin-
nea Micciulla, and John Makhoul. 2006. A Study of
Translation Edit Rate with Targeted Human Annota-
tion. In Proceedings of AMTA, Boston, USA.
Nicolas Stroppa, Antal van den Bosch, and Andy Way.
2007. Exploiting Source Similarity for SMT using
Context-Informed Features. In Proceedings of TMI,
Skovde, Sweden.
Guillaume Wisniewski, Alexandre Allauzen, and
Franc?ois Yvon. 2010. Assessing Phrase-based Trans-
lation Models with Oracle Decoding. In Proceedings
of EMNLP, Cambridge, USA.
666
