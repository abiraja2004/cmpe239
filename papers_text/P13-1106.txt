Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 1073?1082,
Sofia, Bulgaria, August 4-9 2013. c?2013 Association for Computational Linguistics
Joint Word Alignment and Bilingual Named Entity Recognition
Using Dual Decomposition
Mengqiu Wang
Stanford University
Stanford, CA 94305
mengqiu@cs.stanford.edu
Wanxiang Che
Harbin Institute of Technology
Harbin, China, 150001
car@ir.hit.edu.cn
Christopher D. Manning
Stanford University
Stanford, CA 94305
manning@cs.stanford.edu
Abstract
Translated bi-texts contain complemen-
tary language cues, and previous work
on Named Entity Recognition (NER)
has demonstrated improvements in perfor-
mance over monolingual taggers by pro-
moting agreement of tagging decisions be-
tween the two languages. However, most
previous approaches to bilingual tagging
assume word alignments are given as fixed
input, which can cause cascading errors.
We observe that NER label information
can be used to correct alignment mis-
takes, and present a graphical model that
performs bilingual NER tagging jointly
with word alignment, by combining two
monolingual tagging models with two uni-
directional alignment models. We intro-
duce additional cross-lingual edge factors
that encourage agreements between tag-
ging and alignment decisions. We design
a dual decomposition inference algorithm
to perform joint decoding over the com-
bined alignment and NER output space.
Experiments on the OntoNotes dataset
demonstrate that our method yields signif-
icant improvements in both NER and word
alignment over state-of-the-art monolin-
gual baselines.
1 Introduction
We study the problem of Named Entity Recogni-
tion (NER) in a bilingual context, where the goal
is to annotate parallel bi-texts with named entity
tags. This is a particularly important problem for
machine translation (MT) since entities such as
person names, locations, organizations, etc. carry
much of the information expressed in the source
sentence. Recognizing them provides useful in-
formation for phrase detection and word sense dis-
ambiguation (e.g., ?melody? as in a female name
has a different translation from the word ?melody?
in a musical sense), and can be directly leveraged
to improve translation quality (Babych and Hart-
ley, 2003). We can also automatically construct a
named entity translation lexicon by annotating and
extracting entities from bi-texts, and use it to im-
prove MT performance (Huang and Vogel, 2002;
Al-Onaizan and Knight, 2002). Previous work
such as Burkett et al (2010b), Li et al (2012) and
Kim et al (2012) have also demonstrated that bi-
texts annotated with NER tags can provide useful
additional training sources for improving the per-
formance of standalone monolingual taggers.
Because human translation in general preserves
semantic equivalence, bi-texts represent two per-
spectives on the same semantic content (Burkett et
al., 2010b). As a result, we can find complemen-
tary cues in the two languages that help to dis-
ambiguate named entity mentions (Brown et al,
1991). For example, the English word ?Jordan?
can be either a last name or a country. Without
sufficient context it can be difficult to distinguish
the two; however, in Chinese, these two senses are
disambiguated: ???? as a last name, and ????
as a country name.
In this work, we first develop a bilingual NER
model (denoted as BI-NER) by embedding two
monolingual CRF-based NER models into a larger
undirected graphical model, and introduce addi-
tional edge factors based on word alignment (WA).
Because the new bilingual model contains many
cyclic cliques, exact inference is intractable. We
employ a dual decomposition (DD) inference al-
gorithm (Bertsekas, 1999; Rush et al, 2010) for
performing approximate inference. Unlike most
1073
f1 f2 f3 f4 f5 f6
e1 e2 e3 e4 e5 e6
Xinhua News Agency Beijing Feb 16
B-ORG I-ORG I-ORG [O] B-LOC O O
??? ? ?? ? ?? ??
B-ORG O B-GPE O O O
Figure 1: Example of NER labels between two word-aligned bilingual parallel sentences. The [O] tag is
an example of a wrong tag assignment. The dashed alignment link between e3 and f2 is an example of
alignment error.
previous applications of the DD method in NLP,
where the model typically factors over two com-
ponents and agreement is to be sought between the
two (Rush et al, 2010; Koo et al, 2010; DeNero
and Macherey, 2011; Chieu and Teow, 2012), our
method decomposes the larger graphical model
into many overlapping components where each
alignment edge forms a separate factor. We design
clique potentials over the alignment-based edges
to encourage entity tag agreements. Our method
does not require any manual annotation of word
alignments or named entities over the bilingual
training data.
The aforementioned BI-NER model assumes
fixed alignment input given by an underlying word
aligner. But the entity span and type predictions
given by the NER models contain complementary
information for correcting alignment errors. To
capture this source of information, we present a
novel extension that combines the BI-NER model
with two uni-directional HMM-based alignment
models, and perform joint decoding of NER and
word alignments. The new model (denoted as
BI-NER-WA) factors over five components: one
NER model and one word alignment model for
each language, plus a joint NER-alignment model
which not only enforces NER label agreements but
also facilitates message passing among the other
four components. An extended DD decoding algo-
rithm is again employed to perform approximate
inference.
We give a formal definition of the Bi-NER
model in Section 2, and then move to present the
Bi-NER-WA model in Section 3.
2 Bilingual NER by Agreement
The inputs to our models are parallel sentence
pairs (see Figure 1 for an example in English and
Chinese). We denote the sentences as e (for En-
glish) and f (for Chinese). We assume access
to two monolingual linear-chain CRF-based NER
models that are already trained. The English-side
CRF model assigns the following probability for a
tag sequence ye:
PCRFe (ye|e) =
?
vi?Ve
?(vi)
?
(vi,vj)?De
?(vi, vj)
Ze(e)
where Ve is the set of vertices in the CRF and
De is the set of edges. ?(vi) and ?(vi, vj) are
the node and edge clique potentials, and Ze(e)
is the partition function for input sequence e un-
der the English CRF model. We let k(ye) be the
un-normalized log-probability of tag sequence ye,
defined as:
k(ye) = log
?
? ?
vi?Ve
?(vi)
?
(vi,vj)?De
?(vi, vj)
?
?
Similarly, we define model PCRFf and un-
normalized log-probability l(yf) for Chinese.
We also assume that a set of word alignments
(A = {(i, j) : ei ? fj}) is given by a word
aligner and remain fixed in our model.
For clarity, we assume ye and yf are binary vari-
ables in the description of our algorithms. The ex-
tension to the multi-class case is straight-forward
and does not affect the core algorithms.
2.1 Hard Agreement
We define a BI-NER model which imposes hard
agreement of entity labels over aligned word pairs.
At inference time, we solve the following opti-
1074
mization problem:
max
ye,yf
log (PCRFe (ye)) + log
(
PCRFf
(
yf
))
=max
ye,yf
k(ye) + l(yf)? logZe(e)? logZf (f)
'max
ye,yf
k(ye) + l(yf)
3 yei = yfj ?(i, j) ? A
We dropped the Ze(e) and Zf(f) terms because
they remain constant at inference time.
The Lagrangian relaxation of this term is:
L
(
ye,yf,U
)
=
k (ye) + l
(
yf
)
+
?
(i,j)?A
u(i, j)
(
yei ? yfj
)
where u(i, j) are the Lagrangian multipliers.
Instead of solving the Lagrangian directly, we
can form the dual of this problem and solve it us-
ing dual decomposition (Rush et al, 2010):
min
U
(
max
ye
?
?k (ye) +
?
(i,j)?A
u(i, j)yei
?
?
+max
yf
?
?l
(
yf
)
?
?
(i,j)?A
u(i, j)yfj
?
?
)
Similar to previous work, we solve this DD
problem by iteratively updating the sub-gradient
as depicted in Algorithm 1. T is the maximum
number of iterations before early stopping, and ?t
is the learning rate at time t. We adopt a learning
rate update rule from Koo et al (2010) where ?t is
defined as 1N , where N is the number of times weobserved a consecutive dual value increase from
iteration 1 to t.
A thorough introduction to the theoretical foun-
dations of dual decomposition algorithms is be-
yond the scope of this paper; we encourage un-
familiar readers to read Rush and Collins (2012)
for a full tutorial.
2.2 Soft Agreement
The previously discussed hard agreement model
rests on the core assumption that aligned words
must have identical entity tags. In reality, however,
this assumption does not always hold. Firstly, as-
suming words are correctly aligned, their entity
tags may not agree due to inconsistency in anno-
tation standards. In Figure 1, for example, the
Algorithm 1 DD inference algorithm for hard
agreement model.
?(i, j) ? A : u(i, j) = 0
for t? 1 to T do
ye? ? argmax k (ye) + ?
(i,j)?A
u(i, j)yei
yf? ? argmax l
(
yf
)
? ?
(i,j)?A
u(i, j)yfj
if ?(i, j) ? A : ye?i = yf?j then
return (ye?,yf?)
end if
for all (i, j) ? A do
u(i, j)? u(i, j) + ?t
(
yf?j ? ye?i
)
end for
end for
return (ye?(T),yf?(T)
)
word ?Beijing? can be either a Geo-Political En-
tity (GPE) or a location. The Chinese annotation
standard may enforce that ?Beijing? should always
be tagged as GPE when it is mentioned in isola-
tion, while the English standard may require the
annotator to judge based on word usage context.
The assumption in the hard agreement model can
also be violated if there are word alignment errors.
In order to model this uncertainty, we extend
the two previously independent CRF models into a
larger undirected graphical model, by introducing
a cross-lingual edge factor ?(i, j) for every pair of
word positions (i, j) ? A. We associate a clique
potential function h(i,j)(yei , yfj) for ?(i, j):
h(i,j)
(
yei , yfj
)
= pmi
(
yei , yfj
)P? (ei,fj)
where pmi(yei , yfj) is the point-wise mutual in-
formation (PMI) of the tag pair, and we raise it
to the power of a posterior alignment probability
P? (ei, fj). For a pair of NEs that are aligned with
low probability, we cannot be too sure about the
association of the two NEs, therefore the model
should not impose too much influence from the
bilingual agreement model; instead, we will let the
monolingual NE models make their decisions, and
trust that those are the best estimates we can come
up with when we do not have much confidence in
their bilingual association. The use of the poste-
rior alignment probability facilitates this purpose.
Initially, each of the cross-lingual edge factors
will attempt to assign a pair of tags that has the
highest PMI score, but if the monolingual taggers
do not agree, a penalty will start accumulating
over this pair, until some other pair that agrees bet-
ter with the monolingual models takes the top spot.
1075
Simultaneously, the monolingual models will also
be encouraged to agree with the cross-lingual edge
factors. This way, the various components effec-
tively trade penalties indirectly through the cross-
lingual edges, until a tag sequence that maximizes
the joint probability is achieved.
Since we assume no bilingually annotated NER
corpus is available, in order to get an estimate of
the PMI scores, we first tag a collection of unan-
notated bilingual sentence pairs using the mono-
lingual CRF taggers, and collect counts of aligned
entity pairs from this auto-generated tagged data.
Each of the ?(i, j) edge factors (e.g., the edge
between node f3 and e4 in Figure 1) overlaps with
each of the two CRF models over one vertex (e.g.,
f3 on Chinese side and e4 on English side), and
we seek agreement with the Chinese CRF model
over tag assignment of fj , and similarly for ei on
English side. In other words, no direct agreement
between the two CRF models is enforced, but they
both need to agree with the bilingual edge factors.
The updated optimization problem becomes:
max
ye(k)yf(l)ye(h)yf(h)
k
(
ye(k)
)
+ l
(
yf (l)
)
+
?
(i,j)?A
h(i,j)
(
ye(h)i , yf
(h)
j
)
3 ?(i, j) ? A :
(
ye(k)i = ye
(h)
i
)
?
(
yf (l)j = y
f (h)
j
)
where the notation ye(k)i denotes tag assignment to
word ei by the English CRF and ye(h)i denotes as-
signment to word ei by the bilingual factor; yf (l)j
denotes the tag assignment to word fj by the Chi-
nese CRF and yf (h)j denotes assignment to word
fj by the bilingual factor.
The updated DD algorithm is illustrated in Al-
gorithm 2 (case 2). We introduce two separate
sets of dual constraints we and wf, which range
over the set of vertices on their respective half
of the graph. Decoding the edge factor model
h(i,j)(yei , y
f
j) simply involves finding the pair of
tag assignments that gives the highest PMI score,
subject to the dual constraints.
The way DD algorithms work in decomposing
undirected graphical models is analogous to other
message passing algorithms such as loopy belief
propagation, but DD gives a stronger optimality
guarantee upon convergence (Rush et al, 2010).
3 Joint Alignment and NER Decoding
In this section we develop an extended model in
which NER information can in turn be used to
improve alignment accuracy. Although we have
seen more than a handful of recent papers that ap-
ply the dual decomposition method for joint in-
ference problems, all of the past work deals with
cases where the various model components have
the same inference output space (e.g., dependency
parsing (Koo et al, 2010), POS tagging (Rush et
al., 2012), etc.). In our case the output space is
the much more complex joint alignment and NER
tagging space. We propose a novel dual decom-
position variant for performing inference over this
joint space.
Most commonly used alignment models, such
as the IBM models and HMM-based aligner are
unsupervised learners, and can only capture sim-
ple distortion features and lexical translational fea-
tures due to the high complexity of the structure
prediction space. On the other hand, the CRF-
based NER models are trained on manually anno-
tated data, and admit richer sequence and lexical
features. The entity label predictions made by the
NER model can potentially be leveraged to correct
alignment mistakes. For example, in Figure 1, if
the tagger knows that the word ?Agency? is tagged
I-ORG, and if it also knows that the first comma
in the Chinese sentence is not part of any entity,
then we can infer it is very unlikely that there ex-
ists an alignment link between ?Agency? and the
comma.
To capture this intuition, we extend the BI-NER
model to jointly perform word alignment and NER
decoding, and call the resulting model BI-NER-
WA. As a first step, instead of taking the output
from an aligner as fixed input, we incorporate two
uni-directional aligners into our model. We name
the Chinese-to-English aligner model as m(Be)
and the reverse directional model n(Bf ). Be is
a matrix that holds the output of the Chinese-to-
English aligner. Each be(i, j) binary variable in
Be indicates whether fj is aligned to ei; similarly
we define output matrix Bf and bf (i, j) for Chi-
nese. In our experiments, we used two HMM-
based alignment models. But in principle we can
adopt any alignment model as long as we can per-
form efficient inference over it.
We introduce a cross-lingual edge factor ?(i, j)
in the undirected graphical model for every pair of
word indices (i, j), which predicts a binary vari-
1076
Algorithm 2 DD inference algorithm for joint
alignment and NER model. A line marked with (2)
means it applies to the BI-NER model; a line marked with
(3) means it applies to the BI-NER-WA model.
S ? A (2)
S ? {(i, j) : ?i ? |e|, ?j ? |f |} (3)
?i ? |e| : wei = 0; ?j ? |f | : wfj = 0 (2,3)
?(i, j) ? S : de(i, j) = 0, df (i, j) = 0 (3)
for t? 1 to T do
ye(k)? ? argmax k
(
ye(k)
)
+
?
i?|e|
wei ye
(k)
i (2,3)
yf(l)? ? argmax l
(
yf(l)
)
+
?
i?|f |
wfj yf
(l)
j (2,3)
Be??argmax m (Be) + ?
(i,j)
de(i, j)be(i, j) (3)
Bf??argmax n
(
Bf
)
+
?
(i,j)
df(i, j)bf(i, j) (3)
for all (i, j) ? S do
(ye(h)?i yf
(h)?
j )? ?wei ye
(h)
i ? wfj yf
(h)
j
+ argmax h(i,j)(ye
(q)
i yf
(q)
j ) (2)
(ye(q)?i yf
(q)?
j a(i, j)?)? ?wei ye
(q)
i ? wfj yf
(q)
j
+ argmax q(i,j)(ye
(q)
i yf
(q)
j a(i, j))
? de(i, j)a(i, j)? df(i, j)a(i, j) (3)
end for
Conv = (ye(k)=ye(q) ? yf(l)=yf(q)) (2)
Conv = (Be=A=Bf ? ye(k)=ye(q)? yf(l)=yf(q)) (3)
if Conv = true , then
return
(
ye(k)? ,yf(l)?
)
(2)
return
(
ye(k)? ,yf(l)? ,A
)
(3)
else
for all i ? |e| do
wei ? wei + ?t
(
ye(q|h)?i ? ye
(k)?
i
)
(2,3)
end for
for all j ? |f | do
wfj ? wfj + ?t
(
yf
(q|h)?
j ? yf
(l)?
j
)
(2,3)
end for
for all (i, j) ? S do
de(i, j)? de(i, j) + ?t (ae?(i, j)? be?(i, j)) (3)
df(i, j)? df(i, j) + ?t
(
af?(i, j)? bf?(i, j)
) (3)
end for
end if
end for
return
(
ye(k)?(T) ,yf
(l)?
(T)
)
(2)
return
(
ye(k)?(T) ,yf
(l)?
(T) ,A(T )
)
(3)
able a(i, j) for an alignment link between ei and
fj . The edge factor also predicts the entity tags for
ei and fj .
The new edge potential q is defined as:
q(i,j)
(
yei , yfj , a(i, j)
)
=
log(P (a(i, j) = 1)) + S(yei , yfj |a(i, j))P (a(i,j)=1)
S(yei , yfj |a(i, j))=
{
pmi(yei , y
f
j), if a(i, j) = 1
0, else
P (a(i, j) = 1) is the alignment probability as-
signed by the bilingual edge factor between node
ei and fj . We initialize this value to P? (ei, fj) =
1
2(Pm(ei, fj) + Pn(ei, fj)), where Pm(ei, fj) and
Pn(ei, fj) are the posterior probabilities assigned
by the HMM-aligners.
The joint optimization problem is defined as:
max
ye(k)yf(l)ye(h)yf(h)BeBfA
k(ye(k)) + l(yf (l))+
m(Be) + n(Bf) +
?
(i?|e|,j?|f |)
q(i,j)(ye
h
i , yf
(h)
j , a(i, j))
3 ?(i, j) :
(
be(i, j)=a(i, j)
)
?
(
bf (i, j)=a(i, j)
)
? if a(i, j) = 1 then
(
ye(k)i =ye
(h)
i
)
?
(
yf (l)j =y
f (h)
j
)
We include two dual constraints de(i, j) and
df (i, j) over alignments for every bilingual edge
factor ?(i, j), which are applied to the English and
Chinese sides of the alignment space, respectively.
The DD algorithm used for this model is given
in Algorithm 2 (case 3). One special note is that
after each iteration when we consider updates to
the dual constraint for entity tags, we only check
tag agreements for cross-lingual edge factors that
have an alignment assignment value of 1. In other
words, cross-lingual edges that are not aligned do
not affect bilingual NER tagging.
Similar to ?(i, j), ?(i, j) factors do not provide
that much additional information other than some
selectional preferences via PMI score. But the
real power of these cross-language edge cliques
is that they act as a liaison between the NER
and alignment models on each language side, and
encourage these models to indirectly agree with
each other by having them all agree with the edge
cliques.
It is also worth noting that since we decode
the alignment models with Viterbi inference, ad-
ditional constraints such as the neighborhood con-
straint proposed by DeNero and Macherey (2011)
can be easily integrated into our model. The
neighborhood constraint enforces that if fj is
aligned to ei, then fj can only be aligned to ei+1
or ei?1 (with a small penalty), but not any other
word position. We report results of adding neigh-
borhood constraints to our model in Section 6.
4 Experimental Setup
We evaluate on the large OntoNotes (v4.0) cor-
pus (Hovy et al, 2006) which contains manually
1077
annotated NER tags for both Chinese and En-
glish. Document pairs are sentence aligned us-
ing the Champollion Tool Kit (Ma, 2006). Af-
ter discarding sentences with no aligned counter-
part, a total of 402 documents and 8,249 paral-
lel sentence pairs were used for evaluation. We
will refer to this evaluation set as full-set. We use
odd-numbered documents as the dev set and even-
numbered documents as the blind test set. We
did not perform parameter tuning on the dev set
to optimize performance, instead we fix the ini-
tial learning rate to 0.5 and maximum iterations to
1,000 in all DD experiments. We only use the dev
set for model development.
The Stanford CRF-based NER tagger was used
as the monolingual component in our models
(Finkel et al, 2005). It also serves as a state-
of-the-art monolingual baseline for both English
and Chinese. For English, we use the default tag-
ger setting from Finkel et al (2005). For Chi-
nese, we use an improved set of features over the
default tagger, which includes distributional sim-
ilarity features trained on large amounts of non-
overlapping data.1
We train the two CRF models on all portions
of the OntoNotes corpus that are annotated with
named entity tags, except the parallel-aligned por-
tion which we reserve for development and test
purposes. In total, there are about 660 train-
ing documents (?16k sentences) for Chinese and
1,400 documents (?39k sentences) for English.
Out of the 18 named entity types that are an-
notated in OntoNotes, which include person, lo-
cation, date, money, and so on, we select the four
most commonly seen named entity types for evalu-
ation. They are person, location, organization and
GPE. All entities of these four types are converted
to the standard BIO format, and background to-
kens and all other entity types are marked with
tag O. When we consider label agreements over
aligned word pairs in all bilingual agreement mod-
els, we ignore the distinction between B- and I-
tags.
We report standard NER measures (entity pre-
cision (P), recall (R) and F1 score) on the test
set. Statistical significance tests are done using the
paired bootstrap resampling method (Efron and
Tibshirani, 1993).
For alignment experiments, we train two uni-
1The exact feature set and the CRF implementation
can be found here: http://nlp.stanford.edu/
software/CRF-NER.shtml
directional HMM models as our baseline and
monolingual alignment models. The parameters
of the HMM were initialized by IBM Model 1 us-
ing the agreement-based EM training algorithms
from Liang et al (2006). Each model is trained
for 2 iterations over a parallel corpus of 12 mil-
lion English words and Chinese words, almost
twice as much data as used in previous work that
yields state-of-the-art unsupervised alignment re-
sults (DeNero and Klein, 2008; Haghighi et al,
2009; DeNero and Macherey, 2011).
Word alignment evaluation is done over the
sections of OntoNotes that have matching gold-
standard word alignment annotations from GALE
Y1Q4 dataset.2 This subset contains 288 docu-
ments and 3,391 sentence pairs. We will refer
to this subset as wa-subset. This evaluation set
is over 20 times larger than the 150 sentences
set used in most past evaluations (DeNero and
Klein, 2008; Haghighi et al, 2009; DeNero and
Macherey, 2011).
Alignments input to the BI-NER model are
produced by thresholding the averaged posterior
probability at 0.5. In joint NER and alignment ex-
periments, instead of posterior thresholding, we
take the direct intersection of the Viterbi-best
alignment of the two directional models. We re-
port the standard P, R, F1 and Alignment Error
Rate (AER) measures for alignment experiments.
An important past work to make comparisons
with is Burkett et al (2010b). Their method
is similar to ours in that they also model bilin-
gual agreement in conjunction with two CRF-
based monolingual models. But instead of using
just the PMI scores of bilingual NE pairs, as in
our work, they employed a feature-rich log-linear
model to capture bilingual correlations. Parame-
ters in their log-linear model require training with
bilingually annotated data, which is not readily
available. To counter this problem, they proposed
an ?up-training? method which simulates a super-
vised learning environment by pairing a weak clas-
sifier with strong classifiers, and train the bilin-
gual model to rank the output of the strong classi-
fier highly among the N-best outputs of the weak
classifier. In order to compare directly with their
method, we obtained the code behind Burkett et
al. (2010b) and reproduced their experimental set-
ting for the OntoNotes data. An extra set of 5,000
unannotated parallel sentence pairs are used for
2LDC Catalog No. LDC2006E86.
1078
Chinese English
P R F1 P R F1
Mono 76.89 61.64 68.42 81.98 74.59 78.11
Burkett 77.52 65.84 71.20 82.28 76.64 79.36
Bi-soft 79.14 71.55 75.15 82.58 77.96 80.20
Table 1: NER results on bilingual parallel test set.
Best numbers on each measure that are statistically
significantly better than the monolingual baseline
and Burkett et al (2010b) are highlighted in bold.
training the reranker, and the reranker model se-
lection was performed on the development dataset.
5 Bilingual NER Results
The main results on bilingual NER over the test
portion of full-set are shown in Table 1. We
initially experimented with the hard agreement
model, but it performs quite poorly for reasons we
discussed in Section 2.2. The BI-NER model with
soft agreement constraints, however, significantly
outperforms all baselines. In particular, it achieves
an absolute F1 improvement of 6.7% in Chinese
and 2.1% in English over the CRF monolingual
baselines.
A well-known issue with the DD method is
that when the model does not necessarily con-
verge, then the procedure could be very sensi-
tive to hyper-parameters such as initial step size
and early termination criteria. If a model only
gives good performance with well-tuned hyper-
parameters, then we must have manually anno-
tated data for tuning, which would significantly
reduce the applicability and portability of this
method to other language pairs and tasks. To eval-
uate the parameter sensitivity of our model, we
run the model from 50 to 3000 iterations before
early stopping, and with 6 different initial step
sizes from 0.01 to 1. The results are shown in Fig-
ure 2. The soft agreement model does not seem to
be sensitive to initial step size and almost always
converges to a superior solution than the baseline.
6 Joint NER and Alignment Results
We present results for the BI-NER-WA model
in Table 2. By jointly decoding NER with word
alignment, our model not only maintains signifi-
cant improvements in NER performance, but also
yields significant improvements to alignment per-
formance. Overall, joint decoding with NER alone
yields a 10.8% error reduction in AER over the
baseline HMM-aligners, and also gives improve-
0 0.01 0.05
0.1 0.2 0.5
1 2
30001000
800500
300100
5073
74
75
76
77
78
79
80
initial step sizemax no. of iterations
F1 sc
ore
Figure 2: Performance variance of the soft agree-
ment models on the Chinese dev dataset, as a func-
tion of step size (x-axis) and maximum number of
iterations before early stopping (y-axis).
ment over BI-NER in NER. Adding additional
neighborhood constraints gives a further 6% er-
ror reduction in AER, at the cost of a small loss
in Chinese NER. In terms of word alignment re-
sults, we see great increases in F1 and recall, but
precision goes down significantly. This is be-
cause the joint decoding algorithm promotes an ef-
fect of ?soft-union?, by encouraging the two uni-
directional aligners to agree more often. Adding
the neighborhood constraints further enhances this
union effect.
7 Error Analysis and Discussion
We can examine the example in Figure 3 to gain
an understanding of the model?s performance. In
this example, a snippet of a longer sentence pair is
shown with NER and word alignment results. The
monolingual Chinese tagger provides a strong cue
that word f6 is a person name because the unique
4-character word pattern is commonly associated
with foreign names in Chinese, and also the word
is immediately preceded by the word ?president?.
The English monolingual tagger, however, con-
fuses the aligned word e0 with a GPE.
Our bilingual NER model is able to correct this
error as expected. Similarly, the bilingual model
corrects the error over e11. However, the model
also propagates labeling errors from the English
side over the entity ?Tibet Autonomous Region? to
the Chinese side. Nevertheless, the resulting Chi-
nese tags are arguably more useful than the origi-
nal tags assigned by the baseline model.
In terms of word alignment, the HMM models
failed badly on this example because of the long
1079
NER-Chinese NER-English word alignment
P R F1 P R F1 P R F1 AER
HMM-WA - - - - - - 90.43 40.95 56.38 43.62
Mono-CRF 82.50 66.58 73.69 84.24 78.70 81.38 - - - -
Bi-NER 84.87 75.30 79.80 84.47 81.45 82.93 - - - -
Bi-NER-WA 84.42 76.34 80.18 84.25 82.20 83.21 77.45 50.43 61.09 38.91
Bi-NER-WA+NC 84.25 75.09 79.41 84.28 82.17 83.21 76.67 54.44 63.67 36.33
Table 2: Joint alignment and NER test results. +NC means incorporating additional neighbor constraints
from DeNero and Macherey (2011) to the model. Best number in each column is highlighted in bold.
f0 f1 f2 f3 f4 f5 f6
e0 e1 e2 e3 e4 e5 e6 e7 e8 e9 e10 e11
Suolangdaji , president of Tibet Auto. Region branch of Bank of China
B-PER O O O B-GPE I-GPE I-GPE O O B-ORG I-ORG I-ORG
B-PER O O O [B-LOC] [I-LOC] [I-LOC] O O B-ORG I-ORG I-ORG
[B-GPE] O O O [B-LOC] [I-LOC] [I-LOC] O O [O] [O] [B-GPE]
?? ?? ?? ??? ?? ?? ????
B-ORG I-ORG B-GPE O O O B-PER
B-ORG I-ORG [B-LOC] [I-LOC] O O B-PER
B-ORG I-ORG [O] O O O B-PER
Figure 3: An example output of our BI-NER-WA model. Dotted alignment links are the oracle, dashed
links are alignments from HMM baseline, and solid links are outputs of our model. Entity tags in the
gold line (closest to nodes ei and fj) are the gold-standard tags; in the green line (second closest to
nodes) are output from our model; and in the crimson line (furthest from nodes) are baseline output.
distance swapping phenomena. The two unidirec-
tional HMMs also have strong disagreements over
the alignments, and the resulting baseline aligner
output only recovers two links. If we were to take
this alignment as fixed input, most likely we would
not be able to recover the error over e11, but the
joint decoding method successfully recovered 4
more links, and indirectly resulted in the NER tag-
ging improvement discussed above.
8 Related Work
The idea of employing bilingual resources to im-
prove over monolingual systems has been ex-
plored by much previous work. For example,
Huang et al (2009) improved parsing performance
using a bilingual parallel corpus. In the NER
domain, Li et al (2012) presented a cyclic CRF
model very similar to our BI-NER model, and
performed approximate inference using loopy be-
lief propagation. The feature-rich CRF formula-
tion of bilingual edge potentials in their model is
much more powerful than our simple PMI-based
bilingual edge model. Adding a richer bilingual
edge model might well further improve our results,
and this is a possible direction for further experi-
mentation. However, a big drawback of this ap-
proach is that training such a feature-rich model
requires manually annotated bilingual NER data,
which can be prohibitively expensive to generate.
How and where to obtain training signals with-
out manual supervision is an interesting and open
question. One of the most interesting papers in this
regard is Burkett et al (2010b), which explored
an ?up-training? mechanism by using the outputs
from a strong monolingual model as ground-truth,
and simulated a learning environment where a
bilingual model is trained to help a ?weakened?
monolingual model to recover the results of the
strong model. It is worth mentioning that since
our method does not require additional training
and can take pretty much any existing model as
?black-box? during decoding, the richer and more
accurate bilingual model learned from Burkett et
al. (2010b) can be directly plugged into our model.
A similar dual decomposition algorithm to ours
was proposed by Riedel and McCallum (2011)
for biomedical event detection. In their Model
3, the trigger and argument extraction models
are reminiscent of the two monolingual CRFs in
our model; additional binding agreements are en-
forced over every protein pair, similar to how we
enforce agreement between every aligned word
1080
pair. Martins et al (2011b) presented a new DD
method that combines the power of DD with the
augmented Lagrangian method. They showed
that their method can achieve faster convergence
than traditional sub-gradient methods in models
with many overlapping components (Martins et
al., 2011a). This method is directly applicable to
our work.
Another promising direction for improving
NER performance is in enforcing global label
consistency across documents, which is an idea
that has been greatly explored in the past (Sut-
ton and McCallum, 2004; Bunescu and Mooney,
2004; Finkel et al, 2005). More recently, Rush
et al (2012) and Chieu and Teow (2012) have
shown that combining local prediction models
with global consistency models, and enforcing
agreement via DD is very effective. It is straight-
forward to incorporate an additional global consis-
tency model into our model for further improve-
ments.
Our joint alignment and NER decoding ap-
proach is inspired by prior work on improving
alignment quality through encouraging agreement
between bi-directional models (Liang et al, 2006;
DeNero and Macherey, 2011). Instead of enforc-
ing agreement in the alignment space based on
best sequences found by Viterbi, we could opt
to encourage agreement between posterior prob-
ability distributions, which is related to the pos-
terior regularization work by Grac?a et al (2008).
Cromie`res and Kurohashi (2009) proposed an ap-
proach that takes phrasal bracketing constraints
from parsing outputs, and uses them to enforce
phrasal alignments. This idea is similar to our joint
alignment and NER approach, but in our case the
phrasal constraints are indirectly imposed by en-
tity spans. We also differ in the implementation
details, where in their case belief propagation is
used in both training and Viterbi inference.
Burkett et al (2010a) presented a supervised
learning method for performing joint parsing and
word alignment using log-linear models over parse
trees and an ITG model over alignment. The
model demonstrates performance improvements
in both parsing and alignment, but shares the com-
mon limitations of other supervised work in that it
requires manually annotated bilingual joint pars-
ing and word alignment data.
Chen et al (2010) also tackled the problem of
joint alignment and NER. Their method employs a
set of heuristic rules to expand a candidate named
entity set generated by monolingual taggers, and
then rank those candidates using a bilingual named
entity dictionary. Our approach differs in that we
provide a probabilistic formulation of the problem
and do not require pre-existing NE dictionaries.
9 Conclusion
We introduced a graphical model that combines
two HMM word aligners and two CRF NER tag-
gers into a joint model, and presented a dual de-
composition inference method for performing ef-
ficient decoding over this model. Results from
NER and word alignment experiments suggest that
our method gives significant improvements in both
NER and word alignment. Our techniques make
minimal assumptions about the underlying mono-
lingual components, and can be adapted for many
other tasks such as parsing.
Acknowledgments
The authors would like to thank Rob Voigt and
the three anonymous reviewers for their valuable
comments and suggestions. We gratefully ac-
knowledge the support of the National Natural
Science Foundation of China (NSFC) via grant
61133012, the National ?863? Project via grant
2011AA01A207 and 2012AA011102, the Min-
istry of Education Research of Social Sciences
Youth funded projects via grant 12YJCZH304,
and the support of the U.S. Defense Advanced
Research Projects Agency (DARPA) Broad Op-
erational Language Translation (BOLT) program
through IBM.
Any opinions, findings, and conclusion or rec-
ommendations expressed in this material are those
of the authors and do not necessarily reflect the
view of DARPA, or the US government.
References
Yaser Al-Onaizan and Kevin Knight. 2002. Translat-
ing named entities using monolingual and bilingual
resources. In Proceedings of ACL.
Bogdan Babych and Anthony Hartley. 2003. Im-
proving machine translation quality with automatic
named entity recognition. In Proceedings of the
7th International EAMT workshop on MT and other
Language Technology Tools, Improving MT through
other Language Technology Tools: Resources and
Tools for Building MT.
1081
Dimitri P. Bertsekas. 1999. Nonlinear Programming.
Athena Scientific, New York.
Peter F. Brown, Stephen A. Della Pietra, Vincent
J. Della Pietra, and Robert L. Mercer. 1991. Word-
sense disambiguation using statistical methods. In
Proceedings of ACL.
Razvan Bunescu and Raymond J. Mooney. 2004.
Collective information extraction with relational
Markov networks. In Proceedings of ACL.
David Burkett, John Blitzer, and Dan Klein. 2010a.
Joint parsing and alignment with weakly synchro-
nized grammars. In Proceedings of NAACL-HLT.
David Burkett, Slav Petrov, John Blitzer, and Dan
Klein. 2010b. Learning better monolingual mod-
els with unannotated bilingual text. In Proceedings
of CoNLL.
Yufeng Chen, Chengqing Zong, and Keh-Yih Su.
2010. On jointly recognizing and aligning bilingual
named entities. In Proceedings of ACL.
Hai Leong Chieu and Loo-Nin Teow. 2012. Com-
bining local and non-local information with dual de-
composition for named entity recognition from text.
In Proceedings of 15th International Conference on
Information Fusion (FUSION).
Fabien Cromie`res and Sadao Kurohashi. 2009. An
alignment algorithm using belief propagation and a
structure-based distortion model. In Proceedings of
EACL/ IJCNLP.
John DeNero and Dan Klein. 2008. The complexity of
phrase alignment problems. In Proceedings of ACL.
John DeNero and Klaus Macherey. 2011. Model-
based aligner combination using dual decomposi-
tion. In Proceedings of ACL.
Brad Efron and Robert Tibshirani. 1993. An Introduc-
tion to the Bootstrap. Chapman & Hall, New York.
Jenny Rose Finkel, Trond Grenager, and Christopher
Manning. 2005. Incorporating non-local informa-
tion into information extraction systems by Gibbs
sampling. In Proceedings of ACL.
Joao Grac?a, Kuzman Ganchev, and Ben Taskar. 2008.
Expectation maximization and posterior constraints.
In Proceedings of NIPS.
Aria Haghighi, John Blitzer, John DeNero, and Dan
Klein. 2009. Better word alignments with super-
vised ITG models. In Proceedings of ACL.
Eduard Hovy, Mitchell Marcus, Martha Palmer,
Lance Ramshaw, and Ralph Weischedel. 2006.
OntoNotes: the 90% solution. In Proceedings of
NAACL-HLT.
Fei Huang and Stephan Vogel. 2002. Improved named
entity translation and bilingual named entity extrac-
tion. In Proceedings of the 2002 International Con-
ference on Multimodal Interfaces (ICMI).
Liang Huang, Wenbin Jiang, and Qun Liu. 2009.
Bilingually-constrained (monolingual) shift-reduce
parsing. In Proceedings of EMNLP.
Sungchul Kim, Kristina Toutanova, and Hwanjo Yu.
2012. Multilingual named entity recognition using
parallel data and metadata from Wikipedia. In Pro-
ceedings of ACL.
Terry Koo, Alexander M. Rush, Michael Collins,
Tommi Jaakkola, and David Sontag. 2010. Dual
decomposition for parsing with non-projective head
automata. In Proceedings of EMNLP.
Qi Li, Haibo Li, Heng Ji, Wen Wang, Jing Zheng, and
Fei Huang. 2012. Joint bilingual name tagging for
parallel corpora. In Proceedings of CIKM.
Percy Liang, Ben Taskar, and Dan Klein. 2006. Align-
ment by agreement. In Proceedings of HLT-NAACL.
Xiaoyi Ma. 2006. Champollion: A robust parallel text
sentence aligner. In Proceedings of LREC.
Andre? F. T. Martins, Noah A. Smith, Pedro M. Q.
Aguiar, and Ma?rio A. T. Figueiredo. 2011a. Dual
decomposition with many overlapping components.
In Proceedings of EMNLP.
Andre F. T. Martins, Noah A. Smith, Eric P. Xing,
Pedro M. Q. Aguiar, and Ma?rio A. T. Figueiredo.
2011b. Augmenting dual decomposition for map in-
ference. In Proceedings of the International Work-
shop on Optimization for Machine Learning (OPT
2010).
Sebastian Riedel and Andrew McCallum. 2011. Fast
and robust joint models for biomedical event extrac-
tion. In Proceedings of EMNLP.
Alexander M. Rush and Michael Collins. 2012. A tu-
torial on dual decomposition and Lagrangian relax-
ation for inference in natural language processing.
JAIR, 45:305?362.
Alexander M. Rush, David Sontag, Michael Collins,
and Tommi Jaakkola. 2010. On dual decomposi-
tion and linear programming relaxations for natural
language processing. In Proceedings of EMNLP.
Alexander M. Rush, Roi Reichert, Michael Collins, and
Amir Globerson. 2012. Improved parsing and POS
tagging using inter-sentence consistency constraints.
In Proceedings of EMNLP.
Charles Sutton and Andrew McCallum. 2004. Col-
lective segmentation and labeling of distant entities
in information extraction. In Proceedings of ICML
Workshop on Statistical Relational Learning and Its
connections to Other Fields.
1082
