Proceedings of NAACL HLT 2007, Companion Volume, pages 41?44,
Rochester, NY, April 2007. c?2007 Association for Computational Linguistics
Exploring Affect-Context Dependencies for Adaptive System Development
Kate Forbes-Riley
Learning R&D Ctr.
Univ. Pittsburgh
Pittsburgh, PA 15260
forbesk@pitt.edu
Mihai Rotaru
Computer Science Dpt.
Univ. Pittsburgh
Pittsburgh, PA 15260
mrotaru@cs.pitt.edu
Diane J. Litman
Learning R&D Ctr.
Computer Science Dpt.
Univ. Pittsburgh
Pittsburgh, PA 15260
litman@cs.pitt.edu
Joel Tetreault
Learning R&D Ctr.
Univ. Pittsburgh
Pittsburgh, PA 15260
tetreaul@pitt.edu
Abstract
We use ?2 to investigate the context de-
pendency of student affect in our com-
puter tutoring dialogues, targeting uncer-
tainty in student answers in 3 automati-
cally monitorable contexts. Our results
show significant dependencies between
uncertain answers and specific contexts.
Identification and analysis of these depen-
dencies is our first step in developing an
adaptive version of our dialogue system.
1 Introduction
Detecting and adapting to user affect is being ex-
plored by many researchers to improve dialogue sys-
tem quality. Detection has received much atten-
tion (e.g., (Litman and Forbes-Riley, 2004; Lee and
Narayanan, 2005)), but less work has been done on
adaptation, due to the difficulty of developing re-
sponses and applying them at the right time. Most
work on adaptation takes a context-independent ap-
proach: use the same type of response after all in-
stances of an affective state. For example, Liu and
Picard (2005)?s health assessment system responds
with empathy to all instances of user stress.
Research suggests, however, that it may be more
effective to take a context-dependent approach: de-
velop multiple responses for each affective state,
whose use depends on the state?s context. E.g., in the
tutoring domain, Pon-Barry et al (2006) show that
human tutors use multiple responses to uncertain
student answers, depending on the answer?s correct-
ness and prior context. In the information-seeking
domain, it is commonly believed that while an apol-
ogy is a good default response to user frustration (as
in (Klein et al, 2002)), one context requires a differ-
ent response: after several frustrated user turns, the
call should be forwarded to a human operator.
A context-dependent approach to affect adapta-
tion must address 2 issues: in what contexts to adapt,
and what responses to use there. This paper ad-
dresses the first issue and targets student uncertainty
in our computer tutoring dialogues. Although our di-
alogues have a Question-Answer format, our system
contains 275 tutor questions. Treating each question
as a context is too labor-intensive for adaptation de-
velopment and creates a data sparsity issue. Instead
we treat automatically monitorable question proper-
ties as contexts. Here we examine 3 contexts: the di-
alogue act interpretation, and the discourse structure
depth and transition, of the prior tutor question. We
use ?2 to investigate the context dependency of un-
certain student answers (correct and incorrect). Our
results show that some contexts are significantly as-
sociated with uncertain answers. Our next step will
be to use these significant dependencies to develop
system responses to uncertain answers in these con-
texts. These responses will be based both on our
hypotheses about why uncertainty is associated with
these contexts, and on analyses of human tutor re-
sponses to uncertain answers in these contexts.
2 Student Uncertainty and Prior Context
ITSPOKE is a speech-enabled version of a text-
based tutoring system (VanLehn et al, 2002). The
student first types an essay answering one of 5 qual-
itative physics problems. ITSPOKE parses the es-
say, extracts dialogue topics concerning misconcep-
tions, then engages the student in dialogue. In this
study we used 2 ITSPOKE corpora containing 4590
student turns over 185 dialogues from 37 students.
Figure 1 shows an annotated dialogue excerpt.
41
ITSPOKE4: Good. Does the packet have an acceleration? If yes please specify its direction. [SAQ, Advance, D1]
STUDENT4: horizontally forward yes [non-uncertain, incorrect]
ITSPOKE5: Well... To find the packet?s acceleration we will use Newton?s 2nd law. What is the definition of this law? [LAQ,
Push, D2]
STUDENT5: an object in motion tends to stay in motion until it?s act by an outside force [uncertain, incorrect]
ITSPOKE6: Well... Newton?s 2nd law says that the net force acting on an object equals the mass times the acceleration of theobject. We can define Newton?s 2nd law as F=m*a. Hence what can we determine about the acceleration of the packet given
that we know the net force acting on it is not zero and points straight down? [DAQ, Advance, D2]
STUDENT6: I don?t know [uncertain, incorrect]
ITSPOKE7: Well... < further discussion of Newton?s 2nd law...> So once again on the original question. Does the packet have anacceleration? If yes please specify its direction.[SAQ, PopUp, D1]
Figure 1: ITSPOKE Annotated Dialogue Excerpt
2.1 Uncertainty and Correctness Annotations
ITSPOKE, like most computer tutors, responds only
to student correctness. ITSPOKE labels each an-
swer as correct or incorrect1 . If correct, ITSPOKE
moves on to the next question. If incorrect, then for
questions on simple topics, ITSPOKE gives the cor-
rect answer and moves on, while for questions on
complex topics (ITSPOKE4, Figure 1), ITSPOKEinitiates a sub-dialogue with remediation questions
(ITSPOKE5 - ITSPOKE6), before moving on.
Recent computer tutoring research has shown in-
terest in responding to student affect2 over cor-
rectness. Uncertainty is of particular interest: re-
searchers hypothesize that uncertainty and incorrect-
ness each create an opportunity to learn (VanLehn
et al, 2003). They cannot be equated, however.
First, an uncertain answer may be correct or incor-
rect (Pon-Barry et al, 2006). Second, uncertainty in-
dicates that the student perceives a possible miscon-
ception in their knowledge. Thus, system responses
to uncertain answers can address both the correct-
ness and the perceived misconception.
In our ITSPOKE corpora, each student answer
has been manually annotated as uncertain or non-
uncertain3 : uncertain is used to label answers ex-
pressing uncertainty or confusion about the material;
non-uncertain is used to label all other answers.
1We have also manually labeled correctness in our data;
agreement between ITSPOKE and human is 0.79 Kappa (90%).
2We use ?affect? to cover emotions and attitudes that affect
how students communicate. Although some argue ?emotion?
and ?attitude? should be distinguished, some speech researchers
find the narrow sense of ?emotion? too restrictive because it ex-
cludes states where emotion is present but not full-blown, in-
cluding arousal and attitude (Cowie and Cornelius, 2003).
3A second annotator relabeled our dataset, yielding inter-
annotator agreement of 0.73 Kappa (92%).
2.2 Context Annotations
Here we examine 3 automatically monitorable tutor
question properties as our contexts for uncertainty:
Tutor Question Acts: In prior work one annotator
labeled 4 Tutor Question Acts in one ITSPOKE cor-
pus (Litman and Forbes-Riley, 2006)4: Short (SAQ),
Long (LAQ), and Deep Answer Question (DAQ) dis-
tinguish the question in terms of content and the type
of answer it requires. Repeat (RPT) labels variants
of ?Can you repeat that?? after rejections. From
these annotations we built a hash table associating
each ITSPOKE question with a Question Act label;
with this table we automatically labeled ITSPOKE
questions in our second ITSPOKE corpus.
Discourse Structure Depth/Transition: In prior
work we showed that the discourse structure Depth
and Transition for each ITSPOKE turn can be au-
tomatically annotated (Rotaru and Litman, 2006).
E.g., as shown in Figure 1, ITSPOKE4,7 have depth1 and ITSPOKE5,6 have depth 2. We combine lev-els 3 and above (3+) due to data sparsity. 6 Transi-
tion labels represent the turn?s position relative to the
prior ITSPOKE turn: NewTopLevel labels the first
question after an essay. Advance labels questions at
the same depth as the prior question (ITSPOKE4,6).
Push labels the first question in a sub-dialogue
(after an incorrect answer) (ITSPOKE5). After asub-dialogue, ITSPOKE asks the original question
again, labeled PopUp (ITSPOKE7), or moves on tothe next question, labeled PopUpAdv. SameGoal la-
bels both ITSPOKE RPTS (after rejections) and re-
peated questions after timeouts.
4Our Acts are based on related work (Graesser et al, 1995).
Two annotators labeled the Acts in 8 dialogues in a parallel hu-
man tutoring corpus, with agreement of 0.75 Kappa (90%).
42
3 Uncertainty Context Dependencies
We use the ?2 test to investigate the context depen-
dency of uncertain (unc) or non-uncertain (nonunc)
student answers that are correct (C) or incorrect (I).
First, we compute an overall ?2 value between each
context variable and the student answer variable. For
example, the Question Act variable (QACT) has 4
values: SAQ, LAQ, DAQ, RPT. The answer vari-
able (SANSWER) also has 4 values: uncC, uncI,
nonuncC, nonuncI. Table 1 (last column) shows the
?2 value between these variables is 203.38, which
greatly exceeds the critical value of 16.92 (p? 0.05,
df=9), indicating a highly significant dependency.
Significance increases as the ?2 value increases.
Dependency Obs. Exp. ?2
QACT ? SANSWER 203.38
LAQ ? uncC + 72 22 133.98
LAQ ? uncI + 43 27 11.17
LAQ ? nonuncC - 96 151 50.13
LAQ ? nonuncI = 48 60 3.10
DAQ ? uncC = 22 22 0.01
DAQ ? uncI + 37 27 4.57
DAQ ? nonuncC = 135 149 3.53
DAQ ? nonuncI = 63 59 0.35
SAQ ? uncC - 285 328 41.95
SAQ ? uncI - 377 408 17.10
SAQ ? nonuncC + 2368 2271 66.77
SAQ ? nonuncI - 875 898 5.31
RPT ? uncC - 7 14 4.15
RPT ? uncI = 22 18 1.25
RPT ? nonuncC - 70 98 20.18
RPT ? nonuncI + 70 39 33.59
Table 1: Tutor Question Act Dependencies (p?.05:
critical ?2=16.92 (df=9); critical ?2=3.84 (df=1))
However, this does not tell us which variable val-
ues are significantly dependent. To do this, we create
a binary variable from each value of the context and
answer variables. E.g., the binary variable for LAQ
has 2 values: ?LAQ? and ?Anything Else?, and the
binary variable for uncC has 2 values: ?uncC? and
?Anything Else?. We then compute the ?2 value be-
tween the binary variables. Table 1 shows this value
is 133.98, which greatly exceeds the critical value of
3.84 (p? 0.05, df=1). The table also shows the ob-
served (72) and expected (22) counts. Comparison
determines the sign of the dependency: uncC occurs
significantly more than expected (+) after LAQ. The
?=? sign indicates a non-significant dependency.
Table 1 shows uncertain answers (uncC and uncI)
occur significantly more than expected after LAQs.
In contrast, non-uncertain answers occur signifi-
cantly less (-), or aren?t significantly dependent (=).
Also, uncI occurs significantly more than expected
after DAQs. We hypothesize that LAQs and DAQs
are associated with more uncertainty because they
are harder questions requiring definitions or deep
reasoning. Not surprisingly, uncertain (and incor-
rect) answers occur significantly less than expected
after SAQs (easier fill-in-the-blank questions). Un-
certainty shows very weak dependencies on RPTs.
Table 2 shows that Depth1 is associated with more
correctness and less uncertainty overall. Both types
of correct answer occur significantly more than ex-
pected, but this dependency is stronger for nonuncC.
Both incorrect answers occur significantly less than
expected, but this dependency is stronger for uncI.
Dependency Obs. Exp. ?2
Depth# ? SANSWER 53.85
Depth1 ? uncC + 250 228 5.46
Depth1 ? uncI - 230 283 27.55
Depth1 ? nonuncC + 1661 1579 24.73
Depth1 ? nonuncI - 575 625 12.66
Depth2 ? uncC - 78 101 7.80
Depth2 ? uncI + 156 125 11.26
Depth2 ? nonuncC - 664 699 5.65
Depth2 ? nonuncI + 304 277 4.80
Depth3+ ? uncC = 58 57 0.05
Depth3+ ? uncI + 93 70 9.76
Depth3+ ? nonuncC - 344 391 15.66
Depth3+ ? nonuncI + 177 155 4.94
Table 2: Depth Dependencies (p?.05: critical
?2=12.59 (df=6); critical ?2=3.84 (df=1))
At Depths 2 and 3+, correct answers occur sig-
nificantly less than expected or show no signifi-
cance. Incorrect answers occur significantly more
than expected, and the dependencies are stronger for
uncI. We hypothesize that deeper depths are asso-
ciated with increased uncertainty and incorrectness
because they correspond to deeper knowledge gaps;
uncertainty here may also relate to a perceived lack
of cohesion between sub-topic and larger solution.
Table 3 shows Pushes have the same dependen-
cies as deeper depths (increased uncertainty and in-
correctness); however, here the uncI dependency is
only slightly stronger than nonuncI, which suggests
that increased uncertainty at deeper depths is more
reliably associated with remediation questions after
the Push. Although uncertainty shows only weak
43
dependencies on PopUps, after PopUpAdvs the uncI
dependency is strong, with uncI occurring more than
expected. We hypothesize that this dependency re-
lates to students losing track of the original ques-
tion/larger topic. Uncertainty shows only weak de-
pendencies on Advances. After NewTopLevels, in-
correct answers occur less than expected, but the de-
pendency is stronger for nonuncI. After SameGoals,
incorrect answers occur more than expected, but the
dependency is stronger for nonuncI. Compared with
the RPT results, the SameGoal results suggest stu-
dents feel increased uncertainty after timeouts.
Dependency Obs. Exp. ?2
TRANS ? SANSWER 190.97
Push ? uncC = 68 57 2.89
Push ? uncI + 100 70 16.37
Push ? nonuncC - 313 392 44.51
Push ? nonuncI + 193 155 14.13
PopUp ? uncC - 23 36 5.89
PopUp ? uncI - 32 45 4.68
PopUp ? nonuncC = 260 251 0.81
PopUp ? nonuncI + 117 99 4.47
PopUpAdv ? uncC = 8 13 2.50
PopUpAdv ? uncI + 32 17 16.22
PopUpAdv ? nonuncC - 76 93 7.72
PopUpAdv ? nonuncI = 44 37 1.89
Advance ? uncC = 217 205 1.70
Advance ? uncI - 223 254 9.06
Advance ? nonuncC + 1465 1416 8.66
Advance ? nonuncI - 530 560 4.51
NewTopLevel ? uncC = 53 54 0.04
NewTopLevel ? uncI - 49 67 6.47
NewTopLevel ? nonuncC + 463 375 57.33
NewTopLevel ? nonuncI - 80 148 47.63
SameGoal ? uncC = 17 21 0.70
SameGoal ? uncI + 43 25 14.24
SameGoal ? nonuncC - 92 152 44.25
SameGoal ? nonuncI + 92 56 31.43
Table 3: Transition Dependencies (p?.05: critical
?2=25.00 (df=15); critical ?2=3.84 (df=1))
4 Current Directions
We analyzed dependencies between uncertain stu-
dent answers and 3 automatically monitorable con-
texts. We plan to examine more contexts, such as
a Topic Repetition variable that tracks similar ques-
tions about a topic (e.g. gravity) across dialogues.
Our next step will be to use the significant de-
pendencies to develop system responses to uncer-
tain answers in these contexts. These responses will
be based both on our hypotheses about why uncer-
tainty is significantly associated with these contexts,
as well as on analyses of human tutor responses
in these contexts, using our human tutoring corpus,
which was collected with our first ITSPOKE corpus
using the same experimental procedure.
We also plan to investigate context dependencies
for other affective states, such as student frustration.
Acknowledgments
NSF (#0631930, #0354420 and #0328431) and
ONR (N00014-04-1-0108) support this research.
References
R. Cowie and R. R. Cornelius. 2003. Describing the
emotional states that are expressed in speech. Speech
Communication, 40:5?32.
A. Graesser, N. Person, and J. Magliano. 1995. Collabo-
rative dialog patterns in naturalistic one-on-one tutor-ing. Applied Cognitive Psychology, 9:495?522.
J. Klein, Y. Moon, and R. Picard. 2002. This computer
responds to user frustration: Theory, design, and re-sults. Interacting with Computers, 14:119?140.
C. M. Lee and S. Narayanan. 2005. Towards detect-
ing emotions in spoken dialogs. IEEE Transactions
on Speech and Audio Processing, 13(2), March.
D. Litman and K. Forbes-Riley. 2004. Predicting student
emotions in computer-human tutoring dialogues. In
Proc. ACL, pages 352?359.
D. J. Litman and K. Forbes-Riley. 2006. Correlations
between dialogue acts and learning in spoken tutoringdialogues. Natural Language Engineering, 12(2).
K. Liu and R. W. Picard. 2005. Embedded empathy
in continuous, interactive health assessment. In CHI
Workshop on HCI Challenges in Health Assessment.
H. Pon-Barry, K. Schultz, E. Bratt, B. Clark, and S. Pe-
ters. 2006. Responding to student uncertainty in spo-ken tutorial dialogue systems. International Journal
of Artificial Intelligence in Education, 16:171?194.
M. Rotaru and D. Litman. 2006. Exploiting discoursestructure for spoken dialogue performance analysis. In
Proceedings of EMNLP, Sydney, Australia.
K. VanLehn, P. W. Jordan, and C. P. Rose? et al 2002. Thearchitecture of Why2-Atlas: A coach for qualitativephysics essay writing. In Proceedings of ITS.
K. VanLehn, S. Siler, and C. Murray. 2003. Why doonly some events cause learning during human tutor-ing? Cognition and Instruction, 21(3):209?249.
44
