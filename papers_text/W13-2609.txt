Proceedings of the Workshop on Cognitive Modeling and Computational Linguistics, pages 75?83,
Sofia, Bulgaria, August 8, 2013. c?2013 Association for Computational Linguistics
Concreteness and Corpora: A Theoretical and Practical Analysis  
 
Felix Hill 
Computer Laboratory 
University of Cambridge 
fh295@cam.ac.uk 
Douwe Kiela 
Computer Laboratory 
University of Cambridge 
dlk427@cam.ac.uk 
Anna Korhonen 
Computer Laboratory 
University of Cambridge 
alk23@cam.ac.uk 
 
  
Abstract 
An increasing body of empirical evidence 
suggests that concreteness is a fundamental 
dimension of semantic representation. By im-
plementing both a vector space model and a 
Latent Dirichlet Allocation (LDA) Model, we 
explore the extent to which concreteness is re-
flected in the distributional patterns in corpora.  
In one experiment, we show that that vector 
space models can be tailored to better model 
semantic domains of particular degrees of 
concreteness.   In a second experiment, we 
show that the quality of the representations of 
abstract words in LDA models can be im-
proved by supplementing the training data 
with information on the physical properties of 
concrete concepts.  We conclude by discussing 
the implications for computational systems 
and also for how concrete and abstract con-
cepts are represented in the mind 
1 Introduction 
A growing body of theoretical evidence empha-
sizes the importance of concreteness to semantic 
representations.  This fact has not been widely 
exploited in NLP systems, despite its clear theo-
retical relevance to tasks such as word-sense in-
duction and compositionality modeling.  In this 
paper, we take a first step towards integrating 
concreteness into NLP by testing the extent to 
which it is reflected by the superficial (distribu-
tional) patterns in corpora.  The motivation is 
both theoretical and practical: We consider the 
implications for the development of computa-
tional systems and also for how concrete and ab-
stract concepts are represented in the human 
mind.  Experimenting with two popular methods 
of extracting lexical representations from text, 
we show both that these approaches are sensitive 
to concreteness and that their performance can be 
improved by adapting their implementation to 
the concreteness of the domain of application.  In 
addition, our findings offer varying degrees of 
support to several recent proposals about concep-
tual representation.   
In the following section we review recent 
theoretical and practical work. In Section 3 we 
explore the extent to which concreteness is re-
flected by Vector-Space Models of meaning 
(VSMs), and in Section 4 we conduct a similar 
analysis for (Bayesian) Latent Dirichlet Alloca-
tion (LDA) models.   We conclude, in Section 5, 
by discussing practical and theoretical implica-
tions.     
2 Related work 
2.1 Concreteness 
Empirical evidence indicates important cognitive 
differences between abstract concepts, such as 
guilt or obesity, and concrete concepts, such as 
chocolate or cheeseburger.  It has been shown 
that concrete concepts are more easily learned 
and remembered than abstract concepts, and that 
language referring to concrete concepts is more 
easily processed (Schwanenflugel, 1991).  There 
are cases of brain damage in which either ab-
stract or concrete concepts appear to be specifi-
cally impaired (Warrington, 1975), and function-
al magnetic resonance imaging (fMRI) studies 
implicate overlapping but partly distinct neural 
systems in the processing of the two concept 
types (Binder et al, 2005).  Further, there is in-
creasing evidence that concrete concepts are 
represented via intrinsic properties whereas ab-
stract representations encode extrinsic relations 
to other concepts (Hill et al, in press). However, 
while these studies together suggest that con-
creteness is fundamental to human conceptual 
representation, much remains to be understood 
about the precise cognitive basis of the ab-
stract/concrete distinction.  Indeed, the majority 
of theoretically motivated studies of conceptual 
representation focus on concrete domains, and 
75
comparatively little has been established empiri-
cally about abstract concepts. 
Despite this support for the cognitive impor-
tance of concreteness, its application to computa-
tional semantics has been limited to date.  One 
possible reason for this is the difficulty in mea-
suring lexical concreteness using corpora alone 
(Kwong, 2008).  Turney et al (2011) overcome 
this hurdle by applying a semi-supervised me-
thod to quantify noun concreteness.  Using this 
data, they show that a disparity in the concrete-
ness between elements of a construction can faci-
litate metaphor identification. For instance, in the 
expressions kill the process or black comedy, a 
verb or adjective that generally occurs with a 
concrete argument takes an abstract argument. 
Turney et al show that a supervised classifier 
can exploit this effect to correctly identify 79% 
of adjective-noun and verb-object constructions 
as literal or metaphorical.  Although these results 
are clearly promising, to our knowledge Turney 
et al?s paper is unique in integrating corpus-
based methods and concreteness in NLP systems.   
1.2 Association / similarity 
A proposed distinction between abstract and 
concrete concepts that is particularly important 
for the present work relates to the semantic rela-
tions association and (semantic) similarity (see 
e.g. Crutch et al 2009; Resnik, 1995). The dif-
ference between these relations is exemplified by 
the concept pairs {car, petrol} and {car, van}.  
Car is said to be (semantically) similar to van, 
and associated with (but not similar to) petrol.  
Intuitively, the basis for the similarity of car and 
bike may be their common physical features 
(wheels) or the fact that they fall within a clearly 
definable category (modes of transport).  In con-
trast, the basis for the association between car 
and petrol may be that they are often found to-
gether or the clear functional relationship be-
tween them.  The two relations are neither mu-
tually exclusive nor independent; bike and car 
are related to some degree by both association 
and similarity.  
Based on fresults of behavioral experiments, 
Crutch et al (2009) make the following proposal 
concerning how association and similarity inte-
ract with concreteness: 
 
(C) The conceptual organization of abstract con-
cepts is governed by association, whereas the 
organization of concrete concepts is governed by 
similarity.   
 
Crutch et al?s hypothesis derives from experi-
ments in which participants selected the odd-one-
out from lists of five words appearing on a 
screen. The lists comprised either concrete or 
abstract words (based on ratings of six infor-
mants) connected either by similarity (e.g. dog, 
wolf, fox etc.; theft, robbery, stealing etc.) or 
association (dog, bone, collar etc.; theft, law, vic-
tim etc.), with an unrelated odd-one-out item in 
each list. Controlling for frequency and position, 
subjects were both significantly faster and more 
accurate if the related words were either abstract 
and associated or concrete and similar. These 
results support (C) on the basis that decision 
times are faster when the related items form a 
more coherent group, rendering the odd-one out 
more salient.  Hill et al (in press) tested the same 
hypothesis on a larger scale, analyzing over 
18,000 concept pairs scored by human annotators 
for concreteness as well as the strength of associ-
ation between them.  They found a moderate in-
teraction between concreteness and the correla-
tion between association strength and similarity 
(as measured using WordNet), but concluded 
that the strength of the effect was not sufficiently 
strong to either confirm or refute (C). 
Against this backdrop, the present work ex-
amines how association, similarity and concrete-
ness are reflected in LDA models and, first, 
VSMs.  In both cases we test Hypothesis (C) and 
related theoretical proposals, and discuss whether 
these findings can lead to better performing se-
mantic models.   
3 Vector Space Models 
Vector space models (VSMs) are perhaps the 
most common general method of extracting se-
mantic representations from corpora (Sahlgren, 
2006; Turney & Pantel, 2010).  Words are 
represented in VSMs as points in a (geometric) 
vector space. The dimensions of the space cor-
respond to the model features, which in the sim-
plest case are high frequency words from the 
corpus.  In such models, the position of a word 
representation along a given feature dimension 
depends on how often that word occurs within a 
specified proximity to tokens of the feature word 
in the corpus.  The exact proximity required is an 
important parameter for model implementation, 
and is referred to as the context window.  Finally, 
the degree to which two word representations are 
related can be calculated as some function of the 
distance between the corresponding points in the 
semantic space.   
76
3.1 Motivation 
VSMs are well established as a method of quan-
tifying relations between word concepts and have 
achieved impressive performance in related NLP 
tasks (Sahlgren, 2006; Turney & Pantel, 2010).  
In these studies, however, it is not always clear 
exactly which semantic relation is best reflected 
by the implemented models.  Indeed, research 
has shown that by changing certain parameter 
settings in the standard VSM architecture, mod-
els can be adapted to better reflect one relation 
type or another.  Specifically, models with 
smaller context windows are reportedly better at 
reflecting similarity, whereas models with larger 
windows better reflect association. (Agirre et al, 
2009; Peirsman et al, 2008) 
Our experiments in this section aim first to 
corroborate these findings by testing how models 
of varying context window sizes perform on em-
pirical data of both association and similarity.  
We then test if this effect differentially affects 
performance on concrete and abstract words.   
3.2 Method  
We employ a conventional VSM design, extract-
ing representations from the (unlemmatised) 
British National Corpus (Leech et al, 1994) with 
stopwords removed.   In the vector representation 
of each noun, our dimension features are the 
50,000 most frequently occurring (non-
stopword) words in the corpus.    We experiment 
with window sizes of three, five and nine (one, 
two and four words either side of the noun, 
counting stopwords).  Finally, we apply point-
wise mutual information (PMI) weighting of our 
co-occurrence frequencies, and measure similari-
ty between weighted noun vectors by the cosine 
of the angle between them in the vector space.    
To evaluate modeling of association, we use 
the University of South Florida (USF) Free-
association Norms (Nelson & McEvoy, 2012).  
The USF data consist of over 5,000 words paired 
with their free associates.  To elicit free asso-
ciates, more than 6,000 participants were pre-
sented with cue words and asked to ?write the 
first word that comes to mind that is meaningful-
ly related or strongly associated to the presented 
word?.  For a cue word c and an associate a, the 
forward association strength (association) from 
c to a is the proportion of participants who pro-
duced a when presented with c.  association is 
thus a measure of the strength of an associate 
relative to other associates of that cue.  The USF 
data is well suited to our purpose because many 
cues and associates in the data have a concrete-
ness score, taken from either the norms of Paivio, 
Yuille and Madigan (1968) or Toglia and Battig 
(1978).  In both cases contributors were asked to 
rate words based on a scale of 1 (very abstract) to 
7 (very concrete).1  We extracted the all 2,230 
nouns from the USF data for which concreteness 
scores were known, yielding a total of 15,195 
noun-noun pairs together with concreteness and 
association values.   
Although some empirical word-similarity da-
tasets are publically available, they contain few if 
any abstract words (Finkelstein et al, 2002; Ru-
benstein & Goodenough, 1965).  Therefore to 
evaluate similarity modeling, we use Wu-Palmer 
Similarity (similarity) (Wu & Palmer, 1994), a 
word similarity metric based on the position of 
the senses of two words in the WordNet taxono-
my (Felbaum, 1998).  similarity can be applied to 
both abstract and concrete nouns and achieves a 
high correlation, with human similarity judg-
ments (Wu & Palmer, 1994).2     
3.3 Results 
In line with previous studies, we observed that 
VSMs with smaller window sizes were better 
able to predict similarity.  The model with win-
dow size 3 achieves a higher correlation with 
similarity (Spearman rank rs  = -0.29) than the 
model with window size 9 (rs  = -0.25).  Howev-
er, the converse effect for association was not 
observed: Model correlation with association 
was approximately constant over all window siz-
es.  These effects are illustrated in Fig. 1.  
 
                                                 
1Although concreteness is well understood intuitively, it 
lacks a universally accepted definition.  It is often described 
in terms of reference to sensory experience (Paivio et al, 
1968), but also connected to specificity; rose is often consi-
dered more concrete than flora.  The present work does not 
address this ambiguity.     
2 similarity achieves a Pearson correlation of r  = .80 on 
the  30 concrete word pairs in the Miller & Charles (1991) 
data.   
0.123 0.125
0.12
0.286
0.29
0.241
0.0
0.1
0.2
0.3
3 5 9
Window
C
o
r
r
e
l
a
t
i
o
n
Association
Similarity
77
Figure 1:  Spearman correlations between VSM out-
put and association and similarity for different win-
dow sizes. 
 
In addressing the theoretical Hypothesis (C) we 
focused on the output of our VSM of window 
size five, although the same trends were ob-
served over all three models.  Over all 18,195 
noun-noun pairs the correlation between the 
model output and association was significant (rs  
= 0.13, p < 0.001) but notably lower than the cor-
relation with similarity (rs  = -0.29, p < 0.001).  
To investigate the effect of concreteness, we 
ranked each pair in our sample by the total con-
creteness of both nouns, and restricted our analy-
sis to the 1000 most concrete and 1000 most ab-
stract pairs.  The models captured association 
better over the abstract pairs than concrete con-
cepts, but reflected similarity better over the con-
crete concepts.  The strength of this effect is illu-
strated in Fig. 2.   
 
 
Figure 2: Spearman correlation values between VSM 
output and similarity and association over subsets of 
concrete and abstract pairs. 
 
Given that small window sizes are optimal for 
modeling similarity, and that WSMs appear to 
model similarity better over concrete concepts 
than over abstract concepts, we explored whether 
different window sizes were optimal for either 
abstract or concrete word pairs. When comparing 
the model output to association, no interaction 
between window size and concreteness was ob-
served.  However, there was a notable interaction 
when considering performance in modeling simi-
larity.  As illustrated in Fig. 3, performance on 
concrete word pairs is better for smaller window 
sizes, whereas with abstract word pairs a larger 
window size is preferable.   
 
 
Figure 3:  Spearman correlation values between VSM 
output and similarity and association for different 
window sizes over abstract and concrete word pair 
subsets 
3.4 Conclusion 
Our results corroborate the body of VSM re-
search that reports better performance from small 
window sizes in modeling similarity.  A likely 
explanation for this finding is that similarity is a 
paradigmatic relation: Two similar entities can 
be plausibly exchanged in most linguistic con-
texts.  Small context windows emphasize prox-
imity, which loosely reflects structural relation-
ships such as verb-object, ensuring that paradig-
matically related entities score highly.  Models 
with larger context windows cannot discern pa-
radigmatically and syntagmatically related enti-
ties in this way.  The performance of our models 
on the association dataset did not support the 
converse conclusion that larger window sizes 
perform better.  Overall, each of the three models 
was notably better at capturing similarity than 
association.  This suggests that the core architec-
ture of WSMs is not well suited to modeling as-
sociation.  Indeed, ?first order? models that di-
rectly measure word co-occurrences, rather than 
connecting them via features, seem to perform 
better at this task (Chaudhari et al, 2011).  This 
fact is consistent with the view that association is 
a more basic or fundamental semantic relation 
from which other more structured relations are 
derived.  
The fact that the USF association data re-
flects the instinctive first response of participants 
when presented with a cue word is important for 
interpreting the results with respect to Hypothe-
sis (C).  Our findings suggest that VSMs are bet-
ter able to model this data for abstract word pairs 
than for concrete word pairs.  This is consistent 
with the idea that language fundamentally deter-
mines which abstract concepts come to be asso-
ciated or connected in the mind.  Conversely, the 
0.125
0.108
0.215
0.297
0.0
0.1
0.2
0.3
Association Similarity
Relation Type
C
o
r
r
e
l
a
t
i
o
n
Abstract
Concrete
0.202
0.272
0.223
0.254
0.14
0.086
0.104
0.099
0.0
0.1
0.2
3 - Similarity 9 - Similarity 3 - Assoc. 9 - Assoc.
Window size - Relation type
C
o
r
r
e
l
a
t
i
o
n
Abstract
Concrete
78
fact that the model reflects associations between 
concrete words less well suggests that the impor-
tance of extra-linguistic information is lower for 
connecting concrete concepts in this instinctive 
way.  Indeed, it seems plausible that the process 
by which concrete concepts become associated 
involves visualization or some other form of per-
ceptual reconstruction. Consistent with Hypothe-
sis (C), this reconstruction, which is not possible 
for abstract concepts, would naturally reflect si-
milarity to a greater extent than linguistic context 
alone.   
Finally, when modeling similarity, the ad-
vantage of a small window increases as the 
words become more concrete.  Similarity be-
tween concrete concepts is fundamental to cogni-
tive theories involving the well studied notions 
of prototype and categorization (Rosch, 1975; 
Rogers & McClelland, 2003).   In contrast, the 
computation of abstract similarity is intuitively a 
more complex cognitive operation.  Although the 
accurate quantification of abstract similarity may 
be beyond existing corpus-based methods, our 
results suggest that a larger context window 
could in fact be marginally preferable should 
VSMs be applied to this task.   
Overall, our findings show that the design of 
VSMs can be tailored to reflect particular seman-
tic relations and that this in turn can affect their 
performance on different semantic domains, par-
ticularly with respect to concreteness.  In the 
next section, we investigate whether the same 
conclusions should apply to a different class of 
distributional model.        
4 Latent Dirichlet Allocation Models 
LDA models are trained on corpora that are di-
vided into sections (typically documents), ex-
ploiting the principle that words appearing in the 
same document are likely to have similar mean-
ings.  In an LDA model, the sections are viewed 
as having been generated by random sampling 
from unknown latent dimensions, which are 
represented as probability distributions (Dirichlet 
distributions) over words.  Each document can 
then be represented by a probability distribution 
over these dimensions, and by considering the 
meaning of the dimensions, the meaning of the 
document can be effectively characterized.  More 
importantly, because each latent dimension clus-
ters words of a similar meaning, the output of 
such models can be exploited to provide high 
quality lexical representations (Griffiths et al, 
2007).  Such a word representation encodes the 
extent to which each of the latent dimensions 
influences the meaning of that word, and takes 
the form of a probability distribution over these 
dimensions.  The degree to which two words are 
related can then be approximated by any function 
that measures the similarity or difference be-
tween distributions.        
4.1 Motivation 
In recent work, Andrews et al (2009) explore 
ways in which LSA models can be modified to 
improve the quality of their lexical representa-
tions.  They propose that concepts are acquired 
via two distinct information sources: experiential 
data ? the perceptible properties of objects, and 
distributional data ? the superficial patterns of 
language.  To test this hypothesis, Andrews et al 
construct three different LDA models, one 
trained on experiential data, one trained in the 
conventional manner on running text, and one 
trained on the same text but with the experiential 
data appended.  They evaluate the quality of the 
lexical representations in the three models by 
calculating the Kulback-Leibler divergence be-
tween the representation distributions to measure 
how closely related two words are (Kullback & 
Leibler, 1951).  When this data was compared 
with the USF association data, the combined 
model performed better than the corpus-based 
model, which in turn performed better than the 
features-only model.  Andrews et al concluded 
that both experiential and distributional data are 
necessary for the acquisition of good quality lex-
ical representations. 
     As well as suggesting a way to improve the 
performance of LDA models on NLP tasks by 
supplementing the training data, the approach 
taken by Andrews et al may be useful for better 
understanding the nature of the abstract/concrete 
distinction.  In recent work, Hill et al (in press) 
present empirical evidence that concrete con-
cepts are represented in terms of intrinsic fea-
tures or properties whereas abstract concepts are 
represented in terms of connections to other 
(concrete and abstract) concepts.  For example, 
the features [legs], [tail], [fur], [barks] are all 
central aspects of the concrete representation of 
dog, whereas the representation of the abstract 
concept love encodes connections to other con-
cepts such as heart, rose, commitment and hap-
piness etc.  If a feature-based representation is 
understood to be constructed from physical or 
perceptible properties (which themselves may be 
basic or fundamental concrete representations), 
Hill et al?s characterization of concreteness can 
be summarized as follows:  
79
 
(H) Concreteness correlates with the degree to 
which conceptual representations are feature-
based 
 
Because such differences in representation struc-
ture would in turn entail differences in the com-
putation of similarity, (H) is closely related to a 
proposal of Markman and Stilwell (2001; see 
also Gentner & Markman, 2007):  
 
(M) Computing similarity among concrete con-
cepts involves a feature-comparison operation, 
whereas similarity between abstract concepts is 
a structural, analogy-like, comparison.   
 
The findings of Andrews et al do not address 
(H) or (M) directly, for two reasons. Firstly, they 
evaluate their model on a set that includes no 
abstract concepts.  Secondly, they compare their 
model output to association data without testing 
how well it reflects similarity.  In this section we 
therefore reconstruct the Andrews models and 
evaluate how well they reflect both association 
and similarity across a larger set of abstract and 
concrete concepts.   
4.2  Method/materials 
We reconstruct two of the three models devel-
oped by Andrews et al (2009), excluding the 
features-only model because of the present focus 
on corpus-based approaches.  However, while 
the experiential data applied in the Andrews et 
al. combined model was that collected by Vig-
liocco et al (2004), we use the publicly available 
McRae feature production norms (McRae et al, 
2005).  The McRae data consist of 541 concrete 
noun concepts together with features for each 
elicited from 725 participants.  In the data collec-
tion, feature was understood in a very loose 
sense, so that participants were asked to list both 
physical and functional properties of the nouns in 
addition to encyclopedic facts.  However, for the 
present work, we filter out those features that 
were not perceptual properties using McRae et 
al.?s feature classes, leaving a total of 1,285 fea-
ture types, such as [has_claws] and 
[made_of_brass].  The importance of each fea-
ture to the representation of a given concept is 
reflected by the proportion of participants who 
named that feature in the elicitation experiment.  
For each noun concept we therefore extract a 
corresponding probability distribution over fea-
tures. 
The model design and inference are identical 
to those applied by Andrews et al  Our distribu-
tional model contains 250 latent dimensions and 
was trained using a Gibbs Sampling algorithm on 
approximately 7,500 sections of the BNC with 
stopwords removed.3  The combined model con-
tains 350 latent dimensions, and was trained on 
the same BNC data.  However, for each instance 
of one of the 541 McRae concept words, a fea-
ture is drawn at random from the probability dis-
tribution corresponding to that word and ap-
pended to the training data.  The latent dimen-
sions in the combined model therefore corres-
pond to probability distributions both over words 
and over features. This leads to an important dif-
ference between how words come to be related in 
the distributional model and in the combined 
model.  Both models infer connections between 
words by virtue of their occurrence either in the 
same document or in pairs of documents for 
which the same latent dimensions are prominent.  
In the distributional model, it is the words in a 
document that determines which latent dimen-
sions are ultimately prominent, whereas the in 
combined model it is both the words and the fea-
tures in that document.  Therefore, in the com-
bined model, two words can come to be related 
because they occur not only in documents whose 
words are related, but also in documents whose 
features are related.  For words in the McRae 
data, this has the effect of strengthening the rela-
tionship between words with common features.  
More interestingly, because it alters which latent 
dimensions are most prominent for each docu-
ment, it should also influence the relationship 
between words not in the McRae data.   
We evaluate the performance of our models in 
reflecting free association (association) and simi-
larity (similarity).  To obtain test items we rank 
the 18,195 noun-noun pairs from the USF data 
by the product of the two (BNC) word frequen-
cies and select the 5,000 highest frequency pairs.   
4.3 Results 
As expected, the correlation of the combined 
model output with association was greater than 
the correlation of the distributional model output.  
Notably, however, as illustrated in Fig. 4, we 
observed far greater differences between the 
combined and the distributional models when 
comparing to similarity.  Over all noun pairs, the 
addition of features in the combined model im-
                                                 
3 Code for model implementation was taken from Mark 
Andrews : http://www.mjandrews.net/code/index.html  
80
proved the correlation with similarity from 
Spearman rs  =  0.09  to  rs  =  0.15.   
 
Figure 4:  Spearman correlations between distribu-
tional and combined model outputs, similarity and 
association  
 
In order to address Hypothesis (C) (Section 2.2), 
we analyzed the output of the combined model 
on subsets of the 1000 most abstract and concrete 
word pairs in our data as before.  Perhaps surpri-
singly, as shown in Fig. 5, when comparing with 
similarity, the model performed better over ab-
stract pairs, whereas when comparing with asso-
ciation the model performed better over concrete 
pairs.  However, when these concrete pairs were 
restricted to those for which at least one of the 
two words was in the McRae data, and hence to 
which features had been appended in the corpus, 
the ability of the model to reflect similarity in-
creased significantly.          
 
Figure 5:  Spearman correlations between combined 
model output and similarity and association on differ-
ent word pair subsets  
 
Finally, to address hypotheses (H) and (M) we 
compared the previous analysis of the combined 
model output to the equivalent output from the 
distributional model.  Surprisingly, as shown in 
Fig. 6, the ability of the model to reflect associa-
tion over abstract pairs seemed to reduce with the 
addition of features to the training data.  Never-
theless, in all other cases the combined model 
outperformed the distributional model.  Interes-
tingly, the combined model advantage when 
comparing with similarity was roughly the same 
over both abstract and concrete pairs.  However, 
when these pairs contained at least one word 
from the McRae data, the combined model was 
indeed significantly better at modeling similarity, 
consistent with Hypotheses (M) and (H). 
 
Figure 6:  Comparison between distributional 
model and combined model output correlations with 
similarity and association over different word pair 
subsets 
4.4 Conclusion 
Our findings corroborate the main conclusion of 
Andrews et al, that the addition of experiential 
data improves the performance of the LDA mod-
el in reflecting association.  However, they also 
indicate that the advantage of feature-based LDA 
models is far more significant when the objective 
is to model similarity. 
 The findings are also consistent with, if 
not suggestive of, the theoretical hypotheses (H) 
and (M).  Clearly, the property features in the 
combined model training data enable it to better 
model both similarity and association between 
those concepts to which the features correspond.  
However, this benefit is greater when modeling 
similarity than when modeling association.  This 
suggests that the similarity operation is indeed 
based on features to a greater extent than associa-
tion.  Moreover, this effect is far greater for the 
concrete words for which the features were add-
ed than over the other words pairs we tested.  
Whilst this is not a sound test of hypothesis (H) 
(no attempt was made to add ?features? of ab-
stract concepts to the model), it is certainly con-
sistent with the idea that features or properties 
are a more important aspect of concrete represen-
tations than of abstract representations. 
0.13
0.09
0.14
0.15
0.00
0.05
0.10
0.15
Distributional Combined
Model type
C
o
r
r
e
l
a
t
i
o
n
Association
Similarity
0.01
0.16
0.2
0.08
0.14
0.36
0.0
0.1
0.2
0.3
Abstract Concrete McRae
Word pair category
C
o
r
r
e
l
a
t
i
o
n
Association
Similarity
0.03
0.093
0.15
0.018
0.11
0.025
0.01
0.16
0.2
0.08
0.14
0.36
0.0
0.1
0.2
0.3
Abstract Concrete 
 Distributional model
McRae Abstract_ Concrete_
 Combined model
McRae_
Word pair category
C
o
r
r
e
l
a
t
i
o
n
Association
Similarity
81
Perhaps the most interesting aspect of the 
combined model is how the addition of feature 
information in the training data for certain words 
influences performance on words for which fea-
tures were not added.  In this case, our findings 
suggest that the benefit when modeling similarity 
is marginally greater than when modeling associ-
ation, an observation consistent with Hypothesis 
(M).  A less expected observation is that, be-
tween words for which features were not added, 
the advantage of the combined model over the 
distributional model in modeling similarity was 
equal if not greater for abstract than for concrete 
concepts.  We hypothesize that this is because 
abstract representations naturally inherit any re-
liance on feature information from the concrete 
concepts with which they participate.  In con-
trast, highly concrete representations do not en-
code relations to other concepts and therefore 
cannot inherit relevant feature information in the 
same way.  Under this interpretation, the con-
crete information from the McRae words would 
propagate more naturally to abstract concepts 
than to other concrete concepts.  As a result, the 
highest quality representations in the combined 
model would be those of the McRae words, fol-
lowed by those of the abstract concepts to which 
they closely relate.    
5 Discussion  
This study has investigated how concreteness is 
reflected in the distributional patterns found in 
running text corpora. Our results add to the body 
of evidence that abstract and concrete concepts 
are represented differently in the mind.  The fact 
that VSMs with small windows are particularly 
adept at modeling relations between concrete 
concepts supports the view that similarity go-
verns the conceptual organization of concrete 
concepts to a greater extent than for abstract con-
cepts.  Further, the performance of our LSA 
models on different tasks and across different 
word pairs is consistent with the idea that con-
crete representations are built around features, 
whereas abstract concepts are not.  
More practically, we have demonstrated that 
vector space models can be tailored to reflect 
either similarity or association by adjusting the 
size of the context window.  This in turn indi-
cates a way in which VSMs might be optimized 
to either abstract or concrete domains.  Our expe-
riments with Latent Dirichlet Allocation corrobo-
rate a recent proposal that appending training 
data with perceptible feature or property infor-
mation for a subset of concrete nouns can signif-
icantly improve the quality of the model?s lexical 
representations.  As expected, this effect was 
particularly salient for representations of words 
for which features were appended to the training 
data.  However, the results show that this infor-
mation can propagate to words for which fea-
tures were not appended, in particular to abstract 
words.   
The fact that certain perceptible aspects of 
meaning are not exhaustively reflected in linguis-
tic data is a potentially critical obstacle for cor-
pus-based semantic models.  Our findings sug-
gest that existing machine learning techniques 
may be able to overcome this by adding the re-
quired information for words that refer to con-
crete entities and allowing this information to 
propagate to other elements of language.  In fu-
ture work we aim to investigate specifically 
whether this hypothesis holds for particular parts 
of speech.  For example, we would hypothesize 
that verbs inherit a good degree of their meaning 
from their prototypical nominal arguments.     
References  
Agirre, E., Alfonseca, E., Hall, K., Kravalova, J. 
Pasca, K,. & Soroa,A. 2009. A Study on Similarity 
and Relatedness Using Distributional and WordNet-
based Approaches. In Proceedings of NAACL-HLT 
2009. 
Andrews, M., Vigliocco, G. & Vinson, D. 2009. 
Integrating experiential and distributional data to 
learn semantic represenations. Psychological Review, 
116(3), 463-498. 
Barsalou, L. 1999. Perceptual symbol systems. Be-
havioral and Brain Sciences, 22, 577-609. 
Binder, J., Westbury, C., McKiernan, K., Possing, 
E., & Medler, D. 2005. Distinct brain systems for 
processing concrete and abstract concepts. Journal of 
Cognitive Neuroscience 17(6), 905-917. 
Chaudhari, D., Damani, O., & Laxman, S. 2011. 
Lexical Co-occurrence, Statistical Significance, and 
Word Association. EMNLP 2011, 1058-1068. 
Crutch, S., Connell, S., & Warrington, E. 2009. 
The different representational frameworks underpin-
ning abstract and concrete knowledge: evidence from 
odd-one-out judgments. Quarterly Journal of Experi-
mental Psychology, 62(7), 1377-1388. 
Felbaum, C. 1998. WordNet: An Electronic Lexical 
Database. Cambridge, MA: MIT Press. 
Finkelstein, L., Gabrilovich, Matias, Rivlin, Solan, 
Wolfman & Ruppin. 2002. Placing Search in Context: 
The Concept Revisited. ACM Transactions on Infor-
mation Systems, 20(1):116-131. 
Gentner, D., & Markman, A. 1997. Structure map-
ping in analogy and similarity. American Psycholo-
gist, 52. 45-56. 
82
Griffiths, T., Steyvers, M., & Tenembaum, J. 2007. 
Topics in semantic representation. Psychological Re-
view, 114 (2), 211-244. 
Hill, F., Korhonen, A., & Bentz, C. A quantitative 
empricial analysis of the abstract/concrete distinction. 
Cognitive Science. In press.  
Kullback, S., & Leibler, R.A. 1951. On Informa-
tion and Sufficiency. Annals of Mathematical Statis-
tics 22 (1): 79?86. 
Kwong, O, Y. 2008. A Preliminary study on induc-
ing lexical concreteness from dictionary definitions. 
22nd Pacific Asia Conference on Language, In-
formation and Computation, 235?244. 
Leech, G., Garside, R. & Bryant, R. 1994. Claws4: 
The tagging of the British National Corpus. COL-ING 
94, Lancaster: UK. 
Markman, A, & Stilwell, C. 2001. Role-governed 
categories. Journal of Theoretical and Experimental 
Artificial Intelligence, 13, 329-358. 
McRae, K., Cree, G. S., Seidenberg, M. S., & 
McNorgan, C. 2005. Semantic feature production 
norms for a large set of living and nonliving things. 
Behavior Research Methods, 37, 547-559 
Miller, G., & Charles, W. 1991. Contextual corre-
lates of semantic similarity. Language and Cognitive 
Processes, 6(1). 
Nelson, D., & McEvoy, C. 2012. The University of 
South Florida Word Association, Rhyme and Word 
Fragment Norms. Retrieved online from: 
http://web.usf.edu/FreeAssociation/Intro.html. 
Paivio, A., Yuille, J., & Madigan, S. 1968. Con-
creteness, imagery, and meaningfulness values for 
925 nouns. Journal of Experimental Psychology Mo-
nograph Supplement, 76(1, Pt. 2).  
Peirsman, y., Heylen, K. & Geeraerts, D. 2008. 
Size Matters. Tight and Loose Context Definitions in 
English Word Space Models. In Proceedings of the 
ESSLLI Workshop on Distributional Lexical Seman-
tics, Hamburg, Germany 
Resnik, P. 1995. Using Information Content to 
Evaluate Semantic Similarity in a Taxonomy. Pro-
ceedings of IJCAI-95. 
Rogers, T., & McLelland, J. 2003. Semantic Cog-
nition. Cambridge, Mass: MIT Press. 
Rosch, E. 1975. Cognitive representations of se-
mantic categories. Journal of Experimental Psycholo-
gy: General, 104(3), (September 1975), pp. 192?233. 
Rubenstein, H., & Goodenough, J. 1965. Contex-
tual correlates of synonymy. Communications of the 
ACM 8(10), 627-633. 
Sahlgren, M. 2006. The Word-Space Model: Using 
distributional analysis to represent syntagmatic and 
paradigmatic relations between words in high-
dimensional vector spaces. Ph.D. dissertation, De-
partment of Linguistics, Stockholm University.  
Schwanenflugel, P. 1991.  Why are abstract con-
cepts hard to understand? In P.  Schwanenflugel.  
The psychology of word meanings (pp.  223-250).  
Hillsdale, NJ: Erlbaum. 
Toglia, M., & Battig, W. 1978. Handbook of se-
mantic word norms. Hillsdale, N.J: Erlbaum. 
Turney, P, & Pantel, P. 2010. From frequency to 
meaning: Vector space models of semantics. Journal 
of Artificial Intelligence Research (JAIR), 37, 141-
188. 
Turney,P., Neuman, Y., Assaf,.D, Cohen, Y. 2011. 
Literal and Metaphorical Sense Identification through 
Concrete and Abstract Context. EMNLP 2011: 680-
690 
Vigliocco, G., Vinson, D. P., Lewis, W., & Garrett, 
M. F. 2004. Reprssenting the meanings of object and 
action words: The featural and unitary semantic space 
hypothesis. Cognitive Psychology, 48, 422?488. 
Warrington, E. (1975). The selective impairment of 
semantic memory. Quarterly Journal of Experimental 
Psychology 27(4), 635-657. 
Wu, Z., Palmer, M. 1994. Verb semantics and lexi-
cal selection. In: Proceedings of the 32nd Annual 
Meeting of the Associations for Computational Lin-
guistics. 133?138. 
 
 
83
