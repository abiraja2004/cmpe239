SRA:
DESCRIPTION OF THE SOLOMON SYSTEM AS USED FOR.
MUC- 5
Chinatsu Aone, Sharon Flank, Doug McKee, Paul Kraus e
Systems Research and Applications (SRA )
2000 15th Street Nort h
Arlington, VA 2220 1
aonecQ sra .coin
BACKGROUN D
SRA used a language-independent, domain-independent, multipurpose text understanding system as the core
of the MUC-5 system for extraction from English and Japanese joint venture texts . SRA's NLP core system ,
SOLOMON, has been under development since 1986 . It has been used for a variety of domains, and wa s
aimed from the start to be language-independent, domain-independent, and application-independent . More
recently, SOLOMON has been extended to be multilingual, beginning with Spanish in 1990 and Japanese i n
1991 . The Spanish-Japanese text understanding system that uses SOLOMON was developed for a dornai n
very different from the MUC-5 joint venture domain (cf . Aone, et al. [2]) .
SOLOMON's principal applications have been in data extraction, but it is also used in a prototyp e
machine translation system (cf. Aone and McKee [5]) . The domain areas in which SOLOMON application s
have been developed are : financial, terrorism, medical, and the MUC-5 joint-venture domain . SRA has
significantly enhanced its capability to add new domains and languages by developing new strategies fo r
data acquisition using both statistical techniques and a variety of user-friendly tools .
MUC-5 SYSTEM ARCHITECTUR E
SOLOMON employs a modular, data-driven architecture to achieve its language- and domain-independence .
The MUC-5 system, which uses SOLOMON as a core engine, consists of seven processing modules an d
corresponding data modules, as shown in Figure 1, which will be described in the following sections .
Message Zoner
The Message Zoner uploads the SGML-annotated text file into the data extraction system . Input files are
assumed to have been proprocessed so that they contain only "rigorous markup" (cf. Goldfarb [8]) SGM L
tags and text ; however, we do not require sentences or paragraphs to be tagged. Japanese text is assume d
to be encoded in EUC, but tags must be ASCII .
All input, including tags, is tokenized using a simple, language-independent, regular expression recognizer .
The (multi-word) tokens are parsed into sentences, paragraphs, headers and documents using a simpl e
operator-precendence grammar (cf. Aho, Sethi and Ullman [1]) operating on punctuation and tags . The
tokenizer and parser are written entirely in lex .
207
Figure 1 : MUC-5 System Architecture
Sentence and paragraph boundries are inferred using a conservative algorithm and marked as inferred .
Inference is not performed if sentences and paragraphs are rigorously marked . The output is piped to a
post-processor, which does a fast lookup of each word in a btree gazetteer, and includes entry information
in the tokens of place names .
Preprocessing
Preprocessing consists of two processors, the morphological analyzer and the pattern matcher, and associate d
data in the form of morphological data, lexicons, and patterns for each language. Its input is a tokenized
message, and its output is a series of lexical entries with syntactic and semantic attributes .
Declarative morphological data for inflection-rich Japanese and Spanish is compiled into finite-stat e
machines . The English domain lexicon was derived from development texts automatically, using a statistica l
technique (cf. McKee and Maloney [10]) . This derived lexicon also contains automatically acquired domain -
specific subcategorization frames and predicate-argument mapping rules called situation types (cf. Aone an d
McKee [3]), as shown in Figure 2 .
Pattern recognition handles a wide range of phenomena, including multi-words, numbers, acronyms ,
money, date, person names, locations, and organizations . We extended the Pattern matcher to handle multi-
level pattern recognition . The pattern data are divided into ordered multiple groups called priority groups,
and the patterns in each group are fired sequentially, avoiding recursive applications as much as possible .
This extension speeded up the performance of Preprocessing significantly .
Syntactic Analysis
The processor for Syntactic Analysis is a parser based on Tomita 's algorithm (cf. Tomita [11]), with modifi-
cations for disambiguation during parsing . Syntactic Analysis data consist of X-bar based phrase structur e
grammars and preparse patterns for each of the three languages, English, Japanese, and Spanish . Syntacti c
Analysis outputs F-structures (grammatical relations), along the lines of Lexical-Functional Grammar (cf .
Bresnan [7]), as shown in Figure 3 . The Semantic Interpretation module is interleaved for disambiguatio n
208
(SWIM
((CATEGORY . V )
(IDIOSYICRACIES (THEME (MAPPING (LITERAL WITH)))) ; "swim with the big fish"
(OCCS 11 )
(PREDICATE ANIMATE-OBJECT-ACTIVITY )
(SITUATION-TYPE ACTIVITY)) )
(STE P
((CATEGORY . V )
(IDIOSYNCRACIES (SOURCE (MAPPING (LITERAL FROM)) )
(GOAL (MAPPING (LITERAL 01 INTO))) )
(OCCS 36 )
(PREDICATE CHANGING-EVENT )
(PROB 8 .1 . 1 )
(SITUATION-TYPE ACTIVITY)) )
(TEA M
((CATEGORY . V )
(IDIOSYICRACIES (THEME (MAPPING (LITERAL WITH))) )
(OCCS 31 )
(PREDICATE ANIMATE-OBJECT-ACTIVITY )
(SITUATION-TYPE PROCESS -CAUSED-PROCESS)) )
(SWITCH
((CATEGORY . V )
(IDIOSYICRACIES (SOURCE (MAPPING (LITERAL FROM))) )
(OCCS 161 )
(PREDICATE TURNKEY-CHANGE )
(PROB 2 .1 . 1 )
(SITUATION-TYPE CAUSED-PROCESS)) )
Figure 2 : Statistically Acquired Lexical Entrie s
of prepositional phrase attachment, conjunctions, and so on, by calling semantic functions, which are share d
by all three languages, from inside the grammar .
Preparsing takes the burden off of main parsing and increases accuracy, by recognizing structures such a s
sentential complements, appositives, certain PP's, etc . by pattern matching, and sending these to the parse r
as chunks . These preparse chunks are parsed prior to main parsing using the same grammars, and thei r
output consists of F-structures as well .
? Appositives: Or i~ "industry's largest Tokyo Kaijou"
? Sentences with certain verb endings :
' 7 X . ]I ~ .
	
WE
	
. I
? PP's : start production [in january 1990] with production of 20,000 iro n
In order to test the progress of grammar development and pinpoint trouble spots, automatic evaluatio n
of grammars was used . SRA adapted the community-wide program Parseval (cf. Black, et al. [6]) for use
in Japanese in addition to English . Testing on Japanese was limited, since there are not many brackete d
Japanese texts to use as answer keys .
Semantic Interpretation
Semantic Interpretation uses a language-independent processing module, and its data are predicate-argumen t
mapping rules for each verb, plus both core and domain knowledge bases . Semantic Interpretation work s
209
BRIDGESTONE SPORTS CO . SAID FRIDAY IT HAS SET UP A JOINT VENTURE IN TAIWAN WITH A LOCAL CONCERN AN D
A JAPANESE TRADING HOUSE . . .
[ST : <S >
SUBJECT : [ST : <NP >
HEAD : IT ]
PREDICATE: [ST : <VP>
TENSE : PRESENT
ASPECT: PERFECT
PREDICATE : (CREATE )
ROOT : SET
VERB-PARTICLE : UP ]
OBJECT : [ST : <HP >
HEAD : A-JOINT-VENTURE]
PREP-ARGS : ([ST : <PP >
MARKED : WITH
HEAD : A-LOCAL-CONCERN-AND-A-JAPANESE-TRADING-HOUSE] )
ADJUNCTS : ([ST : <PP >
MARKED : I H
HEAD : TAIWAN])]] ]
Figure 3 : Simplified F-Structure Output by Syntactic Analysi s
off of language-neutral F-structures in order to handle all the languages . It outputs semantic structures, i .e .
predicate-argument and modification relations, as shown in Figure 4 . The predicate-argument mapping rule s
(i .e . rules which map F-structures to semantic structures) are acquired automatically (cf . Aone and McKee
[3]) . Domain knowledge bases, on the other hand, were acquired manually . However, a new rapid knowledg e
acquisition tool called KATooI was used to link a lexical entry to its corresponding semantic concept in th e
knowledge bases (cf. Figure 5) .
If a full parse cannot be created, SOLOMON uses a fragment combination strategy . Debris Parsing
and its subsequent process, Debris Semantics, work together to obtain the best interpretation from sentence
fragments . They use as data the grammars and knowledge bases, and they output semantic structures jus t
like when a full parse is created . Debris Parsing retrieves the largest and most preferred constituents from
the parse stack . It then reparses the rest of the input, and creates debris F-structures with the best fragmen t
constituents . Debris Semantics relies on the semantic interpreter to process each fragment, and then fit s
fragments together using semantic constraints on unfilled slots .
Discourse Analysis
Discourse Analysis, which was redesigned and implemented this year (cf . Aone and McKee [4]), performs
reference resolution . Discourse Analysis uses a data-driven architecture to achieve language-independence ,
domain-independence, and extensibility . It employs a single language-independent, domain-independen t
processor, and several discourse knowledge bases, some of which are shared among different languages . The
output, of Discourse Analysis is a set of semantic structures with coreference links added, i .e . File Cards
(cf. Heim [9]) . Discourse phenomena handled for the joint venture domain include name anaphora (e .g .
[ST : <S >
SUBJECT: [ST : <HP>
HEAD : BRIDGESTONE-SPORTS-CO . ]
ADJUNCTS : ([ST : <NP >
HEAD : FRIDAY] )
[ST : <VP >
TENSE : PAST
PREDICATE : (COMMUNICATE )
ROOT : SAY
SENT-COMP :
PREDICATE :
210
BRIDGESTONE SPORTS CO . SAID FRIDAY IT HAS SET UP A JOINT VENTURE I I
TAIWAN WITH A LOCAL CONCERN AND A JAPANESE TRADING HOUS E
(COMMUNICATE-1176 (ISA (VALUE (COMMUNICATE)) )
(TIME (VALUE (FRIDAY-1178)) )
(AGENT (VALUE (COMPANY-1146)) )
(THEME (VALUE (CREATE-1163)) )
(TENSE (VALUE (PAST))) )
(COMPANY-1146 (ISA (VALUE (COMPANY)) )
(QUANTITY (VALUE ((EXACT 1))) )
(UNIT (VALUE (NATURAL-UNIT)) )
(JAMES (VALUE ((BRIDGESTONE SPORTS CO)))) )
(CREATE-1163 (ISA (VALUE (CREATE)) )
(LOCATION (VALUE (COUNTRY-1144)) )
(AGENT (VALUE (THING-1166)) )
(THEME (VALUE (TIE-UP-EVENT-1164)) )
(CO-THEME (VALUE (CONJOINED-COLLECTIOI COMPAIY)-1172) )
(ASPECT (VALUE (PERFECT)) )
(TENSE (VALUE (PRESENT))) )
((CONJOINED-COLLECTION COMPANY)-117 2
(ISA (VALUE ((AID CONJOINED-COLLECTION COMPANY))) )
(HAS-MEMBERS (VALUE (COMPANY-1170 COMPANY-1168))) )
(COMPANY-1168 (ISA (VALUE (COMPANY)) )
(QUANTITY (VALUE ((EXACT 1))) )
(UNIT (VALUE (NATURAL-UNIT)) )
(LOCATION (TYPE (AND T PHYSICAL-LOCATION)) (VALUE (LOCAL))) )
(COMPANY-1170 (ISA (VALUE (COMPANY)) )
(QUANTITY (VALUE ((EXACT 1))) )
(UNIT (VALUE (NATURAL-UNIT)) )
(NATIONALITY (VALUE (JAPAN))) )
(COUNTRY-1144 (ISA (VALUE (COUNTRY)) )
(ENGLISH-GAZ-STRING (VALUE (Taiwan (COUNTRY)))) )
Figure 4: Semantic (Predicate-Argument) Structure
3\ v\~ .\J\l :a~~~il:X25.
	
\>
	
; x ,3 :33\MAt'VY
Figure 5: Knowledge Acquisition Too l
211
DISCOURSE : Classified $<DISCOURSE-MARKER DISCOURSE-MARKER-181>("BRIDGESTONE SPORTS") as DP-NAM E
DISCOURSE : Found an exact match ,
ante : $(DISCOURSE-MARKER DISCOURSE-MARKER-83>("BRIDGESTONE SPORTS CO ." )
ref : $<DISCOURSE-MARKER DISCOURSE-MARKER-181>("BRIDGESTONE SPORTS" )
DISCOURSE : Classified $<DISCOURSE-MARKER DISCOURSE-MARKER-206>("BRIDGESTONE SPORTS") as DP-NAM E
DISCOURSE : Found an exact match ,
ante : $<DISCOURSE-MARKER DISCOURSE-MARKER-181>("BRIDGESTONE SPORTS" )
ref : $(DISCOURSE-MARKER DISCOURSE-MARKER-206>("BRIDGESTONE SPORTS" )
Figure 6 : English Discourse Trace Exampl e
=> IMLEA:%glIg
I)ISCOURSE : Classified #<DISCOURSE-MARKER DISCOURSE-MARKER-511>( "
	
1 #
	
, .Z*k." ) as DP-NAME
DISCOURSE: Found an exact match ,
ante : #<DISCOURSE-MARKER DISCOURSE-MARKER-248>("
	
1
	
`
	
" )
ref : #<DISCOURSE-MARKER DISCOURSE-MARKER-511>("at :t ." )
*A 14 => ni
	
F7 ~
l.)ISCOURSE : Classified #<DISCOURSE-MARKER DISCOURSE-MARKER-573>(" 1#AE") as DP-NAME
DISC(.)URSE: Found an exact match ,
ante : #<DISCOURSE-MARKER DISCOURSE-MARKER-511>("
	
" )
ref : #<DISCOURSE-MARKER DISCOURSE-MARKER-573>(' , E" )
Figure 7 : Japanese Discourse Trace Exampl e
"BRJl)GESTONE SPORTS" for "BRIDGESTONE SPORTS CO .") and definite NP's such as "THE NE W
('OMPAN l
The system traces for English and Japanese walkthrough examples are shown in Figure 6 and Figure 7 .
In the English example, the two instances of name anaphora for "Bridgestone Sports Co." are recognized ,
while in the Japanese example, all the references to "Tokyo Kaijou Kasai Hoken, " including appositives, ar e
resolved .
Pragmatic Inferencin g
Pragmatic Inferencing performs reasoning in order to derive implicit information from the text, using a
forward chainer and inference rules . Pragmatic Inferencing outputs semantic structures, with inferred infor-
inat ion added . It infers additional information from "literal" meanings as required for application domains .
For instance, in the walkthrough example, in order to infer "THE TAIWAN UNIT " is a joint venture
company frorr, the phrase "THE ESTABLISHMENT OF THE TAIWAN UNIT" the following rule is used .
(defrule rule-0009 ((?event) (?event) )
:example ("PNI and SRA established a new company ." )
:if (and (establish ?event )
(theme ?event ?x )
(company ?x) )
:then (and (tie-up-event ?event )
(joint-venture-company ?x )
(joint-venture-company ?event ?x )
(in-jv-event ?x ?event)))
212
It is easy for developers to add, change or remove inferred information due to the declarative nature o f
the inference rules . For instance, to get an additional tie-up from "Company A and Company B tied wit h
Company C " , in ,t, ty-000''2, we just, had to add another rule to infer that. when companies "tie," they form a
tie-up .
(defrule rule-0017b ((?event) (?event) )
:example ("PNI tied with SRA")
:if (and (tie-event ?event )
(not (theme ?event ?z) )
(agent ?event ?x )
(company ?x )
(co-theme ?event ?y )
(company ?y) )
:then (tie-up-event ?event) )
Extract
The Extract module performs template generation, translating the domain-relevant portions of our language -
independent semantic structures into database records . We maintain a strong distinction between processin g
and data even in template generation . Thus, we use the same processing module to output in differen t
languages and to several database schemata, including to a flat template-style schema as in MUC-4 and t o
a more object-oriented schema as in MUC-5 .
To do the actual template filling, we rely on Extract data made up of kb-object/slot to db-table/fiel d
mapping rules and conversion functions for the individual values (e .g . set fills, string fills) . For example, th e
#nationality slot of an #ORGANIZATION object in our knowledge base corresponds to the Nationalit y
field of the Entity object in the MUC-5 template .
REUSABILITY OF THE SYSTE M
SOLOMON is designed for reusability . Each processing module is data-driven and reusable in other lan-
guages and other domains, as well as in applications other than data extraction (e .g . machine translation ,
abstracting, summarization) . A large portion of the data is also reusable in :
? Other languages and domains
- Core knowledge bases
? Other domains
- Morphological data
-
General lexicons
General pattern data (e .g . date, location, personal name, organization name )
Grammars
Some of the discourse knowledge sources
? Other language s
- Domain knowledge bases
213
Figure 8 : Reusability of SRA ' s MUC-5 System
? Some of the discourse knowledge sources
? Inference rules
? Extract (template generation) dat a
The data acquisition tools and techniques are also reusable in other languages and domains . The statis-
tical techniques used to derive lexical information can be reused for other domains . LEXTooI, the lexicon
acquisition tool, is multilingual and relies on system data files for category and morphological informa-
tion. KBTooI, the knowledge base acquisition tool, is language-independent just as the knowledge bases ar e
language-independent . KATool, the knowledge acquisition tool that links lexicon entries with the appropri-
ate knowledge base concepts, is entirely data-driven as well, and is therefore completely reusable . Figure 8
summarizes the reusability of SRA ' s MUC-5 system .
TEST RESULTS AND ANALYSIS
Our MUC-5 results for the English and Japanese joint-venture domain task are shown in Table 1 . We spen t
10 .55 person-months for this task, most of which were devoted to data development for both languages (se e
Table 2) . The "other" category includes time spent on developing language-independent data such as a
joint-venture domain knowledge base, pragmatic inference rules, and Extract data for template generation .
We believe that the results do not indicate the potential of our system, since the system performance fo r
both languages was still improving after five months of development. Much of the work we did resulted in
long-term improvements to our overall text understanding capability, all of which will ensure a stronger base
system for future applications . This implies that although the development cycle for data extraction system
using a text understanding system may be slower in its current maturity stage, the potential for such a syste m
is still unknown and represents a most promising avenue for development . We are particularly pleased wit h
the success of our Japanese system : no other Japanese MUC-5 site is using the full understanding approach ,
but we did as well and our performance continues to improve )
Staff time was the major limiting factor . We needed more time to perform more testing and evaluation
l In the 18-month Tipster evaluation, the highest JJV F-measure was about 40 .
214
Englis h
ERR UND OVG SUB REC PRE
ALL OBJECTS
MATCHED ONLY
TEXT F ILTERIN(.
80
48
-
66
2 8
25
2 6
8
7
34
2 3
-
2 2
5 6
74
4 9
7 1
9 3
I'&R 2I'&R I'&2H.
F-MEASURE 30 .80 39 .56 25 .22
Japanese
ERR UND OVG SUB REC PRE
ALL OBJECT S
MATCHED ONLY
TEXT FILTERING
70
43
-
5 3
2 8
6
34
9
1
2 0
1 4
-
38
6 1
_
	
94
5 2
78
98
P&R 2P&R P&2R
F-MEASURE 43 .92 48 .74 39 .97
Table 1 : SRA 's Scores for the English and Japanese Joint Venture Domai n
task person-months
EJV 3 . 2
JJV 2 . 2
Testing 1 . 5
Documentation 0 .2 5
Other 3 . 4
Table 2 : SRA 's Time Expenditure for MUC- 5
using the scoring program, and to finely tune Extract (template generation) mapping rules . We discovered
we were hampered by formatting errors, and in addition considerable information was "understood" by th e
system all the way through, but was not extracted by the template generator . Since the discourse modul e
was new, it would have been helpful to have additional time to test and expand it . In addition, we neede d
more time to fill the OWNERSHIP, REVENUE, and TIME objects, which we simply did not output .
CONCLUSION
Overall, the data-driven architecture in SOLOMON allowed for minimum work on processing modules whe n
working on different languages and domains. We ported the system to Spanish in a week for the demonstra-
tion given, at the MUC-5 conference .
Although we successfully acquired large amounts of domain data from domain texts in both languages ,
using both statistical methods and newly developed user-friendly knowledge acquisition tools, we recogniz e
the need to move even more quickly to new domains and languages . We plan to continue our work on
automatic acquisition of lexicons, knowledge bases, and links between them in multiple languages .
Tuning performance of each module (e .g. parsing, discourse analysis) as well as the' performance o f
the whole system to a particular task more rapidly is another research issue we identified . We believe that
developing automatic evaluation and training algorithms for such automated module/system tuning is crucia l
to develop a data extraction system that produces optimal results .
21 5
ACKNOWLEDGEMENTS
We are indebted to Rajeev Agarwal, Debbie Sanders, and Vera Zlatarski for their hard work and dedicatio n
in data development, module testing, and more . We also gratefully acknowledge the contributions of Scot t
Bennett, David Garfield, and Hatte Blejer to the MUC-5 process .
References
[1] Alfred V . Aho, Revi Sethi, and Jeffry D . Ullman . Compilers : Principles, Techiniques and Tools.
Addison-Wesley, 1986 .
[2] Chinatsu Aone, Hatte Blejer, Sharon Flank, Douglas McKee, and Sandy Shinn . The Murasaki Project :
Multilingual Natural Language Understanding . In Proceedings of the ARPA Human Language Technol-
ogy Workshop, 1993 .
[3] Chinatsu Aone and Doug McKee . Acquiring Predicate-Argument Mapping Information from Multilin-
gual Texts . In Acquisition of Lexical Knowledge from Text : Proceedings of a Workshop Sponsored b y
the Special Interest Group on the Lexicon of the Association for Computational Linguistics, 1993 .
[4] Chinatsu Aone and Doug McKee . Language-Independent Anaphora Resolution System for Understand-
ing Multilingual Texts . In Proceedings of 31st Annual Meeting of the ACL, 1993 .
[5] Chinatsu Aone and Doug McKee . Three-Level Knowledge Representation of Predicate-Argument Map -
ping for Multilingual Lexicons . In AAAI Spring Symposium Working Notes on Building Lexicons fo r
Machine Translation, 1993 .
[6] E . Black, S . Abney, D . Flickinger, C . Gdaniec, R . Grishman, P . Harrison, D . Hindle, R . Ingria, F . Jelinek ,
J . Klavans, M . Liberman, M . Marcus, S . Roukos, B . Santorini, and T. Strzalkowski . A Procedure fo r
Quantitatively Comparing the Syntactic Coverage of English Grammars . In Proceedings of the Fourt h
DARPA Speech and Natural Language Workshop, 1991 .
[7] Joan Bresnan, editor . The Mental Representation of Grammatical Relations . MIT Press, 1982 .
[8] Charles F . Goldfarb . The SGML Handbook . Oxford, 1990 .
[9] Irene Heim . The Semantics of Definite and Indefinite Noun Phrases . PhD thesis, University of Mas-
sachusetts, 1982 .
[10] Doug McKee and John Maloney . Using Statistics Gained from Corpora in a Knowledge-Based NL P
System . In Proceedings of The AAAI Workshop on Statistically-Based NLP Techniques, 1992 .
[II] Masaru Toinita . Efficient Parsing for Natural Language . Kluwer, Boston, 1986.
APPENDIX
A ejv-0592 SRA's Original Response
<TEMPLATE-0592-1> : =
DOC NR : 0592
DOC DATE : 24118 9
DOCUMENT SOURCE : "Jiji Press Ltd . ; "
CONTENT : <TIE_UP_RELATIONSHIP-0592-3>
216
<TIE_UP_RELATIONSHIP-0592-2 >
<TIE_UP_RELATIONSHIP-0592-2> : =
TIE-UP STATUS : EXISTIBG
ENTITY : <ENTITY-0592-6 >
<ENTITY-0592-5 >
JOINT VENTURE CO : <ENTITY-0592-7 >
ACTIVITY : <ACTIVITY-0592-8 >
<ACTIVITY-0592-8> : =
INDUSTRY : <INDUSTRY-0592-9>
ACTIVITY-SITE : (Taiwan (COUNTRY) <ENTITY-0592-10> )
<INDUSTRY-0592-9> : _
INDUSTRY-TYPE : PRODUCTION
PRODUCT/SERVICE : (67 "A JOINT VENTURE" )
<ENTITY-0592-5> : =
NAME : Taga C O
TYPE : COMPANY
ENTITY RELATIONSHIP : <ENTITY_RELATIONSHIP-0592-11 >
<ENTITY_RELATIONSHIP-0592-11> : =
ENTITY1 : <ENTITY-0592-5 >
<ENTITY-0592-6>
EHTITY2 : <ENTITY-0592-7 >
REL OF EHTITY2 TO ENTITYI : CHILD
STATUS : CURRENT
<ENTITY-0592-6> :_
NAME : Union Precision Casting C O
ALIASES : "Union Precision Casting "
TYPE : COMPANY
ENTITY RELATIONSHIP : <ENTITY_RELATIONSHIP-0592-11 >
<ENTITY-0592-7> :=
NATIONALITY : Taiwan (COUNTRY )
TYPE : COMPANY
ENTITY RELATIONSHIP : <ENTITY_RELATIONSHIP-0592-11 >
<TIfi UP_RELATIONSHIP-0592-3> : =
TIE-UP STATUS : EXISTING
ENTITY: <ENTITY-0592-14>
<ENTITY-0592-13>
ACTIVITY : <ACTIVITY-0592-8>
<ENTITY-0592-13> :=
NAME : Bridgestone Sports CO
ALIASES : "Bridgestone Sports "
TYPE : COMPANY
ENTITY RELATIONSHIP : <ENTITY_RELATIONSHIP-0592-15 >
<ENTITYRELATIONSHIP-0592-15> :=
EBTITYI : <ENTITY-0592-13>
<ENTITY-0592-14 >
REL OF EHTITY2 TO EBTITYI : PARTNER
STATUS : CURRENT
<ENTITY-0592-14> : _
TYPE : COMPANY
EHTITY RELATIONSHIP : <ENTITY_RELATIONSHIP-0592-15 >
B ejv-0592 SRA's Corrected Response
<TEMPLATE-0592-1> : _
DOC NR : 059 2
DOC DATE : 241189
DOCUMENT SOURCE : "Jiji Press Ltd . ; "
CONTEXT : <TIE_UP_RELATIONSHIP-0592-4>
<TIE UP_RELATIONSHIP-0592-3 >
<TIE_UP_RELATIONSHIP-0592-2 >
<TIE_UP_RELATIONSHIP-0592-2> : _
TIE-UP STATUS : EXISTING
ENTITY: <ENTITY-0592-7 >
<ENTITY-0592-6>
217
JOINT VENTURE CO : <ENTITY-0592-8>
ACTIVITY : <ACTIVITY-0592-9 >
<ACTIVITY-0592-9> :_
INDUSTRY : <INDUSTRY-0592-1O>
ACTIVITY-SITE : (- <ENTITY-0592-11> )
<INDUSTRY-0592-10> : _
INDUSTRY-TYPE : PRODUCTION
PRODUCT/SERVICE : (67 "A JOINT VENTURE" )
<ENTITY-0592-6> : _
NAME: Taga C O
TYPE : COMPANY
ENTITY RELATIONSHIP : <ENTITY_RELATIONSHIP-0592-12 >
<ENTITY_RELATIONSHIP-0592-12> :_
ENTITYI : <ENTITY-0592-6>
<ENTITY-0592-7>
ENTITY2 : <ENTITY-0592-8>
REL OF ENTITY2 TO ENTITY1 : CHILD
STATUS : CURRENT
<ENTITY-0592-7> :_
NAME : Bridgestone Sports C O
Bridgestone Sports
TYPE : COMPANY
ENTITY RELATIONSHIP : <EHTITY_RELATIONSHIP-0592-12 >
<ENTITY-0592-8> : _
NAME : Bridgestone Sports Taiwan C O
ALIASES : "Bridgestone Sports CO "
"Bridgestone Sports "
NATIONALITY : Taiwan (COUNTRY )
TYPE : COMPANY
ENTITY RELATIONSHIP : <ENTITY_RELATIONSHIP-0592-12 >
<TIE UP_RELATIONSHIP-0592-3> : _
TIE-UP STATUS : EXISTIN G
ENTITY : <ENTITY-0592-16>
<ENTITY-0592-15>
JOINT VENTURE CO : <ENTITY-0592-17>
ACTIVITY : <ACTIVITY-0592-9>
<ENTITY-0592-15> : _
NATIONALITY : Taiwan (COUNTRY )
TYPE : COMPANY
ENTITY RELATIONSHIP : <ENTITY_RELATIONSHIP-0592-18 >
<ENTITY_RELATIONSHIP-0592-18> : _
EHTITYI : <ENTITY-0592-15>
<ENTITY-0592-16>
ENTITY2 : <ENTITY-0592-17>
REL OF ENTITY2 TO EHTITYI : CHILD
STATUS : CURRENT
<ENTITY-0592-16> :_
NAME : Union Precision Casting C O
ALIASES : "Union Precision Casting "
TYPE : COMPANY
ENTITY RELATIONSHIP : <ENTITY_RELATIONSHIP-0592-18 >
<ENTITY-0592-17> : _
NATIONALITY : Taiwan (COUNTRY )
TYPE : COMPANY
ENTITY RELATIONSHIP : <ENTITY_RELATIONSHIP-0592-18 >
<TIE_UP_RELATIONSHIP-0592-4> : _
TIE-UP STATUS : EXISTING
ENTITY : <ENTITY-0592-22>
<ENTITY-0592-21 >
ACTIVITY : <ACTIVITY-0592-9 >
<ENTITY-0592-21> : _
TYPE : COMPANY
ENTITY RELATIONSHIP : <EHTITY_RELATIONSHIP-0592-23 >
<ENTITY_RELATIONSHIP-0592-23> :_
ENTITY' : <ENTITY-0592-21 >
<ENTITY-0592-22 >
REL OF ENTITY2 TO ENTITY' : PARTNER
STATUS : CURRENT
218
<EITITY-0592-22> :_
NATIONALITY : Japan (COUNTRY )
TYPE: COMPANY
ENTITY RELATIONSHIP : <EITITY_RELATIOISHIP-0592-23 >
C jjv-0002 SRA's Original Response
<7:/7IL? i--0002-1> : =
000 2
A'hrJEl H : 850108
	
"VJf
	
IJ "{*J? : <M-0002-3>
<tM-0002-2>
<#j0002-2>
WM: NH-
=%7474-:<=' 474--0002-4>{ jJ: <gM. fj-0002-5>
<W{j-0002-5> :=
: <-0002-6 >
eel: (- <_ /7 4 7 4 --0002-7>)
<M-0002-6> :=
<2 ' 4 ' 4 --0002-4> : =
Z;/-7-4
.7- 4 ?gg :
Z /7 4 -7- 4 ?mg: <474- JfA- 0002 -8>
:/7 4 7 4 ?f=-0002-8> : =
Z/744-z : <Z/7474--0002-4>
tZ f : i \? i` 1--
M; iM
<#-0002-3> :=
#MR:'rr
Z:/7 4 4 - : <Z,/7 4 7 4 --0002-10>
<g-&M-0002-5>
<Z
	
4 -7- 4 --0002-10> : _
	
=;/7 4 7 4 ? , :
	
?
Z%7474- q :
Z~7 4 7 4 ?Mfg: <X 47 4 - x.-0002-11 >
<2 i7 4 7 4 -Jf-0002-11> : _
Z/7474?Z:<,I>' 474--0002-10>
tJ` Z f : i\?1-t
219
D jjv-0002 SRA's Corrected Response
<7 i7?L? F -0002-I> : =
0002
H : 85010 8
	
" B> 1
	
f1J
?
Js -4: <4 0002-4>
X0002-3>
<M-0002-2>
4J -o002-2> :=
MUM: RH
Z %T 4 7 4 -: < Z /7 4 7 4 --0002-6>
<
._ %7 4 74 --0002-5>
* j J:<-0002-7>
4+tJ-0002-7>
14: <14-0002-8>
ty'): (- <-T.
.'/'7' 4 7 4 --0002-9>)
<
	
i-0(X)2-8> : _
IJ : 'H- tom
<2. :
./7- 4 7 4 --0002-5> : =
z~7-r74 ? : tJJAIT
=%T 44its `
.r :/=r 4 7 4 ?M <x:/=r 4 74? f,-0002-10>
<J
	
4 4 ?Mt-0002- 0> : =
2 ~T 4 4 ? Z .: <z %7 4 7(--0002-5>
<X / 4 7 4 --0002-6>
4
	
f : ) 1?~--
4-FA AM
<12/-7- 4 T --0002-6> : _
I%7474-K
=%7 4 T 4
	
<-T. :/7 T 4 -M-0002-10>
< Wt,--0002-3> : _
&WM: 41i7
. %7474-:<=/T 44--0002-12>
tTh 1j : <ggf:M-0002-7>
<~ %7 4 4 --0002-12> : =
z/74 4
4 -7- 4 --n PEA
z%T 4 7 4
	
<I:/-7- 4 5 4 ?M-0002-13>
<z:/T 4 - 4 ?f-0002-13> : _
1%7474 ?Z: <Z:/74'7'4--0002-12>
EPftZ, f :
	
I-1--
M.,
:_
Mk%Tff
x/7474-: <.=;/7474--0002-15>
<[iTgu1-0002 -7 >
<I:/7 4 7 4 --0002-I5> : =
I/-r4---r47 , .t t
? 7L
"
x:/-7- 4 4
	
4 4
?IM-0002-16>
<1:/-7- 4 T 4 ?-0002-16> : _
1%7474-z.:<=/7474--0002-15 >
I~ ( { : R?1-- -1--
Wk. MA
220
