Proceedings of the 2009 Workshop on Applied Textual Inference, ACL-IJCNLP 2009, pages 48?51,
Suntec, Singapore, 6 August 2009.
c
?2009 ACL and AFNLP
Building an Annotated Textual Inference Corpus for Motion and Space
Kirk Roberts
Human Language Technology Research Institute
University of Texas at Dallas
Richardson TX 75080
kirk@hlt.utdallas.edu
Abstract
This paper presents an approach for build-
ing a corpus for the domain of motion and
spatial inference using a specific class of
verbs. The approach creates a distribution
of inference features that maximize the
discriminatory power of a system trained
on the corpus. The paper addresses the is-
sue of using an existing textual inference
system for generating the examples. This
enables the corpus annotation method to
assert whether more data is necessary.
1 Introduction
Open-domain textual inference provides a vast ar-
ray of challenges to a textual entailment system.
In order to ensure a wide distribution of these chal-
lenges in building the PASCAL 2005 corpus (Da-
gan et al, 2005), seven different application set-
tings were used for inspiration: Information Re-
trieval, Comparable Documents, Reading Com-
prehension, Question Answering, Information Ex-
traction, Machine Translation, and Paraphrase Ac-
quisition. While PASCAL 2005 and its subse-
quent challenges have released numerous corpora
for open-domain textual inference, many types of
textual inference are sparsely represented. This
speaks not to a weakness in the mentioned cor-
pora, but rather the depth and complexity of chal-
lenges that textual inference presents.
Furthermore, the open-domain inference task
often forces systems to face more than one of
these challenges on a single inference pair (such
as requiring both an understanding of paraphrases
and part-whole relationships). In many cases, it
is desirable to isolate out most of these ?sub-
tasks? within textual inference and concentrate
on a single aspect. Partly for this reason, the
Boeing-Princeton-ISI (BPI) Textual Entailment
Test Suite
1
was developed. Its focus is real-world
knowledge and not syntactic constructions, so it
provides 250 syntactically simple but semantically
rich inference pairs.
This paper explores the creation of such a
specific textual inference corpus based on verb
classes, specifically focusing on the class of mo-
tion verbs and their nominalizations. The goal is
to develop a publicly available corpus for spatial
inference involving motion. Section 2 analyzes the
properties of such a corpus. Section 3 outlines the
effort to build a motion corpus. Finally, Section 4
discusses considerations for the size of the corpus.
2 Properties of an Inference Corpus
2.1 General Properties
Annotated corpora are designed for training and
evaluation for specific classification tasks, and
thus an optimal corpus is one that maximizes a
system?s ability to form a discriminative feature
space. However, knowing ahead of time what the
feature space will look like may be difficult. But,
at the same time the corpus should be also reflec-
tive of the real world.
One method for developing a useful corpus un-
der these conditions, especially for a specific do-
main, is to use an existed textual entailment sys-
tem that can aid in the example generation pro-
cess. By using such a system to suggest examples,
one is able to both reduce the time (and cost) of
annotation as well as producing a corpus with a
desirable distribution of features.
1
Available at http://www.cs.utexas.edu/?pclark/bpi-test-
suite/
48
Text: John flew to New York from LA.
Hypothesis: John left LA for New York.
Text: John will fly over the Atlantic during
his trip to London from New York on Tuesday.
Hypothesis: On Tuesday, John flew over water
when going from North America to Europe.
Table 1: Examples of textual inference for motion.
2.2 Properties of a Motion Corpus
Textual inference about motion requires an exter-
nal representation apart from the text. While many
inference pairs can be solved with strategies such
as lexical alignment or paraphrasing, many texts
assume the reader has knowledge of the proper-
ties of motion. Table 1 shows two such inference
pairs. The first can be solved through a paraphrase
strategy, while the second requires explicit knowl-
edge of the properties of motion that are difficult
to acquire through a paraphrasing method. Unfor-
tunately, most open-domain inference corpora are
sparsely populated with such types of inference
pairs, so a new corpus is required.
For the purpose of the corpus, the concept of
motion is strictly limited to the set of words in the
(Levin, 1993) verb-class MOTION. This greatly
benefits the annotation process: passages or sen-
tences without a verb or nominalization that fits
into the MOTION class can immediately be dis-
carded. Levin?s verb classes are easily accessible
via VERBNET (Kipper et al, 1998), which pro-
vides additional syntactic and semantic informa-
tion as well as mappings into WORDNET (Fell-
baum, 1998).
(Muller, 1998) proposes a qualitative theory of
motion based on spatio-temporal primitives, while
(Pustejovsky and Moszkowicz, 2008) shows an
annotation structure for motion. Furthermore, rep-
resenting motion requires the complete representa-
tion of spatial information, as motion is simply a
continuous function that transforms space. (Hobbs
and Narayanan, 2002) discuss many of the prop-
erties for spatial representation, including dimen-
sionality, frame of reference, regions, relative lo-
cation, orientation, shape, and motion. It is there-
fore desirable for a motion corpus to require infer-
ence over many different aspects of space as well
as motion. Table 2 shows the properties of motion
incorporated in the inference system.
In practice, these properties are far from uni-
formly distributed. Properties such as dest(M
x
)
are far more common than shape(M
x
). Clearly,
Property Description
motion(M
x
) Instance of motion in text
theme(M
x
) Object under motion
area(M
x
) Area of motion
src(M
x
) Source location
dest(M
x
) Destination location
path(M
x
) Path of motion
current(M
x
) Current position
orientation(M
x
) Direction/Orientation
shape(M
x
) Shape of object
t start(M
x
) Start of motion
t end(M
x
) End of motion
Table 2: Extracted properties of motion.
having a system that performs well on destinations
is more important than one that can draw infer-
ences from motion?s effects on an object?s shape
(?the car hit the barricade and was crushed?), but
it is still desirable to have a corpus that provides
systems with examples of such properties.
The corpus annotation process shall disregard
many discourse-related phenomena, including co-
reference. Further, the text and hypothesis for each
inference pair will be limited to one sentence. In
this way, knowledge of motion is emphasized over
other linguistic tasks.
3 Building a Corpus Focusing on
Knowledge about Motion
To build the motion inference corpus, we chose
to start with an existing, large document corpus,
AQUAINT-2.
2
This corpus is composed of 2.4GB
of raw files and contains over 900,000 documents.
Having a large corpus is important for finding
sparse verbs like escort and swing and sparse
properties like area(M
x
) and orientation(M
x
).
3.1 Text Annotation
In order to get a more diverse distribution of mo-
tion verbs and properties (hereafter, just referred
to as properties) than the given distribution from
the corpus, the following procedure is considered:
Let V
s
be the (static) distribution of motion
properties from the document corpus. Let V
d
be
the (dynamic) distribution of motion properties
from an (initially empty) set of annotated exam-
ples. Next, define a ?feedback? distribution V
f
,
such that for each property y:
P
f
(y) =
max(0, 2P
s
(y)? P
d
(y))
Z
(1)
Where P
s
(y), P
d
(y), and P
f
(y) are the proba-
bilities of property y in distributions V
s
, V
d
, and
2
Available through the Linguistic Data Consortium, id
LDC2008T25
49
Vf
, respectively, and Z is a normalization factor
(needed when the numerator is zero).
Let the parameter ? determine the likeli-
hood of sampling from this distribution V
f
or
from the uniform distribution U . The function
NextExampleType(V
f
, ?) then specifies which mo-
tion property should be in the next example. An
unannotated example is then drawn from an index,
annotated by the user, and placed in the set of an-
notated examples. V
d
is then updated to reflect the
new distribution of verbs and properties in the an-
notated example set.
There are several items to note. First, the exam-
ple might contain multiple properties not chosen
by the NextExampleType method. When a motion
event with a path(M
x
) is chosen, it is not uncom-
mon for a dest(M
x
) property to be a part of the
same event. This is why the V
d
and V
f
distribu-
tions are necessary: they are a feedback mecha-
nism to try to keep the actual distribution, V
d
, as
close to the desired distribution as possible.
Second, the value for ? is the sole pre-specified
parameter. It dictates the likelihood of choosing
an example despite its a priori probability. Setting
? to 1.0 will result in only sampling based on the
V
f
distribution, and setting it to 0.0 will generate
a uniform sampling. In practice, this is set to 0.8
to allow many of the sparse features through.
Third, V
d
and V
f
account even for proper-
ties generated from the uniform distribution. In
practice this means that low-probability events
will be generated from U and not V
f
, especially
later in the sampling process. Due to the non-
independence of the properties as discussed above,
this discrepancy is difficult to account for and is
considered acceptable: U will still dictate a much
higher distribution of low-probability properties
than would otherwise be the case.
3.2 Hypothesis Annotation
While the hypothesis itself must be written by the
annotator, one can apply some of the same prin-
ciples to ensure a coverage of motion concepts.
Since not every motion term in the text need be
tested by the hypothesis, it is beneficial to keep
track of which properties are tested within each.
For this reason, the annotator is responsible for in-
dicating which motion properties are used in the
hypothesis. This way, the annotator can be alerted
to any properties under-represented in the set of
hypotheses relative to the set of annotated texts.
Feature # Seq Ex Gen
dest(M
x
) 749 48 60
go 382 90 129
leave 105 376 454
. . . . . . . . . . . .
orientation(M
x
) 94 420 282
flee 4 9,991 5,508
steer 2 20,000 7,065
parachute 1 40,000 8,227
Table 3: Motion features with instance counts
from 2000 sample sentences. The Seq (Sequen-
tial) and Ex Gen (see Section 3.1) columns are
the expected number of annotated sentences for
20 instances of the feature to be found using that
method, assuming i.i.d.
3.3 Evaluation
The purpose of the algorithm from Section 3.1 is
not only to build a more balanced corpus, but to
do so more quickly. By looking through exam-
ples that are more likely to maintain a balanced
corpus, annotators are saved from looking through
hundreds (or thousands!) of examples that contain
overly redundant properties.
To illustrate this point, consider a random sam-
ple of 2000 sentences. Table 3 shows the extracted
counts for some of the least and most common
verbs and properties alongside projections of how
many motion sentences would need to be anno-
tated with and without the algorithm to attain a
rather modest 20 examples of each. The results
prove that, for many features, the example genera-
tion approach allows many more instances of that
feature to be placed in the corpus.
3.4 Comparison with Active Learning
The process presented in Section 3.1 bears a close
resemblence with active learning, so the differ-
ences between the two merit some discussion. Ac-
tive learning seeks to improve a specific classifier
by selecting training data based on some confi-
dence/score metric for the purpose of improving
an overall metric (usually the score across all an-
notated data). Often, examples on which the clas-
sifier is the least confident are presented to an an-
notator for manual classification. Then the system
is re-trained to include the new data, and the pro-
cess repeats.
The annotation process presented above, how-
ever, is not ?active? in this same sense. Instead
it seeks a certain distribution of properties regard-
less of a classifier?s ability to accurately perform
inferences. The primary advantage, then, is a cor-
pus that is not designed for a specific classification
50
Corpus # Dev # Test
RTE-1 567 800
RTE-2 800 800
RTE-3 800 800
BPI 250
Table 4: Number of annotated inferences for each
inference corpus.
technique or set of features. A secondary advan-
tage is that it avoids the risk of choosing poor ex-
amples but rather seeks a breadth of data.
4 Corpus Size Considerations
An important consideration?and an active area of
research?is the ideal size of an annotated corpus.
As one can see from Table 4, the RTE tasks make
800 examples available for an open-domain tex-
tual inference corpus.
But when the scope of the corpus is more lim-
ited, perhaps 800 examples is too few or too many.
If the intent is to provide a set on which systems
can be blindly evaluated for motion inference, then
a much smaller number is required than a corpus
intended for training machine-learned models. In
this case, we seek to do the latter.
It should be mentioned that if the corpus gen-
eration process follows the algorithm presented in
Section 3.1, then any reasonable number of infer-
ence pairs should follow the same distribution as
a much larger set. For this reason, it is possible
to adopt the active learning approach and build the
corpus incrementally by iteratively annotating un-
til satisfactory results are reached or gains are min-
imal.
5 Discussion
In addition to building a motion-specific corpus,
this paper argues for the creation of domain-
specific corpora for textual inference. Beyond
simply measuring a system?s ability to reason for
specific tasks, they enable the aquisition of world
knowledge through training data. They can then
be used by statistical learning techniques applied
to natural language processing. This is different
than generating axioms and using them in abduc-
tive reasoning, which is another approach to ap-
proximate world knowledge.
Levin?s verb classes (of which there are less
than fifty) are a useful way to organize corpora.
Levin?s classes are structured under the assump-
tion that syntactic and semantic frames are directly
linked within each class. Since all verbs within the
class have similar semantic arguments, knowledge
aquisition becomes manageable. A system that
has a wide coverage of knowledge trained on such
corpora could claim a wide coverage of knowledge
of all verb-based events within text.
6 Conclusion
This paper has presented an argument for the cre-
ation of domain-specific textual inference corpora
and, in general terms, what that corpus should look
like. In particular, it has described the ongoing
process of building an inference corpus for spa-
tial inference about motion. It has shown how an
existing system can be used to aid in the example
generation and annotation process with analysis as
to the effects of the algorithm on presenting more
balanced data. Finally, the paper discussed some
considerations for the size of such a corpus.
Upon completion, the corpus will be made pub-
lically available.
References
Ido Dagan, Oren Glickman, and Bernardo Magnini.
2005. The pascal recognizing textual entailment
challenge. In Proceedings of the First PASCAL
Challenges Workshop on Recognising Textual En-
tailment, pages 1?8.
Christiane Fellbaum, editor. 1998. WordNet: An Elec-
tronic Lexical Database. MIT Press.
Jerry R. Hobbs and Srini Narayanan. 2002. Spatial
representation and reasoning. In Intelligent Systems:
Concepts and Applications, pages 67?76. MacMil-
lan.
Karin Kipper, Hoa Trang Dang, and Martha Palmer.
1998. Class-based construction of a verb lexicon.
In In Proceedings of AAAI/IAAI.
Beth Levin. 1993. English Verb Classes and Alterna-
tions: A Preliminary Investigation. The University
of Chicago Press.
Philippe Muller. 1998. A Qualitative Theory of Mo-
tion Based on Spatio-Temporal Primitives. In KR
?98: Principles of Knowledge Representation and
Reasoning, pages 131?141.
James Pustejovsky and Jessica L. Moszkowicz. 2008.
Integrating Motion Predicate Classes with Spatial
and Temporal Annotations. In Proceedings of COL-
ING 2008, pages 95?98.
51
