Conversational Implicatures
Robert van Rooy

Institute for Logic, Language and Computation
University of Amsterdam
Nieuwe Doelenstraat 15, 1012 CP Amsterdam
vanrooy@hum.uva.nl
Abstract
According to standard pragmat-
ics, we should account for conver-
sational implicatures in terms of
Grice's (1975) maxims of conversa-
tion. Neo-Griceans like Atlas &
Levinson (1981) and Horn (1984)
seek to reduce those maxims to the
so-called Q and I-principles. In
this paper I want to argue that (i)
there are major problems for reduc-
ing Gricean pragmatics to these two
principles, and (ii) that, in fact, we'd
better account for implicatures in
terms of the principles of (a) opti-
mal relevance and (b) optimal cod-
ing. To formulate both, I will make
use of Shannon's (1948) mathemat-
ical theory of communication.
1 Introduction
Natural language is e?cient in the sense that
a single message can convey dierent seman-
tic contents in dierent contexts. And indeed,
recent trends in semantics (e.g. optimality
theoretic semantics) suggest that the actual
interpretation of an utterance is highly un-
derspecied by the conventional meanings of
the sentence that is used. This requires, how-
ever, that language users have robust ways
to resolve the underspecication and/or am-
biguity. In this paper I will discuss two ways

This research has been made possible by a fellow-
ship of the Royal Netherlands Academy of Arts and
Sciences.
of doing this. First, one where the particular
conversational situation is important; second,
one which depends on more general conven-
tions.
2 The Q and I principle
Neo-Gricean pragmatics seeks to reduce
Grice's maxims of conversation to the so-
called Q and I principles. Both are used
to account for many conversational implica-
tures. The Q-principle (implementing Grice's
rst maxim of Quantity) advises the speaker
to say as much as he can to fulll his com-
municative goals, while the I-principle (im-
plementing Grice's other maxims, except for
quality) advises the speaker to say no more
than he must to fulll these goals. Both prin-
ciples help to strengthen what is communi-
cated by a sentence. The Q-principle induces
inferences from the use of one expression to
the assumption that the speaker did not in-
tend to communicate a contrasting, and in-
formationally stronger, one. This principle
is thus essentially metalinguistic in kind, and
accounts for both `scalar' and `clausal' impli-
catures. It allows us, for instance, to conclude
from \John ate some of the cookies" to \John
didn't eat all of the cookies" (scalar implica-
ture), and from \A or B" to \A or B, but not
both" (clausal + scalar implicature). The I-
principle allows us to infer from the use of an
expression to its most informative or stereo-
typical interpretation. It is used, for instance,
to enrich the interpretation of a conjunction
to a temporal sequential, or causal, relation,
and it allows us to interpret a conditional like
`John walks, if Mary walks' as the bicondi-
tional `John walks if and only Mary walks'.
3 Problems for the Q and I
principles
3.1 Too general
Although the Q and I principles are intu-
itively appealing, they give rise to a num-
ber of conceptual and empirical problems.
Let's start with some cases where it is pre-
dicted that Q-implicatures arise, although in
fact they don't. First, at least when imple-
mented as Gazdar (1979) did, we can derive
from the existential \Someone is sick" as a
Q-implicature that (the speaker knows that)
a is not sick, for any individual a. Second,
on the assumption that scales are dened in
terms of entailment, it is predicted that we
can infer from `B, if A' to the conclusion that
it is not the case that the stronger `B if and
only if A' holds, although in a lot of situa-
tions this is exactly what we can conclude.
Third, on the same assumption, it is incor-
rectly predicted that we can infer `not regret
A' from `know A'. Horn, Levinson and oth-
ers have argued that these problems can be
prevented by (i) weakening the force of Q-
implicatures from know-not to not-know (for
the rst problem), and by putting constraints
on what counts as contrastive expressions:
contrastive expressions must be lexical items
(second problem) and must have the same
presuppositions (for the third). Although it
can be argued that for the biconditional in-
terpretation this { somewhat ad hoc { solu-
tion solves the second problem, Gazdar (1979)
argued that the constraints doesn't solve the
third one. Moreover, the most serious prob-
lematic cases where Q-implicatures overgen-
erate cannot be explained away in this way:
The Horn/Gazdar/Levinson/Atlas analysis of
Q-implicatures as generalized conversational
implicatures (PCIs) triggered solely by lexi-
cal expressions cannot explain why from A's
answer \John has 2 children" to Q's question
\Who has 2 children?" the implicature \John
has only 2 children" does not even arise as a
default (cf. van Kuppevelt). This latter ex-
ample seems to suggest that these so-called
Q-implicatures are, after all, dependent on
the conversational situation, in particular on
the question being asked. Proponents of the
Q and I pragmatics (Horn, Levinson), fol-
lowed by Matsumoto (1995), argue that in
such particular conversational situations the
generalized conversational implicature is can-
celled, for reasons of relevance: The answer
is already informative enough for the purpose
of the conversation. I will argue, however,
that informativity is, in general, not the cru-
cial issue, and that it is much more natural to
assume that { for reasons of relevance in this
particular situation { the (potential) implica-
ture does not even arise.
3.2 Not general enough
Not only does the standard analysis of Q-
implicatures overgeneralize, it also doesn't
seem to be general enough. First, as discussed
extensively by Hirschberg (1985), the stan-
dard analysis is of no help to account for cer-
tain examples that intuitively should be an-
alyzed as scalar implicatures. If Mary's po-
tential new boss asks her at her job-interview
whether she speaks French, and she answers
by saying \My sister does", he can conclude
that Mary herself does not. The standard
analysis fails to account for this, because (a)
scalar implicatures are all analyzed in terms of
the Q-principle, (b) the Q-principle is stated
in terms of informativity, but (c) the propo-
sition that Mary speaks French is not more
informative (i.e. entails) than the proposi-
tion that her sister does. This example sug-
gests (i) that scalar implicatures should not
exclusively be accounted for in terms of infor-
mativity, and (ii) that just like in the previ-
ous example, also here the relevant implica-
ture crucially depends on the conversational
situation (i.e. the beliefs and preferences of
the agents involved). Second, as discussed by
McCawley (1993), the implicatures generated
by the hand, ori scale cannot account for the
fact that a sentence of the form `A or B or
C' gives rise to the inference that only one of
the three is true. A nal example where the
standard analysis of Q-implicatures isn't gen-
eral enough was discussed by Groenendijk &
Stokhof (1984). They observe that when A
answers Q's question \Who comes?" by say-
ing \Peter comes", we typically interpret the
answer as being exhaustive. That is, we inter-
pret A's answer as \Only Peter comes". They
claim that this kind of inference should intu-
itively be accounted for in terms of Grice's
maxim of Quantity (as a Q-implicature), but
note that the standard implementation does
not predict the exhaustivity of the answer.
Still, it seems that the exhaustive interpre-
tation of the answer should be derived by
Gricean pragmatics on the assumption that
answers are as informative as the question re-
quires.
I conclude that the scales relevant for the
implicatures depend on the conversational sit-
uation (i.e. question asked) and the beliefs
and preferences of the agents involved is in
correspondence with Hirschberg's claim that
scales are dependent on context. However, we
would like to say something more; we would
also like to say how the relevant scale depends
on the question asked and the relevant beliefs
and desires.
4 Relevance
In this respect, important progress has been
made recently by Merin (1997). Following the
lead of Anscombre & Ducrot (1983), Merin ar-
gues that scales should be dened not in terms
of informativity, but rather in terms of a no-
tion of relevance. The relevance of a propo-
sition is determined in terms of the argu-
mentative force the proposition would have in
that particular conversational situation. The
relevance of an assertion is then dened in
information/decision/game theoretical terms,
based on the assumption that the partici-
pants of the conversation have strictly oppos-
ing preferences, i.e. that the participants play
a zero-sum game.
Although Merin convincingly shows that
some scalar implicatures (in particular the
Hirschberg examples) can be accounted for
appropriately on the assumption that play-
ers argue for particular hypotheses, and that
their contribution should be interpreted in the
most relevant way (i.e. strongest argument),
it is intuitively clear that not all conversa-
tions can, and should, be modeled as zero-sum
games. It makes little sense, for instance, to
assume that the exhaustive interpretation of
\John has 2 children" as answer to the ques-
tion \How many children does John have?"
can be explained in terms of opposing pref-
erences between questioner and answerer, for
the latter typically cooperates with the for-
mer. What is called for, then, is a gener-
alization of Merin's notion of relevance that
also measures the relevance of propositions
in cooperative conversational situations. It
seems only natural, on the assumption that
speakers are relevance optimizers, that once
we can dene such a measure, not only the
typical Q-implicatures can be accounted for in
terms of relevance, but also the I-implicatures
from conditional to biconditional, and Groe-
nendijk & Stokhof's (1984) observation that
answers are normally interpreted in an ex-
haustive way. As we will see in the next sec-
tion, Groenendijk & Stokhof (1984) show that
almost all typical Q-implicatures can be an-
alyzed alternatively in terms of their explicit
exhaustivity-operator, without giving rise to
the above discussed overgeneralizations, when
the clause that gives rise to the implicature is
used as an answer to a question.
5 Exhaustied answers
Groenendijk & Stokhof (1984) propose to ac-
count for the intuition that answer Peter
comes to question Who comes? should nor-
mally be read exhaustively by introducing an
explicit exhaustivity operator that is applied
to answers and the abstracts underlying the
questions to derive the exhaustive interpreta-
tion.
exh = RP [R(P )^:9P
0
[R(P
0
)^P 6=
P
0
^ 8x[P
0
(x) ! P (x)]]]
This exhaustivity operator accounts for
many of the implicatures traditionally ac-
counted for in terms of Grice's maxim of
quantity. First, it obviously accounts for the
fact that when Who comes? is answered by
John we conclude that only John comes. Sec-
ond, when answer A man is given we can con-
clude that not all men come, an implicature
standardly triggered by the hall, somei scale.
In contrast to Gazdar's analysis of scalar im-
plicatures, however, our analysis does not give
rise to the wrong prediction that John is not
coming: the exhaustive reading of A man is
coming as answer to question Who comes? is
compatible with the fact that John is. Note
that this analysis, in distinction with the stan-
dard analysis of scalar implicatures, works
also well when more than one item gives rise
to an implicature. From the exhaustive inter-
pretation of the term Some of the bacon and
some of the eggs given as answer to the ques-
tion What did Mary ate? we can conclude
that Mary didn't eat all of the bacon, and
that she didn't eat all of the beans, just like
we should.
Notice that our exhaustication analysis
not only predicts intuitions standardly ac-
counted for in terms of the Q principle; also
some I-implicatures are accounted for. If the
question is Who quacks? the answer Every
duck quacks is predicted to mean that every
quacker is a duck. Horn (2000) calls this in-
ference conversion and explicitly proposes to
account for it in terms of the I-principle.
Similarly, if we allow for explicit quanti-
cation over worlds, we can account for the in-
ference from (1b) to (1c), when the former is
given as answer to (1a):
(1) a. Q: Did John walk?
b. A: If Mary talked.
c. John walked i Mary talked.
We assume that the property underlying
a question like (1a) is w:Walk(j)(w), and
that answer (1b) should be represented by
P:8w[Talk(m)(w) ! P (w)] which after ex-
haustication means that Mary talked i
John walked.
1
1
This inference is accounted for by Groenendijk &
Stokhof (1984) in terms of their generalized exhaustiv-
ity operator without using explicit quantication over
worlds. Such an analysis cannot account, however,
for the exclusive reading of disjunctive sentences with
more than two disjuncts, to be discussed below.
Our approach also predicts that (2a) should
be read as (2b) when the color of the ag is
at issue.
(2) a. The ag is red.
b. The ag is all red.
This inference is normally (e.g. Atlas &
Levinson, 1981) accounted for by assuming
that (2a) should be interpreted as informative
as possible. But then it should be explained
why in certain circumstances the inference is
absent. When 3 ags are mutually known by
us to be all white except for a small block of
some other distinguishing color (being either
red, yellow or green), and I ask you to identify
the ag you hold behind your back, your an-
swer (2a) satises me, and I do not imply that
(2b) is true. The standard analysis has to as-
sume that in these cases the triggered general-
ized implicature are cancelled, while we don't
even generate the implicature because we can
assume that the implicit question was some-
thing like What is the color of the small block?
Indeed, our topic-dependent analysis of
`scalar' implicatures prevents us from trig-
gering implicatures to be cancelled later for
reasons of relevance (see also van Kuppevelt
(1997) and Carstyn (ms)). Consider the fol-
lowing example again:
(3) a. Q: Who has 2 children?
b. A: John has 2 children.
c. John doesn't have more than 2 chil-
dren.
Instead of saying that (3b) triggers the po-
tential implicature (3c) that is cancelled when
the former is given as answer to question (3a),
our analysis predicts that the implicature is
not even triggered, because (3b) completely
answers (3a).
A similar analysis can be given for the fact
that a disjunctive sentence sometimes gets an
exclusive reading and sometimes not. If we
allow for explicit quantication over worlds,
we can represent an answer like A or B or
C in terms of an existential quantier as fol-
lows: P:9w[(A(w)_B(w)_C(w))^P (w)]. If
we now assume that this sentence is given as
answer to the question `What proposition(s)
is/are true?', exhaustivity has the eect that
only worlds count that make just one of the
three propositions true, resulting in the ex-
clusive reading.
However, this analysis does not have the re-
sult that a disjunctive sentence should always
have the exclusive reading. In particular this
is rightly predicted not to be the case in (4),
where the complex sentence is given as an (ex-
haustive) polar answer:
(4) Q: Are the cookies or the chocolates in
the box?
A: Yes, the cookies or the chocolates are
in the box.
Something similar is the case with condi-
tional answers. Also after exhaustication
they don't get a bi-conditional interpretation
when they are used as complete answers to
polar questions:
(5) Q: Did John walk, if Mary talked?
A: Yes, John walked if Mary talked.
6 Relevance and Exhaustivity
In the previous section we have seen that
many so-called `quantity' implicatures trig-
gered by sentences can be accounted for by
assuming that these sentences should be in-
terpreted as exhaustive answers to questions.
However, we would like to say something
more; we would also like to give an inde-
pendent motivation for why answers should
normally be interpreted exhaustively. Notice
that Groenendijk & Stokhof's (1984) stipu-
lation that answers should always be inter-
preted exhaustivily would not only be ad hoc,
it would also give rise to counterexamples.
Most importantly, it would predict incorrectly
for so-called mention-some questions. Some-
times an assertion intuitively answers a ques-
tion completely without being read exhaus-
tively. To illustrate, when I ask you (6a) and
you answer by saying (6b), I am satised, al-
though I don't interpret your answer as claim-
ing that this is the only place where I can buy
an Italian newspaper.
(6) a. Where can I buy an Italian newspa-
per?
b. Around the corner.
6.1 Topic dependent relevance
In cooperative dialogues the relevance of com-
municative acts can be determined with re-
spect to decision problems (cf. van Rooy
(2001). A decision problem Using commu-
nication theory we can model these decision
problems by partitions of the logical space {
, i.e., the semantic questions of Groenendijk
& Stokhof (1984). One proposition will then
be more relevant than another when it helps
more to resolve the question.
Intuitively, we would like to say that asser-
tions are relevant with respect to this decision
problem if the decision is easier to make af-
ter an assertion is learned. But to account
for this, we have to measure the di?culty of
the decision. A standard way to do this is in
terms of entropy.
Given a probability function P , we can de-
ne the entropy of decision problem Q as fol-
lows:
E(Q) =
X
q2Q
P (q) log
2
P (q)
When our agent learns proposition A, we
can determine the entropy of decision prob-
lem Q conditional on learning A, E
A
(Q), as
follows:
E
A
(Q) =
X
q2Q
P (q=A)  log
2
P (q=A)
In terms of this notion we can now dene what
might be called the Relevance of proposition
A, with respect to partition Q, R
Q
(A), as
the reduction of entropy, or uncertainty, of
Q when A is learned:
2
R
Q
(A) = E(Q) E
A
(Q)
Relevance will be used to determine the ac-
tual interpretation of a sentence underspeci-
ed by its conventional meaning. We will say
2
This notion was used by Lindley (1956) already to
measure the informational value of a particular result
of an experiment.
that interpretation A is better than interpre-
tation B, A > B, i R
Q
(A) > R
Q
(B) with
respect to all probability functions for which
Q has maximal entropy.
It might be, of course, that for some proba-
bility distributions A is better, while for oth-
ers B is. Which one is then preferred? In
those cases, I propose, interpretation A is bet-
ter if the sentence `gives rise' to a new ques-
tion, Q
0
, which is orthogonal to Q, such that
after learning A, but not after learning B, ev-
ery complete answer to Q
0
also completely an-
swers Q. This indirect notion of relevance will
be crucial to account for the implicatures of
disjunctive and conditional sentences.
6.2 Why Exhaustify
Consider question (7):
(7) Whom of John and Bill are sick?
This question gives rise to a partition with
4 cells. Assuming that the probability that
John is sick equals the probability that Bill is
sick, but that the sickness of the one is inde-
pendent of the other, it is easy to see that the
entropy of the question is 2: the question im-
plicitly asks for answers to two independent
binary questions. Notice that after learning
that (At least) John is sick the entropy of the
question reduces to 1, which means that the
relevance of this answer is 2 - 1 = 1. Af-
ter learning of each of John and Bill whether
they are sick, however, the question/decision
problem is resolved: the entropy reduces to 0,
and the reduction of entropy, the relevance of
an answer like John and Bill are sick, is 2 -
0 = 2. Thus, for an answer to have maximal
relevance, it should say of each individual in
the domain of quantication whether that in-
dividual is sick or not. It should be obvious
that this means that complete, or exhaustive,
answers to questions are always at least as
relevant as partial answers.
Now consider answers (8a) and (8b) to
question (7)
(8) a. John is sick.
b. A man is sick.
What is the relevance of these answers,
i.e., in how far do these answers reduce the
entropy of the question? That depends on
how we interpret them. If we interpret them
non-exhaustively, the conditional entropy of
(7) given (8a) is (P (J ^ B=J)   log
2
P (J ^
B=J))+(P (J^:B=J) log
2
P (J^:B=J)) =
((
1
2
 log
2
1
2
)+(
1
2
 log
2
1
2
)) =  Log
2
1
2
= 1.
Similarly, given that John and Bill are the
only men, the conditional entropy of (7) given
(8b) is (P (J ^B=J _B) log
2
P (J ^B=J _
B))+(P (J^:B=J_B) log
2
(P (J^:B=J_
B)) + (P (:J ^ B=J _ B)   log
2
(P (:J ^
B=J _B)) = 3 (
1
3
 log
2
1
3
) =  log
2
1
3
< 1.
The relevance of these two answers accord-
ing to their non-exhaustive interpretation are
thus 1 and something less than 1, respec-
tively. What if we interpret the answers ex-
haustively? That is, what is the reduction
of entropy if we assume that the propositions
expressed by the answers are determined af-
ter we have applied the exhaustivity operator
to (8a) and (8b), respectively? After exhaus-
tication, answer (8a) really means John is
sick and Bill is not, and after this informa-
tion is received the entropy reduces from 2
to 0; its relevance is thus 2. Similarly, an-
swer (8b) really means that either only John
is sick or that only Bill is sick, and this new in-
formation reduces the entropy of the original
question from 2 to 1. The important fact to
note here is that in both cases the reduction
of entropy of the answer under its exhaustive
interpretation is higher than the reduction of
entropy under its non-exhaustive interpreta-
tion. And this is in general the case: most
answers have a higher relevance on their ex-
haustive reading than on their non-exhaustive
reading. On the assumption that speakers are
relevance maximizers this means that in case
answerers are expected to be cooperative we
should interpret these answers exhaustively.
For disjunctive and conditional sentences
we have to look at our indirect method. If the
question is whether A is the case, A?, and the
answer Yes, or B, it might be the case that
the entropy decreases more on the inclusive
reading than on the exclusive reading. Some-
thing similar happens with respect to the con-
ditional and biconditional interpretations of
answer If B. It is natural to assume, how-
ever, that both questions `give rise' to another
question: B?. Only on the exclusive and bi-
conditional interpretation of the two answers
every answer to the second question will also
resolve the original question whether A is the
case. For this reason, the exclusive and bi-
conditional interpretations are preferred.
Above, we have criticized Groenendijk &
Stokhof's (1984) assumption that in case an-
swers are not explicitly marked as being par-
tial answers, we should always read them ex-
haustively. One complaint was that this as-
sumption is just an ad hoc stipulation. Groe-
nendijk & Stokhof agree, and explicitly regret
that they see no way to derive exhaustica-
tion from the Gricean maxims of conversa-
tion, in particular not from Grice's maxim of
quantity. This complaint can now be met: I
have shown in this section that we can mo-
tivate the assumption that answers should
be read exhaustively by deriving it from the
much more general assumption that speakers
are relevance optimizers.
What about the other complaint I men-
tioned earlier? As noted above, an answer like
Around the corner intuitively resolves ques-
tion Where can I buy an Italian newspaper?
although it does not suggest that you can buy
an Italian newspaper around the corner only.
Fortunately, however, also the problematic
mention-some phenomena can be accounted
for when we assume that speakers are rele-
vance optimizers. In van Rooy (to appear) I
argue that mention-some questions are asked,
or mention-some answers are given, only in
very particular circumstances, and show that
in these circumstances the utility, or rele-
vance, of mention-some questions/answers co-
incide with their mention-all alternatives. For
reasons of economy, mention-some readings
are in these circumstances preferred. We
can conclude that although in normal circum-
stances the exhaustive reading of an answer is
more relevant than its non-exhaustive coun-
terpart, in special circumstances it is not. As
a result, we can explain that for reasons of op-
timizing relevance, exhaustication does not
always take place.
7 Explaining markedness
7.1 Horn's division of labor
Consider a typical case of communication
where two meanings m
1
and m
2
can be
expressed by two linguistic representations
r
1
and r
2
. In principle this gives rise to
two possible codings: fhr
1
;m
1
i; hr
2
;m
2
ig and
fhr
1
;m
2
i; hr
2
;m
1
ig. In many communicative
situations, however, the underspecication
does not really exist, and is resolved due to
the general pragmatic principle that a lighter
form will be interpreted by a more salient,
or stereotypical, meaning: (i) It is a general
defeasible principle, for instance, in centering
theory that if a certain object/expression is
referred to be a pronoun, another more salient
object/expression should be referred to by a
pronoun too; (ii) Reinhard (1983) and Levin-
son (1987) seek to reduce Chomsky's B and C
principles of the binding theory to pragmat-
ics maxims. In particular, disjoint reference
of lexical NPs throughout the sentence is ex-
plained by pointing to the possibility of the
use of a lighter expression, viz. an anaphor
or pronoun; (iii) The preference for bridging
(Clark & Haviland, 1977) and stereotypical
interpretations (Atlas & Levinson, 1981); (iv)
and perhaps most obviously, Horn's (1984) di-
vision of pragmatic labor according to which
marked expression (morphologically complex
and less lexicalized) typically get a marked
meaning (cf. John made the car stop versus
John stopped the car and consider also the fact
that stressed pronouns can pick up less salient
objects). In neo-Gricean pragmatics proposed
by Atlas, Horn and Levinson, this principle is
explained through the interaction of the so-
called Q and I principles, and has recently
been incorporated in (bi-directional) optimal-
ity theory by Blutner (2000) and reformulated
in terms of game theory by Dekker & van
Rooy (2000). However, as we have seen above,
explanations based on the Q and I princi-
ples are very shaky: these principles tend to
clash with one another, and it is not always
clear how to resolve this clash. In particular,
it's unclear under which circumstances which
principle should be used to explain the phe-
nomena. I will show that by thinking of lan-
guage as an e?cient coding system the princi-
ple that lighter expressions get a more salient
meaning can be given a straightforward ex-
planation.
7.2 Optimal coding of information
The question that started information the-
ory was: how can we send messages over a
channel as quickly as possible without distor-
tion? The answer is: by looking for the opti-
mal coding; to represent the data in a way as
comprehensive as possible. Suppose we have
a source (without memory) that sends mes-
sages from a set U = fu
1
; :::; u
n
g in terms
of codes built up from codesymbols belong-
ing to the code-alphabet S = fs
1
; :::; s
n
g. A
source code, or coding system, C, is dened as
a function from U to S

, where `' is Kleene's
star. For example, C(red) = 00; C(white) =
11; C(blue) = 10; C(orange) = 01 is a source
code for U = fred, white, blue, orangeg with
alphabet S = f0; 1g. Of course, the source
and alphabet alow for many dierent codes.
Intuitively, however, some codings are more
e?cient than others. What is the best coding
system? The coding system with the short-
est expected length. The crucial insight of
Shannon (1948) was that this expected length
depends not only on the length of the mes-
sages after encoding, but also on the proba-
bility with which the messages are sent. Sup-
pose that function P assigns numbers to the
elements of U such that
P
u2U
P (u) = 1, i.e.
suppose that P is a probability distribution
over U . Suppose, moreover, that l(C(u)) is
the length of the codeword associated with u.
In that case, the expected length of a source
code C for U and P is given by:
L(C) =
X
u2U
P (u) l(C(u))
To illustrate, let us extend our example by
assuming that the probability distribution of
U is P (red) =
1
2
, P (white) =
1
4
, P (blue) =
1
8
,
P (orange) =
1
8
. Then we can easily see
that the coding C
0
(red) = 0; C
0
(white) =
10; C
0
(blue) = 110; C
0
(orange) = 111 has
a shorter expected length than the coding
given above: 1.75 to 2. A crucial dierence
between the two codings is that in distinc-
tion with C, C
0
does not encode all elements
of U with the same length: the more prob-
able elements of U get an encoding with a
shorter length.
3
This holds in general: in case
P (u
i
) > P (u
j
) the optimal coding C will be
such that l(C(u
i
))  l(C(u
j
)) (cf. Cover &
Thomas, 1991). Thus, the messages that are
more likely to be sent will be encoded with
a smaller length. This fact can now be used
to account for Horn's division of pragmatic
labor. Suppose that speakers have the follow-
ing set of contents/meanings that they might
want to communicate: M = fm
1
; :::;m
n
g.
On average, we might assume that the proba-
bilities with which they want to communicate
these contents/meanings are correlated with
the probabilities with which these contents
are true: if m
i
is more likely to be the case,
or more stereotypical, than m
j
, the probabil-
ity that speakers want to communicate m
i
is
higher than that of m
j
. In other communica-
tive situations the probability with which the
elements of M are communicated depends on
how salient the elements of M are.
4
Speakers
cannot send the contents without represent-
ing them. Let us assume that speakers can
use the elements of R (the representations),
R = fr
1
; :::; r
k
g, to encode the elements of M .
The elements of R might be varied: some are
more complex than others. Codings are now
functions from M to R. Just as before we can
ask: what is the best coding? Following stan-
dards in data comprehension, the answer is:
the coding that minimizes average complex-
ity. Average complexity of coding system C
3
There exists a close connection with entropy too:
for coding C
0
, but not for C, the expected length,
L(C
0
) is equal to the entropy of U , E(U). It turns
out that this is the optimal one can reach for w.r.t.
uniquely decodable codes. Notice that this means
that the optimal codelength for each u
i
is equal to
 log
2
P (u
i
), the surprise value of u
i
.
4
In yet others, the probabilities depend even more
on the conversational situation and correlate with rel-
evance.
is dened as follows:
Compl(C) =
X
m2M
P (m)Compl(C(m))
Now it is easy to show that the assump-
tion of optimal coding accounts for Horn's
observation that simple expressions get
a salient/stereotypical interpretation, while
complex expressions a marked one. Suppose
that the conventional meanings of represen-
tations r
i
and r
j
are such that they both
could express m
i
and m
j
. For instance, with
both words kill and cause to die we could de-
note situations of direct (stereotypical) and
indirect (marked) killing, and with both un-
stressed he and stressed HE we could refer to
both salient and non-salient male individuals
in the discourse. Still, the less complex kill
will typically be interpreted as direct stereo-
typical killing, an the other way around for
complex cause to die. And this follows from
the assumption that speakers use a language
that optimally encodes the relevant informa-
tion. In this case we have two relevantly dif-
ferent coding systems: C, which assigns m
i
to
r
i
and m
j
to r
j
, and C
0
, which assigns m
i
to
r
j
and m
j
to r
i
. The probabilities and com-
plexities are such that P (m
i
) > P (m
j
) and
Compl(r
i
) > Comp(r
j
). A standard proof
showing that Compl(C
0
)   Compl(C) > 0
demonstrates then that C is a more optimal
coding than C
0
(where I abbreviate P (m
i
) by
p
i
, Compl(r
i
) by cpl
i
, and `' by `'):
Compl(C
0
)  Compl(C) =
=
P
p
i
 Compl(C
0
(i))  
P
p
i
 Compl(C(i))
= (p
i
 cpi
j
)+ (p
j
 cpl
i
)  (p
i
 cpl
i
)  (p
j
 cpl
j
)
= (p
i
  p
j
)  (cpl
j
  cpl
i
)
Because p
i
 p
j
> 0, C
0
can only be more opti-
mal than C in case cpl
j
 cpl
i
< 0. But this is
by assumption not the case, and so C is pre-
ferred to C
0
. The same proof shows that when
p
i
 p
j
> 0 the optimal code is such that cpl
i

cpl
j
; only then Compl(C
0
)   Compl(C)  0.
Horn's division explained.
References
Anscombre J.C. and O. Ducrot (1983),
L'Argumentation dans la langue, Brussels,
Mardaga.
Atlas, J. and S. Levinson (1981), `It-Clefts, In-
formativeness and Logical Form', In: P. Cole
(ed.), Radical Pragmatics, New York, AP.
Blutner, R. (2000), `Some aspects of Optimality
in Natural Language Interpretation', Journal of
Semantics.
Carston, R. (ms.), Informativeness, Relevance
and Scalar Implicature, University College Lon-
don.
Clarck H. H. & J. Haviland (1977), `Comprehen-
sion and the given-new contract', In R. Freedle
(ed.), Discourse production and comprehension,
Hillsdale, NJ: Lawrence Erlbaum, pp. 1-40.
Cover, T.M. & J.A. Thomas (1991), Elements of
Information Theory, Wiley: New York.
Dekker, P. & R. van Rooy (2000), `Bidirectional
Optimality Theory: an application of Game
Theory', Journal of Semantics.
Gazdar, G. (1979), Pragmatics, London: Aca-
demic Press.
Groenendijk, J. and M. Stokhof (1984), Studies in
the Semantics of Questions and the Pragmatics
of Answers, Ph.D. thesis, University of Amster-
dam.
Grice, H. P. (1975), `Logic and Conversation', In:
P. Cole & Morgan (eds.), Syntax and Semantics
3: Speech Acts, New York: Academic Press.
Hirschberg, J. (1985), A theory of scalar implica-
ture, Ph.D. thesis, UPenn.
Kuppevelt, J. van (1996), `Inferring from Topics:
Scalar Implicature as Topic-Dependent Infer-
ences', Linguistics and Philosophy, 19, pp. 555-
598.
Horn. L. (1972), The semantics of logical operators
in English, Ph.D. thesis, Yale University.
Horn, L. (1984), `Towards a new taxonomy of
pragmatic inference: Q-based and R-based im-
plicature'. In: Schirin, D. (ed.), Meaning,
Form, and Use in Context:: Linguistic Appli-
cations, GURT84, 11-42, Washington; George-
town University Press.
Horn, L. (2000), `From if to i: Conditional per-
fection as pragmatic strengthening', Journal of
Pragmatics, 32: 289-326.
Levinson, S.C. (1987), `Pragmatics and the gram-
mar of anaphora', Journal of Linguistics, 23:
379-434.
Levinson, S.C. (2000), Presumptive Meanings.
The Theory of Generalized Conversational Im-
plicatures, MIT Press: Cambridge, Mas-
sachusetts.
Lindley, D. V. (1956), `On a measure of informa-
tion provided by an experiment', Ann. Math.
Stat., 29, pp. 986-1005.
Matsumota, Y. (1995), `The conversational con-
dition on Horn scales', Linguistics and Philos-
ophy, 18: 21- 60.
McCawley, J. (1993), Everything that Linguists
always wanted to know about Logic, but were
afraid to ask, Chicago: Chicago University
Press.
Merin, A. (1997), `Information, relevance, and so-
cial decisionmaking', In: L. Moss, J. Ginzburg,
M. de Rijke (eds.), Logic, Language, and Com-
putation, Vol. 2, Stanford.
Reinhard, T. (1983), Anaphora and semantic in-
terpretation, London: Croom Helm.
Rooy, R. van (2001), `Relevance of communicative
acts', In Theoretical Aspects of Rationality and
Knowledge; Proceedings of TARK 2001, J. van
Benthem (ed.), San Francisco, Morgan Kauf-
mann Publishers, Inc., pp. 83-96.
Rooy, R. van (to appear), `Utility of mention-some
questions', Language and Computation.
Shannon, C. (1948), `The Mathematical Theory of
Communication', Bell System Technical Jour-
nal, 27.
