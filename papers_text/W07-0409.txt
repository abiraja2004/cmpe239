Proceedings of SSST, NAACL-HLT 2007 / AMTA Workshop on Syntax and Structure in Statistical Translation, pages 65?71,
Rochester, New York, April 2007. c?2007 Association for Computational Linguistics
Combining Morphosyntactic Enriched Representation with
n-best Reranking in Statistical Translation
H. Bonneau-Maynard, A. Allauzen, D. De?chelotte and H. Schwenk
Spoken Language Processing Group
LIMSI-CNRS, BP 133
91403 Orsay cedex, FRANCE
{maynard,allauzen,dechelot,schwenk}@limsi.fr
Abstract
The purpose of this work is to explore
the integration of morphosyntactic infor-
mation into the translation model itself, by
enriching words with their morphosyntac-
tic categories. We investigate word dis-
ambiguation using morphosyntactic cate-
gories, n-best hypotheses reranking, and
the combination of both methods with
word or morphosyntactic n-gram lan-
guage model reranking. Experiments
are carried out on the English-to-Spanish
translation task. Using the morphosyn-
tactic language model alone does not
results in any improvement in perfor-
mance. However, combining morphosyn-
tactic word disambiguation with a word
based 4-gram language model results in a
relative improvement in the BLEU score
of 2.3% on the development set and 1.9%
on the test set.
1 Introduction
Recent works in statistical machine translation
(SMT) shows how phrase-based modeling (Och and
Ney, 2000a; Koehn et al, 2003) significantly out-
perform the historical word-based modeling (Brown
et al, 1993). Using phrases, i.e. sequences of
words, as translation units allows the system to pre-
serve local word order constraints and to improve
the consistency of phrases during the translation pro-
cess. Phrase-based models provide some sort of
context information as opposed to word-based mod-
els. Training a phrase-based model typically re-
quires aligning a parallel corpus, extracting phrases
and scoring them using word and phrase counts. The
derived statistics capture the structure of natural lan-
guage to some extent, including implicit syntactic
and semantic relations.
The output of a SMT system may be difficult to
understand by humans, requiring re-ordering words
to recover its syntactic structure. Modeling language
generation as a word-based Markovian source (an n-
gram language model) discards linguistic properties
such as long term word dependency and word-order
or phrase-order syntactic constraints. Therefore, ex-
plicit introduction of structure in the language mod-
els becomes a major and promising focus of atten-
tion.
However, as of today, it seems difficult to outper-
form a 4-gram word language model. Several stud-
ies have attempted to use morphosyntactic informa-
tion (also known as part-of-speech or POS informa-
tion) to improve translation. (Och et al, 2004) have
explored many different feature functions. Rerank-
ing n-best lists using POS has also been explored by
(Hasan et al, 2006). In (Kirchhoff and Yang, 2005),
a factored language model using POS information
showed similar performance to a 4-gram word lan-
guage model. Syntax-based language models have
also been investigated in (Charniak et al, 2003). All
these studies use word phrases as translation units
and POS information in just a post-processing step.
This paper explores the integration of morphosyn-
tactic information into the translation model itself
by enriching words with their morphosyntactic cat-
65
egories. The same idea has already been applied
in (Hwang et al, 2007) to the Basic Travel Ex-
pression Corpus (BTEC). To our knowledge, this
approach has not been evaluated on a large real-
word translation problem. We report results on
the TC-STAR task (public European Parliament Ple-
nary Sessions translation). Furthermore, we pro-
pose to combine this approach with classical n-best
list reranking. Experiments are carried out on the
English-to-Spanish task using a system based on the
publicly available Moses decoder.
This paper is organized as follows: In Section
2 we first describe the baseline statistical machine
translation systems. Section 3 presents the consid-
ered task and the processing of the corpora. The
experimental evaluation is summarized in section 4.
The paper concludes with a discussion of future re-
search directions.
2 System Description
The goal of statistical machine translation is to pro-
duce a target sentence e from a source sentence f .
Among all possible target language sentences the
one with the highest probability is chosen. The use
of a maximum entropy approach simplifies the intro-
duction of several additional models explaining the
translation process:
e? = argmaxPr(e|f)
= argmaxe {exp(
?
i
?ihi(e, f))} (1)
where the feature functions hi are the system
models characterizing the translation process, and
the coefficients ?i act as weights.
2.1 Moses decoder
Moses1 is an open-source, state-of-the-art phrase-
based decoder. It implements an efficient beam-
search algorithm. Scripts are also provided to train a
phrase-based model. The popular Giza++ (Och and
Ney, 2000b) tool is used to align the parallel corpora.
The baseline system uses 8 feature functions hi,
namely phrase translation probabilities in both di-
rections, lexical translation probabilities in both di-
rections, a distortion feature, a word and a phrase
1http://www.statmt.org/moses/
penalty and a trigram target language model. Ad-
ditional features can be added, as described in the
following sections. The weights ?i are typically op-
timized so as to maximize a scoring function on a
development set (Och and Ney, 2002).
The moses decoder can output n-best lists, pro-
ducing either distinct target sentences or not (as
different segmentations may lead to the same sen-
tence). In this work, distinct sentences were always
used.
These n-best lists can be rescored using higher
order language models (word- or syntactic-based).
There are two ways to carry out the rescoring: one,
by replacing the language model score or by adding
a new feature function; two, by performing a log-
linear interpolation of the language model used for
decoding and the new language model. This latter
approach was used in all the experiments described
in this paper. The set of weights is systematically
re-optimized using the algorithm presented below.
2.2 Weight optimization
A common criterion to optimize the coefficients of
the log-linear combination of feature functions is to
maximize the BLEU score (Papineni et al, 2002)
on a development set (Och and Ney, 2002). For
this purpose, the public numerical optimization tool
Condor (Berghen and Bersini, 2005) is integrated in
the following iterative algorithm:
0. Using good general purpose weights, the
Moses decoder is used to generate 1000-best
lists.
1. The 1000-best lists are reranked using the cur-
rent set of weights.
2. The current hypothesis is extracted and scored.
3. This BLEU score is passed to Condor, which
either computes a new set of weights (the al-
gorithm then proceeds to step 1) or detects that
a local maxima has been reached and the algo-
rithm stops iterating.
The solution is usually found after about 100 itera-
tions. It is stressed that the n-best lists are generated
only once and that the whole tuning operates only
on the n-best lists.
66
English: IPP declareV V P resumedV V D theDT sessionNN ofIN theDT EuropeanNP ParliamentNP
Spanish: declaroV Lfin reanudadoV Ladj elART perodoNC dePREP sesionesNC
delPDEL ParlamentoNC EuropeoADJ
Figure 1: Example of POS-tag enriched bi-text used to train the translation models
2.3 POS disambiguation
It is well-known that syntactic structures vary
greatly across languages. Spanish, for example,
can be considered as a highly inflectional language,
whereas inflection plays only a marginal role in En-
glish.
POS language models can be used to rerank the
translation hypothesis, but this requires tagging the
n-best lists generated by the SMT system. This can
be difficult since POS taggers are not well suited for
ill-formed or incorrect sentences. Finding a method
in which morphosyntactic information is used di-
rectly in the translation model could help overcome
this drawback but also takes account for the syntac-
tic specificities of both source and target languages.
It seems likely that the morphosyntactic informa-
tion of each word will be useful to encode linguis-
tic characteristics, resulting in a sort of word disam-
biguation by considering its morphosyntactic cate-
gory. Therefore, in this work we investigate a trans-
lation model which enriches every word with its syn-
tactic category. The enriched translation units are a
combination of the original word and the POS tag, as
shown in Figure 1. The translation system takes a se-
quence of enriched units as inputs and outputs. This
implies that the test data must be POS tagged before
translation. Likewise, the POS tags in the enriched
output are removed at the end of the process to pro-
vide the final translation hypothesis which contain
only a word sequence. This approach also allows
to carry out a n-best reranking step using either a
word-based or a POS-based language model.
3 Task, corpus and tools
The experimental results reported in this article were
obtained in the framework of an international evalu-
ation organized by the European TC-STAR project2
in February 2006. This project is envisaged as a
2http://www.tc-star.org/
long-term effort to advance research in all core tech-
nologies for speech-to-speech translation.
The main goal of this evaluation is to trans-
late public European Parliament Plenary Sessions
(EPPS). The training material consists of the sum-
mary edited by the European Parliament in several
languages, which is also known as the Final Text
Editions (Gollan et al, 2005). These texts were
aligned at the sentence level and they are used to
train the statistical translation models (see Table 1
for some statistics).
Spanish English
Whole parallel corpus
Sentence Pairs 1.2M
Total # Words 34.1M 32.7M
Vocabulary size 129k 74k
Sentence length ? 40
Sentence Pairs 0.91M
Total # Words 18.5M 18.0M
Word vocabulary 104k 71k
POS vocabulary 69 59
Enriched units vocab. 115k 77.6k
Table 1: Statistics of the parallel texts used to train
the statistical machine translation system.
Three different conditions are considered in the
TC-STAR evaluation: translation of the Final Text
Edition (text), translation of the transcriptions of the
acoustic development data (verbatim) and transla-
tion of speech recognizer output (ASR). Here we
only consider the verbatim condition, translating
from English to Spanish. For this task, the develop-
ment and test data consists of about 30k words. The
test data is partially collected in the Spanish parlia-
ment. This results in a small mismatch between de-
velopment and test data. Two reference translations
are provided. The scoring is case sensitive and in-
cludes punctuation symbols.
67
3.1 Text normalization
The training data used for normalization differs sig-
nificantly from the development and test data. The
Final Text Edition corpus follows common ortho-
graphic rules (for instance, the first letter of the word
following a full stop or a column is capitalized) and
represents most of the dates, quantities, article refer-
ences and other numbers in digits. Thus the text had
to be ?true-cased? and all numbers were verbalized
using in-house language-specific tools. Numbers are
not tagged as such at this stage; this is entirely left
to the POS tagger.
3.2 Translation model training corpus
Long sentences (more than 40 words) greatly slow
down the training process, especially at the align-
ment step with Giza++. As shown in Figure 2, the
histogram of the length of Spanish sentences in the
training corpus decreases steadily after a length of
20 to 25 words, and English sentences exhibit a sim-
ilar behavior. Suppressing long sentences from the
corpus reduces the number of aligned sentences by
roughly 25% (see Table 1) but speeds the whole
training procedure by a factor of 3. The impact on
performance is discussed in the next section.
 0
 5000
 10000
 15000
 20000
 25000
 30000
 35000
 0  10  20  30  40  50  60  70  80  90  100
Histogram of Spanish sentences? lengths (training set)
Figure 2: Histogram of the sentence length (Spanish
part of the parallel corpus).
3.3 Language model training corpus
In the experiments reported below, a trigram word
language model is used during decoding. This
model is trained on the Spanish part of the parallel
corpus using only sentences shorter than 40 words
(total of 18.5M of language model training data).
Second pass language models were trained on all
available monolingual data (34.1M words).
3.4 Tools
POS tagging was performed with the TreeTagger
(Schmid, 1994). This software provides resources
for both of the considered languages and it is freely
available. TreeTagger is a Markovian tagger that
uses decision trees to estimate trigram transition
probabilities. The English version is trained on the
PENN treebank corpus3 and the Spanish version on
the CRATER corpus.4
Language models are built using the SRI-LM
toolkit (Stolcke, 2002). Modified Knesser-Ney dis-
counting was used for all models. In (Goodman,
2001), a systematic description and comparison of
the usual smoothing methods is reported. Modified
Knesser-Ney discounting appears to be the most ef-
ficient method.
4 Experiments and Results
Two baseline English-to-Spanish translation mod-
els were created with Moses. The first model was
trained on the whole parallel text ? note that sen-
tences with more than 100 words are excluded by
Giza++. The second model was trained on the cor-
pus using only sentences with at most 40 words. The
BLEU score on the development set using good gen-
eral purpose weights is 48.0 for the first model and
47.0 for the second. Because training on the whole
bi-text is much slower, we decided to perform our
experiments on the bi-texts restricted to the ?short?
sentences.
4.1 Language model generation
The reranking experiments presented below use the
following language models trained on the Spanish
part of the whole training corpus:
? word language models,
? POS language model,
? POS language model, with a stop list used to
remove the 100 most frequent words (POS-
stop100 LM),
? language model of enriched units.
3http://www.cis.upenn.edu/ treebank
4http://www.comp.lancs.ac.uk/linguistics/crater/corpus.html
68
English : you will be aware President that over the last few sessions in Strasbourg. ..
Baseline: usted sabe que el Presidente durante los u?ltimos sesiones en Estrasburgo ...
Enriched units: usted sabe que el Presidente en los u?ltimos per??odos de sesiones en Estrasburgo ...
English : ... in this house there might be some recognition ...
Baseline: ... en esta asamblea no puede ser un cierto reconocimiento ...
Enriched units: ... en esta asamblea existe un cierto reconocimiento ...
Figure 3: Comparative translations using the baseline word system and the enriched unit system.
For each of these four models, various orders
were tested (n = 3, 4, 5), but in this paper we only
report those orders that yielded the greatest improve-
ments. POS language models were obtained by first
extracting POS sequences from the previously POS-
tagged training corpus and then by estimating stan-
dard back-off language models.
As shown in Table 1, the vocabulary size of the
word language model is 104k for Spanish and 74k
for English. The number of POS is small: 69 for
Spanish and 59 for English. We emphasize that
the tagset provided by TreeTagger does include nei-
ther gender nor number distinction. The vocabulary
size of the enriched-unit language model is 115k for
Spanish and 77.6k for English. The syntactical am-
biguity of words is low: the mean ambiguity ratio is
1.14 for Spanish and 1.12 for English.
4.2 Reranking the word n-best lists
The results concerning reranking experiments of the
n-best lists provided by the translation model based
on words as units are summarized in Table 2. The
baseline result, with trigram word LM reranking,
gives a BLEU score of 47.0 (1rst row). From the
n-best lists provided by this translation model, we
compared reranking performances with different tar-
get language models. As observed in the literature,
an improvement can be obtained by reranking with
a 4-gram word language model (47.0 ? 47.5, 2d
row). By post-tagging this n-best list, a POS lan-
guage model reranking can be performed. However,
reranking with a 5-gram POS language model alone
does not give any improvement from the baseline
(BLEU score of 46.9, 3rd row). This result corre-
sponds to known work in the literature (Kirchhoff
and Yang, 2005; Hasan et al, 2006), when using
POS only as a post-processing step during rerank-
ing. As suggested in section 2.3, this lack of per-
formance can be due to the fact that the tagger is
not able to provide a usefull tagging of sentences
included in the n-best lists. This observation is
also available when reranking of the word n-best is
done with a language model based on enriched units
(BLEU score of 47.6, not reported in Table 2).
4.3 POS disambiguation and reranking
The results concerning reranking experiments of the
n-best lists provided by the translation model based
on enriched units are summarized in Table 3. Us-
ing a trigram language model of enriched transla-
tion units leads to a BLEU score of 47.4, a 0.4 in-
crease over the baseline presented in section 4.2.
Figure 3 shows comparative translation examples
from the baseline and the enriched translation sys-
tems. In the first example, the baseline system out-
puts ?durante los u?ltimos sesiones? where the en-
riched translation system produces ?en los u?ltimos
per??odos de sesiones?, a better translation that may
be attributed to the introduction of the masculine
word ?per??odos?, allowing the system to build a
syntactically correct sentence. In the second exam-
ple, the syntactical error ?no puede ser un cierto re-
conocimiento? produced by the baseline system in-
duces an incorrect meaning of the sentence, whereas
the enriched translation system hypothesis ?existe un
cierto reconocimiento? is both syntactically and se-
mantically correct.
Reranking the enriched n-best with POS language
models (either with or without a stop list) does not
seem to be efficient (0.3 BLEU increasing with the
POS-stop100 language model).
A better improvement is obtained when reranking
is performed with the 4-gram word language model.
This results in a BLEU score of 47.9, correspond-
ing to a 0.9 improvement over the word baseline. It
is interesting to observe that reranking a n-best list
69
Dev. Test
3g word LM baseline 47.0 46.0
4g word LM reranking 47.5 46.5
5g POS reranking 46.9 46.1
Table 2: BLEU scores using words as translation
units.
obtained with a translation model based on enriched
units with a word LM results in better performances
than a enriched units LM reranking of a n-best list
obtained with a translation model based on words.
The last two rows of Table 3 give results when
combining word and POS language models to rerank
the enriched n-best lists. In both cases, 10 features
are used for reranking (8 Moses features + word
language model probability + POS language model
probability). The best result is obtained by com-
bining the 5-gram word language model with the 5-
gram POS-stop100 language model. In that case,
the best BLEU score is observed (48.1), with a 2.3%
relative increase over the trigram word baseline.
4.4 Results on the test set
The results on the test set are given in the second
column of Tables 2 and 3. Although the enriched
translation system is only 0.1 BLEU over the base-
line system (46.0 ? 46.1) when using a trigram lan-
guage model, the best condition observed on the de-
velopment set (word and POS-stop100 LMs rerank-
ing) results in a 46.8 BLEU score, corresponding to
a 0.8 increasing.
It can be observed that rescoring with a 4-gram
word language model leads to same score resulting
in a 1.9% relative increase over the trigram word
baseline.
5 Conclusion and future work
Combining word language model reranking of n-
best lists based on syntactically enriched units seems
to produce more consistent hypotheses. Using en-
riched translation units results in a relative 2.3%
improvement in BLEU on the development set and
1.9% on the test over the trigram baseline. Over a
standard translation model with 4-gram rescoring,
the enriched unit translation model leads to an abso-
lute increase in BLEU score of 0.4 both on the devel-
opment and the test sets. These first results are en-
Dev. Test
3g enriched units LM baseline 47.4 46.1
4g enriched units LM reranking 47.8 46.8
4g word LM reranking 47.9 46.9
5g POS LM reranking 47.5 46.2
5g POS-stop100 LM reranking 47.7 46.3
word + POS LMs reranking 47.9 46.9
word + POS-stop100 LMs rerank. 48.1 46.8
Table 3: BLEU scores using enriched translation
units.
couraging enough to further investigate the integra-
tion of syntactic information in the translation model
itself, rather than to restrict it to the post-processing
pass. As follow-up experiments, it is planned to in-
clude gender and number information in the tagset,
as well as the word stems to the enriched units.
This work should be considered as preliminary
experiments for the investigation of factored trans-
lation models, which Moses is able to handle. POS
factorization is indeed a way to add some general-
ization capability to the enriched translation models.
6 Acknowledgments
This work has been partially funded by the European
Union under the integrated project TC-STAR (IST-
2002-FP6-506738), and by the French Government
under the project INSTAR (ANR JCJC06 143038).
We would like to thanks Marc Ferras for his help
concerning the Spanish language.
References
Frank Vanden Berghen and Hugues Bersini. 2005. CON-
DOR, a new parallel, constrained extension of powell?s
UOBYQA algorithm: Experimental results and com-
parison with the DFO algorithm. Journal of Computa-
tional and Applied Mathematics, 181:157?175.
Peter F Brown, Stephen A Della Pietra, Vincent J Della
Pietra, and Robert L Mercer. 1993. The mathematics
of statistical machine translation: Parameter estima-
tion. Computational Linguistics, 19(2):263?311.
E. Charniak, K. Knight, and K. Yamada. 2003. Syntax-
based language models for machine translation. In
Proceedings of MT Summit IX.
C. Gollan, M. Bisani, S. Kanthak, R. Schlueter, and ?H.
Ney. 2005. Cross domain automatic transcription on
70
the TC-STAR epps corpus. In Proceedings of ICASSP
2005.
Joshua T. Goodman. 2001. A bit of progress in lan-
guage modeling. Computer Speech and Language,
15(4):403?434, October.
S. Hasan, O. Bender, and H. Ney. 2006. Reranking trans-
lation hypothesis using structural properties. In Pro-
ceedings of EACL 2006.
Y.S. Hwang, A. Finch, and Y. Sasaki. 2007. Improving
statistical machine translation using shallow linguistic
knoledge. to be published in Computer, Speech and
Language.
Katrin Kirchhoff and Mei Yang. 2005. Improved lan-
guage modeling for statistical machine translation. In
Proceedings of ACL ?05 workshop on Building and Us-
ing Parallel Text, pages 125?128.
Philipp Koehn, Franz Josef Och, and Daniel Marcu.
2003. Statistical phrase-based translation. In Proceed-
ings of the Human Language Technology Conference
2003 (HLT-NAACL 2003), Edmonton, Canada, May.
Franz Josef Och and Hermann Ney. 2000a. Improved
statistical alignment models. In Proc. of the 38th An-
nual Meeting of the Association for Computational
Linguistics, pages 440?447, Hongkong, China, Octo-
ber.
Franz Josef Och and Hermann Ney. 2000b. Improved
statistical alignment models. In Proceedings of the
38th Annual Meeting of the Association for Computa-
tional Linguistics, pages 440?447, Hong Kong, China,
October.
Franz Josef Och and Hermann Ney. 2002. Discrimina-
tive training and maximum entropy models for statisti-
cal machine translation. In Proceedings of ACL 2002,
pages 295?302.
F.-J. Och, D. Gildea, S. Khudanpur, A. Sarkar, K. Ya-
mada, A. Fraser, S. Kumar, L. Shen, D. Smith, K. Eng,
V. Jain, Z. Jin, and D. Radev. 2004. A smorgasbord of
features for statistical machine translation. In NAACL,
pages 161?168.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. Bleu: a method for automatic evalua-
tion of machine translation. In Proceedings of the 40th
Annual Meeting of the Association for Computational
Linguistics, pages 311?318, University of Pennsylva-
nia.
Helmut Schmid. 1994. Probabilistic part-of-speech tag-
ging using decision trees. In Proceedings of Interna-
tional Conference on New Methods in Language Pro-
cessing, September.
Andreas Stolcke. 2002. SRILM - an extensible language
modeling toolkit. In Proceedings of ICSLP, pages II:
901?904.
71
