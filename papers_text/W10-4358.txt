Proceedings of SIGDIAL 2010: the 11th Annual Meeting of the Special Interest Group on Discourse and Dialogue, pages 314?321,
The University of Tokyo, September 24-25, 2010. c?2010 Association for Computational Linguistics
User-adaptive Coordination of Agent Communicative Behavior
in Spoken Dialogue
Kohji Dohsaka
NTT Communication Science Laboratories
NTT Corporation
2-4, Hikaridai, Seika-cho,
Kyoto 619-0237, Japan
Atsushi Kanemoto
Graduate School of
Information Science and Technology
Osaka University, 1-1, Yamadaoka,
Suita, Osaka 565-0871, Japan
Ryuichiro Higashinaka
NTT Cyber Space Laboratories
NTT Corporation
1-1, Hikarinooka, Yokosuka,
Kanagawa 239-0847, Japan
Yasuhiro Minami and Eisaku Maeda
NTT Communication Science Laboratories
NTT Corporation
2-4, Hikaridai, Seika-cho,
Kyoto 619-0237, Japan
{dohsaka,minami,maeda}@cslab.kecl.ntt.co.jp
higashinaka.ryuichiro@lab.ntt.co.jp
Abstract
In this paper, which addresses smooth spo-
ken interaction between human users and
conversational agents, we present an ex-
perimental study that evaluates a method
for user-adaptive coordination of agent
communicative behavior. Our method
adapts the pause duration preceding agent
utterances and the agent gaze duration to
reduce the discomfort perceived by indi-
vidual users during interaction. The exper-
imental results showed a statistically sig-
nificant tendency: the duration of the agent
pause and the gaze converged during inter-
action with the method. The method also
significantly improved the perceived rele-
vance of the agent communicative behav-
ior.
1 Introduction
Conversational agents have been studied as an ef-
fective human-computer interface for such pur-
poses as training decision-making in team ac-
tivities (Traum and Rickel, 2002), learning sup-
port (Johnson et al, 2002), museum guides (Kopp
et al, 2005), and community facilitators (Zheng
et al, 2005; Fujie et al, 2009). They will play
a crucial role in establishing a society where hu-
mans and robots collaborate through natural in-
teraction. However, agents cannot produce their
intended effects when the smooth flow of interac-
tion is disturbed. To fully exploit the promise of
agents, we need to achieve smooth interaction be-
tween human users and agents.
Although various types of modalities have been
used in human-computer interfaces, speech has
drawn a great deal of interest because it is one of
the most pervasive communication methods in our
daily lives and we usually perform it without any
special effort (Nass and Brave, 2005). In this pa-
per, we are interested in smooth spoken dialogues
between users and agents.
A spoken dialogue is a joint activity among
participants (Clark, 1996). For such a joint ac-
tivity to be smooth and successful, participants
need to coordinate their communicative behav-
iors in various ways. In human dialogues, par-
ticipants agree on lexical choices to refer to ob-
jects (Brennan and Clark, 1996) and coordinate
eye gaze (Richardson and Dale, 2005) and whose
turn it is to speak (Sacks et al, 1974). They
become more similar to their partners as the di-
alogue proceeds in many aspects such as pitch,
speech rate, and pause structure (Burgoon et al,
1995; Hayashi et al, 2009). Such coordination
serves to make conversation flow easily and intel-
ligibly (Garrod and Pickering, 2004).
The coordination of communicative behaviors
also plays a crucial role in smooth human-agent
interaction. Previous work addressed human be-
havior adaptation to agents (Oviatt et al, 2004),
agent behavior adaptation to human partners (Mit-
sunaga et al, 2005; Tapus and Mataric?, 2007), and
the mutual adaptation of human and agent behav-
ior (Breazeal, 2003).
In this paper, which addresses smooth spoken
interaction between human users and agents, we
focus on the adaptation of agent communicative
behavior to individual users in spoken dialogues
314
with flexible turn-taking. We present a method
for user-adaptive coordination of agent commu-
nicative behavior to reduce the discomfort per-
ceived by individual users during the interaction
and show experimental results that evaluate how
the method influences agent communicative be-
havior and improves its relevance as perceived by
users. For evaluation purposes, we used a quiz-
style multi-party spoken dialogue system (Minami
et al, 2007; Dohsaka et al, 2009). A quiz-style
dialogue is a kind of thought-evoking dialogue
that can stir user thinking and activate communi-
cation (Higashinaka et al, 2007a; Dohsaka et al,
2009). This characteristic is expected to be ad-
vantageous for evaluation experiments since it en-
courages involvement in the dialogue.
Our method adapts agent communicative be-
havior based on policy gradient reinforcement
learning (Sutton et al, 2000; Kohl and Stone,
2004). The policy gradient method has been
used for robot communicative behavior adapta-
tion (Mitsunaga et al, 2005; Tapus and Mataric?,
2007). However, both studies dealt with scenario-
based interaction in which a user and a robot acted
with predetermined timing. In contrast, we focus
on spoken dialogues in which users and agents can
speak with more flexible timing. In addition, we
allow for two- and three-party interactions among
a user and two agents. It remains unclear whether
the policy gradient method can successfully adapt
agent communicative behavior to a user in two-
or three-party spoken dialogues with flexible turn-
taking. Although this paper focuses on agent be-
havior adaptation to human users, we believe that
our investigation of the agent behavior adaptation
mechanism in flexible spoken interaction will con-
tribute to conversational interfaces where human
users and agents can mutually adapt their commu-
nicative behaviors.
As agent communicative behavior to be
adapted, this paper focuses on the pause duration
preceding agent utterances and the agent gaze du-
ration. In conversation, the participant pause du-
ration is influenced by partners, and the coordina-
tion of pause structure leads to smooth communi-
cation (Burgoon et al, 1995; Hayashi et al, 2009).
Without pause structure coordination, undesired
speech overlaps or utterance collisions are likely
to occur between users and agents, which may dis-
turb smooth communication. Funakoshi et al pro-
posed a method to prevent undesired speech over-
laps in human-robot speech interactions by using
a robot?s subtle expressions produced by a blink-
ing LED attached to its chest (Funakoshi et al,
2008). In their method, a blinking light notifies
users about such internal states of the robot as pro-
cessing or busy and helps users identify the robot
pause structures; however we are concerned with
the adaptation of robot pause structures to users.
Gaze coordination is causally related to the
success of communication (Richardson and Dale,
2005), and the amount of gaze influences conver-
sational turn-taking (Vertegaal and Ding, 2002).
The relevant control of agent gaze duration is
thus essential to the smooth flow of conversation.
Moreover, since the amount of gaze is related to
specific interpersonal attitudes among participants
and is also subject to such individual differences as
personalities (Argyle and Cook, 1976), agent gaze
duration must be adapted to individual users.
In the following, Section 2 describes our quiz-
style multi-party spoken dialogue system. Sec-
tion 3 shows our method for the user-adaptive co-
ordination of agent communicative behavior. Sec-
tion 4 explains the experiment, and Section 5 de-
scribes its results. Section 6 concludes our paper.
2 Quiz-Style Spoken Dialogue System
To evaluate a method for agent communicative
behavior adaptation, we used a quiz-style multi-
party spoken dialogue system based on a quiz-
style two-party spoken dialogue system (Minami
et al, 2007) and extended it to performmulti-party
interaction (Dohsaka et al, 2009).
In this system, a human user and one or two
agents interact. The two agents include a quiz-
master and a peer. The quizmaster agent creates
a ?Who is this?? quiz about a famous person
and presents hints one by one to the user and the
peer agent, who participates in the interaction and
guesses the correct answer in the same way that
the user does.
The hints are automatically created from the
biographical facts of people in Wikipedia1 and
ranked based on the difficulty of solving the
quizzes experienced by users (Higashinaka et al,
2007b). Since users must consider the hints to of-
fer reasonable answers, the system can stimulate
their thinking and encourage them to engage in the
interaction (Higashinaka et al, 2007a). In addi-
tion, the peer agent?s presence and the agent?s em-
pathic expressions improve user satisfaction and
1http://ja.wikipedia.org/
315
Figure 1: User interacting with two agents using
the quiz-style spoken dialogue system
increase user utterances (Dohsaka et al, 2009).
Figure 1 shows a human user interacting with
the two agents, both of whom are physically em-
bodied robots. The system utilizes an extremely
large vocabulary with continuous speech recogni-
tion (Hori et al, 2007). Agent utterances are pro-
duced by speech synthesis. The agents can gaze at
other participants by directing their faces to them.
At each point of the dialogue, the system chooses
the next speaker and its utterance based on the
dialogue state that the system maintains, the pre-
conditions of the individual utterances, and a few
turn-taking rules (Dohsaka et al, 2009). The agent
pause and gaze durations are controlled based on
the adaptation method described in Section 3.
A sample dialogue among a user and two agents
is depicted in Figure 2. Master is the quizmaster
agent, and Peer is the peer agent. The agent ut-
terances are classified as either spontaneous or re-
sponsive. Spontaneous utterances are those made
after an agent takes his turn in an unforced man-
ner, and responsive utterances are responses to the
other?s utterances. In the sample dialogue, spon
identifies spontaneous and res identifies respon-
sive utterances.
Quizmaster agent Master makes spontaneous
utterances such as presenting hints (lines 1 and 5),
indicating the quiz difficulty, and addressing lis-
teners. It also makes such responsive utterances
as evaluating the other?s answers (lines 3, 9, and
11). Peer agent Peer makes such spontaneous ut-
terances as showing its own difficulty (line 4), giv-
ing an answer (line 8), giving feedback when its
own or the other?s answer is right (line 12), and
addressing listeners. It also makes such responsive
utterances as showing empathy to the user (line 7).
3 Method for Agent Communicative
Behavior Adaptation
We apply policy gradient reinforcement learn-
ing (Sutton et al, 2000; Kohl and Stone, 2004)
1 Master Who is this? First hint. He gradu-
ated from the University of Tokyo.
(hint/spon)
2 User Yoshida Shigeru? (answer/spon)
3 Master No, not even close! He?s not a
politician. (evaluation/res)
4 Peer I don?t know. Very difficult.
(show difficulty/spon)
5 Master It?s time for the second hint: He?s
a novelist and a scholar of British
literature. (hint/spon)
6 User Oh, I think I know it but I can?t re-
member his name. That?s so frus-
trating. (show difficulty/spon)
7 Peer Difficult for me, too.
(show empathy/res)
8 Peer Haruki Murakami? (answer/spon)
9 Master Close! You are half right, because
he is a novelist. (evaluation/res)
10 User Natsume Soseki? (answer/spon)
11 Master That?s right. Wonderful.
(evaluation/res)
12 Peer Good job. (feedback/spon)
Figure 2: Sample dialogue between user and two
agents: quizmaster Master and peer Peer. Spon
identifies spontaneous and res identifies respon-
sive utterances.
to the user-adaptive coordination of agent com-
municative behavior. A policy gradient method
is a reinforcement learning (RL) approach that di-
rectly optimizes a parameterized policy by gradi-
ent ascent based on the gradient of the expected
reward with respect to the policy parameters. Al-
though RL methods have recently been applied to
optimizing dialogue management in spoken dia-
logue systems (Williams and Young, 2007; Mi-
nami et al, 2009), these previous studies utilized
RL methods based on the value-function estima-
tion. The policy gradient method is an alterna-
tive approach to RL that has the following mer-
its. It can handle continuous and large action
spaces (Kimura and Kobayashi, 1998) and is usu-
ally assured to converge to a locally optimal pol-
icy in such action spaces (Sutton et al, 2000).
Moreover, it does not need to explicitly estimate
the value function, and it is incremental, requiring
only a constant amount of computation per learn-
ing step (Kimura and Kobayashi, 1998).
Due to these advantages, the policy gradient
method is suitable for adapting agent communica-
tive behavior to a user during interaction, because
316
(1) ? = [?j ]? initial policy (policy parameter
vector of size n)
(2) ? = [?j ]? step size vector of size n
(3) ? ? overall scalar step size
(4) maxA? 0 (greatest absolute value of
reward ever observed in adaptation process)
(5) while dialogue continues
(6) for i = 1 to T
(7) for j = 1 to n
(8) rj ? random choice from {?1, 0, 1}
(9) Rij ? ?j + ?j ? rj
(Ri is T random perturbations of?)
(10) for i = 1 to T
(11) Perform a hint dialogue based on
policyRi, and evaluate reward
(12) for j = 1 to n
(13) Avg+?,j ? average reward for all Ri
with positive perturbation in parameter ?j
(14) Avg0,j ? average reward for all Ri
with zero perturbation in parameter ?j
(15) Avg??,j ? average reward for all Ri
with negative perturbation in parameter ?j
(16) if (Avg0,j > Avg+?,j and
Avg0,j > Avg??,j)
(17) aj ? 0
(18) else
(19) aj ? Avg+?,j ?Avg??,j
(20) ?j(aj ? aj|A| ? ?j ? ?)
(21) maxC ? maximum of absolute value of
reward in current adaptation cycle
(22) if (maxC > maxA)
(23) maxA? maxC (update maxA)
(24) else
(25) A? A ? maxCmaxA
(26) ?? ?+A
Figure 3: Pseudocode for user-adaptive coordina-
tion of agent communicative behavior
it can naturally incorporate such continuous pa-
rameters as pause and gaze duration and incremen-
tally adapt agent behavior. In fact, the policy gra-
dient method has been successfully used for robot
behavior adaptation (Mitsunaga et al, 2005; Tapus
and Mataric?, 2007). In this paper, we apply this
method to agent communicative behavior adapta-
tion in spoken dialogues with flexible turn-taking.
Figure 3 shows our method for the user-adaptive
coordination of agent communicative behavior.
This method is a modification of an algorithm pre-
sented by Kohl and Stone (2004) in that the gra-
dient is adjusted based on the maximum absolute
value of the reward obtained during each adapta-
tion cycle.
The agent communicative behaviors are deter-
mined based on a policy that is represented as vec-
tor?(= [?j ]) of n policy parameters. In the quiz-
style dialogues, the behavior of both the quizmas-
ter and peer agents is controlled based on the same
policy parameters. The method adapts the behav-
ior of both agents to individual users by adapting
the policy parameters. In this experiment, we used
the following four parameters (n = 4):
? pre-spontaneous-utterance pause duration
?spon: duration of pauses preceding agent
spontaneous utterances
? pre-responsive-utterance pause duration
?res: duration of pauses preceding agent
responsive utterances
? gaze duration ?gaze: duration of agent?s di-
recting its face to the other while it is speak-
ing or listening
? hint interval ?hint: interval of presenting quiz
hints
As shown above, we used two types of pause
duration since the relevant pause duration can be
dependent on dialogue acts (Itoh et al, 2009). Al-
though our main concern is the pause and gaze du-
ration, we examined the hint interval as a parame-
ter particular to quiz-style dialogues.
To adapt the policy parameters to individual
users, we first generate T random perturbations
[R1, . . . ,RT ] of current policy ? by randomly
adding ?j , 0,??j to each parameter ?j of ? in
lines 6 to 9, where ?j is a step size set for each
parameter. In the experiment, we set T to 10. The
step sizes of the parameters used in the experiment
will be shown later in Table 1.
Dialogue per hint (a hint dialogue) is then per-
formed based on each perturbation policyRi, and
the reward for each hint dialogue is obtained in
lines 10 to 11. All agent behaviors in a hint di-
alogue are determined based on the same pertur-
bation policy. As we will explain in Section 4, in
the experiment, we regarded the magnitude of dis-
comfort perceived by users during a hint dialogue
as a negative reward. Users signified discomfort
by pressing buttons on the controller held in their
hands. After performing hint dialogues for all T
perturbationsRi, gradientA(= [aj ]) is computed
in lines 12 to 19. The gradient is normalized by
317
Parameters ?spon
(sec.)
?res
(sec.)
?gaze
(sec.)
?hint
(sec.)
Initial value 4.96 0.53 3.04 27.7
Step size 0.50 0.20 0.30 2.5
Table 1: Initial values and step sizes of policy pa-
rameters: ?spon (pre-spontaneous-utterance pause
duration), ?res (pre-responsive-utterance pause
duration), ?gaze (gaze duration), and ?hint (hint
interval)
overall scalar step size ? and individual step size
?j for each parameter in line 20. Overall scalar
step size ? is used to adjust the adaptation speed,
which we set to 1.0.
Next we get the maximum maxC of the abso-
lute value of the reward in the current adaptation
cycle. As in lines 21 to 25, the gradient is ad-
justed based on the ratio of maxC to the greatest
absolute value maxA of reward ever observed in
the overall adaptation process. Finally, the current
policy parameters are updated using the gradient
in line 26.
This is an adaptation cycle. By iterating it, the
agent communicative behavior is adapted to re-
duce the discomfort perceived by each user.
4 Experiment
We recruited and paid 32 Japanese adults (16
males and 16 females) for their participation. The
mean ages of the male and female groups were
33.2 and 36.8, respectively. They were divided
into two groups: two-party dialogues (user and
quizmaster) and three-party dialogues (user, quiz-
master, and peer). In each group, the numbers of
males and females were identical.
For this experiment, we used a quiz-style spo-
ken dialogue system. We chose the quiz sub-
jects in advance and divided them into sets of five
so that the difficulty level was approximately the
same in all sets. For this purpose, we made sev-
eral sets of five people of approximately identical
PageRank TM scores based on Wikipedia?s hyper-
link structure.
The users first rehearsed the dialogues for a set
of five quizzes to familiarize themselves with the
system. After practicing, they performed the dia-
logues to evaluate the adaptation method and took
a break per five-quiz set. The presentation order
of the quiz sets was permutated to prevent order
effect. For each user, the dialogues continued un-
til the user received 150 hints. The adaptation
method was applied during the interaction, and the
policy parameters were updated per 10 hint dia-
logues. As a result, the parameters were updated
15 times through the dialogues. It took about two
hours for each user to complete all dialogues.
The policy parameters were updated based on
the magnitude of discomfort perceived by users.
In this experiment, users were told to concentrate
on the discomfort caused by agent pause and gaze
duration and signified it by pressing buttons on
the controller held in their hands at three levels of
magnitude: ?3?, ?2?, and ?1?. The sum of discom-
fort obtained during a hint dialogue was normal-
ized with respect to the hint dialogue length, and
the normalized values were regarded as negative
rewards. Ideally we should estimate user discom-
fort from such user behaviors as pause structure
and eye gaze. However, as the first step toward that
goal, in this experiment we adopted this setting in
which users directly signified their discomfort by
pressing buttons.
Table 1 shows the initial values and the step
sizes of the policy parameters used in the exper-
iment. To obtain the relevant initial values, we
conducted a preparatory experiment in which ten
other participants performed quiz-style dialogues
under the same conditions as this experiment. The
initial values in this experiment were set to the
averaged final values of the policy parameters in
the preparatory experiment. The step sizes were
determined as approximately one-tenth of the ini-
tial values except for the pre-responsive-utterance
pause, for which the step size was set to 200 msec
based on the limits of human perception.
Before and after the adaptation, the users filled
out the following questionnaire items (7-point Lik-
ert scale) to evaluate the relevance of agent pause
and gaze duration:
? Did you feel that the pause duration preced-
ing the agent utterances was relevant?
? Did you feel that the agent gaze duration was
relevant while the agents were speaking or
listening to you?
5 Results
5.1 Convergence of policy parameters
The policy parameters were updated based on the
adaptation method during the user-agent interac-
tion. Figure 4 exemplifies how the policy param-
eter values changed during the adaptation cycles
with a user engaged in the two-party dialogue.
318
33.5
44.5
55.5
0 2 4 6 8 10 12 14(a) Pre-spontaneous-utt.  pause duration (sec.)
22.5
33.5
4
0 2 4 6 8 10 12 14(c) Gazeduration (sec.)
0.450.5
0.550.6
0.65
0 2 4 6 8 10 12 14
2022
2426
2830
0 2 4 6 8 10 12 14
(b) Pre-responsive-utt.  pause duration (sec.)
(d) Hint interval (sec.)
Figure 4: Change of policy parameter values dur-
ing adaptation cycles with a user engaged in two-
party dialogue. Horizontal axis shows adaptation
cycles and vertical axis shows parameter values.
0
0.04
0.08
0.12 First-phase RAC Last-phase RAC
Two-party dialogue
p=0.029 *
p=0.0071 **
p=0.041 * N.S.
?spon ?res ?gaze ?hint
0
0.04
0.08
0.12
First-phase RAC Last-phase RAC
Three-party dialogue
p=0.038 *
p<0.001 ***
p=0.016 *
?spon ?res ?gaze ?hint
p=0.011 *
Figure 5: For each policy parameter, average and
standard error of first- and last-phase RACs (rela-
tive amount of change in parameter values)
Table 2 shows the statistics of the final values
of the policy parameters at the end of the adapta-
tion process. Since the initial values were appro-
priately determined based on the preparatory ex-
periment, the final value averages were not greatly
different from the initial values. However, judging
from the maximum, minimum, and standard devi-
ations, the final values reflected individual users.
If the adaptation method works successfully, the
policy parameter values should converge during
the user-agent interaction. From this viewpoint,
we examined the relative amount of change in the
policy parameters (RAC). Given parameter value
pk?1 at (k ? 1)-th adaptation cycle and param-
eter value pk at k-th cycle, RAC is defined as
Two-party dialogues
Parameters ?spon
(sec.)
?res
(sec.)
?gaze
(sec.)
?hint
(sec.)
Average 5.04 0.62 3.10 25.8
Min 3.90 0.39 2.40 19.5
Max 6.17 1.18 3.69 31.2
Sd. 0.72 0.21 0.36 2.7
Three-party dialogues
Parameters ?spon
(sec.)
?res
(sec.)
?gaze
(sec.)
?hint
(sec.)
Average 4.86 0.62 3.15 27.4
Min 4.07 0.35 2.52 22.0
Max 5.54 0.90 3.58 32.7
Sd. 0.44 0.18 0.27 2.5
Table 2: Statistics of final values of policy param-
eters: ?spon (pre-spontaneous-utterance pause du-
ration), ?res (pre-responsive-utterance pause dura-
tion), ?gaze (gaze duration), and ?hint (hint inter-
val)
|pk?pk?1|
pk?1 .
For each policy parameter, we compared the
RAC averages in the first and in the last three adap-
tation cycles: the first-phase RAC and the last-
phase RAC. As shown in Figure 5, the last-phase
RAC tends to be smaller than the first-phase RAC.
The Kolmogorov-Smirnov test showed that the as-
sumption of normality (p > 0.2) was met for each
group. By applying the paired Welch?s t-test, as
shown in Figure 5, we found that the last-phase
RAC is significantly smaller than the first-phase
RAC except for the hint interval in the two-party
dialogues. This shows that the agent pause and
gaze duration converged during the interaction in
both the two- and three-party dialogues.
The hint interval is unlikely to converge, prob-
ably because it is a longer period than the pause
and gaze duration and is subject to various factors.
Moreover, it greatly depends on user interest.
5.2 User evaluations
Figure 6 shows the subjective user evaluations of
the relevance of agent pause and gaze duration be-
fore and after the adaptation. Each user evaluation
was measured by a Likert question. The rating of
a single Likert question is an ordinal measure, and
we generally cannot apply a parametric statistical
test to an ordinal measure. Therefore we used a
nonparametric test, the Wilcoxon signed-rank test,
to compare user evaluations before and after the
319
12
34
56
7
Pause Gaze Pause Gaze
Before Adaptation After Adaptation
Two-party dialogue Three-party dialogue
p=0.014 * p=0.0051 ** p=0.015 * p=0.021 *
Figure 6: Average and standard error of user eval-
uations of relevance of agent pause and gaze dura-
tion before and after adaptation
adaptation. The F-test for the homogeneity of vari-
ances (p > 0.1) showed that the data satisfied the
statistical test assumption.
We found that in both the two- and three-party
dialogues, the relevance of the agent pause and
gaze duration significantly improved during the
two-hour adaptation process (p < 0.01 for gaze
duration in the two-party dialogues, p < 0.05 for
other cases). The p-values are shown in Figure 6.
No significant differences between gender were
found.
These results on the convergence of policy
parameters and user evaluations show that the
policy-gradient-based method can adapt agent
communicative behavior to individual users in
spoken dialogues with flexible turn-taking.
6 Conclusion
In this paper, addressing smooth spoken inter-
action between human users and conversational
agents, we presented a method for user-adaptive
coordination of agent communicative behavior
and experimentally evaluated how it can adapt
agent behavior to individual users in spoken dia-
logues with flexible turn-taking. The method co-
ordinates agent pause and gaze duration based on
policy gradient reinforcement learning to reduce
the discomfort perceived by individual users dur-
ing interaction. We experimentally evaluated the
method in a setting where the users performed
two- and three-party quiz-style dialogues and sig-
nified their discomfort by pressing buttons held in
their hands. Our experimental results showed a
statistically significant tendency: the agent pause
and gaze duration converged during interaction
with the method in both two- or three-party dia-
logues. The method also significantly improved
the perceived relevance of the agent communica-
tive behavior in both two- and three-party di-
alogues. These results indicate that in spoken
dialogues with flexible turn-taking, the policy-
gradient-based method can adapt agent commu-
nicative behavior to individual users.
Many directions for future work remain. First,
we will analyze how users adapt their communica-
tive behaviors with our method. Second, we need
to automatically estimate user discomfort or sat-
isfaction based on such user behaviors as pause
structure, prosody, eye gaze, and body posture.
Third, we will extend the adaptation method to
regulate agent behavior based on dialogue states,
since one limitation of the current method is its
inability to recognize them. Fourth, we are inter-
ested in the adaptation of additional higher-level
actions like the relevant choice of dialogue topics
based on the level of user interest.
Acknowledgments
This work was partially supported by a Grant-in-
Aid for Scientific Research on Innovative Areas,
?Founding a creative society via collaboration be-
tween humans and robots? (21118004), from the
Ministry of Education, Culture, Sports, Science
and Technology (MEXT), Japan.
References
Michael Argyle and Mark Cook. 1976. Gaze and Mu-
tual Gaze. Cambridge University Press.
Cynthia Breazeal. 2003. Regulation and entrainment
for human-robot interaction. International Journal
of Experimental Robotics, 21(10-11):883?902.
Susan E. Brennan and Herbert H. Clark. 1996. Con-
ceptual pacts and lexical choice in conversation.
Journal of Experimental Psychology: Learning,
Memory, and Cognition, 22:1482?1493.
Judee K. Burgoon, Lesa A. Stern, and Leesa Dillman.
1995. Interpersonal Adaptation: Dyadic Interaction
Patterns. Cambridge University Press.
Herbert H. Clark. 1996. Using Language. Cambridge
University Press.
Kohji Dohsaka, Ryota Asai, Ryuichiro Higashinaka,
Yasuhiro Minami, and Eisaku Maeda. 2009. Effects
of conversational agents on human communication
in thought-evoking multi-party dialogues. In Proc.
of SIGDIAL 2009, pages 217?224.
Shinya Fujie, Yoichi Matsuyama, Hikaru Taniyama,
and Tetsunori Kobayashi. 2009. Conversation robot
participating in and activating a group communica-
tion. In Proc. of Interspeech 2009, pages 264?267.
320
Kotaro Funakoshi, Kazuki Kobayashi, Mikio Nakano,
Seiji Yamada, Yasuhiko Kitamura, and Hiroshi Tsu-
jino. 2008. Smoothing human-robot speech interac-
tions by using a blinking-light as subtle expression.
In Proc. of ICMI 2008, pages 293?296.
Simon Garrod and Martin J. Pickering. 2004. Why is
conversation so easy? Trends in Cognitive Sciences,
8:8?11.
Takanori Hayashi, Shohei Kato, and Hidenori Itoh.
2009. A synchronous model of mental rhythm using
paralanguage for communication robots. In Lecture
Notes in Computer Science (PRIMA 2009), volume
5925, pages 376?388.
Ryuichiro Higashinaka, Kohji Dohsaka, Shigeaki
Amano, and Hideki Isozaki. 2007a. Effects of quiz-
style information presentation on user understand-
ing. In Proc. of Interspeech 2007, pages 2725?2728.
Ryuichiro Higashinaka, Kohji Dohsaka, and Hideki
Isozaki. 2007b. Learning to rank definitions to gen-
erate quizzes for interactive information presenta-
tion. In Proc. of ACL 2007 (Poster Presentation),
pages 117?120.
Takaaki Hori, Chiori Hori, Yasuhiro Minami, and At-
sushi Nakamura. 2007. Efficient WFST-based one-
pass decoding with on-the-fly hypothesis rescoring
in extremely large vocabulary continuous speech
recognition. IEEE Transactions on Audio, Speech
and Language Processing, 15:1352?1365.
Toshihiko Itoh, Norihide Kitaoka, and Ryota
Nishimura. 2009. Subjective experiments on
influence of response timing in spoken dialogues.
In Proc. of Interspeech 2009, pages 1835?1838.
W. Lewis Johnson, Jeff W. Rickel, and James C. Lester.
2002. Animated pedagogical aqgents: face-to-face
interaction in interactive learning environments. In-
ternational Journal of Artificial Intelligence in Edu-
cation, 11:47?78.
Hajime Kimura and Shigenobu Kobayashi. 1998. Re-
inforcement learning for continuous action using
stochastic gradient ascent. In Proc. of the 5th Inter-
national Conference on Intelligent Autonomous Sys-
tems, pages 288?295.
Nate Kohl and Peter Stone. 2004. Policy gradient rein-
forcement learning for fast quadrupedal locomotion.
In Proc. of ICRA 2004, volume 3, pages 2619?2624.
Stefan Kopp, Lars Gesellensetter, Nicole C. Kra?mer,
and Ipke Wachsmuth. 2005. A conversational agent
as museum guide: design and evaluation of a real-
world application. In Lecture Notes in Computer
Science (IVA 2009), volume 3661, pages 329?343.
Yasuhiro Minami, Minako Sawaki, Kohji Dohsaka,
Ryuichiro Higashinaka, Kentaro Ishizuka, Hideki
Isozaki, Tatsushi Matsubayashi, Masato Miyoshi,
Atsushi Nakamura, Takanobu Oba, Hiroshi Sawada,
Takeshi Yamada, and Eisaku Maeda. 2007. The
World of Mushrooms: human-computer interaction
prototype systems for ambient intelligence. In Proc.
of ICMI 2007, pages 366?373.
Yasuhiro Minami, Akira Mori, Ryuichiro Higashinaka,
Kohji Dohsaka, and Eisaku Maeda. 2009. Dialogue
control algorithm for ambient intelligence based on
partially observable Markov decision processes. In
Proc. of IWSDS 2009.
Noriaki Mitsunaga, Christian Smith, Takayuki Kanda,
Hiroshi Isiguro, and Norihiro Hagita. 2005.
Human-robot interaction based on policy gradient
reinforcement learning. In Proc. of IROS 2005,
pages 1594?1601.
Clifford Nass and Scott Brave. 2005. Wired for
Speech: How Voice Activates and Advances the
Human-Computer Relationship. The MIT Press.
Sharon Oviatt, Courtney Darves, and Rachel Coulston.
2004. Toward adaptive conversational interfaces:
modeling speech convergence with animated per-
sonas. ACM Transactions on Computer-Human In-
teraction, 11(3):300?328.
Daniel C. Richardson and Rick Dale. 2005. Look-
ing to understand: the coupling between speakers?
and listeners? eye movements and its relationship
to discourse comprehension. Cognitive Science,
29:1045?1060.
Harvey Sacks, Emanuel A. Schegloff, and Gail Jeffer-
son. 1974. A simplest systematics for the orga-
nization of turn-taking in conversation. Language,
50:696?735.
Richard S. Sutton, David McAllester, Satinder Singh,
and Yishay Mansour. 2000. Policy gradient meth-
ods for reinforcement learning with function approx-
imation. In Advances in Neural Information Pro-
cessing Systems, volume 12, pages 1057?1063.
Adriana Tapus and Maja J. Mataric?. 2007. Hands-off
therapist robot behavior adaptation to user person-
ality for post-stroke rehabilitation therapy. In Proc.
of 2007 IEEE International Conference on Robotics
and Automation, pages 1547?1553.
David Traum and Jeff Rickel. 2002. Embodied agents
for multi-party dialogue in immersive virtual worlds.
In Proc. of AAMAS 2002, pages 766?773.
Roel Vertegaal and Yaping Ding. 2002. Explaining
effects of eye gaze on mediated group conversations:
amount or synchronization. In Proc. of CSCW 2002,
pages 41?48.
Jason D. Williams and Steve Young. 2007. Par-
tially observable Markov decision processes for spo-
ken dialog systems. Computer & Speech Language,
21(2):393?422.
Jun Zheng, Xiang Yuan, and Yam San Chee. 2005.
Designing multiparty interaction support in Elva, an
embodied tour guide. In Proc. of AAMAS 2005,
pages 929?936.
321
