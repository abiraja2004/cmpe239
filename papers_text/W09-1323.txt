Proceedings of the Workshop on BioNLP, pages 179?184,
Boulder, Colorado, June 2009. c?2009 Association for Computational Linguistics
Clustering semantic spaces of suicide notes and newsgroups articles
P. Matykiewicz1,2, W. Duch2, J. Pestian1
1Cincinnati Children?s Hospital Medical Center, University of Cincinnati,
2Nicolaus Copernicus University, Torun?, Poland.
Abstract
Historically, suicide risk assessment has re-
lied on question-and-answer type tools. These
tools, built on psychometric advances, are
widely used because of availability. Yet there
is no known tool based on biologic and cogni-
tive evidence. This absence often cause a vex-
ing clinical problem for clinicians who ques-
tion the value of the result as time passes. The
purpose of this paper is to describe one exper-
iment in a series of experiments to develop a
tool that combines Biological Markers (Bm)
with Thought Markers (Tm), and use machine
learning to compute a real-time index for as-
sessing the likelihood repeated suicide attempt
in the next six-months. For this study we fo-
cus using unsupervised machine learning to
distinguish between actual suicide notes and
newsgroups. This is important because it gives
us insight into how well these methods dis-
criminate between real notes and general con-
versation.
1 Introduction
It is estimated that each year 800,000 die by suicide
worldwide (World Health Organization, 2001). In
the United States, suicide ranks second as the lead-
ing cause of death among 25-34 year-olds and the
third leading cause of death among 15-25 year-olds
(Kung et al, 2008). The challenge for those who
care for suicide attempters, such as an Emergency
Medicine clinicians, is to assess the likelihood of an-
other attempt, a more lethal one. We believe to fully
asses this risk a tool must be developed that mea-
sures both the biological and cognitive state of the
patient. Such a tool will include Biological Mark-
ers (Bm): measured by the concentration of cer-
tain biochemical markers, Thought Markers (Tm):
measured by artifacts of thought that have been re-
duced to writing or transcribe speech, and Clini-
cal Markers (Cm): measured by traditional clinical
risk factors. In this study we focus on the Tm be-
cause of BioNLP?s important role. Here, we employ
machine-learning analysis to examine suicide notes
and how these notes compare to newsgroups. This
is one experiment in a series of experiments that are
intended to provide insight into how best to apply
linguistic tools when responding to suicidal patients.
To gain insight into the suicidal mind, researchers
have suggested empirically analyzing national mor-
tality statistics, psychological autopsies, nonfatal
suicide attempts and documents such as suicide
notes (Shneidman and Farberow, 1957; Maris,
1981). Most suicide notes analysis has focused
on classification and theoretical-conceptual analysis.
Content analysis has been limited to extracting ex-
plicit information from a suicide note, e.g., length of
the message, words, and parts of speech (Ogilvie et
al., 1969). Classification analysis uses data such as
age, sex, marital status, educational level, employ-
ment status and mental disorder (Ho et al, 1998;
Girdhar et al, 2004; Chavez et al, 2006; Demirel
et al, 2007). Only a very few studies have utilized
theoretical-conceptual analysis , despite the asser-
tion in the first formal study of suicide notes (Shnei-
dman and Farberow, 1957) that such an analysis has
much promise. So, the inconclusive nature of the
methods of analysis has limited their application to
patient care.
179
Our own research has taken a different approach.
In particular we first wanted to determine if mod-
ern machine learning methods could be applied to
free-text from those who committed suicide. Our
first experiment focused on the the ability of ma-
chine learning to distinguish between real suicide
notes and elicited suicide notes as well as mental
health professionals. This is an important question
since all current care is based on a mental health pro-
fession?s interpretation. Our findings showed that
mental health professionals accurately selected gen-
uine suicide notes 50% of the time and the super-
vised machine learning methods were accurate 78%
(Pestian et al, 2008). In this study we shift from
supervised to unsupervised machine learning meth-
ods. Even though these methods have rich history
we know of no research that has applied them to
suicide notes. Our rationale for this study, then, is
that since our ultimate goal is to create a Suicide
Risk Index that incorporates biological and thought
markers it is important to determine if unsupervised
methods can distinguish between suicidal and non-
suicidal writings. To conduct this research we de-
veloped a corpus of over 800 suicide notes from in-
dividuals who had committed suicide, as opposed to
those who attempted or ideated about suicide. This
is an important contribution and, as far as we know,
it is the largest ever developed. It spans 70 years of
notes, and now includes multiple languages. Details
of this corpus are described below. We also created
a corpus of data from various newsgroups that acted
as non-suicidal writings. These corpora were used
to conduct the analysis. The sections below describe
the cluster analysis process and results.
2 Data
Suicide Notes Corpus
Data for the suicide note database were collected
from around the United States. They were either
in a hand written or typed written form. Once the
note was acquired it was scanned into the database.
Optical character recognition was attempted on the
typed written notes, but not accurate, so the notes
were read from the scanned version and type into the
database exactly as seen. A second person reviewed
what was typed. There were limitation in collecting
deceased demographics. The table 1 provides vari-
ous descriptive statistics.
Newsgroup Corpus
Newsgroup data was selected because it was conve-
nient and as close to normal discourse as we could
find. We understood that and ideal comparison
group would be composed of Internet blogs or e-
mails that were written by suicide ideators. True,
a Google query of ?suicide blog? yields millions
of response, a review of many of these responses
shows that the data are of little use for this analy-
sis. In our opinion, the next suitable corpora was
found in a 20 newsgroup collection from the Uni-
versity of California in Irvine (UCI) machine learn-
ing repository1 . Most of the newsgroups have no
relevance to suicide notes. Since our hypothesis
is that unsupervised learning methods can tell the
difference between suicidal and non-suicidal writ-
ing we selected discussions that we believed may
have some similarity to suicide writings. This se-
lection was based on reviewing the newsgroups
with experts. We had conjectured that if an unsu-
pervised method could distinguish between similar
clusters those methods could distinguish between
dissimilar clusters. The newsgroups ultimately se-
lected were talk.politics.guns, talk.politics.mideast,
talk.politics.misc, talk.religion.misc. Each news-
group contains 1000 articles (newsgroup postings).
Headers and quotes from other postings were re-
moved.
3 Methods
Basic statistics are calculated using variables ex-
tracted by Linguistic Inquiry and Word Count ver-
sion 2007 software (LIWC2007) (Chung and Pen-
nebaker, 2007). J. W. Pennebaker, C. K. Chung, M.
Ireland, A. Gonzales, and R. J. Booth created an an-
notated dictionary. Each word in the dictionary is
assigned to at least one of the following high level
category: linguistic process, psychological process,
personal concern, or spoken category. These cat-
egories provide an efficient and effective method
for studying the various emotional, cognitive, and
structural components present in individuals? verbal
and written speech samples (Chung and Pennebaker,
2007; Pennebaker et al, 2001). Here it is used to
analyze differences between suicide notes and news-
1http://archive.ics.uci.edu/ml/
180
group articles.
Feature space was prepared using open source al-
gorithms available in Perl language2 . First, Brian
Duggan spell checking software that uses aspell li-
brary was used (Text::SpellChecker module3). Then,
tokenizer created by Aaron Coburn was used (Lin-
gua::EN::Tagger module2) to extract words was ap-
plied. After that, words were filtered with 319 ele-
ment stop word list 4. Next, the Richardson/Franz
English stemmer was included in the pre-processing
stage (Lingua::Stem module2). Features that ap-
peared in less than 10 documents or in more than 500
documents were removed. Documents that had less
than 10 features or more than 500 were removed.
Finally, columns and rows were normalized to have
unitary lengths. These last steps of pre-processing
are used to reduce outliers.
Calculations are done using open source software
called R5. Clustering is done with the following al-
gorithms: expectation maximization (EM) (Witten
and Frank, 2000), simple k-means with euclidean
distance (SKM) (Witten and Frank, 2000), and
sequential information bottleneck algorithm (sIB)
(Slonim et al, 2002). The last approach has been
shown to work well work well when clustering doc-
uments. Specificity, sensitivity and F1 measure are
used as performance measures (Rijsbergen, 1979).
Multidimensional scaling with euclidean distance
measures is used for visualization purposes (Cox
and Cox, 1994).
To extract features that represent each cluster,
Pearson correlation coefficient is used. The correla-
tion coefficient r is calculated between each feature
and each cluster separately r(wi, cj) where wi is ith
word and cj is jth cluster. N best features with the
highest values for each cluster are selected as most
representative.
4 Results
Descriptive statistics for the data sets are listed in
table 1. It shows syntactic differences between lan-
guage use in suicide notes and newsgroups when
Lingua::EN::Tagger is used.
2http://www.perl.org
3http://search.cpan.org
4http://www.dcs.gla.ac.uk/idom/ir resources/
/linguistic utils/stop words
5http://www.r-project.org
Table 1: Descriptive statistics of suicide note corpus and
newsgroups.
suicide
corpus
newsgroups
Sample Size 866 4000 (1000
per group)
Collection Years 1945-2009 1992-1993
Avg tokens per record
(SD)
105 (154) 243 (582)
Range of tokens per
record
1-1837 0-11024
Average (SD) nouns 25.21 (34.81) 77.19
(181.63)
Average (SD) pronouns 16.58 (26.69) 18.05 (63.18)
Average (SD) verbs 21.07 (32.82) 41.31
(109.23)
Average (SD) adjec-
tives
6.43 (9.81) 16.92 (36.45)
Table 2 summarizes information about the lin-
guistic and psychological processes of the data.
The idea of ?process? is derived from the Lin-
guistic Inquiry and Word Count (LIWC2007) soft-
ware (Chung and Pennebaker, 2007). This software
conducts traditional natural language processing by
placing various word into categories. For example,
sixltrs includes words that are at least six letters in
length. A full description of this software, dictio-
naries, reliability and validity tests can be found on
LIWC?s website. 6. Table 2 shows that suicide notes
are, in many ways, different than normal text. For
our study this provides inspiration for continued re-
search.
Table 2: Mean and standard deviation in linguistic and
psychological processes. Selected categories with small-
est p-values (<0.0001) are shown.
suicide guns mideast politics religion
artcl 3.31 (2.79) 7.80 (3.52) 7.37 (3.34) 7.21 (3.40) 7.07 (3.51)
sixltrs 14.20 (7.34) 21.22 (6.32) 23.24 (7.03) 22.41 (7.13) 21.37 (7.87)
prnoun 16.75 (6.82) 11.96 (5.15) 10.64 (4.92) 11.77 (5.18) 13.21 (5.76)
prepos 10.61 (4.35) 12.13 (3.97) 12.89 (3.89) 12.21 (3.97) 11.75 (4.07)
verb 14.69 (5.99) 12.75 (4.72) 11.54 (4.74) 12.72 (4.63) 13.54 (4.97)
biolog 2.70 (3.04) 0.93 (1.27) 0.85 (1.50) 1.59 (2.08) 1.10 (1.75)
affctiv 7.71 (5.39) 4.83 (2.87) 4.77 (3.45) 4.90 (3.18) 5.10 (3.93)
cognitv 12.68 (5.76) 16.14 (5.93) 14.72 (5.62) 16.00 (5.49) 17.14 (6.17)
social 10.45 (5.86) 8.10 (4.20) 8.43 (4.71) 8.76 (4.37) 9.06 (5.17)
The four newsgroup data sets are combined
as follows: talk.politics.guns + suicide notes
= guns, talk.politics.mideast + suicide notes =
mideast, talk.politics.misc + suicide notes = politics,
6http://www.liwc.net/liwcdescription.php#index1
181
talk.religion.misc + suicide notes = religion. Each
data set contained 1866 documents before document
and feature selection is applied. Table 3 has final
number of features while table 4 has final number of
documents. In general sIB clustering algorithm per-
formed best for all data sets with respect to F1 mea-
sure (mean = 0.976, sd = 0.008). The average score
also did not change when the number of clusters var-
ied from two to six (mean = 0.973, sd = 0.012). Per-
formance of k-means and expectation maximization
algorithm was much worse. If number of clusters
was varied between two and six for different data
sets the algorithms achieved F1 measure 0.146 lower
than sIB (SKM mean = 0.831, sd = 0.279, EM mean
= 0.824, sd = 0.219). Table 3 summarizes perfor-
mance of best algorithms for each data set if two
clusters are chosen.
Table 3: Best clustering algorithms for each newsgroup
when clustered with suicide notes in case of two clus-
ters (alg = clustering algorithm, sens = sensitivity, spec
= specificity, F1 = F1 measure, #f = number of features,
sIB = sequential information bottleneck, SKM = simple
k-means).
dataset al sens spec F1 #f
guns sIB .9689 .9834 .9721 1658
mideast sIB .9837 .9942 .9877 2023
politics SKM .9705 .9889 .9769 1694
religion sIB .9787 .9700 .9692 1553
If the desired number of clusters is increased to
four then two major sub-groups are discovered in
suicide notes: emotional (represented by words like:
love, forgive, hope, and want) and non-emotional
(represented by words like: check, bank, and no-
tify). Example of the first type of note might be
(suicide note was annonymized and misspellings left
unchanged):
Jane I am bitterly sorry for what I have done to
you. Please try to forgive me. I can?t live with-
out you and you don?t want me. I can?t blame you
though. But I love you very much. I didn?t act like it
but I did and still do. Please try to be happy, Jane.
That is all I ask. I try hope for the best for you and
I guess that is all there is for me to say. Good by.
John Johnson. Please mail this to Mom. Mrs. Jane
Johnson. Cincinnati, OH.
Example of a non-emotional suicide note might be:
There is no use living in pains. That arthritis and
hardening of the arteries are too much for me. There
are two hundred and five dollars in the bank, and
here are fifty- five dollars and eight cents. I hope that
will be enough for my funeral. You have to notify the
Old Age Assistance Board. Phone - 99999.
Table 4 shows best five ranked features for each clus-
ter for each data set according to correlation coeffi-
cient CC . Features are in the order of rank so that
feature with the highest CC is first. Even though
that we use different newsgroups as control groups
same sub-groups of suicide notes are discovered.
sIB is the most stable and best performing algorithm
in this experiment so it was used to discover those
clusters. Stemmed word that appear in best five
ranked features in at least three data sets are marked
bold.
Figures 1, 2, 3, and 4 show high-dimensional doc-
ument/stemmed word feature space projected on a
two dimensional plane using multidimensional scal-
ing (MDS) initialized by principal component analy-
sis. Each figure has different rotation but the shapes
are similar. In addition MDS shows very little mix-
ing of suicide notes and newsgroups which is also
explained by results in the table 3.
Figure 1: MDS showing suicide notes and
talk.politics.guns articles (s character in the figure
means suicide note while a character depicts newsgroup
article, colors are used as cluster numbers).
182
Table 4: Best five features when four clusters are created
by the sIB algorithm (#c = cluster number, #a = number
of newsgroup articles in a cluster, #s = number of suicide
notes in a cluster). Stemmed word that appear in best five
ranked features in at least three data sets are marked bold.
dataset #c stemmed words #a #s
guns 1 address, bank, bond, notifi,
testam
28 204
guns 2 clinton, fbi, foreign, jim,
spea
318 2
guns 3 forgiv, god, hope, love,
want
4 381
guns 4 crime, firearm, gun, law,
weapon
541 8
mideast 1 appressian, armenia, arme-
nian, ohanu, proceed
464 5
mideast 2 arab, congress, isra, israel,
jew
379 4
mideast 3 bank, check, funer, insur,
testam
10 233
mideast 4 forgiv, good, hope, love,
want
2 355
politics 1 compound, disclaim, fbi,
govern, major
593 12
politics 2 clayton, cramer, optilink,
relat, uunet
274 1
politics 3 bank, box, check, funer,
notifi
11 258
politics 4 forgiv, good, hope, life,
love
11 330
religion 1 bank, bond, check, notifi,
paper
36 192
religion 2 frank, object, observ, the-
ori, valu
279 0
religion 3 activ, christian, jesu, ko-
resh, net
502 10
religion 4 forgiv, hope, love, sorri,
want
12 395
5 Conclusions
Our findings suggest that unsupervised methods can
distinguish between suicide notes and newsgroups,
our proxy for general discussion. This is important
because it is helpful in determining if NLP can be
useful when integrating thought markers with bio-
logical and clinical markers (f(Bm, Tm, Cm)). In
other words, can an NLP tools accurately distin-
guish between suicidal and normal thought markers
(T Sm 6= TNm )? Moreover these unsupervised meth-
ods have shown an ability to find sub-groups of sui-
cide notes even when other types of newsgroups are
present. In our analysis, one subgroup showed no
Figure 2: MDS showing suicide notes and
talk.politics.mideast articles (s character in the fig-
ure means suicide notes while a character depicts
newsgroup article, colors are used as cluster numbers).
Figure 3: MDS showing suicide notes and
talk.politics.misc articles (s character in the figure
means suicide note while a character depicts newsgroup
article, colors are used as cluster numbers).
emotional content while the other was emotionally
charged. This finding is consistent with Tuckman?s,
1959 work that showed suicide notes fall into six
emotional categories: emotionally neutral, emotion-
ally positive, emotionally negative directed inward,
emotionally negative directed outward, emotionally
negative directed inward and outward (Tuckman et
al., 1959). The next step in developing a Suicide
Risk Index is to conduct a clinical trail in the Emer-
gency Department that will collect Bm, Tm, Cm
and test multiple methods for computing the Suicide
183
Figure 4: MDS showing suicide notes and
talk.religion.misc articles (s character in the figure
means suicide note while a character depicts newsgroup
article, colors are used as cluster numbers).
Risk Index.
References
A. Chavez, D. Paramo-Castillo, A. Leenaars, and
L. Leenaars. 2006. Suicide notes in mexico: What do
they tell us? Suicide and Life-Threatening Behavior,
36:709?715.
C.K. Chung and J.W. Pennebaker, 2007. The
psychological functions of function words, pages 343?
359. New York: Psychology Press.
T. F. Cox and M. A. A. Cox. 1994. Multidimensional
Scaling. Chapman and Hall.
B. Demirel, T. Akar, A. Sayin, S. Candansayar, and
A Leenaars. 2007. Farewell to the world: Sui-
cide notes from turkey. Suicide and Life-Threatening
Behavior, 38:123?128.
S. Girdhar, A. Leenaars, T.D. Dogra, L. Leenaars, and
G. Kumar. 2004. Suicide notes in india: what do they
tell us? Archives of Suicide Research, 8:179?185.
T. Ho, P. Yip, C. Chiu, and P. Halliday. 1998. Sui-
cide notes: what do they tell us? Acta Psychiatrica
Scandinavica, 98:467?473.
Hsiang-Ching Kung, Donna L. Hoyert, Jiaquan Xu, and
Sherry L. Murphy. 2008. Deaths: Final data for 2005.
National Vital Statistics Report, 56:1?121.
R. Maris. 1981. Pathways to suicide. John Hopkins
University Press, Baltimore, MD.
D Ogilvie, P. Stone, and E. Shneidman. 1969. Some
characteristics of genuine versus simulated suicide
notes. Bulletin of Suicidology, 1:17?26.
J. W. Pennebaker, M. E. Francis, and R. J. Booth. 2001.
Linguistic Inquiry and Word Count: LIWC. Lawrence
Erlbaum Associates, Mahwah, NJ, 2nd edition.
J. P. Pestian, P. Matykiewicz, J. Grupp-Phelan,
S. Arszman-Lavanier, J. Combs, and Robert Kowatch.
2008. Using natural language processing to clas-
sify suicide notes. In AMIA Annual Symposium
Proceedings, volume 2008. American Medical Infor-
matics Association.
C. J. Van Rijsbergen. 1979. Information Retrieval.
Butterworth-Heinemann, Newton, MA, USA.
E Shneidman and N Farberow. 1957. Clues to Suicide.
McGraw Hill Paperbacks.
Noam Slonim, Nir Friedman, and Naftali Tishby. 2002.
Unsupervised document classification using sequential
information maximization. In Proceedings of the 25th
International ACM SIGIR Conference on Research
and Development in Information Retrieval, pages 129?
136.
Jacob Tuckman, Robert J. Kleiner, and Martha Lavell.
1959. Emotional content of suicide notes. Am J
Psychiatry, 116(1):59?63.
Ian H. Witten and Eibe Frank. 2000. Data mining:
practical machine learning tools and techniques with
Java implementations. Morgan Kaufmann Publishers
Inc., San Francisco, CA, USA.
World Health Organization, 2001. Burden of mental and
behavioral disorders, pages 19?45. World Health Or-
ganization, Geneva.
184
