Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 110?114,
Sofia, Bulgaria, August 4-9 2013. c?2013 Association for Computational Linguistics
Easy-First POS Tagging and Dependency Parsing with Beam Search 
Ji Ma?   JingboZhu?  Tong Xiao?   Nan Yang? 
?Natrual Language Processing Lab., Northeastern University, Shenyang, China 
?MOE-MS Key Lab of MCC, University of Science and Technology of China, 
Hefei, China 
majineu@outlook.com 
{zhujingbo, xiaotong}@mail.neu.edu.cn 
nyang.ustc@gmail.com 
 
Abstract 
In this paper, we combine easy-first de-
pendency parsing and POS tagging algo-
rithms with beam search and structured 
perceptron. We propose a simple variant 
of ?early-update? to ensure valid update 
in the training process. The proposed so-
lution can also be applied to combine 
beam search and structured perceptron 
with other systems that exhibit spurious 
ambiguity. On CTB, we achieve 94.01% 
tagging accuracy and 86.33% unlabeled 
attachment score with a relatively small 
beam width. On PTB, we also achieve 
state-of-the-art performance. 
1 Introduction 
The easy-first dependency parsing algorithm 
(Goldberg and Elhadad, 2010) is attractive due to 
its good accuracy, fast speed and simplicity. The 
easy-first parser has been applied to many appli-
cations (Seeker et al, 2012; S?ggard and Wulff, 
2012). By processing the input tokens in an easy-
to-hard order, the algorithm could make use of 
structured information on both sides of the hard 
token thus making more indicative predictions. 
However, rich structured information also causes 
exhaustive inference intractable. As an alterna-
tive, greedy search which only explores a tiny 
fraction of the search space is adopted (Goldberg 
and Elhadad, 2010). 
 To enlarge the search space, a natural exten-
sion to greedy search is beam search. Recent 
work also shows that beam search together with 
perceptron-based global learning (Collins, 2002) 
enable the use of non-local features that are help-
ful to improve parsing performance without 
overfitting (Zhang and Nivre, 2012). Due to the-
se advantages, beam search and global learning 
has been applied to many NLP tasks (Collins and 
Roark 2004; Zhang and Clark, 2007). However, 
to the best of our knowledge, no work in the lit-
erature has ever applied the two techniques to 
easy-first dependency parsing.  
While applying beam-search is relatively 
straightforward, the main difficulty comes from 
combining easy-first dependency parsing with 
perceptron-based global learning. In particular, 
one needs to guarantee that each parameter up-
date is valid, i.e., the correct action sequence has 
lower model score than the predicted one1. The 
difficulty in ensuring validity of parameter up-
date for the easy-first algorithm is caused by its 
spurious ambiguity, i.e., the same result might be 
derived by more than one action sequences.  
For algorithms which do not exhibit spurious 
ambiguity, ?early update? (Collins and Roark 
2004) is always valid: at the k-th step when the 
single correct action sequence falls off the beam, 
                                                 
1 As shown by (Huang et al, 2012), only valid update guar-
antees the convergence of any perceptron-based training. 
Invalid update may lead to bad learning or even make the 
learning not converge at all. 
Figure 1: Example of cases without/with spurious 
ambiguity. The 3 ? 1 table denotes a beam. ?C/P? 
denotes correct/predicted action sequence. The 
numbers following C/P are model scores. 
 
110
its model score must be lower than those still in 
the beam (as illustrated in figure 1, also see the 
proof in (Huang et al, 2012)). While for easy-
first dependency parsing, there could be multiple 
action sequences that yield the gold result (C1 and 
C2 in figure 1). When all correct sequences fall 
off the beam, some may indeed have higher 
model score than those still in the beam (C2 in 
figure 1), causing invalid update. 
For the purpose of valid update, we present a 
simple solution which is based on early update. 
The basic idea is to use one of the correct action 
sequences that were pruned right at the k-th step 
(C1 in figure 1) for parameter update.  
The proposed solution is general and can also 
be applied to other algorithms that exhibit spuri-
ous ambiguity, such as easy-first POS tagging 
(Ma et al, 2012) and transition-based dependen-
cy parsing with dynamic oracle (Goldberg and 
Nivre, 2012). In this paper, we report experi-
mental results on both easy-first dependency 
parsing and POS tagging (Ma et al, 2012). We 
show that both easy-first POS tagging and de-
pendency parsing can be improved significantly 
from beam search and global learning. Specifi-
cally, on CTB we achieve 94.01% tagging accu-
racy which is the best result to date2 for a single 
tagging model. With a relatively small beam, we 
achieve 86.33% unlabeled score (assume gold 
tags), better than state-of-the-art transition-based 
parsers (Huang and Sagae, 2010; Zhang and 
Nivre, 2011). On PTB, we also achieve good 
results that are comparable to the state-of-the-art. 
2 Easy-first dependency parsing 
The easy-first dependency parsing algorithm 
(Goldberg and Elhadad, 2010) builds a depend-
ency tree by performing two types of actions 
LEFT(i) and RIGHT(i) to a list of sub-tree struc-
tures p1,?, pr. pi is initialized with the i-th word  
                                                 
2 Joint tagging-parsing models achieve higher accuracy, but 
those models are not directly comparable to ours.  
Algorithm 1: Easy-first with beam search 
Input:     sentence   of n words,  beam width s 
Output:  one best dependency tree 
     (     )        
         ( )   
    (  ) 
            // top s extensions from the beam 
1                     // initially, empty beam 
2 for    1   1 do 
3             (        ) 
4 return        ( )   // tree built by the best sequence  
 
of the input sentence. Action LEFT(i)/RIGHT(i) 
attaches pi to its left/right neighbor and then re-
moves pi from the sub-tree list. The algorithm 
proceeds until only one sub-tree left which is the 
dependency tree of the input sentence (see the 
example in figure 2). Each step, the algorithm 
chooses the highest score action to perform ac-
cording to the linear model: 
     ( )     ( ) 
Here,  is the weight vector and  is the feature 
representation. In particular,  (    ( ) 
     ( )) denotes features extracted from pi. 
The parsing algorithm is greedy which ex-
plores a tiny fraction of the search space. Once 
an incorrect action is selected, it can never yield 
the correct dependency tree. To enlarge the 
search space, we introduce the beam-search ex-
tension in the next section. 
3 Easy-first with beam search  
In this section, we introduce easy-first with beam 
search in our own notations that will be used 
throughout the rest of this paper.  
For a sentence x of n words, let   be the action 
(sub-)sequence that can be applied, in sequence, 
to x and the result sub-tree list is denoted by 
 ( )  For example, suppose x is ?I am valid? and 
y is [RIGHT(1)], then y(x) yields figure 2(b). Let 
   to be LEFT(i)/RIGHT(i) actions where    1   . 
Thus, the set of all possible one-action extension 
of   is: 
     ( )            ( )   
Here, ? ? means insert   to the end of  . Follow-
ing (Huang et al, 2012), in order to formalize 
beam search, we also use the          
    ( ) 
operation which returns the top s action sequenc-
es in   according to   ( ). Here,  denotes a 
set of action sequences,   ( ) denotes the sum of 
feature vectors of each action in    
Pseudo-code of easy-first with beam search is 
shown in algorithm 1. Beam search grows s 
(beam width) action sequences in parallel using a  
Figure 2: An example of parsing ?I am valid?. Spu-
rious ambiguity: (d) can be derived by both 
[RIGHT(1), LEFT(2)] and [LEFT(3), RIGHT(1)]. 
111
Algorithm 2: Perceptron-based training over one 
training sample (   ) 
Input:    (   ), s, parameter   
Output: new parameter    
    (       )        
     (      ( ))   
   (  ) 
 // top correct extension from the beam 
1         
2 for    1   1 do 
3     ?      (          ) 
4            (        ) 
5    if           // all correct seq. falls off the beam 
6             ( ?)   (     ) 
7         break 
8 if        ( )      // full update 
9         ( ?)   (       )  
10 return  
 
beam  , (sequences in   are sorted in terms of 
model score, i.e.,   (    )     (  1 ) ). 
At each step, the sequences in   are expanded in 
all possible ways and then   is filled up with the 
top s newly expanded sequences (line 2 ~ line 3). 
Finally, it returns the dependency tree built by 
the top action sequence in      . 
4 Training  
To learn the weight vector , we use the percep-
tron-based global learning3 (Collins, 2002) which 
updates  by rewarding the feature weights fired 
in the correct action sequence and punish those 
fired in the predicted incorrect action sequence. 
Current work (Huang et al, 2012) rigorously 
explained that only valid update ensures conver-
gence of any perceptron variants. They also justi-
fied that the popular ?early update? (Collins and  
Roark, 2004) is valid for the systems that do not 
exhibit spurious ambiguity4.  
However, for the easy-first algorithm or more 
generally, systems that exhibit spurious ambigui-
ty, even ?early update? could fail to ensure valid-
ity of update (see the example in figure 1). For 
validity of update, we propose a simple solution 
which is based on ?early update? and which can 
accommodate spurious ambiguity. The basic idea 
is to use the correct action sequence which was  
                                                 
3 Following (Zhang and Nivre, 2012), we say the training 
algorithm is global if it optimizes the score of an entire ac-
tion sequence. A local learner trains a classifier which dis-
tinguishes between single actions. 
4 As shown in (Goldberg and Nivre 2012), most transition-
based dependency parsers (Nivre et al, 2003; Huang and 
Sagae 2010;Zhang and Clark 2008) ignores spurious ambi-
guity by using a static oracle which maps a dependency tree 
to a single action sequence.  
Features of (Goldberg and Elhadad, 2010) 
for p in pi-1, pi, pi+1 wp-vlp, wp-vrp, tp-vlp,  
tp-vrp, tlcp, trcp, wlcp, wlcp 
for p in pi-2, pi-1, pi, pi+1, pi+2 tp-tlcp,  tp-trcp, tp-tlcp-trcp 
for p, q, r in (pi-2, pi-1, pi), (pi-
1, pi+1, pi), (pi+1, pi+2 ,pi) 
tp-tq-tr, tp-tq-wr 
for p, q in (pi-1, pi) tp-tlcp-tq,   tp-trcp-tq,   ,tp-tlcp-wq,, 
 tp-trcp-wq,   tp-wq-tlcq,  tp-wq-trcq 
 
Table 1: Feature templates for English dependency 
parsing. wp denotes the head word of p, tp denotes the 
POS tag of wp. vlp/vrp denotes the number p?s of 
left/right child. lcp/rcp denotes p?s leftmost/rightmost 
child. pi denotes partial tree being considered. 
 
pruned right at the step when all correct sequence 
falls off the beam (as C1 in figure 1).  
Algorithm 2 shows the pseudo-code of the 
training procedure over one training sample 
(   ), a sentence-tree pair. Here we assume   to 
be the set of all correct action sequences/sub-
sequences. At step k, the algorithm constructs a 
correct action sequence  ? of length k by extend-
ing those in      (line 3). It also checks whether 
   no longer contains any correct sequence. If so, 
 ? together with       are used for parameter up-
date (line 5 ~ line 6). It can be easily verified that 
each update in line 6 is valid. Note that both 
?TOPC? and the operation in line 5 use   to check 
whether an action sequence y is correct or not. 
This  can  be  efficiently  implemented   (without 
explicitly enumerating  ) by checking if each 
LEFT(i)/RIGHT(i) in y are compatible with (   ): 
pi already collected all its dependents according 
to t; pi is attached to the correct neighbor sug-
gested by t.  
5 Experiments 
For English, we use PTB as our data set. We use 
the standard split for dependency parsing and the 
split used by (Ratnaparkhi, 1996) for POS tag-
ging. Penn2Malt5 is used to convert the bracket-
ed structure into dependencies. For dependency 
parsing, POS tags of the training set are generat-
ed using 10-fold jack-knifing.  
For Chinese, we use CTB 5.1 and the split 
suggested by (Duan et al, 2007) for both tagging 
and dependency parsing. We also use Penn2Malt 
and the head-finding rules of (Zhang and Clark 
2008) to convert constituency trees into depend-
encies. For dependency parsing, we assume gold 
segmentation and POS tags for the input.  
                                                 
5 http://w3.msi.vxu.se/~nivre/research/Penn2Malt.html 
112
Features used in English dependency parsing 
are listed in table 1. Besides the features in 
(Goldberg and Elhadad, 2010), we also include 
some trigram features and valency features 
which are useful for transition-based dependency 
parsing (Zhang and Nivre, 2011). For English 
POS tagging, we use the same features as in 
(Shen et al, 2007). For Chinese POS tagging and 
dependency parsing, we use the same features as 
(Ma et al, 2012). All of our experiments are 
conducted on a Core i7 (2.93GHz) machine, both 
the tagger and parser are implemented using C++.  
5.1 Effect of beam width 
Tagging/parsing performances with different 
beam widths on the development set are listed in 
table 2 and table 3. We can see that Chinese POS  
tagging, dependency parsing as well as English 
dependency parsing greatly benefit from beam 
search. While tagging accuracy on English only 
slightly improved. This may because that the 
accuracy of the greedy baseline tagger is already 
very high and it is hard to get further improve-
ment. Table 2 and table 3 also show that the 
speed of both tagging and dependency parsing 
drops linearly with the growth of beam width. 
5.2 Final results 
Tagging results on the test set together with some 
previous results are listed in table 4. Dependency 
parsing results on CTB and PTB are listed in ta-
ble 5 and table 6, respectively. 
On CTB, tagging accuracy of our greedy base-
line is already comparable to the state-of-the-art. 
As the beam size grows to 5, tagging accuracy 
increases to 94.01% which is 2.3% error reduc-
tion. This is also the best tagging accuracy com-
paring with previous single tagging models (For 
limited space, we do not list the performance of 
joint tagging-parsing models).  
Parsing performances on both PTB and CTB 
are significantly improved with a relatively small 
beam width (s = 8). In particular, we achieve 
86.33% uas on CTB which is 1.54% uas im-
provement over the greedy baseline parser. 
Moreover, the performance is better than the best 
transition-based parser (Zhang and Nivre, 2011) 
which adopts a much larger beam width (s = 64).  
6 Conclusion and related work 
This work directly extends (Goldberg and El-
hadad, 2010) with beam search and global learn-
ing. We show that both the easy-first POS tagger 
and dependency parser can be significantly impr- 
s PTB CTB speed  
1 97.17 93.91 1350 
3 97.20 94.15 560 
5 97.22 94.17 385 
 
Table 2: Tagging accuracy vs beam width vs. Speed is 
evaluated using the number of sentences that can be 
processed in one second 
 
s 
PTB CTB 
speed 
uas compl uas compl 
1 91.77 45.29 84.54 33.75 221 
2 92.29 46.28 85.11 34.62 124 
4 92.50 46.82 85.62 37.11 71 
8 92.74 48.12 86.00 35.87 39 
 
Table 3: Parsing accuracy vs beam width. ?uas? and 
?compl? denote unlabeled score and complete match 
rate respectively (all excluding punctuations). 
 
PTB CTB 
(Collins, 2002) 97.11 (Hatori et al, 2012) 93.82 
(Shen et al, 2007) 97.33 (Li et al, 2012) 93.88 
(Huang et al, 2012) 97.35 (Ma et al, 2012) 93.84 
this work   1 97.22 this work   1 93.87 
this work     97.28 this work     94.01? 
 
Table 4: Tagging results on the test set. ??? denotes 
statistically significant over the greedy baseline by 
McNemar?s test (      ) 
 
Systems s uas compl 
(Huang and Sagae, 2010) 8 85.20 33.72 
(Zhang and Nivre, 2011) 64 86.00 36.90 
(Li et al, 2012) ? 86.55 ? 
this work 1 84.79 32.98 
this work 8 86.33
?
 36.13 
 
Table 5: Parsing results on CTB test set. 
  
Systems s uas compl 
(Huang and Sagae, 2010) 8 92.10 ? 
(Zhang and Nivre, 2011) 64 92.90 48.50 
(Koo and Collins, 2010) ? 93.04 ? 
this work 1 91.72 44.04 
this work 8 92.47
?
 46.07 
 
Table 6: Parsing results on PTB test set.  
 
oved using beam search and global learning. 
This work can also be considered as applying 
(Huang et al, 2012) to the systems that exhibit 
spurious ambiguity. One future direction might 
be to apply the training method to transition-
based parsers with dynamic oracle (Goldberg and 
Nivre, 2012) and potentially further advance per-
formances of state-of-the-art transition-based 
parsers. 
113
Shen et al, (2007) and (Shen and Joshi, 2008) 
also proposed bi-directional sequential classifica-
tion with beam search for POS tagging and 
LTAG dependency parsing, respectively. The 
main difference is that their training method aims 
to learn a classifier which distinguishes between 
each local action while our training method aims 
to distinguish between action sequences. Our 
method can also be applied to their framework. 
Acknowledgments 
We would like to thank Yue Zhang, Yoav Gold-
berg and Zhenghua Li for discussions and sug-
gestions on earlier drift of this paper. We would 
also like to thank the three anonymous reviewers 
for their suggestions. This work was supported in 
part by the National Science Foundation of Chi-
na (61073140; 61272376), Specialized Research 
Fund for the Doctoral Program of Higher Educa-
tion (20100042110031) and the Fundamental 
Research Funds for the Central Universities 
(N100204002). 
References  
Collins, M. 2002. Discriminative training methods for 
hidden markov models: Theory and experiments 
with perceptron algorithms. In Proceedings of 
EMNLP. 
Duan, X., Zhao, J., , and Xu, B. 2007. Probabilistic 
models for action-based Chinese dependency pars-
ing. In Proceedings of ECML/ECPPKDD. 
Goldberg, Y. and Elhadad, M. 2010 An Efficient Al-
gorithm for Eash-First Non-Directional Dependen-
cy Parsing. In Proceedings of NAACL 
Huang, L. and Sagae, K. 2010. Dynamic program-
ming for linear-time incremental parsing. In Pro-
ceedings of ACL. 
Huang, L. Fayong, S. and Guo, Y. 2012. Structured 
Perceptron with Inexact Search. In Proceedings of 
NAACL. 
Koo, T. and Collins, M. 2010. Efficient third-order 
dependency parsers. In Proceedings of ACL. 
Li, Z., Zhang, M., Che, W., Liu, T. and Chen, W. 
2012. A Separately Passive-Aggressive Training 
Algorithm for Joint POS Tagging and Dependency 
Parsing. In Proceedings of COLING 
Ma, J., Xiao, T., Zhu, J. and Ren, F. 2012. Easy-First 
Chinese POS Tagging and Dependency Parsing. In 
Proceedings of COLING 
Rataparkhi, A. (1996) A Maximum Entropy Part-Of-
Speech Tagger. In Proceedings of EMNLP 
Shen, L., Satt, G. and Joshi, A. K. (2007) Guided 
Learning for Bidirectional Sequence Classification. 
In Proceedings of ACL. 
Shen, L. and  Josh, A. K. 2008. LTAG Dependency 
Parsing with Bidirectional Incremental Construc-
tion. In Proceedings of  EMNLP. 
Seeker, W., Farkas, R. and Bohnet, B. 2012 Data-
driven Dependency Parsing With Empty Heads. In 
Proceedings of COLING 
S?ggard, A. and Wulff, J. 2012. An Empirical Study 
of Non-lexical Extensions to Delexicalized Trans-
fer. In Proceedings of COLING 
Yue Zhang and Stephen Clark. 2007 Chinese Seg-
mentation Using a Word-based Perceptron Algo-
rithm. In Proceedings of ACL.  
Zhang, Y. and Clark, S. 2008. Joint word segmenta-
tion and POS tagging using a single perceptron. In 
Proceedings of ACL. 
Zhang, Y. and Nivre, J. 2011. Transition-based de-
pendency parsing with rich non-local features. In 
Proceedings of ACL. 
Zhang, Y. and Nivre, J. 2012. Analyzing the Effect of 
Global Learning and Beam-Search for Transition-
Based Dependency Parsing. In Proceedings of 
COLING. 
114
