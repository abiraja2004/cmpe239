Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational
Natural Language Learning, pp. 306?314, Prague, June 2007. c?2007 Association for Computational Linguistics
Probabilistic Coordination Disambiguation
in a Fully-lexicalized Japanese Parser
Daisuke Kawahara
National Institute of Information and
Communications Technology,
3-5 Hikaridai Seika-cho, Soraku-gun,
Kyoto, 619-0289, Japan
dk@nict.go.jp
Sadao Kurohashi
Graduate School of Informatics,
Kyoto University,
Yoshida-Honmachi, Sakyo-ku,
Kyoto, 606-8501, Japan
kuro@i.kyoto-u.ac.jp
Abstract
This paper describes a probabilistic model
for coordination disambiguation integrated
into syntactic and case structure analy-
sis. Our model probabilistically assesses
the parallelism of a candidate coordinate
structure using syntactic/semantic similari-
ties and cooccurrence statistics. We inte-
grate these probabilities into the framework
of fully-lexicalized parsing based on large-
scale case frames. This approach simulta-
neously addresses two tasks of coordination
disambiguation: the detection of coordinate
conjunctions and the scope disambiguation
of coordinate structures. Experimental re-
sults on web sentences indicate the effective-
ness of our approach.
1 Introduction
Coordinate structures are a potential source of syn-
tactic ambiguity in natural language. Since their in-
terpretation directly affects the meaning of the text,
their disambiguation is important for natural lan-
guage understanding.
Coordination disambiguation consists of the fol-
lowing two tasks:
? the detection of coordinate conjunctions,
? and finding the scope of coordinate structures.
In English, for example, coordinate structures are
triggered by coordinate conjunctions, such as and
and or. In a coordinate structure that consists of
more than two conjuncts, commas, which have var-
ious usages, also function like coordinate conjunc-
tions. Recognizing true coordinate conjunctions
from such possible coordinate conjunctions is a task
of coordination disambiguation (Kurohashi, 1995).
The other is the task of identifying the range of co-
ordinate phrases or clauses.
Previous work on coordination disambiguation
has focused on the task of addressing the scope am-
biguity (e.g., (Agarwal and Boggess, 1992; Gold-
berg, 1999; Resnik, 1999; Chantree et al, 2005)).
Kurohashi and Nagao proposed a similarity-based
method to resolve both of the two tasks for Japanese
(Kurohashi and Nagao, 1994). Their method, how-
ever, heuristically detects coordinate conjunctions
by considering only similarities between possible
conjuncts, and thus cannot disambiguate the follow-
ing cases1:
(1) a. kanojo-to
she-cmi
gakkou-ni
school-acc
itta
went
(? went to school with her)
b. kanojo-to
she-cnj
watashi-ga
I-nom
goukaku-shita
passed an exam
(she and I passed an exam)
In sentence (1a), postposition ?to? is used as a comi-
tative case marker, but in sentence (1b), postposition
?to? is used as a coordinate conjunction.
To resolve this ambiguity, predicative case frames
are required. Case frames describe what kinds of
1In this paper, we use the following abbreviations:
nom (nominative), acc (accusative), abl (ablative), cmi (comi-
tative), cnj (conjunction) and TM (topic marker).
306
Table 1: Case frame examples (Examples are writ-
ten in English. Numbers following each example
represent its frequency.).
CS Examples
ga I:18, person:15, craftsman:10, ? ? ?
yaku (1) wo bread:2484, meat:1521, cake:1283, ? ? ?
(broil) de oven:1630, frying pan:1311, ? ? ?
yaku (2) ga teacher:3, government:3, person:3, ? ? ?
(have wo fingers:2950
difficulty) ni attack:18, action:15, son:15, ? ? ?
ga maker:1, distributor:1
yaku (3) wo data:178, file:107, copy:9, ? ? ?
(burn) ni R:1583, CD:664, CDR:3, ? ? ?
...
...
...
ga dolphin:142, student:50, fish:28, ? ? ?
oyogu (1) wo sea:1188, underwater:281, ? ? ?
(swim) de crawl:86, breaststroke:49, stroke:24, ? ? ?
...
...
...
ga I:4, man:4, person:4, ? ? ?
migaku (1) wo tooth:5959, molar:27, foretooth:12
(brush) de brush:38, salt:13, powder:12, ? ? ?
...
...
...
nouns are related to each predicate. For example, a
case frame of ?iku? (go) has a ?to? case slot filled
with the examples such as ?kanojo? (she) or human.
On the other hand, ?goukaku-suru? (pass an exam)
does not have a ?to? case slot but does have a ?ga?
case slot filled with ?kanojo? (she) and ?watashi?
(I). These case frames provide the information for
disambiguating the postpositions ?to? in sentences
(1a) and (1b): (1a) is not coordinate and (1b) is co-
ordinate.
This paper proposes a method for integrating co-
ordination disambiguation into probabilistic syntac-
tic and case structure analysis. This method simul-
taneously addresses the two tasks of coordination
disambiguation by utilizing syntactic/semantic par-
allelism in possible coordinate structures and lexi-
cal preferences in large-scale case frames. We use
the case frames that were automatically constructed
from the web (Table 1). In addition, cooccurrence
statistics of coordinate conjuncts are incorporated
into this model.
2 Related Work
Previous work on coordination disambiguation has
focused mainly on finding the scope of coordinate
structures.
Agarwal and Boggess proposed a method for
identifying coordinate conjuncts (Agarwal and
Boggess, 1992). Their method simply matches parts
of speech and hand-crafted semantic tags of the
head words of the coordinate conjuncts. They tested
their method using the Merck Veterinary Manual
and found their method had an accuracy of 81.6%.
Resnik described a similarity-based approach for
coordination disambiguation of nominal compounds
(Resnik, 1999). He proposed a similarity measure
based on the notion of shared information content.
He conducted several experiments using the Penn
Treebank and reported an F-measure of approxi-
mately 70%.
Goldberg applied a cooccurrence-based proba-
bilistic model to determine the attachments of am-
biguous coordinate phrases with the form ?n1 p n2
cc n3? (Goldberg, 1999). She collected approxi-
mately 120K unambiguous pairs of two coordinate
words from a raw newspaper corpus for a one-year
period and estimated parameters from these statis-
tics. Her method achieved an accuracy of 72% using
the Penn Treebank.
Chantree et al presented a binary classifier for co-
ordination ambiguity (Chantree et al, 2005). Their
model is based on word distribution information
obtained from the British National Corpus. They
achieved an F-measure (? = 0.25) of 47.4% using
their own test set.
The previously described methods focused on co-
ordination disambiguation. Some research has been
undertaken that integrated coordination disambigua-
tion into parsing.
Kurohashi and Nagao proposed a Japanese pars-
ing method that included coordinate structure detec-
tion (Kurohashi and Nagao, 1994). Their method
first detects coordinate structures in a sentence, and
then heuristically determines the dependency struc-
ture of the sentence under the constraints of the de-
tected coordinate structures. Their method correctly
analyzed 97 Japanese sentences out of 150.
Charniak and Johnson used some features of syn-
tactic parallelism in coordinate structures for their
MaxEnt reranking parser (Charniak and Johnson,
2005). The reranker achieved an F-measure of
91.0%, which is higher than that of their genera-
tive parser (89.7%). However, they used a numer-
ous number of features, and the contribution of the
307
Table 2: Expressions that indicate coordinate struc-
tures.
(a) coordinate noun phrase:
,(comma) to ya toka katsu oyobi ka aruiwa ...
(b) coordinate predicative clause:
-shi ga oyobi ka aruiwa matawa ...
(c) incomplete coordinate structure:
,(comma) oyobi narabini aruiwa ...
parallelism features is unknown.
Dubey et al proposed an unlexicalized PCFG
parser that modified PCFG probabilities to condi-
tion the existence of syntactic parallelism (Dubey
et al, 2006). They obtained an F-measure increase
of 0.4% over their baseline parser (73.0%). Experi-
ments with a lexicalized parser were not conducted
in their work.
A number of machine learning-based approaches
to Japanese parsing have been developed. Among
them, the best parsers are the SVM-based depen-
dency analyzers (Kudo and Matsumoto, 2002; Sas-
sano, 2004). In particular, Sassano added some fea-
tures to improve his parser by enabling it to detect
coordinate structures (Sassano, 2004). However, the
added features did not contribute to improving the
parsing accuracy. This failure can be attributed to
the inability to consider global parallelism.
3 Coordination Ambiguity in Japanese
In Japanese, the bunsetsu is a basic unit of depen-
dency that consists of one or more content words and
the following zero or more function words. A bun-
setsu corresponds to a base phrase in English and
?eojeol? in Korean.
Coordinate structures in Japanese are classified
into three types. The first type is the coordinate noun
phrase.
(2) nagai
long
enpitsu-to
pencil-cnj
keshigomu-wo
eraser-acc
katta
bought
(bought a long pencil and an eraser)
We can find these phrases by referring to the words
listed in Table 2-a.
The second type is the coordinate predicative
clause, in which two or more predicates form a co-
ordinate structure.
bn
An: Partial matrix
A = (a(i, j))
Coordination key bunsetsu
a(n, m)
a(pm-n, n+1)
a path
Similarity betweenbn and bm
Figure 1: Method using triangular matrix.
(3) kanojo-to
she-cmi
kekkon-shi
married
ie-wo
house-acc
katta
bought
(married her and bought a house)
We can find these clauses by referring to the words
and ending forms listed in Table 2-b.
The third type is the incomplete coordinate struc-
ture, in which some parts of coordinate predicative
clauses are present.
(4) Tom-wa
Tom-TM
inu-wo,
dog-acc
Jim-wa
Jim-TM
neko-wo
cat-acc
kau
buys
(Tom (buys) a dog, and Jim buys a cat)
We can find these structures by referring to the
words listed in Table 2-c and also the correspon-
dence of case-marking postpositions.
For all of these types, we can detect the possibility
of a coordinate structure by looking for a coordina-
tion key bunsetsu that accompanies one of the words
listed in Table 2 (in total, we have 52 coordination
expressions). That is to say, the left and right sides of
a coordination key bunsetsu constitute possible pre-
and post-conjuncts, and the key bunsetsu is located
at the end of the pre-conjunct. The size of the con-
juncts corresponds to the scope of the coordination.
4 Calculating Similarity between Possible
Coordinate Conjuncts
We assess the parallelism of potential coordinate
structures in a probabilistic parsing model. In this
308
puroguramingu gengo-wa 2 2 0 2 2 2 0 0 2 0 (prog. language)
mondai kaiketsu-no 2 0 2 4 2 0 0 2 0 (problem solution)
arugorizumu-wo 0 2 2 4 0 0 2 0 (algorithm)hyogen dekiru 0 0 0 2 4 0 2 (can express)kijutsuryoku-to 2 2 0 0 2 0 (descriptive power)keisanki-no 2 0 0 2 0 (computer)kinou-wo 0 0 2 0 (function)jubun-ni 2 0 2 (sufficiently)kudou dekiru 0 2 (can drive)
wakugumi-ga 0 (framework)hitsuyou-dearu. (require)
(Programming language requires descriptive power to express an algorithm for 
solving problems and a framework to sufficiently drive functions of a computer.)
post-conjunct
pre-conjunct
Figure 2: Example of calculating path scores.
section, we describe a method for calculating simi-
larities between potential coordinate conjuncts.
To measure the similarity between potential pre-
and post-conjuncts, a lot of work on the coordi-
nation disambiguation used the similarity between
conjoined heads. However, not only the conjoined
heads but also other components in conjuncts have
some similarity and furthermore structural paral-
lelism. Therefore, we use a method to calculate the
similarity between two whole coordinate conjuncts
(Kurohashi and Nagao, 1994). The remainder of this
section contains a brief description of this method.
To calculate similarity between two series of bun-
setsus, a triangular matrix, A, is used (illustrated in
Figure 1).
A = (a(i, j)) (0 ? i ? l; i ? j ? l) (1)
where l is the number of bunsetsus in a sentence,
diagonal element a(i, j) is the i-th bunsetsu, and el-
ement a(i, j) (i < j) is the similarity value between
bunsetsus bi and bj . A similarity value between
two bunsetsus is calculated on the basis of POS
matching, exact word matching, and their semantic
closeness in a thesaurus tree (Kurohashi and Nagao,
1994). We use the Bunruigoihyo thesaurus, which
contains 96,000 Japanese words (The National In-
stitute for Japanese Language, 2004).
To detect a coordinate structure involving a key
bunsetsu, bn, we consider only a partial matrix (de-
noted An), that is, the upper right part of bn (Figure
1).
An = (a(i, j)) (0 ? i ? n;n + 1 ? j ? l) (2)
To specify correspondences between bunsetsus in
potential pre- and post-conjuncts, a path is defined
as follows:
path ::= (a(p1,m), a(p2,m? 1), . . . ,
a(pm?n, n + 1)) (3)
where n+1 ? m ? l, a(p1,m) 6= 0, p1 = n, pi ?
pi+1, (1 ? i ? m? n? 1).
That is, a path represents a series of elements from
a non-zero element in the lowest row in An to an
element in the leftmost column in An. The path has
an only element in each column and extends toward
the upper left. The series of bunsetsus on the left side
of the path and the series under the path are potential
conjuncts for key bn. Figure 2 shows an example of
a path.
A path score is defined based on the following cri-
teria:
? the sum of each element?s points on the path
? penalty points when the path extends non-
diagonally (which causes conjuncts of unbal-
anced lengths)
? bonus points on expressions signaling the be-
ginning or ending of a coordinate structure,
such as ?kaku? (each) and nado? (and so on)
? the total score of the above criteria is divided
by the square root of the number of bunsetsus
covered by the path for normalization
The score of each path is calculated using a dy-
namic programming method. We consider each path
as a candidate of pre- and post-conjuncts.
309
5 Integrated Probabilistic Model for
Syntactic, Coordinate and Case
Structure Analysis
This section describes a method of integrating coor-
dination disambiguation into a probabilistic parsing
model. The integrated model is based on a fully-
lexicalized probabilistic model for Japanese syntac-
tic and case structure analysis (Kawahara and Kuro-
hashi, 2006b).
5.1 Outline of the Model
This model gives a probability to each possible de-
pendency structure, T , and case structure, L, of the
input sentence, S, and outputs the syntactic, coordi-
nate and case structure that have the highest proba-
bility. That is to say, the model selects the syntactic
structure, T best, and the case structure, Lbest, that
maximize the probability, P (T,L|S):
(T best, Lbest) = argmax (T,L)P (T,L|S)
= argmax (T,L)
P (T,L, S)
P (S)
= argmax (T,L)P (T,L, S) (4)
The last equation is derived because P (S) is con-
stant.
The model considers a clause as a generation unit
and generates the input sentence from the end of the
sentence in turn. The probability P (T,L, S) is de-
fined as the product of probabilities for generating
clause Ci as follows:
P (T,L, S) =
?
i=1..nP (Ci, relihi |Chi) (5)
where n is the number of clauses in S, Chi is Ci?s
modifying clause, and relihi is the dependency re-
lation between Ci and Chi . The main clause, Cn,
at the end of a sentence does not have a modify-
ing head, but a virtual clause Chn = EOS (End Of
Sentence) is inserted. Dependency relation relihi is
first classified into two types C (coordinate) and D
(normal dependency), and C is further divided into
five classes according to the binned similarity (path
score) of conjuncts. Therefore, relihi can be one of
the following six classes.
relihi = {D,C0, C1, C2, C3, C4} (6)
For instance, C0 represents a coordinate relation
with a similarity of less than 1, and C4 represents
a coordinate relation with a similarity of 4 or more.
bentou-wa
tabete-te
kaet-ta(go home)
bentou-wa
tabete-te
kaet-ta(go home) EOSEOS)|,( EOSDtakaetP ? )|,( EOSDtakaetwabentouP ??)|,( takaetDtetabewabentouP ??? )|,( takaetwabentouDtetabeP ???
(eat)
(lunchbox)
(eat)
(lunchbox)
)|,( EOSDtakaetP ? )|,( EOSDtakaetwabentouP ??)|0,( takaetCtetabewabentouP ??? )|0,( takaetwabentouCtetabeP ???
(1) (3)
(4)(2)
Dependency structure Dependency structure21,TT 43 ,TT
DT :1 0:2 CT DT :3 0:4 CT
Figure 3: Example of probability calculation.
For example, consider the sentence shown in Fig-
ure 3. There are four possible dependency structures
in this figure, and the product of the probabilities
for each structure indicated below the tree is calcu-
lated. Finally, the model chooses the structure with
the highest probability (in this case T 1 is chosen).
Clause Ci is decomposed into its clause type,
f i, (including the predicate?s inflection and function
words) and its remaining content part Ci?. Clause
Chi is also decomposed into its content part, Chi ?,
and its clause type, fhi .
P (Ci, relihi |Chi) = P (Ci
?, f i, relihi |Chi
?, fhi)
= P (Ci?, relihi |f i, Chi
?, fhi)? P (f i|Chi
?, fhi)
? P (Ci?, relihi |f i, Chi
?)? P (f i|fhi) (7)
Equation (7) is derived because the content part, Ci?,
is usually independent of its modifying head type,
fhi , and in most cases, the type, f i, is independent
of the content part of its modifying head, Chi .
We call P (Ci?, relihi |f i, Chi ?) generative prob-
ability of a case and coordinate structure, and
P (f i|fhi) generative probability of a clause type.
The latter is the probability of generating func-
tion words including topic markers and punctuation
marks, and is estimated using a syntactically an-
notated corpus in the same way as (Kawahara and
Kurohashi, 2006b).
The generative probability of a case and coordi-
nate structure can be rewritten as follows:
P (Ci?, relihi |f i, Chi
?)
= P (Ci?|relihi , f i, Chi
?)? P (relihi |f i, Chi
?)
? P (Ci?|relihi , f i, Chi
?)? P (relihi |f i) (8)
310
Equation (8) is derived because dependency rela-
tions (coordinate or not) heavily depend on mod-
ifier?s types including coordination keys. We call
P (Ci?|relihi , f i, Chi ?) generative probability of a
case structure, and P (relihi |f i) generative proba-
bility of a coordinate structure. The following two
subsections describe these probabilities.
5.2 Generative Probability of Coordinate
Structure
The most important feature to decide whether two
clauses are coordinate is coordination keys. There-
fore, we consider a coordination key, ki, as clause
type f i. The generative probability of a coordinate
structure, P (relihi |f i), is defined as follows:
P (relihi |f i) = P (relihi |ki) (9)
We classified coordination keys into 52 classes ac-
cording to the classification proposed by (Kurohashi
and Nagao, 1994). If type f i does not contain a co-
ordination key, the relation is always D (normal de-
pendency), that is P (relihi |f i) = P (D|?) = 1.
The generative probability of a coordinate struc-
ture was estimated from a syntactically annotated
corpus using maximum likelihood. We used the
Kyoto Text Corpus (Kurohashi and Nagao, 1998),
which consists of 40K Japanese newspaper sen-
tences.
5.3 Generative Probability of Case Structure
We consider that a case structure consists of a pred-
icate, vi, a case frame, CF l, and a case assignment,
CAk. Case assignment CAk represents correspon-
dences between the input case components and the
case slots shown in Figure 4. Thus, the generative
probability of a case structure is decomposed as fol-
lows:
P (Ci?|relihi , f i, Chi
?)
= P (vi, CF l, CAk|relihi , f i, Chi
?)
= P (vi|relihi , f i, Chi
?)
? P (CF l|relihi , f i, Chi
?, vi)
? P (CAk|relihi , f i, Chi
?, vi, CF l)
? P (vi|relihi , f i, whi)
? P (CF l|vi)
? P (CAk|CF l, f i) (10)
bentou-wa
tabete
(lunchbox)
(eat)
?
lunchbox, bread, ?wo
man, student, ?ga
taberu1 (eat)
Case Frame CF
l
Case 
Assignment
CA
k
(no correspondence)
Dependency Structure of S
Figure 4: Example of case assignment.
The above approximation is given because it is nat-
ural to consider that the predicate vi depends on its
modifying head whi instead of the whole modifying
clause, that the case frame CF l only depends on the
predicate vi, and that the case assignment CAk de-
pends on the case frame CF l and the clause type f i.
The generative probabilities of case frames and
case assignments are estimated from case frames
themselves in the same way as (Kawahara and Kuro-
hashi, 2006b). The remainder of this section de-
scribes the generative probability of a predicate,
P (vi|relihi , f i, whi).
The generative probability of a predicate cap-
tures cooccurrences of coordinate or non-coordinate
phrases. This kind of information is not handled
in case frames, which aggregate only predicate-
argument relations.
The generative probability of a predicate mainly
depends on a coordination key in the clause type, f i,
as well as the generative probability of a coordinate
structure. We define this probability as follows:
P (vi|relihi , f i, whi) = P (vi|relihi , ki, whi)
If Ci? is a nominal clause and consists of a noun
ni, we consider the following probability in stead of
equation (10):
Pn(Ci?|relihi , f i, Chi
?) ? P (ni|relihi , f i, whi)
This is because a noun does not have a case frame
and any case components in the current framework.
To estimate these probabilities, we first applied a
conventional parsing system with coordination dis-
ambiguation to a huge corpus, and collected coor-
dinate bunsetsus from the parses. We used KNP2
(Kurohashi and Nagao, 1994) as the parser and a
web corpus consisting of 470M Japanese sentences
(Kawahara and Kurohashi, 2006a). The generative
probability of a predicate was estimated from the
2http://nlp.kuee.kyoto-u.ac.jp/nl-resource/knp-e.html
311
collected coordinate bunsetsus using maximum like-
lihood.
5.4 Practical Issue
The proposed model considers all the possible de-
pendency structures including coordination ambigu-
ities. To reduce this high computational cost, we in-
troduced the CKY framework to the search.
Each parameter in the model is smoothed by using
several back-off levels in the same way as (Collins,
1999). Smoothing parameters are optimized using a
development corpus.
6 Experiments
We evaluated the coordinate structures and depen-
dency structures that were outputted by our model.
The case frames used in this paper were automati-
cally constructed from 470M Japanese sentences ob-
tained from the web. Some examples of the case
frames are listed in Table 1 (Kawahara and Kuro-
hashi, 2006a).
In this work, the parameters related to unlexical
types are calculated from a small tagged corpus of
newspaper articles, and lexical parameters are ob-
tained from a huge web corpus. To evaluate the ef-
fectiveness of our fully-lexicalized model, our ex-
periments are conducted using web sentences. As
the test corpus, we prepared 759 web sentences 3.
The web sentences were manually annotated using
the same criteria as the Kyoto Text Corpus. We also
used the Kyoto Text Corpus as a development corpus
to optimize the smoothing parameters. The system
input was automatically tagged using the JUMAN
morphological analyzer 4.
We used two baseline systems for comparative
purposes: the rule-based dependency parser, KNP
(Kurohashi and Nagao, 1994), and the probabilis-
tic model of syntactic and case structure analysis
(Kawahara and Kurohashi, 2006b), in which coor-
dination disambiguation is the same as that of KNP.
6.1 Evaluation of Detection of Coordinate
Structures
First, we evaluated detecting coordinate structures,
namely whether a coordination key bunsetsu triggers
3The test set was not used to construct case frames and esti-
mate probabilities.
4http://nlp.kuee.kyoto-u.ac.jp/nl-resource/juman-e.html
Table 3: Experimental results of detection of coor-
dinate structures.
baseline proposed
precision 366/460 (79.6%) 361/435 (83.0%)
recall 366/447 (81.9%) 361/447 (80.8%)
F-measure ? (80.7%) ? (81.9%)
a coordinate structure. Table 3 lists the experimen-
tal results. The F-measure of our method is slightly
higher than that of the baseline method (KNP). In
particular, our method achieved good precision.
6.2 Evaluation of Dependency Parsing
Secondly, we evaluated the dependency structures
analyzed by the proposed model. Evaluating the
scope ambiguity of coordinate structures is sub-
sumed within this dependency evaluation. The de-
pendency structures obtained were evaluated with
regard to dependency accuracy ? the proportion of
correct dependencies out of all dependencies except
for the last dependency in the sentence end 5. Ta-
ble 4 lists the dependency accuracy. In this table,
?syn? represents the rule-based dependency parser,
KNP, ?syn+case? represents the probabilistic parser
of syntactic and case structure (Kawahara and Kuro-
hashi, 2006b), and ?syn+case+coord? represents our
proposed model. The proposed model significantly
outperformed both of the baseline systems (McNe-
mar?s test; p < 0.01).
In the table, the dependency accuracies are clas-
sified into four types on the basis of the bunsetsu
classes (PB: predicate bunsetsu and NB: noun bun-
setsu) of a dependent and its head. ?syn+case?
outperformed ?syn?. In particular, the accuracy
of predicate-argument relations (?NB?PB?) was
improved, but the accuracies of ?NB?NB? and
?PB?PB? decreased. ?syn+case+coord? outper-
formed the two baselines for all of the types. Not
only the accuracy of predicate-argument relations
(?NB?PB?) but also the accuracies of coordinate
noun/predicate bunsetsus (related to ?NB?NB? and
?PB?PB?) were improved. These improvements
are conduced by the integration of coordination dis-
ambiguation and syntactic/case structure analysis.
5Since Japanese is head-final, the second last bunsetsu un-
ambiguously depends on the last bunsetsu, and the last bunsetsu
has no dependency.
312
Table 4: Experimental results of dependency parsing.
syn syn+case syn+case+coord
all 3,833/4,436 (86.4%) 3,852/4,436 (86.8%) 3,893/4,436 (87.8%)
NB?PB 1,637/1,926 (85.0%) 1,664/1,926 (86.4%) 1,684/1,926 (87.4%)
NB?NB 1,032/1,136 (90.8%) 1,029/1,136 (90.6%) 1,037/1,136 (91.3%)
PB?PB 654/817 (80.0%) 647/817 (79.2%) 659/817 (80.7%)
PB?NB 510/557 (91.6%) 512/557 (91.9%) 513/557 (92.1%)
To compare our results with a state-of-the-art dis-
criminative dependency parser, we input the same
test corpus into an SVM-based Japanese dependency
parser, CaboCha6(Kudo and Matsumoto, 2002).
Its dependency accuracy was 86.3% (3,829/4,436),
which is equivalent to that of ?syn? (KNP). This low
accuracy is attributed to the out-of-domain training
corpus. That is, the parser is trained on a newspa-
per corpus, whereas the test corpus is obtained from
the web, because of the non-availability of a tagged
web corpus that is large enough to train a supervised
parser.
6.3 Discussion
Figure 5 shows some analysis results, where the
dotted lines represent the analysis by the baseline,
?syn+case?, and the solid lines represent the analysis
by the proposed method, ?syn+case+coord?. These
sentences are incorrectly analyzed by the baseline
but correctly analyzed by the proposed method. For
instance, in sentence (1), the noun phrase coordina-
tion of ?apurikeesyon? (application) and ?doraiba?
(driver) can be correctly analyzed. This is because
the case frame of ?insutooru-sareru? (installed) is
likely to generate ?doraiba?, and ?apurikeesyon?
and ?doraiba? are likely to be coordinated.
One of the causes of errors in dependency parsing
is the mismatch between analysis results and anno-
tation criteria. As per the annotation criteria, each
bunsetsu has only one modifying head. Therefore, in
some cases, even if analysis results are semantically
correct, they are judged as incorrect from the view-
point of the annotation. For example, in sentence
(4) in Figure 6, the baseline method, ?syn?, correctly
recognized the head of ?iin-wa? (commissioner-TM)
as ?hirakimasu? (open). However, the proposed
method incorrectly judged it as ?oujite-imasuga?
(offer). Both analysis results can be considered to
be semantically correct, but from the viewpoint of
6http://chasen.org/?taku/software/cabocha/
our annotation criteria, the latter is not a syntactic
relation (i.e., incorrect), but an ellipsis relation. This
kind of error is caused by the strong lexical prefer-
ence considered in our method.
To address this problem, it is necessary to simul-
taneously evaluate not only syntactic relations but
also indirect relations, such as ellipses and anaphora.
This kind of mismatch also occurred for the detec-
tion of coordinate structures.
Another errors were caused by an inherent char-
acteristic of generative models. Generative models
have some advantages, such as their application to
language models. However, it is difficult to incor-
porate various features that seem to be useful for
addressing syntactic and coordinate ambiguity. We
plan to apply discriminative reranking to the n-best
parses produced by our generative model in the same
way as (Charniak and Johnson, 2005).
7 Conclusion
This paper has described an integrated probabilistic
model for coordination disambiguation and syntac-
tic/case structure analysis. This model takes advan-
tage of lexical preference of a huge raw corpus and
large-scale case frames and performs coordination
disambiguation and syntactic/case analysis simulta-
neously. The experiments indicated the effective-
ness of our model. Our future work involves incor-
porating ellipsis resolution to develop an integrated
model for syntactic, case, and ellipsis analysis.
Acknowledgment
This research is partially supported by special coor-
dination funds for promoting science and technol-
ogy.
References
Rajeev Agarwal and Lois Boggess. 1992. A simple but
useful approach to conjunct identification. In Proceed-
ings of ACL1992, pages 15?21.
313
??
(1) insutooru-sareteiru apurikeesyon-oyobi doraiba-tono kyougou-niyori dousa-shinai baai-ga arimasu.
installed application driver conflict not work case-nom exist
(due to the conflict between installed application and driver, there is a case that (it) does not work.)
? ?
(2) ... kuroji-wa 41oku-doru-to, zennen-yori 10oku-doru gensyou-shita.
surplus-TM 4.1 billion dollars preceding year-abl 1 billion dollars reduced
(... surplus was 4.1 billion dollars and was reduced by 1 billion dollars from the preceding year.)
??
(3) ... gurupu-wa sugu ugokidasu-node wakaru-nodaga, ugokidasa-nai gurupu-mo aru.
group-TM soon start to work see not start to work group also be
(... can see the groups that start to work soon, but there are groups that do not start to work.)
Figure 5: Examples of correct analysis results. The dotted lines represent the analysis by the baseline,
?syn+case?, and the solid lines represent the analysis by the proposed method, ?syn+case+coord?.
??
(4) iin-wa, jitaku-de minasan-karano gosoudan-ni oujite-imasuga, ... soudansyo-wo hirakimasu
commissioner-TM at home all of you consultation-acc offer window open
(the commissioner offers consultation to all of you at home, but opens a window ...)
Figure 6: An example of incorrect analysis results caused by the mismatch between analysis results and
annotation criteria.
Francis Chantree, Adam Kilgarriff, Anne de Roeck, and
Alistair Wills. 2005. Disambiguating coordinations
using word distribution information. In Proceedings
of RANLP2005.
Eugene Charniak and Mark Johnson. 2005. Coarse-to-
fine n-best parsing and maxent discriminative rerank-
ing. In Proceedings of ACL2005, pages 173?180.
Michael Collins. 1999. Head-Driven Statistical Models
for Natural Language Parsing. Ph.D. thesis, Univer-
sity of Pennsylvania.
Amit Dubey, Frank Keller, and Patrick Sturt. 2006. In-
tegrating syntactic priming into an incremental prob-
abilistic parser, with an application to psycholinguis-
tic modeling. In Proceedings of COLING-ACL2006,
pages 417?424.
Miriam Goldberg. 1999. An unsupervised model for
statistically determining coordinate phrase attachment.
In Proceedings of ACL1999, pages 610?614.
Daisuke Kawahara and Sadao Kurohashi. 2006a.
Case frame compilation from the web using
high-performance computing. In Proceedings of
LREC2006.
Daisuke Kawahara and Sadao Kurohashi. 2006b. A
fully-lexicalized probabilistic model for Japanese syn-
tactic and case structure analysis. In Proceedings of
HLT-NAACL2006, pages 176?183.
Taku Kudo and Yuji Matsumoto. 2002. Japanese depen-
dency analysis using cascaded chunking. In Proceed-
ings of CoNLL2002, pages 29?35.
Sadao Kurohashi and Makoto Nagao. 1994. A syntactic
analysis method of long Japanese sentences based on
the detection of conjunctive structures. Computational
Linguistics, 20(4):507?534.
Sadao Kurohashi and Makoto Nagao. 1998. Building
a Japanese parsed corpus while improving the parsing
system. In Proceedings of LREC1998, pages 719?724.
Sadao Kurohashi. 1995. Analyzing coordinate structures
including punctuation in English. In Proceedings of
IWPT1995, pages 136?147.
Philip Resnik. 1999. Semantic similarity in a taxonomy:
An information-based measure and its application to
problems of ambiguity in natural language. Journal of
Artificial Intelligence Research, 11:95?130.
Manabu Sassano. 2004. Linear-time dependency anal-
ysis for Japanese. In Proceedings of COLING2004,
pages 8?14.
The National Institute for Japanese Language. 2004.
Bunruigoihyo. Dainippon Tosho, (In Japanese).
314
