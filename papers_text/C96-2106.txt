Modularizing Codescriptive Grammars for Efficient Parsing* 
Walter  Kasper  and Hans -U l r i ch  Kr ieger  
German Research  Center  for Art i f ic ia l  In te l l igence (DFK I )  
S tuh lsatzenhausweg 3, D-66123 Saarbr / i cken ,  Germany 
{kasper ,  k r ieger}@dfk i ,  un i - sb ,  de 
Abst rac t  
Unification-based theories of grammar al- 
low to integrate different levels of linguis- 
tic descriptions in the common framework 
of typed feature structures. Dependencies 
among the levels are expressed by corefer- 
ences. Though highly attractive theoreti- 
cally, using such codescriptions for analysis 
creates problems of efficiency. We present 
an approach to a modular use of codescrip- 
tions on the syntactic and semantic level. 
Grammatical nalysis is performed by tight- 
ly coupled parsers running in tandem, each 
using only designated parts of the grammat- 
ical description, in the paper we describe 
the partitioning of grammatical information 
for the parsers and present results about the 
performance. 
1 In t roduct ion  
Unification-based theories of grammar allow for 
an integration of different levels of linguistic de- 
scriptions in a common framework of typed fea- 
ture structures. In HPSG this assumption is em- 
bodied in the flmdamental concept of a sign (Pol- 
lard and Sag, 1987; Pollard and Sag, 1994). A 
sign is a structure incorporating information from 
all levels of linguistic analysis, such as phonology, 
syntax, and semantics. This structure specifies in- 
teractions between these levels by means of cord- 
erences~ indicating the sharing of information. It 
also describes how the levels constrain each other 
mutually. Such a concept of linguistic description 
is attractive for several reasons: 
1. it supports the use of common formalisms and 
data structures on all linguistic levels, 
2. it provides declarative and reversible inter- 
face specifications between these levels, 
3. all information is simultaneously available, 
and 
4. no procedural interaction between linguistic 
modules needs to be set up. 
*This work was funded by the German Federal 
Ministry of Education, Science, Research and Tech- 
nology (BMBF) in the framework of the Verbmobil 
Project under Grant 01 IV 101 K/1. The responsibil- 
ity for the content of this study lies with the authors. 
Similar approaches, especially for the syntax- 
semantics interface, have been suggested for all 
major kinds of unification-based theories, such as 
LFG or CUG. (Halvorsen and Kaplan, 1988) call 
such approaches codescriptive in contrast to the 
approach of description by analysis which is close- 
ly related to sequential architectures where lin- 
guistic levels correspond to components, operat- 
ing on the basis of the (complete) analysis results 
of lower levels. In a codescriptive grammar se- 
mantic descriptions are expressed by additional 
constraints. 
Though theoretically very attractive, codescrip- 
tion has its price: (i) the grammar is difficult to 
modularize due to the fact that the levels con- 
strain each other mutually and (ii) there is a com- 
putational overhead when parsers use the com- 
plete descriptions. Problems of these kinds which 
were already noted by (Shieber, 1985) motivat- 
ed tile research described here. The goal was to 
develop more flexible ways of using codescriptive 
grammars than having them applied by a pars- 
er with full informational power. The underlying 
observation is that constraints in such grammars 
can play different roles: 
? Genuine constraints which relate directly 
to tile grammaticality (wellformedness) of the 
input. Typically, these are t, he syntactic on- 
straints. 
? Spur ious  const ra in ts  which basically build 
representational structures. These are less 
concerned with wellformedness of the input 
but rather with output for other components 
in the overall system. Much of semantic de- 
scriptions are of this kind. 
If a parser treats all constraints on a par, it 
cannot distinguish between the structure-building 
and the filtering constraints. Since unification- 
based formalisms are monotonic, large structures 
are built up and have to undergo all the steps of 
unification, copying, and undoing in the proces- 
sor. The cost, s of these operations (in time and 
space) increase xponentially with the size of the 
structures. 
In the VI,iRBMOBIL project, tile parser is used 
within a speech translation system (Wahlster, 
1993; Kay, Gawron, and Norvig, 1994). The pars- 
628  
- intrans-fin-verb-lex 
INDEX 10281 
np-nmn-type 
SEM \[ cont2quant 
l 
SO ( CNI'-SYM rtp-ea, t 
\[syntax - type \ 
SYN / , \[AGI{ \[\] \] 
"semantics-type 
QUANT empty-diff-list 
SEM 
CON'FEN'r 
> 
\[ rp-typeAsubwff inst-shr-var" 
VAR \[\] \[ atornic-wff-type- 
/INST \[\] 
? syntax- type \] 
J m AD \[aol  \[\] 
PtlON "kolnme" 
Figure 1: The simplified feature structure for the 
German verb komrne (to come). 
er input consists of word lattices of hypotheses 
from speech recognition. Tile parser has to iden- 
tify those paths in tile lattice which represent a
grammatically acceptable utterance. Parser and 
recognizer are increlnental and interactively run- 
ning in parallel? Even for short utterances, the 
lattices can contain several mndreds of word hy- 
potheses, most of which do not combine to gram- 
matical utterances. Parsing these lattices is much 
more complex than parsing written text. 
The basic idea presented here is to distribute 
the labour of evaluating the constraints in the 
grammar on several processors (i.e., parsers). Im- 
portant considerations in the design of the system 
were 
1. increasing the Imrtbrmance, 
2. achieving incremental and interactive be- 
haviour, 
3. minimizing the ow~'rhead in communication 
between the processors. 
We used a mid-size HPSG-kind German gram- 
mar written in the "/7)? formalism (Krieger and 
Schgfer, 1994). The grammar cospecifies yntax 
and semantics in the attributes SYN and SEM. A 
simplified exmnple is shown in tile lexical entry 
for the verb come in Fig. 1. 
In the following section, we start with a top- 
down view of the architecture. Alter that we will 
describe the conmmnication protocol between the 
parsing processes. Then several options for cre- 
ating subgrammars from the complete grammar 
will be discussed. The subgrammars epresent the 
distribution of information across the parsers. Fi- 
nally, some experimental results will be reported. 
2 The Arch i tec ture  
The most important aspect for the distribution 
of analysis tasks and for defining modes of inter- 
action is that one of the processes must work as 
a filter on the input word lattices, reducing the 
search space. The other component then works 
only with successflfl analysis results of the previ- 
ous one. This means, that one parser is in control 
over the other, whereas the latter one is not di- 
rectly exposed to the input. For reasons which 
will become obvious below, we will call the first 
of these parsers the SYN-parser, the second one 
controlled by the SYN-parser, the SEM-par'ser. 
Another consideration to be taken into account; 
is that the analysis should be incremental and 
t ime synchronous. This implies that the SVN- 
parser should not send its results only when it is 
completely finished, thus forcing the SEM-parser 
to wait} Interactivity is another aspect we had 
to consider. Tile SF, M-parser must be able to re- 
port back to the SYN-parser at least when its hy- 
potheses failed. This would not be possible when 
the SEM-parser has to wait till the SYN-parser is 
finished. This requirement also constrains the ex- 
change of messages. 
Incrementality and interactivity imply a steady 
exchange of messages between the parsers. An im- 
portant consideration then is that the overhead for 
this communication should not outweigh the gains 
of distributed processing. This rules out that the 
parsers should communicate by exchanging their 
analysis results in terms of resulting feature struc- 
tures, since it; would imply that on each commu- 
nication event the parsers would have to analyze 
the structures to detect changes, whether a struc- 
ture is part of other already known structures, etc. 
It is hard to see how this kind of communication 
can be interleaved with normal parsing activity in 
efficient ways. 
In contrast o this, our approach allows to ex- 
ploit tim fact that the grammars employed by the 
parsers are derived fl'om the same grammar and 
thereby "similar" in structure. This makes it pos- 
sible to restrict the conmmnication between the 
parsers to intbrmation about what rules were suc- 
cessfiflly or nnsuccessfiflly applied. Each parser 
then can reconstruct on its side the state the other 
parser is in how its chart; or analysis tree looks 
like? Both parsers try to maintain or arriw~ at 
1 Another l)roblem in incremental processing isthat 
it; is not known in advmme when an utte.rance is 
tinished or a new utterance starts. To deal with 
this, prosodic information is taken into account; see 
(Kasper m~d Krieger, 1996) for more detmls. 
629 
isomorphic harts. The approach allows that the 
parsers never need to exchange analysis results in 
terms of structures as the parsers hould always be 
able to reconstruct these if necessary. On the oth- 
er hand, this reconstructibility poses constraints 
on how the codescriptive grammar can be split up 
in subgrammars. 
The requirements of incrementality, interactivi- 
ty and efficient communication show that, our ap- 
proach does not ernulate the "description by anal- 
ysis" methodology in syntax-semantics interfaces 
on the basis of codescriptive grmnmars. 
3 The  Parsers  and  the  Pro toco l  
The SYN-parser and the SEM-parser are agenda- 
driven chart parsers. For speech parsing, the 
nodes represent points of times and edges repre- 
sent word hypotheses/paths in the word lattice. 
The parsers communicate by exchanging h~jpothe- 
ses, bottom-up hypotheses from syntax to seman- 
tics and top-down hypotheses from semantics to 
syntax; see (Kasper, Krieger, Spilker, and Weber, 
1996) for an in-depth description of the current 
setup. 
? Bot tmn-up hypotheses are emitted by the 
SYN-parser and sent to the SEM-parser. They 
undergo verification at tile semantic level. 
A bot tom-up hypothesis describes a passive 
edge (complete subtree) constructed by tile 
syntax parser and consists of the identifier of 
the rule instantiation that represents the edge 
and the completion history of the constructed 
passive edge. Having passive status is a nec- 
essary but not sufficient condition for an edge 
to be sent as hypothesis. Whether a hypothe- 
sis is sent also depends on other criteria, such 
as its score. 
? Top-Down hypotheses result from activ- 
ities of the SEM-parser, trying to verify 
bottom-up-hypotheses. To keep the commu- 
nication efforts low, only failures are reported 
back to the SYN-parser by sending simply the 
hypothesis' identifier. This narrows the space 
of successflfl hypotheses on the SYN-parser's 
side (see remarks in Section 4.3.1). 
The central data structure by which synchro- 
nization and communication between tile parsers 
is achieved is that of a completion history, con- 
taining a record on how a subtree was complet- 
ed. Basically it tells us for each edge in the chart 
which other edges are spanned, The nodes in tile 
chart correspond to points in time and edges to 
time intervals spanned. Completion histories are 
described by the following EBNF: 
{R<rule-id><edge-id><start ><end>{E<edge-id>} *I 
L<lex-id><edge-id><st art ><end> }+ 
<rule-id>, <lex-id>, <edge-id>, <start>, and 
<end> are integers. R<rule-id> and L<lex-id> 
denote rules and lexicon entries, resp. <edge-id> 
uniquely identifies a chart edge. Finally, <star t> 
and <end> specify the start /end point of a span- 
ning edge. 
This protocol allows the parsers to efficiently 
exchange information about the structure of their 
chart without having to deal with explicit analysis 
results as feature structures. Since the SEM-parser 
does not directly work on linguistic input, there 
are two possible parsing modes: 
? Non-autonomous  parsing. The parsing 
process mainly consists of constructing the 
tree described by tile completion history, us- 
ing the semantic counterparts of tile rules 
which led to a syntactic hypothesis. If this 
fails, it is reported back to the SYN-parser. 
? Quasi -autonomous parsing. The parser 
extends the chart on its own through predic- 
tion and completion steps. Obviously, this 
is only possible after some initial information 
by tile SYN-parser, since the S~;M-parser is not 
directly connected to the input word lattice. 
4 Compi la t ion  o f  Subgrammars  
In the following, we discuss possible options and 
problems for the distribution of information in a 
cospecifying rammar. Our approach raises tile 
question which of tile parsers uses what informa- 
tion. This set of information is what we call a 
subgrarnraar. These subgrammars are generated 
from a common source grammar. 
4.1 Reducing the Representat ional  
Overhead by Separat ing  Syntax  and 
Semantics 
An obvious choice for splitting up the grammar 
was to separate the linguistic levels (strata), such 
as syntax and semantics. This choice was also 
motivated by the observation that, typically the 
most important constraints on grammaticality of
the input are in the syntactic part, while most 
of the semantics is purely representational. 2 A 
straightforward way to achieve this is by inanipu- 
bating grammar ules and lexicon entries for the 
SYN-parser, we recursively delete tile information 
under the SEM attributes and sinfilarly clear the 
SYN attributes to obtain the subgrammar for the 
SEM-parser. We abbreviate these subgrammars by 
G~v.,- ~and G ....... and tile original grammar by G. 
This methodology reduces the size of tile struc- 
tures for the SYN-parser to about 30% of the eom- 
2This must be taken cu,n ,qrano salis as it depends 
on how a specific grammar draws the line between 
syntax and semantics: selecdonal constraints, e.g., for 
verb arguments, are typically part of semantics and 
are "true" constraints. Also, semantic constraints 
would have a much larger impact if, for instance, 
agreement constraints are considered as semantic, too, 
as (Pollard and Sag, 1994) suggest. 
630 
plete structure. On(', disadvantage of this simple 
al)proach is that coreferences between syntax and 
semantics disappear (we call the collection of these 
(',Onllnon reentrancies the coref ske, lcton). This 
might lead to several problems which we address 
in Section 4.2. Section 4.3 then discusses possible 
solutions. 
Another, more sophisticated way to keep the 
structures small is due to the type expansion 
mechanism in 7T)? (Krieger and SchMer, 1995). 
Instead of destructively modifying the feature. 
structures lmforehaml, we can elnl)loy type exl)an~ 
sion to let SYN or SI,;M unexpan(le(l. This has the 
desired eft'cot hat we (lo not lose the coreference 
consl:raints and furthernlore are fl'ee to expan(l 
parts of the feature stru(',ture afterwards. We will 
discuss this feature in Section 4.4. 
4.2 Prob lems 
Obviously, the major advantage of our method ix 
that unification and copying l)ecome faster dur- 
ing processing, due to smaller structures. We Call 
even estimate the st)eedup ill the best case, viz., 
quasi-linear w.r.t, input structure if only conjunc- 
tive structures are used. Clearly, if many disjun(:- 
tions are involved, the speedut) might even be ex- 
ponential. 
However, the most imi)ortant disadwmtage of 
the conq)ilation mthod is that it no longer guar- 
antees soundness, that ix, the sut)grammar(s) 
might accel)t ul;terances which are ruled out hy 
tile flfll grammar. This is due to tile silnple fact 
that certain constraints have \])een elinfinated in 
the subgranunars. If at least, one such constraint 
is a filtering constrMnt, we automatically enlarge 
the language accepted 1)y this sul)grainmar w.r.t. 
the original granunar. Clearly, completeness is not 
affected, since we do not add further constrMnts 
to the sul)grannnars. 
At this 1)oint, let us focus on the estimation 
above, since it is only a 1)est;-case forecast. Clear- 
ly, the structures I)econm snmller; however, due 
to the possil)le decrease of filter constraints, we 
nmst expect all increase of hypotheses in the pars- 
er. In fact, tile experimental results ill Section 
5 show that our approach has a ditferent impact 
on tile SYN-parser and the Sl,;M-parser (see Figure 
2). Our hope here, however, is that; the increase 
of non-deternfinisut inside the parser is coml)en- 
sated by tile processing of smalh;r structures; see 
(Maxwell I I I  and Kaplan, 1991) for more argu- 
inents on this theme. 
In general, ewm the intersection of the lan- 
guages accepted by G~,v, ~and G~ ..... does not yield 
the language accepted by G only the weaker re- 
lation ?(G) C ?((;~y,~) O/2(G ..... )holds. This t)e,- 
haviour is all outcome of our compilation schema, 
namely, cutting reentrancy points. Thus, even if 
an utterance is accepted by G with analysis fs 
encoded as a feature structure, it might be tile 
case that the unifi(:ation of the corresponding re- 
suits for G.~.v,,. and G ....... will truly subsume fs: 
A' -</,%.~ A f.~ . . . . . .  
Let; us mention fllrther problems. Firstly, ter- 
mination inight change ill case of tile sul)gram- 
mars. Consider a subgranunar which contains 
elnpty productions or unary (coercion) rules. As- 
sume that such rules were previously "controlled" 
t)y constraints which are no longer presell(;. Ob- 
viously, if a parser is not restricted through addi- 
tional (meta-)constraints, ile iterated al)l)lication 
of these rules could lead to all infinite computa- 
tion, i.e., a loop. This was sometilnes the case. 
during our experin~ents. Secondly, recursivc rules 
couhl introduce infinitely nlany solutions for a giv- 
en utterance. Theoretically, this might not pose a 
problenl, since the intersection of two infinite sets 
of parse trees nfight be finite. However in practice, 
l, his i)roblem might occur. 
4.a Solut ions 
In this section, we will discuss three solution to 
the protflems mentioned before. 
4.3.1 Feedback  Loop  
Although senumtics construction is driven by 
the speech pm'ser, the use of (titfelent subgram- 
mars suggest hat the sl)e, cch I)mser should also 
be guided 1)y the Sl,:M-parsel'. This is achieved 
by sending 1)ack faIs~i/icd hypotheses. Because hy- 
potheses are uniquely identitied in our framework, 
we must only send the integer that idenl;ities tile 
falsified chart edge. Ill the SYN-parser, this infer- 
mat;ion might either lead to a true ('hart revision 
process or be employed as a filter to narrow the 
set of enfitted bottom-ul) hyl)otheses. 
4.3.2 Corer  Ske leton 
In order to gjuarantee correctness of tll(., alml- 
ysis, we might unify the results of 1)oth parsers 
with the corresl)onding coref skeletons at the end 
of an analysis. We (lid not tmrsue this strategy 
since it introduces an additional 1)recessing step 
during parsing. Illstea(l, as explained above, it is 
1)referabh; to employ type expansion here, letting 
SYN or SEM unexpanded, so that coreferences are 
preserved. This treatment will be inve, stigated in 
Section 4.4. 
4.3.3 Full-Size Grammar  
The most straighttbrward way to guarantee 
soundness is siml)ly by elnploying the full-size 
grammar ill one of the two parsers. This might 
sound strange, but if one processor lm.sieally only 
verifies hypotheses from tile other and doe, s not 
generate additional hyl)otheses, tile overhead is 
neglectat)le. We have used this scheme ill that 
the SEM-parser oI)erates oil the full-size grammar, 
whereas the si)eech parser directly conlnmnicates 
with tile word recognizer. This makes sense since 
631  
the word lattice parser processes an order of mag- 
nitude more hypotheses than the SEM-parser; see 
(Kasper, Krieger, Spilker, and Weber, 1996) for 
more details. Because the SEM-parser passes its 
semantic representation to other components, it
makes further sense to guarantee total correctness 
here. 
4.4 hnprovements 
This section investigates several improvements of
our compilation approach, solving the problems 
mentioned before. 
4.4.1 Identifying Functional Strata 
Manually 
Normally, the grammarian "knows" which in- 
formation needs to be made explicit. Hence, in- 
stead of differentiating between the linguistic stra- 
ta sYN and SEM, we let the linguist identify which 
constraints filter and which only serve as a means 
for representation; see also (Shieber, 1985). In 
contrast o the separation along linguistic levels, 
this approach adopts a functional view, cutting 
across linguistic strata. On this view, the syntac- 
tic constraints together with, e.g., semantic selec- 
tion constraints would constitute a subgrammar. 
4.4.2 Bookkeeping Unifications 
In case that the grammarian is unaware of these 
constraints, it is at least possible to determine 
them relatively to a training corpus, simply by 
counting unifications. Features that occur only 
once on top of the input feature structures do not 
specialize the information in the resulting struc- 
ture (actually the values of these features). Fhr- 
thermore, unrestricted features (value T) do not 
constrain the result. For instance, 
indicates that only the path A needs to be made 
explicit, since its value is more specific than the 
corresponding input values: say  -~ s and say  ~_ v. 
4.4.3 Partial Evaluation 
Partial evaluation, as known from function- 
al/logic programming, is a method of carrying 
out parts of computation at compile time that 
would otherwise be done at run time, hence im- 
proving run time performance of programs; see, 
e.g., (Jones, Gomard, ~and Stestoft, 1993). Anal- 
ogous to partial evaluation of definite clauses, we 
can partially evaluate annotated grammar ules, 
since they drive the derivation. Partial evaluation 
means here to substitute type symbols by their 
expanded efinitions. 
Because a grammar contains finitely many rules 
of the above form and because the daughters (the 
right hand side of the rule) are type symbols (and 
there are only finitely many of them), a great deal 
of this partial evaluation process can be performed 
otttine. In contrast o a pure CF grammar with 
finitely many terminal/nonterminals, the evalua- 
tion process must; not terminate, due to eorefer- 
enee constraints within feature structures. How- 
ever, recta-constraints such as of\]line parsability 
or lazy type expansion (see next section) help us 
to determine those features which actively partic- 
ipate in unification during partial evaluation. In 
contrast o the previous method, partial evalua- 
tion is corpus-independent. 
4.4.4 Lazy Type Expansion 
We have indicated earlier that type expansion 
can be fruitfully employed to preserve the coref 
skeleton. Type expansion can also be chosen to 
expand parts of a feature structure on the fly at 
run time. 
The general idea is as follows. Guaranteeing 
that the lexicon entries and the rules are consis- 
tent, we let everything unexpanded unless we are 
enforced to make structure xplicit. As was the' 
case for the previous two strategies, this is only 
necessary if a path is introduced in the resulting 
structure whose value is more specific than the 
value(s) in the input structure(s). 
The biggest advantage of this approach is 
obvious--only those constraints must be touched 
which are involved in restricting the set of possi- 
ble solutions. Clearly, such a test should be done 
every time the chart is extended. The cost of such 
tests and the on-line type expansions need further 
investigation. 
5 Exper imenta l  Resu l ts  
This section presents experimental results of our 
compilation method, indicating that the simple 
SYN/SEM separation does not match the distinc- 
tion between true and spurious constraints, most- 
ly due to semantic selectional constraints (see Fig. 
2). The measurements have been obtained w.r.t. 
a corpus of 56 sentences/turns from 4 dialogsdn 
the VERBMOBIL corpus. 
The column Syn shows that parsing with syn- 
tax only takes 50% of the time of parsing with 
the complete grammar (SynSem).  The num- 
ber of readings, hypotheses, and chart edges on- 
ly slightly increase here. The column SemNA 
shows the results for operating the SEM-parser 
in non-autonomous mode, that is, simply veri- 
lying/falsifying hypotheses fi'om the SYN-parser. 
The parsing time of the coupled system is slightly 
higher than that for SYN-parser alone, due to the 
fact that the SEM-parser can only terminate after 
the SYN-parser has sent its last hypothesis. Nev- 
ertheless, the overall time is still only 50% of the 
system With the complete gramifiar (a sequential 
coupling only improves the overall run time for 
SemNA only by 5-10%). This illustrates that 
632 
number of sentences: 56 
average ler, gth: 7.6 
'nSenl  
rim time: 30.6 
#readings: 1.7 
#hypotheses: 53.0 
~chart edges: 7t 92.0 
Syn SemNA Sem(  
% - -~%-0  - - -~  
15.2 50 15.4 50 45.8 
2.1 123 1 1.7 1 ( ~  
58.1 \[ l{} ~ ~ ~  
215.0 112158.1 -~1-  
Figure 2: \]~xt)erimental results of SYN/SEM separation. SemNA rot)resents results for tile SEM-p~u'ser 
in 1ran-autonomous mode, SemQA the results tbr SEM-patwer as quasi-autonomous semantic parser. 
The percentage vahws are relative to SynSem.  
the efficiency of the parallel running system main- 
ly depends on that of the SYN-parser. The colmnn 
SemQA shows the results for the m.:Mq)arser in 
quasi-autonomous mode. Since no syntactic eon- 
st, raints are involved in filtering, we expect a con- 
siderable increase in processing time and number 
of hypotheses. In fact, our measurements indicate 
that syntax (in our grammar) provides most of the 
genuine constraints. 
These results show that the modularization of 
the grammar and the distribution of its informa- 
tion lead to a considerable increase ill parsing ef- 
ficiency, thus ilnproving the comimtational ppli- 
(:ability of codescriptive grmnmars. 
6 Conc lus ions  
Linguistic theories like HPSG provide an integrat- 
ed view on linguistic objects by providing a uni- 
form fi'amework for all levels of linguistic analy- 
sis. Though attractive from a theoretical I)oint 
of view, their implementation raises questions of 
coinputational tractability. We subscribe to that 
integrated view on the level of linguistic descrip- 
tions and specitications. However, fi'om a compu- 
tational view, we think that for special tasks not 
all that inforination is useful or required, at least 
not all at the same time. 
In this paper we described attelnpts to make a 
more flexible use of integrated linguistic descrip- 
tions by splitting them up into subi)ackages that 
are handled by special processors. We also devised 
an efficient protocol for cominunication between 
such processors and addressed a nmnber of t)rob- 
lems and solutions, some of which need fl~rther 
empirical investigation. The results obtained so 
far indicate that our approach is very promising 
for making efficient use of codescriptive grmnmars 
in natural anguage analysis. 
3ones, Nell 1)., Carsten K. Gomard, and Peter Stestoft 
1993. Partial t"\]vahuttion and Automatic Program 
Generation. New York: Prentice \[lall. 
Kasper, Walter and ltans-Ulrich Krieger. 1996. Inte- 
gration of Prosodic and Grammatical hfformation 
in the Analysis of t)ialogs. Verbmobil Report. 
Kasper, Walter, ltans-Ulrich Krieger, J6rg Spilker, 
and llans Weber. \[996. From Word \[\[ypotheses to' 
Logical Form: An 1,3ficient Interleaved Approach. 
Verbmobil {eport. 
Kay, Martin, Jean Mark Gawron, and Peter Norvig. 
1994. Verbmobil. A Translation System for Face- 
to-Face Dialog. CS\],\[ Lecture Notes, volume 33. 
Chicago University I)ress. 
Krieger, Hans-Ulrich and Ubich Sch'~fer. 1994. :f'D/2 
A Type Description Language for Constraint-Based 
(h'ammars. In Proceedings of COLING-94, pages 
893 89(.). 
Krieger, Hans-Ulrich and Ulrich Sch?fer. 1995. Fill- 
clout l)arameterizal)le Type l,;xt)ansion tbr Typed 
li'eature Formalisms. In Proceedings of IJUAI-95, 
pages \[428 1434. 
Maxwell Ill, John T. and Ronald M. Kaplan. :1993. 
The Interface between Phrasal and 1,'mlctional Con- 
straints. In Computational Linguistics, Vol. 19, 
No. 4, pages 571 590. 
Polhu'd, Carl and \[van A. Sag. 1987. lnformation- 
Hased Syntax and Semantics. Vol. h Fmldamen- 
tals. CSLI Lecture Notes, Volume 13. Stanford: 
CSIA. 
Pollard, Carl and Ivan A. Sag. 11994. Head-Driven 
Phrase Structure Grammar. (\]hicago: University of 
Chicago Press. 
Shieber, Stuart M." 1985. Using Restriction to 
Extend Parsing Algorithms for Complex-Feature- 
Based \]"ormalisms. In Proceedings of ACL-85, 
pages 145-152. 
Wahlster, Wolfgang. 1993. Verbmobih 0bersetzung 
von Verhandhmgsdialogen. Verbmobil Report. 
References  
IIalvorsen, Per-Kristian and Ronald M. Kaplan. 1988. 
Projections and Semantic Description in l,exical- 
Functional (\]ralnmar. In Proceedings of 5th Gener- 
ation Computer System.s, pages 1116 1122. 
633 
