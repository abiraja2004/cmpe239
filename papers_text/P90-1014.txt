Free Indexation: Combinator ia l  Analysis and 
A Composi t ional  Algorithm* 
Sand iway  Fong 
545 Techno logy  Square ,  Rm.  NE43-810,  
M IT  Art i f ic ia l  In te l l igence Laboratory ,  
Cambr idge  MA 02139 
In ternet :  sand iway@ai .mi t .edu  
Abst ract  
The principle known as 'free indexation' plays 
an important role in the determination f the refer- 
ential properties of noun phrases in the principle- 
and-parameters language framework. First, by in- 
vestigating the combinatorics of free indexation, 
we show that the problem of enumerating all possi- 
ble indexings requires exponential time. Secondly, 
we exhibit a provably optimal free indexation al- 
gorithm. 
1 Introduct ion 
In the principles-and-parameters model of lan- 
guage, the principle known as 'free indexation' 
plays an important part in the process of deter- 
mining the referential properties of elements uch 
as anaphors and pronominals. This paper ad- 
dresses two issues. (1) We investigate the combi- 
natorics of free indexation. By relating the prob- 
lem to the n-set partitioning problem, we show 
that free indexation must produce an exponen- 
tial number of referentially distinct phrase struc- 
tures given a structure with n (independent) noun 
phrases. (2) We introduce an algorithm for free in- 
dexation that is defined compositionally on phrase 
structures. We show how the compositional na- 
ture of the algorithm makes it possible to incre- 
mentally interleave the computation of free index- 
ation with phrase structure construction. Addi- 
tionally, we prove the algorithm to be an 'optimal' 
procedure for free indexation. More precisely, by 
relating the compositional structure of the formu- 
lation to the combinatorial nalysis, we show that 
the algorithm enumerates precisely all possible in- 
dexings, without duplicates. 
2 Free Indexat ion 
Consider the ambiguous entence: 
(1) John believes Bill will identify him 
*The author would like to acknowledge Eric S. Ris- 
tad, whose interaction helped to motivate much of 
the analysis in this paper. Also, Robert C. Berwick, 
Michael B. Kashket, and Tanveer Syeda provided 
many useful comments on earlier drafts. This work 
is supported by an IBM Graduate Fellowship. 
In (1), the pronominal "him" can be interpreted 
as being coreferential with "John", or with some 
other person not named in (1), but not with "Bill". 
We can represent these various cases by assigning 
indices to all noun phrases in a sentence together 
with the interpretation that two noun phrases are 
coreferential if and only if they are coindexed, that 
is, if they have the same index. Hence the follow- 
ing indexings represent the three coreference op- 
tions for pronominal "him" :1 
(2) a. John1 believes Bill2 will identify him1 
b. John1 believes Bill2 will identify him3 
c. *John1 believes Bills will identify him2 
In the principles-and-parameters framework 
(Chomsky \[3\]), once indices have been assigned, 
general principles that state constraints on the lo- 
cality of reference of pronominals and names (e.g. 
"John" and "Bill") will conspire to rule out the 
impossible interpretation (2c) while, at the same 
time, allow the other two (valid) interpretations. 
The process of assigning indices to noun phrases 
is known as "free indexation," which has the fol- 
lowing general form: 
(4) Assign indices freely to all noun 
phrases? 
In such theories, free indexation accounts for the 
fact that we have coreferential mbiguities in lan- 
guage. Other principles interact so as to limit the 
1Note that the indexing mechanism used above is 
too simplistic a framework to handle binding examples 
involving inclusion of reference such as: 
(3) a. We1 think that I1 will win 
b. We1 think that Is will win 
c. *We1 like myself 1 
d. John told Bill that they should leave 
Richer schemes that address ome of these problems, 
for example, by representing indices as sets of num- 
bers, have been proposed. See Lasnik \[9\] for a discus- 
sion on the limitations of, and alternatives to, simple 
indexation. Also, Higginbotham \[7\] has argued against 
coindexation (a symmetric relation), and in favour of 
directed links between elements (linking theory). In 
general, there will be twice as many possible 'linkings' 
as indexings for a given structure. However, note that 
the asymptotic results of Section 3 obtained for free 
indexation will also hold for linking theory. 
105 
number of indexings generated by free indexation 
to those that are semantically well-formed. 
In theory, since the indices are drawn from the 
set of natural numbers, there exists an infinite 
number of possible indexings for any sentence. 
However, we are only interested in those indexings 
that are distinct with respect o semantic interpre- 
tation. Since the interpretation of indices is con- 
cerned only with the equality (and inequality) of 
indices, there are only a finite number of seman- 
tically different indexings. 3 For example, "John1 
likes Mary2" and "John23 likes Mary4" are con- 
sidered to be equivalent indexings. Note that the 
definition in (4) implies that "John believes Bill 
will identify him" has two other indexings (in ad- 
dition to those in (2)): 
(5) a. *John1 believes Bill1 will identify him1 
b. *John1 believes Bill1 will identify him2 
subsets. For example, a set of four elements 
{w, x, y, z} can be partitioned into two subsets in 
the following seven ways: 
{w, z}{y} {w, 
y, y} 
y, z){w} 
The number of partitions obtained thus is 
usually represented using the notation {~} 
(Knuth \[8\]). In general, the number of ways of 
partitioning n elements into m sets is given by the 
following formula. (See Purdom & Brown \[10\] for 
a discussion of (6).) 
(6) 
{:++11} = { :}  + (m + 1){m:  1 } 
In some versions of the theory, indices are only 
freely assigned to those noun phrases that have 
not been coindexed through a rule of movement 
(Move-a). (see Chomsky \[3\] (pg.331)). For exam- 
ple, in "Who1 did John see  \[NPt\]l?", the rule of 
movement effectively stipulates that "Who" and 
its trace noun phrase must be coreferential. In 
particular, this implies that free indexation must 
not assign different indices to "who" and its trace 
element. For the purposes of free indexation, we 
can essentially 'collapse' these two noun phrases, 
and treat them as if they were only one. Hence, 
this structure contains only two independent noun 
phrases. 4 
3 The  Combinator i cs  o f  
F ree  Indexat ion  ........ 
In this section, we show that free indexation gen- 
erates an exponential number of indexings in the 
number of independent noun phrases in a phrase 
structure. We achieve this result by observing that 
the problem of free indexation can be expressed in
terms of a well-known combinatorial partitioning 
problem. 
Consider the general problem of partitioning 
a set of n elements into m non-empty (disjoint) 
2The exact form of (4) varies according to different 
versions of the theory. For example, in Chomsky \[4\] 
(pg.59), free indexation is restricted to apply to A- 
positions at the level of S-structure, and to A-positions 
at the level of logical form. 
ZIn other words, there are only a finite number of 
equivalence classes on the relation 'same core\[erence 
relatlons hold.' This can easily be shown by induction 
on the number of indexed elements. 
4TechnicaJly, "who" and its trace are said to form 
a chain. Hence, the structure in question contains two 
distinct chains. 
for n ,m > 0 
The number of ways of partitioning n elements 
into zero sets, {o}, is defined to be zero for n > 0 
and one when n = 0. Similarly, {,no}, the number 
of ways of partitioning zero elements into m sets 
is zero for m > 0 and one when m = 0. 
We observe that the problem of free indexa- 
tion may be expressed as the problem of assign- 
ing 1, 2, . . .  ,n distinct indices to n noun phrases 
where n is the number of noun phrases in a sen- 
tence. Now, the general problem of assigning m 
distinct indices to n noun phrases is isomorphic 
to the problem of partitioning n elements into m 
non-empty disjoint subsets. The correspondence 
here is that each partitioned subset represents a 
set of noun phrases with the same index. Hence, 
the number of indexings for a sentence with n noun 
phrases is: 
(7) 
m=l  
(The quantity in (7) is commonly known as 
Bell's Exponential Number B.; see Berge \[2\].) 
The recurrence relation in (6) has the following 
solution (Abramowitz \[1\]): 
(8) 
Using (8), we can obtain a finite summation 
form for the number of indexings: 
(9) 
(-1) k" S. = (?7  k-7.' 
rn=l  k=0 
106 
It can also be shown (Graham \[6\]) that Bn is 
asymptotically equal to (10): 
(10) 
mrtn em~-n- ~ 
where the quantity mn is given by: 
(11) 
1 
mn In mn= n - - 
2 
That is, (10) is both an upper and lower bound 
on the number of indexings. More concretely, to 
provide some idea of how fast the number of pos- 
sible indexings increases with the number of noun 
phrases in a phrase structure, the following table 
exhibits the values of (9) for the first dozen values 
of n: 
NPs Indexings NPs Indexings 
1 1 7 877 
2 2 8 4140 
3 5 9 21147 
4 15 10 115975 
5 52 11 678570 
6 203 12 4123597 
4 A Compositional 
Algorithm 
In this section, we will define a compositional go- 
rithm for freeindexation that provably enumerates 
all and only all the possible indexings predicted by 
the analysis of the previous ection. 
The PO-PARSER is a parser based 
on a principles-and-parameters framework with a 
uniquely flexible architecture (\[5\]). In this parser, 
linguistic principles uch as free indexation may be 
applied either incrementally as bottom-up hrase 
structure construction proceeds, or as a separate 
operation after the complete phrase structure for 
a sentence is recovered. The PO-PARSER was de- 
signed primarily as a tool for exploring how to 
organize linguistic principles for efficient process- 
ing. This freedom in principle application allows 
one to experiment with a wide variety of parser 
configurations. 
Perhaps the most obvious algorithm for free in- 
dexation is, first, to simply collect all noun phrases 
occurring in a sentence into a list. Then, it is easy 
to obtain all the possible indexing combinations 
by taking each element in the list in turn, and 
optionally coindexing it with each element follow- 
ing it in the list. This simple scheme produces 
each possible indexing without any duplicates and 
works well in the case where free indexing applies 
after structure building has been completed. 
The problem with the above scheme is that it is 
not flexible enough to deal with the case when free 
107 
indexing is to be interleaved with phrase structure 
construction. Conceivably, one could repeatedly 
apply the algorithm to avoid missing possible in- 
dexings. However, this is very inefficient, that is, 
it involves much duplication of effort. Moreover, 
it may be necessary to introduce extra machin- 
ery to keep track of each assignment of indices 
in order to avoid the problem of producing du- 
plicate indexings. Another alternative is to sim- 
ply delay the operation until all noun phrases in 
the sentence have been parsed. (This is basically 
the same arrangement as in the non-interleaved 
case.) Unfortunately, this effectively blocks the 
interleaved application of other principles that are 
logically dependent on free indexation to assign 
indices. For example, this means that principles 
that deal with locality restrictions on the bind- 
ing of anaphors and pronominals cannot be in- 
terleaved with structure building (despite the fact 
that these particular parser operations can be ef- 
fectively interleaved). 
An algorithm for free indexation that is defined 
compositionally on phrase structures can be effec- 
tively interleaved. That is, free indexing should be 
defined so that the indexings for a phrase is some 
function of the indexings of its sub-constituents. 
Then, coindexings can be computed incrementally 
for all individual phrases as they are built. Of 
course, a compositional gorithm can also be used 
in the non-interleaved case. 
Basically, the algorithm works by maintaining a 
set of indices at each sub-phrase of a parse tree. 5
Each index set for a phrase represents the range 
of indices present in that phrase. For example, 
"Whoi did Johnj see tiT' has the phrase structure 
and index sets shown in Figure 1. 
There are two separate tasks to be performed 
whenever two (or more) phrases combine to form 
a larger phrase, s First, we must account for the 
possibility that elements in one phrase could be 
coindexed (cross-indexed) with elements from the 
other phrase. This is accomplished by allowing in- 
dices from one set to be (optionally) merged with 
distinct indices from the other set. For example, 
the phrases "\[NpJohni\]" and "\[vP likes himj\]" 
have index sets {i} and {j}, respectively. Free 
indexation must allow for the possibilities that 
"John" and "him" could be coindexed or main- 
tain distinct indices. Cross-indexing accounts for 
this by optionally merging indices i and j. Hence, 
we obtain: 
(12) a. Johnl likes him/, i merged with j 
5For expository reasons, we consider only pure in- 
dices. The actual algorithm keeps track of additional 
information, such as agreement features like person, 
number and gender, associated with each index. For 
example, irrespective of configuration, "Mary" and 
"him" can never have the same index. 
\[cP \[NP who/\] \[~- did \[IP \[NP Johnj\] \[vP see \[NP tdl\]\]\] 
{i,j} {i} {/,j} {i,j} {j} {i} {/} 
Figure 1 Index sets for "Who did John see?" 
b. Johni likes himj, i not merged with j 
Secondly, we must find the index set of the ag- 
gregate phrase. This is just the set union of the in- 
dex sets of its sub-phrases after cross-indexation. 
In the example, "John likes him", (12a) and (125) 
have index sets {i} and {i, j}. 
More precisely, let Ip be the set of all in- 
dices associated with the Binding Theory-relevant 
elements in phrase P. Assume, without loss 
of generality, that phrase structures are binary 
branching. 7 Consider a phrase P = Iv X Y\] with 
immediate constituents X and Y. Then: 
1. Cross Indexing: Let fx  represent those ele- 
ments of Ix which are not also members of 
Iv, that is, (Ix - I v ) .  Similarly, let iv  be 
(Iv - Ix). s 
(a) If either ix  or f r  are empty sets, then 
done. 
(b) Let x and y be members of i x  and fy,  
respectively. 
(c) Eifher merge indices z and y or do noth- 
ing. 
(d) Repeat from step ( la)  with ix_ - {z} in 
place of ix .  Replace I r  with Iv - {y} if 
and y have been merged. 
2. Index Set Propagation: Ip = Ix O Iv. 
The nondeterminism in step (lc) of cross- 
indexing will generate all and only all (i.e. with- 
out duplicates) the possible indexings. We will 
show this in two parts. First, we will argue that 
eSome rea?lers may realize that the algorithm must 
have an additional step in cases where the larger 
phrase itself may be indexed, for instance, as in 
\[NPi\[NP, John's \] mother\]. In such cases, the third 
step is slCmply to merge the singleton set consisting of 
the index of the larger phrase with the result of cross- 
indexing in the first step. (For the above example, the 
extra step is to just merge {i} with {j}.) For exposi- 
tory reasons, we will ignore such cases. Note that no 
loss of generality is implied since a structure of the 
form \[NPI \[NPj... ~. .  -\] . . .  ~ . . . \ ]  can be can always be 
handled as \[P1 \[NPi\]\[P2\[NPj... o?. . . \ ] . . . /~. . . \ ] \ ] .  
rThe algorithm generalizes to n-ary branching us- 
ing iteration. For example, a ternary branching struc- 
ture such as \[p X Y Z\] would be handled in the same 
way as \[p X\[p, Y Z\]\]. 
SNote that ix and iv are defined purely for no- 
tational convenience. That is, the algorithm directly 
operates on the elements of Ix and Iy. 
108 
/ 
N P k / ~  
N Pj Y Pi 
Figure 2 Right-branching tree 
the above algorithm cannot generate duplicate in- 
dexings: That is, the algorithm only generates 
distinct indexings with respect o the interpreta- 
tion of indices. As shown in the previous ection, 
the combinatorics of free-indexlng indicates that 
there are only B ,  possible indexings. Next, we 
will demonstrate hat the algorithm generates ex- 
actly that number of indexings. If the algorithm 
satisfies both of these conditions, then we have 
proved that it generates all the possible indexings 
exactly once. 
1. Consider the definition of cross-indexing, ix  
represents hose indices in X that do not ap- 
pear in Y. (Similarly for iv.)  Also, whenever 
two indices are merged in step (lb), they are 
'removed' from ix  and iv  before the next it- 
eration. Thus, in each iteration, z and y from 
step (lb) are 'new' indices that have not been 
merged with each other in a previous itera- 
tion. By induction on tree structures, it is 
easy to see that two distinct indices cannot 
be merged with each other more than once. 
Hence, the algorithm cannot generate dupli- 
cate indexings. 
2. We now demonstrate why the algorithm gen- 
erates exactly the correct number of index- 
ings by means of a simple example. Without 
loss of generality, consider the right-branching 
phrase scheme shown in Figure 2. 
Now consider the decision tree shown in Fig- 
ure 3 for computing the possible indexings of 
the right-branching tree in a bottom-up fash- 
ion. 
Each node in the tree represents he index set 
of the combined phrase depending on whether 
the noun phrase at the same level is cross- 
NPs 
gPi  
i= 
NPj 
i= 
NPk 
Decision Tree 
k i=k  i , j   
{ {i,k} {i, j} {~j} {i, j ,k} 
: : : : 
Figure 3 Decision tree 
1 
1 2 
1 2 2 2 3 
r',, B. b. B. b.. 
122232232233334 
: : : : : 
Figure 4 Condensed ecision tree 
indexed or not. For example, {i} and {i, j} 
on the level corresponding to NPj  are the two 
possible index sets for the phrase Pij. The 
path from the root to an index set contains 
arcs indicating what choices (either to coin- 
dex or to leave free) must have been made in 
order to build that index set. Next, let us 
just consider the cardinality of the index sets 
in the decision tree, and expand the tree one 
more level (for NP~) as shown in Figure 4. 
Informally speaking, observe that each deci- 
sion tree node of cardinality i 'generates' i 
child nodes of cardinality i plus one child node 
of cardinality i + 1. Thus, at any given level, 
if the number of nodes of cardinality m is cm, 
and the number of nodes of cardinality m-  1 
is c,,-1, then at the next level down, there 
will be mcm + c,n-1 nodes of cardinality m. 
Let c(n,m) denote the number of nodes at 
level n with cardinality m. Let the top level 
of the decision tree be level 1. Then: 
(13) 
c(n+l ,  re+l)  = c(n, m)+(m+l)c(n, re+l)  
Observe that this recurrence relation has the 
same form as equation (6). Hence the al- 
gorithm generates exactly the same number 
of indexings as demanded by combinatorial 
analysis. 
5 Conc lus ions  
This paper has shown that free indexation pro- 
duces an exponential number of indexings per 
phrase structure. This implies that all algorithms 
that compute free indexation, that is, assign in- 
dices, must also take at least exponential time. In 
this section, we will discuss whether it is possible 
for a principle-based parser to avoid the combina- 
torial 'blow-up' predicted by analysis. 
First, let us consider the question whether the 
'full power' of the free indexing mechanism is nec- 
essary for natural anguages. Alternatively, would 
it be possible to 'shortcut' the enumeration pro- 
cedure, that is, to get away with producing fewer 
than B ,  indexings? After all, it is not obvious 
that a sentence with a valid interpretation can be 
constructed for every possible indexing. However, 
it turns out (at least for small values of n; see 
Figures 5 and 6 below) that language makes use 
of every combination predicted by analysis. This 
implies, that all parsers must be capable of pro- 
ducing every indexing, or else miss valid interpre- 
tations for some sentences. 
There are B3 = 5 possible indexings for three 
noun phrases. Figure 5 contains example sen- 
tences for each possible indexing. 9 Similarly, 
there are fifteen possible indexings for four noun 
phrases. The corresponding examples are shown 
in Figure 6. 
Although it may be the case that a parser must 
be capable of producing every possible indexing, 
it does not necessarily follow that a parser must 
enumerate every indexing when parsing a parlicu- 
lar sentence. In fact, for many cases, it is possible 
to avoid exhaustively exploring the search space 
of possibilities predicted by combinatorial analy- 
sis. To do this, basically we must know, a priori, 
what classes of indexings are impossible for a given 
sentence. By factoring in knowledge about restric- 
tions on the locality of reference of the items to be 
indexed (i.e. binding principles), it is possible to 
explore the space of indexings in a controlled fash- 
ion. For example, although free indexation implies 
that there are five indexings for "John thought \[s 
Tom forgave himself \] ", we can make use of the 
fact that "himself" must be coindexed with an el- 
ement within the subordinate clause to avoid gen- 
STo make the boundary cases match, just define 
c(0, 0) to be 1, and let c(0, m) = 0 and c(n, 0) = 0 for 
m > 0 and n > 0, respectively. 
9PRO is an empty (non-overt) noun phrase 
element. 
109 
(111) 
012) 
(121) 
(122) 
(123) 
John1 wanted PRO1 to forgive himselfl 
John1 wanted PRO1 to forgive him2 
Johnl wanted Mary 2 to forgive himl 
Johnl wanted Mary 2 to forgive herself2 
John1 wanted Mary 2 to forgive him3 
Figure 5 Example sentences for B3 
(1111) 
(1222) 
(1112) 
(1221) 
(1223) 
(1233) 
(1122) 
(1211) 
(1121) 
(1232) 
0123) 
0213) 
0e31) 
(1234) 
John1 
John1 
John1 
Johnl 
Johnl 
John1 
Johnl 
John1 
JOhnl 
John1 
John1 
John1 
John1 
John1 
persuaded himselfl that hel should give himselfl up 
persuaded Mary 2 PRO2 to forgive herself2 
persuaded himselfl PRO1 to forgive hers 
persuaded Mary 2 PROs to forgive himl 
persuaded Mary 2 PRO~ to forgive him3 
wanted Bill2 to ask Mary a PRO3 to leave 
wanted 
wanted 
wanted 
wanted 
wanted 
wanted 
wanted 
wanted 
PRO1 to tell Mary 2 about herself2 
Mary 2 to tell him1 about himselfl 
PRO1 to tell Mary 2 about himself1 
Bill2 to tell Marya about himself2 
PRO1 to tell Mary 2 about Torna 
Mary 2 to tell him1 about Torn3 
Mary 2 to tell Toma about himl 
Mary2 to tell Toma about Bill4 
Figure 6 Example sentences for B4 
crating indexings in which "Tom" and "himself" 
are not coindexed. 1?Note that the early elimina- 
tion of ill-formed indexings depends crucially on 
a parser's ability to interleave binding principles 
with structure building. But, as discussed in Sec- 
tion 4, the interleaving of binding principles logi- 
cally depends on the ability to interleave free in- 
dexation with structure building. Hence the im- 
portance of an formulation of free indexation, such 
as the one introduced in Section 4, which can be 
effectively interleaved. 
References 
\[1\] M. Abramowitz ~ I.A. Stegun, Handbook of 
Mathematical Functions. 1965. Dover. 
\[2\] Berge, C., Principles of Combinatorics. 1971. 
Academic Press. 
\[3\] Chornsky, N.A., Lectures on Government and 
Binding: The Pisa Lectures. 1981. Foris Pub- 
lications. 
1?This leaves only two remaining indexings: (1) 
where "John" is coindexed with "Tom" and "himself", 
and (2) where "John" has a separate index. Similarly, 
if we make use of the fact that "Tom" cannot be coin- 
dexed with "John", we can pare the list of indexings 
down to just one (the second case). 
ii0 
\[4\] Chomsky, N.A., Some Concepts and Conse- 
quences of of the Theory of Government and 
Binding. 1982. MIT Press. 
\[5\] Fong, S. &: R.C. Berwick, "The Compu- 
tational Implementation of Principle-Based 
Parsers," InternationM Workshop on Pars- 
ing Technologies. Carnegie Mellon University. 
1989. 
\[6\] Graham, R.L., D.E. Knuth, & O. Patash- 
nik, Concrete Mathematics: A Foundation 
for Computer Science. 1989. Addison-Wesley. 
\[7\] Higginbotham, J., "Logical Form, Binding, 
and Nominals," Linguistic Inquiry. Summer 
1983. Volume 14, Number 3. 
\[8\] Knuth, D.E., The Art of Computer Program- 
ming: Volume 1 / Fundamental Algorithms. 
2nd Edition. 1973. Addison-Wesley. 
\[9\] Lasnik, H. & J. Uriagereka, A Course in GB 
Syntax: Lectures on Binding and Empty Cat- 
egories. 1988. M.I.T. Press. 
\[10\] Purdom, P.W., Jr. ~ C.A. Brown, The Anal- 
ysis of Algorithms. 1985. CBS Publishing. 
