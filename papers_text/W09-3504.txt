Proceedings of the 2009 Named Entities Workshop, ACL-IJCNLP 2009, pages 28?31,
Suntec, Singapore, 7 August 2009. c?2009 ACL and AFNLP
DIRECTL: a Language-Independent Approach to Transliteration
Sittichai Jiampojamarn, Aditya Bhargava, Qing Dou, Kenneth Dwyer, Grzegorz Kondrak
Department of Computing Science
University of Alberta
Edmonton, AB, T6G 2E8, Canada
{sj,abhargava,qdou,dwyer,kondrak}@cs.ualberta.ca
Abstract
We present DIRECTL: an online discrimi-
native sequence prediction model that em-
ploys a many-to-many alignment between
target and source. Our system incorpo-
rates input segmentation, target charac-
ter prediction, and sequence modeling in
a unified dynamic programming frame-
work. Experimental results suggest that
DIRECTL is able to independently dis-
cover many of the language-specific reg-
ularities in the training data.
1 Introduction
In the transliteration task, it seems intuitively im-
portant to take into consideration the specifics of
the languages in question. Of particular impor-
tance is the relative character length of the source
and target names, which vary widely depending on
whether languages employ alphabetic, syllabic, or
ideographic scripts. On the other hand, faced with
the reality of thousands of potential language pairs
that involve transliteration, the idea of a language-
independent approach is highly attractive.
In this paper, we present DIRECTL: a translit-
eration system that, in principle, can be applied to
any language pair. DIRECTL treats the transliter-
ation task as a sequence prediction problem: given
an input sequence of characters in the source lan-
guage, it produces the most likely sequence of
characters in the target language. In Section 2,
we discuss the alignment of character substrings
in the source and target languages. Our transcrip-
tion model, described in Section 3, is based on
an online discriminative training algorithm that
makes it possible to efficiently learn the weights
of a large number of features. In Section 4, we
provide details of alternative approaches that in-
corporate language-specific information. Finally,
in Section 5 and 6, we compare the experimental
results of DIRECTL with its variants that incor-
porate language-specific pre-processing, phonetic
alignment, and manual data correction.
2 Transliteration alignment
In the transliteration task, training data consist of
word pairs that map source language words to
words in the target language. The matching be-
tween character substrings in the source word and
target word is not explicitly provided. These hid-
den relationships are generally known as align-
ments. In this section, we describe an EM-based
many-to-many alignment algorithm employed by
DIRECTL. In Section 4, we discuss an alternative
phonetic alignment method.
We apply an unsupervised many-to-many align-
ment algorithm (Jiampojamarn et al, 2007) to the
transliteration task. The algorithm follows the ex-
pectation maximization (EM) paradigm. In the
expectation step shown in Algorithm 1, partial
counts ? of the possible substring alignments are
collected from each word pair (xT , yV ) in the
training data; T and V represent the lengths of
words x and y, respectively. The forward prob-
ability ? is estimated by summing the probabili-
ties of all possible sequences of substring pairings
from left to right. The FORWARD-M2M procedure
is similar to lines 5 through 12 of Algorithm 1, ex-
cept that it uses Equation 1 on line 8, Equation 2
on line 12, and initializes ?0,0 := 1. Likewise, the
backward probability ? is estimated by summing
the probabilities from right to left.
?t,v += ?(xtt?i+1, ?)?t?i,v (1)
?t,v += ?(xtt?i+1, yvv?j+1)?t?i,v?j (2)
The maxX and maxY variables specify the
maximum length of substrings that are permitted
when creating alignments. Also, for flexibility, we
allow a substring in the source word to be aligned
with a ?null? letter (?) in the target word.
28
Algorithm 1: Expectation-M2M alignment
Input: xT , yV ,maxX,maxY, ?
Output: ?
? := FORWARD-M2M (xT , yV ,maxX,maxY )1
? := BACKWARD-M2M (xT , yV ,maxX,maxY )2
if (?T,V = 0) then3
return4
for t = 0 . . . T , v = 0 . . . V do5
if (t > 0) then6
for i = 1 . . .maxX st t? i ? 0 do7
?(xtt?i+1, ?) +=
?t?i,v?(xtt?i+1,?)?t,v
?T,V8
if (v > 0 ? t > 0) then9
for i = 1 . . .maxX st t? i ? 0 do10
for j = 1 . . . maxY st v ? j ? 0 do11
?(xtt?i+1, yvv?j+1) +=
?t?i,v?j?(xtt?i+1,y
v
v?j+1)?t,v
?T,V12
In the maximization step, we normalize the par-
tial counts ? to the alignment probability ? using
the conditional probability distribution. The EM
steps are repeated until the alignment probability
? converges. Finally, the most likely alignment for
each word pair in the training data is computed
with the standard Viterbi algorithm.
3 Discriminative training
We adapt the online discriminative training frame-
work described in (Jiampojamarn et al, 2008) to
the transliteration task. Once the training data has
been aligned, we can hypothesize that the ith let-
ter substring xi ? x in a source language word
is transliterated into the ith substring yi ? y in
the target language word. Each word pair is rep-
resented as a feature vector ?(x,y). Our feature
vector consists of (1) n-gram context features, (2)
HMM-like transition features, and (3) linear-chain
features. The n-gram context features relate the
letter evidence that surrounds each letter xi to its
output yi. We include all n-grams that fit within
a context window of size c. The c value is deter-
mined using a development set. The HMM-like
transition features express the cohesion of the out-
put y in the target language. We make a first order
Markov assumption, so that these features are bi-
grams of the form (yi?1, yi). The linear-chain fea-
tures are identical to the context features, except
that yi is replaced with a bi-gram (yi?1, yi).
Algorithm 2 trains a linear model in this fea-
ture space. The procedure makes k passes over
the aligned training data. During each iteration,
the model produces the nmost likely output words
Y?j in the target language for each input word xj
in the source language, based on the current pa-
Algorithm 2: Online discriminative training
Input: Data {(x1,y1), (x2,y2), . . . , (xm,ym)},
number of iterations k, size of n-best list n
Output: Learned weights ?
? := ~01
for k iterations do2
for j = 1 . . .m do3
Y?j = {y?j1, . . . , y?jn} = argmaxy[? ? ?(xj ,y)]4
update ? according to Y?j and yj5
return ?6
rameters ?. The values of k and n are deter-
mined using a development set. The model param-
eters are updated according to the correct output
yj and the predicted n-best outputs Y?j , to make
the model prefer the correct output over the in-
correct ones. Specifically, the feature weight vec-
tor ? is updated by using MIRA, the Margin In-
fused Relaxed Algorithm (Crammer and Singer,
2003). MIRA modifies the current weight vector
?o by finding the smallest changes such that the
new weight vector ?n separates the correct and in-
correct outputs by a margin of at least ?(y, y?), the
loss for a wrong prediction. We define this loss to
be 0 if y? = y; otherwise it is 1 + d, where d is
the Levenshtein distance between y and y?. The
update operation is stated as a quadratic program-
ming problem in Equation 3. We utilize a function
from the SVMlight package (Joachims, 1999) to
solve this optimization problem.
min?n ? ?n ? ?o ?
subject to ?y? ? Y? :
?n ? (?(x,y) ? ?(x, y?)) ? ?(y, y?)
(3)
The argmax operation is performed by an exact
search algorithm based on a phrasal decoder (Zens
and Ney, 2004). This decoder simultaneously
finds the l most likely substrings of letters x that
generate the most probable output y, given the
feature weight vector ? and the input word xT .
The search algorithm is based on the following dy-
namic programming recurrence:
Q(0, $) = 0
Q(t, p) = max
p?,p,
t?maxX?t?<t
{? ? ?(xtt?+1, p?, p) +Q(t?, p?)}
Q(T+1, $) = max
p?
{? ? ?($, p?, $) +Q(T, p?)}
To find the n-best predicted outputs, the table
Q records the top n scores for each output sub-
string that has the suffix p substring and is gen-
erated by the input letter substring xt1; here, p? is
29
a sub-output generated during the previous step.
The notation ?(xtt?+1, p?, p) is a convenient way
to describe the components of our feature vector
?(x,y). The n-best predicted outputs Y? can be
discovered by backtracking from the end of the ta-
ble, which is denoted by Q(T + 1, $).
4 Beyond DIRECTL
4.1 Intermediate phonetic representation
We experimented with converting the original Chi-
nese characters to Pinyin as an intermediate repre-
sentation. Pinyin is the most commonly known
Romanization system for Standard Mandarin. Its
alphabet contains the same 26 letters as English.
Each Chinese character can be transcribed pho-
netically into Pinyin. Many resources for Pinyin
conversion are available online.1 A small percent-
age of Chinese characters have multiple pronunci-
ations represented by different Pinyin representa-
tions. For those characters (about 30 characters in
the transliteration data), we manually selected the
pronunciations that are normally used for names.
This preprocessing step significantly reduces the
size of target symbols from 370 distinct Chinese
characters to 26 Pinyin symbols which enables our
system to produce better alignments.
In order to verify whether the addition of
language-specific knowledge can improve the
overall accuracy, we also designed intermediate
representations for Russian and Japanese. We
focused on symbols that modify the neighbor-
ing characters without producing phonetic output
themselves: the two yer characters in Russian,
and the long vowel and sokuon signs in Japanese.
Those were combined with the neighboring char-
acters, creating new ?super-characters.?
4.2 Phonetic alignment with ALINE
ALINE (Kondrak, 2000) is an algorithm that
performs phonetically-informed alignment of two
strings of phonemes. Since our task requires
the alignment of characters representing different
writing scripts, we need to first replace every char-
acter with a phoneme that is the most likely to be
produced by that character.
We applied slightly different methods to the
test languages. In converting the Cyrillic script
into phonemes, we take advantage of the fact
that the Russian orthography is largely phonemic,
which makes it a relatively straightforward task.
1For example, http://www.chinesetopinyin.com/
In Japanese, we replace each Katakana character
with one or two phonemes using standard tran-
scription tables. For the Latin script, we simply
treat every letter as an IPA symbol (International
Phonetic Association, 1999). The IPA contains a
subset of 26 letter symbols that tend to correspond
to the usual phonetic value that the letter repre-
sents in the Latin script. The Chinese characters
are first converted to Pinyin, which is then handled
in the same way as the Latin script.
Similar solutions could be engineered for other
scripts. We observed that the transcriptions do not
need to be very precise in order for ALINE to pro-
duce high quality alignments.
4.3 System combination
The combination of predictions produced by sys-
tems based on different principles may lead to im-
proved prediction accuracy. We adopt the follow-
ing combination algorithm. First, we rank the in-
dividual systems according to their top-1 accuracy
on the development set. To obtain the top-1 pre-
diction for each input word, we use simple voting,
with ties broken according to the ranking of the
systems. We generalize this approach to handle n-
best lists by first ordering the candidate translitera-
tions according to the highest rank assigned by any
of the systems, and then similarly breaking ties by
voting and system ranking.
5 Evaluation
In the context of the NEWS 2009 Machine
Transliteration Shared Task (Li et al, 2009), we
tested our system on six data sets: from English to
Chinese (EnCh) (Li et al, 2004), Hindi (EnHi),
Russian (EnRu) (Kumaran and Kellner, 2007),
Japanese Katakana (EnJa), and Korean Hangul
(EnKo); and from Japanese Name to Japanese
Kanji (JnJk)2. We optimized the models? param-
eters by training on the training portion of the
provided data and measuring performance on the
development portion. For the final testing, we
trained the models on all the available labeled data
(training plus development data). For each data
set, we converted any uppercase letters to lower-
case. Our system outputs the top 10 candidate an-
swers for each input word.
Table 1 reports the performance of our system
on the development and final test sets, measured
in terms of top-1 word accuracy (ACC). For cer-
tain language pairs, we tested variants of the base
2http://www.cjk.org/
30
Task Model Dev Test
EnCh DIRECTL 72.4 71.7
INT(M2M) 73.9 73.4
INT(ALINE) 73.8 73.2
COMBINED 74.8 74.6
EnHi DIRECTL 41.4 49.8
DIRECTL+MC 42.3 50.9
EnJa DIRECTL 49.9 50.0
INT(M2M)? 49.6 49.2
INT(ALINE) 48.3 51.0
COMBINED? 50.6 50.5
EnKo DIRECTL 36.7 38.7
EnRu DIRECTL 80.2 61.3
INT(M2M) 80.3 60.8
INT(ALINE) 80.0 60.7
COMBINED? 80.3 60.8
JnJk DIRECTL 53.5 56.0
Table 1: Top-1 word accuracy on the development
and test sets. The asterisk denotes the results ob-
tained after the test reference sets were released.
system described in Section 4. DIRECTL refers
to our language-independent model, which uses
many-to-many alignments. The INT abbreviation
denotes the models operating on the language-
specific intermediate representations described in
Section 4.1. The alignment algorithm (ALINE or
M2M) is given in brackets.
In the EnHi set, many names consisted of mul-
tiple words: we assumed a one-to-one correspon-
dence between consecutive English words and
consecutive Hindi words. In Table 1, the results in
the first row (DIRECTL) were obtained with an au-
tomatic cleanup script that replaced hyphens with
spaces, deleted the remaining punctuation and nu-
merical symbols, and removed 43 transliteration
pairs with a disagreement between the number of
source and target words. The results in the sec-
ond row (DIRECTL+MC) were obtained when the
cases with a disagreement were individually ex-
amined and corrected by a Hindi speaker.
We did not incorporate any external resources
into the models presented in Table 1. In order
to emphasize the performance of our language-
independent approach, we consistently used the
DIRECTL model for generating our ?standard?
runs on all six language pairs, regardless of its rel-
ative performance on the development sets.
6 Discussion
DIRECTL, our language-independent approach to
transliteration achieves excellent results, espe-
cially on the EnCh, EnRu, and EnHi data sets,
which represent a wide range of language pairs
and writing scripts. Both the many-to-many
and phonetic alignment algorithms produce high-
quality alignments. The former can be applied di-
rectly to the training data without the need for an
intermediate representation, while the latter does
not require any training. Surprisingly, incorpo-
ration of language-specific intermediate represen-
tations does not consistently improve the perfor-
mance of our system, which indicates that DI-
RECTL may be able to discover the structures im-
plicit in the training data without additional guid-
ance. The EnHi results suggest that manual clean-
ing of noisy data can yield noticeable gains in ac-
curacy. On the other hand, a simple method of
combining predictions from different systems pro-
duced clear improvement on the EnCh set, but
mixed results on two other sets. More research on
this issue is warranted.
Acknowledgments
This research was supported by the Alberta Inge-
nuity, Informatics Circle of Research Excellence
(iCORE), and Natural Sciences of Engineering
Research Council of Canada (NSERC).
References
Koby Crammer and Yoram Singer. 2003. Ultracon-
servative online algorithms for multiclass problems.
Journal of Machine Learning Research, 3:951?991.
International Phonetic Association. 1999. Handbook
of the International Phonetic Association. Cam-
bridge University Press.
Sittichai Jiampojamarn, Grzegorz Kondrak, and Tarek
Sherif. 2007. Applying many-to-many alignments
and Hidden Markov Models to letter-to-phoneme
conversion. In Proc. HLT-NAACL, pages 372?379.
Sittichai Jiampojamarn, Colin Cherry, and Grzegorz
Kondrak. 2008. Joint processing and discriminative
training for letter-to-phoneme conversion. In Proc.
ACL, pages 905?913.
Thorsten Joachims. 1999. Making large-scale SVM
learning practical. Advances in kernel methods:
support vector learning, pages 169?184. MIT Press.
Grzegorz Kondrak. 2000. A new algorithm for the
alignment of phonetic sequences. In Proc. NAACL,
pages 288?295.
A. Kumaran and Tobias Kellner. 2007. A generic
framework for machine transliteration. In Proc. SI-
GIR, pages 721?722.
Haizhou Li, Min Zhang, and Jian Su. 2004. A joint
source channel model for machine transliteration. In
Proc. ACL, pages 159?166.
Haizhou Li, A Kumaran, Min Zhang, and Vladimir
Pervouchine. 2009. Whitepaper of NEWS 2009
machine transliteration shared task. In Proc. ACL-
IJCNLP Named Entities Workshop.
Richard Zens and Hermann Ney. 2004. Improvements
in phrase-based statistical machine translation. In
Proc. HLT-NAACL, pages 257?264.
31
