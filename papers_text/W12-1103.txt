JEP-TALN-RECITAL 2012, Atelier DEFT 2012: D?fi Fouille de Textes, pages 25?31,
Grenoble, 4 au 8 juin 2012. c?2012 ATALA & AFCP
Acquisition terminologique pour identifier les mots cl?s
d?articles scientifiques
Thierry Hamon
LIM&BIO (EA3969)
Universit? Paris 13
93017 Bobigny Cedex
France
thierry.hamon@univ-paris13.fr
R?SUM?
Le d?fi Fouille de texte 2012 (DEFT2012) a pour objectif d?identifier automatiquement des mots
cl?s choisis par les auteurs d?articles scientifiques dans les Sciences Humaines et Sociales. Une
liste de termes constitu?e des mots cl?s est fournie dans la t?che 1. Pour participer ? ce d?fi,
nous avons choisi d?exploiter des outils d?di?s ? la constitution de terminologies structur?es. Les
termes obtenus sont aussi ?t? tri?s et filtr?s ? l?aide de leur position, de m?thodes de pond?ration
statistiques et de crit?res linguistiques. Plusieurs configurations de notre syst?me ont ?t? d?finies.
Nous avons obtenu une F-mesure de 0,3985 dans la t?che 1 et de 0,1921 dans la t?che 2.
ABSTRACT
Terminological acquisition for identifying keywords of scientific articles
The challenge DEFT2012 aims at automatically identifying the keywords chosen by the authors
of scientific articles in the Humanities. A keyword list is provided within the track 1. We propose
to exploit terminological acquisition approaches. The extracted terms are also sorted and filtered
according to their position in the documents, weighting measures and linguistic criteria. We
defined several configurations of our system. Our best F-measure for the track 1 is 0.3985 while
for the track 2, the best F-measure is 0.1921.
MOTS-CL?S : Mots cl?s, extraction de termes, mesure de pond?ration, filtrage de termes.
KEYWORDS: Keywords, Term Recognition, Weighting Measure, Term Filtering.
1 Introduction
L?association de mots cl?s ? un document, notamment ? un article scientifique, est un aspect
important de l?indexation documentaire. L?objectif du d?fi fouille de texte 2012 (DEFT2012)
est d?identifier automatiquement les mots cl?s choisis par les auteurs d?articles scientifiques en
Sciences Humaines et Sociales. Deux t?ches sont propos?es. Dans la premi?re t?che, une liste
de mots cl?s est fournie. Il s?agit donc de retrouver les mots cl?s les plus pertinents pour un
document donn?, parmi ceux fournis. Dans la deuxi?me t?che, aucune liste de mots cl?s n?est
fournie. Il s?agit alors d?identifier les mots cl?s pouvant ?tre associ?s ? chaque document. Dans
25
les deux cas, le nombre de mots cl?s attendus est connu.
Apr?s une description, ? la section 2, du mat?riel utilis?, nous pr?sentons les diff?rentes approches
et param?tres utilis?s ? la section 3. Nous d?crivons ensuite, ? la section 4, les diff?rentes
exp?rimentations qui nous permis d?obtenir les r?sultats pr?sent?s ? la section 5.
2 Mat?riel
Nous avons ? notre disposition un corpus pour les phases d?entra?nement et de test de chaque
t?che. De plus, pour la t?che 1, une liste des mots cl?s associ?s ? l?ensemble des documents du
corpus est mise ? disposition.
Corpus Le corpus est compos? d?articles scientifiques parus entre 2001 et 2008 dans des revues
de Sciences Humaines et Sociales :
? Revue des Sciences de l??ducation (RSE),
? Traduction, Terminologie, R?daction (TTR),
? Anthropologie et Soci?t?s (AS),
? Meta (journal des traducteurs ? META).
Le corpus est d?compos? en quatre sous-corpus, constituant les ensembles d?entra?nement et
de test pour les t?ches 1 et 2. Pour chaque t?che, le corpus d?entra?nement comporte environ 1
million de mots (environ 60% de la totalit? du corpus pour une t?che donn?e), tandis que les
corpus de test sont constitu?s de 680 668 mots pour la t?che 1 et 639 267 mots pour la t?che 2
(voir tableau 1). Les corpus d?entra?nement ?taient disponibles pendant environ 2 mois, tandis
que les corpus de test devaient ?tre trait?s en 3 jours.
Entra?nement Test
Revue T?che 1 T?che 2 T?che 1 T?che 2
mots doc. mots doc. mots doc. mots doc.
RSE 143 314 19 160 387 20 112 203 13 91 371 13
TTR 95 731 13 96 083 13 65 056 9 65 382 9
AS 459 467 56 435 146 56 297 006 38 269 535 37
META 334 238 52 339 051 52 206 412 34 212 979 34
Total 1 032 750 140 1 030 667 94 680 677 141 639 267 93
TABLE 1 ? Description des corpus d?entra?nement et de test pour les t?ches 1 et 2 (nombre de
mots et de documents).
Liste des mots cl?s Pour la t?che 1, nous disposons ?galement de la liste de mots cl?s du
corpus. Ainsi, lors de l?entra?nement, nous disposons de 66 mots cl?s, et lors de la phase de test,
de 478 mots cl?s.
26
3 M?thode
Afin d?identifier les mots cl?s de chaque document, nous avons choisi d?utiliser dans un premier
temps des approches d?extraction et de reconnaissance terminologiques (section 3.1). Les r?sul-
tats de cette premi?re ?tape sont ensuite tri?s avec des m?thodes de pond?ration des termes
(section 3.2). Enfin, une ?tape de filtrage et de s?lection des termes tri?s permet d?identifier les
mots cl?s potentiellement les plus pertinents pour chaque document (section 3.3)
3.1 Acquisition terminologique
Dans cette premi?re ?tape, nous avons exploit? des m?thodes de reconnaissance ou d?extraction
de termes pour identifier des mots cl?s. Afin d??tendre la couverture de l?acquisition de termes et
d?am?liorer l??tape de filtrage, nous avons ?galement acquis des variantes morpho-syntaxiques
des termes extraits.
Reconnaissance de termes (TermTagger). Les mots cl?s fournis lors de la t?che 1 ont ?t?
projet?s sur l?ensemble des documents du corpus de travail. Cette projection a ?t? ?largie en
prenant en compte les lemmes de mots du corpus. Pour r?aliser la reconnaissance des mots cl?s,
nous avons utilis? le module Perl Alvis::TermTagger 1.
Extraction des termes (YATEA). Afin d?identifier les mots cl?s, nous avons choisi d?utiliser unem?thode d?extraction de termes. Les mots cl?s pouvant ?tre des mots ou des groupes nominaux,
nous conservons aussi bien les termes complexes que leurs composants simples. Cette approche a
?t? utilis?e lors de la t?che 2 (o? aucune liste de mots cl?s n?est fournie) mais aussi lors de la
t?che 1 pour ?tendre l?identification des mots cl?s.
Pour r?aliser l?extraction de termes sur les corpus, nous avons utilis? YATEA 2 (Aubin et Hamon,2006). Cet outil terminologique a pour objectif d?extraire d?un corpus des groupes nominaux
qui peuvent ?tre consid?r?s comme de termes candidats. Il fournit leur analyse syntaxique sous
forme d?une d?composition en t?te et modifieur. L?extraction des termes est r?alis?e sur des
crit?res linguistiques (patrons d?analyse simples utilis?s de mani?re r?cursive et combin?s ?
une d?sambiguisation endog?ne et la prise en compte de ph?nom?ne de variation morpho-
syntaxique). Des mesures de pond?ration statiques sont ?galement associ?es ? chaque terme
(fr?quence, TF-IDF, etc.).
Acquisition de variantes morpho-syntaxiques (Faster). L?acquisition de variantes morpho-
syntaxiques nous permet d??tendre la couverture des termes extraits par YATEA, mais aussid?am?liorer le tri et le filtrage des termes extraits.
Nous avons utilis? Faster (Jacquemin, 1997) en mode indexation libre. Il nous est ainsi possible
de reconna?tre les variantes des termes extraits par YATEA ? travers trois types de variationmorpho-syntaxique : la coordination de termes, l?insertion et la juxtaposition de modifieurs
1. http://search.cpan.org/~thhamon/Alvis-TermTagger/
2. http://search.cpan.org/~thhamon/Lingua-YaTeA/
27
et la permutation. Comme nous ne disposons pas de ressources d?rivationnelles, les variantes
d?rivationelles n?ont pas pu ?tre identifi?es.
3.2 M?thodes de pond?ration
Afin d?identifier les mots cl?s parmi les termes extraits du corpus, ceux-ci doivent ?tre tri?s par
ordre de pertinence. Pour cela, nous avons utilis? plusieurs m?thodes de pond?ration :
? la fr?quence du terme dans le document (tf)
? le TF-IDF associ? au terme (Salton et McGill, 1986)
? la position de la premi?re occurrence du terme (position). Nous consid?rons ici que les termes
situ?s au d?but du document ont un poids plus ?lev?s que ceux situ?s ? la fin. La position est
le nombre de caract?res depuis le d?but du document. Les termes sont alors tri?s dans l?ordre
d?croissant. Nous n?avons pas distingu? le r?sum? du reste du document afin d?avoir les termes
pr?sents dans le r?sum? parmi les premi?res positions.
? le cosinus de la position de la premi?re occurrence du terme (positionCos). Nous avons
fait l?hypoth?se que les termes pr?sents au d?but (notamment dans les sections r?sum? et
introduction) ou ? la fin (notamment conclusion) du document sont les plus pertinents. On
place ainsi la premi?re occurrence de chaque terme sur le cercle trigonom?trique en consid?rant
que le d?but du document est l?angle 0 et la fin l?angle 2pi. Nous avons calcul? le cosinus de
l?angle form? par la position.
? l?origine des termes (termOrigin). Les termes issus de la liste de mots cl?s sont prioritaire sur
les termes extraits par YATEA ou les variantes morpho-syntaxiques. Dans le cas des termes extraitsautomatiquement, la pond?ration peut tenir compte de l?application du filtre filtrTermino
(voir section 3.3).
3.3 Filtrage et s?lection des termes
Les termes peuvent ?tre filtr?s ou regroup?s suivant diff?rents crit?res linguistiques :
? Suppression des termes situ?s dans des phrases r?dig?s dans une langue autre que le fran?ais
(filtrLang). Les revues ?tant issues des Sciences Humaines et Sociales, les articles contiennent
des phrases exemples pouvant ?tre ?crits dans diff?rentes langues. L?extracteur de termes identi-
fie alors des termes qu?il n?est pas n?cessaire de consid?rer comme des mots cl?s. Pour identifier
la langue des phrases des articles, nous avons utilis? le module Perl Lingua::Identify 3 en
utilisant les param?tres par d?faut et ne visant ? identifier que le fran?ais, l?anglais, l?allemand,
l?espagnol et l?italien.
? Suppression des termes (modifieurs de termes complexes) ?tiquet?s comme adjectifs. Les
adjectifs correspondant ? des mots cl?s sont conserv?s (filtrAdj) lors de la t?che 1. Par
exemple, espagnol est ?tiquet? comme un adjectif mais peut correspondre ? un nom et donc ?
un mot cl?. Il est alors conserv?.
? Prise en compte de l?inclusion lexicale : les termes en position t?te d?un terme et ayant de
rang plus ?lev? dans la liste tri?e sont supprim?s (filtrInclLex). Par exemple, dans la liste tri?e
(Verbes supports, traduction, paraphrase, traduction automatique), le terme traduction sera
supprim? car celui-ci est inclus dans le terme traduction automatique.
3. http://search.cpan.org/~ambs/Lingua-Identify/
28
? Regroupement des termes en fonction de leur forme canonique (concat?nation des lemmes
des composants) et filtrage par la forme fl?chie la plus fr?quente (filtrCan).
? S?lection des termes contenant au moins un mot plein issu de la liste des mots cl?s (filtrTermino).
Nous faisons l?hypoth?se que si les mots cl?s sont compos?s de mots caract?ristiques du do-
maine (en ?cartant les mots vides), il est possible de conserver les termes compos?s de ces
mots. Nous avons ?galement associ? ? chaque terme, un poids correspondant ? la proportion
de mots caract?ristiques pr?sents parmi les mots composants le terme.
Les filtres filtrAdj et filtrTermino sont appliqu?s avant le tri de la liste de termes par ordre de
pertinence, tandis que les autres sont utilis?s avec la liste des termes tri?s. La liste r?sultante de
ce filtrage est ensuite r?duite au nombre de mots cl?s attendus pour chaque document.
4 Exp?rimentations
Nous avons r?alis? plusieurs exp?riences afin d?identifier les combinaisons de param?tres les
plus adapt?s pour l?identification des mots cl?s. L?ensemble des traitements a ?t? r?alis? dans la
plate-forme Ogmios (Hamon et Nazarenko, 2008). Chaque corpus a ?t? segment? en mots et en
phrases. Nous avons utilis? le TreeTagger (Schmid, 1997) pour l??tiquetage morpho-syntaxique
et la lemmatisation des mots. En fonction des param?tres des exp?riences, nous avons utilis? au
moins un des trois outils terminologiques (TermTagger, YATEA, Faster) d?crits ? la section 3.1. Leslistes de termes ont ensuite ?t? tri?es et filtr?es en combinant plusieurs param?tres.
A partir des r?sultats sur le corpus d?entra?nement, nous avons d?fini 3 runs pour les t?ches 1
et 2. Pour tous les runs, nous avons effectu? un filtrage sur la langue (filtrLang) et les adjectifs
(filtrAdj).
T?che 1 (utilisation de la liste des mots cl?s)
? Run 1 : Les termes sont identifi?s ? l?aide du TermTagger en exploitant la liste des mots cl?s
fournie par le d?fi. Suite aux r?sultats sur le corpus d?entra?nement, nous avons choisi de
diff?rencier les m?thodes de filtrage en fonction des sous-corpus. Ainsi, pour les sous-corpus
RSE, TTR et META, nous avons exploit? la position des termes pour trier la liste, alors que
pour le sous-corpus AS, les termes sont tri?s en fonction du produit des poids positionCos et
tf. Le filtre filtrInclLex est ensuite appliqu? pour r?duire la liste des termes et s?lectionner les
mots cl?s.
? Run 2 : Nous avons exploit? TermTagger et YATEA pour extraire les termes du corpus. Le filtrefiltrTermino a ?t? appliqu? pour d?une part s?lectionner les termes les plus pertinents, d?autre
part pour associer le poids termOrigin aux termes extraits par YATEA. La liste des termes aensuite ?t? tri?e en fonction de la m?thode de pond?ration termOrigin et, lorsque les valeurs
sont ?gales, en fonction du poids tf.
? Run 3 : dans ce run, nous avons ?galement exploit? TermTagger et YATEA pour extraire lestermes du corpus et le filtre filtrTermino. Nous avons choisi d?utiliser diff?rents poids pour le
tri de la liste des termes en fonction des sous-corpus. Ainsi, pour les sous-corpus RSE et TTR,
nous avons exploit? le TF-IDF pour trier les termes. Pour les sous-corpus META et AS, nous
utilis? le produit des poids positionCos et tf.
29
T?che 2
? Run 1 : L?extraction des termes a ?t? r?alis? ? l?aide de YATEA. Nous avons ensuite exploit? leTF-IDF pour trier la liste des termes. Celle-ci a ensuite ?t? r?duite ? l?aide du filtre filtrCan
(regroupement des termes poss?dant les m?mes formes canoniques).
? Run 2 : Nous avons utilis? YATEA pour extraire les termes du corpus et Faster. La liste destermes a ?t? tri?e en fonction du produit des poids positionCos et TF-IDF, et r?duite ? l?aide
du filtre filtrCan.
? Run 3 : Les termes ont ?t? extraits ? l?aide de YATEA. Nous avons utilis? le produit des poidspositionCos et tf pour trier les termes. Les termes ont ensuite ?t? s?lectionn? ? l?aide du filtre
filtrCan.
5 R?sultats et discussion
Les r?sultats obtenus sur le corpus de test sont pr?sent?s dans le tableau 2. Le meilleur run
de la t?che 1 obtient une F-mesure de 0,39. Il s?agit de projeter les mots cl?s et de les trier en
fonction de leur position. Les exp?rimentations sur les corpus d?entra?nement ont montr? que
les param?tres li?s ? la position (position et positionCos) ont une influence sur les r?sultats.
Les r?sultats obtenus sur les deux autres runs semblent montrer que la fr?quence des termes
d?gradent l?identification des mots cl?s. Enfin, sur le corpus d?entra?nement, nous avons observ?
que seulement 72 % des mots cl?s projet?s avec TermTagger ?taient pr?sents dans le corpus 4,
et que l?utilisation de YATEA permet d?augmenter l?g?rement les r?sultats (+0,5 %). De m?me,YATEA permet d?identifier 55 % des mots cl?s.
En ce qui concerne la t?che 2, nous obtenons une F-mesure de 0,19 pour le meilleur run. Il s?agit
de trier les termes extraits avec YATEA, en fonction du produit des poids positionCos et de lafr?quence dans le document, les termes ?tant ensuite regroup?s et filtr?s en fonction de leur
forme canonique.
Run t?che 1 T?che 2
Pr?cision Rappel F-mesure Pr?cision Rappel F-mesure
1 0,3985 0,3985 0,3985 0,1798 0,1798 0,1798
2 0,3333 0,3333 0,3333 0,1612 0,1612 0,1612
3 0,2253 0,2253 0,2253 0,1921 0,1921 0,1921
TABLE 2 ? R?sultats sur le corpus de test
L?analyse des r?sultats montre que lorsque la liste des mots cl?s est fournie, la position de la
premi?re occurrence de termes est pr?pond?rante lors des phases de tri et de s?lection. Par
ailleurs, l?utilisation d?un extracteur de termes permet de couvrir correctement les mots cl?s
? identifier.Enfin, les mesures de pond?ration globales telles que le TF-IDF ne permettent pas
d?obtenir des r?sultats satisfaisants (le constat est le m?me avec la CValue (Maynard et Ananiadou,
2000)).
4. Il s?agit d?un calcul du rappel l?g?rement diff?rent de celui utilis? par les organisateurs du d?fi.
30
6 Conclusion
Nous avons exploit? des approches d?di?es ? l?acquisition terminologique pour identifier des
mots cl?s dans des corpus d?articles scientifiques des Sciences Humaines et Sociales. Les listes de
termes extraites ont ?t? tri?es et filtr?es ? l?aide de m?thodes de pond?ration (position, fr?quence
au sein du document, TF-IDF, etc.) et de crit?res linguistiques. Les r?sultats obtenus montrent
l?importance de la prise en compte de la position dans cette t?che quel que soit le cas de figure.
En revanche, une m?thode de pond?ration globale comme le TF-IDF ne semble pas ?tre tr?s utile
dans ce contexte applicatif.
Les approches d?acquisition terminologique et notamment les extracteurs de termes, permettent
d?obtenir une couverture relativement correcte, mais il est n?cessaire de poursuivre les inves-
tigations sur les mesures statistiques permettant de trier au mieux les termes extraits. Nous
envisageons par la suite d?utiliser l?algorithme de Page Rank (Page et al, 1998) pour trier et
filtrer les termes. De m?me la structure des documents pourraient ?tre exploit?s beaucoup plus,
notamment en prenant en compte la pr?sence des termes dans le r?sum? ou les diff?rentes sec-
tions du document (le titre des documents n??tait malheureusement pas disponible lors du d?fi,
mais il nous semble qu?il pourrait ?tre important de le prendre en compte). Enfin, l?identification
automatique des mots cl?s pourrait ?tre con?ue comme une t?che d?assistance aux r?dacteurs des
documents. Dans ce cas de figure, il serait int?ressant de pouvoir ?valuer l?apport des diff?rentes
approches en calculant une pr?cision sur les n premiers termes ou un pourcentage de la liste.
R?f?rences
AUBIN, S. et HAMON, T. (2006). Improving term extraction with terminological resources. In
SALAKOSKI, T., GINTER, F., PYYSALO, S. et PAHIKKALA, T., ?diteurs : Advances in Natural Language
Processing (5th International Conference on NLP, FinTAL 2006), num?ro 4139 de LNAI, pages
380?387. Springer.
HAMON, T. et NAZARENKO, A. (2008). Le d?veloppement d?une plate-forme pour l?annotation
sp?cialis?e de documents web : retour d?exp?rience. Traitement Automatique des Langues,
49(2):127?154.
JACQUEMIN, C. (1997). Variation terminologique : Reconnaissance et acquisition automatiques
de termes et de leurs variantes en corpus. M?moire d?habilitation ? diriger des recherches en
informatique fondamentale, Universit? de Nantes.
MAYNARD, D. et ANANIADOU, S. (2000). Identifying terms by their family and friends. In
Proceedings of COLING 2000, pages 530?536, Saarbrucken, Germany.
PAGE, L., BRIN, S., MOTWANI, R. et WINOGRAD, T. (1998). The pagerank citation ranking : Bringing
order to the web. Rapport technique, Stanford Digital Library Technologies Project.
SALTON, G. et MCGILL, M. J. (1986). Introduction to Modern Information Retrieval. McGraw-Hill,
Inc., New York, NY, USA.
SCHMID, H. (1997). Probabilistic part-of-speech tagging using decision trees. In JONES, D. et
SOMERS, H., ?diteurs : New Methods in Language Processing Studies in Computational Linguistics.
31

