META-COMPILING TEXT GRAMMARS 
AS A MODEL FOR HUMAN BEHAVIOR 
Sheldon Klein 
Computer Sciences Department 
University of Wisconsin 
I. BACKGROUND 
In our efforts to model the totality of 
synchronic and diachronic language behavior 
in complex social groups, we developed a 
meta-symbolic simulation system that 
includes a powerful behavioral simulation 
programming language that models, generates 
and manipulates events in the notation of a 
semantic network that changes through time, 
and a generalized, semantics-to-surface 
structure generation mechanism that can 
describe changes in the semantic universe in 
the syntax of any natural language for which 
a grammar is supplied. Because the system 
is a meta-theoretical device, it can handle 
generative semantic grammars formulated 
within a variety of theoretical frameworks. 
A key feature of the system is that the 
semantic deep structure of the non-verbal, 
behavioral rules may be represented in the 
same network notation as the semantics for 
natural language grammars, and, as a 
consequence, provide non-verbal context for 
linguistic rules. 
We are also experimenting with a 
natural language meta-compiling capability, 
that is, the use of the semantic network to 
generate productions in the simulation 
language itself -- productions in the form 
of "texts" that may themselves be compiled 
as new behavioral rules during the flow of 
the simulation -- rules that may themselves 
control the process of deriving new rules. 
This feature permits non-verbal behavioral 
rules to be derived from natural language 
conversational inputs, and through inference 
techniques identical with those for 
inferring natural language generative 
semantic grammars. The total system has the 
power of at least the 2nd order predicate 
calculus, and will facilitate the 
formulation of highly abstract meta-models 
of discourse, including the logical 
quantification of such models. 
Achievements with the generative 
portion of the system include a text grammar 
model that generates 2100 word murder 
mystery stories in less than 19 seconds 
each, complete with calculation of the plot 
and specification of the deep structure as 
well as the surface syntax (Klein et al
1973). The speed of this generation is 100 
to 1000 times faster than other existing 
programs using transformational grammars. 
(The algorithm for the semantics-to-surface 
structure generative component is such that 
processing time increases only linearly as a 
funct ion  of sentence length and syntactic 
complexity.) 
More recent achievements include models 
of portions of Levi-Strauss" mythology work 
in The Raw & the Cooked (Levi-Strauss 1969) 
and a model for Propp's Morphology of the 
84 
! 
Folktale (Propp 1968) which generated 50 
Russian fairytales, according to the ru les  ? 
of his text grammar, at an average speed of i 128 words a second, again including plot 
computations and specification of deep 
structure as well as surface syntax (Klein i 
et al1974, Klein et al 1975). I 
Our earliest automatic text generation 
work used syntactic dependency 
network/graphs with 2-valued labelling of ? 
edges as an approximation to semantic | 
network/graphs with multi-valued labelling 
of edges (Klein & Simmons 1963, Klein 1965a, 
1965b). i 
Our work on automatic inference of I 
grammars includes the world's first program 
for learning context free, phrase structure 
grammars, for both natural and artificial 
languages, and the first program for 
learning transformational grammars (Klein 
1967, Klein et al1968, Klein & Kuppin 
1970). More recent inference work includes 
the formulation of techniques for automatic 
inference of generative semantic grammars 
(Klein 1973) and for the ontogeny of Pidgin 
and Creole languages (Klein & Rozencvejg 
1974). 
I 
I 
I 
I 
The text grammarian movement, centered 
in Germany and Holland, includes work such I 
as that of van Dijk, Ihwe, Pet~fi and Rieser l (1972), Pet6fi and Rieser (1973), Pet~fi 
(1973), van Dijk (1973), and van Dijk and 
Pet6fi (1974). The underlying motivation of J 
this group is the belief that Chomskian I derived linguistic theories are inadequate 
to handle the complexities of complex 
narrative and discourse -- that more 
powerful logical devices are needed. An ? 
attempted refutation of the text grammarian Q 
position appeared in Dascal & Margalit 
(1974). Our own work on Propp and 
Levi-Strauss models refutes the refutation J 
by demonstration (Klein et al1974). I 
! 
To provide the reader with an intuitive 
view of the nature of a text grammar, we 
offer the following two Russian fairytales 
generated by our automated model of Propp 
(Klein et al1974). The same text grammar 
I 
In formulating components for automatic 
inference of rules in the meta-symbolic 
simulation system, we find that the common 
notation for the semantics of the non-verbal 
behavioral simulation rules and natural 
language means that the same learning 
heuristics may be used to infer behavioral 
rules as well as linguistic rules. The ? 
implication is that the totality of human | 
verbal and non-verbal behavior, in complex 
social groups, both synchronically and 
diachronically, may now be modelled within 
the same notational framework. What for us I started as a generalized device for testing 
varying theoretical models as part of an 
effort to model language change and 
variation (Klein 1974a, Klein & Rozencvejg I 
1974) now appears as the basis for a higher m level theory of the linguistic basis of 
human behavior (Klein 1974b). 
i 
II. WHAT IS A TEXT GRAMMAR? I 
generated both s tor ies  from a structural  
model at a level of abstract ion that 
provided a semantic unif icat ion of the 
apparent surface diversity. 
Tale I 
THE BORISIEVICHES LIVE IN A DISTANCE 
PROVINCE. 
THE FATHER IS EMELYA. 
THE ONLY SON IS BORIS. 
MARTHA IS THE ONLY DAUGHTER. 
EMELYA HAS THE SHEEP. 
BORIS, MARTHA AND THE SHEEP ARE IN THE 
WOODS. 
BORIS SAYS MARTHA, DO NOT LEAVE THE WOODS. 
BORIS LEAVES TO GO BERRY GATHERING. 
MARTHA LEAVES THE WOODS. 
A WOLF APPEARS IN THE DISTANT PROVINCE. 
EMELYA ASKS THE WOLF WHERE IS YOUR 
WISDOM. 
THE WOLF SAYS THAT MY WISDOM IS IN A MAGIC 
EGG. 
THE WOLF PLUNDERS THE SHEEP. 
EMELYA SENDS MARTHA TO SEARCH FOR THE WOLF. 
MARTHA DECIDES TO SEARCH FOR THE WOLF. 
MARTHA LEAVES ON A SEARCH. 
MARTHA MEETS A WITCH ALONG THE WAY. 
THE WITCH PROPOSES THAT MARTHA LISTEN TO THE 
GUSLA WITHOUT FALLING ASLEEP. 
MARTHA RESPONDS BY STAYING AWAKE WHILE 
LISTENING TO THE GUSLA. 
A MAGIC WAFER IS CONSUMED BY MARTHA. 
MARTHA OBTAINS SUPER-HUMAN STRENGTH. 
MARTHA TRAVELS TO THE LOCATION OF THE WOLF 
IN ANOTHER KINGDOM. 
MARTHA IS DIRECTED BY A HEDGEHOG. 
MARTHA FINDS THE WOLF 
THEY FIGHT IN AN OPEN FIELD. 
MARTHA IS WOUNDED. 
MARTHA DEFEATS THE WOLF WITH THE AID OF 
SUPER-HUMAN STRENGTH. 
THE WOLF IS CAUGHT BY MARTHA. 
MARTHA STARTS BACK HOME. 
MARTHA RETURNS HOME. 
Tale 2 
THE MOREVNAS LIVE IN A DISTANT PROVINCE. 
THE FATHER IS EREMA. 
THE MOTHER IS VASILISA. 
THE OLDEST SON IS BALDAK. 
THE YOUNGER SON IS MARCO. 
THE YOUNGEST SON IS BORIS. 
THE OLDEST DAUGHTER IS MARIA. 
THE YOUNGER DAUGHTER IS KATRINA. 
THE YOUNGEST DAUGHTER IS MARTHA. 
NICHOLAS ALSO LIVES IN THE SAME LAND. 
NICHOLAS IS OF MIRACULOUS BIRTH. 
BALDAK HAS A MAGIC STEED. 
A BEAR APPEARS IN THE DISTANT PROVINCE. 
THE BEAR SEIZES THE MAGIC STEED. 
BALDAK CALLS FOR HELP FROM NICHOLAS. 
NICHOLAS DECIDES TO SEARCH FOR THE MAGIC 
STEED. 
NICHOLAS LEAVES ON A SEARCH. 
NICHOLAS MEETS A JUG ALONG THE WAY. 
THE JUG IS FIGHTING WITH ELENA OVER A MAGIC 
BOW. 
THE JUG ASKS NICHOLAS TO DIVIDE THE MAGIC 
BOW. 
NICHOLAS TRICKS THE DISPUTANTS INTO LEAVING 
THE MAGIC BOW UNPROTECTED. 
THE MAGIC BOW, A MAGIC CARPET AND A MAGIC 
BOX ARE SEIZED BY NICHOLAS. 
NICHOLAS TRAVELS TO THE LOCATION OF THE 
MAGIC STEED IN ANOTHER KINGDOM. 
NICHOLAS BY THE MAGIC CARPET. 
NICHOLAS FINDS THE BEAR. 
NICHOLAS SURPRISES THE BEAR. 
NICHOLAS KILLS THE BEAR WITH THE AID OF THE 
MAGIC BOW. 
THE MAGIC STEED APPEARS FROM THE MAGIC BOX. 
NICHOLAS STARTS BACK HOME. 
THE BEAR'S FATHER CHASES AFTER NICHOLAS. 
NICHOLAS ESCAPES BY FLYING ON A FALCON. 
NICHOLAS RETURNS HOME. 
III. THE KEY QUESTION 
We perceive the locus of theoret ical  
interest to  be the process of verbal and 
non-verbal  behavior transmission across 
generations. Our work on model l ing speech 
communit ies includes designs for s imulat ions 
in which many model led individuals, each 
with his own semantic network, his own 
grammar(s),  his own behavior rules, interact 
with each other according to the model led 
rules of the social structure of the society 
(Klein 1974a). 
It is our hope to be able to model the 
t ransmiss ion process of all the rules in the 
system. This means that newly born model led 
indiv iduals  wil l  infer rules for natural  
language and also for non-verba l  behavioral  
s imulat ion rules, as a function of inputs of 
texts suppl ied by other model led 
individuals.  The texts may be verbal 
discourse, or non-verbal  sequences of 
behavior. The learning individual wil l  
actual ly  compile and recompile new versions 
of his own behavioral  rules as the 
s imulat ion process proceeds. His own test 
product ions of behavior scenarios as well as 
natural  language discourse wil l  be subject 
to evaluat ion and possible correct ion by 
o ther  members of the model led community, and 
their react ions as well as the consequences 
of the productions,  wil l  serve as a control  
on the entire learning process. And, as 
indicated earlier, the rules to be inferred, 
compiled and recompi led will include rules 
that govern the process of inference and 
compi lat ion itself. 
IV. LOGICAL QUANTIFICATION, SEMANTIC 
PARSING, PRESUPPOSIT IONAL ANALYSIS 
We have ment ioned the 2nd order or 
higher predicate calculus. For our 
purposes, the essential  feature is that the 
logical quant i f icat ion of the rules may be 
quant i f ied by the contents of the rules 
themselves. Meta-compi l ing of rules 
governing meta-compi l ing is an example of 
this process. 
There are other techniques avai lable. 
The behavioral  rules operate with h igh- level  
classes that make it possible to formulate 
rules that can treat objects, characters and 
complex act ions as mani festat ions of the 
85 
same abstract semantic Unit. A major type 
of behavior rule modif icat ion and extension 
is the abi l i ty to requantify the rules as a 
heurist ic function of experience. The 
process does not involve 
recompi lat ion -- rather modif icat ion of the 
domain of appl icabi l i ty  of an existing rule. 
One of the types of semantic parsing 
possible in the system is the determinat ion 
of the presupposit ions of the semantic 
content of input text. The scenario rules 
that could have generated the text have 
precondit ions, and these precondit ions also 
have their own precondit ions as specif ied by 
other rules. In cases where the semantic 
content of an input text is not potent ia l ly  
derivable from exist ing behavioral  rules, 
the system can posit requant i f icat ion 
(assignments and reassignments to semantic 
classes) to make the input text derivable. 
Or, if necessary, the same end can be 
achieved by compi l ing new rules that would 
make the text plausible. 
General izat ion of the method makes it 
possible to build complex learning models 
for highly abstract, semantical ly  driven 
text grammars. Perhaps the ult imate test is 
the model l ing of the heurist ic processes of 
Levi-Strauss. We hope to be able to build a 
model that learns text grammars with 
arb i t rar i ly  abstract semantics such as that 
manifested in Levi -Strauss (1969). At the 
moment, we are working on model l ing the text 
grammar he himself  has derived (Klein et al
1975). The potential  of our work is to 
handle a degree and kind of abstract ion in 
semantics heretofore untouched by 
l inguistics, including the model l ing of the 
automatic creation of text grammars for 
dreams and myths as a function of cultural  
rules. 
V. GENERALITY OF THE META-SYMBOLIC 
SIMULATION SYSTEM AS A THEORY TESTING DEVICE 
Our methodology and programming sty le 
have y ie lded a system wherein all the rules, 
and even the form of the theories in which 
they are cast, are input as data. As far as 
we can determine, this permits us to encode 
in our system virtual ly  all the theoret ical  
models current ly prevalent in l inguistics, 
plus heretofore unformulated models of 
vastly greater power. (Prel iminary work in 
the classroom, for example, indicates that 
models of the work of Schank and his 
students may easi ly be implemented in our 
system, with an increased speed of execution 
of about 50 to I in favor of our versions.) 
VI. THE METHODOLOGICAL SIGNIFICANCE OF OUR 
WORK 
Our work over the years has suggested 
and reinforced the fol lowing methodologica l  
principles: 
I. No s igni f icant theories can be 
formulated in L inguist ics that are 
not computed based. 
86 
2. The theoret ical  foundations of 
Computer Science are identical  with 
those of Linguist ics.  
3. Theoret ical  l inguistic models that 
are not strongly l inked to 
object ive tasks are meaningless. 
No semantics is meaningful  except 
in terms of the object ive tasks it 
faci l itates. 
4. The future of Linguistics, 
Computat ional  Linguist ics,  
Art i f ic ia l  Intel l igence, 
Psychological  models of human 
behavior, are in the future of the 
Foundat ions of Programming 
Languages and the Theory of 
Operat ing Systems. The human mind 
is at least as compl icated as an 
operat ing system for a 4th 
generat ion computer. 
5. An adequate l inguist ic theory must 
account for the function of 
language in social groups and its 
t ransmiss ion through time and 
space. At the same time, such a 
theory must account for the highest 
semantic atta inments of the human 
mind, including l i terature and art, 
and, in fact, the total i ty of 
symbolic processes. 
6. Input/output equ iva lence  of model 
and model led does not imply 
isomorphism between model and 
modelled. (Chomskian bel iefs to 
the contrary have their roots in 
Leibniz" Theory of Monads and its 
required ontological  argument.)  
There are no models of performance, 
only models of competence which can 
be compared, one against the other, 
for accuracy in predict ing 
relat ions between input and output 
in real world systems. 
VII. THEORETICAL IMPLICATIONS 
A. The Non- inateness of Human 
Structures 
Mental 
Our work const i tutes a refutat ion by 
counter example of the necessity for a 
correlat ion between models of human mental  
structures and the structure of the human 
brain. (A software system can operate with 
no inherent isomorphisms with a part icular  
computer.)  Nothing need be innate except the 
meta-compi l ing capacity and the percept ion 
of time. 
Our work suggests the logical 
poss ib i l i ty  that the human mind can learn to 
learn, and learn how to learn to learn, and 
that each human may do it dif ferently.  The 
basic pr inciples of language inference, 
which can be derived from a behavior ist ic  
psychological  framework, can alone account 
for the structur ing of mental processes as a 
software phenomenon, independent of 
physio logical  reality. It fol lows that 
humans can have dif ferent rules, di f ferent 
data structures, di f ferent h ierarchical  
D 
! 
! 
I 
II 
i 
! 
II 
! 
! 
! 
! 
! 
! 
i 
I 
I 
i 
organizations, where the only control l ing 
factor is the requirement that the 
internal ized models permit the individuals 
to function and interact with the inputs and 
outputs of other individuals in a social 
group. 
B. History as the Meta- language of 
History 
Implicit in our approach is an 
alternat ive to the concept of an infinite 
hierarchy of meta- languages, as formulated 
by Bertrand Russell in his Theory of Types 
in Principia Mathematica (Whitehead & 
Russell 1911-1913). The concept of 
successive states of time, each linked with 
the possibi l i ty of defining (meta-compil ing) 
new rules of the universe for the next 
state, ( including the rules for defining new 
rules), suggests that there need be only a 
single meta- language and a single language 
in any state at any point in time, and that 
each serves, in turn, as the meta- language 
for the other in successive time frames. 
This is not a stochastic process. 
It is the concepts of time and 
meta-compi l ing that appear to be the 
fundamental  aspects of human cognition. The 
principle may be universal  for all human 
behavioral /symbol ic  processes, and students 
of the ph i losophy  of history wil l  now 
recognize our meta-symbol ic  s imulat ion 
system as equivalent to an automated 
Hegel ian dialectic phi losophy which 
specif ies that each successive state of 
histor ical  development is control led by the 
meta- language of its previous state, and 
becomes the meta- language of its successor 
state. 
REFERENCES 
Dascal, M. and A. Margal it  1974. A new 
"revolution" in 
l inguist ics? -- "Text-grammars" vs. 
"sentence-grammars."  Theoret ical  
Linguistics, 1:195-213 
van Dijk, T.A. (ed), 1973, Text Grammar and 
Narrat ive Structures. Poetics 3. 
van Dijk, T.A., J. Ihwe, J.S. Pet~fi and 
H. Rieser 1972, Zur Best immung von 
narrat iven Strukturen auf der Grundlage 
von Textgrammatiken. 
Verlag. 
Hamburg: Buske 
van Dijk, T.A. and J. Pet~fi (eds) 1974. 
Grammars and Descriptions. Ber l in- -New 
York: de Gruyter. 
Klein, S. 1965a. Automatc paraphrasing in 
essay format. Mechanical  Translat ion 
8.3/4:68-83. 
.... 1965b. Control of style with a 
generat ive grammar. Language 41: 
619-631. 
1967. Current research in the computer 
s imulat ion of histor ical  change in 
language. Actes d__uu X e Congres 
87 
Internat ional  des Linguistics. Bucharest 
1967. 
.... 1973. Automatic inference of semantic 
deep structure rules in generative 
semantic Grammars. Univ. if Wisconsin 
Comp. Sci. Tech Report 180. Also in 
1974. Computat ional  and Mathematical  
Linguistics, Proceedings of the Int. 
Conf. on Computat ional  Linguistics, 
Pisa, 1973. A. Zampolli, ed., Florence: 
Olschki 
.... 1974a. Computer simulation of language 
contact models. In Towards Tomorrow's 
Linguistics, Shuy & Bailey, editors, 
Washington, D.C.: Georgetown University 
Press. 
.... 1974b. A computer model for the 
l inguist ic basis of the transmission of 
culture. Presented at 1974 Meeting of 
American Anthropological  Association, 
Mexico City, Nov. 1974. (Final draft in 
preparation) 
Klein, S., J.F. Aeschlimann, D.F. 
Balsiger, S.L. Converse, C. Court, M. 
Foster, R. Lao, J.D. Oakley, and J. 
Smith 1973. AUTOMATIC NOVEL WRITING: a 
status report. Univ. of Wisc. Comp. 
Sci. Dept. Tech Report 186. Presented 
at 1973 Int. Conf. on Computers in the 
Humanities. 
Klein, S., J.F. Aeschlimann, M.A. 
Appelbaum, D.F. Balsiger, E.J. Curtis, 
M. Foster, S.D. Kalish, S.J. Kamin, 
Y-D. Lee, L.A. Price, D.F. Salsieder. 
1974. Model l ing Propp and Levi-Strauss 
in a Meta-symbol ic  Simulat ion System. 
Univ. of Wisc. Comp. Sci. Tech Report 
226. In press in Patterns in Oral 
Literature, edited by Heda Jason and 
Dimitr i  Segal as a retroact ive 
contr ibut ion to this volume of the 1973 
Wolrd Conference of Anthropological  and 
Ethnological  Sciences. Chicago. 
Klein, S., W. Fabens, R. Herriot, W. 
Katke, M.A. Kuppin, A. Towster 1968. 
The AUTOLING system. Univ. of Wisc. 
Comp. Sci. Dept. Tech Report 43. 
Klein, S. and M.A. Kuppin 1970. An 
interactive, heurist ic program for 
learning transformat ional  grammars. 
Computer Studies in the Humanit ies and 
Verbal Behavior, 3:144-162. 
Klein, S., L.A. Price, J.F. Aeschlimann, 
D.A. Bals iger and E.J. Curtis, 1975. A 
Meta-symbol ic  Simulat ion Model for Five 
Myths from Levi -Strauss" The Raw and the 
Cooked. Univ. of Wisc. Comp. Sci. 
Dept. Tech Report Presented at 2nd Int. 
Conf. on Computers in the Humanities, 
Chicago, Apri l  1975. 
Klein, S. and V. Rozencvejg 1974. A 
Computer Model for the Ontogeny of Pidgin 
and Creole Languages, Univ. of Wisc. 
Comp. Sci. Dept. Tech Report 238. 
Presented at the 1975 Int. Conf. on 
Pidgins and Creoles, Hawaii, January 
1975. 
Klein, S. and R .F .  Simmons 1963. 
Syntactic dependence and the computer 
generation of coherent discourse. 
Mechanical Translation 7:50-61. 
Levi-Strauss, C. 1969, The Raw and the 
Cooked. (English translation) New York: 
Harper & Row. 
PetSfi, J.S. 1973. Toward an empirically 
motivated grammatical theory of verbal 
texts. In Studies in Text Grammar, 
edited by J.S. Petofi & H. Rieser. 
Dordrecht: Reidel. 
Pet~fi, J.S. & H. Rieser 1973. Probleme 
der modelltheoretischen Interpretation 
yon Texten. Hamburg: Buske Verlag. 
Propp, V. 1968. Morphology of the Folkt~le 
(English translation) 2nd Edition, 
Austin: University of Texas Press. 
Whitehead, A.N. and B. Russell 1911-1913. 
Princip~a Mathematica. (3 volumes 
London: Cambridge University Press. 
88 
I 
It 
II 
I 
I 
