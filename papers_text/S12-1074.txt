First Joint Conference on Lexical and Computational Semantics (*SEM), pages 519?523,
Montre?al, Canada, June 7-8, 2012. c?2012 Association for Computational Linguistics
NJU-Parser: Achievements on Semantic Dependency Parsing 
Guangchao Tang1 Bin Li1,2 Shuaishuai Xu1 Xinyu Dai1 Jiajun Chen1 
1 State Key Lab for Novel Software Technology, Nanjing University 
2 Research Center of Language and Informatics, Nanjing Normal University 
Nanjing, Jiangsu, China 
{tanggc, lib, xuss, dxy, chenjj}@nlp.nju.edu.cn 
 
Abstract 
In this paper, we introduce our work on 
SemEval-2012 task 5: Chinese Semantic De-
pendency Parsing. Our system is based on 
MSTParser and two effective methods are 
proposed: splitting sentence by punctuations 
and extracting last character of word as lemma. 
The experiments show that, with a combina-
tion of the two proposed methods, our system 
can improve LAS about one percent and final-
ly get the second prize out of nine participat-
ing systems. We also try to handle the multi-
level labels, but with no improvement. 
1 Introduction 
Task 5 of SemEval-2012 tries to find approaches to 
improve Chinese sematic dependency parsing 
(SDP). SDP is a kind of dependency parsing. Cur-
rently, there are many dependency parsers availa-
ble, such as Eisner?s probabilistic dependency 
parser (Eisner, 1996), McDonald?s MSTParser 
(McDonald et al 2005a; McDonald et al 2005b) 
and Nivre?s MaltParser (Nivre, 2006). 
Despite of elaborate models, lots of problems 
still exist in dependency parsing. For example, sen-
tence length has been proved to show great impact 
on the parsing performance. (Li et al, 2010) used a 
two-stage approach based on sentence fragment for 
high-order graph-based dependency parsing. Lack-
ing of linguistic knowledge is also blamed. 
Three methods are promoted in this paper try-
ing to improve the performance: splitting sentence 
by commas and semicolons, extracting last charac-
ter of word as lemma and handling multi-level la-
bels. Improvements could be achieved through the 
first two methods while not for the third. 
2 Overview of Our System 
Our system is based on MSTParser which is one of 
the state-of-the-art parsers. MSTParser tries to ob-
tain the maximum spanning tree of a sentence. For 
projective parsing task, it takes Eisner?s algorithm 
(Eisner, 1996) to get the dependency tree in O(n3) 
time. Meanwhile, Chu-Liu-Edmond?s algorithm 
(Chu and Liu, 1965) is applied for non-projective 
task, which takes O(n2) time. 
Three methods are adopted to MSTParser in our 
system: 
1) Sentences are split into sub-sentences by 
commas and semicolons, for which there 
are two ways. Splitting sentences by all 
commas and semicolons is used in our 
primary system. In our contrast system, we 
use a classifier to determine whether a 
comma or semicolon can be used to split 
the sentence. In the primary and contrast 
system, the proto sentences and the sub-
sentences are trained and tested separately 
and the outputs are merged in the end. 
2) In a Chinese word, the last character usual-
ly contains main sense or semantic class. 
We treat the last character of the word as 
word lemma and find it gets a slightly im-
provement in the experiment. 
3) An experiment trying to solve the problem 
of multi-level labels was conducted by 
parsing different levels separately and con-
sequently merging the outputs together. 
The experiment results have shown that the first 
two methods could enhance the system perfor-
mance while further improvements could be ob-
tained through a combination of them in our sub-
submitted systems. 
519
 
a) The proto sentence from train data 
                       
b) The first sub sentence of a)                         c) The second sub sentence of a) 
Figure 1. An example of the split procedure. 
 
3 Experiments 
3.1 Split sentences by commas and semicolons 
It is observed that the performance decreases as 
the length of the sentences increases. Table 1 
shows the statistical analysis on the data including 
SemEval-2012, Conll-07?s Chinese corpus and a 
subset extracted from CTB using Penn2Malt. Long 
sentence can be split into sub-sentences to get bet-
ter parsing result.  
 
Items 
SemEval
-2012 
Conll-
07 CN 
CTB 
Postages count 35 13 33 
Dependency 
labels count 
122 69 12 
Average sentence 
length 
30.15 5.92 25.89 
Average 
dependency length 
4.80 1.71 4.36 
LAS 61.37 82.89 67.35 
UAS 80.18 87.64 79.90 
Table 1. Statistical analysis on the data. The CTB data is 
a subset extracted from CTB using Penn2Malt. 
 
Our work can be described as following steps: 
Step 1: Use MSTParser to parse the data. We 
name the result as ?normal output?. 
Step 2: Split train and test data by all commas 
and semicolons. The delimiters are removed in the 
sub sentences. For train data, a word?s dependency 
relation is kept if the word?s head is under the cov-
er of the sub sentence. Otherwise, its head will be 
set to root and its label will be set to ROOT (ROOT 
is the default label of dependency arcs whose head 
is root). We define the word as ?sentence head? if 
its head is root. ?Sub-sentence head? indicates the 
sentence head of a sub-sentence. After splitting, 
there may be more than one sub-sentence heads in 
a sub-sentence. Figure 1 shows an example of the 
split procedure. 
Step 3: Use MSTParser to parse the data gener-
ated in step 2. We name the parsing result ?split 
output?. In split output, there may be more than 
one sub-sentences corresponding to a single sen-
tence in normal output. 
Step 4: Merge the split output and the normal 
output. The outputs of sub-sentences are merged 
with delimiters restored. Dependency relations are 
recovered for all punctuations and sub-sentence 
heads in split output with relations in normal out-
put. The sentence head of normal output is kept in 
final output. The result is called ?merged split out-
put?. This step need to be consummated because it 
may result in a dependency tree not well formed 
with several sentence heads or even circles. 
The results of experiments on develop data and 
test data are showed in table 2. For develop data, 
an improvement of 0.85 could be obtained while 
0.93 for test data, both on LAS. 
In step 2, there is an alternative to split the sen-
tences, i.e., using a classifier to determine which 
comma and semicolon can be split. This method is 
taken in the contrast system. When applying the 
classifier, all commas and semicolons in train data 
520
are labeled with S-IN or S-STOP while other 
words with NULL. If the sub sentence before the 
comma or semicolon has only one sub-sentence 
head, it is labeled with S-STOP, otherwise with S-
IN. A model is built from train data with CRF++ 
and test data is evaluated with it. Features used are 
listed in table 3. Only commas and semicolons 
with label S-STOP can be used to split the sen-
tence in step 2. Other steps are the same as above. 
The result is also shown in table 2 as ?merged split 
output with CRF++?. 
 
Data Methods LAS UAS 
Develop 
data 
normal output 61.37 80.18 
merged split output 62.22 80.56 
merged split output 
with CRF++ 
61.97 80.73 
lemma output 61.64 80.47 
primary system output 62.41 80.96 
contrast system output 62.05 80.90 
Test 
 data 
normal output 60.63 79.37 
merged split output 61.56 80.17 
merged split output 
with CRF++ 
61.42 80.20 
lemma output 60.88 79.42 
primary system output 61.63 80.35 
contrast system output 61.64 80.29 
Table 2. Results of the experiments. 
 
w-4,w-3,w-2,w-1,w,w+1,w+2,w+3,w+4 
p-4,p-3,p-2,p-1,p,p+1,p+2,p+3,p+4 
wp-4,wp-3,wp-2,wp-1,wp wp+1,wp+2,wp+3,wp+4 
w-4|w-3,w-3|w-2,w-2|w-1,w-1|w, 
w|w+1,w+1|w+2,w+2|w+3,w+3|w+4 
p-4|p-3,p-3|p-2,p-2|p-1,p-1|p, 
p|p+1,p+1|p+2,p+2|p+3,p+3|p+4 
first word of sub-sentence before the delimiter 
Table 3. Features used in CRF++. w represents for word 
and p for PosTag. +1 means the index after current 
while -1 means before. 
3.2 Extract last character of word as lemma 
In Chinese, the last character of a word usually 
contains main sense or semantic class, which indi-
cates that it may represent the whole word. For 
example, ? ? ?(country) can represent ? ?
? ?(China) and ?? ?(love) can represent ??
??(crazy love).  
The last character is used as lemma in the ex-
periment, with an improvement of 0.27 for LAS on 
develop data and 0.24 on test data. Details of the 
scores are listed in table 2 as ?lemma output?. 
3.3 Multi-level labels experiment 
A notable characteristic of SemEval-2012?s da-
ta is multi-level labels. It introduces four kinds of 
multi-level labels which are s-X, d-X, j-X and r-X. 
The first level represents the basic semantic rela-
tion of the dependency while the second level 
shows the second import, except that s-X repre-
sents sub-sentence relation.  
The r-X label means that a verb modifies a 
noun and the relation between them is reverse. For 
example, in phrase ???(poor) ??(born) ? ?
?(star)?, ???? is headed to ???? with label r-
agent. It means that ???? is the agent of ????. 
When a verbal noun is the head word and its 
child has indirect relation to it, the dependency is 
labeled with j-X. In phrase ???(school) ??
(construction)?, ???? is the head of ???? with 
label j-content. ???? is the content of ????. 
The d-X label means that the child modifies the 
head with an additional relation. For example, in 
phrase ???(technology) ??(enterprise)?, ??
?? modifies ???? and the domain of ???? is 
????. 
A heuristic method is tried in the experiment. 
The multi-level labels of d-X, j-X and r-X are sep-
arated into two parts for each level. For example, 
?d-content? will be separated to ?d? and ?content?. 
For each part, MSTParser is used to train and test. 
We call the outputs ?first-level output? and ?se-
cond-level output?. The outputs of each level and 
normal output are merged then. 
In our experiments, only the word satisfies the 
following conditions need to be merged: 
a) The dependency label in normal output is 
started with d-, j- or r-. 
b) The dependency label in first-level output is 
d, j or r. 
c) The heads in first-level output and second-
level output are of the same. 
Otherwise, the dependency relation in normal 
output will be kept. There are also three ways in 
merging outputs: 
a) Label in first-level output and label in se-
cond-level output are merged. 
b) First level label in normal output and label 
in second-level output are merged. 
c) Label in first-level output and second level 
label in normal output are merged. 
521
Experiment has been done on develop data. In 
the experiment, 24% of the labels are merged and 
92% of the new merged labels are the same as 
original. The results of three ways are listed in ta-
ble 4. All of them get decline compared to normal 
output. 
 
outputs LAS UAS 
normal output 61.37 80.18 
way a) 61.18 80.18 
way b) 61.25 80.18 
way c) 61.25 80.18 
Table 4. Results of multi-level labels experiment on 
develop data. 
3.4 Combined experiment on split and lemma 
Improvements are achieved by first two meth-
ods in the experiment while a further enhancement 
is made with a combination of them in the submit-
ted systems. The split method and lemma method 
are combined as primary system. The split method 
with CRF++ and lemma method are combined as 
contrast system. When combining the two methods, 
last character of the word is firstly extracted as 
lemma for train data and test data. Then the split or 
split with CRF++ method is used. 
The outputs of the primary system and contrast 
system are listed in table 2.  
4 Analysis and Discussion 
The contrast system presented in this paper finally 
got the second prize among nine systems. The pri-
mary system gets the third. There is an improve-
ment of about one percent for both primary and 
contrast system. The following conclusions can be 
made from the experiments: 
1) Parsing is more effective and accurate on 
short sentences. A word prefers to depend 
on another near to it. A sentence can be 
split to several sub sentences by commas 
and semicolons to get better parsing output. 
Result may be improved with a classifier to 
determine whether a comma or semicolon 
can be used to split the sentence. 
2) Last character of word is a useful feature. 
In the experiment, the last character is 
coarsely used as lemma and a minor im-
provement is achieved. Much more lan-
guage knowledge can be used in parsing. 
3) The label set of the data is worthy to be re-
viewed. The meanings of the labels are not 
given in the task. Some of them are confus-
ing especially the multi-level labels. The 
trying of training and testing multi-level la-
bels separately by levels fails with a slight-
ly decline of the score. Multi-level also 
causes too many labels: any single-level la-
bel can be prefixed to form a new multi-
level label. It?s a great problem for current 
parsers. Whether the label set is suitable to 
Chinese semantic dependency parsing 
should be discussed. 
5 Conclusion and Future Work 
Three methods applied in NJU-Parser are de-
scribed in this paper: splitting sentences by com-
mas and semicolons, taking last character of word 
as lemma and handling multi-level labels. The first 
two get improvements in the experiments. Our 
primary system is a combination of the first two 
methods. The contrast system is the same as prima-
ry system except that it has a classifier implement-
ed in CRF++ to determine whether a comma or a 
semicolon should be used to split the sentence. 
Both of the systems get improvements for about 
one percent on LAS. 
In the future, a better classifier should be devel-
oped to split the sentence. New method should be 
applied in merging split outputs to get a well 
formed dependency tree. And we hope there will 
be a better label set which are more capable of de-
scribing semantic dependency relations for Chi-
nese. 
Acknowledgments 
This paper is supported in part by National Natural 
Science Fund of China under contract 61170181, 
Natural Science Fund of Jiangsu under contract 
BK2011192, and National Social Science Fund of 
China under contract 10CYY021. 
References 
Y.J. Chu and T.H. Liu. 1965. On the shortest arbores-
cence of a directed graph. Science Sinica, 14:1396?
1400. 
MSTParser: 
http://www.seas.upenn.edu/~strctlrn/MSTParser/MS
TParser.html 
522
J. Eisner. 1996. Three new probabilistic models for de-
pendency parsing: An exploration. In Proc. COLING. 
J. Nivre. 2006. Inductive Dependency Parsing. Springer. 
R. McDonald, K. Crammer, and F. Pereira. 2005. 
Online Large-Margin Training of Dependency 
Parsers. 43rd Annual Meeting of the Association for 
Computational Linguistics (ACL 2005). 
R. McDonald, F. Pereira, K. Ribarov, and J. Haji?. 2005. 
Non-projective Dependency Parsing using Spanning 
Tree Algorithms. Proceedings of HLT/EMNLP 2005. 
Zhenghua Li, Wanxiang Che, Ting Liu. 2010. Improv-
ing Dependency Parsing Using Punctuation. Interna-
tional Conference on Asian Language 
Processing(IALP) 2010. 
523
