Proceedings of the 2012 Workshop on Language in Social Media (LSM 2012), pages 1?8,
Montre?al, Canada, June 7, 2012. c?2012 Association for Computational Linguistics
Analyzing Urdu Social Media for Sentiments using Transfer Learning 
with Controlled Translations 
 
 Author 2 
Smruthi Mukund Rohini K Srihari 
CEDAR, Davis Hall, Suite 113 CEDAR, Davis Hall, Suite 113 
University at Buffalo, SUNY, Buffalo, NY University at Buffalo, SUNY, Buffalo, NY 
smukund@buffalo.edu rohini@cedar.buffalo.edu 
 
 
 
 
 
Abstract 
The main aim of this work is to perform sen-
timent analysis on Urdu blog data. We use the 
method of structural correspondence learning 
(SCL) to transfer sentiment analysis learning 
from Urdu newswire data to Urdu blog data. 
The pivots needed to transfer learning from 
newswire domain to blog domain is not trivial 
as Urdu blog data, unlike newswire data is 
written in Latin script and exhibits code-
mixing and code-switching behavior. We con-
sider two oracles to generate the pivots. 1. 
Transliteration oracle, to accommodate script 
variation and spelling variation and 2. Trans-
lation oracle, to accommodate code-switching 
and code-mixing behavior.  In order to identi-
fy strong candidates for translation, we pro-
pose a novel part-of-speech tagging method 
that helps select words based on POS catego-
ries that strongly reflect code-mixing behav-
ior. We validate our approach against a 
supervised learning method and show that the 
performance of our proposed approach is 
comparable. 
1 Introduction 
The ability to break language barriers and under-
stand people's feelings and emotions towards soci-
etal issues can assist in bridging the gulf that exists 
today. Often emotions are captured in blogs or dis-
cussion forums where writers are common people 
empathizing with the situations they describe. As 
an example, the incident where a cricket team vis-
iting Pakistan was attacked caused widespread an-
guish among the youth in that country who thought 
that they will no longer be able to host internation-
al tournaments. The angry emotion was towards 
the failure of the government to provide adequate 
protection for citizens and visitors. Discussion fo-
rums and blogs on cricket, mainly written by Paki-
stani cricket fans, around the time, verbalized this 
emotion. Clearly analyzing blog data helps to esti-
mate emotion responses to domestic situations that 
are common to many societies. 
Traditional approaches to sentiment analysis re-
quire access to annotated data. But facilitating such 
data is laborious, time consuming and most im-
portantly fail to scale to new domains and capture 
peculiarities that blog data exhibits; 1. spelling var-
iations and 2. code mixing and code switching. 3. 
script difference (Nastaliq vs Latin script). In this 
work, we present a new approach to polarity classi-
fication of code-mixed data that builds on a theory 
called structural correspondence learning (SCL) 
for domain adaptation. This approach uses labeled 
polarity data from the base language (in this case, 
Urdu newswire data - source) along with two sim-
ple oracles that provide one-one mapping between 
the source and the target data set (Urdu blog data).  
Subsequent sections are organized as follows. 
Section 2 describes the issues seen in Urdu blog 
data followed by section 3 that explains the con-
cept of structural correspondence learning. Section 
4 details the code mixing and code switching be-
havior seen in blog data. Section 5 describes the 
statistical part of speech (POS) tagger developed 
for blog data required to identify mixing patterns 
followed by the sentiment analysis model in sec-
tion 6. We conclude with section 7 and briefly out-
line analysis and future work in section 8. 
1
2 Urdu Blog Data 
Though non-topical text analysis like emotion de-
tection and sentiment analysis, have been explored 
mostly in the English language, they have also 
gained some exposure in non-English languages 
like Urdu (Mukund and Srihari, 2010), Arabic 
(Mageed et al., 2011) and Hindi (Joshi and 
Bhattacharya, 2012). Urdu newswire data is writ-
ten using Nastaliq script and follows a relatively 
strict grammatical guideline. Many of the tech-
niques proposed either depend heavily on NLP 
features or annotated data. But, data in blogs and 
discussion forums especially written in a language 
like Urdu cannot be analyzed by using modules 
developed for Nastaliq script for the following rea-
sons; (1) the tone of the text in blogs and discus-
sion forums is informal and hence differs in the 
grammatical structure (2) the text is written using 
Latin script (3) the text exhibits code mixing and 
code switching behavior (with English) (4) there 
exists spelling errors which occur mostly due to the 
lack of predefined standards to represent Urdu data 
in Latin script. 
Urdish (Urdu blog data) is the term used for 
Urdu, which is (1) written either in Nastaliq or Lat-
in script, and (2) contains several English 
words/phrases/sentences.  In other words, Urdish is 
a name given to a language that has Urdu as the 
base language and English as the seasoning lan-
guage. With the wide spread use of English key-
boards these days, using Latin script to encode 
Urdu is very common. Data in Urdish is never in 
pure Urdu. English words and phrases are com-
monly used in the flow integrating tightly with the 
base language. Table 1 shows examples of differ-
ent flavors in which Urdu appears in the internet. 
Differ-
ent 
Forms 
of Data 
Main Issues Example Sentence 
1. Urdu 
written 
in Nasta-
liq 
1.  Lack of tools for 
basic operations such 
as segmentation and 
diacritic restoration 
2. Lack of sufficient 
annotated data for 
POS and NE tagging 
3.  Lack of annotated 
data for more ad-
vanced NLP  
??? ?????? ?? ???? 
????? ?? ??? ???? 
[ The soldiers were 
angry with a lot of 
people] 
 
2. Urdu 
written 
in ASCII 
1.  Several variations 
in spellings that need 
to be normalized 
Wo Mulk Jisko Hum 
nay 1000000 logoon 
sey zayada Loogoon 
(Eng-
lish) 
2.  No normalization 
standards 
3.  Preprocessing 
modules needed if 
tools for Urdu in 
Nastaliq are to be 
used 
4.  Developing a 
completely new NLP 
framework needs 
annotated data 
ki Qurbanian dey ker 
hasil kia usi mulk 
main yai kaisa waqt a 
gay hai ? 
 
[Look at what kind of 
time the land that had 
1000000?s of people 
sacrifice their lives is 
experiencing now] 
3. Urd-
ish writ-
ten in 
Nastaliq 
1.  No combined 
parser that deals with 
English and Urdu 
simultaneously 
2.  English is written 
in Urdu but with 
missing diacritics 
?? ??? ??? ????? ?? ?? 
??? ??? ???  
 
[the phones rang one 
after the other in the 
TV station] 
 
4. Urd-
ish writ-
ten in  
ASCII(
English) 
1.  No combined 
parser that deals 
with English and 
Urdu simultaneous-
ly 
2.  Issue of spelling 
variations that need 
to be normalized 
Afsoos key baat hai . 
kal tak jo batain 
Non Muslim bhi 
kartay hoay dartay 
thay abhi this man 
has brought it out in 
the open. 
 
[It is sad to see that 
those words that even 
a non muslim would 
fear to utter till yes-
terday, this man had 
brought it out in the 
open] 
Table 1: Different forms of using Urdu lan-
guage on the internet 
Blog data follows the order shown in example 
4 of table 1. Such a code-switching phenomenon is 
very common in multilingual societies that have 
significant exposure to English. Other languages 
exhibiting similar behaviors are Hinglish (Hindi 
and English), Arabic with English and Spanglish 
(Spanish with English). 
3   Structural Correspondence Learning 
For a problem where domain and data changes 
requires new training and learning, resorting to 
classical approaches that need annotated data be-
comes expensive. The need for domain adaptation 
arises in many NLP tasks ? part of speech tagging, 
semantic role labeling, dependency parsing, and 
sentiment analysis and has gained high visibility in 
the recent years (Daume III and Marcu, 2006; 
Daume III et al., 2007; Blitzer et al., 2006, Pret-
tenhofer and Stein et al., 2010). There exists two 
main approaches; supervised and semi-supervised.  
2
In the supervised domain adaptation approach 
along with labeled source data, there is also access 
to a small amount of labeled target data. Tech-
niques proposed by Gildea (2001), Roark and Bac-
chiani (2003), Daume III (2007) are based on the 
supervised approach. Studies have shown that 
baseline approaches (based on source only, target 
only or union of data) for supervised domain adap-
tion work reasonably well and beating this is sur-
prisingly difficult (Daume III, 2007).  
 In contract, the semi supervised domain adapta-
tion approach has access to labeled data only in the 
source domain (Blitzer et al., 2006; Dredze et al., 
2007; Prettenhofer and Stein et al., 2010). Since 
there is no access to labeled target data, achieving 
baseline performance exhibited in the supervised 
approach requires innovative thinking.  
The method of structural correspondence learn-
ing (SCL) is related to the structural learning para-
digm introduced by Ando and Zhang (2005). The 
basic idea of structural learning is to constrain the 
hypothesis space of a learning task by considering 
multiple different but related tasks on the same 
input space. SCL was first proposed by Blitzer et 
al., (2006) for the semi supervised domain adapta-
tion problem and works as follows (Shimizu and 
Nakagawa, 2007).  
1. A set of pivot features are defined on unla-
beled data from both the source domain and 
the target domain 
2. These pivot features are used to learn a map-
ping from the original feature spaces of both 
domains to a shared, low-dimensional real?
valued feature space. A high inner product in 
this new space indicates a high degree of cor-
respondence along that feature dimension  
3. Both the transformed and the original features 
in the source domain are used to train a learn-
ing model  
4. The effectiveness of the classifier in the source 
domain transfers to the target domain based on 
the mapping learnt 
This approach of SCL was applied in the field of 
cross language sentiment classification scenario by 
Prettenhofer and Stein (2010) where English was 
used as the source language and German, French 
and Japanese as target languages. Their approach 
induces correspondence among the words from 
both languages by means of a small number of 
pivot pairs that are words that process similar se-
mantics in both the source and the target lan-
guages. The correlation between the pivots is mod-
eled by a linear classifier and used as a language 
independent predictor for the two equivalent clas-
ses. This approach solves the classification prob-
lem directly, instead of resorting to a more general 
and potentially much harder problem such as ma-
chine translation. 
The problem of sentiment classification in blog 
data can be considered as falling in the realm of 
domain adaptation. In this work, we approach this 
problem using SCL tailored to accommodate the 
challenges that code-mixed data exhibits. Similar 
to the work done by Prettenhofer and Stein (2010), 
we look at generating pivot pairs that capture code-
mixing and code-switching behavior and language 
change.  
4 Code Switching and Code Mixing 
Code switching refers to the switch that exists from 
one language to another and typically involves the 
use of longer phrases or clauses of another lan-
guage while conversing in a totally different base 
language. Code mixing, on the other hand, is a 
phenomenon of mixing words and other smaller 
units of one language into the structure of another 
language. This is mostly inter-sentential.  
In a society that is bilingual such as that in Pa-
kistan and India, the use of English in the native 
language suggests power, social prestige and the 
status. The younger crowd that is technologically 
well equipped tends to use the switching phenom-
enon in their language, be it spoken or written. 
Several blogs, discussion forums, chat rooms etc. 
hold information that is expressed is intensely code 
mixed. Urdu blog data exhibits mix of Urdu lan-
guage with English. 
There are several challenges associated with 
developing NLP systems for code-switched lan-
guages. Work done by Kumar (1986) and Sinha & 
Thakur, (2005) address issues and challenges asso-
ciated with Hinglish (Hindi ? English) data.  
Dussias (2003) and Celia (1997) give an overview 
of the behavior of code switching occurring in 
Spanish - Spanglish. This phenomenon can be seen 
in other languages like Kannada and English, 
German and English.  Rasul (2006) analyzes the 
linguistic patterns occurring in Urdish (Urdu and 
English) language. He tries to quantize the extent 
to which code-mixing occurs in media data, in par-
ticular television. Most of his rules are based on 
3
what is proposed by Kachru (1978) for Hinglish 
and has a pure linguistic approach with manual 
intervention for both qualitative and quantitative 
analysis.  
Several automated techniques proposed for 
Hinglish and Spanglish are in the context of ma-
chine translation and may not be relevant for a task 
like information retrieval since converting the data 
to one standardized form is not required. A more 
recent work was by Goyal et al., (2003) where they 
developed a bilingual parser for Hindi and English 
by treating the code mixed language as a complete-
ly different variety. However, the credibility of the 
system depends on the availability of WordNet1.  
4.1 Understanding Mixing Patterns 
Performing analysis on data that exhibit code-
switching has been attempted by many across vari-
ous languages. Since the Urdu language is very 
similar to Hindi, in this section we discuss the 
code-mixing behavior based on a whole battery of 
work done by researchers in the Hindi language. 
Researchers have studied the behavior of the 
mixed patterns and generated rules and constraints 
on code-mixing. The study of code mixing with 
Hindi as the base language is attempted by Sinha 
and Thakur (2005) in the context of machine trans-
lation. They categorize the phenomenon into two 
types based on the extent to which mixing happens 
in text in the context of the main verb. Linguists 
such as Kachru (1996) and Poplack (1980) have 
tried to formalize the terminologies used in this 
kind of behavior. Kumar (1986) says that the moti-
vation for assuming that the switching occurs 
based on certain set of rules and constraints are 
based on the fact that users who use this can effec-
tively communicate with each other despite the 
mixed language. In his paper he proposes a set of 
rules and constraints for Hindi-English code 
switching. However, these rules and constraints 
have been countered by examples proposed in the 
literature (Agnihotri, 1998). This does not mean 
that researchers earlier had not considered all the 
possibilities. It only means that like any other lan-
guage, the language of code-mixing is evolving 
over time but at a very fast pace. 
One way to address this problem of code-mixing 
and code switching for our task of sentiment analy-
                                                          
1 http://www.cfilt.iitb.ac.in/wordnet/webhwn/ 
sis in blog data is rely on predefined rules to identi-
fy mixed words. But this can get laborious and the 
rules may be insufficient to capture the latest be-
havior. Our approach is to use a statistical POS 
model to determine part of speech categories of 
words that typically undergo such switches.  
5 Statistical Part of Speech Tagger  
Example 5.1 showcases a typical sentence seen in 
blog data. Example 5.2 shows the issue with 
spelling variations sometimes that occur in the 
same sentence 
Example 5.1: Otherwise humara bhi wohi haal hoga jo 
is time Palestine, Iraq, Afghanistan wagera ka hai ~ 
Otherwise our state will also be like what is in Pales-
tine, Iraq, Afghanistan etc. are experiencing at this time 
Example 5.2: Shariyat ke aitebaar se bhi ghaur kia jaey 
tu aap ko ilm ho jaega key joh haraam khata hai uska 
dil kis tarhan ka hota hey ~ If you look at it from morals 
point of you too you will understand the heart of people 
who cheat 
A statistical POS tagger for blog data has to take 
into consideration spelling variations, mixing pat-
terns and script change. The goal here is not to 
generate a perfect POS tagger for blog data 
(though the idea explained here can be extended 
for further improvisation) but to be able to identify 
POS categories that are candidates for switch and 
mix. The basic idea of our approach is as follows 
1. Train Latin script POS tagger (LS tagger) on 
pure Urdu Latin script data (Example 2 in table 
1 ? using Urdu POS tag set, Muaz et al., 2009) 
2. Train English POS tagger on English data 
(based on English tag sets, Santorini, 1990) 
3. Apply LS tagger and English tagger on Urdish 
data and note the confidence measures of the 
applied tags on each word 
4. Use confidence measures, LS tags, phoneme 
codes (to accommodate spelling variations) as 
features to train a new learning model on Urd-
ish data 
5. Those words that get tagged with the English 
tagset are potential place holders for mixing 
patterns  
 
Word Act Eng LS 
Urdu  
Urd 
CM 
Eng 
CM 
and CC CC NN 0.29 0.99 
most RB RB VM 0.16 0.83 
im-
portant 
JJ JJ VAUX 0.08 0.97 
thing NN NN CC 0.06 0.91 
4
Zardari NNP NNP NN 0.69 0.18 
ko PSP NNP PSP 0.99 0.28 
shoot VB NNP JJ 0.54 0.29 
ker NN NNP NN 0.73 0.29 
dena VM NNP VM 0.83 0.29 
chahiya VAUX NNP VAUX 0.98 0.21 
. SYM . SYM 0.99 0.99 
Table 2. POS tagger with confidence measures 
 
The training data needed to develop LS tagger for 
Urdu is obtained from Hindi. IIIT POS annotated 
corpus for Hindi contains data in the SSF format 
(Shakti Standard Format) (Bharati, 2006). This 
format tries to capture the pronunciation infor-
mation by assigning unique English characters to 
Hindi characters. Since this data is already in Latin 
script with each character capturing a unique pro-
nunciation, changing this data to a form that repli-
cates chat data using heuristic rules is trivial. 
However, this data is highly sanskritized and hence 
need to be changed by replacing Sanskrit words 
with equivalent Urdu words. This replacement is 
done by using online English to Urdu dictionaries 
(www.urduword.com and www.hamariweb.com). 
We have succeeded in replacing 20,000 pure San-
skrit words to Urdu by performing a manual 
lookup. The advantage with this method is that  
1. The whole process of setting up annotation 
guidelines and standards is eliminated.  
2. The replacement of pure Hindi words with Ur-
du words in most cases is one-one and the POS 
assignment is retained without disturbing the 
entire structure of the sentence. 
Our training data now consists of Urdu words writ-
ten in Latin script. We also generate phonemes for 
each word by running the phonetic model. A POS 
model is trained using CRF (Lafferty, 2001) learn-
ing method with current word, previous word and 
the phonemes as features. This model called the 
Latin Script (LS) POS model has an F-score of 
83%.  
English POS tagger is the Stanford tagger that 
has a tagging accuracy of about 98.7%2 . 
5.1 Approach 
Urdish blog data consists of Urdu code-mixed with 
English. Running simple Latin script based Urdu 
POS tagger results in 81.2% accuracy when POS 
tags on the entire corpus is considered and 52.3% 
                                                          
2 http://nlp.stanford.edu/software/tagger.shtml 
accuracy on only the English words. Running Eng-
lish tagger on the entire corpus improves the POS 
tagging accuracy of English words to 79.2% accu-
racy. However, the tagging accuracy on the entire 
corpus reduces considerably ? 55.4%. This indi-
cates that identifying the language of the words 
will definitely improve tagging.  
Identifying the language of the words can be 
done simply by a lexicon lookup. Since English 
words are easily accessible and more enriched, 
English Wordnet3 makes a good source to perform 
this lookup. Running Latin script POS tagger and 
English tagger on the language specific words re-
sulted in 79.82% accuracy for the entire corpus and 
59.2% accuracy for English words. Clearly there is 
no significant gain in the performance. This is on 
account of English equivalent Urdu representation 
of words (e.g. key ~ their, more ~ peacock, bat ~ 
speak). 
Since identifying the language explicitly yields 
less benefit, we showcase a new approach that is 
based on the confidence measures of the taggers. 
We first run the English POS tagger on the entire 
corpus. This tagger is trained using a CRF model. 
Scores that indicate the confidence with which this 
tagger has applied tags to each word in the corpus 
is also estimated (table 2). Next, the Latin script 
tagger is applied on the entire corpus and the con-
fidence scores for the selected tags are estimated. 
So, for each word, there exist two tags, one from 
the English tagger and the other from the Latin 
script Urdish tagger along with their confidence 
scores. This becomes our training corpus. 
The CRF learning model trained on the above 
corpus using features shown in table 3 generates a 
cross validation accuracy is 90.34%. The accuracy 
on the test set is 88.2%, clearly indicating the ad-
vantages of the statistical approach.  
 
Features used to train Urdish POS tagger 
Urdish word 
POS tag generated by LS tagger 
POS tag generated by English tagger 
Confidence measure by LS tagger 
Confidence measure by English tagger 
Double metaphone value 
Previous and next tags for English and Urdu 
Previous and next words 
Confidence priorities 
Table 3. Features used to train the final POS tagger 
for Urdish data 
                                                          
3 http://wordnet.princeton.edu/ 
5
Table 4 illustrates the POS categories used as po-
tential pattern switching place holders  
 
POS Category Example 
noun within a noun 
phrase 
uski life par itna control acha nahi 
hai ~ its not good to control his life 
this much 
Interjection  Comon Reema yaar! ~ Hey Man 
Reema! 
lol! ~ lol 
Adjective Yeh story bahut hi scary or ugly tha 
~ This story was really scary and 
ugly 
Adverb Babra Shareef ki koi bhi film lagti 
hai, hum definitely dekhtai ~ I would 
definitely watch any movie of Babra 
Shareef 
Gerund (tagged as a 
verb by English 
POS tagger) 
Yaha shooting mana hai ~ shooting 
is prohibited here 
Verb Iss movie main I dozed ~ I slept 
through the movie 
Verb Afridi.. Cool off!  
Table 4. POS categories that exhibit pattern switch 
6 Sentiment Polarity Detection 
The main goal of this work is to perform sentiment 
analysis in Urdu blog data. However, this task is 
not trivial owing to all the peculiarities that blog 
data exhibits. The work done on Urdu sentiment 
analysis (Mukund and Srihari, 2010) provided an-
notated data for sentiments in newswire domain. . 
Newspaper data make a good corpus to analyze 
different kinds of emotions and emotional traits of 
the people.  They reflect the collective sentiments 
and emotions of the people and in turn the society 
to which they cater. When specific frames are con-
sidered (such as semantic verb frames) in the con-
text of the triggering entities ? opinion holders 
(entities who express these emotions) and opinion 
targets (entities towards whom the emotion is di-
rected) - performing sentiment analysis becomes 
more meaningful and newspapers make an excel-
lent source to analyze such phenomena (Mukund et 
al., 2011). We use SCL to transfer sentiment anal-
ysis learning from this newswire data to blog data. 
Inspired by the work done by (Prettenhofer and 
Stein, 2010), we rely on oracles to generate pivot 
pairs. A pivot pair {wS, wT} where wS ? 9S (the 
source language ? Urdu newswire data) and wT ? 
VT (the target language ? Urdish data) should satis-
fy two conditions 1. high support and 2. high con-
fidence, making sure that the pairs are predictive of 
the task.  
Prettenhofer and Stein (2010) used a simple 
translation oracle in their experiments. However 
there exist several challenges with Urdish data that 
inhibits the use of a simple translation oracle.  
1. Script difference in the source and target 
languages. Source corpus (Urdu) is written 
in Nastaleeq and the target corpus (Urdish) 
is written in ASCII 
2. Spelling variations in roman Urdu 
3. Frequent use of English words to express 
strong emotions 
We use two oracles to generate pivot pairs.  
The first oracle accommodates the issue with 
spelling variations. Each Urdu word is converted to 
roman Urdu using IPA (1999) guidelines. Using 
the double metaphone algorithm4 phoneme code 
for the Urdu word is determined. This is also ap-
plied to Urdish data at the target end. Words that 
have the same metaphone code across the source 
and target languages are considered pivot pairs.  
The second oracle is a simple translation oracle 
between Urdu and English. Our first experiment 
(experiment 1) is using words that belong to the 
adjective part of speech category as candidates for 
pivots. We augment this set to include words that 
belong to other POS categories shown in table 4 
that exhibit pattern mixing (experiment 2).  
 
6.1 Implementation  
 
The feature used to train the learning algorithm is 
limited to unigrams. For linear classification, we 
use libSVM (Chang and Lin, 2011). The computa-
tional bottleneck of this method is in the SVD de-
composition of the dense parameter matrix W. We 
set the negative values of W to zero to get a sparse 
representation of the matrix. For SVD computation 
the Lanczos algorithm provided by SVDLIBC5 is 
employed. Each feature matrix used in libSVM is 
scaled between -1 and 1 and the final matrix for 
SVD is standardized to zero mean and unit vari-
ance estimated on DS U Du (source subset and tar-
get subset). 
6.2 Results 
The domain of the source data set is limited to 
cricket and movies in order to ensure domain over-
                                                          
4 http://en.wikipedia.org/wiki/Double_Metaphone 
5 http://tedlab.mit.edu/~dr/SVDLIBC 
6
lap between newswire data that we have and blog 
data. In order to benchmark the proposed tech-
nique, our baseline technique is based on the con-
ventional method of supervised learning approach 
on annotated data. Urdish data set used for polarity 
classification contains 705 sentences written in 
ASCII format (example 6.1). This corpus is manu-
ally annotated by one annotator (purely based on 
intuition and does not follow any predefined anno-
tation guidelines) to get 440 negative sentences 
and 265 positive sentences. The annotated corpus 
is purely used for testing and in this work consid-
ered as unlabeled data. A suitable linear kernel 
based support vector machine is modeled on the 
annotated data and a five-fold cross validation on 
this set gives an F-Measure of 64.3%. 
Example 6.1: 
General zia-ul-haq ke zamane mai qabayli elaqe Russia 
ke khilaf jang ka merkaz thea aur general Pervez 
Musharraf ke zamane mai ye qabayli elaqe Pakistan ke 
khilaf jang ka markaz ban gye . ~ negative 
Our first experiment is based on using the se-
cond oracle for translations on only adjectives 
(most obvious choice for emotion words). We use 
438 pivot pairs. The average F-measure for the 
performance is at 55.78% which is still much be-
low the baseline performance of 64.3% if we had 
access to annotated data. However, the results 
show the ability of this method. 
Our second experiment expands the power of 
the second oracle to provide translations to other 
POS categories that exhibit pattern switching. This 
increased the number of pivot pairs to 640. In-
crease in pivots improved the precision. Also we 
see significant improvement in the recall. The new-
ly added pivots brought more sentences under the 
radar of the transfer model. The average F-
Measure increased to 59.71%.  
The approach can be further enhanced by im-
proving the oracle used to select pivot features. 
One way is add more pivot pairs based on the cor-
relation in the topic space across language domains 
(future work).  
7 Conclusion 
In this work we show a way to perform sentiment 
analysis in blog data by using the method of struc-
tural correspondence learning. This method ac-
commodates the various issues with blog data such 
as spelling variations, script difference, pattern 
switching. 
 
Table 5. SCL based polarity classification for Urdish data 
We rely on two oracles, one that takes care of 
spelling variations and the other that provides 
translations. The words that are selected to be 
translated by the second oracle are carefully cho-
sen based on POS categories that exhibit emotions 
and pattern switching. We show that the perfor-
mance of this approach is comparable to what is 
achieved by training a supervised learning model. 
In order to identify the POS categories that exhibit 
pattern switching, we developed a statistical POS 
tagger for Urdish blog data using a method that 
does not require annotated data in the target lan-
guage. Through these two modules (sentiment 
analysis and POS tagger for Urdish data) we suc-
cessfully show that the efforts in performing non-
topical analysis in Urdu newswire data can easily 
be extended to work on Urdish data. 
8 Future work 
Analyzing the test data set for missing and false 
positives, here are some of the examples of where 
the model did not work 
Example 7.1: ?tring tring tring tring.. Phone to bar bar 
bajta hai. Annoying.? ~ tring tring tring tring tring.. 
the phone rings repeatedly. Annoying. 
Example 7.2: ?bookon ko padna tho ab na mumkin hai. 
Yaha thak mere friends mujhe blindee pukarthey hai? ~ 
cannot read books any more. Infact, my friends call me 
blindee. 
Example 7.3: ?Ek Tamana Hai Ke Faqt Mujh Pe 
Mehrban Raho, Tum Kise Or Ko Dekho To Bura Lagta 
Hai? ~ I have this one wish that destiny be kind to me 
If you see someone else I feel bad 
Our method fails to tag sentences like in example 
7.1 where English verbs are used by themselves. 
Our POS tagger fails to capture such stand-alone 
Precision (P %) Recall (R %) F-Measure (F %) 
Phonemes (Roman Urdu) 
37.97 58.82 46.15 
Metaphones based synonym mapping (adjectives) 
50.9 51 50.89 
56.6 56.4 55.62 
58.9 60.64 59.75 
Precision (P %) Recall (R %) F-Measure (F %) 
Metaphones based synonym mapping (adjectives + other 
POS categories) 
54.2 64.3 58.82 
58.4 60.85 59.6 
59.4 62.12 60.73 
7
verbs as verbs but tags them as nouns. Hence, 
GRHVQ?W RFFXU LQ WKH SLYRW VHW  
Our second issue is with Morpho syntactic 
switching, a behavior seen in example 7.2. 
Nadhkarni (1975) and Pandaripande (1983) have 
shown that when two or more languages come into 
contact, there is mutual feature transfer from one 
language to another. The languages influence each 
other considerably and constraints associated with 
free morphemes fail in most cases. The direction 
and frequency of influence depends on the social 
status associated with the languages used in mix-
ing. The language that has a high social status 
tends to use the morphemes of the lower language.  
Example 7.4: Bookon ? in books, Fileon ? in files, 
Companiyaa ? many companies 
Clearly we can see that English words due to their 
frequent contact with Urdu grammatical system 
tend to adopt the morphology associated with the 
base language and used mostly as native Urdu 
words. These are some issues, if addressed, will 
definitely improve the performance of the senti-
ment analysis model in Urdish data. 
References  
