Proceedings of the SIGDIAL 2011: the 12th Annual Meeting of the Special Interest Group on Discourse and Dialogue, pages 332?334,
Portland, Oregon, June 17-18, 2011. c?2011 Association for Computational Linguistics
An Incremental Architecture for the Semantic Annotation of Dialogue
Corpora with High-Level Structures. A case of study for the MEDIA corpus.?
Lina Maria Rojas-Barahona and Matthieu Quignard
LORIA/INRIA, France
{lina.rojas,matthieu.Quignard}@loria.fr
Abstract
The semantic annotation of dialogue cor-
pora permits building efficient language un-
derstanding applications for supporting en-
joyable and effective human-machine interac-
tions. Nevertheless, the annotation process
could be costly, time-consuming and compli-
cated, particularly the more expressive is the
semantic formalism. In this work, we propose
a bootstrapping architecture for the semantic
annotation of dialogue corpora with rich struc-
tures, based on Dependency Syntax and Frame
Semantics.
1 Introduction
We propose a cooperative architecture that incre-
mentally generates and improves the annotation of
the French MEDIA dialogue corpus with high-level
semantics (HLS), as a result of the cooperation of
several linguistic modules. MEDIA is a French cor-
pus that has collected about 70 hours of spontaneous
speech from the task of hotel room reservation. It
contains transcribed utterances1 that have been man-
ually segmented2 and annotated with a flat seman-
tics i.e.,concept-value pairs (Bonneau-Maynard et
al., 2005).
?This work is supported by the Agence Nationale de la
Recherche (ANR) in France and is part of the French Project
PORT-MEDIA.
1Utterances with ellipsis, disfluencies, false starts, reformu-
lations, repetitions and ungrammaticalities and special charac-
ters such as the symbol ?*? that indicates uncertainty due to
noise in the communication channel.
2The term Segment means sequence of words in utterances.
The HLS semantics, namely the MultiModal In-
terface Language formalism (MMIL) (Denis et al,
2010), augments the expressivity of the flat seman-
tics by representing communicative actions, predi-
cates, arguments and fine-grained features. Commu-
nicative actions are components built up from two
types of entity (i.e. events and participants), which
are linked together by relations and described by
sets of features (attribute-value pairs). It is possible
to identify in entities a set of main features, which
can be domain-specific. For the semantic annota-
tion, components are mapped to segments in utter-
ances. Figure 1 shows the canonical representation
of an utterance in the corpus in compliance with the
specifications for the annotation3.
2 The Architecture
The architecture (Figure 2) for the automatic anno-
tation has been formulated as a post-interpretation
process that takes place after the syntactic analysis
and semantic role labeling (SRL). Two linguistic re-
sources interact within the architecture, the corpus
and the Frames4. Four linguistic modules are in-
volved in the annotation: the Part-Of-Speech (POS)
tagger, the parsing, the semantic-role labeling (SRL)
and the HLS Builder. The common knowledge base
comprises two knowledge-bases (one for the domain
and the other for the HLS formalism) together with a
relational database management system (RDBMS).
The knowledge bases assure the coherence of the an-
3http://www.port-media.org/doku.php?id=
mmil_for_annotating_media
4Frames is the process in which the frames and frame ele-
ments (FE) are defined.
332
Speak
Request
Reserver
(Reserve)
Personne
(People)
Chambre
(Room)
indef.
je (I)
Ville
(City)
Niort
propContent
patient
aObjetRe?serve?
aBe?ne?ficiaires
aLocalisation
Entities Segment Features=Value
Communicative Act:Request je voudrais ... a` Niort
Main Event:Reserve faire une re?servation
Participant 1:Pronoun je
Participant 2:Chambre d? une chambre
une refType=indefinite
chambre objType=Chambre
Figure 1: HLS representation for the French utterance ?je voudrais
faire une re?servation d? une chambre pour une personne a` Niort? (So I
would like to make a reservation for a room for one person in Niort).
It shows a request to reserve: the communicative action is Request the
main event is Reserve. Note that the beneficiary and the patient are two
different roles, the beneficiary is the person, not necessarily the same
speaker, who will use the object reserved (e.g. rooms). The patient is
the speaker. The segmentation of the HLS Component is presented in
the Table, the component is mapped to the whole utterance. The fine-
grained segmentation of features is shown for the Participant 2.
notation while the database assures persistence and
data integrity. The database stores the corpus, the
frames, the results at each level of analysis, as well
as the progress in the annotation. The persistence
permits progressively optimizing the algorithms un-
til the desired annotation is obtained and integrated
into the corpus files. The corpus manager is in
charge of the resources management. Last but not
least, two annotation tools were built: one for the
SRL gold standard (web-based) and the other for the
HLS gold standard (standalone).
Syntactic Analysis. We decided to employ sta-
tistical approaches that could learn the irregularities
of spoken language: the French Tree-Tagger5 and
the dependency-based MALT-PARSER (Nivre et al,
2007). The parser has been trained with 1449 utter-
ances annotated according to the annotation guide-
lines described in (Cerisara and Gardent, 2009).
5http://www.ims.uni-stuttgart.de/
?schmid/
Figure 2: General Architecture for the HLS Annotation.
Definition of Frames. Frame Semantics, (Baker
et al, 1998) arranges common background knowl-
edge for situations by grouping verbal, nominal
causative and non-causative predicates. Neverthe-
less, paraphrases are more used in spoken language
than explicitly uttered nouns, adjectives or verbs for
referring to a situation (e.g.?ask?, ?request? or ?de-
mand?). Here we introduce the term: Frame Evok-
ing Phrase (FEP) for evoking frames and we in-
clude syntactic templates that mirror these phrases
in frames and frame elements (FE). Table 1 summa-
rizes the differences between PORT-MEDIA frames
and FrameNet (Baker et al, 1998).
FrameNet PORT-MEDIA
Frames
Lexical Units Lexical Units, POS tags and templates
MEDIA Flat Semantics
Frame Elements
Lexical Units, Phrase Type Lexical Units, POS tags, templates
and Grammatical Function and dependency relation
Semantic Type Semantic Type
and MEDIA flat semantics
Table 1: Static Characteristics of Frames in FrameNet
and in PORT-MEDIA.
Semantic Role Labeling. We built a rule-based
semantic role labeling for detecting frames and FE
(roles) by using dependency tree-template pattern
matchers that exploit the information already com-
pressed in frames. The SRL detects the bound-
aries of FEP and FE by measuring the syntactic and
semantic similarity between the utterance and the
frame.
HLS Builder.The HLS Builder is the last phase in
the annotation process: it is rule-based and it takes
utterances in the corpus with their flat semantics, de-
333
pendency trees and predicates-arguments and builds
the HLS representation (See Figure 1), according to
the specifications for the annotation and the knowl-
edge bases. The dialogue act and main event in
HLS components can be detected from the predi-
cates. Similarly, secondary events and participants
with their features can be detected from the roles and
the flat semantics.
3 Evaluation and Discussion
For evaluating the system we separately com-
puted the accuracy of its linguistic components.
The parser achieved a label attachment score
(LAS) (Nivre et al, 2007) of 86.16%, with a train-
ing set of 1097 utterances and a test-set of 100 utter-
ances. The SRL was evaluated with metrics adapted
from the CONLL 2005 evaluation (Carreras and
Ma`rquez, 2005) for supporting FEP and allowing
overlapped FEP for different frames. The LAS was
computed by comparing the semantic dependencies
of system?s and gold?s propositions6 and their seg-
ments. The gold standard comprises 115 utterances
annotated with the major frames in the domain:
Request, Reserve and Attributes. The F1-measure
computed for propositions with exactly the same
segments was 56.66%. When verifying whether the
segments contain the same syntactic governor, the
SRL achieves a better score: 71.30%. Finally, vary-
ing the number of excluded words in both segments7
yielded a constant increase of the F1-measure un-
til a maximum of 84.27%. The HLS annotation
was evaluated by measuring the similarity between
gold?s and system?s components with a gold stan-
dard of 330 complex utterances related to the reser-
vation task. When rigorously measuring the equal-
ity of components8, we obtained a F1-measure of
57.79%. Measuring equality of components with-
out being so rigorous with features? segmentation,
yielded a slightly higher score 63.31%. Finally,
when measuring equality of components by taking
6A proposition is a structure containing the predicate, their
arguments and the semantic relation between them.
7From 1 to n words not common in both segments.
8Two HLS components are equal if their entities and rela-
tions are equal. Two entities are equal if they have the same
segment and features (feature name and feature value) and if
these features are mapped to the same segments in the utter-
ance. Two relations are equal if they have the same source and
target entities as well as the same name
into account only the main features of entities, we
obtained a higher score: 70.65%.
We proposed an architecture for corpus manage-
ment that allows incremental updates over persistent
information until a more accurate semantic annota-
tion is obtained. The preliminary results show a gen-
eral agreement when defining the main features and
the main entities in HLS components and a disagree-
ment when segmenting fine-grained features. We
observed that the system tends to create new entities
when it detects repetitions or references in long ut-
terances. Defining a more precise segmentation pol-
icy in the manual annotation guidelines, augmenting
the training data for parsing, as well as integrating
reference resolution and disambiguation techniques,
will enhance the annotation process. An appealing
research direction would be to integrate and evaluate
machine learning components in the architecture.
References
He?le`ne Bonneau-Maynard and Matthieu Quignard and
Alexandre Denis. 2005. MEDIA: A semantically an-
notated corpus of task oriented dialogs in French. Lan-
guage Resources and Evaluation.
Alexandre Denis and Lina M. Rojas-Barahona and
Matthieu Quignard. 2010. Extending MMIL Seman-
tic Representation: Experiments in Dialogue Systems
and Semantic Annotation of Corpora. In: Proceedings
of the Fifth ISO-ACL/SIGSEM Workshop on Interoper-
able Semantic Annotation (ISA-5), Hong Kong.
Collin Baker and Charles Fillmore and John Lowe. 1998.
The Berkeley FrameNet Project. Proceedings of the
17th International Conference on Computational lin-
guistics, 86?90. Association for Computational Lin-
guistics.
Joakim Nivre and Johan Hall and Sandra Ku?bler and
Ryan McDonald and Jens Nilsson and Sebastian
Riedel and Deniz Yuret. 2007. The CoNLL 2007
Shared Task on Dependency Parsing. Proceedings of
the CoNLL Shared Task Session of EMNLP-CoNLL
2007. Prague, Czech Republic:915?932. Association
for Computational Linguistics.
Christophe Cerisara and Claire Gardent. 2009. Anal-
yse syntaxique du franc?ais parle?. Journe?e the?matique
ATALA Quels analyseurs syntaxiques pour le franc?ais.
Xavier Carreras and Llu??s Ma`rquez. 2005. Introduc-
tion to the CoNLL-2005 shared task: Semantic role
labeling. CONLL ?05: Proceedings of the Ninth Con-
ference on Computational Natural Language Learning.
152?164. Association for Computational Linguistics.
334
