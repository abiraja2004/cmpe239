Parsing Parallel Grammatical Representations 
Derrick Higgins 
Department  of Linguistics 
University of Chicago 
1050 East 59th Street 
Chicago, IL 60626 
dchiggin@midway.uchicago.edu 
Abst rac t  
Traditional accounts of quantifier scope em- 
ploy qualitative constraints or rules to account 
for scoping preferences. This paper outlines 
a feature-based parsing algorithm for a gram- 
mar with multiple simultaneous levels of repre- 
sentation, one of which corresponds to a par- 
tial ordering among quantifiers according to 
scope. The optimal such ordering (as well as 
the ranking of other orderings) is determined 
in this grammar not by absolute constraints, 
but by stochastic heuristics based on the de- 
gree of alignment among the representational 
levels. A Prolog implementation is described 
and its accuracy is compared with that of other 
accounts. 
1 In t roduct ion  
It has long been recognized that the possibility 
and preference rankings of scope readings de- 
pend to a great degree on the position of scope- 
taking elements in the surface string (Chomsky, 
1975; Hobbs and Shieber, 1987). Yet most tra- 
ditional accounts of semantic scopal phenomena 
in natural anguage have not directly tied these 
two factors together. Instead, they allow only 
certain derivations to link the surface structure 
of a sentence with the representational level 
at which scope relations are determined, place 
constraints upon the semantic feature-passing 
mechanism, or otherwise mulate a constraint 
which requires some degree of congruence be- 
tween the surface syntax of a sentence and its 
preferred scope reading(s). 
A simpler and more direct approach is sug- 
gested by constraint-based, multistratal theo- 
ries of grammar (Grimshaw, 1997; Jackendoff, 
1997; Sadock, 1991; Van Valin, 1993). In these 
models, it is possible to posit multiple represen- 
tational evels for a sentence without according 
ontological primacy to any one of them, as in 
all varieties of transformational grammar. This 
allows constraints to be formulated which place 
limits on structural discrepancies between lev- 
els, yet need not be assimilated into an overrid- 
ing derivational mechanism. 
This paper will examine the model of one of 
these theories, Autolexical Grammar (Sadock, 
1991; Sadock, 1996; Schiller et al, 1996), as it 
is implemented in a computational scope gen- 
erator and critic. This left-corner chart parser 
generates urface syntactic structures for each 
sentence (as the only level of syntactic represen- 
tation), as well as Function-Argument seman- 
tic structures and Quantifier/Operator-Scope 
structures. These latter two structures together 
determine the semantic interpretation of a sen- 
tence. 
It will be shown that this model is both 
categorical enough to handle standard gener- 
alizations about quantifier scope, such as bans 
on extraction from certain domains, and fuzzy 
enough to present reasonable preference rank- 
ings among scopings and account for lexical 
differences in quantifier strength (Hobbs and 
Shieber, 1987; Moran, 1988). 
2 A Mu l t id imens iona l  Approach  to  
Quant i f ie r  Scoping 
2.1 The  Auto lex ica l  Mode l  
The framework of Autolexical Grammar treats 
a language as the intersection of numerous inde- 
pendent CF-PSGs, or hierarchies, each of which 
corresponds to a specific structural or functional 
aspect of the language. Semantic, syntactic, 
morphological, discourse-functional and many 
other hierarchies have been introduced in the 
literature, but this project focuses on the in- 
teractions among only three major hierarchies: 
Surface Syntax, Function-Argument S ructure, 
545 
and Operator Scope Structure. 
The surface syntactic hierarchy is a feature- 
based grammar expressing those generalizations 
about a sentence which are most clearly syn- 
tactic in nature, such as agreement, case, and 
syntactic valency. The function-argument hi-
erarchy expresses that (formal) semantic infor- 
mation about a sentence which does not involve 
scope resolution, e.g., semantic valency and as- 
sociation of referential terms with argument po- 
sitions, as in Park (1995). The operator scope 
hierarchy, naturally, imposes a scope ordering 
on the quantifiers and operators found in the 
expression. Two other, minor hierarchies are 
employed in this implementation. The linear or- 
dering of words in the surface string is treated 
as a hierarchy, and a lexical hierarchy is intro- 
duced in order to express the differing lexical 
"strength" of quantifiers. 
Each hierarchy can be represented as a tree 
in which the terminal nodes are not ordered 
with respect o one another. This implies that, 
for example, \[John \[saw Mary\]\] and \[Mary \[saw 
John\]\] will both be acceptable syntactic rep- 
resentations for the surface string Mary saw 
John. The optimal set of hierarchies for a string 
consists of the candidate hierarchies for each 
level of representation which together are most 
structurally congruous. The structural similar- 
ity between hierarchies is determined in Au- 
tolexical Grammar by means of an Alignment 
Constraint, which in the implementation de- 
scribed here counts the number of overlapping 
constituents in the two trees. Thus, while struc- 
tures similar to \[Mary \[saw John\]\] and \[John 
\[saw Mary\]\] will both be acceptable as syntac- 
tic and function-argument structure representa- 
tions, the alignment constraint will strongly fa- 
vor a pairing in which both hierarchies share the 
same representation. Structural hierarchies are 
additionally evaluated by means of a Contigu- 
ity Constraint, which requires that the terminal 
nodes of each constituent of a hierarchy should 
be together in the surface string, or at least as 
close together as possible. 
2.2 Quantifier Ordering Heuristics 
The main constraints which this model places 
on the relative scope of quantifiers and opera- 
tors are the alignment of the operator scope hi- 
erarchy with syntax, function-argument struc- 
ture, and the lexical hierarchy of quantifier 
strength. The first of these constraints reflects 
"the principle that left-to-right order at the 
same syntactic level is preserved in the quan- 
tifier order" 1 and accounts for syntactic extrac- 
tion restrictions. The second will favor operator 
scope structures in which scope-taking elements 
are raised as little as possible from their base ar- 
gument positions. The last takes account of the 
scope preferences of individual quantifiers, such 
as the fact that each tends to have wider scope 
than all other quantifiers (Hobbs and Shieber, 
1987; Moran, 1988). 
As an example of the sort of syntactically- 
based restrictions on quantifier ordering which 
this model can implement, consider the general- 
ization listed in Moran (1988), that "a quanti- 
fier cannot be raised across more than one ma- 
jor clause boundary." Because the approach 
pursued here already has a general constraint 
which penalizes candidate parses according to 
the degree of discrepancy between their syntax 
and scope hierarchies, we do not need to accord 
a privileged theoretical status to "major clause 
boundaries." 
Figure 1 illustrates the approximate optimal 
structure accorded to the sentence Some pa- 
tients believe all doctors are competent on the 
syntactic and scopal hierarchies, in which an 
extracted quantifier crosses one major clause 
boundary. It will be given a misalignment index 
of 4 (considering for the moment only the inter- 
action of these two levels), because of the four 
overlapping constituents on the two hierarchies. 
This example would be misaligned only to de- 
gree 2 if the other quantifier order were chosen, 
and depending on the exact sentence type con- 
sidered, an example with a scope-taking element 
crossing two major clause boundaries should be 
misaligned to about degree 8. 
The fact that the difference between the pri- 
mary and secondary scopings of this sentence 
is 2 degrees of alignment, while the difference 
between crossing one clause boundary and two 
clause boundaries i 4 degrees of alignment, cor- 
responds with generally accepted assumptions 
about the acceptability of this example. While 
the reading in which the scope of quantifiers 
mirrors their order in surface structure is cer- 
tainly preferred, the other ordering is possible 
as well. If the extraction crosses another clause 
1Hobbs and Shieber (1987), p. 49 
546 
S 
Some patients believe all doctors are competent 
@ 
Figure 1: Illustration of the Alignment Constraint. The four highlighted nodes count against his 
combination of structures, because they overlap with constituents in the other tree. 
boundary, however, as in Some patients believe 
Mary thinks all doctors are competent, he re- 
versed scoping is considerably more unlikely. 
2.3 Lexical  P roper t ies  of  Quant i f iers  
In addition to ranking the possible scopings of 
a sentence based on the surface syntactic posi- 
tions of its quantifiers and operators, the pars- 
ing and alignment algorithm employed in this 
project takes into account he "strength" of dif- 
ferent scope-taking elements. By introducing a 
lexical hierarchy of quantifier strength, in which 
those elements more likely to take wide scope 
are found higher in the tree, we are able to use 
the same mechanism of the alignment constraint 
to model the facts which other approaches treat 
with stipulative heuristics. 
For example, in Some patient paid each doc- 
tor, the preferred reading is the one in which 
each takes wide scope, contrary to our expecta- 
tions based on the generalization that the pri- 
mary scoping tends to mirror surface syntactic 
order. An approach employing some variant of 
Cooper storage would have to account for this 
by assigning to each pair of quantifiers a like- 
lihood that one will be raised past the other. 
In this case, it would be highly likely for each 
to be raised past some. The autolexical ap- 
proach, however, allows us to achieve the same 
effect without introducing an additional device. 
Given a proper weighting of the result of align- 
ing the scope hierarchy with this lexical hierar- 
chy, it is a simple matter to settle on the correct 
candidates. 
3 The  A lgor i thm 
3.1 Pars ing  S t ra tegy  
This implementation f the Autolexical account 
of quantifier scoping is written for SWI-Prolog, 
and inherits much of its feature-based grammat- 
ical formalism from the code listings of Gazdar 
and Mellish (1989), including dagun i fy .p l ,  by 
Bob Carpenter. The general strategy employed 
by the program is first to find all parses which 
each hierarchy's grammar permits for the string, 
and then to pass these lists of structures to func- 
tions which implement the alignment and con- 
tiguity constraints. These functions perform a 
pairwise evaluation of the agreement between 
structures, eventually converging on the opti- 
mal set of hierarchies. 
The same parsing engine is used to generate 
structures for each of the major hierarchies con- 
tributing to the representation f a string. It is 
based on the left-corner parser of p ro_pat r .p l  
in Gazdar and Mellish (1989), attributed origi- 
nally to Pereira and Shieber (1987). This parser 
has been extended to store intermediate r sults 
for lookup in a hash table. 
At present, the parsing of each hierarchy is in- 
dependent of that of the other hierarchies, but 
ultimately it would be preferable to allow, e.g., 
edges from the syntactic parse to contribute to 
547 
the function-argument parsing process. Such a 
development would allow us to express catego- 
rial prototypes in a natural way. For example, 
the proposition that "syntactic NPs tend to de- 
note semantic arguments" could be modeled as 
a default rule for incorporating syntactic edges 
into a function-argument structure parse. 
The "generate and test" mechanism em- 
ployed here to maximize the congruity of repre- 
sentations on different levels is certainly some- 
what inefficient. Some of the structures which 
it considers will be bizarre by all accounts. To 
a certain degree, this profligacy is held in check 
by heuristic cutoffs which exclude a combina- 
tion from consideration as soon as it becomes 
apparent that is misaligned to an unacceptable 
degree. Ultimately, however, the solution may 
lie in some sort of parallel approach. A develop- 
ment of this program designed either for parallel 
Prolog or for a truly parallel architecture could 
effect a further restriction on the candidate set 
of representations by implementing constraints 
on parallel parsing processes, rather than (or in 
addition to) on the output of such processes. 
3.2 A l ignment  
The alignment constraint (applied by the 
a l ign /3  predicate here) compares two trees 
(Prolog lists), returning the total number of 
overlapping constituents in both trees as a mea- 
sure of their misalignent. Constituents are said 
to overlap if the sets of terminal nodes which 
they dominate intersect, but neither is a subset 
of the other. 
The code fragment below provides a rough 
outline of the operation of this predicate. First, 
both trees being compared are "pruned" so that 
neither contains any terminal nodes not found 
in the other. The terminal elements of each 
of the tree's constituents are then recorded in 
lists. Once those constituents which occur in 
both trees are removed, the sum of the length 
of these two lists is the total number of overlap- 
ping constituents. 
align(Li,L2,Num) "- 
flatten(LI,Fl), flatten(L2,F2), 
union(FI,F2,AllTerms), 
intersection(FI,F2,GoodTerms), 
subtract(AllTerms,GoodTerms,BadTerms), 
Delete constits without correlates 
rmbad(LI,BadTerms,Goodl), 
rmbad(L2,BadTerms,Good2), 
Z Get list of constits in each tree 
constits(Goodl,CListl), 
constits(Good2,CList2), 
Z Delete dup l i ca tes  
in tersect ion(CL is t l ,CL i s t2 ,CL is t3 ) ,  
subtract(CListl,CList3,Finall), 
subtract(CList2,CList3,Final2), 
Z Count mismatches 
length(Finall,Sizel), 
length(Final2,Size2), 
Num is Sizel + Size2. 
3.3 Contiguity 
While the alignment constraint evaluates the 
similarity of two trees, the contiguity constraint 
(cont ig/3 in this project) calculates the degree 
of fit between a hierarchy and a string (in this 
case, the surface string). The relevant measure 
of "goodness of fit" is taken here to be the min- 
imal number of crossing branches the structure 
entails. It is true that this approach makes the 
contiguity constraint dependent on the partic- 
ular grammatical rules of each representational 
level. However, since an Autolexical model does 
not attempt o handle syntax directly in the 
semantic representation, or morphology in the 
syntactic representation, there is no real dan- 
ger of proliferating nonterminal nodes on any 
particular level. 
The definition of the cont ig  predicate is 
somewhat more complex than that for al ign,  
because it must find the minimum number of 
crossing branches in a structure. It works by 
maintaining a chart (based on the contval  
predicate) of the number of branches "covering" 
each constituent, as it works its way up the tree. 
The contmin predicate keeps track of the cur- 
rent lowest contiguity violation for the struc- 
ture, so that worse alternatives can be aban- 
doned as soon as they cross this threshold. 
contig(\[\],_,0). 
contig(A,_,0) "- 
not(is_list(A)), 
!. 
contig(\[A\],Flat,Num) "- 
548 
is_list (A), 
cont ig (A, Flat, Num), 
!. 
contig(\[A,B\] ,Flat,Num) "- 
cont ig (A ,Flat, Numl), 
contig (B ,Flat, Num2), 
contval (A ,Left I ,Right I, Num3), 
contval (B, Left2, Right2, Num4), 
NumO is Numl + Num2 + Num3 + Num4, 
forall (contmin (Min), 
(NumO >= Min) *-> fail ; true), 
Num is NumO, 
forall (contval (X,L,R, N), 
(L > min(Leftl,Left2), 
R < max(Rightl,Right2)) *-> 
(retract (contval (X, L, R, N) ), 
asserta (contval (X ,L ,R, N+I ) ) ) 
; true) , 
asserta( 
contval ( \[A,B\] ,min(Left I ,Left2), 
max (Right I, Right 2), O) ). 
contig( \[B ,A\] ,Flat ,Num) ? - 
contig (A ,Flat, Numl), 
contig (B ,Flat, Num2), 
contval (A ,Left I ,Right I, Num3), 
contval (B, Left2, Right 2, Num4), 
NumO is Numl + Num2 + Num3 + Num4, 
forall (contmin (Min), 
(NumO >= Min) *-> fail ; true), 
Num is NumO, 
forall (contval (X, L,R, N), 
(L > min(Leftl,Left2), 
R < max(Rightl,Right2)) *-> 
(retract (contval (X, L, R, N) ), 
asserta(contval (X, L,R, N+I) ) ) 
; true), 
asserta( 
contval ( \[A,B\] ,min(Left I ,Left2), 
max (Right I, Right 2), O) ). 
4 Conc lus ion  
Multistratal theories of grammar are not often 
chosen as guidelines for computational linguis- 
tics, because of performance and manageability 
concerns. This project, however, should at least 
demonstrate hat even in a high-level language 
like Prolog a multistratal parsing model can be 
made to produce consistent results in a reason- 
able length of time. 
Furthermore, the project described here does 
more than simply emulate the output of a stan- 
dard, monostratal CF-PSG parser; it yields a 
preference ranking of readings for each string, 
rather than a single right answer. While the 
Autolexical model may not now be correct for 
applications in which speed is of primary con- 
cern, it has only begun to be implemented com- 
putationally, and any serious attempt at infer- 
encing from natural anguage input will have to 
produce similar, graded output (Moran, 1988). 
Re ferences  
Noam Chomsky. 1975. Deep structure, sur- 
face structure, and semantic interpretation. 
In Studies on Semantics in Generative Gram- 
mar, pages 62-119. Mouton. 
Gerald Gazdar and Chris Mellish. 1989. Natu- 
ral Language Processing in PROLOG. Addi- 
son Wesley. 
Jane Grimshaw. 1997. Projection, heads, and 
optimality. Linguistic Inquiry, 28(3):373- 
422. 
Jerry R. Hobbs and Stuart M. Shieber. 1987. 
An algorithm for generating quantifier scop- 
ings. Computational Linguistics, 13:47-63. 
Ray Jackendoff. 1997. The Architecture of the 
Language Faculty. Number 28 in Linguistic 
Inquiry Monographs. The MIT Press. 
Douglas B. Moran. 1988. Quantifier scoping in 
the SRI core language ngine. In A CL Pro- 
ceedings, 26th Annual Meeting, pages 33-40. 
Jong C. Park. 1995. Quantifier scope and con- 
stituency. In A CL Proceedings, 33rd Annual 
Meeting. 
Fernando C.N. Pereira and Stuart M. Shieber. 
1987. Prolog and Natural-Language Analysis, 
volume 10 of CSLI Lecture Notes. Center for 
the Study of Language and Information. 
Jerrold M. Sadock. 1991. Autolexical Syntax: a 
Theory of Parallel Grammatical Representa- 
tions. University of Chicago Press. 
Jerrold M. Sadock. 1996. Reflexive reference in 
west greenlandic. Contemporary Linguistics, 
1:137-160. 
Eric Schiller, Elisa Steinberg, and Barbara 
Need, editors. 1996. Autolexical Theory: 
Ideas and Methods. Mouton de Gruyter. 
Robert D. Van Valin, editor. 1993. Advances 
in Role and Reference Grammar. Number 82 
in Current Issues in Linguistic Theory. John 
Benjamins Publishing Company. 
549 
