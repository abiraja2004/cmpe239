Proceedings of NAACL HLT 2007, Companion Volume, pages 189?192,
Rochester, NY, April 2007. c?2007 Association for Computational Linguistics
Modifying SO-PMI for Japanese Weblog Opinion Mining by Using a
Balancing Factor and Detecting Neutral Expressions
Guangwei Wang
Graduate School of Information
Science and Technology
Hokkaido University
Sapporo, Japan 060-0814
wgw@media.eng.hokudai.ac.jp
Kenji Araki
Graduate School of Information
Science and Technology
Hokkaido University
Sapporo, Japan 060-0814
araki@media.eng.hokudai.ac.jp
Abstract
We propose a variation of the SO-PMI al-
gorithm for Japanese, for use in Weblog
Opinion Mining. SO-PMI is an unsuper-
vised approach proposed by Turney that
has been shown to work well for English.
We first used the SO-PMI algorithm on
Japanese in a way very similar to Turney?s
original idea. The result of this trial leaned
heavily toward positive opinions. We then
expanded the reference words to be sets of
words, tried to introduce a balancing fac-
tor and to detect neutral expressions. After
these modifications, we achieved a well-
balanced result: both positive and negative
accuracy exceeded 70%. This shows that
our proposed approach not only adapted
the SO-PMI for Japanese, but also modi-
fied it to analyze Japanese opinions more
effectively.
1 Introduction
Recently, more and more websites add information
in the form of personal opinions to the Web, e.g.
customer reviews of products, forums, discussion
groups, and blogs. Here, we use the term Weblog for
these sites. This type of information is often useful.
However, we have to deal with an enormous amount
of unstructured and/or semi-structured data. These
data are subjective, in free format and mostly tex-
tual, thus using them is difficult and time consum-
ing. Therefore, how to mine the Weblog opinions
automatically more effectively has attracted more
and more attention (Gamon, 2005; Popescu, 2005;
Chaovalit, 2005).
Turney (2002) has presented an unsupervised
opinion classification algorithm called SO-PMI (Se-
mantic Orientation Using Pointwise Mutual Infor-
mation). The main use of SO-PMI is to estimate
the semantic orientation (i.e. positive or negative)
of a phrase by measuring the hits returned from a
search engine of pairs of words or phrases, based on
the mutual information theory. This approach has
previously been successfully used on English. The
average accuracy was 74% when evaluated on 410
reviews from Epinions1.
However, according to our preliminary experi-
ment, directly translating Turney?s original idea into
Japanese gave a very slanted result, with a positive
accuracy of 95% and a negative accuracy of only
8%. We found that the balance between the posi-
tive and negative sides is influenced greatly by the
page hits of reference words/sets, since a search en-
gine is used. Therefore, we introduced a balancing
factor according for the difference in occurrence be-
tween positive and negative words. And then we
added several threshold rules to detect neutral ex-
pressions. The proposed approach is evaluated on
200 positive and 200 negative Japanese opinion sen-
tences and yielded a well-balanced result.
In the remainder of this paper, we review the SO-
PMI Algorithm in Section 2, then adapt the SO-PMI
for Japanese and present the modifications in Sec-
tion 3. In section 4, we evaluate and discuss the
experimental results. Section 5 gives concluding re-
marks.
2 Details of the SO-PMI Algorithm
The SO-PMI algorithm (Turney, 2002) is used to es-
timate the semantic orientation (SO) of a phrase by
1http://www.epinions.com
189
measuring the similarity of pairs of words or phrases
using the following formula:
PMI(word1,word2)=log2
[
p(word1&word2)
p(word1)p(word2)
]
(1)
SO(phrase) = PMI(phrase,?excellent?)
?PMI(phrase,?poor?) (2)
The reference words ?excellent? and ?poor? are
used, thus SO is positive when a phrase is more
strongly associated with ?excellent? and negative
when a phrase is more strongly associated with
?poor?. Let hits(query) be the number of hits re-
turned when using a search engine, the following
estimate of SO can be derived from Formula (2) and
(1) with some minor algebraic manipulation.
SO(phrase) = log2 [A]
A = hits(phrase NEAR?excellent?)?hits(?poor?)hits(phrase NEAR?poor?)?hits(?excellent?) (3)
Turney used AltaVista2 search engine because it
has a NEAR operator. This operator constrains the
search to documents that contain the words within
ten words of one another, in either order. Turney?s
previous work has shown that NEAR performs bet-
ter than AND when measuring the strength of se-
mantic association between words.
3 Our Proposed Approach
The first step of our approach is to extract opin-
ion phrases using word POS (part of speech) tem-
plates based on our analysis of opinions in Japanese
Weblog and the results of related work (Kobayashi,
2003; Taku, 2002; Wang, 2006). The second step is
to estimate the semantic orientation of the extracted
phrases, using the SO-PMI algorithm.
3.1 Adapting SO-PMI for Japanese
Following Turney?s original idea, we first translated
the SO formula to the one shown in Formula (4) for
Japanese.
SO(phrase) = log2 [B] (4)
We used the Google search engine3 to get the
hits(query) even though Google does not have a
NEAR operator. The AltaVista NEAR operator does
not work well for Japanese and Google indexes more
2http://www.altavista.com/sites/search/adv
3http://www.google.co.jp/
pages than AltaVista, thus we used Google and re-
placed the NEAR operator with the AND operator in
the SO formula. ? ? and ? ? were se-
lected because they correspond to the English words
?excellent? and ?poor?.
For testing the performance of this trial, we used
200 positive and 200 negative Japanese opinion sen-
tences which have been labeled by hand. The re-
sults were very slanted. Many phrases, whether pos-
itive or negative in meaning, still received a posi-
tive SO. Some possible causes could be that ?
(poor)? has more hits than ? (excellent)?,
as shown in Table 1, and that the AND operator is
less useful than the NEAR operator.
3.2 Modifying SO-PMI for Japanese
In Japanese, there are many expressions when
people evaluate something. For example, ?
(good)?, ? (good)?, ? (satisfaction)? , ?
(excellent)? are usually used when some-
one wants to convey a positive opinion. Hence
we tried to replace the reference words ?excellent?
and ?poor? with two reference sets: ?p?basic? and
?n?basic?:
SO(phrase) = log2 [C]
C = hits(phrase ANDp?basic)?hits(n?basic)hits(phrase ANDn?basic)?hits(p?basic) (5)
?p?basic? is a set of common strong positive
words in Japanese. ?n?basic? is a set of common
weak negative words. The hit counts of these words
from Google is shown in Table 1 (All data from
2007/01/12). The hits(query) was calculated by
hits(phrase AND (? (good)? OR ? (like)?)
OR ? (good)? OR ...).
Table 1: Frequency of p?basic/n?basic words on the Web
2.57 26,000?????(excellent)
2.81 28,400?????(interesting)
5.89 59,500????(happy)
7.40 74,700??(lovely)
7.48 75,500???(happy)
7.89 79,700???(interesting)
7.98 80,600??(satisfaction)
9.59 96,900??(good)
10.20 103,000??(good)
10.59 107,000???(delightful)
11.39 115,000???(want)
11.39 115,000???(favorite) 
14.85 150,000??(charm)
20.89 211,000??(good)
23.96 242,000??(like)
36.83 372,000??(good)
R(%)Hits (K)p_basic words
1.02 10,300 ???(bad)
1.54 15,600 ???(not good) 
1.64 16,600 ??? (fault)
2.05 20,700 ??(worst)
2.20 22,200 ??(dissatisfaction)
2.58 26,100 ??(dissatisfaction)
2.62 26,500 ??(painful)
2.62 26,500 ??(useless)
3.67 37,100 ??(dislike)
3.75 37,900 ????(not good)
6.44 65,000 ?(dislike)
7.68 77,600 ???(hard)
7.71 77,900 ??(fault)
8.22 83,000 ??(worry)
10.89 110,000 ??(bad)
11.78 119,000 ??(poor)
R(%)Hits (K)n_basic words
We evaluated this modification using the same
190
data as in Section 3.1. We obtained a slightly bet-
ter result. However the SO values were still slanted.
This time many phrases, whether positive or nega-
tive in meaning, still received a negative SO. All of
these test results are shown in detail in Section 4.2.
In the experiments above, we obtained heavily
slanted results. We consider that the large differ-
ence in page hits between the positive and negative
reference words/sets are the main cause for this phe-
nomenon. To mitigate this problem, we decided to
introduce a balancing factor to adjust the balance be-
tween the positive and negative sides. The SO for-
mula was modified from (5) to (6).
SO(phrase) = log2 [C] + f (?) (6)
The balancing factor f(?) was calculated by For-
mula (7).
f (?) = ? ? log2
[hits(p?basic)
hits(n?basic)
]
(7)
The log2 of ?p?basic? and ?n?basic? is a fac-
tor that adjusts the balance of the similarity of
?p?basic?/?n?basic? and phrases automatically by
the hits of ?p?basic?/?n?basic? itself. ? is a weight
value. We evaluated different values of ? from ?0.0?
to ?1.0? on the benchmark dataset, which is shown
in detail in Section 4.2.
From these preliminary trials, we also found that
many neutral phrases often receive positive or neg-
ative SO. Therefore we added detection of neu-
tral expressions. The idea is that if the phrase is
strongly or faintly associated with both ?p?basic?
and ?n?basic?, it is considered a neutral phrase. Be-
cause this means that this phrase has an ambiguous
connection with both ?p?basic? and ?n?basic?. We
use the following rules (Figure 1) to separate neutral
phrases from positive/negative phrases. The thresh-
old values ta, tb and tc are obtained from a small,
hand-labeled corpus.
1. hits( phrase AND p_basic) > ta AND hits( phrase AND n_basic) > ta
2.  hits( phrase AND p_basic) < tb AND  hits( phrase AND n_basic) < tb
3.  | hits( phrase AND p_basic) ? hits( phrase AND n_basic) | < tc
4. SO( phrase ) = 0 
Figure 1: Rules for Detecting Neutral Expressions
4 Experimental Performance Evaluation
4.1 Gold Standard and Evaluation Metrics
As a gold standard, we collected a benchmark
dataset which has 200 positive opinion sentences
and 200 negative opinion sentences from the reviews
about Electronic Dictionary and MP3 Player prod-
ucts that have been labeled as either positive or neg-
ative reviews in ?Kakaku.com?4. ?Kakaku.com? is
the largest Japanese Weblog specializing in product
comparison of consumer goods, including price and
user opinions, etc. Lots of people exchange mis-
cellaneous product information and reviews. These
reviews are classified as questions, positive re-
views, negative reviews, rumors, sale information or
?other? category.
To classify a sentence as positive (P) or negative
(N), the average SO of the phrases in the sentence is
used. If the average SO is P, the sentence is a posi-
tive sentence; otherwise it is a negative sentence. As
evaluation metrics, we measured our proposed ap-
proach?s performance by accuracy. accuracy was
measured as the number of sentences correctly clas-
sified as P/N sentences to the total number of P/N
sentences in the benchmark dataset (200). PA means
positive accuracy, NA means negative accuracy, i.e.
the accuracy on only positive or negative sentences
respectively.
4.2 Experiments and Results
First we did the balancing factor experiment to
determine the value of ???, using the benchmark
dataset. The results are shown in Figure 2. (a)
and (b) show the dashed line indicates average ac-
curacy (74%) on English Data from Turney?s Study
(2002). Turney didn?t evaluate positive and nega-
tive accuracy respectively. The full drawn line indi-
cates the result after translating the original SO-PMI
to Japanese (PA:95%, NA: 8%). PA series (the line
with triangle mark)/NA series (the line with circle
mark) when values of ??? from ?0.0? to ?1.0? were
used.
Changing the ? tends to be a tradeoff, lowering
PA when NA is improved and vice versa. There-
fore, we used Harmonic?Mean by the following
formula to find a proper value of ???.
Harmonic?Mean = 2 ? PA ?NAPA+NA (8)
Figure 2, (c) shows PA, NA and
Harmonic?Mean curves for different values
4http://www.kakaku.com/
191
0.00
0.10
0.20
0.30
0.40
0.50
0.60
0.70
0.80
0.90
1.00
0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0
?
A
c
c
u
r
a
c
y
Positive Accuracy by Modified SO-PMI (PA)
Positive Accuracy by Original SO-PMI for Japanese
Accuracy on English Data from Turney's Study
0.00
0.10
0.20
0.30
0.40
0.50
0.60
0.70
0.80
0.90
1.00
0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0
?
A
c
c
u
r
a
c
y
Negative Accuracy by modified SO-PMI (NA)
Negative Accuracy by Original SO-PMI for Japanese
Accuracy on English Data from Turney's Study
0.00
0.10
0.20
0.30
0.40
0.50
0.60
0.70
0.80
0.90
1.00
0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0
?
A
c
c
u
r
a
c
y
Harmonic_Mean of PA & NA
Positive Accuracy by Modified SO-PMI (PA)
Negative Accuracy by Modified SO-PMI (NA)
(a) Positive Accuracy (PA) (b) Negative Accuracy (NA) (c) Harmonic-Mean of PA/NA
Figure 2: Experiment for ? in Balance Factor
of ???. We selected the ??=0.9? giving the highest
Harmonic?Mean value, thus giving a good
balance between PA (75%) and NA (70%).
The comparative experiment results between the
SO-PMI for Japanese (Test 1), and our modifications
(Test 2, 3, 4) are shown in Table 2.
Table 2: Comparative Experiment Results
7278Test 3 + Modification 3: Neutral Phrase DetectionTest 4
PA: Positive Accuracy         NA: Negative Accuracy 
Test 3
Test 2
Test 1
9912Modification 1: Two Reference Sets
7075Test 2 + Modification 2: Balancing Factor [? =  0.9] 
895Naive translation of Turney?s Approach for Japanese
NA(%)PA(%)Test Content
In Test 1 and 2, we obtained extreme results, lean-
ing to the positive or negative end, whether using the
Turney?s original approach or expanding the refer-
ence word as ?p?basic? and ?n?basic?. In Test 3,
we added a balancing factor as described in section
3.2, and obtained a comparatively well-balanced re-
sult. Finally, after adding the neutral expressions de-
tection, we achieved a PA of 78% and NA of 72%
(Test 4). The balance between positive and negative
sides was quite improved by contrast with Test 1 and
2.
5 Conclusions
This study first proposed a modified unsupervised
approach (SO-PMI) for Japanese Weblog Opinion
Mining. Some parts of Turney?s approach, such as
the NEAR operator, does not work for Japanese,
thus some modifications must be done. In a prelim-
inary experiment, the negative accuracy (8%) was
very poor while the positive accuracy (95%) was
high. To deal with this phenomenon, we presented
three modifications based on the characteristics of
Japanese and the results of related work. The ex-
periment results (positive accuracy: 78%, negative
accuracy: 72%) show that our proposal achieved
a considerably improved performance, comparing
with directly translating the SO-PMI. Hence it
would be expected that the balancing factor and neu-
tral expressions detection would work effectively
also for other reference words or languages. In the
future, we will evaluate different choices of words
for the sets of positive and negative reference words.
We also plan to appraise our proposal on other lan-
guages.
References
Peter D. Turney. 2002. Thumbs up or thumbs down? Semantic
orientation applied to unsupervised classification of reviews.
Proceedings 40th Annual Meeting of the ACL, pp. 417-424.
Popescu, Ana-Maria, and Oren Etzioni. 2005. Extracting Prod-
uct Features and Opinions from Reviews. Proceedings of
HLT-EMNLP.
Michael Gamon, Anthony Aue, Simon Corston-Oliver and Eric
K. Ringger. 2005. Pulse: Mining Customer Opinions from
Free Text. Proceedings of the 2005 Conference on Intelligent
Data Analysis (IDA), pp.121-132.
Pimwadee Chaovalit and Lina Zhou. 2005. Movie Review Min-
ing: a Comparison between Supervised and Unsupervised
Classification Approaches. Proceedings of the 38th Annual
HICSS.
Nozomi Kobayashi, Kentaro Inui, Yuji Matsumoto, Kenji
Tateishi and Toshikazu Fukushima. 2003. Collecting eval-
uative expressions by a text mining technique. IPSJ SIG
NOTE, Vol.154, No.12, In Japanese.
Taku Kudoh and Yuji Matsumoto. 2002. Applying Cascaded
Chunking to Japanese Dependency Structure Analysis. In-
formation Processing Society of Japan (IPSJ)Academic
Journals, Vol 43, No 6, pp. 1834-1842, In Japanese.
Guangwei Wang and Kenji Araki. 2006. A Decision Support
System Using Text Mining Technology. IEICE SIG Notes
WI2-2006-6, pp. 55-56.
192
