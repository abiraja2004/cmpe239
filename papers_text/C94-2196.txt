l) iscourse and Deliberation: Testing a Collaborative Strategy 
Marilyn A. Walker 
Mitsubishi Electric Research Laboratories* 
20l Broadway, Cambrklge, Ma. 02139, USA 
walker@mer l ,  corn  
Abstract 
A discourse sl,'ategy is a strategy lor communi- 
caling wilh ~motller agenl. Designing elli:clive 
dialogue syslems requires designing agents 
that can choose among discourse strategies. 
Wc claim that file design of effective sIfale- 
gies must lake cognilive laclors into account, 
propose a new melhod for lesling Ihe hypothe- 
sized factors, and present experimental results 
on an effective strategy for stlpporting deliber- 
ation. 'File proposed method of compulational 
dialogue simulation provides a iiew empirical 
basis 1+Ol +computalional linguislics. 
1 Introduction 
A discourse slralegy is a strategy for communicaling 
with another agent. Agents make slrategy choices via 
decisions abotlt whetl 1o talk, when 1o let tile olher agenl 
talk, wllal Io say, aiR\[ how to say il. ()no choice a 
COllVelSitliOllal i:lgelll lnllst make is whether ~ltl utterance 
sholdd include some relev~ml, but Olllional, information 
in what is communicated. For ex~unple, consider 1: 
1) a. Let's walk along Wahlut St. 
b. ll's shorter. 
The speaker made a shategic hoice in 1 to include lb 
since she could have simply said la. What detemlines 
the speaker's choice? 
Existing dialogue systems have two modes lot dealing 
with optional inlormalion: (1) includeall optional inlor- 
matiou thai is not already known lo the he, e'er; (2) include 
no optional inlommlion IMoore and l'aris, 19931. Bul 
Ihese modes are simply the extremes of possibility ~md 
Io my knowledge, no l)revious work has proposed any 
principles for when Io include oplional fillornmtion, or 
any way of lesting the i)roposcd l/rinciples lo see how 
lhey are affecled by the conversants and their processing 
ahilities, by the task, by tile COtTllntlnication channel, or 
by the domain. 
This lmper presenls a new experimeillal melhod for 
determining whelher adiscourse strategy is effective and 
presents experimenlal results on a slralegy for supporling 
deliberalion. Tile ntethod is b~tsed on earlier simulation 
work by Carletla and Pollack ICarletla, 1992; Pollack 
~md Ringuelle, 1990\]. Section 2 outlines hypotheses 
about he factors that affect which strategies are effective. 
Section 3 presenls a new inelhod for testing lhe role el'the 
*This research was parlially futlded by AR() grant 
I)AAI A) J,-gg-C0031PI.~I and 1 )A RPA grant N00014-90-J- 1863 
at Ihe University of l'ennsylwmia and by \[ lewlcit l'ackard, U.K. 
hypothesized factors. "File experimental results in section 
4 show that effective stralegies 1o supporl deliberation 
are determined by bolh cognilive and lask variables. 
2 Deliberation ill l)iscourse 
l)Niberation is file process by which an agent decides 
what to believe and what to tit> \[G~dliers, 199 l; Doyle, 
19921. ()he slralegy that supports deliberation is the 
ExpliciI-Warrant strategy, as in 1. The WARRANT in lb 
can be used by the he~uer in deliberating whether lo 
ACCEPT or REJIi(?T tile speakef's I'ROPOSAI, in la. 1 
An amdysis of proposals in a corpus of 55 problem- 
solving dialogues SllOWS lhat communicating agents 
don't always include warrants in a prol)osal, and sug- 
gest a number of hypolheses abotlt which factors alfecl 
lheir decision IWalker, 1993; Pollack el al., 19821. 
Consider a situalion in which an agent A w~mts ~u~ 
agent B to accept a proposal P. If B is a 'helpful' agent 
(llOllaHl.Ol)Ol/lOtlS), B will accepl A's proposal withoul a 
wammt. Altemalively, if B deliberates whether to accept 
1; but B knows of no competing options, Ihen P will be 
the best el)lion whether or not A lells P, the WatW~Ult l o r  P. 
Since a w~u','ant makes the dialogue longer, tile Explicit- 
Wml'~mt strategy might be inefficient whenever either of 
these situalions hold. 
Now consi(lel a silualiOll where P, is HI) atltOllOlllO|lS 
agenl I Galliers, 19911. B always deliberates every pro- 
posed and B probably knows of oplions which compete 
with proposal P. Then B c~umot decide whelher to accept 
P withoul a warrant. Supposedly agenl A should omit 
a warrant is if it is ah'eady believed by B, so that the 
speaker in 1 woukl not have said It's shorter if she be- 
lieved that the hem'or knew that file Wahlul St. mute was 
shorter. However, consider 2, said in discussing which 
Indian reslaurant to go to for hmch: 
(2) a. Listen to Ramesh. 
b. tle's lndiau. 
The w~m~Ult in 217 was included despite tile facl that 
il was cOlnlllOll knowledge ;llllOng lhe COl)VelSalltS. Its 
inclusion violates the rule of Don't tell people facts that 
they already k#tow. ~= Clearly lhe rule does not hold. 
I The telalion between a WARRANT and the PR(II,OSI{ COlll- 
municative act is similar to the MOTIVATION relation of \[Moore 
and Paris, 1993; Mann and Thompson, 1987\]. A WARRANT is 
always optional; this is consistent with the RST fl'anlewolk in 
which all satellites are optional information. 
2The WARRANT having lhe desired cflect of getting the 
hearer io listen to l{amesh depends till ltle hearel previously 
believing or coming Io believe that hldians know of good Indian 
restaurants \[Webber a id \]oshi, 19921. 
1205 
TO WARRANT OR NOT 
B not acceot without warrant B will accept without a warrant 
2",, 
B doesn't know w~u'rant B knows wammt warrant is required for task wan'ant is not required for task 
YES ~ YES NO 
warrant is salient (for B) w,'urant is not salient(for B) 
NO ~ retrieval is indeterminate / , -  -,,, 
YES 
retrieval is cheaper than communication communication is cheaper than retrieval 
NO YES 
Figure 1: Potentild Factors of Decision in whether to use the Explicit-Warrant s rategy 
These aheady-known w~u'rants m'e a type of INFOR- 
MKI'I()NAI,LY RE\[)\[ INI)ANT UTTERANf:E, l lencel()rth IRU, 
which iue surprisingly frequent in naturally-occurring 
dialogue \[Walker, 19931. 
A Warrant IR/J such a.S that in 2 suggests tllat B's 
cognilive limitations \[nay be a factor in what A cllooses 
to say, so thai even if B knows a wlu'rant for adopting A's 
proposed, what is critical is whetlm,' the warrant is salient 
lot B, i.e. whether the warnmt is ah'eady accessible in 
B's working memory \[Prince, 1981; Baddelcy, 1986\]. 11 
the w~u'rant is not already salient, then B must either infer 
or retrieve the wlurant information or obtain it from an 
external source in order to evaluate A's proposed. Thus 
A's slrategy choice may depend oil A's model of B's 
alteutional stale, as well as the costs of retrieval ~md 
inference as opposed to communication. In other words, 
A may decide thal it is e~Lsier to just say the warrant 
rather than require B to infer or retrieve it. 
Finally, the task determines whether there are penalties 
lor leaving a w~ur~mt implicit and relying on B 1o inter 
or relrieve it. Some tasks require that two agents agree 
oil tile reasons lot adopting a proposal, e.g. in order to 
ensure robustness insituations of environmental change. 
()ther tasks, such ~ts a mmmgement/union negotiation, 
only require the agents to agree on the actions to be 
cluried out and each agent can have its own reasons 
lot wanting tl~ose actions to be done withoul affecting 
success in the lask. 
Figure 1 summ~uizes these hypotheses by proposing 
a hypothetical decision lree for an agent's choice of 
whetlmr to use the Explicit-W~n-rlmt s rategy. The choice 
is hypothesized todepend oil cognitive properties of B, 
e.g. what B knows, B's anentiomd state, lind B's pro- 
cessing capabilities, as well as properties of the tiksk 
and the communication cl~annel. To my knowledge, all 
previous work on di~dogne has simply assumed that ,'m 
agent should never tell ~m agen! facts that the other agent 
already knows. The hypotheses in figure 1 seem coin- 
pie\[ely plausible, but the relationship of cognitive ffort 
to dildogue behavior has never been explored. Given 
these hypotheses, what is required is a way to test the 
hypothesized relationship oft~tsk and cognitive factors to 
effective discourse strategies. Section 3 describes a new 
method for testing hypotheses about ellective discourse 
stralegies in dialogue. 
3 Design.World 
Design-World is an experimentld enviro|unent for test- 
iug the relationship hetween discourse strategies, task 
p~u'ameters ,and agents' cognitive capabilities, similar 
to the single ,agent TileWorld simnlalion environment 
\[Pollack and Ringuette, 1990; Hanks et al, 199311. 
Design-World agents can be parametrized as to dis- 
course strategy, and tilt elfecls of this strategy can he 
me~Lsured against a |'imge of cognitive and task p~u'ame- 
ters. This paper compares \[l~e Explicit-Winrant s rategy 
to the All-lmplicil strategy as strategies lot supporting 
deliberation. Other strategies tested in Design-World 
me presented elsewhere \[W~dker, 1993; Walker, 1994a; 
Riunbow ~md Walker, 19941. 
3.1 Design Wor ld  l )omain  and  task  
~ 5 54 \]1 \]\]1\]\] ~,1 
F = I'UCHSIA 
P= IURPI? 
55 
52 53 
ROOM # I ROOM # 2 
I)\[~IGN WORLI) (:OLI,AI\]ORATIVI!PLAN:434pokats 
Figure 2: One Fined State for Design-World Slandard 
Task: Represents the Collaborative Plan Achieved by 
the Dialogue, 434 points 
Tile Design-World task requires two agents to carry out a 
dialoguein order to negotiate ;m agreement oil the design 
of the lloor plml of a two room house \[Whittaker t al., 
199311. The DI!SI(;N-IlOIJSE plan requires the agents to 
agree on how to DF, SI(;N-ROOM-1 and I/I!SI{;N-ROOM-2. 
Both agents know whal tile I)ESI(;N-IIOUSE p l~ requires 
and stm'l out with a set of fnmiture pieces that can he 
used to design each room. 
1206 
To negotiale all ;-tgxec.lllt3nt, each agetll c:uTics ()tit 
means-end reasoning itl)oul tile furniture pieees Ihat Ihey 
hilve thal Call be used izl lhe lloof plan. Means-elld rea- 
soning generates OPTIONS these options are tile content 
o1: I'I{OI'()SAI2q Io Ihe other agent o 1,1 IT iI piece of fumi- 
tu fe in looneof therooms.  Dialogue 3 ilhlstratesagents' 
communication for part e l  desiguing loom- l, including 
bolh tile aflilicial lallgtlage lhaI the agents conlnitmicate 
wilh and a gloss generated li'om 1hal llmgl,age in italics: 
(3) 
1 : ITIl,\[,: First, lel's put lhe green rug in the study. 
(p,olmSC agent, hill agenl.kinl optima. 10: pill acl (agent-bill 
ff3eet/ l~lg fclonl 1 )) 
2: KIM: Nexl, lefs pill the .wee, htm t) there. 
2:(propose agcnt-kim agent-bill {~plion-33: put-act (a~,ent- 
kim green lamp room-Ill 
3: BILL: Then, leFs put the green cotwh in the study. 
(propose. agent-bill agcnt-kim option-45: put-act (agenr bill 
green Cmlch mOln- 1 )) 
4: KIM: No. instead let's put in the purl)le ~ om:h. 
(rcjecl agcnt-kim agent bill o1~1ion-55: lnlt acl (agent kml 
purple couch l'OOlll-\[ ))
()n receiving a proposal, au agent dcliberalcs whclhcf 
I() ACCI!I'T ,:51 R10ECT tile proposal \[Doyle, 1992\]. As po- 
Ielllial warfants to suppofl deliberation, ~md It.) provide a 
wily of ohjeclively evaluating agents' l)erlbrm~mce, each 
piece of l:ufnitufe has a score. The score ira)positions lor 
all tile pieces of furniture are stored in both agents' mem- 
ories al Ihe beginning of lhe dialogue. 
Agents RI{JI,'.( :'ra proposal if delibefalion leads lhenl 1o 
believe lhal lhey know t)l'a bellm option or if they believe 
the precondilions for tile proposal do not hold. The con- 
toni of rt~jc.clions is dctcf,nined by the (:()I.I.AI;()RKI'IV){ 
PI.ANNIN(; PRIN('II'IJ{S, abslfacled frolll analyzing fotlf 
different types oF pt'oblem solving dialogues \[Walker 
and Whitlakef, 1990; Walker, 1994bJ. Per example, in 
3-4 Kiln fejecls the proposal ill 3-3, and gives its her 
reason that oplion-S6 is a teenier-proposal, 
Pml)osals 1 aiRl 2 ~ue infeffed Io be implicilly Ac- 
t 3.;HE\]) because they are not rejected \[Walker ~md Whil- 
taker, 1991); Walker, 19921. I1 a pfOl)OSal is A(:t'EI'Tt,.'I), 
eilhef implicitly or explicitly, then the oplion Ihat wits 
Ihe content of tile pfoposal hecollles a mtnlual intenlitm 
thai conlrihutes Io Ihe iinal design plan II'ower, 1984; 
Sidner, 1992I. A polenlial final design plan negolialed 
via a dialogue is shown in ligure 2. 
3.2 Vary ing  l ) i scourse  S l ra teg ies  
The l)esign-Wodd experimenls reporlcd here compare 
1he All-hnplicit slratcgy with the ExpliciI-Wmrant strat- 
egy. Agcnls are paianmlrized for difl~:renl discot,rsc 
strategies by placing different expansions o1' discourse 
phms in their plan libfaries. I)iscoufsc plans m'e plans for 
I'i,'()I'OSAI,, RI{J\](C'\['It)N, A(:C\]!I"I~.NCI(, ?I,ARIF\[CKI'R)N, 
()I'I(NING alld t'I,()SIN(;. Tht3 only wtriations discussed 
here are variations in lhe expansions (51 I'ROI'OSAI ~'S. 
The All-lmplicil slralcgy is an explmsion of a dis- 
COIII'Se 151;Ill Io lllilke a I'R/)I'O.RAI., in which a PiU)I'OSAI. 
decomposes lrivially to lhe COl/llllut/icalive ;El of I'R.()- 
I'()SE. In dialogue 3, both l)esign-World agents conllnll- 
nicale using the AIl-hnplicil slfategy, and file proposals 
m'c shown in utlerances 1, 2, lind 3. The All-hnplicil 
slfalcgy never includes warrants ill proposals, leaving it 
up 1(:5 the other ;:tgeill It) feltlove them fiom memofy. 
The Explieit-Wmf~mt slralegy expands lhe I'ROI'()SAI. 
discourse act to be a WAId<ANT followed by a PR()I'OSE 
utter~mee. Since agents already know tile point values 
for pieces of furniture, wm'rauts ~ue Idways IRUs ill lhe 
experimenls here. For exmnple, 4-1 is a WARRANT for 
the pn)posal ill 4+2: The n~unes of agents who use tile 
Explicit-Win-rant smltegy are a numbered version of tile 
siring "IEI" to help the experimenter keep track of tile 
simulation data tiles; IEI stlmds lor hnplicit acceptance, 
Explicil warrant, Implicit opening ~md closing. 
FI) 
\[: let: lhxtting in the green rug is worth 56. 
(say agcnt-iei agent ici2 bel.-10: scm'c (option..\[0: put-act 
(aEelli-iei green mg room- I) 56)) 
2: IEt: Then, let's i;,ut the green rug it* the study. 
(pmlmSe agent-iei agenViei2 {q~lion .10: put-acl (age,ll iei 
green tug romu-I )) 
3: IEI2: Pulling ill lhe green laml~ is wol'th 55. 
(say agent-iei2 agent-ici bvl 34: score (optiOll 33: put-acl 
(agent ici2 ~,leell amp room-1) 55) ) 
4: IE12: Then, let's put the green lamp in lhe study. 
(Ismp-sc agcnl-iei2 agc.nt-ici optitm-.33: puVacI (aget~t-ici2 
green lamp teen> 1)) 
The fact lhal the green rile is worth 56 points sup- 
polls deliberation about wlmlhet 1o adopt the intention 
of putting the green rug in the study. The I~xplicit-- 
WalTall\[ sirategy models nalurally oceun'ing examples 
such as those in 2 because Ihe points illfofmalitm used 
by lhe hem'er to deliberate whether to accept or reject the 
proposal is already mulually believed. 
3.3 Cogn i t ive  and  ' lask i ' a rametevs  
Seclion 2 inlfoduced a range of factors motivated by 
the coqms analysis that were hypothesized to deter- 
mine when ExpliciI-Wm-fant is an efleelive slralegy. 
This seclion discusses how Design-World SUl)ports Ihc 
plu'iunetfization f these \[~ICIOfS. 
The agent architecture R/r deliberalion and means-end 
reasoning is based on the IRMA architeclure, also used 
in the 'l-'ile, World simulation environment IPollack and 
R.inguclte, 19901, with Ihe addition of a model o1' lira-- 
ile(l Allenlkm/Working IllellIOfy, AWM, \[Walker, 1993\] 
inchldes a fullef disctlssion of tile l)esig,>WorM delib- 
eration and melms-end reasoning mechanism and Ihe 
underlying mechanisms assumed in collaborative plan- 
ning. 
We hypolhcsizcd lhal a warrant Inllsi be ,'qAIJENT for 
hoth agents (as shown by example 2). In l)esign-Wodd, 
salience is modeled by AWM model, adapted lronl \[Lan- 
dauer, 1975 I. While the AWM model is extremely sin> 
pie, \[,andauer showed thai it could be pm'ameterized lo 1il 
many empirical resells on human memory and learning 
\[Baddeley, 19861. AWM consists of a three dimensional 
slsace in which propositions acquired Dora perceiving the 
world are stored in chronological sequence according 1o 
tile localion o1' a moving memory pointef. The sequence 
of memory loci iised lof slotage constitutes a fI.Itldolll 
walk lhrough memory wilh each loci a shorl dislance 
lfonl tile previous one. If items are encountefed illtllliple 
times, they me stored nmlliple limes \[Itinlzmann and 
Block, 1971\]. 
Whell }Ill agellt rchieves ilenls 1}o111 inelllOfy, search 
slarls from tile current poinlef Iocalion and spreads out 
1207 
in a spherical fashion. Search is restricted to a particular 
se,'u'ch radius: radius is defined in Hiunming distance. 
For ex~unple if the current memory pointer loci is (0 0 (1), 
the loci dist~mce 1 away would be (0 1 0) (0 -1 0) (0 0 l) (0 
0 - 1) (- 1 0 0) (1 0 0). The actual ocations are cldculated 
modulo the memory size. The limit on the search radius 
defines the capacity of attention/working memory and 
hence defines which stored beliefs and intentions are 
SAI ,IENT. 
Thc radius of tile search sphere in the AWM model 
is used as the par,'uneter for Design-World agents' 
resource-bound on attentional capacity. In the exper- 
iments below, memory is 16x16x16 and tile radius pa- 
rmneler v~n'ies between 1and 16, where AWM of 1 gives 
severely attention limited agents imd AWM of 16 means 
that everything an agent knows is accessible. 3 This pa- 
rluneter lets us distinguish between an agent's ability to 
access all the inlimnation stored in its memory, lind the 
effort involved in doing so. 
The advantages of the AWM model is that it was 
shown to reproduce, in simulation, mlmy results on hu- 
man memory ~md lem'ning. Because search st~n'ts from 
the current pointer location, items that have been stored 
most recently are more likely to be retrieved, predicting 
recency effects \[BMdeley, 19861. Because items that 
are stored in multiple locations are more likely to be re- 
trieved, tbe model predicts fiequency effects \[Hiutzmmm 
and Block, 1971 I. Because items are stored in chrono- 
IogicN sequence, the model produces natural associativ- 
ity effects \[Landaner, 19751. Because deliberation and 
means-end re~tsoning can only operate on salient belietls, 
limited attention produces a concomitlmt inl)rential lim- 
itation, i.e. if a belief is nol salient it cannot be used in 
deliberation or mcans-end-reltsoniug. This means that 
mistakes that agents make in their planning process have 
a plansible cognitive basis. Agents can both fail to ac- 
cess a belief that would idlow them to produce ,an optim~d 
plan, its well as make a mistake in pl~mning if a belief 
about bow the world has changed its a result of pllmning 
is not sldicnt. I)epending on the preceding discourse, and 
the agent's attentionld capacity, the propositions that im 
agent knows may or may not be salient when a proposed 
is made. 
Another hypothetical riveter was the relative cost of re- 
trievld and communication. AWM ~dso gives ns a way to 
measure tile nmnber of retriev~ds from memory in terms 
of tile number of locations searched to find a proposi- 
tion. The iunount of effort required li)r each retrieval 
step is a parmnetel, its is tile cost of each inference step 
lind the cost of each communicated message. These cost 
parluneters supporl modeling v~uious cognilive mchitec- 
tures, e.g. vmying tile cost of retrieved models different 
assumptions ahout memory. For example, if retrieval is 
free then ~dl items in working memory me instfmtly ac- 
cessible, as they would be if they were stored in registers 
with litst p~uallel access. If AWM is set to 16, but re- 
lrievzd isn't free, tile model approximates slow spreading 
3The size of memory was determined as adequate for pro 
ducing the desired level ~1' variation in tile current task across 
all the experimental variables, while slill making it possible to 
I'1.1 n a large iltlnlher el" simtllalions over  night wherl agents have 
access to all of their memory. In order Io use the AWM model 
in a different ask, the experimenter might want to explore 
dilferent sizes lbr memory. 
activation that is quite effortful, yet the agent still has the 
ability to access ~dl of memory, given enough time. If 
AWM is set lower than 16 ~md retrievld isn't liee, then 
we model slow spreading activation with a timeout when 
e/fort exceeds acertain ~unount, so that im agent does not 
have the ability to access all of memory. 
It does not make sense to fix absolute v~dues li)r the re- 
trievld, inference lind communication cost plu~uncters in
relation to human processing. However, Design-World 
supports exploring issues about he relative costs of vlu'- 
ions processes. These relative costs might v,'u'y depend- 
ing,on the language that the agents are communicat- 
ing with, properties of the communication channel, how 
smtu't tile agents ,arc, how much time they have, lind what 
the demands of the ti~sk are \[Norm~m and Bobrow, 1975\]. 
Below we vary tile relative cost of communication and 
retrieval. 
Fin~dly, we hypothesized that the Explicit-Wm3'ant 
strategy may be beneficial if the relationship betweeu 
the wlm'imt and the proposed must be mutu~dly believed. 
Thus the delinition of success for the task is a Design- 
World plu','uneter: the Stimd~u'd task does not require a 
shared wlu'r~mt, whereas the Zero NonMatching Beliefs 
task gives a zero score to any negotiated plan without 
agreed-upon warrants. 
3.4 Evaluating Perfiwmance 
qb evlduate PERFOI),MANCti, We compare the Explicit- 
Winximt strategy with tbe All-Implicit strategy in sit- 
uations where we vm'y the tltsk requirements, agents' 
attcntiotud capacity, lind the cost of retrieval, inference 
and communication. Evlduation of tile resulting I)ESIGN- 
IIOtJSli plan is p~u'~unctrized by (1) ('OMMCOST: COSt of 
sending a message; (2) INFCOST: cost of inference; and 
(3) RETCOST: COSt of retrieval from memory: 
I'ERFORMANCE 
= Task Defined RAW SCORI~ 
((!OMM(~OST x number of messages) 
- (INFCOST x nnmber  o f  in fe rences)  
- (RETCOST X number of retrieved steps) 
RAW S(:ORE is task specilic: ill the Stand'ud task we 
simply summiu'ize the point values of the furniture pieces 
in each PUT-A('T ill the fined Design, while in tile Zero 
NonMatching Beliefs task, agents get no points for a 
pllm unless they agree on the reasons underlying each 
action that contributes to the plan. 
The way I'ERFORMANCI! is defined reflects the litct 
that agents m'e me,'mt o collaborate on the tlksk. The 
costs that ~u'e deducted liom tbe RAW SCORE are the 
costs for both agents' communication, inference, m~d 
retrieval. Thus PERFORMANCE is a measnre of LEAS'I" 
COLI,ABORATIVE EFFORT \[Cl~u'k and Scbaeler, 1989; 
Brennan, 19901. Since the par~uneters for cognitive f- 
lk~rt iu'e fixed while discom'se strategy and AWM settings 
iue vltried, we can directly test the benefits of different 
discourse strategies under different assumptions ~d)ont 
cognitive ffort and Ihe cognitive demands of the task. 
This is impossible to do with corpus imldysis alone. 
We simulate 100 dildogues at each pmiuncter setting 
lk)r each strategy. Differences in perfimnance distri- 
butions ~u'e wduated l'or significance over the 100 dia- 
logues using the Kohnogorov-Smimov (KS) two siunple 
test I Siegel, 1956 I. 
/208 
A strategy A is I~F.NI:,FiCIAI, as compmcd to a strategy 
B, for a sel of lixed parameter settings, if the diflerence in 
distributions using the Kobnogorov-Smirnov two sam- 
ple test is signilicmlt at p < .05, in the positive direction, 
for two or more AWM settings. A slrategy is DETRI- 
MI!N'IAI, if tile differences go in tile negalive direction. 
Slratcgics may be neither BENF, FICIA1, or I)ETRIMF, NTAI,, 
as lhere may be no dillerence between two strategies. 
4 Results: Explicit Warrant 
This section discusses the results of compm'ing the 
Explicit-Wmranl discourse strategy with the All-Implicit 
discotuse slrategy to determine when each slralegy is 
BENEH(:IAI,. We test 4 factors outlined in figure 1 : when 
the wal'rlull is salient or  nol, when the w~u'falll is required 
for the task or not, when the cosls of retrieval and com- 
munication vary, and when retrieval is indeterufinate. 
Dilli~rences in performmlce between the Explicit- 
Warrallt slrategy and tile All-hnplicit slrategy ~ue shown 
via a I)IFFI2RI!NCE I'LOT such as ligme 3. In figure 3 
pcrform~mce differences are plolled on the Y-axis and 
AWM seltings are shown on the X-axis. If the plot 
is above file dotted line for 2 or more AWM settings, 
then the Explicit-Warrant strategy may be IIENt{FI(:IAI, 
depending on whether the differences are signilic,'mt by 
the KS lest. Each point represents he difference in the 
means of 100 runs of each stralegy at a l)mticul~u" AWM 
selling. Those plots summarize the results of 1800 sim- 
ulated dialogues: 100 lbr each AWM setting lot each 
stralegy. 
Explicit Wa,'rant reduces Retrievals 
oost  - i o i - i o i2  b i l l - k in~ O= 1 , I = 1 , R ~ 0 
_o  
~ - - - -  I -  1 ? f I F q 
Figure 3: If Retrieval is Free, Explicit-Win'hint is detri- 
mental at AWM of 3,4,5: Strategy l of two Explicit- 
Warrant agents and slrategy 2 of two All-hnplicit agents: 
Task = Standard, commcost = 1, infcost = 1, retcost = 0 
Dialogues in which one or both agents use the Explicit- 
Warrant strategy m'e more eflicient when relriev~d has a 
cost. 
Figure 3 shows that the Explicil-Wmr~mt s rategy is 
I)HRIMI!NTAI, at AWM of 3,4,5 for the St~mdard lask, 
oo~t  - i e i - i o i2  b i l l - k i rn  c - -  1 , I ~ 1 , F3 - -  0 .01  
j o  
jo  
o 2 "l ~ 8 I O ~ 4 
Figure 4: Relrieval costs: Strategy 1 is two Explicit- 
Winrant agents m~d strategy 2 is two All-hnplicit agents: 
Task = Sl~mdard, commcost = 1, infcost = 1, retcost = 
.01 
cost  - i e i - i o i2  b i l l - k im C-  lO  , I - -  O , R = o 
i:{ J 
Al l  o l~t lO lWWo rk l l l \ [ /  Mo l l \ ]o ry  
Figure 5: l fCommuuication is Expensive: Communica- 
lion costs c~ul dominate other costs in dialogues. Strategy 
i is two Explicit-Warrant agents ,'rod strategy 2 is two 
All-hnplicit agents: Task = Stmld,'u'd, commcost = 10, 
infcost = 0, retcost = 0 
in compm'ison with tile All-hnplicit strategy, if relrieval 
fi'om memory is fi'ee (KS 3,4,5 > .19, p < .05). This 
is because making the wammt salient displaces infor- 
mation about other pieces of furniture when agents m'e 
attention-limited. In the St,'uld~u'd t&sk, agents m'en't re- 
quired to sh,'ue beliefs about the value of a proposed, so 
remembering what pieces they have is more importmlt 
than remembering their value. 
However, figure 4 shows that Explicit-Wm'rm~t is ben- 
elici~d when retrieval is one tenth tile cost of communi- 
cation :rod inference. By AWM v,'dues of 3, performance 
1209 
wilh Explicit-W~u'rant is belier than All-Implicit because 
lhe beliefs necess~n'y for deliberation are made salienl 
with each proposal (KS lk)r AWM of 3 and above > 
.23, p < .01). At AWM parameter settings el' 16, where 
agenls have lhe ability to search all their beliefs lk)r war- 
rants, the saving in processing time is substantial. Again 
at the lowest AWM seltings, the slrategy is not benefi- 
cial because it displaces information about other pieces 
fronl AWM. However in figure 4, in conlr&st wilh ligure 
3, retrieval has an associated cost. Thus Iho savings in 
relriowtl balance out wilh the loss of raw score so that ile 
strategy is nol I\]I!TRIMENTAI. ()ther experiments show 
that even when the relative cost of retrieved is .0001, that 
Explicit-Wanant is still benelicial at AWM settings of 
I 1 ~md 16 (KS Ik/r 11,16 > .23 ,  p < .01). 
Explicit Warrant is detrimental if Communication is 
Expensive 
If we ch~mge the relative cosls of the dillerent processes 
in the siluation, we change whether a strategy is beneli- 
cial. Figure 5 shows that if connnnnication cost is 10, 
~md inlerence and rolrieval ~u'e li'ee, then the Expl ic it-  
Wlu'i'~nll strategy is DI,ITRIMI\]N'IAL (KS for AWM 1 to 5 
> .23, p< .01). This is because the Explicit-Warr~mt 
slralegy increases the number of ntter~mces required to 
perform Ihe task; it doubles the number of messages in
every proposal. If communication is expensive com- 
pared to retrieval, communication cost can dominate the 
other benelits. 
l!;xplicit Warrant Achieves a High Level of 
Agreement 
I f  we change lhe dol init ion o f  success in the ta:sk, we 
change whether a slrategy is benelicial. When the l&sk is 
Zero-Nouiilatching-Beliefs, the Explicit-W~u'ranl strat- 
egy is beneficial oven i f  retrieval is f iee (KS > .23 for 
AWM ll'onl 2 lo 11, p < .01)The warranl inl\]Jrnlation 
that is redundantly provided is exactly tilt inlk)rmation 
that is needed in order to achieve inatching beliel\s about 
Ihe warranls for intended actions. Tile strategy virtual ly 
gu~u~nllees thai the agenls will agree on the re&sons l(/l' 
carrying onl a particular course of action. The fact that 
relrieval is indclcrminate produces this effect; a simi- 
hit resnll is oblained when wm'r~mls are required and 
relriewll costs someihing. 
To my great surprise, Ihe benelicial effect of Explicit- 
W~uralll for the Zero-NonMatching-Beliefs task is so 
robust thal even if communication cost is 10 and re- 
irieval and inference are fl+ee, Explicil-Warrant is better 
than AII-hnplicit at AWM of 3 ?.. 11 (KS > .23, p < 
.0l). See ligure 6. In other words, even when every 
extra WARRANT message incurs a penalty of 10 poinls, 
if the task is Zero-NonMatching-Beliefs, agents using 
Explicit-W~u'rant do belier. Contrasl igure 6 with the 
Standard t~tsk ~md s~une cost p~n'amelers in 5. 
These result suggesls thai including w~u'rants is highly 
effective when agents must agree on a specilic w~ua~u/t, 
if lhey are atlenlion-limited to any extent. 
5 (~t lnc l l l s ion  
This paper has discussed an iuslaiice o f  a general prob- 
loin in tile design o f  convorsalional agents: when lo 
inchido optional infornlation. We presented and lested a 
nunlber of  hypotheses aboul the factors lhat conlr ibnle 
g 
7~ 
<q 
ITlatotl - iei-ioi2 bill-kiln C= 10 , I ~ 0 , F{ = 0 
/ . . o / ? / ? ~  
/ 
- - 7 ; ,', ; - - - - t ,  ,'~ ,L, ,L 
Figure6: Explicit-Warranl is STILL benelicial: Strategy 
1 is two Explicit-W~u'ranl agents ~md slrategy 2 is two 
All-Implicit agents: qlisk = Zero-Nonmatching-Bcliel~s, 
commcost = 10, inl~;ost = (/, retcost = 0 
to tile decision of when Io include a w:urant in a pro- 
posed. We showed thai w~ur~mts ~u'e useful when the task 
requires agreement on the warrant, when the win'rant is 
not currently s~dient, when retrieval of tile w~u-r~mt is in- 
determinate, or when retriewd has some associated cost, 
and that warranls hinder perfornlance if communication 
is costly ~uld if tim w~urant c~ul displace inli.)rnlation that 
is needed to complete the task, e.g. when AWM is very 
limited and wm'r\[mts ~ue not required to be shared. 
Tile method used here is a new experimental method- 
elegy for computational linguistics that supports testing 
hypotheses about benelici~d isconrse strategies \[Car- 
letta, 1992; Pollack and Ringuelle, 1990\]. The Design- 
World environment is b~tsed on a cognitive model of 
limited attention ~md supports experimenls on the in- 
teraction of discourse strategies with agents' cognitive 
limitations. The use of the method and the focns of lhis 
wtnk are novel: previous work has l~)CliSed Oil determin- 
ing nnderlying mechanisnls ?~r cooperative strategies 
rather than on investigating when a slrategy is elIective. 
To my knowledge, no previous work on di;dogue l/~ts 
ever argued that conversational agents' resonroe l imits 
are a lnajor factor in determining ?IIective conversational 
strategies in collaboration. Tim resulls presented here 
suggest that cooperative strategies cannot be delhied in 
the abslracl, but cooperation arises from the interaction 
of two agents in dialogue. If one agent has limited work- 
ing memory, then the ()thor agenl can make the di~doguc 
go more slnoothly by adopting astrategy that makes de- 
liberative premises salient. In other words, slrategies ~ue 
cooperative for certain conversational p;u'tners, in/der 
particular task delinitions, lor p~uticul~u communicalion 
situations. 
Here we compared two discourse strategies: All- 
hnplicit ~ul(l Explicit-Warr~mh Explicit-W;uranl is a 
type of discourse stralegy called ~m Attelition strategy 
in \[W;dkel; 1993\] because its main lunction is to ma- 
nipulate agents' altenlional slate. Elsewhere we show 
1210 
that (1) some IRU strategies are only beneficial when in- 
ferential complexity is higher Ihall in the Standard "l,u,~k 
\[R~unbow and Walker, 1994; Walker, 1994al; (2) IRUs 
that make intL'rences explicit can help inlbrence lim- 
ited agents perlorm as well as logic;ally omniscient ones 
I Walker, 199311. 
Although much work remains to be done, there is rea- 
son to believe that these results are (Iomsdn independent. 
The simplicity of the Design-World task inemls thai its 
,',;trllCttlr(.; is a stlbCOlllpOl/enl of malty other task,,,;. The 
model of limited resources is cognilively based, but the 
cosl pmameters support modeling diflcrent ageil\[ archi- 
lectures, and we exl)h)red the effects of dilli:rent cost 
l)ar~unelers. The Exl)licil-WmTant strategy is b~used on 
simple relationships between different ihcls which we 
would expect o occur in any domain, i.e. the lact that 
some belief csm be ilsed sis a WARRANT fi)r accepting a
l)roposal should occur in sdmost any task. Future work 
should extend these results, showing that a 'cooperative 
strategy' need not always be 'coopcralive', sut(l inves- 
tigate additional factors thai determine when strategies 
me effective. 
Re ferences  
\[Baddeley, 1986\] Alan Baddclcy. Workit~g Memory. 
()xford University Press, 1986. 
I Blcmum, 19901 Susan E. BleltllHl\]. Seeking attd Pro- 
viding Evidem:e \[br Mutual UnderstatMing. PhD the- 
sis, Stanlbrd University Psychology I)epl., 19911.11n- 
pul)lished Manuscript. 
\[Carletta, 19921 Je~m C. Carlelta. Risk J'uking and Re- 
covery in 7ask-Oriented Dialogue. t'hD thesis, Edin- 
burgh Universily, 1992. 
\[Clarkand Schaefer, 1989\] llerberl tl. Clark and Ed- 
ward F. Schaefer. Contributing lo discourse. Cog- 
nitive Sciem:e, 13:259-294, 1989. 
I Doyle, 19921 Jon Doyle. Rationality and ils roles in 
re~e;oning. Conqmlatiomfl Intelligem:e, November 
1992. 
IGalliers, 19911 Julia R. Gsdliers. Autonomous belief 
revision and communication, in 1: Gardenfors, ed- 
itor, Bel&f Revision, pages 220 - 246. Cmnbridge 
tJniversily Press, 1991. 
\[llanks et al, 1993 \[ Steve Ilanks, Mmlha E. Pollack, 
and Paul R. Cohen. Benchmarks, testbetls, controlled 
experimenlation a d the design of agent architectures. 
AI Magazine, I)ecembcr 1993. 
\[llinlznuu|n alld Bh)ck, 1971\] 1). 1,. tlinlznuum and 
R. A. Block. Rcpclilion and incmory: evidence lot 
st multiple Irate hypolhesis. Journal ofl",q~erimental 
Psychology, 88:297-306,1971. 
\[Landauer, 19751 Thomas K. l~mldauer. Memory with- 
out organization: Properties of a model with random 
storage and undirected retrieval. Cognitive Psychof 
ogy, pages 495-.531, 1975. 
IMann and Thompson, 19871 W.C. Mann and S.A. 
"l'homlJSOn. Rhetorical slrllClllre theory: l)escriplion 
and conslrllc|io\]t of text structures. In Gcrmd Kern- 
pen, editor, NaturalLa,gttage (l ,eration, pages 83- 
96. Maitinus Nijhofl', 1987. 
\[ Moore and Paris, 19931 Johallna D. 
Moore and C6cile L. Paris. Planning text for advi- 
sory di~dogues: Capturing intentional mid rhetorical 
infornmtion. ComputationalLinguistics, 19(4), 1993. 
\[Normsul and Bobmw, 1975l Donald A. Nonnan and 
l)mfiel G. Bobmw. ()n dala-limited and resource- 
limited processes. Cognitive Psychoh)gy, 711):44 6, 
1975. 
\[Pollack et al, 19821 Martha Pollack, Julia flirschberg, 
and Bonnie Webber. I, Jscr i,articil)ation i Ihe reason- 
ing process of expert systems. In AAAI82, 1982. 
IPollack and Ringuette, 19901 Martha E. Pollack and 
Marc Ringuette. Introducing the Tileworld: ExperiL- 
mentally Evsduating Agent Architectures. Ill AAAI90, 
pages 183-189, 1990. 
\[Power, 1984\] Richmd Power. Mutual intention..lour- 
nalJor the Theory of Sociul Behaviour, 14, 1984. 
\[Prince, 1981\] Ellen F. Prince. qbward a taxonomy of 
given-new information. InRadical Pragmatics, pages 
223- 255. Academic Press, 1981. 
\[Rainbow and Walker, 1994\] ()wen Rainbow ~u/d Mar- 
ilyn A. Walker. The role of cognitive modeling in 
COlllillllnicative intenlions. In The 7th ltllertzaliotla\[ 
Cotff?rem:e on Natltral Lattgttage Generation, 1994. 
\[Sidncr, 19921 Candace Sidner. Using discourse to ne- 
gotiate in collaborative activity: An artilicial lan- 
guage. AAAI Workshop ott Cooperation among Ilet- 
erogeneous Agents, 1992. 
\[Siegel, 19561 Sidney Siegel. Nonparametric Statistics 
fi)r the Behavioral Sciences. McGraw l lill, 1956. 
IWalkel', 19921 Marilyn A. W:dker. Redun&mcy in col- 
laborative dialogue. In I"ourteenth lntertJutionalCon- 
ferem:e on COmlmtatiomtl Linguistics, pages 345. 
351, 1992. 
IWalker, 19931 Marilyn A. Walker. In/i,mational Re- 
dundatwy aml Resource lloutlds in I)ialogue. l 'hl) 
thesis, University of Pennsylvania, 1993. 
IWalker, 1994al Marilyn A. Walker. Experimentally 
cv~dualing commtlnicative slralegies: The ellibel of 
the lask. In AAAI94, 1994. 
IWalker, 1994bl Marilyn A. Walker. Rejection by im- 
plicalure. In Proceedings of the 20th Meeting of the 
Berkeley Lingustics Society, 1994. 
IWtdker stud Whittaker, 19901 Mmilyn A. Walker mtd 
Steve Whillaker. Mixed initiative in dialogue: An 
investigation i to discourse segmetllalion. Ill l'roc. 
281h Annual Meeting qf the ACL, pages 70 79, 1991). 
\[Webber and Joshi, 19821 Bonnie Webbcr mtd Aravind 
Joshi. Taking the iniliative in natural language 
dalabw;e interaction: Justifying why. In COLING84: 
l'roc. 9lh Interttatiot~al (7ot~J?tetzce on Computational 
Linguistics. Prague, 1982. 
IWhittakeretal., 19931 Steve Whittaker, Erik (3eel- 
hoed, and Elizabeth Robinson. Shmed workspaces: 
I low do they work and when are they usefitl? LIMMS, 
39:813 842,1993. 
1211 
