Proceedings of the 6th Workshop on Statistical Machine Translation, pages 140?144,
Edinburgh, Scotland, UK, July 30?31, 2011. c?2011 Association for Computational Linguistics
The UPV-PRHLT combination system for WMT 2011
Jesu?s Gonza?lez-Rubio and Francisco Casacuberta
Instituto Tecnolo?gico de Informa?tica
Departamento de Sistemas Informa?ticos y Computacio?n
Universitat Polite`cnica de Vale`ncia
{jegonzalez|fcn}@dsic.upv.es
Abstract
This paper presents the submissions of the pat-
tern recognition and human language technol-
ogy (PRHLT) group to the system combina-
tion task of the sixth workshop on statistical
machine translation (WMT 2011). Each sub-
missions is generated by a multi-system mini-
mum Bayes risk (MBR) technique. Our tech-
nique uses the MBR decision rule and a linear
combination of the component systems? prob-
ability distributions to search for the minimum
risk translation among all the sentences in the
target language.
1 Introduction
The UPV-PHRLT approach to machine translation
(MT) system combination is based on the mini-
mum Bayes risk system combination (MBRSC) al-
gorithm (Gonzlez-Rubio et al, 2011). A multi-
system MBR technique that computes consensus
translations over multiple component systems.
MBRSC operates directly on the outputs of the
component models. We perform an MBR decod-
ing using a linear combination of the component
models? probability distributions. Instead of re-
ranking the translations provided by the component
systems, we search for the hypothesis with the min-
imum expected translation error among all the pos-
sible finite-length strings in the target language. By
using a loss function based on BLEU (Papineni et
al., 2002), we avoid the hypothesis alignment prob-
lem that is central to standard system combination
approaches (Rosti et al, 2007). MBRSC assumes
only that each translation model can produce expec-
tations of n-gram counts; the latent derivation struc-
tures of the component systems can differ arbitrary.
This flexibility allows us to combine a great variety
of MT systems.
2 Minimum Bayes risk Decoding
SMT can be described as a mapping of a word se-
quence f in a source language to a word sequence
e in a target language; this mapping is produced by
the MT decoder D(f). If the reference translation
e is known, the decoder performance can be mea-
sured by the loss function L(e,D(f)). Given such a
loss function L(e, e?) between an automatic transla-
tion e? and a reference e, and an underlying proba-
bility model P (e|f), MBR decoding has the follow-
ing form (Goel and Byrne, 2000; Kumar and Byrne,
2004):
e? = arg min
e??E
R(e?) (1)
= arg min
e??E
?
e?E
P (e|f) ? L(e, e?) , (2)
where R(e?) denotes the Bayes risk of candidate
translation e? under loss function L, and E repre-
sents the space of translations.
If the loss function between any two hypotheses
can be bounded: L(e, e?) ? Lmax, the MBR de-
coder can be rewritten in term of a similarity func-
tion S(e, e?) = Lmax ? L(e, e?). In this case, in-
stead of minimizing the Bayes risk, we maximize
the Bayes gain G(e?):
e? = arg max
e??E
G(e?) (3)
= arg max
e??E
?
e?E
P (e|f) ? S(e, e?) . (4)
MBR decoding can use different spaces for hy-
pothesis selection and gain computation (arg max
and sum in Eq. (4)). Therefore, the MBR decoder
can be more generally written as follows:
e? = arg max
e??Eh
?
e?Ee
P (e|f) ? S(e, e?) , (5)
140
where Eh refers to the hypotheses space form where
the translations are chosen and Ee refers to the evi-
dences space that is used to compute the Bayes gain.
We will investigate the expansion of the hypotheses
space while keeping the evidences space as provided
by the decoder.
3 MBR System Combination
MBRSC is a multi-system generalization of MBR
decoding. It uses the MBR decision rule on a linear
combination of the probability distributions of the
component systems. Unlike existing MBR decoding
methods that re-rank translation outputs, MBRSC
search for the minimum risk hypotheses on the com-
plete set of finite-length hypotheses over the out-
put vocabulary. We assume the component systems
to be statistically independent and define the Bayes
gain as a linear combination of the Bayes gains
of the components. Each system provides its own
space of evidences Dn(f) and its posterior distribu-
tion over translations Pn(e|f). Given a sentence f in
the source language, MBRSC is written as follows:
e? = arg max
e??Eh
G(e?) (6)
? arg max
e??Eh
N?
n=1
?n ? Gn(e?) (7)
= arg max
e??Eh
N?
n=1
?n ?
?
e?Dn(f)
Pn(e|f) ? S(e, e?) , (8)
where N is the total number of component systems,
Eh represents the hypotheses space where the search
is performed, Gn(e?) is the Bayes gain of hypothe-
sis e? given by the nth component system and ?n is
a scaling factor introduced to take into account the
differences in quality of the component models. It is
worth mentioning that by using a linear combination
instead of a mixture model, we avoid the problem
of component systems not sharing the same search
space (Duan et al, 2010).
3.1 Computing BLEU-based Gain
We are interested in performing MBRSC under
BLEU. Therefore, we rewrite the gain function G(?)
using single evidence (or reference) BLEU (Pap-
ineni et al, 2002) as the similarity function:
Gn(e?) =
?
e?Dn(f)
Pn(e|f) ? BLEU(e, e?) (9)
BLEU =
4?
k=1
(
mk
ck
) 1
4
?min
(
e1?
r
c , 1.0
)
, (10)
where r is the length of the evidence, c the length of
the hypothesis, mk the number of n-gram matches
of size k, and ck the count of n-grams of size k in
the hypothesis.
The evidences space Dn(f) may contain a huge
number of hypotheses1 which often make impracti-
cal to compute Eq. (9) directly. To avoid this prob-
lem, Tromble et al (2008) propose linear BLEU, an
approximation to the BLEU score to efficiently per-
form MBR decoding on the lattices provided by the
component systems. However, we want to explore a
hypotheses space not restricted to the evidences pro-
vided by the systems.
In Eq. (9), we have one hypothesis e? that is to be
compared to a set of evidences e ? Dn(f) which
follow a probability distribution Pn(e|f). Instead
of computing the expected BLEU score by calcu-
lating the BLEU score with respect to each of the
evidences, our approach will be to use the expected
n-gram counts and sentence length of the evidences
to compute a single-reference BLEU score. We re-
place the reference statistics (r and mn in Eq. (10))
by the expected statistics (r? and m?n) given the pos-
terior distribution Pn(e|f) over the evidences:
Gn(e?) =
4?
k=1
(
m?k
ck
) 1
4
?min
(
e1?
r?
c , 1.0
)
(11)
r? =
?
e?Dn(f)
|e| ? Pn(e|f) (12)
m?k =
?
ng?Nk(e?)
min(Ce?(ng), C
?(ng)) (13)
C ?(ng) =
?
e?Dn(f)
Ce(ng) ? Pn(e|f) , (14)
where Nk(e?) is the set of n-grams of size k in the
hypothesis, Ce?(ng) is the count of the n-gram ng in
1For example, in a lattice the number of hypotheses may be
exponential in the size of its state set.
141
the hypothesis and C ?(ng) is the expected count of
ng in the evidences. To compute the n-gram match-
ings m?k, the count of each n-gram is truncated, if
necessary, to not exceed the expected count for that
n-gram in the evidences.
We have replaced a summation over a possibly ex-
ponential number of items (e? ? Dn(f) in Eq. (9))
with a summation over a polynomial number of n-
grams that occur in the evidences2. Both, the ex-
pected length of the evidences r? and their expected
n-gram counts m?k can be pre-computed efficiently
from N -best lists and translation lattices (Kumar et
al., 2009; DeNero et al, 2010).
3.2 Model Training
The scaling factors in Eq. (8) denote the ?quality? of
each system with respect to the rest of them, i.e. the
relative importance of each system in the Bayes gain
computation. This scaling factors must be carefully
tuned to obtain good translations.
We compute the scaling factor of each system as
the number of times the hypothesis of the system is
the best TER-scoring translation in the tuning cor-
pora. Previous works show that this measure ob-
tains the best translation results among other heuris-
tic measures (Gonza?lez-Rubio et al, 2010) and even
as good results as more complex methods such as
MERT (Och, 2003). A normalization is performed
to transform these counts into the range [0.0, 1.0].
After the normalization, a weight value of 0.0 is as-
signed to the lowest-scoring system, i.e. the lowest-
scoring system is discarded and not taken into ac-
count in the computation of the Bayes gain.
3.3 Model Decoding
In most MBR algorithms, the hypotheses space is
equal to the evidences space. However, we are inter-
ested in extend the hypotheses space by including
new sentences created using fragments of the hy-
potheses in the evidences spaces of the component
models. We perform the search (argmax opera-
tion in Eq. (8)) using the approximate median string
(AMS) algorithm (Mart??nez et al, 2000). AMS
algorithm perform a hill-climbing search on a hy-
potheses space equal to the free monoid ?? of the
vocabulary of the evidences ? = V oc(Ee).
2If Dn(f) is represented by a lattice, the number of n-grams
Algorithm 1 MBRSC decoding algorithm.
Require: Initial hypothesis e
Require: Vocabulary the evidences ?
1: e?? e
2: repeat
3: ecur ? e?
4: for j = 1 to |ecur| do
5: e?s ? ecur
6: for a ? ? do
7: e?s ? Substitute(ecur, a, j)
8: if G(e?s) > G(e?s) then
9: e?s ? e?s
10: e?d ? Delete(ecur, j)
11: e?i ? ecur
12: for a ? ? do
13: e?i ? Insert(ecur, a, j)
14: if G(e?i) > G(e?i) then
15: e?i ? e?i
16: e?? arg maxe??{ecur,e?s,e?d,e?i} G(e
?)
17: until G(e?) 6> G(ecur)
18: return ecur
Ensure: G(ecur) ? G(e)
The AMS algorithm is shown in Algorithm 1.
AMS starts with an initial hypothesis e3 that is mod-
ified using edit operations until there is no improve-
ment in the Bayes gain (Lines 3?16). On each posi-
tion j of the current solution ecur, we apply all the
possible single edit operations: substitution of the
jth word of ecur by each word a in the vocabulary
(Lines 5?9), deletion of the jth word of ecur (Line
10) and insertion of each word a in the vocabulary in
the jth position of ecur (Lines 11?15). If the Bayes
gain of any of the new edited hypotheses is higher
than the Bayes gain of the current hypothesis (Line
17), we repeat the loop with this new hypotheses e?,
in other case, we return the current hypothesis.
AMS algorithm takes as input an initial hypothe-
sis e and the combined vocabulary of the evidences
spaces ?. Its output is a possibly new hypothesis
whose Bayes gain is assured to be higher or equal
than the Bayes gain of the initial hypothesis.
The complexity of the main loop (lines 2-17) is
O(|ecur| ? |?| ? CG), where CG is the cost of com-
is polynomial in the number of edges in the lattice.
3In the experimentation we use the evidence with minimum
Bayes? risk as the initial hypothesis of the algorithm.
142
cz?en en?cz de?en en?de es?en en?es fr?en en?fr
#systems 12 14 25 34 15 22 23 21
de
v
Worst 15.6 8.8 12.8 4.5 15.1 20.3 15.8 13.9
Best 25.9 16.9 22.2 16.3 27.8 32.7 28.6 35.5
MBRSC 26.7 15.9 22.2 17.1 30.5 33.3 30.2 34.7
te
st
Worst 13.3 9.1 12.9 5.1 14.7 20.7 16.1 13.0
Best 27.2 18.6 21.9 16.7 27.4 32.5 28.1 33.5
MBRSC 27.9 17.7 22.1 16.5 30.4 32.9 29.6 32.7
Table 1: BLEU scores (case-sensitive) on the shared translation task development and test corpora of the best and
worst single systems and MBRSC. For each translation direction, we show the number of systems being combined.
Best translation results are in bold.
puting the gain of a hypothesis, and usually only a
moderate number of iterations (< 10) is needed to
converge (Mart??nez et al, 2000).
4 Results
Experiments were conducted on all the 8 translation
directions of the shared translation task Czech?
English (cz?en), German?English (de?en),
Spanish?English (es?en) and French?English
(fr?en) and also on the raw and clean versions
of the Haitian creole?English featured translation
task (ht?en). All the experiments were carried
out with the true-cased, detokenized version of the
tuning and test corpora, following the WMT 2011
submission guidelines.
4.1 Shared translation task
Table 1 shows the BLEU scores of MBRSC on the
development and test corpora in comparison with
the score of the best and worst individual systems.
In most of the translation directions, MBRSC im-
proved the results of the best individual system,
e.g. +2.7/+3.0 BLEU point in es?en. However,
in en?cz and en?fr, MBRSC performs worse than
the best individual system. One thing we noticed is
that for these translation directions, the translations
from one provided single system (online-B) were
much better in terms of BLEU than those of all other
systems (in the former case by more than 14% rel-
ative in development). In our experience, MBRSC
requires ?comparably good? systems to be able to
achieve significant improvements (particularly if us-
ing heuristic scaling factors). On the other hand, we
would have achieved improvements over all remain-
ing systems leaving out online-B.
4.2 Featured translation task
Regarding the ht?en featured translation task,
MBRSC is not able to improve the results of the
best individual system in any case. As in the en?cz
and en?fr translation directions, one of the systems
(bm-i2r) perform much much better than all other
systems. We can notice the surprisingly low score
of one of the systems (umd-hu) in the clean task.
The translations of this system are all equal (?N /
A?) so we suppose that some error occurred during
the translation or submission processes.
ht?en
raw clean
#systems 8 16
worst 15.4 2.9
best 29.6 33.1
MBRSC 28.6 32.2
Table 2: BLEU scores (case-sensitive) on the featured
translation task development corpora of the best and
worst single systems and MBRSC. Best translation re-
sults are in bold.
5 summary
The UPV-PRHLT submissions for WMT 2011 sys-
tem combination task were described in this paper.
The combination was based on a multi-system MBR
technique that uses the MBR decision rule and a lin-
ear combination of the component systems? proba-
bility distributions to search for the minimum risk
translation among all the finite-length strings in the
output vocabulary. We introduced expected BLEU,
143
an approximation to the BLEU score that allows to
efficiently apply MBR in these conditions. In most
of the translation directions we were able to obtain
BLEU gains over the best individual systems.
Acknowledgements
This paper is based upon work supported by the EC
(FEDER/FSE) and the Spanish MEC/MICINN un-
der the MIPRCV ?Consolider Ingenio 2010? pro-
gram (CSD2007-00018), the iTrans2 (TIN2009-
14511) project and the UPV under grant 20091027.
Also supported by the Spanish MITyC under the
erudito.com (TSI-020110-2009-439) project and by
the Generalitat Valenciana under grant Prome-
teo/2009/014.
References
John DeNero, Shankar Kumar, Ciprian Chelba, and Franz
Och. 2010. Model combination for machine trans-
lation. In Human Language Technologies: The 2010
Annual Conference of the North American Chapter of
the Association for Computational Linguistics, pages
975?983, Morristown, NJ, USA. Association for Com-
putational Linguistics.
Nan Duan, Mu Li, Dongdong Zhang, and Ming Zhou.
2010. Mixture model-based minimum bayes risk de-
coding using multiple machine translation systems. In
Proceedings of the 23rd International Conference on
Computational Linguistics (Coling 2010), pages 313?
321, Beijing, China, August. Coling 2010 Organizing
Committee.
Vaibhava Goel and William J. Byrne. 2000. Minimum
bayes-risk automatic speech recognition. Computer
Speech & Language, 14(2):115?135.
Jesu?s Gonza?lez-Rubio, Germa?n Sanchis-Trilles, Joan-
Andreu Sa?nchez, Jesu?s Andre?s-Ferrer, Guillem Gasco?,
Pascual Mart??nez-Go?mez, Martha-Alicia Rocha, and
Francisco Casacuberta. 2010. The upv-prhlt combi-
nation system for wmt 2010. In Proceedings of the
Joint Fifth Workshop on Statistical Machine Trans-
lation and MetricsMATR, pages 296?300, Uppsala,
Sweden, July. Association for Computational Linguis-
tics.
Jess Gonzlez-Rubio, Alfons Juan, and Francisco Casacu-
berta. 2011. Minimum bayes-risk system combina-
tion. In Proceedings of the 49th Annual Meeting of
the Association for Computational Linguistics: Hu-
man Language Technologies, pages 1268?1277, Port-
land, Oregon, USA, June. Association for Computa-
tional Linguistics.
Shankar Kumar and William J. Byrne. 2004. Minimum
bayes-risk decoding for statistical machine translation.
In HLT-NAACL, pages 169?176.
Shankar Kumar, Wolfgang Macherey, Chris Dyer, and
Franz Och. 2009. Efficient minimum error rate train-
ing and minimum bayes-risk decoding for translation
hypergraphs and lattices. In Proceedings of the Joint
Conference of the 47th Annual Meeting of the ACL and
the 4th International Joint Conference on Natural Lan-
guage Processing of the AFNLP: Volume 1 - Volume 1,
pages 163?171, Morristown, NJ, USA. Association for
Computational Linguistics.
C. D. Mart??nez, A. Juan, and F. Casacuberta. 2000. Use
of Median String for Classification. In Proceedings of
the 15th International Conference on Pattern Recog-
nition, volume 2, pages 907?910, Barcelona (Spain),
September.
Franz J. Och. 2003. Minimum error rate training in
statistical machine translation. In Proceedings of the
41st Annual Meeting on Association for Computa-
tional Linguistics - Volume 1, pages 160?167, Morris-
town, NJ, USA. Association for Computational Lin-
guistics.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. BLEU: a method for automatic
evaluation of machine translation. In Proceedings of
the 40th Annual Meeting on Association for Compu-
tational Linguistics, pages 311?318, Morristown, NJ,
USA. Association for Computational Linguistics.
Antti-Veikko Rosti, Necip Fazil Ayan, Bing Xiang, Spy-
ros Matsoukas, Richard Schwartz, and Bonnie Dorr.
2007. Combining outputs from multiple machine
translation systems. In Human Language Technolo-
gies 2007: The Conference of the North American
Chapter of the Association for Computational Lin-
guistics; Proceedings of the Main Conference, pages
228?235, Rochester, New York, April. Association for
Computational Linguistics.
Roy W. Tromble, Shankar Kumar, Franz Och, and Wolf-
gang Macherey. 2008. Lattice minimum bayes-risk
decoding for statistical machine translation. In Pro-
ceedings of the Conference on Empirical Methods in
Natural Language Processing, pages 620?629, Mor-
ristown, NJ, USA. Association for Computational Lin-
guistics.
144
