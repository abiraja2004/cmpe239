Proceedings of the Second Workshop on Hybrid Approaches to Translation, pages 42?50,
Sofia, Bulgaria, August 8, 2013. c?2013 Association for Computational Linguistics
An English-to-Hungarian Morpheme-based Statistical Machine
Translation System with Reordering Rules
La?szlo? J. Laki, Attila Nova?k, Borba?la Siklo?si
MTA-PPKE Language Technology Research Group
Pa?zma?ny Pe?ter Catholic University, Faculty of Information Technology
50/a Pra?ter Street, 1083 Budapest, Hungary
{surname.firstname}@itk.ppke.hu
Abstract
Phrase-based statistical machine transla-
tion systems can generate translations of
reasonable quality in the case of language
pairs with similar structure and word or-
der. However, if the languages are more
distant from a grammatical point of view,
the quality of translations is much behind
the expectations, since the baseline trans-
lation system cannot cope with long dis-
tance reordering of words and the mapping
of word internal grammatical structures.
In our paper, we present a method that tries
to overcome these problems in the case of
English-Hungarian translation by apply-
ing reordering rules prior to the translation
process and by creating morpheme-based
and factored models. Although automatic
evaluation scores do not reliably reflect the
improvement in all cases, human evalua-
tion of our systems shows that readabil-
ity and accuracy of the translations were
improved both by reordering and applying
richer models.
1 Introduction
Phrase-based statistical machine translation sys-
tems rely on statistical observations derived from
phrase alignments automatically extracted from
parallel bilingual corpora. The main advantage of
applying SMT is its language-independence. The
phrase-based model works well for language pairs
with similar syntactic structure and word order.
However, phrase-based models fail to handle
great word-order differences adequately. We de-
scribe our attempt to improve performance by
transforming source language (English) sentences
to a structure similar to that of the corresponding
target (Hungarian) sentence. We also describe our
approach for handling data sparseness due to the
inadequate coverage of linguistic structures by the
limited training corpus. It is a common problem in
the case of translation to agglutinating languages
like Hungarian, where a much greater amount of
training data would be necessary to provide ade-
quate statistics than what is necessary for closely
related language pairs involving only morphologi-
cally less complex languages.
2 Machine Translation from English to
Hungarian
English and Hungarian are rather distant regarding
morphological and syntactic structure and word
order. Hungarian, like Finish or Turkish, is an
agglutinating and compounding language, which
morphological processes yield a huge number of
different word forms. This, combined with free
word order of main grammatical constituents and
systematically different word order in NP?s and
PP?s, results in poor performance of traditional
phrase-based SMT systems. In order to have an
SMT system produce correct translations of high
quality, it is required to have a relevant statisti-
cal model acquired from bilingual corpora. Thus,
even if a corpus of a substantial size were available
(which is not the case), both the alignment phase
of constructing a translation model and translation
itself would be compromised by the high number
of seldom or never seen word forms.
3 Related work
For language pairs having very different syntactic
structure and word order, research has shifted to-
wards using hierarchical models or the use of hy-
brid methods, such as augmenting purely statisti-
cal approaches by handmade rules as a preprocess-
ing step. Such extensions have proved to improve
results significantly in systems translating from
English to German, Arabic or Turkish and several
other languages (Yeniterzi and Oflazer, 2010; Go-
42
jun and Fraser, 2012; Collins et al, 2005). The
hybrid models applied to English-Hungarian ma-
chine translation that we present in this paper be-
long to the latter line of research.
We applied both reordering and morphological
segmentation in order to handle both word order
problems and data sparseness caused by agglu-
tination. Luong et al (2010) applied only mor-
phological analysis in the case of translation from
English to Finnish. On the other hand, Yeniterzi
and Oflazer (2010) described an approach for En-
glish to Turkish translation, in which they applied
both syntactic source-side reordering and morpho-
logical segmentation. In their work, morphemes
constructing a single word were joined during the
translation process, but in our experiments, this
method increased data sparseness in the training
set, decreasing the quality of the final translation
rather than improving it. Another difference be-
tween Yeniterzi and Oflazer (2010)?s and our work
is that they applied the morphological generator
integrated in the SMT system, while we used our
computational morphology on SMT output as a
word form generator, generating final word forms
in cases, where the SMT system was not able to
find it.
Relying on recent trends and results of research
in the field of machine translation, we believe that
neither a purely rule-based nor a statistical method
by itself is an optimal way to handle the problem.
Our work reflects this attitude by applying hand-
made language-specific rules. Some works, such
as (Jiang et al, 2010; Holmqvist et al, 2012; Gen-
zel, 2010) have also tried deriving such reordering
rules automatically.
A further method to apply would be using a hi-
erarchical tree-based translation system, also aug-
mented by reordering rules and morphological
segmentation. Such a method is presented in (Gao
et al, 2011), but focusing on a narrower problem
and applying it to Chinese to English translation.
4 Hybrid morpheme-based machine
translation system with reordering
rules
In order to mitigate the aforementioned difficulties
regarding word order and data sparseness, we cre-
ated a hybrid system with different preprocessing
and decoding solutions. First we applied reorder-
ing rules in order to transform the source sentence
to a structure more appropriate for word alignment
Test Train
# of sentences 1000 1,026,836
Words
(AVG per sent.)
en 14.137 14.173
hu 11.672 11.764
Morphemes
(AVG per sent.)
en 16.764 16.768
hu 18.391 18.429
Table 1: Size of training and test datasets mea-
sured in the number of sentences, average number
of words per sentences and the average number of
morphemes per sentences on the English and Hun-
garian sides.
and phrase extraction. The problem of lexical
granularity (i.e. the relatively substantial differ-
ence in the number of words in the corresponding
sentences, see Table 1) was also to be solved. We
explored two approaches: a) increasing the num-
ber of tokens on both sides using morphemes in-
stead of words and b) decreasing the number of
word tokens on the English side to approximate
that of the corresponding Hungarian sentences.
4.1 Reordering rules
In order to augment the phrase-based SMT sys-
tem, we defined reordering rules as a preprocess-
ing step. The goal of these transformations is to
move words in the English source sentence to po-
sitions that correspond to their place in the Hun-
garian translation. Fig. 1 illustrates the trans-
formation process on the phrase the sons of the
many merchants living in the city. E.g., the sub-
phrase living in the city is transformed to the order
the city in living corresponding to the Hungarian
translation ?a va?ros+ban e?lo?? as shown in Fig. 1a.
Our rules apply only to those word order differ-
ences, which are systematically present between
the two grammars (e.g. prepositions vs. case end-
ings/postpositions). We did not intend to handle
free word order variations of Hungarian, where the
same meaning can be expressed with several dif-
ferent orderings, since the actual word order in a
sentence is not only determined by syntactic rules,
but also by pragmatic factors.
Dependency structure: Reordering rules are
guided by dependency relations. After generat-
ing a context-free parse, these relations are ex-
tracted by the Stanford parser (Marneffe et al,
2006) that we used in our experiments. The depen-
dency structure of our example is shown in Fig. 1b.
Thus the example phrase merchants living in
the city is transformed along the relations PART-
43
(a) Word alignment of a sentence pair before and after reorder-
ing
(b) Dependency structure of the sentence: The sons of the many
merchants living in the city
(c) The process of reordering along dependency relations.
Figure 1: Word alignment, dependency relations and reordering
MOD(merchant, living)1, PREP(living, in)1 and
POBJ(in, city)1. First the preposition is attached
to the child of the POBJ relation, then they are
positioned before the noun phrase preceding it as
shown in Fig. 1c. The resulting word order the city
in living merchants corresponds to the Hungarian
structure ?a va?ros+ban e?lo? kereskedo?k?.
Since these levels of analysis depend on each
other, errors arising at each phase propagate and
cumulate through the whole process having a sig-
nificant effect on reordering. Even though we
used the lexicalized version of the Stanford parser,
which is reported to work more accurately, it
still very often generates agrammatical parses with
agreement errors and odd PoS sequences as shown
in Table 2 (showing only the generated PoS tag se-
quences here).
1PARTMOD=participial modifier, PREP=prepositional
modifier, POBJ=object of preposition. The full
list of dependency relations can be found in
http://nlp.stanford.edu/software/
dependencies_manual.pdf
-/: 100/CD million/CD sound/NN good/JJ
to/TO me/PRP ./.
For/IN airline/NN personnel/NNS ,/, we/PRP
cash/NN personal/JJ checks/VBZ up/RP
to/TO $/$ 100/CD ./.
Table 2: Examples of low level errors (verbs
tagged as nouns and vice versa) that affect reorder-
ing and translation
Morpheme-based restructuring: Due to the
agglutinating nature of Hungarian, many func-
tion words in English are expressed as suffixes
in the Hungarian translation. In order to enable
the phrase-based system to have them correspond
to each other, we applied morphological analy-
sis on the Hungarian sentences segmenting each
word to their morphological constituents. To an-
notate the Hungarian side of the corpus, we used
the PurePos automated morphological annotation
system (Orosz and Nova?k, 2012). A simple ex-
ample is a phrase like in my house, which is
44
transformed to the form house my in correspond-
ing to the single word ?ha?zamban? in Hungarian.
The morphological segmentation of this word is
ha?z[N]+am[PxS1]+ban[Ine]1. Defining and ap-
plying the rules for such short phrases is not partic-
ularly difficult. However, related words in longer
sentences can be much further separated from each
other and they may be involved in more than one
relation, which often results in an interaction of
word order constraints. In a similar manner, some
rules insert morphological elements correspond-
ing to those present in the Hungarian sentence,
but not explicitly expressed in English, such as
the accusative case suffix or subject agreement of
verbs. These pieces of implicit structural informa-
tion can be induced from the dependency relations.
For example, in the English phrase giving/VBG
a/DT present/NN, the word present is tagged as
acc (based on its object role) corresponding to the
Hungarian accusative -t suffix resulting in the re-
ordered phrase of giving a present+acc now per-
fectly aligning to the Hungarian structure of ?adni
egy aja?nde?k+ot?
4.2 Lexical granularity
The number of words is often rather different in a
pair of Hungarian and English sentences enforcing
the alignment module of the SMT system to cre-
ate one-to-many or many-to-many alignments, or
simply leave tokens unaligned. Such alignments
often result in missing or ?hallucinated? words in
the translation. Table 1 shows the differences in
the average number of words and morphemes in
our parallel corpus. The average number of words
is smaller in Hungarian than in the English sen-
tences. On the other hand, at least at the granu-
larity of the morphological analysis we applied to
our data, the number of morphemes is higher in
Hungarian than in English. The number of tokens
on both sides can be made more similar by either
decreasing the number of words on the English
side by joining function words corresponding to
Hungarian suffixes or by increasing the number on
both sides using morphemes as tokens.
As the difference is primarily due to the fact
that some English function words are represented
as suffixes in Hungarian, the relative difference
between the number of morphemes in the cor-
responding sentences is lower than that of the
words. So one possible approach to solving the
1PxS1=Possessor:1Sg=?my?, Ine=Inessive=?in?
lexical granularity difference problem is to use
morphemes instead of words. One problem with
morpheme-based translation is that it is often the
case in longer sentences that instances of the same
functional morpheme belong to more than one dif-
ferent word in the sentence. This causes inde-
terminacies in the alignment process (because the
models implemented in the Giza++ word aligner
cannot be forced to assume locally monotone
alignment at the places where we in fact know that
the alignment should be monotone), which often
results in erroneous phrases being extracted from
the training corpus. For example, if there are two
nouns in a sentence and one of them is plural, then
the [PL] tag corresponding to this feature might
land at another noun.
The difficulty of aligning very frequent func-
tional morphemes is illustrated by the fact that
in the Giza++ alignments created from our train-
ing corpus, 39% of the nominal plural ([PL])
morphemes remained unaligned, 13% was not at-
tached to the noun it should have been attached to,
because the alignment was not monotone, while
1% was aligned to several (up to eight) instances
of the corresponding morpheme. Alignment is not
the only problem: some indivisible morpheme se-
quences (like noun+plural) should always stay to-
gether but we had concerns that, unless it is con-
strained to monotone decoding, the baseline dis-
tortion model of the decoder will often scatter suf-
fixes throughout the sentence instead. A lexical-
ized reordering model can be expected to solve
this problem, thus we used lexical reordering in
our models but for comparison we also tested how
each model performs when the decoder is con-
strained to monotone decoding.
Another approach we tested was fusing sepa-
rate words on the English side that correspond to
a single word in the Hungarian sentence (model-
ing English as an agglutinating language) to avoid
the aligner connecting these morphemes to some
other words on the Hungarian side and using a
factored model to try to solve the data sparse-
ness issues this move results in. For example,
possessive determiners are attached to the head
noun as suffixes in this model like the correspond-
ing possessive suffixes in Hungarian : the phrase
my/PRP$ own/JJ mother/NN is transformed to the
form own/JJ mother/NN my/PRP$, which corre-
sponds to the Hungarian phrase saja?t anya? m.
By applying either of the morpheme-token-
45
based or the factored morphosyntactic-feature-
based solution, the translations generated by the
SMT system contain sequences of lemmas and
morphosyntactic tags, thus, in order to get the fi-
nal form of the translated sentence, the surface
form of the words have to be generated from the
morpheme sequence. In our experiments, we ap-
plied the word form generator module of the Hu-
mor morphological analyzer to the output of the
decoder (Nova?k, 2003; Pro?sze?ky and Kis, 1999).
4.3 Factored translation
The Moses SMT toolkit (Koehn et al, 2007),
which we used in our experiments, is suitable for
implementing factored translation models. Instead
of relying on just the surface form of the words,
further annotations such as morphological analy-
sis can be used in the process of a factored trans-
lation. Translation factors might be the surface
form of each word, its lemma, its main PoS tag
and its morphosyntactic features. During factored
translation, there is an opportunity to use multiple
translation models, generation models or contex-
tual language models. Since the system has the
possibility to use any combination of these, in the-
ory it is able to generate better translations using
sparse linguistic data than a word-based baseline
system. This feature is vital in cases where some
abstraction is necessary, because some words in
the sentence to be translated or generated are miss-
ing from the training set.
To see how well a factored model performs in
the case of translation to an agglutinating lan-
guage, we also trained a factored translation sys-
tem combined with our reordering rules. The fac-
tors in our case were of the form: lemma/PoS |
PoS+morphtags, where PoS is the main part-
of-speech tag and morphtags are the rest of the
morphological features and extra morphemes at-
tached to the word as described in Section 4.2.
Training the system with this combination of fac-
tors to handle data sparseness issues seems reason-
able in theory; however, translation of lexical and
grammatical factors is compromised by a serious
weakness of the factored translation implementa-
tion in Moses. If the two factors are treated as con-
nected at training time, then if a certain combina-
tion of a lemma and its morphology is not present
in the translation models, which is very frequent in
the case of an agglutinating language, then it can
not be translated even if both the lemma and the
morphological feature set are represented in the
training corpus separately. In such cases none of
the factors are translated and the source word is
copied to the output untranslated.
Another method of training a factored model is
to translate factors independently. This could in-
deed solve data sparseness problems, but, as we
noted during our experiments, another problem
arises in this case: at translation time, translations
of morphological tags often land at wrong lem-
mas. This is due to the fact when translating a
phrase, the system selects a translation having one
word order, e.g. [Det N V], for one factor (the lem-
mas) and another, e.g. [V Det N] for the other (the
morphosyntactic tags). This results in ill-formed
structures, such as nominal morphosyntactic fea-
tures landing on verbs and verbal morphosyntac-
tic features landing on nouns etc., thus, although
the translation might contain the relevant transla-
tions regarding both lemmas and morphological
features, the final sentence will be an inconsistent
mixture of them, making generation of the right
word forms impossible. Due to word order vari-
ations in Hungarian, this situation turned out to
be rather frequent, affecting 21% of our 1000 test
sentences.
In order to improve translations compromised
by inconsistent mapping of lemmas and morphol-
ogy, we introduced a postprocessing step extract-
ing and restoring the proper positions of the mor-
phological tags in the result of factored transla-
tions. Relying on the alignment information, the
proper position of each morphological tag in the
sequence can be found. At translation time, Moses
can output which source words each target phrase
was translated from. We introduced two auxil-
iary factors to the phrase table that represent align-
ments of our two main factors. If the alignments in
the two factors mismatch, we can realign them us-
ing the auxiliary alignment factors (using the word
order in the lemma factor as pivot). Once having
the factors rematched, the two factors of the target
translation are unified and the morphological gen-
erator can be applied to generate the final word
forms. As it is evident from the evaluation data
presented in Section 5, the realignment of factors
consistently improved the quality of translations
produced by all factored models.
46
5 Experiments and results
We performed experiments on word-based,
morpheme-based and factored translations from
English to Hungarian with and without applying
our reordering rules as a preprocessing step. We
also contrasted the performance of our experi-
mental systems with that of some commercial
systems: the rule-based MetaMorpho (Nova?k
et al, 2008; Nova?k, 2009) and the major com-
mercial translation services, Google Translate
and Bing Translator, which apply their language
independent statistical systems trained on huge
parallel corpora. Low BLEU scores of translations
generated by these systems (compared to those
usually obtained for other languages) indicate
that machine translation to Hungarian is indeed a
difficult task.
In all of our experiments, the Moses (Koehn et
al., 2007) toolkit was used for building the trans-
lation models and performing the translation task
itself, using IRSTLM (Federico et al, 2008) to
build language models. Wherever it was neces-
sary, PurePos (Orosz and Nova?k, 2012) was used
for morphological analysis and generation, and the
Stanford Parser (Marneffe et al, 2006) for con-
stituent and dependency parsing.
5.1 Datasets
As training data, we used the Hunglish (Varga et
al., 2005) corpus, created by BME MOKK2 and
the Research Institute for Linguistics of the Hun-
garian Academy of Sciences. This corpus contains
parallel texts from the following domains: litera-
ture and magazines, legal texts and movie subti-
tles. There is a great degree of variation in the
quality of different parts of the corpus. We auto-
matically eliminated sentence pairs from the cor-
pus that caused technical problems, but overall
translation quality was not checked.
The corpus we used for training the sys-
tem consists of 1,026,836 parallel sentences
with 14,553,765 words on the English side and
12,079,557 on the Hungarian side. For testing pur-
poses, a 1000-sentence-long portion was selected
from the same corpus with one reference transla-
tion. Automatic evaluation was performed on this
set using the BLEU evaluation metric. Results for
each system are listed in Table 3.
2MOKK Centre for Media Research and Education at
the Department of Sociology and Communication, Budapest
University of Technology and Economics
5.2 Baseline systems
We built a word-based, a morpheme-based, and a
factored baseline system (featured as w, m and f in
Table 3), not using the reordering rules described
in Section 4.1, each trained using Moses.
For the word-based baseline model w, the only
preprocessing we applied was standard tokeniza-
tion and lowercasing. A phrase table with a phrase
length limit of 7 was extracted, and a 5-gram lan-
guage model was built. A lexicalized reordering
model with a distortion limit of 6 was used in this
baseline model (and all other models with non-
monotone decoding).
We evaluated this system using two automatic
metrics: the usual word-based BLEU (w-BLEU)
and, in order to have a relevant base of compari-
son to the other systems, a morpheme-based score
(mm-BLEU), which in the case of the word-based
baseline was computed applying morphological
analysis to the translations. mm-BLEU is based on
counts of identical abstract morpheme sequences
in the generated and the reference translations in-
stead of identical word sequences. Note that this
differs from m-BLEU as used in e.g. (Clifton and
Sarkar, 2011), which is BLEU applied to pseudo-
morphs generated by an unsupervised segmenter.
mm-BLEU measures the ability of the system to
generate the correct morphemes in the transla-
tions.
The second baseline system m was trained on
morphologically segmented sentences, thus the
output of the decoder is a sequence of morphemes.
A BLEU score computed on the output of the de-
coder in this case is mm-BLEU. The morpholog-
ical generator was applied to the output of the
Moses decoder in order to acquire the final word
forms. The morpheme-based system m performed
better in terms of mm-BLEU, although it got a
lower w-BLEU score.
The third, factored baseline model f was outper-
formed by the two other models both in terms of
w-BLEU and mm-BLEU, even when the problem
caused by a different word order in the factors was
fixed as described in Section 4.3 (the system fx).
5.3 Reordered models
Based on considerations described in Sections 4.1
and 4.2, we performed reordering as a prepro-
cessing step both at training and translation time.
Models using this configuration were also evalu-
ated applying the same w-BLEU and mm-BLEU
47
ID w-BLEU mm-BLEU
w-based baseline (w) 14.57% 59.32%
m-based baseline mon. (mm) 11.69% 63.18%
m-based baseline (m) 12.19% 63.87%
factored baseline monotone
(fm)
9.70% 56.00%
factored baseline mon. fixed
(fmx)
9.84% 57.09%
w-based reord. (wre) 14.83% 58.06%
w-based reord. joined (wre ) 13.05% 57.21%
m-based reord. mon. (mrem) 12.01% 64.24%
m-based reord. (mre) 12.22% 64.94%
fact. reord. mon. (frem) 10.50% 59.56%
fact. reord. mon. fixed
(fremx)
10.64% 60.28%
fact. reord. (fre) 10.78% 59.97%
fact. reord. fixed (frex) 10.88% 60.83%
Google Translate (goo) 15.68% 55.86%
Bing Translator (bing) 12.16% 53.05%
MetaMorpho (mmo) 6.86% 50.97%
Table 3: Automatic evaluation scores for systems
tested in the experiments.
metrics. We implemented various morpheme-
based, factored and word-based reordered mod-
els. The two word-based setups performed the
same transformations moving function words, the
difference between the two was only whether the
moved words were kept as distinct words (wre) or
joined to the target word as suffixes to form a sin-
gle word form (wre ). The models allowed further
reordering during decoding using a lexicalized re-
ordering model.
The morpheme-based (mre) and the factored
models (fre and frex, the latter with factor mis-
alignment fixed) were contrasted with alterna-
tive setups where the decoder was constrained
to monotone decoding (mrem, frem, fremx). We
had concerns that in the case of the morpheme-
based model the decoder might move suffixes to
incorrect positions. However, using a lexicalized
reordering model prevented these problems and
the systems with reordering during decoding per-
formed consistently better. Monotone decoding
blocked the decoder from fixing word order in the
preverbal field of the comment part of Hungarian
sentences, where strict word order constraints ap-
ply in contrast to the free word order of the topic
and the postverbal part of the comment. While our
reordering rules did not capture these constraints
depending on various subtle features of the actu-
ally selected translation that cannot be reliably in-
ferred from the English original, the lexically con-
strained reordering performed by the decoder did
manage to generate translations that conformed to
them at least to some extent.
The results presented in Table 3 show that the
reordered wre, mre and frex models obtained con-
sistently higher BLEU scores than the correspond-
ing baseline models (the only exception being the
mm-BLEU score of the wre model). Although
the BLEU scores do not show this clearly, the
translations generated by the wre model are far
worse than the output of any other system due to
a high number of untranslated ?agglutinating En-
glish? words with function words attached to con-
tent words as suffixes.
Figure 4 shows the translation results of our dif-
ferent systems. As it can be seen, mre performed
the best, regarding fluency and reflecting the orig-
inal meaning.
6 Human evaluation
It has been shown that system rankings based on
single reference BLEU scores often do not cor-
respond to how humans evaluate the translations.
For this reason, automatic evaluation has for a
long time not been used to officially rank systems
at Workshops on Statistical Machine Translation
(WMT) (Callison-Burch et al, 2007). In our work,
we presented results of automated evaluation us-
ing a single reference BLEU metrics, but we also
investigated translations generated by each sys-
tem using human evaluation, applying the ranking
scheme used at WMT workshops to officially rank
systems.
300 sentences were randomly chosen from the
test set for the purpose of human evaluation.
Five annotators evaluated translations generated
by each of the above described systems plus the
reference translation in the corpus with regard to
translation quality (considering both adequacy and
fluency in a single quality ranking). The order of
translations was randomized for each sentence and
a balanced number of comparisons was performed
for each system pair. The systems were ranked
based on a score that was defined as the number
of times the output of a system was deemed not
worse than that of the other in pairwise compar-
isons divided by the number of pairwise compar-
isons. The aggregate results of human evaluation
are listed in Table 5.
Manual investigation of the translation outputs
revealed that the system incorporating morpholog-
ical and syntactic information are better at captur-
ing grammatical relations in the original text and
rendering them in the translation by generating the
48
original English After you were picked up at sea , our listening post in Malta intercepted that fax .
reordered English after/[IN] you/[PRP] be/[VB] [Past] pick/[VB] [PPart] up/[RP] at/[IN] sea/[NN] ,/[,]
our/[PRP$] listen/[VB] [ING] post/[NN] in/[IN] malta/[NNP] intercept/[VB] [PPart] that/[DT]
fax/[NN] ./[.]
morpheme based
translation
miuta?n/[KOT] felvesz/[IGE] [Past] [t3] [Def] maga/[FN NM] [e3] [ACC] a/[DET] tenger/[FN]
[SUP] ,/[PUNCT] hallgat/[IGE] [Past] [e3] [Def] a/[DET] hely/[FN] [PSt1] ,/[PUNCT]
hogy/[KOT] ma?lta/[FN] [INE] a?ll/[IGE] [Past] [e3] [Def] ez/[FN NM] [ACC] a/[DET] fax/[FN]
[ACC] ./[PUNCT]
final translation Miuta?n felvette?k maga?t a tengeren , hallgatta a helyu?nk , hogy ma?lta a?llta ezt a faxot .
back-translation After you were picked up at sea, our listening post caught the fax in Malta.
baseline translation Azuta?n , hogy felvette a tengeren , a ma?ltai hallgatta az emelkedo? , hogy fax .
back-translation After you, he picked it up at the sea, and that Malta were caught, that it is a fax.
Hungarian reference Miuta?n o?nt kihala?szta?k , ezt fogta?k el egy ma?ltai posta?n .
back-translation After you were fished out, this was caught at a post in Malta.
Table 4: Translation results of our systems with hand made backtranslations for comparison with the
reference.
ref mmo goo bing mre frex m fx w wre wre
88.33 76.30 72.80 61.66 55.60 55.42 54.28 52.03 51.33 50.89 37.57
Table 5: Human evaluation ranking of systems measured as percentage of generating a translation not
worse than the other in pairwise comparisons
appropriate inflected forms. Rule-based reorder-
ing also improved quality when using linguisti-
cally rich models. The only ones that performed
worse than the baseline were the word-based re-
ordered solutions, especially the one based on
?agglutinating English?, the poor performance of
which came as no surprise. BLEU scores do not
correspond well to human judgments. Of our
models, the wre system had the highest BLEU
score, however, human evaluation ranked that
worse than any of the morpheme-based systems.
Moreover, MetaMorpho, the commercial system
having highest rank had by far the lowest BLEU
score.
Considering all the systems in the ranking pro-
cedure, it can be observed that the reference trans-
lation used also for measuring BLEU score does
not always represent the best translation either
according to our evaluators. It is worth not-
ing though that there was a rather significant
variance in the ranking of reference translations
due to some evaluators ranking them much less
favourably than others (75.29% vs. 92.98%).
7 Conclusion
We performed several experiments on English-
Hungarian machine translation. Automatic eval-
uation consistently scored models including rule-
based reordering higher than systems not includ-
ing it. Human evaluation confirmed that applying
reordering and morphological segmentation does
improve translation quality in the case of translat-
ing to an agglutinating language like Hungarian.
Our models are not yet on par with commer-
cial systems. The rather limited amount of train-
ing corpus that also has serious quality problems
is certainly one factor playing a role in this. Our
future plans include enlarging and improving our
training corpus, improving alignment and compo-
nents of the syntactic annotation and reordering
chain as well as experimenting with combination
of morpheme-based and factored models.
Acknowledgement
This work was partially supported by TA?MOP ?
4.2.1.B ? 11/2/KMR-2011-0002 and TA?MOP ?
4.2.2./B ? 10/1-2010-0014.
References
Chris Callison-Burch, Cameron Fordyce, Philipp
Koehn, Christof Monz, and Josh Schroeder. 2007.
(Meta-)evaluation of machine translation. In Pro-
ceedings of the Second Workshop on Statistical
Machine Translation, StatMT ?07, pages 136?158,
Stroudsburg, PA, USA. Association for Computa-
tional Linguistics.
Ann Clifton and Anoop Sarkar. 2011. Combin-
ing morpheme-based machine translation with post-
processing morpheme prediction. In Proceedings of
the 49th Annual Meeting of the Association for Com-
putational Linguistics: Human Language Technolo-
gies - Volume 1, HLT ?11, pages 32?42, Stroudsburg,
49
PA, USA. Association for Computational Linguis-
tics.
Michael Collins, Philipp Koehn, and Ivona Kuc?erova?.
2005. Clause restructuring for statistical machine
translation. In Proceedings of the 43rd Annual
Meeting on Association for Computational Linguis-
tics, ACL ?05, pages 531?540, Stroudsburg, PA,
USA. Association for Computational Linguistics.
Marcello Federico, Nicola Bertoldi, and Mauro Cet-
tolo. 2008. Irstlm: an open source toolkit for
handling large scale language models. In INTER-
SPEECH, pages 1618?1621.
Yang Gao, Philipp Koehn, and Alexandra Birch. 2011.
Soft dependency constraints for reordering in hier-
archical Phrase-Based translation. In Proceedings
of the 2011 Conference on Empirical Methods in
Natural Language Processing, pages 857?868, Ed-
inburgh, Scotland, UK., jul. Association for Compu-
tational Linguistics.
Dmitriy Genzel. 2010. Automatically learning source-
side reordering rules for large scale machine transla-
tion. In COLING, pages 376?384.
Anita Gojun and Alexander Fraser. 2012. Determin-
ing the placement of German verbs in English-to-
German SMT. In Walter Daelemans, Mirella La-
pata, and Llus Mrquez, editors, EACL, pages 726?
735. The Association for Computer Linguistics.
Hieu Hoang. 2007. Factored translation models. In
In Proceedings of the 2007 Joint Conference on
Empirical Methods in Natural Language Process-
ing and Computational Natural Language Learning
(EMNLP-CoNLL, pages 868?876.
Maria Holmqvist, Sara Stymne, Lars Ahrenberg, and
Magnus Merkel. 2012. Alignment-based reordering
for SMT. In Nicoletta Calzolari (Conference Chair)
et al, editor, Proceedings of the Eight International
Conference on Language Resources and Evaluation
(LREC?12), Istanbul, Turkey, may. European Lan-
guage Resources Association (ELRA).
Jie Jiang, Jinhua Du, and Andy Way. 2010. Source-
side syntactic reordering patterns with functional
words for improved phrase-based SMT. In Pro-
ceedings of SSST-4, Fourth Workshop on Syntax and
Structure in Statistical Translation, pages 19?27,
Beijing.
P. Koehn, H. Hoang, A. Birch, C. Callison-Burch,
M. Federico, N. Bertoldi, B. Cowan, W. Shen,
C. Moran, R. Zens, C. Dyer, O. Bojar, A. Constantin,
and E. Herbst. 2007. Moses: Open Source Toolkit
for Statistical Machine Translation. In Proceed-
ings of the ACL 2007 Demo and Poster Sessions,
pages 177?180, Prague. Association for Computa-
tional Linguistics.
Minh-Thang Luong, Preslav Nakov, and Min-Yen Kan.
2010. A hybrid morpheme-word representation for
machine translation of morphologically rich lan-
guages. In Proceedings of the 2010 Conference on
Empirical Methods in Natural Language Process-
ing, EMNLP ?10, pages 148?157, Stroudsburg, PA,
USA. Association for Computational Linguistics.
Marie-Catherine De Marneffe, Bill Maccartney, and
Christopher D. Manning. 2006. Generating typed
dependency parses from phrase structure parses. In
In LREC 2006.
Attila Nova?k, La?szlo? Tihanyi, and Ga?bor Pro?sze?ky.
2008. The MetaMorpho translation system. In
Proceedings of the Third Workshop on Statistical
Machine Translation, StatMT ?08, pages 111?114,
Stroudsburg, PA, USA. Association for Computa-
tional Linguistics.
Attila Nova?k. 2003. What is good Humor like?
In I. Magyar Sza?mto?ge?pes Nyelve?szeti Konferencia,
pages 138?144, Szeged. SZTE.
Attila Nova?k. 2009. MorphoLogic?s submission for
the WMT 2009 Shared Task. In Proceedings of the
Fourth Workshop on Statistical Machine Translation
at EACL 2009, Athens, Greece.
Gyo?rgy Orosz and Attila Nova?k. 2012. PurePos ? an
open source morphological disambiguator. In Pro-
ceedings of the 9th International Workshop on Nat-
ural Language Processing and Cognitive Science.,
Wroclaw, Poland.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. BLEU: a method for automatic
evaluation of machine translation. In Proceedings
of the 40th Annual Meeting on Association for Com-
putational Linguistics, ACL ?02, pages 311?318,
Stroudsburg, PA, USA. Association for Computa-
tional Linguistics.
Ga?bor Pro?sze?ky and Bala?zs Kis. 1999. A unification-
based approach to morpho-syntactic parsing of ag-
glutinative and other (highly) inflectional languages.
In Proceedings of the 37th annual meeting of the
Association for Computational Linguistics on Com-
putational Linguistics, ACL ?99, pages 261?268,
Stroudsburg, PA, USA. Association for Computa-
tional Linguistics.
D. Varga, L. Ne?meth, P. Hala?csy, A. Kornai, V. Tro?n,
and V. Nagy. 2005. Parallel corpora for medium
density languages. In Recent Advances in Natural
Language Processing (RANLP 2005), pages 590?
596.
Reyyan Yeniterzi and Kemal Oflazer. 2010. Syntax-to-
morphology mapping in factored phrase-based sta-
tistical machine translation from English to Turkish.
In Proceedings of the 48th Annual Meeting of the As-
sociation for Computational Linguistics, ACL ?10,
pages 454?464, Stroudsburg, PA, USA. Association
for Computational Linguistics.
50
