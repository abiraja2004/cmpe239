Proceedings of the Second Workshop on Hybrid Approaches to Translation, pages 82?87,
Sofia, Bulgaria, August 8, 2013. c?2013 Association for Computational Linguistics
Experiments with POS-based restructuring and alignment-based re-
ordering for statistical machine translation 
 
 
Shuo Li, Derek F. Wong and Lidia S. Chao 
Department of Computer and Information Science 
University of Macau, Macau S.A.R., China. 
leevis1987@gmail.com, {derekfw, lidiasc}@umac.mo 
 
Abstract 
This paper presents the methods which are 
based on the part-of-speech (POS) and auto 
alignment information to improve the quality 
of machine translation result and the word 
alignment. We utilize different types of POS 
tag to restructure source sentences and use an 
alignment-based reordering method to im-
prove the alignment. After applying the reor-
dering method, we use two phrase tables in the 
decoding part to keep the translation perfor-
mance. Our experiments on Korean-Chinese 
show that our methods can improve the align-
ment and translation results. Since the pro-
posed approach reduces the size of the phrase 
table, multi-tables are considered. The combi-
nation of all these methods together would get 
the best translation result. 
1 Introduction 
Translating between two morphological different 
languages is more difficult in the descriptions by 
Koehn (2005). In Statistical Machine Translation 
(SMT) system, the surface word in a morpholog-
ically poor language is difficult to be generated 
from a morphologically richer language. Take 
the example of Korean and Chinese, their mor-
phologies are different from European languages. 
Korean is a kind of subject-object-verb (SOV) 
language while Chinese is subject-verb-object 
(SVO) language which is a little similar to Eng-
lish. This leads to a problem of word order: de-
spite the automatic word alignment tool GIZA++ 
(Och and Ney, 2003) is widely applied, there are 
still many generated misaligned language pairs 
among these two languages. 
In Korean, a functional word may have differ-
ent morphologies under different conditions. The 
verb and adjective usually end with suffixes in a 
sentence to represent different meanings (Li et al, 
2012). On the other hand, alignment mistakes are 
often generated when many Korean words with 
different morphologies are aligned with the same 
Chinese tokens in Korean-Chinese translation. 
We applied a simple but efficient approach by 
utilizing different part-of-speech (POS) infor-
mation to restructure Korean, after restructuring, 
many Korean words share the same Chinese 
meaning with different morphologies can be re-
stored to their original forms. In particular, we 
expect to reduce the problem of misalignment 
due to the verb and adjective variations. Besides 
word restructuring, an alignment?based word 
reordering method which would improve the 
alignment result indirectly was applied in our 
experiment. This method is simple but effective 
and language-independent by modifying some 
alignment files. The lack of the off-the-shelf Ko-
rean-Chinese corpus is also an important prob-
lem. Most of these corpora are not open source 
for users, so it is hard for people applying Kore-
an-Chinese corpus in the experiments like Euro-
parl (Koehn, 2005), we built a small size corpus 
by ourselves in a short time to do the experi-
ments based on the proposed methods. A script is 
developed for crawling parallel corpus of some 
specific websites. 
In this paper, section 2 will review previous 
related works. In section 3, the POS-based re-
structuring method and alignment-based reorder-
ing approaches to improve the quality of align-
ment will be introduced. Experimental results 
and the analysis will be given in the following 
section 4. Finally, section 5 is the conclusion. 
2 Related work 
Several studies have been proposed to use POS 
tags and morphological information to enrich 
82
languages to tackle some problems in SMT: Li et 
al. (2009) proposed an approach focused on us-
ing pre-processing and post-processing methods, 
such as reordering the source sentences in a Chi-
nese-Korean phrase-based SMT using syntactic 
information. Lee et al (2010) transformed the 
syntactic relations of Chinese SVO patterns and 
inserted the corresponding transferred relations 
as pseudo words to solve the problem of word 
order. In order to reduce the morpheme-level 
translation ambiguity in an English-Chinese 
SMT system, Wu et al (2008) grouped the mor-
phemes into morpheme phrase and used the do-
main information for translation candidate selec-
tion. A contraction separation for Spanish in a 
Spanish-English SMT system was proposed in 
(Gispert and Mari?o, 2008). Habash et al (2009) 
proposed methods to tackle the Arabic enclitics. 
The experiment in Stymne et al (2008) described 
that using POS information to split the com-
pounds in a morphologically rich language 
(German nouns and adjectives) gave an effect for 
translation output. Holmqvist et al (2009) also 
reported that using POS-based and morphology-
based sequence model would give an improve-
ment to the translation quality between English 
and German in WMT09 shared task.  
In accordance with adding richer information 
to the training model, reordering the source lan-
guage text to make it more similar to the target 
side is confirmed to be another kind of method to 
improve the word alignment. Collins et al (2005) 
employed the forms of syntactic analysis and 
hand?written rules on the corpus, Xia and 
McCord (2004) extracted the rules from a paral-
lel text automatically. A statistical machine pre-
reordering method which addressed the reorder-
ing problems as a translation from the source 
sentence to a monotonized source sentence was 
proposed by Costa-juss? and Fonollosa (2006). 
Visweswariah et al (2011) proposed a method 
which learns a model that can directly reorder 
source side text from a small parallel corpus with 
high quality word alignment, but this is hard for 
people to get such a high-quality aligned parallel 
corpus. Ma et al (2007) packed some words to-
gether with the help of the existing statistical 
word aligner, which simplify the task of automat-
ic word alignment by packing consecutive words 
together.  
These approaches are integrated with morpho-
logical information in the translation and decod-
ing model. Our approach is inspired by the ap-
proach proposed by Lee et al(2006) which added 
POS information; reordered the word sequence 
in the source corpus; deleted case particle and 
final ending words in Korean; appended the ex-
ternal dictionary in the training step between Ko-
rean and English. In the experiment reported by 
Li et al (2012), these pre-processing methods on 
the Korean to Chinese translation system took 
advantage of POS in their additional factored 
translation model. In these studies, POS infor-
mation was reported that it would improve the 
translation quality, but their taxonomy of POS 
tag is sole and less. On the word alignment side, 
we try to implement the idea proposed by 
Holmqvist et al (2012), which was reported as a 
simple, language-independent reordering method 
to improve the quality of word alignment. But 
their method did not consider the problem that 
the probability and the amount would be changed 
when updated with an improved word alignment. 
The accuracy of alignment would be improved 
but the size of phrase-table would be less than 
the original one because there are more sure 
alignments generated. The probabilities of word 
and phrase also have the same problem.  
Our works are based on the integration of 
these two methods. We utilized POS information 
and applied a richer taxonomy of POS tags in the 
restructuring of Korean, applied reordering 
method on Korean-Chinese, and combined the 
POS-based restructuring and alignment-based 
reordering together in the experiment. 
3 POS-based restructuring and align-
ment-based reordering 
The POS information is helpful when dealing 
with morphologically rich languages. In the 
morphological analysis, the Korean POS tagger 
involves the analytical task to identify the stem 
and suffixes of Korean, followed by assigning 
corresponding POS tags to both the morphemes 
and extracted stems. As described in Li et al 
(2012), Korean is considered as a highly aggluti-
native language: the verbs, adjectives and ad-
verbs are able to attach with affixes and particles. 
We considered that different category of POS tag 
would lead to different results of the translation. 
The more complex of tag would get a better re-
sult of alignment and the quality of translation. 
The method of processing Chinese POS is simi-
lar to Korean, which applies a more complex 
POS tag category from a Chinese POS tagger. 
Another simple but effective and language-
independent reordering method which
83
Figure 1. Different types of POS tag of Korean 
 
improves the quality of automatic word align-
ment is applied on Korean-Chinese. The method 
is implemented by modifying the alignment file 
in Moses (Koehn et al, 2007), which needs two 
runs of GIZA++. After this step, an improved 
word alignment is generated potentially. Then, 
we combine the restructuring and reordering to-
gether to compare the superposed quality of 
these two methods. 
3.1 POS-based restructuring 
Because Korean is a kind of morphologically 
rich language, most of Korean verbs, adjectives 
and adverbs can be taken as the compound words 
like Germany. For example, the negative verb 
??? ?? (do not go)? should be restored to its 
original form ??? (go)? and the negative verb 
suffix ?? ?? (do not)?. Another example is 
the future tense verb ???? (will go)? is the 
combination of original stem ?? (go)? and suf-
fix with future tense ??? (will)?. With the help 
of POS tagger, we can restructure the Korean 
with the 22 tags category instead of 9 tags in (Li 
et al, 2012). Here is an example of Korean re-
structuring in Figure 1, POS tagger can be de-
tected the compound word and analyze its com-
bination (tagged with ?+?). The taxonomy with 
22 tags is more specific than 9 tags, when tag-
ging a noun, 22 tags will use NC (normal noun) 
instead of N (noun, pronoun, numeral) in 9 tags. 
When dealing with the compound verb ???? 
(in order to avoid)?, ??? (avoid) +??? is 
more reasonable than ???+??, because 
???? represents ?in order to? in corresponding 
Chinese grammar. Then the tags were removed 
and restructured to a new sentence. After restruc-
turing, the length of original sentence increased 
from 5 to 9 (9 tags) and 10 (22 tags). Based on 
previous relative simple tags, more complex tax-
onomy gives a deeper analysis of the sentence 
which would influence the alignment and the 
lexical possibility between the source and target 
language.  
3.2 Alignment-based reordering 
The aim of utilizing the alignment information is 
to make the order in source text same as the tar-
get text. It is believed that statistical word align-
ment methods perform better on translation with 
similar word orders.  
The method needs two runs of word alignment, 
in the first run of GIZA++: the alignment infor-
mation is acquired based on the original order. 
Then the source text is reordered by the order of 
the target text based on the information in the 
first alignment. Next, the reordered source text 
and the original target text are applied on the 
second run of GIZA++, which means this new 
parallel corpus includes the word with more sim-
ilar order than before. After this step, a new 
alignment file would be generated, which covers 
potential improved word alignment with the re-
ordered source language. Finally, the order of 
source text in the new alignment file is restored 
in its original order but kept with its new align-
ment information. 
 
 
 
 
 
 
 
 
 
 
 
Figure 2. The alignment 
 
The algorithm processes the corpus and the 
alignment results in a single direction: source 
side (Holmqvist et al, 2012). As an example, in 
the Korean-Chinese single direction in Figure 2, 
each Korean word aligns with the corresponding 
Chinese word, but Chinese is different. There are 
cross alignments between ????, ????, 
?????, ?????, ???? and ????, ???, 
???? ???? ???? ??? ???. 
9 tags: 
????/N ??/N+?/X+?/E ????/N ??/N+?/J ??/P+?/E ./S 
22 tags: 
????/NC ??/NC+?/XS+?/EC ????/NC ??/NC+?/JC ??/PV+??/EC ./SF 
9 tags deleted: 
???? ?? ? ? ???? ?? ? ?? ? . 
22 tags deleted: 
???? ?? ? ? ???? ?? ? ?? ?? . 
First alignment: 
Bill?  ??  ????  ??  ??  ???  ???  ??  
 
 
?? 1? 2?? 3 6 7 8 ?? null ?? null ? 4?? 5 
(Bill is very quiet, try to encourage him to speak) 
Second alignment (reordered): 
Bill?  ??  ????  ???  ???  ??  ??  ?? 
 
 
?? 1? 2?? 3 4 ?? 5 6 ?? null ? 7?? 8 
84
????. Moreover, the alignment of these words 
is not totally correct. 
Before the second run of GIZA++, the original 
Korean is reordered to the alignment of the Chi-
nese side, so a new Korean sentence is generated 
by the Chinese order. After the second alignment, 
in Figure 2, there are no cross points and the ad-
ditional correct alignment between ?????, 
???? and ???? is generated, the misalign-
ment is decreased.  
 
 
 
 
 
 
Figure 3. The improved alignment  
 
In Figure 3, the new alignment information 
(new) is kept in the restored file. The crossing 
alignment still exists but it is more correct than 
the previous one (old). Based on this alignment, 
the establishment of word alignment, the estima-
tion of lexical translation table and the extraction 
of phrase table are changed.  
We assume that after applying our method, the 
size of the extracted words would increase be-
cause more alignments are generated at the end 
of the second run of GIZA++. Another assump-
tion is that the size of the phrase table would de-
crease if two languages share such a different 
word order, because additional alignments would 
result in some cross alignments but the phrase 
extraction algorithm could not extract them. 
Based on two assumptions, we utilize multiple 
models in the decoding stage. This approach was 
proposed in (Koehn and Schroeder, 2007; Axel-
rod et al, 2011) which passes phrase and reor-
dering tables in parallel. We used our modified 
tables (small size) as the main tables, and the 
baseline tables (big size) as the additional table 
when decoding. This can guarantee that if a 
phrase in testing sentence does not occur in the 
modified tables, the decoder would find the 
phrase in the original table. This method is effec-
tive in avoiding translation mistakes if our meth-
od harms the result.  
4 Experimental results 
We apply our methods on Korean-Chinese 
phrase-based statistical machine translation sys-
tems. The system is built based on Moses, and 
our reordering method is applied at the second 
step among the nine steps during the training in 
Moses. An additional combination of the POS-
based restructuring and alignment-based reorder-
ing is considered in our experiment.  
4.1 Corpus and system information 
The Korean-Chinese (KOR-CHN) corpus is 
crawled from the Internet by our script1 and we 
limited the length of sentence to be under 25 
words. We use 990 sentences as the testing cor-
pus. On the other hand, we use a monolingual 
corpus of 600k Chinese sentences to build a Chi-
nese 3-gram language model. ICTCLAS 2 is an 
open source Chinese segmenter applied to delim-
iter the word boundaries and label with proper 
POS tags, while the Korean text is processed by 
the Korean POS tagger, HanNanum 3. Table 1 
shows the average information of each corpus. 
All the experiment was trained without tuning.  
 
 Token Avg. 
Length 
Sentence 
CHN 664,290 7.36 90,237 
KOR 539,903 5.98 
KOR (9) 969,445 10.74 
KOR (22) 1,010,117 11.19 
 
Table 1. Summary of training corpora 
 
4.2 Korean-Chinese machine translation 
The Korean-Chinese translation system contains 
a reordering model in the translation model. The 
reordering model is trained as the default setting 
from the training corpus itself. The ?grow-diag-
final-and? symmetrization heuristic is applied in 
two directions word alignment. As described in 
the previous section, we restructured the Korean 
by POS tagger and applied our reordering ap-
proach to the translation system. Since the re-
structured Korean can be considered as a new 
corpus, it could be applied to our reordering 
method. 
According to the study of Holmqvist et al 
(2012), when dealing with the morphologically 
different language pair, reordering the morpho-
logically richer side performs better. In the ex-
periments, Korean was reordered and the exper-
imental result is shown in Table 2. 
From the results, applying more POS tags on 
the morphological analysis of Korean got a better 
performance and our reordering method im-
1 http://nlp2ct.sftw.umac.mo/views/tools/WebpageCrawler  
2 http://ictclas.nlpir.org/ 
3 http://semanticweb.kaist.ac.kr/home/index.php/HanNanum 
Bill? ?? ???? ?? ?? ??? ??? ?? 
 
 
?? 1? 2?? 3 6 ?? 7 8 ?? null ? 4?? 5 (new) 
?? 1? 2?? 3 6 7 8 ?? null ?? null ? 4?? 5  (old) 
                                                 
85
proved the translation result from 14.98 to 15.50 
in BLEU (Papineni et al, 2002). The combina-
tion of POS and reordering methods based on the 
multiple phrase tables and reordering tables got 
the best performance with BLEU score 17.35. 
 
Corpus KOR-
CHN 
BLEU 
Baseline 14.98 
POS-based (9 tags) 16.61 
POS-based (22 tags) 16.92 
Alignment-based 15.50 
POS (9 tags) + Alignment 16.71 
POS (22 tags) + Alignment 17.03 
POS (22 tags) + Alignment + two tables 17.35 
 
Table 2. The translation results 
 
4.3 Analysis and discussion 
After the modification of the alignment file, the 
changes of size of the lexical file and the tables 
(phrase and reordering) file are shown in Table 3. 
 
Tables KOR-CHN 
baseline 
KOR-CHN 
modified 
Word 12.39 MB 12.52 MB 
Phrase 19.41 MB 19.04 MB 
Reordering 10.01 MB 9.83 MB 
 
Table 3. The size changes of the word and 
phrase tables 
 
From the table we found that the lexical ex-
traction is bigger than the original system, but 
the size of phrase tables and the reordering tables 
decreased slightly. The result of these changes 
shows that our assumption is reasonable: our 
method can improve the quality of automatic 
alignment, but the phrase extracted from the cor-
pus would decrease. The more word alignment 
points were generated by using our method, the 
more words would be extracted. But this will 
bring some cross alignments when dealing with 
two morphological different languages. 
5 Conclusion 
In this paper, we presented some pre-
processing methods to deal with Korean, which 
is a morphological rich language. POS-based 
restructuring restores most of the Korean verbs, 
adjectives and adverbs to their original format. It 
is shown that the POS tag set with a richer tax-
onomy gives a higher translation result. Moreo-
ver, two runs of automatic alignment information 
got better results on the morphologically richer 
side. All of these methods can be combined to-
gether and improve the final translation. Finally, 
using two tables instead of one modified table in 
the decoding part will guarantee the translation 
quality if the reordering model harms the transla-
tion result.  
 
Acknowledgments 
 
This work is partially supported by the Research 
Committee of University of Macau, and Science 
and Technology Development Fund of Macau 
under the grants RG060/09-10S/CS/FST, and 
057/2009/A2. 
References  
Amittai Axelrod, Xiaodong He, and Jianfeng Gao. 
2011. Domain adaptation via pseudo in-domain da-
ta selection. In Proceedings of the Conference 
on Empirical Methods in Natural Language 
Processing. pages 355?362, Edinburgh, Scotland, 
UK. 
Michael Collins, Philipp Koehn, and Ivona Kucerov?. 
2005. Clause restructuring for statistical machine 
translation. In Proceedings of the 43rd Annual 
Meeting on Association for Computational 
Linguistics. pages 531?540, Ann Arbor, Michigan. 
Marta Ruiz Costa-juss? and Jos? A. R. Fonollosa. 
2006. Statistical machine reordering. In Proceed-
ings of the 2006 Conference on Empirical 
Methods in Natural Language Processing, 
pages 70?76, Sydney, Australia. 
Adri? de Gispert and Jos? B. Mari?o. 2008. On the 
impact of morphology in English to Spanish statis-
tical MT. Speech Communication. Pages 
50:1034?1046. 
Maria Holmqvist, Sara Stymne, Jody Foo, and Lars 
Ahrenberg. 2009. Improving alignment for SMT 
by reordering and augmenting the training corpus. 
In Proceedings of the Fourth Workshop on 
Statistical Machine Translation, Athens, 
Greece. 
Maria Holmqvist, Sara Stymne, Lars Ahrenberg, and 
Magnus Merkel. 2012. Alignment-based reordering 
for SMT. In Proceedings of the Eight Interna-
tional Conference on Language Resources and 
Evaluation (LREC?12). pages 3436?3440, Istan-
bul, Turkey. 
86
Nizar Habash, Owen Rambow, and Ryan Roth. 2009. 
MADA+TOKAN: A toolkit for arabic tokenization, 
diacritization, morphological disambiguation, pos 
tagging, stemming and lemmatization. In Pro-
ceedings of the 2nd International Conference 
on Arabic Language Resources and Tools 
(MEDAR), pages 102?109, Cairo, Egypt. 
Philipp Koehn. 2005. Europarl: A parallel corpus for 
statistical machine translation. In Machine Trans-
lation Summit X, pages 79-86, Phuket, Thailand. 
Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris 
Callison-Burch, Marcello Federico, Nicola Bertoldi, 
Brooke Cowan, Wade Shen, Christine Moran, 
Richard Zens, Chris Dyer, Ondrej Bojar, Alexandra 
Constantin, and Evan Herbst. 2007. Moses: Open 
source toolkit for statistical machine translation. In 
Proceedings of the 45th Annual Meeting of the 
ACL, Demonstration session, Prague, Czech 
Republic. 
Philipp Koehn and Josh Schroeder. 2007. Experi-
ments in domain adaptation for statistical machine 
translation. In Proceedings of the Second Work-
shop on Statistical Machine Translation, pag-
es 224?227, Prague, Czech Republic. 
Shuo Li, Derek F. Wong, and Lidia S. Chao. 2012. 
Korean-Chinese statistical translation model. In 
Machine Learning and Cybernetics (ICMLC), 
2012 International Conference, 2:767-772, Xian, 
Shannxi, China. 
Jin-Ji Li, Jungi Kim, Dong-Il Kim, and Jong-Hyeok 
Lee. 2009. Chinese syntactic reordering for ade-
quate generation of Korean verbal phrases in Chi-
nese-to-Korean SMT. In Proceedings of the 
Fourth Workshop on Statistical Machine 
Translation, pages 190?196, Athens, Greece. 
Jae-Hee Lee, Seung-Wook Lee, Gumwon Hong, 
Young-Sook Hwang, Sang-Bum Kim, and Hae-
Chang Rim. 2010. A post-processing approach to 
statistical word alignment reflecting alignment ten-
dency between part-of-speeches. In Proceedings 
of the 23rd International Conference on Com-
putational Linguistics: Posters, pages 623?629, 
Beijing, China. 
Jonghoon Lee, Donghyeon Lee, and Gary Geunbae 
Lee. 2006. Improving phrase-based Korean-
English statistical machine translation. In Pro-
ceedings of the Ninth International Confer-
ence on Spoken Language Processing, Pitts-
burgh, Pennsylvania. 
Yanjun Ma, Nicolas Stroppa, and Andy Way. 2007. 
Bootstrapping word alignment via word packing. 
In Proceedings of Annual Meeting-association 
for Computational Linguistic, pages 304-311, 
Prague, Czech Republic. 
Franz Josef Och and Hermann Ney. 2003. A system-
atic comparison of various statistical alignment 
models. Computational Linguistics, 29(1):19?51. 
Kishore Papineni, Salim Roukos, Todd Ward, and 
Wei-Jing Zhu. 2002. BLEU: a method for automat-
ic evaluation of machine translation. In Proceed-
ings of the 40th Annual Meeting on Associa-
tion for Computational Linguistics. pages 311?
318, Philadelphia, USA. 
Sara Stymne, Maria Holmqvist, and Lars Ahrenberg. 
2008. Effects of morphological analysis in transla-
tion between German and English. In Proceedings 
of the Third Workshop on Statistical Machine 
Translation, pages 135?138, Columbus, Ohio, 
USA. 
Karthik Visweswariah, Rajakrishnan Rajkumar, 
Ankur. Gandhe, Ananthakrishnan Ramanathan, and 
Jiri Navratil. 2011. A word reordering model for 
improved machine translation. In Proceedings of 
the Conference on Empirical Methods in Nat-
ural Language Processing, pages 486?496, Ed-
inburgh, Scotland, UK. 
Xianchao Wu, Naoaki Okazaki, Takashi Tsunakawa, 
and Jun?ichi Tsujii. 2008. Improving English-to-
Chinese translation for technical terms using mor-
phological information. In Proceedings of the 
8th AMTA Conference, Hawaii, USA. 
Fei Xia and Michael McCord. 2004. Improving a sta-
tistical MT system with automatically learned re-
write patterns. In Proceedings of the 20th Inter-
national Conference on Computational Lin-
guistics, pages 508, Geneva, Switzerland. 
 
 
87
