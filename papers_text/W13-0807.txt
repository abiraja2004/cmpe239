Proceedings of the 7th Workshop on Syntax, Semantics and Structure in Statistical Translation, pages 58?67,
Atlanta, Georgia, 13 June 2013. c?2013 Association for Computational Linguistics
A Formal Characterization of Parsing Word Alignments by Synchronous
Grammars with Empirical Evidence to the ITG Hypothesis
Gideon Maillette de Buy Wenniger?
University of Amsterdam
gemdbw@gmail.com
Khalil Sima?an?
University of Amsterdam
k.simaan@uva.nl
Abstract
Deciding whether a synchronous grammar
formalism generates a given word alignment
(the alignment coverage problem) depends on
finding an adequate instance grammar and
then using it to parse the word alignment. But
what does it mean to parse a word align-
ment by a synchronous grammar? This is for-
mally undefined until we define an unambigu-
ous mapping between grammatical deriva-
tions and word-level alignments. This pa-
per proposes an initial, formal characteriza-
tion of alignment coverage as intersecting two
partially ordered sets (graphs) of translation
equivalence units, one derived by a gram-
mar instance and another defined by the word
alignment. As a first sanity check, we report
extensive coverage results for ITG on auto-
matic and manual alignments. Even for the
ITG formalism, our formal characterization
makes explicit many algorithmic choices of-
ten left underspecified in earlier work.
1 Introduction
The training data used by current statistical machine
translation (SMT) models consists of source and
target sentence pairs aligned together at the word
level (word alignments). For the hierarchical and
syntactically-enriched SMT models, e.g., (Chiang,
2007; Zollmann and Venugopal, 2006), this training
data is used for extracting statistically weighted Syn-
chronous Context-Free Grammars (SCFGs). For-
mally speaking, a synchronous grammar defines a
set of (source-target) sentence pairs derived syn-
chronously by the grammar. Contrary to common
? Institute for Logic, Language and Computation.
belief, however, a synchronous grammar (see e.g.,
(Chiang, 2005; Satta and Peserico, 2005)) does not
accept (or parse) word alignments. This is because
a synchronous derivation generates a tree pair with
a bijective binary relation (links) between their non-
terminal nodes. For deciding whether a given word
alignment is generated/accepted by a given syn-
chronous grammar, it is necessary to interpret the
synchronous derivations down to the lexical level.
However, it is formally defined yet how to unam-
biguously interpret the synchronous derivations of
a synchronous grammar as word alignments. One
major difficulty is that synchronous productions, in
their most general form, may contain unaligned ter-
minal sequences. Consider, for instance, the rela-
tively non-complex synchronous production
?X ? ? X(1) ? X(2) ? X(3), X ? ? X(2) ? X(1) ? X(3)?
where superscript (i) stands for aligned instances
of nonterminal X and all Greek symbols stand for
arbitrary non-empty terminals sequences. Given a
word aligned sentence pair it is necessary to bind
the terminal sequence by alignments consistent with
the given word alignment, and then parse the word
alignment with the thus enriched grammar rules.
This is not complex if we assume that each of the
source terminal sequences is contiguously aligned
with a target contiguous sequence, but difficult if we
assume arbitrary alignments, including many-to-one
and non-contiguously aligned chunks.
One important goal of this paper is to propose
a formal characterization of what it means to syn-
chronously parse a word alignment. Our formal
characterization is borrowed from the ?parsing as in-
tersection" paradigm, e.g., (Bar-Hillel et al, 1964;
Lang, 1988; van Noord, 1995; Nederhof and Satta,
58
2004). Conceptually, our characterization makes use
of three algorithms. Firstly, parse the unaligned sen-
tence pair with the synchronous grammar to obtain a
set of synchronous derivations, i.e., trees. Secondly,
interpret a word alignment as generating a set of
synchronous trees representing the recursive trans-
lation equivalence relations of interest1 perceived in
the word alignment. And finally, intersect the sets
of nodes in the two sets of synchronous trees to
check whether the grammar can generate (parts of)
the word alignment. The formal detail of each of
these three steps is provided in sections 3 to 5.
We think that alignment parsing is relevant for
current research because it highlights the differ-
ence between alignments in training data and align-
ments accepted by a synchronous grammar (learned
from data). This is useful for literature on learn-
ing from word aligned parallel corpora (e.g., (Zens
and Ney, 2003; DeNero et al, 2006; Blunsom et al,
2009; Cohn and Blunsom, 2009; Riesa and Marcu,
2010; Mylonakis and Sima?an, 2011; Haghighi et
al., 2009; McCarley et al, 2011)). A theoretical,
formalized characterization of the alignment pars-
ing problem is likely to improve the choices made in
empirical work as well. We exemplify our claims by
providing yet another empirical study of the stability
of the ITG hypothesis. Our study highlights some of
the technical choices left implicit in preceding work
as explained in the next section.
2 First application to the ITG hypothesis
A grammar formalism is a whole set/family of syn-
chronous grammars. For example, ITG (Wu, 1997)
defines a family of inversion-transduction gram-
mars differing among them in the exact set of syn-
chronous productions, terminals and non-terminals.
Given a synchronous grammar formalism and an
input word alignment, a relevant theoretical ques-
tion is whether there exists an instance synchronous
grammar that generates the word alignment exactly.
We will refer to this question as the alignment cover-
age problem. In this paper we propose an approach
to the alignment coverage problem using the three-
step solution proposed above for parsing word align-
1The translation equivalence relations of interest may vary
in kind as we will exemplify later. The known phrase pairs are
merely one possible kind.
ments by arbitrary synchronous grammars.
Most current use of synchronous grammars is
limited to a subclass using a pair of nonterminals,
e.g., (Chiang, 2007; Zollmann and Venugopal, 2006;
Mylonakis and Sima?an, 2011), thereby remain-
ing within the confines of the ITG formalism (Wu,
1997). On the one hand, this is because of computa-
tional complexity reasons. On the other, this choice
relies on existing empirical evidence of what we will
call the ?ITG hypothesis", freely rephrased as fol-
lows: the ITG formalism is sufficient for represent-
ing a major percentage of reorderings in translation
data in general.
Although checking whether a word alignment can
be generated by ITG is far simpler than for arbi-
trary synchronous grammars, there is a striking vari-
ation in the approaches taken in the existing litera-
ture, e.g., (Zens and Ney, 2003; Wellington et al,
2006; S?gaard and Wu, 2009; Carpuat and Wu,
2007; S?gaard and Kuhn, 2009; S?gaard, 2010).
S?gaard and Wu (S?gaard and Wu, 2009) observe
justifiably that the literature studying the ITG align-
ment coverage makes conflicting choices in method
and data, and reports significantly diverging align-
ment coverage scores. We hypothesize here that
the major conflicting choices in method (what to
count and how to parse) are likely due to the ab-
sence of a well-understood, formalized method for
parsing word alignments even under ITG. In this pa-
per we apply our formal approach to the ITG case,
contributing new empirical evidence concerning the
ITG hypothesis.
For our empirical study we exemplify our ap-
proach by detailing an algorithm dedicated to ITG in
Normal-Form (NF-ITG). While our algorithm is in
essence equivalent to existing algorithms for check-
ing binarizability of permutations, e.g.,(Wu, 1997;
Huang et al, 2009), the formal foundations pre-
ceding it concern nailing down the choices made
in parsing arbitrary word alignments, as opposed to
(bijective) permutations. The formalization is our
way to resolve some of the major points of differ-
ences in existing literature.
We report new coverage results for ITG parsing
of manual as well as automatic alignments, showing
the contrast between the two kinds. While the latter
seems built for phrase extraction, trading-off preci-
sion for recall, the former is heavily marked with id-
59
iomatic expressions. Our coverage results make ex-
plicit a relevant dilemma. To hierarchically parse the
current automatic word alignments exactly, we will
need more general synchronous reordering mecha-
nisms than ITG, with increased risk of exponential
parsing algorithms (Wu, 1997; Satta and Peserico,
2005). But if we abandon these word alignments,
we will face the exponential problem of learning re-
ordering arbitrary permutations, cf. (Tromble and
Eisner, 2009). Our results also exhibit the impor-
tance of explicitly defining the units of translation
equivalence when studying (ITG) coverage of word
alignments. The more complex the choice of trans-
lation equivalence relations, the more difficult it is to
parse the word alignments.
3 Translation equivalence in MT
In (Koehn et al, 2003), a translation equivalence
unit (TEU) is a phrase pair: a pair of contiguous
substrings of the source and target sentences such
that the words on the one side align only with words
on the other side (formal definitions next). The hier-
archical phrase pairs (Chiang, 2005; Chiang, 2007)
are extracted by replacing one or more sub-phrase
pairs, that are contained within a phrase pair, by
pairs of linked variables. This defines a subsumption
relation between hierarchical phrase pairs (Zhang et
al., 2008). Actual systems, e.g., (Koehn et al, 2003;
Chiang, 2007) set an upperbound on length or the
number of variables in the synchronous productions.
For the purposes of our theoretical study, these prac-
tical limitations are irrelevant.
We give two definitions of translation equivalence
for word alignments.2 The first one makes no as-
sumptions about the contiguity of TEUs, while the
second does require them to be contiguous sub-
strings on both sides (i.e., phrase pairs).
As usual, s = s1...sm and t = t1...tn are source and
target sentences respectively. Let s? be the source
word at position ? in s and t? be the target word at
position ? in t. An alignment link a ? a in a word
alignment a is a pair of positions ??, ?? such that 1 ?
2Unaligned words tend to complicate the formalization un-
necessarily. As usual we also require that unaligned words must
first be grouped with aligned words adjacent to them before
translation equivalence is defined for an alignment. This stan-
dard strategy allows us to informally discuss unaligned words
in the following without loss of generality.
? ? m and 1 ? ? ? n. For the sake of brevity, we
will often talk about alignments without explicitly
mentioning the associated source and target words,
knowing that these can be readily obtained from the
pair of positions and the sentence pair ?s, t?. Given
a subset a? ? a we define wordss(a?) = {s? | ?X :
??, X? ? a?} and wordst(a?) = {t? | ?X : ?X, ?? ? a?}.
Now we consider triples (s?, t?, a?) such that
a? ? a, s? = wordss(a?) and t? = wordst(a?). We
define the translation equivalence units (TEUs) in
the set TE(s, t, a) as follows:
Definition 3.1 (s?, t?, a?) ? TE(s, t, a) iff ??, ?? ? a?
? (for all X, if ??, X? ? a then ??, X? ? a?) ? (for
all X, if ?X, ?? ? a then ?X, ?? ? a?)
In other words, if some alignment involving source
position ? or ? is included in a?, then all alignments
in a containing that position are in a? as well. This
definition allows a variety of complex word align-
ments such as the so-called Cross-serial Discontigu-
ous Translation Units and Bonbons (S?gaard and
Wu, 2009).
We also define the subsumption relation (partial
order) <a as follows:
Definition 3.2 A TEU u2 = (s2, t2, a2) subsumes
(<a) a TEU u1 = (s1, t1, a1) iff a1 ? a2. The sub-
sumption order will be represented by u1 <a u2.
Based on the subsumption relation we can par-
tition TE(s, t, a) into two disjoint sets : atomic
TEAtom(s, t, a) and composed TEComp(s, t, a).
Definition 3.3 u1 ? TE(s, t, a) is atomic iff @ u2 ?
TE(s, t, a) such that (u2 <a u1).
Now the set TEAtom(s, t, a) is simply the set
of all atomic translation equivalents, and
the set of composed translation equivalents
TEComp(s, t, a) = (TE(s, t, a) \ TEAtom(s, t, a)).
Based on the general definition of translation
equivalence, we can now give a more restricted
definition that allows only contiguous translation
equivalents (phrase pairs):
Definition 3.4 (s?, t?, a?) constitutes a contiguous
translation equivalent iff:
1. (s?, t?, a?) ? TE(s, t, a) and
60
2. Both s? and t? are contiguous substrings of s
and t? respectively.
This set of translation equivalents is the unlimited
set of phrase pairs known from phrase-based ma-
chine translation (Koehn et al, 2003). The relation
<a as well as the division into atomic and composed
TEUs can straightforwardly be adapted to contigu-
ous translation equivalents.
4 Grammatical translation equivalence
The derivations of a synchronous grammar can be
interpreted as deriving a partially ordered set of
TEUs as well. A finite derivation S ?+ ?s, t, aG?
of an instance grammar G is a finite sequence of
term-rewritings, where at each step of the sequence a
single nonterminal is rewritten using a synchronous
production of G. The set of the finite derivations
of G defines a language, a set of triples ?s, t, aG?
consisting of a source string of terminals s, a target
string of terminals t and an alignment between their
grammatical constituents. Crucially, the alignment
aG is obtained by recursively interpreting the align-
ment relations embedded in the synchronous gram-
mar productions in the derivation for all constituents
and concerns constituent alignments (as opposed to
word alignments).
Grammatical translation equivalents TEG(s, t)
A synchronous derivation S ?+ ?s, t, aG? can be
viewed as a deductive proof that ?s, t, aG? is a gram-
matical translation equivalence unit (grammatical
TEU). Along the way, a derivation also proves other
constituent-level (sub-sentential) units as TEUs.
We define a sub-sentential grammatical TEU of
?s, t, aG? to consist of a triple ?sx, tx, ax?, where sx
and tx are two subsequences3 (of s and t respec-
tively), derived synchronously from the same con-
3A subsequence of a string is a subset of the word-position
pairs that preserves the order but do not necessarily constitute
contiguous substrings.
Figure 2: Alignment with both contiguous and dis-
contiguous TEUs (example from Europarl En-Ne).
stituent X in some non-empty ?tail" of a derivation
S ?+ ?s, t, aG?; importantly, by the workings of G,
the alignment ax ? aG fulfills the requirement that a
word in sx or in tx is linked to another by aG iff it is
also linked that way by ax (i.e., no alignments start
out from terminals in sx or tx and link to terminals
outside them). We will denote with TEG(s, t) the set
of all grammatical TEUs for the sentence pair ?s, t?
derived by G.
Subsumption relation <G(s,t) Besides deriving
TEUs, a derivation also shows how the different
TEUs compose together into larger TEUs according
to the grammar. We are interested in the subsump-
tion relation: one grammatical TEU/constituent (u1)
subsumes another (u2) (written u2 <G(s,t) u1) iff the
latter (u2) is derived within a finite derivation of the
former (u1).4
The set of grammatical TEUs for a finite set of
derivations for a given sentence pair is the union of
the sets defined for the individual derivations. Simi-
larly, the relation between TEU?s for a set of deriva-
tions is defined as the union of the individual rela-
tions.
5 Alignment coverage by intersection
Let a word aligned sentence pair ?s, t, a? be given,
and let us assume that we have a definition of an or-
dered set TE(s, t, a) with partial order <a. We will
say that a grammar formalism covers a iff there ex-
ists an instance grammar G that fulfills two intersec-
tion equations simultaneously:5
(1) TE(s, t, a) ? TEG(s, t) = TE(s, t, a)
(2) <a ? <G(s,t)=<a
In the second equation, the intersection of partial or-
ders is based on the standard view that these are in
essence also sets of ordered pairs. In practice, it
is sufficient to implement an algorithm that shows
4Note that we define this relation exhaustively thereby defin-
ing the set of paths in synchronous trees derived by the grammar
for ?s, t?. Hence, the subsumption relation can be seen to define
a forest of synchronous trees.
5In this work we have restricted this definition to full cover-
age (i.e., subset) version but it is imaginable that other measures
can be based on the cardinality (size) of the intersection in terms
of covered TEUs, in following of measures found in (S?gaard
and Kuhn, 2009; S?gaard and Wu, 2009). We leave this to fu-
ture work.
61
Figure 1: Alignment with only contiguous TEUs (example from LREC En-Fr).
that G derives every TEU in TE(s, t, a), and that
the subsumption relation <a between TEUs in a
must be realized by the derivations of G that de-
rive TE(s, t, a). In effect, this way every TEU that
subsumes other TEUs must be derived recursively,
while the minimal, atomic units (not subsuming any
others) must be derived using the lexical produc-
tions (endowed with internal word alignments) of
NF-ITG. Again, the rationale behind this choice is
that the atomic units constitute fixed translation ex-
pressions (idiomatic TEUs) which cannot be com-
posed from other TEUs, and hence belong in the lex-
icon. We will exhibit coverage algorithms for doing
so for NF-ITG for the two kinds of semantic inter-
pretations of word alignments.
A note on dedicated instances of NF-ITG Given
a translation equivalence definition over word align-
ments TE(s, t, a), the lexical productions for a ded-
icated instance of NF-ITG are defined6 by the set
{X ? u | u ? TEAtom(s, t, a)}. This means that the
lexical productions have atomic TEUs at the right-
hand side including alignments between the words
of the source and target terminals. In the sequel, we
will only talk about dedicated instances of NF-ITG
and hence we will not explicitly repeat this every
time.
Given two grammatical TEUs u1 and u2, an NF-
ITG instance allows their concatenation either in
monotone [] or inverted <> order iff they are ad-
jacent on the source and target sides. This fact
implies that for every composed translation equiv-
alent u ? TE(s, t, a) we can check whether it is
derivable by a dedicated NF-ITG instance by check-
ing whether it recursively decomposes into adjacent
pairs of TEUs down to the atomic TEUs level. Note
that by doing so, we are also implicitly checking
6Unaligned words add one wrinkle in this scheme: infor-
mally, we consider a TEU u formed by attaching unaligned
words to an atomic TEU also as atomic iff u is absolutely needed
to cover the aligned sentence pair.
whether the subsumption order between the TEUs
in TE(s, t, a) is realized by the grammatical deriva-
tion (i.e, <G(s,t)?<a). Formally, an aligned sentence
pair ?s, t, a? is split into a pair of TEUs ?s1, t1, a1?
and ?s2, t2, a2? that can be composed back using
the [] and <> productions. If such a split exists,
the splitting is conducted recursively for each of
?s1, t1, a1? and ?s2, t2, a2? until both are atomic TEUs
in TE(s, t, a). This recursive splitting is the check
of binarizability and an algorithm is described in
(Huang et al, 2009).
6 A simple algorithm for ITG
We exemplify the grammatical coverage for (nor-
mal form) ITG by employing a standard tabular al-
gorithm based on CYK (Younger, 1967). The al-
gorithm works in two phases creating a chart con-
taining TEUs with associated inferences. In the ini-
tialization phase (Algorithm 1), for all source spans
that correspond to translation equivalents and which
have no smaller translation equivalents they contain,
atomic translation equivalents are added as atomic
inferences to the chart. In the second phase, based
on the atomic inferences, the simple rules of NF-
ITG are applied to add inferences for increasingly
larger chart entries. An inference is added (Algo-
rithms 2 and 3) iff a chart entry can be split into two
sub-entries for which inferences already exist, and
furthermore the union of the sets of target positions
for those two entries form a consecutive range.7 The
addMonotoneInference and addInvertedInference in
Algorithm 3 mark the composit inferences by mono-
tone and inverted productions respectively.
7We are not treating unaligned words formally here. For un-
aligned source and target words, we have to generate the differ-
ent inferences corresponding to different groupings with their
neighboring aligned words. Using pre-processing we set aside
the unaligned words, then parse the remaining word alignment
fully. After parsing, by post-processing, we introduce in the
parse table atomic TEUs that include the unaligned words.
62
InitializeChart
Input : ?s, t, a?
Output: Initialized chart for atomic units
for spanLength? 2 to n do
for i? 0 to n ? spanLength + 1 do
j? i + spanLength ? 1
u? {?X,Y? : X ? {i... j}}
if (u ? TEAtom(s, t, a)) then
addAtomicIn f erence(chart[i][ j],u)
end
end
end
Algorithm 1: Algorithm that initializes the Chart
with atomic sub-sentential TEUs. In order to be
atomic, a TEU may not contain smaller TEUs that
consist of a proper subset of the alignments (and
associated words) of the TEU.
ComputeTEUsNFITG
Input : ?s, t, a?
Output: TRUE/FALSE for coverage
InitializeChart(chart)
for spanLength? 2 to n do
for i? 0 to n ? spanLength + 1 do
j? i + spanLength ? 1
if chart[i][ j] ? TE(s, t, a) then
continue
end
for splitPoint ? i + 1 to j do
a? ? (chart[i][k ? 1] ? chart[k][ j])
if (chart[i][k ? 1] ? TE(s, t, a)) ?
(chart[k][ j] ? TE(s, t, a)) ?
(a? ? TE(s, t, a)) then
addT EU(chart, i, j, k, a?)
end
end
end
if (chart[0][n ? 1] , ?) then
return TRUE
else
return FALSE
end
end
Algorithm 2: Algorithm that incrementally builds
composite TEUs using only the rules allowed by
NF-ITG
addTEU
Input :
chart - the chart
i,j,k - the lower, upper and split point indices
a? - the TEU to be added
Output: chart with TEU a? added in the
intended entry
if MaxYt ({Yt : ?Xs,Yt? ? chart[i][k ? 1]})
< MaxYt ({Yt : ?Xs,Yt? ? chart[k][ j]}) then
addMonotoneIn f erence(chart[i][ j], a?)
else
addInvertedIn f erence(chart[i][ j], a?)
end
Algorithm 3: Algorithm that adds a TEU and as-
sociated Inference to the chart
7 Experiments
Data Sets We use manually and automatically
aligned corpora. Manually aligned corpora come
from two datasets. The first (Grac?a et al,
2008) consists of six language pairs: Portuguese?
English, Portuguese?French, Portuguese?Spanish,
English?Spanish, English?French and French?
Spanish. These datasets contain 100 sentence pairs
each and distinguish Sure and Possible alignments.
Following (S?gaard and Kuhn, 2009), we treat these
two equally. The second manually aligned dataset
(Pad? and Lapata, 2006) contains 987 sentence pairs
from the English-German part of Europarl anno-
tated using the Blinker guidelines (Melamed, 1998).
The automatically aligned data comes from Europarl
(Koehn, 2005) in three language pairs (English?
Dutch, English?French and English?German). The
corpora are automatically aligned using GIZA++
(Och and Ney, 2003) in combination with the grow-
diag-final-and heuristic. With sentence length cut-
off 40 on both sides these contain respectively 945k,
949k and 995k sentence pairs.
Grammatical Coverage (GC) is defined as the
percentage word alignments (sentence pairs) in a
parallel corpus that can be covered by an instance
of the grammar (NF-ITG) (cf. Section 5). Clearly,
GC depends on the chosen semantic interpretation
of word alignments: contiguous TE?s (phrase pairs)
or discontiguous TE?s.
63
Alignments Set GC contiguous TEs GC discontiguous TEs
Hand aligned corpora
English?French 76.0 75.0
English?Portuguese 78.0 78.0
English?Spanish 83.0 83.0
Portuguese?French 78.0 74.0
Portuguese?Spanish 91.0 91.0
Spanish?French 79.0 74.0
LREC Corpora Average 80.83?5.49 79.17?6.74
English?German 45.427 45.325
Automatically aligned Corpora
English?Dutch 45.533 43.57
English?French 52.84 49.95
English?German 45.59 43.72
Automatically aligned corpora average 47.99?4.20 45.75?3.64
Table 1: The grammatical coverage (GC) of NF-ITG for different corpora dependent on the interpretation
of word alignments: contiguous Translation Equivalence or discontiguous Translation Equivalence
Results Table 1 shows the Grammatical Coverage
(GC) of NF-ITG for the different corpora depen-
dent on the two alternative definitions of translation
equivalence. The first thing to notice is that there
is just a small difference between the Grammatical
Coverage scores for these two definitions. The dif-
ference is in the order of a few percentage points,
the largest difference is seen for Portuguese?French
(79% v.s 74% Grammatical Coverage), for some
language pairs there is no difference. For the au-
tomatically aligned corpora the absolute difference
is on average about 2%. We attribute this to the fact
that there are only very few discontiguous TEUs that
can be covered by NF-ITG in this data.
The second thing to notice is that the scores are
much higher for the corpora from the LREC dataset
than they are for the manually aligned English?
German corpus. The approximately double source
and target length of the manually aligned English?
German corpus, in combination with somewhat less
dense alignments makes this corpus much harder
than the LREC corpora. Intuitively, one would
expect that more alignment links make alignments
more complicated. This turns out to not always be
the case. Further inspection of the LREC alignments
also shows that these alignments often consist of
parts that are completely linked. Such completely
linked parts are by definition treated as atomic
TEUs, which could make the alignments look sim-
pler. This contrasts with the situation in the man-
ually aligned English?German corpus where on av-
erage less alignment links exist per word. Exam-
ples 1 and 2 show that dense alignments can be sim-
pler than less dense ones. This is because sometimes
the density implies idiomatic TEUs which leads to
rather flat lexical productions. We think that id-
iomatic TEUs reasonably belong in the lexicon.
When we look at the results for the automati-
cally aligned corpora at the lowest rows in the ta-
ble, we see that these are comparable to the results
for the manually aligned English?German corpus
(and much lower than the results for the LREC cor-
pora). This could be explained by the fact that the
manually aligned English?German is not only Eu-
roparl data, but possibly also because the manual
alignments themselves were obtained by initializa-
tion with the GIZA++ alignments. In any case, the
manually and automatically acquired alignments for
this data are not too different from the perspective of
NF-ITG. Further differences might exist if we would
employ another class of grammars, e.g., full SCFGs.
One the one hand, we find that manual align-
ments are well but not fully covered by NF-ITG.
On the other, the automatic alignments are not cov-
ered well but NF-ITG. This suggests that these au-
tomatic alignments are difficult to cover by NF-ITG,
and the reason could be that these alignments are
built heuristically by trading precision for recall cf.
64
(Och and Ney, 2003). Sogaard (S?gaard, 2010) re-
ports that full ITG provides a few percentage points
gains over NF-ITG.
Overall, we find that our results for the LREC data
are far higher Sogaard?s (S?gaard, 2010) results but
lower than the upperbounds of (S?gaard and Wu,
2009). A similar observation holds for the English?
German manually aligned EuroParl data, albeit the
maximum length (15) used in (S?gaard and Wu,
2009; S?gaard, 2010) is different from ours (40). We
attribute the difference between our results and So-
gaard?s approach to our choice to adopt lexical pro-
ductions of NF-ITG that contain own internal align-
ments (the detailed version) and determined by the
atomic TEUs of the word alignment. Our results
differ substantially from (S?gaard and Wu, 2009)
who report upperbounds (indeed our results still fall
within these upperbounds for the LREC data).
8 Related Work
The array of work described in (Zens and Ney,
2003; Wellington et al, 2006; S?gaard and Wu,
2009; S?gaard and Kuhn, 2009; S?gaard, 2010) con-
centrates on methods for calculating upperbounds
on the alignment coverage for all ITGs, including
NF-ITG. Interestingly, these upperbounds are deter-
mined by filtering/excluding complex alignment phe-
nomena known formally to be beyond (NF-)ITG.
None of these earlier efforts discussed explicitly the
dilemmas of instantiating a grammar formalism or
how to formally parse word alignments.
The work in (Zens and Ney, 2003; S?gaard and
Wu, 2009), defining and counting TEUs, provides
a far tighter upperbound than (Wellington et al,
2006), who use the disjunctive interpretation of
word alignments, interpreting multiple alignment
links of the same word as alternatives. We adopt the
conjunctive interpretation of word alignments like a
majority of work in MT, e.g., (Ayan and Dorr, 2006;
Fox, 2002; S?gaard and Wu, 2009; S?gaard, 2010).
In deviation from earlier work, the work in (S?-
gaard and Kuhn, 2009; S?gaard and Wu, 2009;
S?gaard, 2010) discusses TEUs defined over word
alignments explicitly, and defines evaluation metrics
based on TEUs. In particular, Sogaard (S?gaard,
2010) writes that he employs "a more aggressive
search" for TEUs than earlier work, thereby leading
to far tighter upperbounds on hand aligned data. Our
results seem to back this claim but, unfortunately, we
could not pin down the formal details of his proce-
dure.
More remotely related, the work described in
(Huang et al, 2009) presents a binarization algo-
rithm for productions of an SCFG instance (as op-
posed to formalism). Although somewhat related,
this is different from checking whether there exists
an NF-ITG instance (which has to be determined)
that covers a word alignment.
In contrast with earlier work, we present the align-
ment coverage problem as an intersection of two par-
tially ordered sets (graphs). The partial order over
TEUs as well as the formal definition of parsing as
intersection in this work are novel elements, mak-
ing explicit the view of word alignments as automata
generating partially order sets.
9 Conclusions
In this paper we provide a formal characterization
for the problem of determining the coverage of a
word alignment by a given grammar formalism as
the intersection of two partially ordered sets. These
partially ordered set of TEUs can be formalized in
terms of hyper-graphs implementing forests (packed
synchronous trees), and the coverage as the intersec-
tion between sets of synchronous trees generalizing
the trees of (Zhang et al, 2008).
Practical explorations of our findings for the bene-
fit of models of learning reordering are underway. In
future work we would like to investigate the exten-
sion of this work to other limited subsets of SCFGs.
We will also investigate the possibility of devising
ITGs with explicit links between terminal symbols
in the productions, exploring different kinds of link-
ing.
Acknowledgements We thank reviewers for their
helpful comments, and thank Mark-Jan Nederhof for
illuminating discussions on parsing as intersection.
This work is supported by The Netherlands Orga-
nization for Scientific Research (NWO) under grant
nr. 612.066.929.
65
References
Nacip Ayan and Bonnie Dorr. 2006. Going beyond AER:
an extensive analysis of word alignments and their im-
pact on MT. In Proc. of the 21st International Confer-
ence on Computational Linguistics and the 44th An-
nual Meeting of the ACL, pages 9?16, Morristown, NJ,
USA.
Yehoshua Bar-Hillel, Micha Perles, and Eli Shamir.
1964. On formal properties of simple phrase struc-
ture grammars. In Y. Bar-Hillel, editor, Language and
Information: Selected Essays on their Theory and Ap-
plication, chapter 9, pages 116?150. Addison-Wesley,
Reading, Massachusetts.
Phil Blunsom, Trevor Cohn, Chris Dyer, and Miles Os-
borne. 2009. A gibbs sampler for phrasal synchronous
grammar induction. In ACL/AFNLP, pages 782?790.
Marine Carpuat and Dekai Wu. 2007. Improving statisti-
cal machine translation using word sense disambigua-
tion. In Proc. of the Joint Conference on Empirical
Methods in Natural Language Processing and Compu-
tational Natural Language Learning (EMNLP-CoNLL
2007), page 61?72.
David Chiang. 2005. A hierarchical phrase-based model
for statistical machine translation. In Proceedings of
the 43rd Annual Meeting of the ACL, pages 263?270,
June.
David Chiang. 2007. Hierarchical phrase-based transla-
tion. Computational Linguistics, 33(2):201?228.
Trevor Cohn and Phil Blunsom. 2009. A bayesian model
of syntax-directed tree to string grammar induction. In
EMNLP, pages 352?361.
John DeNero, Daniel Gillick, James Zhang, and Dan
Klein. 2006. Why generative phrase models underper-
form surface heuristics. In Proceedings of the work-
shop on SMT, pages 31?38.
Heidi J. Fox. 2002. Phrasal cohesion and statistical
machine translation. In Proceedings of the ACL-02
conference on Empirical methods in natural language
processing - Volume 10, Proceedings of EMNLP,
pages 304?311, Stroudsburg, PA, USA. Association
for Computational Linguistics.
Joao Grac?a, Joana Pardal, Lu?sa Coheur, and Diamantino
Caseiro. 2008. Building a golden collection of paral-
lel multi-language word alignment. In LREC?08, Mar-
rakech, Morocco. European Language Resources As-
sociation (ELRA).
Aria Haghighi, John Blitzer, John DeNero, and Dan
Klein. 2009. Better word alignments with supervised
itg models. In Proceedings of the Joint Conference of
the 47th Annual Meeting of the ACL and the 4th Inter-
national Joint Conference on Natural Language Pro-
cessing of the AFNLP, pages 923?931, Suntec, Singa-
pore, August. Association for Computational Linguis-
tics.
Liang Huang, Hao Zhang, Daniel Gildea, and Kevin
Knight. 2009. Binarization of synchronous
context-free grammars. Computational Linguistics,
35(4):559?595.
Philipp Koehn, Franz Josef Och, and Daniel Marcu.
2003. Statistical phrase-based translation. In Proc.
of the Human Language Technology Conference, HLT-
NAACL, May.
Philipp Koehn. 2005. Europarl: A parallel corpus for
statistical machine translation. In Proc. of MT Summit.
Bernard Lang. 1988. Parsing incomplete sentences. In
Proceedings of COLING, pages 365?371.
J. Scott McCarley, Abraham Ittycheriah, Salim Roukos,
Bing Xiang, and Jian-Ming Xu. 2011. A correc-
tion model for word alignments. In Proceedings of
EMNLP, pages 889?898.
Dan Melamed. 1998. Annotation style guide for the
blinker project, version 1.0. Technical Report IRCS
TR #98-06, University of Pennsylvania.
Markos Mylonakis and Khalil Sima?an. 2011. Learning
hierarchical translation structure with linguistic anno-
tations. In Proceedings of the HLT/NAACL-2011.
Mark-Jan Nederhof and Giorgio Satta. 2004. The lan-
guage intersection problem for non-recursive context-
free grammars. Inf. Comput., 192(2):172?184.
Franz Josef Och and Hermann Ney. 2003. A system-
atic comparison of various statistical alignment mod-
els. Computational Linguistics, 29(1):19?51.
Sebastian Pad? and Mirella Lapata. 2006. Optimal con-
stituent alignment with edge covers for semantic pro-
jection. In ACL-COLING?06, ACL-44, pages 1161?
1168, Stroudsburg, PA, USA. Association for Compu-
tational Linguistics.
Jason Riesa and Daniel Marcu. 2010. Hierarchical
search for word alignment. In Proceedings of ACL,
pages 157?166.
Giorgio Satta and Enoch Peserico. 2005. Some com-
putational complexity results for synchronous context-
free grammars. In Proceedings of Human Language
Technology Conference and Conference on Empirical
Methods i n Natural Language Processing, pages 803?
810, Vancouver, British Columbia, Canada, October.
Association for Computational Linguistics.
Anders S?gaard and Jonas Kuhn. 2009. Empirical lower
bounds on alignment error rates in syntax-based ma-
chine translation. In SSST ?09, pages 19?27, Strouds-
burg, PA, USA. Association for Computational Lin-
guistics.
Anders S?gaard and Dekai Wu. 2009. Empirical lower
bounds on translation unit error rate for the full class
of inversion transduction grammars. In Proceedings of
the 11th International Workshop on Parsing Technolo-
gies (IWPT-2009), 7-9 October 2009, Paris, France,
66
pages 33?36. The Association for Computational Lin-
guistics.
Anders S?gaard. 2010. Can inversion transduction
grammars generate hand alignments? In Proccedings
of the 14th Annual Conference of the European Asso-
ciation for Machine Translation (EAMT).
Roy Tromble and Jason Eisner. 2009. Learning linear or-
dering problems for better translation. In Proceedings
of EMNLP?09, pages 1007?1016, Singapore.
Gertjan van Noord. 1995. The intersection of finite state
automata and definite clause grammars. In Proceed-
ings of ACL, pages 159?165.
Benjamin Wellington, Sonjia Waxmonsky, and I. Dan
Melamed. 2006. Empirical lower bounds on the com-
plexity of translational equivalence. In Proceedings of
the Annual Meeting of the Association for Computa-
tional Linguistics (ACL).
Dekai Wu. 1997. Stochastic inversion transduction
grammars and bilingual parsing of parallel corpora.
Computational Linguistics, 3(23):377?403.
D.H. Younger. 1967. Recognition and parsing of
context-free languages in time n3. Information and
Control, 10(2):189?208.
Richard Zens and Hermann Ney. 2003. A comparative
study on reordering constraints in statistical machine
translation. In Proceedings of the Annual Meeting of
the ACL, pages 144?151.
Hao Zhang, Daniel Gildea, and David Chiang. 2008. Ex-
tracting synchronous grammar rules from word-level
alignments in linear time. In Proceedings of COLING,
pages 1081?1088.
Andreas Zollmann and Ashish Venugopal. 2006. Syn-
tax augmented machine translation via chart parsing.
In Proceedings of the North-American Chapter of the
ACL (NAACL?06), pages 138?141.
67
