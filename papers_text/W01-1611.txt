Condence-based Adaptivity in Response Generation
for a Spoken Dialogue System
Kristiina Jokinen
University of Art and Design Helsinki
00560 Helsinki, Finland
kjokinen@uiah.fi
Graham Wilcock
University of Helsinki
00014 Helsinki, Finland
Graham.Wilcock@helsinki.fi
Abstract
The paper addresses the issue of how to increase
adaptivity in response generation for a spoken
dialogue system. Realization strategies for dia-
logue responses depend on communicative con-
dence levels and interaction management goals.
We rst describe a Java/XML-based generator
which produces dierent realizations of system
responses based on agendas specied by the di-
alogue manager. We then discuss how greater
adaptivity can be achieved by using a set of dis-
tinct generator agents, each of which is special-
ized in its realization strategy (e.g. highly ellip-
tical or highly explicit). This allows a simpler
design of each generator agent, while increas-
ing the overall system adaptivity to meet the
requirements for exible cooperation in incre-
mental and immediate interactive situations.
1 Introduction
When describing the desired characteristics of
human-computer interaction, the common key-
words are cooperation and naturalness. Coop-
eration is used to refer to the participants' abil-
ity to collaborate with each other on a given
task and to provide informative and helpful con-
tributions in a given task context. Naturalness,
however, describes the participants' reaction
which is appropriate in the current communica-
tive context, and usually presupposes reasoning
through which the participants can adapt them-
selves to the requirements of the situation and
to the knowledge level of their partner.
Naturalness in spoken interaction can be
characterised by features such as incrementality
and immediacy (Jokinen et al, 1998). Speak-
ers exchange information and present the new
information in a stepwise manner, constructing
a common ground by providing new pieces of
relevant information to complete the task that
the interaction was initiated for. They mon-
itor their own presentations and react to the
partner's contributions immediately, often si-
multaneously, to prevent potential misunder-
standings growing and causing problems to the
interaction. Spoken dialogue systems that aim
at natural interaction with the user should thus
have capabilities for incremental and immedi-
ate management of interaction. In other words,
they should be able to produce responses that
take into account the requirements of an incre-
mental and immediate interactive situation. In
this paper we discuss how various types of sys-
tem responses can be generated taking into ac-
count the special requirements of incremental
and immediate interaction situations.
The paper is structured as follows. In Sec-
tion 2 we discuss concrete examples from a spo-
ken dialogue system, in which dierent forms
of surface realization are required in order to
achieve interaction management goals. This
may involve, for example, deliberate repetition
of old information to get implicit conrmation
of speech recognition accuracy. When there is
a high level of condence in the eectiveness of
the communication channel, however, the pre-
ferred form of response realization is to include
only the new information in the response.
Section 3 describes an implementation of dia-
logue response generation based on Java, XML
and XSL transformations. The implementation
can generate the dierent realizations discussed
in Section 2. The way in which the genera-
tor chooses between the dierent realizations
is based on detailed specications of the infor-
mation status of dierent concepts, given in an
agenda by the dialogue manager component.
In Section 4 we then discuss an alternative
approach to the choice of realization, in which
a set of distinct generation agents are used, each
agent being specialized in its realization strat-
egy (e.g. highly elliptical or highly explicit).
The design of the individual generation agents
is therefore simpler, but the system as a whole
increases in adaptivity by choosing which agent
to use according to the wider dialogue context.
We describe a Java and XML-based framework
which supports this architecture, and discuss a
strategy for adaptivity based on communicative
condence.
2 Interaction Management
In this section we discuss concrete examples
from a spoken dialogue system. The domain
is public transportation in Helsinki.
2.1 Agenda, NewInfo and Topic
To enable incremental presentation and imme-
diate reaction, Jokinen et al (1998) structure
the context with the help of NewInfo and Topic,
so that the generator can distinguish the new in-
formation that is meant to be put across in the
current dialogue situation, and the background
information that the new information is linked
to. The pool of contextual information includes
an agenda, a set of concepts marked with the
help of 'topic' and 'newinfo' tags, the tags be-
ing determined by the dialogue manager which
decides how the system is to react next.
The generator can freely use the tagged pieces
of information in order to realise the system's
intention as a surface string, but it is not forced
to include in the response all the concepts that
the dialogue manager has designated as rele-
vant in the agenda. Thus the dialogue manager
and the generator communicate via the specif-
ically marked conceptual items in the shared
knowledge-base, but they both make their own
decisions on the basis of their own reasoning and
task management. The dialogue manager need
not know about particular rules of surface real-
isation while the generator need not know how
to decide the information status of the concepts
in the current dialogue situation.
While the notions of NewInfo and Topic are
often used to illustrate the characteristics of
word-order variation, their importance in spo-
ken dialogue systems can be mostly shown in
the planning process that lies at the border
of dialogue processing and tactical generation.
Consider rst the following questions by the
user:
(1) Which bus goes to Malmi?
(2) How do I get to Malmi?
The dialogue manager has analysed them as
timetable requests related to the user's going to
Malmi. It has also recognized that NewInfo in
(1) is the information concerning bus numbers
while NewInfo in (2) concerns means of trans-
portation.
In the case of (1), the information that the
dialogue manager gets from the task manager
which consults the timetable database, is that
there is bus 74 that goes to Malmi. The dialogue
manager decides to put the following concepts
into the agenda in the shared knowledge pool
(using XML as discussed in Section 3):
<agenda>
<concept info="Topic">
<type>means-of-transportation</type>
<value>bus</value>
</concept>
<concept info="Topic">
<type>destination</type>
<value>malmi</value>
</concept>
<concept info="Topic">
<type>bus</type>
<value>exists</value>
</concept>
<concept info="NewInfo">
<type>busnumber</type>
<value>74</value>
</concept>
</agenda>
The dialogue manager also tags the concepts
as NewInfo or Topic, reecting its knowledge of
how the concepts relate to the current dialogue
situation. The concept 'busnumber' is tagged
as NewInfo, and the other three as Topic, since
this is a match with the new information asked
in the previous utterance, and the user will be
likely to link the response correctly.
The generator can then select the concepts
and decide the surface realisation as described
in Section 4. The simplest realisation is:
(1a) Number 74.
2.2 Indirect Requests
For example (2), however, the situation is some-
what more complicated since the user question
can be understood either as a literal question
about public transportation to Malmi, or as an
indirect request for buses that go to Malmi. In-
formation about the previous dialogue situation
must thus be used, and we relate the dierence
to the Topic of the conversation: in the 'literal'
case, the Topic is Malmi, the destination where
the speaker wants to nd out transportation
for, whereas in the indirect request, the Topic is
the bus as a means of transportation to Malmi.
Consequently, in the 'literal' case, the dialogue
manager consults the task manager by request-
ing a value for the concept 'means of trans-
portation', while in the indirect request, the di-
alogue manager requests task manager to give
a value for the busnumber. In both cases, how-
ever, the information that the dialogue man-
ager gets from the task manager is the same:
that there exists a means of transportation to
Malmi, namely a bus and the busnumber is 74.
1
When deciding on the response to the 'lit-
eral' case, the dialogue manager regards the
means of transportation as NewInfo and the
destination to Malmi as Topic, continuing the
information structure of the previous question.
The two other concepts, 'bus' and 'busnumber',
are also tagged as new but since the NewInfo
that matches the dialogue situation concerns
the public transportation to Malmi, the piece of
information of the bus number is extra informa-
tion that can be seen as a sign of cooperation on
the system's side, rather than a necessary new
information to be told to the user, i.e. they
can be added in the response if the time con-
straints allow this and the level of cooperation
so requests.
The agenda in the shared knowledge pool in
case (2a) is as follows:
<agenda>
<concept info="NewInfo">
<type>means-of-transportation</type>
<value>bus</value>
</concept>
<concept info="Topic">
1
The dialogue manager and task manager commu-
nicate with each other via a particular task-form which
has as its parameters the concepts important for the task
manager to fetch information from the database. If the
form is lled in so that a database query can be per-
formed, the task manager returns the form with all the
appropriate parameters lled in, and thus lets the dia-
logue manager decide on the status of the parameters
and their values with respect to the dialogue situation.
<type>destination</type>
<value>malmi</value>
</concept>
<concept info="NewInfo">
<type>bus</type>
<value>exists</value>
</concept>
<concept info="NewInfo">
<type>busnumber</type>
<value>74</value>
</concept>
</agenda>
In the case of an indirect request, the dia-
logue manager again relies on the dialogue con-
text when tagging the concepts for the agenda.
The Topic is the means of transportation to
Malmi, whereas the NewInfo concerns the bus-
number, and so only the 'bus' and 'busnumber'
are tagged as new. For (2b), the shared knowl-
edge is thus as follows:
<agenda>
<concept info="Topic">
<type>means-of-transportation</type>
<value>bus</value>
</concept>
<concept info="Topic">
<type>destination</type>
<value>malmi</value>
</concept>
<concept info="NewInfo">
<type>bus</type>
<value>exists</value>
</concept>
<concept info="NewInfo">
<type>busnumber</type>
<value>74</value>
</concept>
</agenda>
The dierence in the system responses is re-
ected in the alternatives (2a) and (2b):
(2a) By bus - number 74.
(2b) Bus 74 goes there.
2.3 Condence Levels
The next example is related to a dierent as-
pect of spoken dialogue systems: condence in
speech recognition results. The dialogue man-
ager gets the recognized words together with
their recognition scores, and decides on the ap-
propriate action depending on the condence
levels.
(3) When will the next bus leave for Malmi?
(a) 2.20pm
(b) It will leave at 2.20pm
(c) The next bus to Malmi leaves at
2.20pm
As is common, we assume that if recognition
is above a certain condence level, the system
will use the simplest and most straightforward
answer, while if the recognition error becomes
bigger, a conrmation strategy has to be used.
Thus response (3a) is used when the system has
condence that the user has indeed asked about
new information concerning the next bus leav-
ing for Malmi (cf. 1a). Response (3b) is also
used in the similar situation where the system is
condent about its recognition, but the dialogue
situation diers from the one in (3a) in that
now the system assumes that the user expects a
polite full response, instead of an elliptical an-
swer as in (3a) where the user has talked about
the buses to Malmi and just wants to check the
next one leaving. The alternative (3c) is used
when the system explicitly wants to conrm the
Topic (= next bus to Malmi), so as not to allow
user to draw false implicatures about which bus
timetable the answer concerns.
The agendas for the alternatives (3a) and (3b)
are similar, and the dierence in the surface re-
alizations is due to the dierent interaction his-
tory: in the former case the Topic continues and
the dialogue history contains the concepts des-
tination and bus as previous Topics, whereas in
the latter case, the previous Topics may be dif-
ferent concepts or there may me no previous
Topic at all (beginning of the dialogue).
(3a,b)
<agenda>
<concept info="Topic">
<type>means-of-transportation</type>
<value>bus</value>
</concept>
<concept info="Topic">
<type>destination</type>
<value>malmi</value>
</concept>
<concept info="Topic">
<type>bus</type>
<value>exists</value>
</concept>
<concept info="NewInfo">
<type>bustime</type>
<value>2.20pm</value>
</concept>
</agenda>
Also the agenda for the alternative (3c) looks
the same, except for the feature <confidence>
which characterizes the system's own evaluation
of how condent it is of the correctness of the
recognized concepts. The value 1 marks cer-
tainty as in the case of bustime whose value is
retrieved from the database. This feature has
been left out in the other representations for
the sake of clarity: if the condence is above
the threshold, the concept is treated according
to its information status in the shared pool.
(3c)
<agenda>
<concept info="Topic">
<type>means-of-transportation</type>
<value>bus</value>
<confidence>0.6</confidence>
</concept>
<concept info="Topic">
<type>destination</type>
<value>malmi</value>
<confidence>0.2</confidence>
</concept>
<concept info="Topic">
<type>bus</type>
<value>exists</value>
<confidence>0.6</confidence>
</concept>
<concept info="NewInfo">
<type>bustime</type>
<value>2.20pm</value>
<confidence>1.0</confidence>
</concept>
</agenda>
3 Dialogue Response Generation
The system's competence in dialogue manage-
ment is shown in the two tasks that the sys-
tem must perform: evaluating the user goal,
and response generation. The former results
in strategic decision about operationally appro-
priate goals, while the latter concerns how the
same goal can be realised in dierent ways in
dierent contexts.
We now describe the framework which per-
forms the dialogue response generation. The
content determination has been done by the di-
alogue manager, which has selected the relevant
concepts to put on the agenda. The discourse
planning is based closely on the specication of
Topic and NewInfo by the dialogue manager,
but also includes specic decisions by the gener-
ator described in Section 3.2. The response gen-
eration continues with an aggregation stage, de-
scribed in Section 3.3, followed by a stage which
combines lexicalization and generation of refer-
ring expressions, described in Section 3.4. Mor-
phological generation, which is very important
for one of the languages generated (Finnish), is
done in a separate stage.
The framework is based on Java, XML and
XSL transformations. The implemented system
can generate the responses which we have dis-
cussed. In the next section, we will describe an
extension to this framework, suitable for adap-
tive and exible response generation.
3.1 A Pipeline Architecture
The generator starts from an agenda of con-
cepts specied in XML, set up by the dialogue
manager as shown in the examples in Section 2.
The generator produces linguistic output which
is also specied in XML, to be passed to the
speech synthesizer. We are therefore generating
XML from XML. The simplest way to do this
is to apply a set of XML transformations spec-
ied in XSL (XML Stylesheet Language). We
do this using the Xalan XSL Processor (Apache
XML Project, 2001) which is open-source soft-
ware written entirely in Java.
With the Xalan XSL Processor it is easy to
set up a sequence of transformations, in which
the output of one transformation becomes the
input to the next transformation. This kind of
\piping" is a natural way to implement the stan-
dard pipeline architecture regularly used in nat-
ural language generation systems (Reiter and
Dale, 2000).
The ease of setting up a pipeline architecture
with XSL raises the general question of whether
XSL transformations are suitable for wider use
in NLG systems. This is discussed by Cawsey
(2000), who concludes that relatively simple
XSL transformations can be used for generation
when the input is fairly constrained, but XSL is
not suitable for less constrained input, when we
need to turn to general purpose programming
languages or NLG tools.
However, XSL can be combined with gen-
eral purpose programming languages by embed-
ding extension functions in the XSL templates.
These functions can be written in Java (Apache
XML Project, 2001). This means that even
where general purpose programming languages
are required for specic purposes, such as com-
plex morphology, a pipeline of XSL transforma-
tions can still be used as a general framework.
3.2 Focus-based Generation
The model of dialogue response generation
which we use is based on generation from the
new information focus, as proposed by Jokinen
et al (1998). In this model, response planning
starts from the new information focus, called
NewInfo. One of the tasks of the generator is
to decide how to present the NewInfo to the
user: whether it should be presented by itself
or whether it should be wrapped in appropriate
linking information.
The wrapping of the NewInfo depends on
the pragmatic requirements of the dynamic dia-
logue context. When the context permits a u-
ent exchange of contributions, wrapping will be
avoided and the response will be based on new
information only. When the context requires
more clarity and explicitness, the new informa-
tion will be wrapped by Topic information in
order to avoid ambiguity and misunderstand-
ing. When the communication channel is work-
ing well, wrapping will be reduced, and when
there are uncertainties about what was actually
said, wrapping will be increased to provide im-
plicit conrmation.
Typically, XSL transformations are used
to convert information content represented in
XML into a desired presentation format, for ex-
ample in HTML. There is usually no need for
complex re-ordering of the content. Here how-
ever, the generator must convert the unordered
bag of concepts in the agenda into a syntacti-
cally correct ordered sequence of words to be
passed to the speech synthesizer. Also, the new
information focus tends to come last in surface
order, so the linking information (if any) will
generally precede the new information in the
surface realization.
Simple reordering can be performed in XSL,
for example by using XSL modes. We have ex-
perimented with applying XSL templates rst
with a Topic mode (if required), followed by a
NewInfo mode. The usefulness of XSL modes
for such purposes is noted by Cawsey (2000).
However, as we must also handle detailed syn-
tactic ordering, we use aggregation templates as
described in Section 3.3.
If the real-time requirements of the system al-
low su?cient time, the generator can decide on
the optimum way to wrap the new information,
but if there is extreme urgency to produce a re-
sponse, the generator can simply give the new
information without wrapping it. If this leads
to misunderstanding, the system can attempt
to repair this in subsequent turns. In this sense,
the model oers an any-time algorithm, impor-
tant for providing incremental and immediate
responses for spoken interactive situations.
3.3 Aggregation
The aggregation stage selects those concepts
marked as NewInfo as the basis for generation,
and also decides whether NewInfo will be the
only output, or whether it will be preceded by
the Topic linking concepts.
In order to implement detailed syntactic or-
dering, we use aggregation templates as a form
of sentence plan specication. The aggregation
templates are implemented by means of XSL
named templates, as in the following simplied
example:
<xsl:template name="NUM-DEST-TIME">
<aggregation>
<tree><node>S</node>
<tree><node>NP</node>
<xsl:copy-of select=".
/concept[type='busnumber']"/>
</tree>
<tree><node>V</node>
<xsl:copy-of select=".
/concept[type='bus']"/>
</tree>
<tree><node>PP</node>
<xsl:copy-of select=".
/concept[type='destination']"/>
</tree>
<tree><node>PP</node>
<xsl:copy-of select=".
/concept[type='bustime']"/>
</tree>
</tree>
</aggregation>
</xsl:template>
The selected aggregation template creates a
new XML document instance, with root node
<aggregation>. Its child nodes are one or more
<tree> nodes, containing syntactic categories
and other features. The trees contain variable
slots, which will be lled in later by the lexical-
ization and referring expression stages. In the
aggregation stage, the concepts from the agenda
are copied directly into the appropriate slots by
means of <xsl:copy-of> statements.
Our aggregation templates are quite similar
to the syntactic templates described by Theune
(2000). As argued by van Deemter et al (1999),
this kind of syntactic template-based approach,
which rather resembles TAG-based generation,
is fundamentally well-founded.
The selection of an appropriate aggregation
template is based on which concept types are in
the agenda and on their information status as
Topic or NewInfo. The logic is implemented by
means of nested <xsl:choose> statements, as
in the following example:
<!-- CHOOSE TEMPLATE BASED ON AGENDA -->
<xsl:template match="agenda">
<xsl:choose>
<xsl:when test="concept[@info='NewInfo']
/type='means-of-transportation'">
<xsl:call-template name="BY-TRANSPORT"/>
</xsl:when>
<xsl:when test="concept[@info='NewInfo']
/type='bus'">
<xsl:choose>
<xsl:when test="concept[@info='NewInfo']
/type='busnumber'">
<xsl:call-template name="NUM-DEST-TIME"/>
</xsl:when>
...
</xsl:choose>
</xsl:when>
<xsl:when test="concept[@info='NewInfo']
/type='busnumber'">
<xsl:call-template name="NUMBER-ONLY"/>
</xsl:when>
...
</xsl:choose>
</xsl:template>
Here, if means-of-transportation is NewInfo
as in (2a), the template named BY-TRANSPORT
is selected. If means-of-transportation is not
NewInfo, but bus and busnumber are NewInfo
as in (2b), template NUM-DEST-TIME is selected.
If only busnumber is NewInfo, as in (1a), the
template NUMBER-ONLY is selected.
3.4 Referring Expressions
In the lexicalization and referring expression
stages of the response generation pipeline, the
concepts in the aggregation templates are re-
placed by lexical items and referring expres-
sions. In general, concepts which are marked
as Topic are realized as pronouns, as shown by
the following simplied examples:
<!-- REFERRING EXPRESSIONS: PRONOUNS -->
<xsl:template
match="concept[@info='Topic']"
mode="referring-expression">
<xsl:choose>
<xsl:when test="type='busnumber'">
<xsl:text> it </xsl:text>
</xsl:when>
<xsl:when test="type='destination'">
<xsl:text> there </xsl:text>
</xsl:when>
<xsl:when test="type='bustime'">
<xsl:text> then </xsl:text>
</xsl:when>
</xsl:choose>
</xsl:template>
Here, a destination concept marked as Topic
is pronominalized as there, as in (2b). By con-
trast, concepts which are marked as NewInfo
are realized as full descriptions. In the following
template, the destination concept is realized by
a prepositional phrase, to followed by the text
value of the destination placename, obtained by
the <xsl:value-of> statement.
<!-- REFERRING EXPRESSIONS: DESCRIPTIONS -->
<xsl:template
match="concept[@info='NewInfo']"
mode="referring-expression">
<xsl:choose>
<xsl:when test="type='busnumber'">
<xsl:text> number </xsl:text>
<xsl:value-of select="value/text()"/>
</xsl:when>
<xsl:when test="type='destination'">
<xsl:text> to </xsl:text>
<xsl:value-of select="value/text()"/>
</xsl:when>
<xsl:when test="type='bustime'">
<xsl:text> at </xsl:text>
<xsl:value-of select="value/text()"/>
</xsl:when>
</xsl:choose>
</xsl:template>
The above examples are simplied to show
simple text output. The nal stages of response
generation actually perform syntactic and mor-
phological realization producing XML output
(SABLE or VoiceXML) which is passed to the
speech synthesizer.
4 Condence-based Adaptivity
In general, when condence in speech recog-
nition accuracy goes down, the dialogue sys-
tem needs to adapt by increasing the repetition
of old information to check that it is correct.
When condence in speech recognition accuracy
is high, the system should adapt by reducing the
repetition of old information, given the dialogue
context itself does not require this. Normally,
with high speech recognition condence, a u-
ent dialogue will be made up of responses with
only new information.
4.1 A Development Framework
In order to allow this kind of variation in the re-
sponses produced, the framework in which the
dialogue management is embedded must itself
be designed specically to support adaptivity.
One such system is the Jaspis adaptive speech
application framework (Turunen and Hakuli-
nen, 2000). Jaspis is a general agent-based de-
velopment architecture, and on the most general
level it contains managers which handle general
coordination between the system components
and functional modules (such as the Input Man-
ager, the Dialogue Manager and the Presenta-
tion Manager). Within each manager there are
several agents which handle various interaction
situations, as well as a set of evaluators which
try to choose the best possible agent to handle
each situation. The architecture also exploits
a shared knowledge-base called the Information
Storage, where the information about the cur-
rent state of the system is kept and which each
of the agents can read and update.
The adaptivity-oriented architecture of our
dialogue system is shown in Figure 1 (the In-
put Manager is left out). The Dialogue Man-
ager consists of a number of dialogue agents that
are experts on one specic aspect of dialogue
management and whose activities are controlled
and coordinated by a particualr dialogue con-
troller (which thus currently acts as the central
evaluator for all the dialogue agents). The Di-
alogue Manager decides what to say next on
Figure 1: Part of the system architecture
the basis of the dialogue context recorded in
the Information Storage by the various agents,
and by consulting the Task Manager, whenever
the requested information requires factual in-
formation about the task itself. The output of
this reasoning is expressed in terms of concepts
marked as NewInfo and Topic, and stored in the
shared Information Storage in the XML format
as shown in the examples in Section 2.
The response generation takes place in the
presentation management module, which con-
tains several generator agents, each of which
specialized in one particular type of generation.
The agents may, for example, generate in dier-
ent languages (we are developing generators for
English and Finnish). In the current implemen-
tation, we mainly consider agents for pronomi-
nalization, explicitness and politeness.
We are developing generation agents at three
distinct explicitness levels. The rst agent gen-
erates NewInfo only, and is suitable for quick in-
formal interactions with high speech recognition
condence like example (3a). The second agent
generates NewInfo wrapped by Topic, where
Topic is normally realized as a minimal refer-
ring expression such as a pronoun. This agent
is suitable for more polite interactions with good
speech recognition, as in example (3b). The
third agent generates a fully explicit Topic, and
is suitable for situations where speech recogni-
tion condence is low, and conrmation of the
topic is required, as in example (3c). One ad-
vantage of this approach is that the design of
the individual generators is simplied, as they
can follow a xed realization strategy, but the
overall adaptivity of the system is increased.
The selection of the appropriate generator
agent is the task of the component called the
Adapter in Figure 1. The Adapter is a particu-
lar kind of evaluator based on a neural network
implementation. Input consists of a number of
features which are encoded as binary features,
and output consists of categories that represent
the dierent generators. The features are ex-
tracted from the shared information storage and
concern e.g. the content of the planned utter-
ance (Topic, NewInfo), recognition condence
of the previous user utterance, and general re-
quirements for cooperative, natural responses.
4.2 Adaptivity
Adaptivity is one of the desirable properties for
learning dialogue systems (Jokinen, 2000). It
is linked to the system's cooperation with the
user, i.e. its capability to provide informative
and helpful responses but also its capability to
tailor responses according to various situations
the users nd themselves in.
In the above framework, one approach to pro-
viding the desired adaptivity is to have gen-
erator agents with dierent levels of explicit-
ness. Changing levels of condence in speech
recognition accuracy can then lead to selecting
generator agents with more or less explicitness.
The detailed mechanisms for switching between
these dierent agents by means of the evalua-
tors in the Jaspis framework, including a soft
computing approach based on neural networks,
are being evaluated.
Related research has studied adaptivity with
respect to system strategies, and identied con-
rmation as one of the helpful strategies that
spoken dialogue systems can use in order to
show cooperation and allow the user to cor-
rect misrecognized words (Danieli and Gerbino,
1995). The use of system initiative also helps re-
duce misrecognition errors and thus contributes
to user satisfaction (Walker et al, 1998). How-
ever, a xed dialogue strategy may not suit all
users, whose knowledge of the system's capabil-
ities may dier. Adaptivity can thus be related
to the system's ability to change from a user ini-
tiative strategy to a system initiative one, or to
use varied conrmation strategies, in response
to circumstances and the user model. Empiri-
cal evaluation of one such system shows that an
adaptable system outperforms a non-adaptable
one (Litman and Pan, 2000).
We have widened the notion of adaptivity
to concern also the system's generation strate-
gies in maintaining natural interaction with the
user. The dialogue manager can be said to select
among dialogue strategies, such as conrmation
or initiative, and the choice is implicitly shown
in the selection of the concepts in the agenda.
The presentation manager then selects a gener-
ator agent to realise the agenda, and can be said
to further extend the system's adaptivity as an
aspect of the realization possibilities available
for the system. The same agenda can be re-
alised dierently (as in examples 3a and 3b) by
dierent generator agents, and thus the system
can adapt on dierent levels. The selection of
conrmation or non-conrmation strategy can
also depend on the system's other capabilities.
4.3 Condence
The aim of the adaptivity-oriented architecture
is to enable the spoken dialogue system to adapt
its responses to the changing condence lev-
els concerning the system's knowledge of the
current dialogue situation. At the start of a
new dialogue, when there is no previous history
on which to establish any general communica-
tive condence, the system should start with a
highly explicit response generator, and gradu-
ally, if some level of condence is established,
switch to a less explicit generator.
The high level of explicitness in the system
responses has several aspects. Simply by pro-
viding a quantity of words to be recognised and
acknowledged, the system can verify its under-
standing of the relevant concepts. Explicitness
thus enables speech recognition condence to be
established, and is related to the system's con-
rmation strategy as in example (3c).
It is also associated with politeness: a high
level of explicitness is more polite, and a high
level of elliptical expression is more friendly.
Since politeness is expected with strangers,
more explicitness is therefore appropriate at the
start of a dialogue and less appropriate as the
dialogue proceeds: it is thus inversely related
to the condence of the partner which gets es-
tablished in the shared situation. This pattern
of gradual change from a more formal initial
register to a more informal register as the di-
alogue progresses is well known, at least in cul-
tures in which register is not dictated strictly
by social hierarchy. Dierences between En-
glish dialogues (dynamic register adaptivity)
and Japanese dialogues (xed register through-
out) have been studied (Kume et al, 1989).
Generation of referring expressions is mainly
concerned with enabling successful discrimina-
tion of the correct referent. However, referring
expressions in dialogue systems are also strongly
aected by the level of condence. When there
is some doubt, it is safer to use highly explicit
referring expressions. When there is a high level
of condence, it is normal to take certain risks
for the sake of uent interaction. In fact the
dierence between denite descriptions and pro-
nouns is based on condence: if an entity has
not been mentioned previously, it has no history
on which any condence can be established, so
a high level of explicitness is required.
4.4 Communicative Obligations
As argued by Allwood (1976), communication
creates normative social obligations which con-
cern the speaker's rational coordinated interac-
tion. Obligations are connected to a particular
activity and a role in the activity, varying also
according to the speakers' familiarity and rela-
tive status with each other.
In dialogue systems, communicative obliga-
tions are usually part of the system's control
structure. The system can take the initiative,
give helpful information in anticipation of the
user's questions or to resolve problematic sit-
uations (misheard words, ambiguous referents,
etc.), or simply react to the user input as best
as it can. Obligations are thus used as a basic
motivation for action (Traum and Allen, 1994).
In our framework communicative obligations
are dispersed among the agents and evaluator
control. This allows us to make the obligations
overt, since they can be implemented as simple
dialogue agents. However, as their application
order is not xed, the overall architecture sup-
ports exible interaction where the basic com-
municative ability of the system is shown in the
functioning of the system itself. The systems's
cooperation is not only a pre-assigned disposi-
tion to act in a helpful way, but involves reason-
ing about the appropriate act in the context.
5 Conclusion
We have described our work on adaptivity in re-
sponse generation for a spoken dialogue system,
and have argued in favour of a system architec-
ture using highly specialized agents. The sys-
tem adapts its responses to dialogue situations
by means of the detailed agendas specied by
the dialogue manager and the selection of the
generator agent by the presentation manager.
Further evaluation of a larger demonstrator sys-
tem is planned.
References
Jens Allwood. 1976. Linguistic Communication
as Action and Cooperation. Department of
Linguistics, University of Goteborg. Gothen-
burg Monographs in Linguistics 2.
Apache XML Project. 2001. Xalan-Java
version 2.1.0. http://xml.apache.org/xalan-
j/index.html.
Alison Cawsey. 2000. Presenting tailored re-
source descriptions: Will XSLT do the job?
In 9th International Conference on the World
Wide Web.
Morena Danieli and Elisabetta Gerbino. 1995.
Metrics for evaluating dialogue strategies in
a spoken language system. In Proceedings
of the AAAI Spring Symposium on Empiri-
cal Methods in Discourse Interpretation and
Generation, pages 34{39.
Kristiina Jokinen, Hideki Tanaka, and Akio
Yokoo. 1998. Planning dialogue contribu-
tions with new information. In Proceedings
of the Ninth International Workshop on Nat-
ural Language Generation, pages 158{167,
Niagara-on-the-Lake, Ontario.
Kristiina Jokinen. 2000. Learning dialogue sys-
tems. In L. Dybkjaer, editor, LREC 2000
Workshop: From Spoken Dialogue to Full
Natural Interactive Dialogue - Theory, Em-
pirical Analysis and Evaluation, pages 13{17,
Athens.
Masako Kume, Gayle K. Sato, and Kei Yoshi-
moto. 1989. A descriptive framework for
translating speaker's meaning: Towards a di-
alogue translation system between Japanese
and English. In Fourth Conference of the
European Chapter of the Association for
Computational Linguistics, pages 264{271,
Manchester.
Diane Litman and Shimei Pan. 2000. Predict-
ing and adapting to poor speech recognition
in a spoken dialogue system. In Proceed-
ings of the Seventeenth National Conference
on Articial Intelligence (AAAI-2000), pages
722{728, Austin, TX.
Ehud Reiter and Robert Dale. 2000. Building
Natural Language Generation Systems. Cam-
bridge University Press.
Mariet Theune. 2000. From Data to Speech:
Language Generation in Context. Ph.D. the-
sis, Eindhoven University of Technology.
David Traum and James F. Allen. 1994. Dis-
course obligations in dialogue processing. In
32nd Annual Meeting of the Association for
Computational Linguistics, pages 1{8, Las
Cruces.
Markku Turunen and Jaakko Hakulinen. 2000.
Jaspis - a framework for multilingual adaptive
speech applications. In Proceedings of 6th In-
ternational Conference on Spoken Language
Processing, Beijing.
Kees van Deemter, Emiel Krahmer, and Mariet
Theune. 1999. Plan-based vs. template-
based NLG: A false opposition? In Proceed-
ings of the KI'99 Workshop: May I Speak
Freely?, pages 1{5, Saarbrucken.
Marilyn Walker, Diane Litman, Candace
Kamm, and Alicia Abella. 1998. Evaluat-
ing spoken dialogue agents with PARADISE:
Two case studies. Computer Speech and Lan-
guage, 12-3.
