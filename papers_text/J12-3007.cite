Aho, A. and J. Ullman. 1972. The Theory
of Parsing, Translation, and Compiling,
Volume 1: Parsing. Prentice-Hall,
Upper Saddle River, NJ.
Amari, S. and H. Nagaoka. 2000. Methods
of Information Geometry. Translations
of Mathematical Monographs; v. 191,
American Mathematical Society,
Providence, RI.
Bahl, L., J. Baker, F. Jelinek, and R. Mercer.
1977. Perplexity: A measure of difficulty
of speech recognition tasks. 94th Meeting
of the Acoustical Society of America, 62:S63,
Supplement 1, Miami, FL.
Baker, J. 1979. Trainable grammars for
speech recognition. The 97th Meeting of
the Acoustical Society of America, 547?550,
Cambridge, MA.
Banko, M. and E. Brill. 2001. Mitigating
the paucity-of-data problem: Exploring
the effect of training corpus size on
classifier performance for natural
language processing. Proceedings of the
1st International Conference on Human
Language Technology Research (HLT), 1?5,
Strodsburg, PA.
Barron, A. and C. Sheu. 1991. Approximation
of density functions by sequences of
exponential families. Annals of Statistics,
19:1347?1369.
Bellegarda, J. 2000. Exploiting latent
semantic information in statistical
language modeling. Proceedings of IEEE,
88(8):1279?1296.
Bellegarda, J. 2001. Robustness in
statistical language modeling: Review
and perspectives. In J. Junqua and
G. van Noods, editors, Robustness in
Language and Speech Technology, pages
101?121. Kluwer Academic Publishers,
Dordrecht.
Bellegarda, J. 2003. Statistical language
model adaptation: Review and
perspectives. Speech Communication,
42:93?108.
Bened??, J. and J. Sa?nchez. 2005. Estimation of
stochastic context-free grammars and their
use as language models. Computer Speech
and Language, 19(3):249?274.
Bengio, Y., R. Ducharme, P. Vincent, and
C. Jauvin. 2003. A neural probabilistic
language model. Journal of Machine
Learning Research, 3:1137?1155.
Berger, A., S. Della Pietra, and V. Della Pietra.
1996. A maximum entropy approach
to natural language processing.
Computational Linguistics, 22(1):39?71.
Bilmes, J. and K. Kirchhoff. 2003. Factored
language models and generalized parallel
backoff. Proceedings of the North American
Chapter of the Association for Computational
Linguistics - Human Language Technologies
(NAACL-HLT), 4?6, Edmonton, Alberta,
Canada.
Blei, D., A. Ng, and M. Jordan. 2003. Latent
Dirichlet allocation. Journal of Machine
Learning Research, 3:993?1022.
Brants, T., A. Popat, P. Xu, F. Och, and
J. Dean. 2007. Large language models in
machine translation. The 2007 Conference
on Empirical Methods in Natural Language
Processing (EMNLP), 858?867, Prague,
Czech Republic.
Charniak, E. 2001. Immediate-head
parsing for language models. The
39th Annual Conference on Association
of Computational Linguistics (ACL),
124?131, Toulouse, France.
Charniak, E., K. Knight, and K. Yamada.
2003. Syntax-based language models for
statistical machine translation. MT Summit
IX, International Association for Machine
Translation, 40?46, New Orleans, LA.
Chelba, C. 2000. Exploiting Syntactic
Structure for Natural Language Modeling.
Tan et al. A Scalable Distributed Syntactic, Semantic, and Lexical Language Model
Ph.D. dissertation, The Johns Hopkins
University, Baltimore, MD.
Chelba, C. and F. Jelinek. 1998. Exploiting
syntactic structure for language modeling.
The 36th Annual Conference on Association of
Computational Linguistics (ACL), 225?231,
Montreal, Quebec, Canada.
Chelba, C. and F. Jelinek. 2000. Structured
language modeling. Computer Speech and
Language, 14(4):283?332.
Chelba, C., J. Schalkwyk, T. Brants, V. Ha,
B. Harb, W. Neveitt, C. Parada, and
P. Xu. 2010. Query language modeling for
voice search. Proceedings of the 2010 IEEE
Workshop on Spoken Language Technology
(SLT), 127?132, Berkeley, CA.
Chen, S. and J. Goodman. 1999. An
empirical study of smoothing techniques
for language modeling. Computer Speech
and Language, 13(4): 319?358.
Chiang, D. 2005. A hierarchical phrase-based
model for statistical machine translation.
The 43th Annual Conference on Association of
Computational Linguistics (ACL), 263?270,
Ann Arbor, MI.
Chiang, D. 2007. Hierarchical phrase-based
translation. Computational Linguistics,
33(2):201?228.
Dean, J. and S. Ghemawat. 2004. MapReduce:
Simplified data processing on large
clusters. The Sixth Symposium on Operating
Systems Design and Implementation (OSDI),
137?150, San Francisco, CA.
Della Pietra, S., V. Della Pietra, J. Gillett,
J. Lafferty, H. Printz, and L. Ures. 1994.
Inference and estimation of a long-range
trigram model. Second International
Colloquium on Grammatical Inference
and Applications (ICGI), pages 78?92,
Springer-Verlag, Alicante, Spain.
Della Pietra, S., V. Della Pietra and J. Lafferty.
1997. Inducing features of random fields.
IEEE Transactions on Pattern Analysis and
Machine Intelligence, 19(4):380?393.
Dempster, A., N. Laird, and D. Rubin. 1977.
Maximum likelihood estimation from
incomplete data via the EM algorithm.
Journal of Royal Statistical Society, 39:1?38.
Emami, A., K. Papineni, and J. Sorensen.
2007. Large-scale distributed language
modeling. The 32nd IEEE International
Conference on Acoustics, Speech, and
Signal Processing (ICASSP), pages 37?40,
Honolulu, HI.
Gildea, D. and T. Hofmann. 1999.
Topic-based language models using
EM. The 6th European Conference on
Speech Communication and Technology
(EUROSPEECH), pages 2167?2170.
Goodman, J. 2001. A bit of progress in
language modeling. Computer Speech
and Language, 15(4):403?434.
Halevy, A., P. Norvig, and F. Pereira. 2009.
The unreasonable effectiveness of data.
IEEE Intelligent Systems, 24(2):8?12.
Hastie, T., R. Tibshirani and J. Friedman.
2009. The Elements of Statistical Learning:
Data Mining, Inference, and Prediction,
2nd edition. Springer, Berlin.
Hofmann, T. 2001. Unsupervised learning
by probabilistic latent semantic analysis.
Machine Learning, 42(1):177?196.
Jelinek, F. 1991. Up from trigrams!
The struggle for improved language
models. Second European Conference on
Speech Communication and Technology
(EUROSPEECH), pages 1037?1040,
Genove, Italy.
Jelinek, F. 1998. Statistical Methods for Speech
Recognition. MIT Press, Cambridge, MA.
Jelinek, F. 2004. Stochastic analysis of
structured language modeling. In M.
Johnson, S. Khudanpur, M. Ostendorf,
and R. Rosenfeld, editors, Mathematical
Foundations of Speech and Language
Processing, pages 37?72, Springer-Verlag,
Berlin.
Jelinek, F. 2009. The dawn of statistical
ASR and MT. Computational Linguistics,
35(4):483?494.
Jelinek, F. and C. Chelba. 1999. Putting
language into language modeling.
Sixth European Conference on Speech
Communication and Technology
(EUROSPEECH), Keynote Paper 1,
Budapest, Hungary.
Jelinek, F. and R. Mercer. 1980. Interpolated
estimation of Markov source parameters
from sparse data. In E. Gelsema and
L. Kanal, editors, Pattern Recognition in
Practice, pages 381?397. North Holland
Publishers, Amsterdam.
Jurafsky, D. and J. Martin. 2008. Speech
and Language Processing, 2nd edition.
Prentice Hall, Upper Saddle River, NJ.
Khudanpur, S. and J. Wu. 2000. Maximum
entropy techniques for exploiting
syntactic, semantic and collocational
dependencies in language modeling.
Computer Speech and Language,
14(4):355?372.
Kneser, R. and H. Ney. 1995. Improved
backing-off for m-gram language
modeling. The 20th IEEE International
Conference on Acoustics, Speech, and Signal
Processing (ICASSP), 181?184, Detroit, MI.
Koehn, P. 2004. Statistical significance tests
for machine translation evaluation. The
Computational Linguistics Volume 38, Number 3
2004 Conference on Empirical Methods in
Natural Language Processing (EMNLP),
pages 388?395, Barcelona, Spain.
Koehn, P., F. Och, and D. Marcu. 2003.
Statistical phrase-based translation.
The Human Language Technology
Conference (HLT), pages 48?54,
Edmonton, Alberta, Canada.
Lari, K. and S. Young. 1990. The estimation
of stochastic context-free grammars using
the inside-outside algorithm. Computer
Speech and Language, 4:35?56.
Lau, R., R. Rosenfeld, and S. Roukos.
1993. Trigger-based language models:
A maximum entropy approach. The 18th
IEEE International Conference on Acoustics,
Speech, and Signal Processing (ICASSP),
II:45?48, Minneapolis, MN.
Lauritzen, S. 1996. Graphical Models. Oxford
University Press.
Lavie, A., D. Yarowsky, K. Knight,
C. Callison-Burch, N. Habash, and
T. Mitamura. 2006. MINDS Workshops
Machine Translation Working
Group Final Report. Available at
http://www-nlpir.nist.gov/MINDS/
FINAL/MT.web.pdf.
Lin, J. and C. Dyer. 2010. Data-Intensive Text
Processing with MapReduce. Morgan and
Claypool Publishers.
Mark, K., M. Miller, and U. Grenander.
1996. Constrained stochastic language
models, In S. Levinson and L. Shepp,
editors, Image Models and Their Speech
Model Cousins, pages 131?137,
Springer-Verlag, Berlin.
McAllester, D., M. Collins, and F. Pereira.
2004. Case-factor diagrams for structured
probabilistic modeling. Proceedings of the
20th Conference on Uncertainty in Artificial
Intelligence (UAI), pages 382?391, Banff,
Canada.
Norvig, P. 2008. Statistical learning as the
ultimate agile development tool. ACM
17th Conference on Information and
Knowledge Management (CIKM)
Industry Event, Napa Valley, CA.
Och, F. 2003. Minimum error rate training
in statistical machine translation. The
41th Annual Meeting of the Association
for Computational Linguistics (ACL),
pages 160?167, Sapporo, Japan.
Och, F. 2005. Statistical machine
translation: Foundations and recent
advances. Presentation at MT-Summit.
http://www.mt-archive.info/
MTS-2005-och.pdf
Papineni, K., S. Roukos, T. Ward, and
W. Zhu. 2002. BLEU: a method for
automatic evaluation of machine
translation. The 40th Annual Meeting of the
Association for Computational Linguistics
(ACL), pages 311?318, Philadelphia, PA.
Pereira, F. 2000. Formal grammar and
information theory: Together again?
Philosophical Transactions of the Royal
Society: Mathematical, Physical and
Engineering Sciences, 358(1769):1239?1253.
Roark, B. 2001. Probabilistic top?down
parsing and language modeling.
Computational Linguistics, 27(2):249?276.
Rosenfeld, R. 1996. A maximum entropy
approach to adaptive statistical language
modeling. Computer Speech and Language,
10(2):187?228.
Rosenfeld, R. 2000a. Two decades of
statistical language modeling: Where
do we go from here? Proceedings of IEEE,
88(8):1270?1278.
Rosenfeld, R. 2000b. Incorporating
linguistic structure into statistical
language models. Philosophical
Transactions of the Royal Society:
Mathematical, Physical and Engineering
Sciences, 358(1769):1311?1324.
Rosenfeld, R., S. Chen, and X. Zhu. 2001.
Whole-sentence exponential language
models: A vehicle for linguistic-statistical
integration. Computer Speech and Language,
15(1): 55?73.
Russell, S. and P. Norvig. 2010. Artificial
Intelligence: A Modern Approach,
3rd edition. Prentice Hall, Upper
Saddle River, NJ.
Saul, L. and F. Pereira. 1997. Aggregate
and mixed-order Markov models for
statistical language processing. The
Second Conference on Empirical Methods
in Natural Language Processing (EMNLP),
81?89, Providence, RI.
Teh, Y. 2006. A hierarchical Bayesian
language model based on Pitman-Yor
processes. The 44th Annual Conference of
the Association of Computational Linguistics
(ACL), 985?992, Sydney, Australia.
Teh, Y. and M. Jordan. 2010. Hierarchical
Bayesian nonparametric models with
applications. In N. Hjort, C. Holmes,
P. Mueller, and S. Walker, editors,
Bayesian Nonparametrics: Principles
and Practice, pages 158?207,
Cambridge University Press.
Van Uytsel, D. and D. Compernolle. 2005.
Language modeling with probabilistic
left corner parsing. Computer Speech and
Language, 19(2):171?204.
Vapnik, V. 1998. Statistical Learning Theory.
Springer, Berlin.
Tan et al. A Scalable Distributed Syntactic, Semantic, and Lexical Language Model
Wallach, H. 2006. Topic modeling: Beyond
bag-of-words. The 23rd International
Conference on Machine Learning (ICML),
977?984, Pittsburgh, PA.
Wang, S., R. Greiner, and S. Wang. 2009.
Consistency and generalization bounds
for maximum entropy density estimation.
Manuscript.
Wang, W. and M. Harper. 2002. The
SuperARV language model: Investigating
the effectiveness of tightly integrating
multiple knowledge sources. The 2002
Conference on Empirical Methods in
Natural Language Processing (EMNLP),
pages 238?247, Philadelphia, PA.
Wang, S., D. Schuurmans, F. Peng, and
Y. Zhao. 2005a. Combining statistical
language models via the latent maximum
entropy principle. Machine Learning
Journal: Special Issue on Learning in Speech
and Language Technologies, 60:229?250.
Wang, S., D. Schuurmans, and Y. Zhao.
2012. The latent maximum entropy
principle. ACM Transactions on Knowledge
Discovery from Data (TKDD) to appear.
In Press.
Wang, K., C. Thrasher, E. Viegas, X. Li,
and P. Hsu. 2010. An overview of
Microsoft web N-gram corpus and
applications. Proceedings of the North
American Chapter of the Association for
Computational Linguistics - Human
Language Technologies (NAACL-HLT):
Demonstration Session, pages 45?48,
Los Angeles, CA.
Wang, S., S. Wang, L. Cheng, R. Greiner,
and D. Schuurmans. 2006. Stochastic
analysis of lexical and semantic
enhanced structural language model.
The 8th International Colloquium on
Grammatical Inference (ICGI), pages 97?111,
Tokyo, Japan.
Wang, S., S. Wang, R. Greiner, D.
Schuurmans, and L. Cheng. 2005b.
Exploiting syntactic, semantic and
lexical regularities in language modeling
via directed Markov random fields.
The 22nd International Conference on
Machine Learning (ICML), 953?960,
Bonn, Germany.
Wu, C. 1983. On the convergence properties
of the EM algorithm. Annals of Statistics,
11:95?103.
Yamada, K. and K. Knight. 2001.
A syntax-based statistical translation
model. Proceedings of the 39th Annual
Conference of the Association of
Computational Linguistics (ACL),
1067?1074, Toulouse, France.
Zangwill, W. 1969. Nonlinear Programming:
A Unified Approach. Prentice-Hall,
Upper Saddle River, NJ.
Zhang, Y. 2008. Structured Language
Models for Statistical Machine Translation.
Ph.D. dissertation, Carnegie Mellon
University, Pittsburgh, PA.
Zhang, Y., A. Hildebrand, and S. Vogel.
2006. Distributed language modeling for
N-best list re-ranking. The 2006 Conference
on Empirical Methods in Natural Language
Processing (EMNLP), 216?223, Sydney,
Australia.
Zhang, Y., S. Vogel, A. Emami, K. Papineni,
J. Sorensen, and J. Quinn. 2011. Distributed
language modeling. In Joseph Olive,
Caitlin Christianson, and John McCary,
editors, Handbook of Natural Language
Processing and Machine Translation: DARPA
Global Autonomous Language Exploitation,
Chapter 2.5.1, 252?270, Springer.