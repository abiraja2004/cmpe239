I s sues  in  Communicat ion  Game 
HASIDA K6iti 
Electrotechnical Laboratory 
1-1-4 Umezono, Tukuba, Ibaraki 305, Japan. 
hasida@etl.go.jp 
Abstract 
As interaction between autonomous 
agents, communication can be analyzed 
in game-theoretic terms. Meaning game 
is proposed to formalize the core of 
intended communication in which the 
sender sends a message and the re- 
ceiver attempts to infer its meaning in- 
tended by the sender. Basic issues in- 
volved in the game of natural language 
communication are discussed, such as 
salience, grammaticality, common sense, 
and common belief, together with some 
demonstration of the feasibility of game~ 
theoretic account of language. 
1 Introduction 
Communication is a game (interaction among au- 
tonomous agents) by definition. So it can be ana- 
lyzed in game-theoretic terms} In this paper we 
study a fundamental aspect of linguistic commu- 
nication from the point of view of game theory, 
and enumerate some basic issues involved in the 
communication games of natural language. 
Let I be the proposition that the sender S in- 
tends to communicate a semantic ontent c to the 
receiver R. Then I entails that S intends that 
R should both recognize c and believe I. This 
is the core of nonnatural meaning (Grice, 1957; 
Grice, 1969). Grice's original notion of nonnatu- 
ral meaning further entails (S's intention of) R's 
believing (when e is a proposition or a reference) 
or obeying (when it is an order or a request) c, 
but we disregard this aspect and concentrate on 
this core. 
This restricted sense of nonnatural meaning im- 
plies that communication is inherently collabora- 
tive, because both S and R want that R should 
recognize c and I.  S of course wants it, and so 
does R because it is beneficial in general to know 
what S intends to make R believe or obey. S 
might be lying or trying to mislead R, but even in 
1See Osborne and R.ubinstein (1994), ~mong oth- 
ers, for general reference on game theory. 
such a case S is still intending to communicate a 
content c by way of making R recognize this inten- 
tion. Even if R doubts S's honesty, R will try to 
know what c is, because knowing what e is would 
help R infer what the hidden intent of S may be, 
among others. For instance, when S tells R that 
it is raining, R will learn that S wants to make R 
believe that it is raining. R would do so even if R 
knew that it is not raining. Even if R were unsin- 
cere and misunderstood S's message on purpose, 2 
the nonnatural meaning is still properly conveyed, 
because otherwise the intended misunderstanding 
would be impossible. 
The present study concerns this aspect of com- 
munication, the nonnatural meaning in the re- 
stricted sense, which is a core of intended commu- 
nication. Lies, ironies, indirect speech acts, and so 
forth (Perrault, 1990; Perrault and Allen, 1980) 
all share this core. Our understanding about it 
will hence help us understand basic workings of 
natural communication systems. As an example, 
centering theory (Grosz et al, 1995) could be at- 
tributed to game-theoretic accounts, as demon- 
strated l~ter in this paper. 
2 Communicat ion Games 
Communication has been discussed in the game- 
theory literature. A signaling game consists of 
sender S's sending a message (or a signal) to re- 
ceiver R and R's doing some action in response 
to that message. Here S knows something that R 
did not know before receiving the message. This 
is formulated by assuming that S belongs to some 
type, which S knows but R does not know at first. 
Let T be the set of the types, P be the proba- 
bility distribution over T. Let M be the set of 
the messages and A be the set of R's possible 
actions. Finally, let Ux be the utility function 
for player X. Us(t,m,a) and UR(t,m,a) are real 
numbers for t E T, m 6 M and a E A. A signal- 
ing game with T = {h,t~}, M : {ml,m2} and 
A = {al, a2} is illustrated by a game tree as shown 
~If /~ is sincere and unintentionally misunder- 
stands, that is just a failure of sharing the same con- 
text with S. 
531 
in Figure 1. Here the game proceeds downwards. 
tl t2 
ml m2 ml m2 
A A A A 
~1 a2 a l  a 2 a l  a2 a l  a2 
Figure 1: A signaling game. 
The top branch is the nature's initial choice of S's 
type according to P, the middle layer is S's de- 
cision on which message to send, and finally the 
bottom layer is R's choice of her action. When R 
has just received ml (i = 1, 2), she does not know 
whether the game has been played through tl or 
t2. 
Let as  and ~n be S's and R's strategies, 3 re- 
spectively. That is, as(mlt ) is the conditional 
probability of S's sending message m provided 
that she is of type t, and an(aim ) the conditional 
probability of R's doing action a provided that 
she has received m. The combination (~s, an) 
of strategies i an equilibrium 4 of a signaling game 
when as  and a~ are the optimal responses to each 
other; that is, when az  maximizes X 's  expected 
utility 
g(t) ~s(mlt) ~n(alm) Ux( t, m, a) 
given ay ,  for both X = SAY = R and X = 
RAY=S.  
In typical applications of signMing game, T, M 
and A are not discrete sets as in the above ex- 
ample but connected subsets of real numbers, and 
S's preference for R's action is the same irrespec- 
tive of her type. In this setting, S should send a 
costly message to get a large payoff. For instance, 
in job market signaling (Spence, 1973), a worker S 
signals her competence (type) to a potential em- 
ployer R with the level of her education as the 
message, and R decides the amount of salary to 
offer to S. A competent worker will have high 
education and the employer will offer her a high 
salary. In mate selection (Zahavi, 1975), a deer 
S indicates its strength by the size of its antlers 
3Or mixed strategies, which are probability distri= 
butions over the simple strategies (actions). 
4Or complete Bayesian equilibrium, in a more pre- 
cise, technical term. 
to potential mates R. A strong deer will grow ex- 
tra large antlers to demonstrate its extra survival 
competence with this handicap. 
Cheap-talk game is another sort of communi- 
cation game. It is a special case of signaling 
game where Us and UR do not depend on the 
message; that is, composing/sending and receiv- 
ing/interpreting message are free of cost. In a 
cheap-talk game, S's preference for R's action 
must depend on her type for non-trivial commu- 
nication to obtain, because otherwise S's message 
would give no information to R about her type. 
3 Mean ing  Game 
Now we want to formulate the notion of mean- 
ing game to capture nonnatural meaning in the 
restricted sense discussed in Section 1. Let C be 
the set of semantic ontents and P the probability 
distribution over the linguistic reference to the se- 
mantic contents. That is, P(c) is the probability 
that S intends to communicate semantic ontent 
c to R. As before, M is the set of the messages. 
A meaning game addresses a turn of communi- 
cation (cs,m,c~>, which stands for a course of 
events where S, intending to communicate a se- 
mantic content Ks, sends a message m to R and R 
interprets m as meaning CR. CS = cn is a neces- 
sary condition for this turn of communication to 
be successful. It seems reasonable to assume that 
the success of communication is the only source of 
positive utility for any player. 
So a meaning ame might be a sort of signaling 
game in which S's type stands for her intending 
to communicate some semantic ontent, and R's 
action is to infer some semantic content. That 
is, both T and A could be simply regarded as C. 
Strategies ors and an are defined accordingly. 
In a simple formulation, the utility function Ux 
of player X would thus be a real-valued function 
from C ? M ? C (the set of turns). It would be 
sensible to assume that Ux(cs,m,  eR) > 0 holds 
only if es = cn. Ux reflects the grammar of the 
language (which might be private to S or R to var- 
ious degrees). The grammar evaluates the (corn= 
putational, among others) cost of using content- 
message pairs. The more costly are (cs, m I and 
(m, cR), the smaller is Uz(cs, m, cn). The notion 
of equilibria in a meaning game is naturally de- 
rived from that in a signaling game. 
If the players want something like common 
belief, 5 however, meaning games are not signaling 
games. This is because cs = cn is not a suffi- 
cient condition for the success of communication 
in that case. Ux should then depend on not just 
KS, m, and c~, but also the players' nested beliefs 
5People have common belief of proposition p when 
they all believe p, thcy all believe that they M1 believe 
p, they all believe that they all believe that they all 
believe p, and so on, ad infinitum. 
532 
about each other. We will come back to this issue 
in Section 4. 
Note also that the typical instances of meaning 
game in natural language communication is not 
like the typical applications of signaling ame such 
as mentioned before, even if meaning games are 
special sort of signaling games. That is, meaning 
games in natural anguage would normally involve 
discrete sets of semantic ontents and messages. 
Natural-language meaning ames are not cheap- 
talk games, either, because we must take into con- 
sideration the costs of content-message pairs. It 
is not just the success of communication but also 
various other factors that account for the players' 
utility. S and R hence do not just want to maxi- 
mize the probability of successful communication. 
To illustrate a meaning game and to demon- 
strate that meaning games are not cheap-talk 
games, let us consider the following discourse. 
(1) ul: Fred scolded Max. 
u2: He was angry with the man. 
The preferred interpretation of 'he' and 'the man' 
in u~ are Fred and Max, respectively, rather than 
the contrary. This preference is accounted for by 
the meaning game as shown in Figure 2. In this 
probability: /)1 > P2 
Fred Max 
'he' ~the inall' 
utility: U~ > U2 
Figure 2: A meaning game about references of 
NPs. 
game, Fred and Max are semantic ontents, and 
'he' and 'the man' are messages. 6 We have omit- 
ted the nature's election among the semantic on- 
tents. Also, the nodes with the same label are col- 
lapsed to one. S's choice goes downward and R's 
choice upward, without their initially knowing the 
other's choice. The complete bipartite connection 
between the contents and the messages means that 
either message can mean either content grammat- 
ically (without too much cost). 
-Pl and P2 are the prior probabilities of refer- 
ences to Fred and Max in u2, respectively. Since 
Fred was referred to by the subject and Max by 
the object in ul, Fred is considered more salient 
than Max in u2. This is captured by assuming 
P1 > P2. U1 and /72 are the utility (negative 
6Perhaps there are other semantic ontents and 
messages. 
cost) of using 'he' and 'the man,' respectively, r 
Utilities are basically assigned to content-message 
pairs, but sometimes it is possible to consider costs 
of messages irrespective of their contents. We as- 
sume U1 > U~. to the effect that 'he' is less com- 
plex than 'the man' both phonologically and se- 
mantically; 'he' is not only shorter than 'the man' 
but also, more importantly, less meaningful in the 
sense that it lacks the connotation of being adult 
which 'the man' has. 
There are exactly two equilibria entailing 100% 
success of communication, as depicted in Figure 3 
with their expected utilities ~1 and ?2 apart from 
the utility of success of communication, s P, > P2 
Fred Max 
qle' 'the man' 
Fred Max X 
'he' 'the man' 
& = P~u, + P2U2 ?2 = P1U2 + I?2U1 
Figure 3: Two equilibria of the meaning game in 
Figure 2, 
and/71 > U2 imply ~1 -~2 = (P1 -/)2)(U1 -U2) 
0. So the equilibrium in the left-hand side is 
preferable for both S and R, or Pareto superior. 
This explains the preference in (1). It is straight- 
forward to generalize this result for cases with 
more than two contents and messages: A more 
salient content should be referred to by a lighter 
message when the combinations between tile con- 
tents and the messages are complete. A general 
conjecture we might draw from this discussion is 
the following. 
(2) Natural-language meaning games are played 
at their Pareto-optimal equilibria. 
An equilibrium is Pareto optimal iff no other equi- 
librium is Pareto superior to it. 
Note that we have derived an essence of 
centering theory (Joshi and Weinstein, 1981; 
Kamcyama, 1986; Walker et al, 1994; Grosz et al, 
1995). Centering theory is to explain anaphora 
in natural language. It considers list Cf(ui )  of 
forward-looking centers, which are the semantic 
entities realize~ in ui, where ul is the i-th utte> 
ance. The forward-looking centers of utterance u
7For the sake of simplicity, here we assume that Us 
and U~ arc equal. See Section 4 for discussion. 
SCommon belief about the communicated content 
is always obtained in both cases. So the current dis- 
cussion does not depend on whether the success of 
communication is defined by cs = cR or common 
belief. 
9A linguistic expression realizes a semantic ontent 
when the former directly rcfers to the latter or the 
situation described by the former involves the latter. 
533 
are ranked in Cf(u) according to their saliences. 
In English, this ranking is determined by gram- 
matical functions of the expressions in the utter- 
ance, as below. 
subject > direct object > indirect object 
> other complements > adjuncts 
The highest-ranked element of Cf(u) is called 
the preferred center of U and written Cp(u). 
Backward-looking center Cb(ui) of utterance ui 
is the highest-ranked element of Cf(ui-1) that 
is realized in ui. Cb(u) is the entity which the 
discourse is most centrally concerned with at u. 
Centering theory stipulates the following rule. 
(3) If an element of Cf(ui_J is realized by a pro- 
noun in ui, then so is Cb(u{). 
In (1), Cb(u2) : Fred because Cf(ul) : \[Fred, 
Max\], if either 'he' or 'the man' refers to Fred. 
Then rule (3) predicts that Fred cannot be realized 
by 'the man' if Max is realized by 'he' - -  the same 
prediction that we derived above. Moreover, (3) 
itself is a special instance of our above observation 
that a more salient content should be referred to 
by a lighter message, provided that the backward- 
looking center is particularly salient. 
(3) is common in all the version of centering 
theory, but of course there are further details of 
the theory, which vary from one version to an- 
other. To derive all of them (which are right) in a 
unified manner equires further extensive study. 
4 P lay ing  the  Same Game 
We have so far assumed implicitly that S and R 
have common knowledge about (the rule of) the 
game (that is, P, Us and UR). This assump- 
tion will be justified as a practical approximation 
in typical applications of signaling games (and 
cheap-talk games). For instance, there may well 
be a body of roughly correct, stable common-sense 
knowledge about the correlation between the com- 
petence of workers and the degree of effort they 
make to have higher education, about how much 
an employer will offer to an employee with a cer- 
tain competence, and so on. 
However, common knowledge on the game 
might be harder to obtain in natural-language 
meaning ames, because the game lacks such sta- 
bility of the typical signaling games as mentioned 
above. A natural-language meaning game is al- 
most equivalent to the context of discourse, which 
changes dynamically as the discourse unfolds. 
In general, to figure out her own best strategy, 
S (R) attempts to infer R's (S's) strategy by sim- 
ulating R's (S's) inference. If S and R do not have 
common knowledge about the game, this inference 
will constitute an infinite tree. 1? For instance, 
For instance, after an utterance of 'a house,' 'the door' 
realizes the house referred to by 'a house.' 
1?This is not a game tree but a tree of belief 
embedding. 
Figure 4 depicts S's inference when she wants to 
communicate cl, where the players have common 
knowledge of C : {Cl, c2\] and M : {ml, m2} but 
not of their utility functions. The nodes labeled 
by c~ represent S when she wants to communicate 
c~, and those labeled by m~ represent R when she 
wants to interpret mi, for i = 1, 2. The inference 
by R when interpreting message mi is a similar 
tree rooted by mi. 
Although it is impossible to actually have com- 
mon knowledge in general (Halpern and Moses, 
1990), there are several motivations for the play- 
ers to pretend to have common knowledge about 
the game. First, they can avoid the computational 
complexity in dealing with infinite trees such as 
above. Second, common belief on the game is 
a simple means to obtain common belief on the 
communicated content. Third, the best payoff is 
obtained when the players have common knowl- 
edge about the game, if their utility functions are 
equal. In fact, the utility functions are proba- 
bly equal, because language use as a whole is a 
repeated game. That is, provided that commu- 
nicating agents play the role of S and R half of 
the time each, they can maximize their expected 
utility by setting their utility functions to the av- 
erage of their selfish utilities. Fortunately, this 
equalization is very stable, as long as the success 
of communication is the only source of positive 
utility for both the players. 
In communication games, common knowledge 
on which message S has sent should help the 
players converge on common belief on the game. 
That is, when the players have common knowl- 
edge that message m was sent, they may be able 
to detect errors in their embedded beliefs. In fact, 
an embedded belief turns out wrong if it implies 
~rs(mlc ) = 0 for every c in the embedded context. 
This common knowledge about m may be even 
incorporated in the meaning game. That is, it 
may affect the cost of retrieving or composing var- 
ious content-message pairs, thus biasing the scope 
of the game towards those content-message pairs 
closely associated with m. Contents and messages 
very difficult to envisage given m will be virtually 
excluded from the game. Once the game is de- 
fined, however, both players must take into con- 
sideration the entire maximal connected subgraph 
containing the content she wants to convey or the 
message she wants to interpret. 
5 Compos i te  Game 
Natural-language communication is a composite 
game in two senses. First, as mentioned in the 
previous ection, it is considered a repeated game, 
which is a sequence of smaller games. Second, 
each such smaller game is a compound game con- 
sisting of temporally overlapping meaning ames. 
These facts introduce several complications into 
the communication game. 
534 
Cl  
ml  
cl c2 
Zl~ l Tt%2 Tfg l m2 
hA AA 
Cl C2 Cl C2 C1 C2 C1 C2 
: : : : : : : : 
m2 
C1 C 2 
ml m2 ml m2 
?h AA 
C1 C2 C1 C2 CI  C2 C l  C 2 
: : : : : : : : 
Figure 4: Inference by S to communicate semantic ontent cl. 
In a repeated game, one stage may affect the 
subsequent stage. In natural-language communi- 
cation, a meaning game can influence the next 
meaning game. For instance, if a semantic on- 
tent c is referred to by a message with a low cost, 
then the probability of reference to c may increase 
as a sort of accommodation, 1~ because a reference 
by a lightweight message presupposes high prior 
probability of reference, as discussed in Section 3. 
For instance, a reference to Fred by 'he' will raise 
the salience of Fred. 
Another type of contextual effect shows up the 
following discourse. 
(4) ul: Fred scolded Max. 
u2: The man was angry with him. 
Here 'the man' and 'he' in u2 are more readily 
interpreted as Fred and Max, respectively, which 
violates (3) and hence our game-theoretic a count. 
This preference is accounted for by the prefer- 
ence for parallelism concerning the combination 
of semantic ontent and grammatical function: In 
both ul and u~. Fred is realized by the subject 
NP and Max is realized by the object NP. This is 
the same sort of preference that is addressed by 
property-sharing constraint (Kameyama, 1986). 
This effect is attributed to the utility assignment 
as shown in Figure 5. That is, the utility U1 of 
associating t he proposition angry(Fred, Max) (that 
l~ed is angry with Max) with the sentence 'The 
man was angry with him' is greater than the util- 
ity (/2 of associating angry(Max,Fred) (the propo- 
sition that Max is angry with Fred) with the same 
11Lewis (1979) discusses everal types of accommo- 
dation for conversationM score, of which the most rel- 
evant here is accommodation forcomparative salience: 
x becomes more salient han y when something is said 
which presupposes x to be more salient han y. 
probability: /91 ~ P2 
angry(Fred,Max) angry(Max,Fred) 
utility: 
'The man was angry with him' 
Figure 5: A meaning ame about propositions and 
sentences. 
sentence. This game might involve other possible 
associations such as that between angry(Max,Fred) 
and 'The man made him angry,' but as mentioned 
at the end of Section 4 contents and messages 
other than included in Figure 5 probably accom- 
pany great costs and hence may be neglected. 
In general, several meaning games are played 
possibly in parallel during linguistic communica~ 
tion using a compound expression. A turn of corn= 
munication with an utterance of 'the man was an- 
gry with him' consists of the sentence-level game 
mentioned above, the two noun phrase-level games 
- -  one concerning the subject NP (shown in Fig- 
ure 2) and the other the object NP of 'with' - -  
and so on. A strategy of each player in such 
a compound game associated with a compound 
expression is a combination of her strategies for 
all such constituent games. Each player attempts 
to maximize the expected utility over the entire 
compound game, rather than for each constituent 
game. 
Different constituent games often interact. For 
instance, if the speaker chooses to say 'the man'  
for the subject NP, then the whole sentence can- 
535 
not be 'he was angry with the man.' So a global 
solution, which maximizes the utility from the en- 
tire game, may maximize the utility from some 
constituent games but not from others. In the 
above example, the global solution, which involves 
saying 'the man was angry with him' and inter- 
preting it as angry(Fred,Ma?), maximizes the util- 
ity from the sentence-level game but not from the 
NP-level games. Incidentally, the players will gain 
greater utility if they use the combination of an- 
gry(Fred,Max) and 'he was angry with the man,' 
which is consistent with the optimal equilibrium 
of the NP-games. When 'the man was angry with 
him' is used despite the smaller default utility as- 
sociated with it, Max will probably be assigned a
greater salience than otherwise, which is again a 
sort of accommodation. 
Extralinguistic context enters sentence-level 
games and plays an important role in language 
use. For example, if it is known that Max 
never gets angry and that Fred is short-tempered, 
then both in (1) and (4) the second utterance 
will preferably be interpreted as meaning an- 
gry(Fred,Max). 
6 Conc lus ion  
Meaning game captures nonnatural meaning in 
the restricted sense which obtains in basically 
all the cases of natural-language communication. 
The factors which define a meaning ame include 
grammatical function, reference by lightweight 
message, extralinguistic nformation (these affect 
P), grammar, cost of recalling (these affect the 
utility), and so on. To have a more complete 
game-theoretic a count of natural language, we 
need a quantitative characterization f how those 
factors contribute to the game. 
We have almost restricted ourselves to refer- 
ences of nouns phrases, but the seemingly promis- 
ing targets of game-theoretic a count of natural 
language apparently include binding theory, con- 
vcrsational implicature (Parikh, 1992), and so on. 
Since our account is very general in nature, how- 
ever, it should apply to language as a whole. For 
instance, the notion of grammaticality may well 
be attributed to the computational difficulty in 
convergence to a common game-theoretic equilib- 
rium. Also, abductive inference involved in lan- 
guage understanding (Hobbs et al, 1993) (hence 
in language production, too, fl'om the game- 
theoretic, reciprocal viewpoint) is closely related 
with our theory. That is, the particular usefulness 
of abduction in natural anguage communication 
could be ascribed to the fact that language use in 
essence is a collaborative interaction such as dis- 
cussed so far. 
Re ferences  
H. Paul Grice. 1957. Meaning. Philosophical Re- 
view, 66:377-388. 
H. Paul Grice. 1969. Utterer's meaning and in- 
tentions. Philosophical Review, 68(2):147= 177. 
Barbara J. Grosz, Aravind K. Joshi, and Scott 
Weinstein. 1995. Centering: A framework 
for modeling the local coherence of discource. 
Computational Linguistics, 21(2):203-225. 
Joseph Y. Halpern and Yoram Moses. 1990. 
Knowledge and common-knowledge in a dis- 
tributed environment. Journal of the ACM, 
37(3):549-587. 
Jerry R. Hobbs, Mark E. Stickel, Douglous E. Ap- 
pelt, and Paul Martin. 1993. Interpretation as 
abduction. Artificial Intelligence, 63(1-2):69- 
142. 
Aravind K. Joshi and Scott Weinstein. 1981. 
Control of inference: Role of some aspects of 
discourse structure - -  centering. In Proceed- 
ings of the 7th International Joint Conference 
on Artificial Intelligence, pages 385-387. 
Megumi Kameyama. 1986. A property-sharing 
constraint in centering. In Proceedings of the 
2~th Annual Meeting of ACL, pages 200-206. 
David Lewis. 1979. Scorekeeping in a language 
game. Journal of Philosophical Logic, 8:339 
359. 
Martin J. Osborne and Ariel Rubinstein. 1994. 
A Course in Game Theory. The MIT Press, 
Cambridge, Massachusetts. 
Prashant Parikh. 1992. A game-theoretic a count 
of implicature. In Proc. of the Fourth Confer- 
ence on Theoretical Aspects of Reasoning About 
Knowledge, pages 85-94, Monterey, CA. 
C. Raymond Perrault and James F. Allen. 1980. 
A plan-based analysis of indirect speech act. 
American Journal of Computational Linguis- 
tics, 6(3-4):167-182. 
C. Raymond Perrault. 1990. An application of 
default logic to speech act theory. In Philip R. 
Cohen, J. Morgan, and Martha E. Pollack, edi- 
tors, Intentions in COMMUNICATION, pages 
161-185. MIT Press. 
A. Michael Spence. 1973. Job market signaling. 
Quartery Journal of Economics, 87:355-74. 
Marilyn Walker, Masayo Iida, and Sharon Cote. 
1994. Japanese discourse and the pro- 
cess of centering. Computational Linguistics, 
20(2):193-232. 
A. Zahavi. 1975. Mate selection - -  a selection 
for a handicap. Journal of Theoretical Biology, 
53:205-214. 
536 
