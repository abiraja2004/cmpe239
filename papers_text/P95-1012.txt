Compil ing HPSG type constraints into definite clause programs 
Th i lo  G~tz  and Wal t  Detmar  Meurers*  
SFB 340, Universit?t Tf ibingcn 
Kleine Wilhelmstrat~e 113 
72074 Tfibingen 
Germany 
~tg, dm}?sf s. nphil, uni-tuebingen, de 
Abst rac t  
We present a new approach to HPSG pro- 
cessing: compiling HPSG grammars ex- 
pressed as type constraints into definite 
clause programs. This provides a clear 
and computationally useful correspondence 
between linguistic theories and their im- 
plementation. The compiler performs off- 
line constraint inheritance and code opti- 
mization. As a result, we are able to effi- 
ciently process with HPSG grammars with- 
out haviog to hand-translate them into def- 
inite clause or phrase structure based sys- 
tems. 
1 In t roduct ion  
The HPSG architecture as defined in (Pollard and 
Sag, 1994) (henceforth HPSGII) is being used by 
an increasing number of linguists, since the formally 
well-defined framework allows for a rigid and ex- 
plicit formalization of a linguistic theory. At the 
same time, the feature logics which provide the for- 
mal foundation of HPSGII have been used as basis 
for several NLP systems, such as ALE (Carpenter, 
1993), CUF (DSrre and Dorna, 1993), Troll (Gerde- 
mann and King, 1993) or TFS (Emele and Zajac, 
1990). These systems are - at least partly - intended 
as computational environments for the implementa- 
tion of HPSG grammars. 
HPSG linguists use the description language of 
the logic to express their theories in the form of im- 
plicative constraints. On the other hand, most of the 
computational setups only allow feature descriptions 
as extra constraints with a phrase structure or defi- 
nite clause based language. 1 From a computational 
point of view the latter setup has several advantages. 
It provides access to the pool of work done in the 
*The authors are listed alphabetically. 
1One exception is the TFS system. However, the pos- 
sibility to express recursive relations on the level of the 
description language l ads to serious control problems in 
that system. 
area of natural language processing, e.g., to efficient 
control strategies for the definite clause level based 
on tabelling methods like Earley deduction, or differ- 
ent parsing strategies in the phrase structure setup. 
The result is a gap between the description lan- 
guage theories of HPSG linguists and the definite 
clause or phrase structure based NLP systems pro- 
vided to implement these theories. Most grammars 
currently implemented therefore have no clear corre- 
spondence to the linguistic theories they originated 
from. To be able to use implemented grammars to 
provide feedback for a rigid and complete formal- 
ization of linguistic theories, a clear and computa- 
tionMly useful correspondence has to be established. 
This link is also needed to stimulate further devel- 
opment of the computational systems. Finally, an 
HPSGII style setup is also interesting to model from 
a software ngineering point of view, since it permits 
a modular development and testing of the grammar. 
The purpose of this paper is to provide the de- 
sired link, i.e., to show how a HPSG theory formu- 
lated as implicative constraints can be modelled on 
the level of the relational extension of the constraint 
language. More specifically, we define a compilation 
procedure which translates the type constraints of 
the linguistic theory into definite clauses runnable in 
systems uch as Troll, ALE, or CUF. Thus, we per- 
form constraint inheritance and code optimization 
off-line. This results in a considerable efficiency gain 
over a direct on-line treatment oftype constraints as, 
e.g., in TFS. 
The structure of the paper is as follows: A short 
discussion of the logical setup for HPSGII provides 
the necessary formal background and terminology. 
Then the two possibilities for expressing a theory -
using the description language as in HPSGII or the 
relational level as in the computational architectures 
- are introduced. The third section provides asimple 
picture of how HPSGII theories can be modelled 
on the relational level. This simple picture is then 
refined in the fourth section, where the compilation 
procedure and its implementation is discussed. A 
small example grammar isprovided in the appendix. 
85 
2 Background 
2.1 The HPSGI I  architecture 
A HPSG grammar consists of two components: the 
declaration of the structure of the domain of linguis- 
tic objects in a signature (consisting of the type hi- 
erarchy and the appropriateness conditions) and the 
formulation of constraints on that domain. The sig- 
nature introduces the structures the linguist wants 
to talk about. The theory the linguist proposes dis- 
tinguishes between those objects in a domain which 
are part of the natural language described, and those 
which are not. 
HPSGII gives a closed world interpretation to the 
type hierarchy: every object is of exactly one min- 
imal (most specific) type. This implies that every 
object in the denotation of a non-minimal type is 
also described by at least one of its subtypes. Our 
compilation procedure will adhere to this interpre- 
tation. 
2.2 The theories of HPSGI I :  Directly 
constraining the domain 
A HPSGII theory consists of a set of descriptions 
which are interpreted as being true or false of an 
object in the domain. An object is admissible with 
respect o a certain theory iff it satisfies each of the 
descriptions in the theory and so does each of its 
substructures. The descriptions which make up the 
theory are also called constraints, since these de- 
scriptions constrain the set of objects which are ad- 
missible with respect o the theory. 
Figure 1 shows an example of a constraint, the 
head-feature principle of HPSGII. Throughout the 
paper we will be using HPSG style AVM notation 
for descriptions. 
phrase - . . *  
DTRS headed-strut 
SYNSEM\]LOC\[CAT\[HEAD 
DTRSIH AD DTRISYNSE I' OClC  l" '  
Figure 1: The Head-Feature Principle of HPSGII 
The intended interpretation f this constraint isthat 
every object which is being described by type phrase 
and by \[DTI~S h~aded-str~c\] alsohas to be described by 
the consequent, i.e. have its head value shared with 
that of its head-daughter. 
In the HPSG II architecture any description can be 
used as antecedent of an implicative constraint. As 
shown in (Meurers, 1994), a complex description can 
be expressed as a type by modifying the signature 
and/or adding theory statements. In the following, 
we therefore only deal with implicative constraints 
with type antecedents, he type definitions. 
2.3 Theories in constraint logic 
programming: expressing definite 
clause relations 
As mentioned in the introduction, in most computa- 
tional systems for the implementation f HPSG the- 
ories a grammar is expressed using a relational ex- 
tension of the description language 2 such as definite 
clauses or phrase structure rules. Figure 2 schemat- 
ically shows the embedding of HPSG II descriptions 
in the definition of a relation. 
relo (D1 . . . . .  D~) : -  tell(E1,..., Ej), 
re/n(Fl . . . .  , Fh). 
Figure 2: Defining relation relo 
The HPSG description language is only used to 
specify the arguments of the relations, in the exam- 
ple noted as D, E, and F. The organization of the 
descriptions, i.e. their use as constraints to narrow 
down the set of described objects, is taken over by 
the relational level. This way of organizing descrip- 
tions in definite clauses allows efficient processing 
techniques of logic programming to be used. 
The question we are concerned with in the follow- 
ing is how a HPSG II theory can be modelled in such 
a setup. 
3 Mode l l ing  HPSGI I  theor ies  on  a 
re la t iona l  leve l :  a s imp le  p ic ture  
There are three characteristics of HPSGII theories 
which we need to model on the relational level: one 
needs to be able to 
1. express constraints on any kind of object, 
2. use the hierarchical structure of the type hier- 
archy to organize the constraints, and 
3. check any structure for consistency with the 
theory. 
A straightforward encoding isachieved by express- 
ing each of these three aspects in a set of relations. 
Let us illustrate this idea with a simple example. As- 
sume the signature given in figure 3 and the HPSGII 
2 For the logical foundations of relational extensions of 
arbitrary constraint languages see (HShfeld and Smolka, 
1988). 
86 
style theory of figure 4. 
T /-= 
b c 
Figure 3: An example signature 
o _ 
b --. \ [Q?I  
Figure 4: An example theory in a HPSGII setup 
First, we define a relation to express the con- 
straints immediately specified for a type on the ar- 
gument of the relation: 
? a o,, ) :- T ,vp ,G) .  
? b b :- 
? c ?on , (c ) .  
For every type, the relation specifies its only argu- 
ment to bear the type information and the conse- 
quents of the type definition for that type. Note 
that the simple type assignment \[G a\] leads to a call 
to the relation atvp~ imposing all constraints for type 
a, which is defined below. 
Second, a relation is needed to capture the hier- 
archical organization of constraints: 
? ; . . . .  
? ah i ,~(~) : -  a,o,,,(\[~\]), ( bh, ,~(~);  chi,r(\[~) ). 
? bhi,r(\]~\]):-  bco,, ,(~). 
Each hierarchy relation of a type references the con- 
straint relation and makes ure that the constraints 
below one of the subtypes are obeyed. 
Finally, a relation is defined to collect all con- 
straints on a type: 
? atyp~(~) :- This,-( ri-1 a ). 
? bt,p~(E~ \]) :- Thief( \[-i~b ). 
* ctvpe(\[~\]) :- Thier( r-~c ). 
aA disjunction of the immediate subtypes of T. 
Compared to the hierarchy relation of a type which 
collects all constraints on the type and its subtypes, 
the last kind of relation additionally references those 
constraints which are inherited from a supertype. 
Thus, this is the relation that needs to be queried to 
check for grammaticality. 
Even though the simple picture with its tripartite 
definition for each type yields perspicuous code, it 
falls short in several respects. The last two kinds 
of relations (reltype and relhier) just perform inheri- 
tance of constraints. Doing this at run-time is slow, 
and additionally there are problems with multiple 
inheritance. 
A further problem of the encoding is that the value 
of an appropriate feature which is not mentioned 
in any type definition may nonetheless be implicitly 
constrained, since the type of its value is constrained. 
Consider for example the standard HPSG encoding 
of list structures. This usually involves a type he_list 
with appropriate f atures HD and TL, where under 
HD we encode an element of the list, and under TL 
the tail of the list. Normally, there will be no extra 
constraints on ne_list. But in our setup we clearly 
need a definite clause 
he_list 
ne_listcon,( HD ) :- Ttvp~(\[~), listtyp?(~\]). 
.TL 
since the value of the feature HD may be of a type 
which is constrained by the grammar. Consequently, 
since he_list is a subtype of list, the value of TL needs 
to be constrained as well. 
4 Compi l ing  HPSG type  const ra in ts  
in to  de f in i te  c lauses  
After this intuitive introduction to the problem, we 
will now show how to automatically generate definite 
clause programs from a set of type definitions, in 
a way that avoids the problems mentioned for the 
simple picture. 
4.1 The a lgor i thm 
Before we can look at the actual compilation proce- 
dure, we need some terminology. 
Definit ion (type interaction) 
Two types interact if they have a common subtype. 
Note that every type interacts with itself. 
Definit ion (defined type) 
A defined type is a type that occurs as antecedent of 
an implicational constraint in the grammar. 
Definit ion (constrained type) 
A constrained type is a type that interacts with a 
defined type. 
87 
Whenever we encounter a structure of a constrained 
type, we need to check that the structure conforms 
to the constraint on that type. As mentioned in 
section 2.1, due to the closed world interpretation of
type hierarchies, we know that every object in the 
denotation of a non-minimal type t also has to obey 
the constraints on one of the minimal subtypes of t. 
Thus, if a type t has a subtype t' in common with 
a defined type d, then t ~ is a constrained type (by 
virtue of being a subtype of d) and t is a constrained 
type (because it subsumes t'). 
Def in i t ion  (hiding type) 
The set of hiding types is the smallest set s.t. if t is 
not  a constrained type and subsumes a type to that 
has a feature f appropriate s.t. approp(to,f) is a con- 
strained type or a hiding type, then t is a hiding type. 
The type ne_list that we saw above is a hiding type. 
Def in i t ion  (hiding feature) 
I f  t is a constrained or hiding type, then f is a hiding 
feature on t iff approp(t,f) is a constrained or hiding 
type. 
Def in i t ion  (simple type) 
A simple type is a type that is neither a constrained 
nor  a hiding type. 
When we see a structure of a simple type, we don't 
need to apply any constraints, neither on the top 
node nor on any substructure. 
Partitioning the types in this manner helps us 
to construct definite clause programs for type con- 
straint grammars. For each type, we compute a 
unary relation that we just give the same name as 
the type. Since we assume a closed world interpre- 
tation of the type hierarchy, we really only need to 
compute proper definitions for minimal types. The 
body of a definition for a non-minimal type is just 
a disjunction of the relations defining the minimal 
subtypes of the non-minimal type. 
When we want to compute the defining clause for 
a minimal type, we first of all check what sort of 
type it is. For each simple type, we just introduce 
a unit clause whose argument is just the type. For 
a constrained type t, first of all we have to perform 
constraint inheritance from all types that subsume t. 
Then we transform that constraint to some internal 
representation, usually a feature structure (FS). We 
now have a schematic defining clause of the form 
t(FS) :- ?. 
Next, we compute the missing right-hand side 
(RHS) with the following algorithm. 
1. Compute HF, the set of hiding features on the 
type of the current node, then insert these fea- 
tures with appropriate types in the structure 
P':<.} 
/ARG2 list I e_list /HD T / 
/ARG3 iist~ I.TL ,i,tJ 
LGOALS list.\] 
(FS) if they're not already there. For each node 
under a feature in HF, apply step 2. 
2. Let t be the type on the current node and X its 
tag (a variable). 
(a) If t is a constrained type, enter t(X) into 
RHS (if it's not already there). 
(b) Elseif t is a hiding type, then check if its 
hiding features and the hiding features of 
all its hiding subtypes are identical. If they 
are identical, then proceed as in step 1. If 
not, enter t(X) into RHS. 
(c) Else (t is a simple type) do nothing at all. 
For hiding types, we do exactly the same thing, ex- 
cept that we don't have any structure to begin with. 
But this is no problem, since the hiding features get 
introduced anyway. 
4.2 An  example  
A formal proof of correctness of this compiler is given 
in (GStz, 1995) - here, we will try to show by ex- 
ample how it works. Our example is an encodin~ 
of a definite relation in a type constraint setup2 
append_c appends an arbitrary list onto a list of con- 
stants. 
T 
constant 
Figure 5: The signature for the append_c example 
We will stick to an AVM style notation for our ex- 
amples, the actual program uses a standard feature 
term syntax. List are abbreviated in the standard 
HPSG manner, using angled brackets. 
append_c -* 
\[A O1 
ARG 2 
ARG3 
GOALS e_listJ 
"ARG 1 
ARG2 
ARG3 
V 
GOALS 
15q oo.,,..,i 5q ? 
\[\] 
IE\]I\[EI 
ARG 1 \[~\] 
ARG2 
ARG3 
Figure 6: A constraint on append_c 
Note that the set of constrained types is {append_c, 
4This sort of encoding was pioneered by (Ait-Kaci, 
1984), but see also (King, 1989) and (Carpenter, 1992). 
88  
T} and the set of hiding types is {list, ne_list}. Con- 
verting the first disjunct of append_c into a feature 
structure to start our compilation, we get something 
like 
'append_c I ARG1 v--a\[\]e-list\] 
append_c( ARG2 121 list 
ARG3 
.GOALS e_list.I 
: - ? .  
Since the values of the features of append_c are of 
type list, a hiding type, those features are hiding 
features and need to be considered. Yet looking at 
node \[-i7, the algorithm finds e_list, a simple type, 
and does nothing. Similarly with node \[~\]. On node 
~\] ,  we find the hiding type list. Its one hiding sub- 
type, ne_list, has different hiding features (list has no 
features appropriate at all). Therefore, we have to 
enter this node into the RHS. Since the same node 
appears under both ARG1 and ARG2, we're done 
and have 
\[ 1 append_c ARG1 e_list 
append_c( I ARG3ARG2 ~__lisq):-\]Jst(~). 
LGOALS e_list j 
which is exactly what we want. It means that a 
structure of type append_c is well-formed if it unifies 
with the argument of the head of the above clause 
and whatever is under ARG2 (and AR.G3) is a well- 
formed list. Now for the recursive disjunct, we start 
out with 
append_el 
"append_c 
rne_list 
ARGI E\] l \ [ \ ]  constant 
\ [ \ ]  .st 
ARG2 \[~\] list 
rne-list t\] 
he.list -append_c \] 
GOALS\[\] HD ~\] ARG2 L.~J| 
\[\] 4,: mJ 
: - ? .  
Node E \ ]  bears a hiding type with no subtypes. 
Therefore we don't enter that node in the RHS, but 
proceed to look at its features. Node \ [ \ ]  bears a sim- 
ple type and we do nothing, but node \ [ \ ]  is again a 
list and needs to be entered into the RHS. Similarly 
with nodes \ [ \ ]  and \['~. append_c on node \ [ \ ]  is a con- 
strained type and \ [ \ ]  also has to go onto the RHS. 
The final result then is 
append_c( 
"append_c 
me-list constant\] 
ARG2 \[~\] list 
me-list t\] 
rne_list 
/ rapP:-d_c "1 
/ IARG1 r31 |
._ 
l ist(~), list(\[~\]), list(\[~\]), append_c(~\]). 
This is almost what we want, but not quite. Con- 
sider node ~\] .  Clearly it needs to be checked, but 
what about nodes ~\] ,  \ [ \ ]  and E\]?  They are all em- 
bedded under node \ [ \ ]  which is being checked any- 
way, so listing them here in the RHS is entirely re- 
dundant. In general, if a node is listed in the RHS, 
then no other node below it needs to be there as 
well. Thus, our result should really be 
append_c( 
"append_c 
rne-list constant\] 
ARG2 r~1 list 
me-list t\] 
rne-list 
I r append-e 1 
IHD GOALS I I 
| LAFtG3 16~J 
LTL e_list 
:_ 
appendoc(\[~\]). 
Our implementation f the compiler does in fact 
perform this pruning as an integrated part of the 
compilation, not as an additional step. 
It should be pointed out that this compilation re- 
sult is quite a dramatic improvement on more naive 
on-line approaches to ttPSG processing. By reason- 
ing with the different kinds of types, we can dras- 
tically reduce the number of goals that need to be 
checked on-line. Another way of viewing this would 
be to see the actual compilation step as being much 
simpler (just check every possible feature) and to 
subsequently apply program transformation tech- 
niques (some sophisticated form of partial evalua- 
tion). We believe that this view would not simplify 
the overall picture, however. 
89 
4.3 Implementat ion  a d Extensions 
The compiler as described in the last section has 
been fully implemented under Quintus Prolog. Our 
interpreter at the moment is a simple left to right 
backtracking interpreter. The only extension is to 
keep a list of all the nodes that have already been 
visited to keep the same computation from being 
repeated. This is necessary since although we avoid 
redundancies a shown in the last example, there are 
still cases where the same node gets checked more 
than once. 
This simple extension also allows us to process 
cyclic queries. The following query is allowed by our 
system. 
me_list ~\] 
Query> \[~\] [THD 
Figure 7: A permitted cyclic query 
An interpreter without the above-mentioned exten- 
sion would not terminate on this query. 
The computationally oriented reader will now 
wonder how we expect o deal with non-termination 
anyway. At the moment, we allow the user to specify 
minimal control information. 
? The user can specify an ordering on type expan- 
sion. E.g., if the type hierarchy contains a type 
sign with subtypes word and phrase, the user 
may specify that word should always be tried 
before phrase. 
? The user can specify an ordering on feature x- 
pansion. E.g., HD should always be expanded 
before TL in a given structure. 
Since this information is local to any given structure, 
the interpreter does not need to know about it, and 
the control information is interpreted as compiler 
directives. 
5 Conc lus ion  and  Out look  
We have presented a compiler that can encode 
HPSG type definitions as a definite clause program. 
This for the first time offers the possibility to ex- 
press linguistic theories the way they are formulated 
by linguists in a number of already existing compu- 
tational systems. 
The compiler finds out exactly which nodes of a 
structure have to be examined and which don't. In 
doing this off-line, we minimize the need for on-line 
inferences. The same is true for the control informa- 
tion, which is also dealt with off-line. This is not to 
say that the interpreter wouldn't profit by a more 
sophisticated selection function or tabulation tech- 
niques (see, e.g., (DSrre, 1993)). We plan to apply 
Earley deduction to our scheme in the near future 
and experiment with program transformation tech- 
niques and bottom-up interpretation. 
Our work addresses a similar problem as Carpen- 
ter's work on resolved feature structures (Carpen- 
ter, 1992, ch. 15). However, there are two major 
differences, both deriving form the fact that Car- 
penter uses an open world interpretation. Firstly, 
our approach can be extended to handle arbitrar- 
ily complex antecedents of implications (i.e., arbi- 
trary negation), which is not possible using an open 
world approach. Secondly, solutions in our approach 
have the so-called subsumption monotonicity or per- 
sistence property. That means that any structure 
subsumed by a solution is also a solution (as in Pro- 
log, for example). Quite the opposite is the case in 
Carpenter's approach, where solutions are not guar- 
anteed to have more specific extensions. This is un- 
satisfactory at least from an HPSG point of view, 
since HPSG feature structures are supposed to be 
maximally specific. 
Acknowledgments  
The research reported here was carried out in the 
context of SFB 340, project B4, funded by the 
Deutsche Forschungsgemeinschaft. We would like to 
thank Dale Gerdemann, Paul John King and two 
anonymous referees for helpful discussion and com- 
ments. 
References  
Hassan Ait-Kaci. 1984. A lattice theoretic approach 
to computation based on a calculus of partially or- 
dered type structures. Ph.D. thesis, University of 
Pennsylvania. 
Bob Carpenter. 1992. The logic of typed feature 
s~ructures, volume 32 of Cambridge Tracts in The- 
oretical Computer Science. Cambridge University 
Press. 
Bob Carpenter. 1993.  ALE - the attribute 
logic engine, user's guide, May. Laboratory for 
Computational Linguistics, Philosophy Depart- 
ment, Carnegie Mellon University, Pittsburgh, PA 
15213. 
Jochen DSrre and Michael Dorna. 1993. CUF - 
a formalism for linguistic knowledge representa- 
tion. In Jochen DSrre, editor, Computational as- 
pects of constraint based linguistic descriptions I,
pages 1-22. DYANA-2 Deliverable R1.2.A, Uni- 
versit~t Stuttgart, August. 
Jochen DSrre. 1993. Generalizing earley deduction 
for constraint-based grammars. In Jochen DSrre, 
editor, Computational aspects of constraint based 
linguistic descriptions I, pages 25-41. DYANA- 
2 Deliverable R1.2.A, Universit~t Stuttgart, Au- 
gust. 
Martin C. Emele and R~mi Zajac. 1990. Typed 
unification grammars. In Proceedings of the 13 'h 
90 
International Conference on Computational Lin- 
guistics. 
Dale Gerdemann and Paul John King. 1993. 
Typed feature structures for expressing and com- 
putationally implementing feature cooccurrence 
restrictions. In Proceedings of 4. Fachtagung 
der Sektion Computerlinguistik der Deutschen 
Gesellschafl ffr Sprachwissenschaft, pages 33-39. 
Thilo GStz. 1995. Compiling HPSG constraint 
grammars into logic programs. In Proceedings of 
the joint ELSNET/COMPULOG-NET/EAGLES 
workshop on computational logic for natural lan- 
guage processing. 
M. HShfeld and Gert Smolka. 1988. Definite rela- 
tions over constraint languages. LILOG technical 
report, number 53, IBM Deutschland GmbH. 
Paul John King. 1989. A logical formalism for head. 
driven phrase structure grammar. Ph.D. thesis, 
University of Manchester. 
W. Detmar Meurers. 1994. On implementing 
an HPSG theory - Aspects of the logical archi- 
tecture, the formalization, and the implementa- 
tion of head-driven phrase structure grammars. 
In: Erhard W. Hinrichs, W. Detmar Meurers, 
and Tsuneko Nakazawa: Partial- VP and Split-NP 
Topicalization in German - An HPSG Analysis 
and its Implementation. Arbeitspapiere des SFB 
340 Nr. 58, Universit?t Tfibingen. 
Carl Pollard and Ivan A. Sag. 1994. Head-Driven 
Phrase Structure Grammar. Chicago: University 
of Chicago Press and Stanford: CSLI Publica- 
tions. 
Append ix  A. A small grammar 
The following small example grammar, together 
with a definition of an append type, generates sen- 
tences like "John thinks cats run". It is a modified 
version of an example from (Carpenter, 1992). 
phrase --, 
A 
"CAT s 
DTRI IAGR 
LPHON 
I AGR 
, LPHO N 
A RG I 
GOALS ( I ARG2 
\[ARG3 
"CAT vp 
AGR \ [~ 
r?AT 
V DTRI IAGR 
LPHON 
T 
.DTR2 \[PHON 
\] 
word ---} 
V 
V 
V 
V 
"CAT 
PHON 
AGR 
ICAT 
:PHON 
AGR 
rCAT 
~PHON 
AGR 
'CAT 
PHON 
~GR 
'CAT 
PHON 
AGR 
p \] ( john V raary } 
singular 
( cats V dogs ) 
plural 
up 
( runs V jumps  ) singular 
( run v jump ) 
plural 
"" \] 
( knows v thinks ) 
singular 
Here's an example query. Note that the feature 
GOALS has been suppressed in the result. 
Query> \[PHON { john, runs )\] 
Result> 
"phrase 
CAT 
PHON 
DTR1 
DTR2 
\ [~ j ob .  I ~ \ ]  ( ru .s  ) ) 
"word t CAT np 
AGR {~ingular 
PHON ) 
"word 
AGR 
PHON 
For the next query we get exactly the same result. 
query> \[DTR2 \[FHON { runs 
91 
