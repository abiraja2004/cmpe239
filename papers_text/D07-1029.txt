Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational
Natural Language Learning, pp. 277?286, Prague, June 2007. c?2007 Association for Computational Linguistics
Hierarchical System Combination for Machine Translation
Fei Huang
IBM T.J. Watson Research Center
Yorktown Heights, NY 10562
huangfe@us.ibm.com
Kishore Papineni ?
Yahoo! Research
New York, NY 10011
kpapi@yahoo-inc.com
Abstract
Given multiple translations of the same
source sentence, how to combine them to
produce a translation that is better than any
single system output? We propose a hier-
archical system combination framework for
machine translation. This framework inte-
grates multiple MT systems? output at the
word-, phrase- and sentence- levels. By
boosting common word and phrase trans-
lation pairs, pruning unused phrases, and
exploring decoding paths adopted by other
MT systems, this framework achieves bet-
ter translation quality with much less re-
decoding time. The full sentence translation
hypotheses from multiple systems are addi-
tionally selected based on N-gram language
models trained on word/word-POS mixed
stream, which further improves the transla-
tion quality. We consistently observed sig-
nificant improvements on several test sets in
multiple languages covering different gen-
res.
1 Introduction
Many machine translation (MT) frameworks have
been developed, including rule-based transfer MT,
corpus-based MT (statistical MT and example-based
MT), syntax-based MT and the hybrid, statistical
MT augmented with syntactic structures. Different
MT paradigms have their strengths and weaknesses.
?This work was done when the author was at IBM Research.
Systems adopting the same framework usually pro-
duce different translations for the same input, due
to their differences in training data, preprocessing,
alignment and decoding strategies. It is beneficial
to design a framework that combines the decoding
strategies of multiple systems as well as their out-
puts and produces translations better than any single
system output. More recently, within the GALE1
project, multiple MT systems have been developed
in each consortium, thus system combination be-
comes more important.
Traditionally, system combination has been con-
ducted in two ways: glass-box combination and
black-box combination. In the glass-box combi-
nation, each MT system provides detailed decod-
ing information, such as word and phrase transla-
tion pairs and decoding lattices. For example, in the
multi-engine machine translation system (Nirenburg
and Frederking, 1994), target language phrases from
each system and their corresponding source phrases
are recorded in a chart structure, together with their
confidence scores. A chart-walk algorithm is used
to select the best translation from the chart. To com-
bine words and phrases from multiple systems, it is
preferable that all the systems adopt similar prepro-
cessing strategies.
In the black-box combination, individual MT sys-
tems only output their top-N translation hypothe-
ses without decoding details. This is particularly
appealing when combining the translation outputs
from COTS MT systems. The final translation may
be selected by voted language models and appropri-
ate confidence rescaling schemes ((Tidhar and Kuss-
1http://www.darpa.mil/ipto/programs/gale/index.htm
277
ner, 2000) and (Nomoto, 2004)). (Mellebeek et al,
2006) decomposes source sentences into meaning-
ful constituents, translates them with component MT
systems, then selects the best segment translation
and combine them based on majority voting, lan-
guage models and confidence scores.
(Jayaraman and Lavie, 2005) proposed another
black-box system combination strategy. Given sin-
gle top-one translation outputs from multiple MT
systems, their approach reconstructs a phrase lat-
tice by aligning words from different MT hypothe-
ses. The alignment is based on the surface form
of individual words, their stems (after morphology
analysis) and part-of-speech (POS) tags. Aligned
words are connected via edges. The algorithm finds
the best alignment that minimizes the number of
crossing edges. Finally the system generates a new
translation by searching the lattice based on align-
ment information, each system?s confidence scores
and a language model score. (Matusov et al, 2006)
and (Rosti et al, 2007) constructed a confusion net-
work from multiple MT hypotheses, and a consen-
sus translation is selected by redecoding the lattice
with arc costs and confidence scores.
In this paper, we introduce our hierarchical sys-
tem combination strategy. This approach allows
combination on word, phrase and sentence levels.
Similar to glass-box combination, each MT sys-
tem provides detailed information about the trans-
lation process, such as which source word(s) gener-
ates which target word(s) in what order. Such in-
formation can be combined with existing word and
phrase translation tables, and the augmented phrase
table will be significantly pruned according to reli-
able MT hypotheses. We select an MT system to re-
translate the test sentences with the refined models,
and encourage search along decoding paths adopted
by other MT systems. Thanks to the refined trans-
lation models, this approach produces better transla-
tions with a much shorter re-decoding time. As in
the black-box combination, we select full sentence
translation hypotheses from multiple system outputs
based on n-gram language models. This hierarchical
system combination strategy avoids problems like
translation output alignment and confidence score
normalization. It seamlessly integrates detailed de-
coding information and translation hypotheses from
multiple MT engines, and produces better transla-
tions in an efficient manner. Empirical studies in a
later section show that this algorithm improves MT
quality by 2.4 BLEU point over the best baseline de-
coder, with a 1.4 TER reduction. We also observed
consistent improvements on several evaluation test
sets in multiple languages covering different genres
by combining several state-of-the-art MT systems.
The rest of the paper is organized as follows: In
section 2, we briefly introduce several baseline MT
systems whose outputs are used in the system com-
bination. In section 3, we present the proposed hi-
erarchical system combination framework. We will
describe word and phrase combination and pruning,
decoding path imitation and sentence translation se-
lection. We show our experimental results in section
4 and conclusions in section 5.
2 Baseline MT System Overview
In our experiments, we take the translation out-
puts from multiple MT systems. These include
phrase-based statistical MT systems (Al-Onaizan
and Papineni, 2006) (Block) and (Hewavitharana et
al., 2005) (CMU SMT) , a direct translation model
(DTM) system (Ittycheriah and Roukos, 2007) and a
hierarchical phrased-based MT system (Hiero) (Chi-
ang, 2005). Different translation frameworks are
adopted by different decoders: the DTM decoder
combines different features (source words, mor-
phemes and POS tags, target words and POS tags)
in a maximum entropy framework. These features
are integrated with a phrase translation table for
flexible distortion model and word selection. The
CMU SMT decoder extracts testset-specific bilin-
gual phrases on the fly with PESA algorithm. The
Hiero system extracts context-free grammar rules
for long range constituent reordering.
We select the IBM block decoder to re-translate
the test set for glass-box system combination. This
system is a multi-stack, multi-beam search decoder.
Given a source sentence, the decoder tries to find
the translation hypothesis with the minimum trans-
lation cost. The overall cost is the log-linear combi-
nation of different feature functions, such as trans-
lation model cost, language model cost, distortion
cost and sentence length cost. The translation cost
278
between a phrase translation pair (f, e) is defined as
TM(e, f) =
?
i
?i?(i) (1)
where feature cost functions ?(i) includes:
? log p(f |e), a target-to-source word translation
cost, calculated based on unnormalized IBM model1
cost (Brown et al, 1994);
p(f |e) =
?
j
?
i
t(fj|ei) (2)
where t(fj|ei) is the word translation probabilities,
estimated based on word alignment frequencies over
all the training data. i and j are word positions in
target and source phrases.
? log p(e|f), a source-to-target word translation
cost, calculated similar to ? log p(f |e);
S(e, f), a phrase translation cost estimated ac-
cording to their relative alignment frequency in the
bilingual training data,
S(e, f) = ? log P (e|f) = ? log C(f, e)C(f) . (3)
??s in Equation 1 are the weights of different fea-
ture functions, learned to maximize development set
BLEU scores using a method similar to (Och, 2003).
The SMT system is trained with testset-specific
training data. This is not cheating. Given a test set,
from a large bilingual corpora we select parallel sen-
tence pairs covering n-grams from source sentences.
Phrase translation pairs are extracted from the sub-
sampled alignments. This not only reduces the size
of the phrase table, but also improves topic relevancy
of the extracted phrase pairs. As a results, it im-
proves both the efficiency and the performance of
machine translation.
3 Hierarchical System Combination
Framework
The overall system combination framework is
shown in Figure 1. The source text is translated
by multiple baseline MT systems. Each system pro-
duces both top-one translation hypothesis as well as
phrase pairs and decoding path during translation.
The information is shared through a common XML
file format, as shown in Figure 2. It demonstrates
how a source sentence is segmented into a sequence
of phrases, the order and translation of each source
phrase as well as the translation scores, and a vector
of feature scores for the whole test sentence. Such
XML files are generated by all the systems when
they translate the source test set.
We collect phrase translation pairs from each de-
coder?s output. Within each phrase pair, we iden-
tify word alignment and estimate word translation
probabilities. We combine the testset-specific word
translation model with a general model. We aug-
ment the baseline phrase table with phrase trans-
lation pairs extracted from system outputs, then
prune the table with translation hypotheses. We re-
translate the source text using the block decoder with
updated word and phrase translation models. Ad-
ditionally, to take advantage of flexible reordering
strategies of other decoders, we develop a word or-
der cost function to reinforce search along decod-
ing paths adopted by other decoders. With the re-
fined translation models and focused search space,
the block decoder efficiently produces a better trans-
lation output. Finally, the sentence hypothesis se-
lection module selects the best translation from each
systems? top-one outputs based on language model
scores. Note that the hypothesis selection module
does not require detailed decoding information, thus
can take in any MT systems? outputs.
3.1 Word Translation Combination
The baseline word translation model is too general
for the given test set. Our goal is to construct a
testset-specific word translation model, combine it
with the general model to boost consensus word
translations. Bilingual phrase translation pairs are
read from each system-generated XML file. Word
alignments are identified within a phrase pair based
on IBM Model-1 probabilities. As the phrase pairs
are typically short, word alignments are quite accu-
rate. We collect word alignment counts from the
whole test set translation, and estimate both source-
to-target and target-to-source word translation prob-
abilities. We combine such testset-specific transla-
tion model with the general model.
t??(e|f) = ?t?(e|f) + (1 ? ?)t(e|f); (4)
where t?(e|f) is the testset-specific source-to-target
word translation probability, and t(e|f) is the prob-
279
<tr engine="XXX"> 
<s id="0"> <w>  </w><w> 	
 </w><w>  </w><w> 	 </w><w>  
</w><w>  </w><w>  </w><w>  </w><w>   </w><w> ! " </w><w> #$% </w></s> 
<hyp r="0" c="2.15357"> 
 <t>  
<p al="0-0" cost="0.0603734"> erdogan </p>  
<p al="1-1" cost="0.367276"> emphasized </p>  
<p al="2-2" cost="0.128066"> that </p>  
<p al="3-3" cost="0.0179338"> turkey </p>  
<p al="4-5" cost="0.379862"> would reject any </p>  
<p al="6-6" cost="0.221536"> pressure </p>  
<p al="7-7" cost="0.228264"> to urge them </p>  
<p al="8-8" cost="0.132242"> to</p>  
<p al="9-9" cost="0.113983"> recognize </p>  
<p al="10-10" cost="0.133359"> Cyprus </p>  
</t> 
<sco> 
19.6796 8.40107 0.333514 0.00568583 0.223554 0 0.352681 0.01 -0.616 0.009 0.182052     
</sco> 
</hyp> 
</tr> 
 
Figure 2: Sample XML file format. This includes a source sentence (segmented as a sequence of source
phrases), their translations as well as a vector of feature scores (language model scores, translation model
scores, distortion model scores and a sentence length score).
ability from general model. ? is the linear combi-
nation weight, and is set according to the confidence
on the quality of system outputs. In our experiments,
we set ? to be 0.8. We combine both source-to-
target and target-to-source word translation models,
and update the word translation costs, ? log p(e|f)
and ? log p(f |e), accordingly.
3.2 Phrase Translation Combination and
Pruning
Phrase translation pairs can be combined in two dif-
ferent ways. We may collect and merge testset-
specific phrase translation tables from each system,
if they are available. Essentially, this is similar to
combining the training data of multiple MT systems.
The new phrase translation probability is calculated
according to the updated phrase alignment frequen-
cies:
P ?(e|f) = Cb(f, e) +
??mCm(f, e)
Cb(f) +
??mCm(f)
, (5)
where Cb is the phrase pair count from the baseline
block decoder, and Cm is the count from other MT
systems. ?m is a system-specific linear combination
weight. If not all the phrase tables are available, we
collect phrase translation pairs from system outputs,
and merge them with Cb. In such case, we may ad-
just ? to balance the small counts from system out-
puts and large counts from Cb.
The corresponding phrase translation cost is up-
dated as
S?(e, f) = ? log P ?(e|f). (6)
Another phrase combination strategy works on
the sentence level. This strategy relies on the con-
sensus of different MT systems when translating the
same source sentence. It collects phrase translation
pairs used by different MT systems to translate the
same sentence. Similarly, it boosts common phrase
pairs that are selected by multiple decoders.
S??(e, f) = ?|C(f, e)| ? S
?(e, f), (7)
where ? is a boosting factor, 0 < ? ? 1 . |C(f, e)|
is the number of systems that use phrase pair (f, e)
to translate the input sentence. A phrase translation
pair selected by multiple systems is more likely a
good translation, thus costs less.
The combined phrase table contains multiple
translations for each source phrase. Many of them
280
are unlikely translations given the context. These
phrase pairs produce low-quality partial hypothe-
ses during hypothesis expansion, incur unnecessary
model cost calculation and larger search space, and
reduce the translation efficiency. More importantly,
the translation probabilities of correct phrase pairs
are reduced as some probability mass is distributed
among incorrect phrase pairs. As a result, good
phrase pairs may not be selected in the final trans-
lation.
Oracle experiments show that if we prune the
phrase table and only keep phrases that appear in
the reference translations, we can improve the trans-
lation quality by 10 BLEU points. This shows the
potential gain by appropriate phrase pruning. We
developed a phrase pruning technique based on self-
training. This approach reinforces phrase transla-
tions learned from MT system output. Assuming
we have reasonable first-pass translation outputs, we
only keep phrase pairs whose target phrase is cov-
ered by existing system translations. These phrase
pairs include those selected in the final translations,
as well as their combinations or sub-phrases. As
a result, the size of the phrase table is reduced by
80-90%, and the re-decoding time is reduced by
80%. Because correct phrase translations are as-
signed higher probabilities, it generates better trans-
lations with higher BLEU scores.
3.3 Decoding Path Imitation
Because of different reordering models, words in the
source sentence can be translated in different orders.
The block decoder has local reordering capability
that allows source words within a given window to
jump forward or backward with a certain cost. The
DTM decoder takes similar reordering strategy, with
some variants like dynamic window width depend-
ing on the POS tag of the current source word. The
Hiero system allows for long range constituent re-
ordering based on context-free grammar rules. To
combine different reordering strategies from vari-
ous decoders, we developed a reordering cost func-
tion that encourages search along decoding paths
adopted by other decoders.
From each system?s XML file, we identify the or-
der of translating source words based on word align-
ment information. For example, given the following
hypothesis path,
<p al=?0-1?> izzat ibrahim </p> <p al=?2-
2?> receives </p> <p al=?3-4?> an economic
official </p> <p al=?5-6?> in </p> <p al=?7-
7?> baghdad </p>
We find the source phrase containing words [0,1]
is first translated into a target phrase ?izzat ibrahim?,
which is followed by the translation from source
word 2 to a single target word ?receives?, etc.. We
identify the word alignment within the phrase trans-
lation pairs based on IBM model-1 scores. As a re-
sult, we get the following source word translation
sequence from the above hypothesis (note: source
word 5 is translated as NULL):
0 < 1 < 2 < 4 < 3 < 6 < 7
Such decoding sequence determines the transla-
tion order between any source word pairs, e.g., word
4 should be translated before word 3, 6 and 7. We
collect such ordered word pairs from all system out-
puts? paths. When re-translating the source sen-
tence, for each partially expanded decoding path, we
compute the ratio of word pairs that satisfy such or-
dering constraints2 .
Specifically, given a partially expanded path P =
{s1 < s2 < ? ? ? < sm}, word pair (si < sj) implies
si is translated before sj . If word pair (si < sj) is
covered by a full decoding path Q (from other sys-
tem outputs), we denote the relationship as (si <
sj) ? Q.
For any ordered word pair (si < sj) ? P , we de-
fine its matching ratio as the percentage of full de-
coding paths that cover it:
R(si < sj) =
|Q|
N , {Q|(si < sj) ? Q} (8)
where N is the total number of full decoding paths.
We define the path matching cost function:
L(P ) = ? log
?
?(si<sj)?P R(si < sj)
?
?(si<sj)?P 1
(9)
The denominator is the total number of ordered
word pairs in path P . As a result, partial paths are
boosted if they take similar source word translation
orders as other system outputs. This cost function is
multiplied with a manually tuned model weight be-
fore integrating into the log-linear cost model frame-
work.
2We set no constraints for source words that are translated
into NULL.
281
3.4 Sentence Hypothesis Selection
The sentence hypothesis selection module only takes
the final translation outputs from individual systems,
including the output from the glass-box combina-
tion. For each input source sentence, it selects the
?optimal? system output based on certain feature
functions.
We experiment with two feature functions. One
is a typical 5-gram word language model (LM). The
optimal translation output E? is selected among the
top-one hypothesis from all the systems according
to their LM scores. Let ei be a word in sentence E:
E? = arg min
E
? log P5glm(E) (10)
= arg min
E
?
i
? log p(ei|ei?1i?4),
where ei?1i?4 is the n-gram history,
(ei?4, ei?3, ei?2, ei?1).
Another feature function is based on the 5-gram
LM score calculated on the mixed stream of word
and POS tags of the translation output. We run POS
tagging on the translation hypotheses. We keep the
word identities of top N frequent words (N=1000
in our experiments), and the remaining words are re-
placed with their POS tags. As a result, the mixed
stream is like a skeleton of the original sentence, as
shown in Figure 3.
With this model, the optimal translation output E?
is selected based on the following formula:
E? = arg min
E
? log Pwplm(E) (11)
= arg min
E
?
i
? log p(T (ei)|T (e)i?1i?4)
where the mixed stream token T (e) = e when e ?
N , and T (e) = POS(e) when e > N . Similar to
a class-based LM, this model is less prone to data
sparseness problems.
4 Experiments
We experiment with different system combination
strategies on the NIST 2003 Arabic-English MT
evaluation test set. Testset-specific bilingual data
are subsampled, which include 260K sentence pairs,
10.8M Arabic words and 13.5M English words. We
report case-sensitive BLEU (Papineni et al, 2001)
BLEUr4n4c TER
sys1 0.5323 43.11
sys4 0.4742 46.35
Tstcom 0.5429 42.64
Tstcom+Sentcom 0.5466 42.32
Tstcom+Sentcom+Prune 0.5505 42.21
Table 1: Translation results with phrase combination
and pruning.
and TER (Snover et al, 2006) as the MT evaluation
metrics. We evaluate the translation quality of dif-
ferent combination strategies:
? WdCom: Combine testset-specific word trans-
lation model with the baseline model, as de-
scribed in section 3.1.
? PhrCom: Combine and prune phrase trans-
lation tables from all systems, as described
in section 3.2. This include testset-specific
phrase table combination (Tstcom), sen-
tence level phrase combination (Sentcom) and
phrase pruning based on translation hypotheses
(Prune).
? Path: Encourage search along the decoding
paths adopted by other systems via path match-
ing cost function, as described in section 3.3.
? SenSel: Select whole sentence translation hy-
pothesis among all systems? top-one outputs
based on N-gram language models trained on
word stream (word) and word-POS mixed
stream(wdpos).
Table 1 shows the improvement by combining
phrase tables from multiple MT systems using dif-
ferent combination strategies. We only show the
highest and lowest baseline system scores. By com-
bining testset-specific phrase translation tables (Tst-
com), we achieved 1.0 BLEU improvement and 0.5
TER reduction. Sentence-level phrase combination
and pruning additionally improve the BLEU score
by 0.7 point and reduce TER by 0.4 percent.
Table 2 shows the improvement with differ-
ent sentence translation hypothesis selection ap-
proaches. The word-based LM is trained with about
1.75G words from newswire text. A distributed
282
BLEUr4n4c TER
sys1 0.5323 43.11
sys2 0.5320 43.06
SentSel-word: 0.5354 42.56
SentSel-wpmix: 0.5380 43.06
Table 2: Translation results with different sentence
hypothesis selection strategies.
BLEUr4n4c TER
sys1 0.5323 43.11
sys2 0.5320 43.06
sys3 0.4922 46.03
sys4 0.4742 46.35
WdCom 0.5339 42.60
WdCom+PhrCom 0.5528 41.98
WdCom+PhrCom+Path 0.5543 41.75
WdCom+PhrCom+Path+SenSel 0.5565 41.59
Table 3: Translation results with hierarchical system
combination strategy.
large-scale language model architecture is devel-
oped to handle such large training corpora3, as de-
scribed in (Emami et al, 2007). The word-based LM
shows both improvement in BLEU scores and error
reduction in TER. On the other hand, even though
the word-POS LM is trained with much less data
(about 136M words), it improves BLEU score more
effectively, though there is no change in TER.
Table 3 shows the improvements from hierarchi-
cal system combination strategy. We find that word-
based translation combination improves the baseline
block decoder by 0.16 BLEU point and reduce TER
by 0.5 point. Phrase-based translation combina-
tion (including phrase table combination, sentence-
level phrase combination and phrase pruning) fur-
ther improves the BLEU score by 1.9 point (another
0.6 drop in TER). By encouraging the search along
other decoder?s decoding paths, we observed addi-
tional 0.15 BLEU improvement and 0.2 TER reduc-
tion. Finally, sentence translation hypothesis selec-
tion with word-based LM led to 0.2 BLEU point
improvement and 0.16 point reduction in TER. To
3The same LM is also used during first pass decoding by
both the block and the DTM decoders.
BLEUr4n4c TER
sys1 0.3205 60.48
sys2 0.3057 59.99
sys3 0.2787 64.46
sys4 0.2823 59.19
sys5 0.3028 62.16
syscom 0.3409 58.89
Table 4: System combination results on Chinese-
English translation.
BLEUr1n4c TER
sys1 0.1261 71.70
sys2 0.1307 77.52
sys3 0.1282 70.82
sys4 0.1259 70.20
syscom 0.1386 69.23
Table 5: System combination results for Arabic-
English web log translation.
summarize, with the hierarchical system combina-
tion framework, we achieved 2.4 BLEU point im-
provement over the best baseline system, and reduce
the TER by 1.4 point.
Table 4 shows the system combination results on
Chinese-English newswire translation. The test data
is NIST MT03 Chinese-English evaluation test set.
In addition to the 4 baseline MT systems, we also
add another phrase-based MT system (Lee et al,
2006). The system combination improves over the
best baseline system by 2 BLEU points, and reduce
the TER score by 1.6 percent. Thanks to the long
range constituent reordering capability of different
baseline systems, the path imitation improves the
BLEU score by 0.4 point.
We consistently notice improved translation qual-
ity with system combination on unstructured text
and speech translations, as shown in Table 5 and 6.
With one reference translation, we notice 1.2 BLEU
point improvement over the baseline block decoder
(with 2.5 point TER reduction) on web log transla-
tion and about 2.1 point BLEU improvement (with
0.9 point TER reduction) on Broadcast News speech
translation.
283
BLEUr1n4c TER
sys1 0.2011 61.46
sys2 0.2211 66.32
sys3 0.2074 61.21
sys4 0.1258 85.45
syscom 0.2221 60.54
Table 6: System combination results for Arabic-
English speech translation.
5 Related Work
Many system combination research have been done
recently. (Matusov et al, 2006) computes consen-
sus translation by voting on a confusion network,
which is created by pairwise word alignment of mul-
tiple baseline MT hypotheses. This is similar to the
sentence- and word- level combinations in (Rosti
et al, 2007), where TER is used to align multi-
ple hypotheses. Both approaches adopt black-box
combination strategy, as target translations are com-
bined independent of source sentences. (Rosti et al,
2007) extracts phrase translation pairs in the phrase
level combination. Our proposed method incorpo-
rates bilingual information from source and target
sentences in a hierarchical framework: word, phrase
and decoding path combinations. Such information
proves very helpful in our experiments. We also de-
veloped a path matching cost function to encourage
decoding path imitation, thus enable one decoder to
take advantage of rich reordering models of other
MT systems. We only combine top-one hypothesis
from each system, and did not apply system confi-
dence measure and minimum error rate training to
tune system combination weights. This will be our
future work.
6 Conclusion
Our hierarchical system combination strategy effec-
tively integrates word and phrase translation com-
binations, decoding path imitation and sentence hy-
pothesis selection from multiple MT systems. By
boosting common word and phrase translation pairs
and pruning unused ones, we obtain better transla-
tion quality with less re-decoding time. By imitat-
ing the decoding paths, we take advantage of various
reordering schemes from different decoders. The
sentence hypothesis selection based on N-gram lan-
guage model further improves the translation qual-
ity. The effectiveness has been consistently proved
in several empirical studies with test sets in different
languages and covering different genres.
7 Acknowledgment
The authors would like to thank Yaser Al-Onaizan,
Abraham Ittycheriah and Salim Roukos for help-
ful discussions and suggestions. This work is sup-
ported under the DARPA GALE project, contract
No. HR0011-06-2-0001.
References
Yaser Al-Onaizan and Kishore Papineni. 2006. Dis-
tortion Models for Statistical Machine Translation.
In Proceedings of the 21st International Conference
on Computational Linguistics and 44th Annual Meet-
ing of the Association for Computational Linguistics,
pages 529?536, Sydney, Australia, July. Association
for Computational Linguistics.
Peter F. Brown, Stephen Della Pietra, Vincent J. Della
Pietra, and Robert L. Mercer. 1994. The Mathematic
of Statistical Machine Translation: Parameter Estima-
tion. Computational Linguistics, 19(2):263?311.
David Chiang. 2005. A Hierarchical Phrase-Based
Model for Statistical Machine Translation. In Pro-
ceedings of the 43rd Annual Meeting of the Associ-
ation for Computational Linguistics (ACL?05), pages
263?270, Ann Arbor, Michigan, June. Association for
Computational Linguistics.
Ahmad Emami, Kishore Papineni, and Jeffrey Sorensen.
2007. Large-scale Distributed Language Modeling.
In Proceedings of the 2007 International Conference
on Acoustics, Speech, and Signal Processing (ICASSP
2007), Honolulu, Hawaii, April.
Sanjika Hewavitharana, Bing Zhao, Almut Silja Hilde-
brand, Matthias Eck, Chiori Hori, Stephan Vogel, and
Alex Waibel. 2005. The CMU Statistical Machine
Translation System for IWSLT2005. In Proceedings
of IWSLT 2005, Pittsburgh, PA, USA, November.
Arraham Ittycheriah and Salim Roukos. 2007. Di-
rect Translation Model2. In Proceedings of the 2007
Human Language Technologies: The Annual Confer-
ence of the North American Chapter of the Association
for Computational Linguistics (NAACL-HLT 2007),
Rochester, NY, April. Association for Computational
Linguistics.
284
Shyamsundar Jayaraman and Alon Lavie. 2005. Multi-
Engine Machine Translation Guided by Explicit Word
Matching. In Proceedings of the ACL Interactive
Poster and Demonstration Sessions, pages 101?104,
Ann Arbor, Michigan, June. Association for Compu-
tational Linguistics.
Y-S. Lee, S. Roukos, Y. Al-Onaizan, and K. Papineni.
2006. IBM Spoken Language Translation System.
In Proc. of TC-STAR Workshop on Speech-to-Speech
Translation, Barcelona, Spain.
Evgeny Matusov, Nicola Ueffing, and Hermann Ney.
2006. Computing Consensus Translation for Multi-
ple Machine Translation Systems Using Enhanced Hy-
pothesis Alignment. In Proceedings of the 11th Con-
ference of the European Chapter of the Association
for Computational Linguistics (EACL ?06), pages 263?
270, Trento, Italy, April. Association for Computa-
tional Linguistics.
B. Mellebeek, K. Owczarzak, J. Van Genabith, and
A. Way. 2006. Multi-Engine Machine Translation by
Recursive Sentence Decomposition. In Proceedings
of the 7th biennial conference of the Association for
Machine Translation in the Americas, pages 110?118,
Boston, MA, June.
Sergei Nirenburg and Robert Frederking. 1994. Toward
Multi-engine Machine Translation. In HLT ?94: Pro-
ceedings of the workshop on Human Language Tech-
nology, pages 147?151, Morristown, NJ, USA. Asso-
ciation for Computational Linguistics.
Tadashi Nomoto. 2004. Multi-Engine Machine Transla-
tion with Voted Language Model. In Proceedings of
ACL, pages 494?501.
Franz Josef Och. 2003. Minimum Error Rate Training
in Statistical Machine Translation. In Proceedings of
ACL, pages 160?167.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2001. BLEU: a Method for Automatic
Evaluation of Machine Translation. In ACL ?02: Pro-
ceedings of the 40th Annual Meeting on Association
for Computational Linguistics, pages 311?318, Mor-
ristown, NJ, USA. Association for Computational Lin-
guistics.
Antti-Veikko Rosti, Necip Fazil Ayan, Bing Xiang, Spy-
ros Matsoukas, Richard Schwartz, and Bonnie J.
Dorr. 2007. Combining Translations from Mul-
tiple Machine Translation Systems. In Proceed-
ings of the Conference on Human Language Technol-
ogy and North American chapter of the Association
for Computational Linguistics Annual Meeting (HLT-
NAACL?2007), Rochester, NY, April.
Matthew Snover, Bonnie Dorr, Richard Schwartz, Lin-
nea Micciulla, and John Makhoul. 2006. A Study
of Translation Edit Rate with Targeted Human An-
notation. In Proceedings of Association for Machine
Translation in the Americas.
D. Tidhar and U. Kussner. 2000. Learning to Select a
Good Translation. In Proceedings of the International
Conference on Computational Linguistics, pages 843?
849.
285
  
 
 
 
System 1 System 2 System N 
Word 
Combination 
Phrase 
Combination 
& Pruning 
Decoder 
Decoding 
Path 
Imitation 
Sentence 
Hypothesis 
Selection 
Decoder 
 
Target 
Translation 
Source 
Text 
Figure 1: Hierarchical MT system combination ar-
chitecture. The top dot-line rectangle is similar to
the glass-box combination, and the bottom rectangle
with sentence selection is similar to the black-box
combination.
 
 
Original Sentence: 
  
 
 
 
 
Word-POS mixed stream: 
 
 
 
 
in short , making a good plan at the 
beginning of the construction is the crucial 
measure for reducing haphazard economic 
development . 
in JJ , making a good plan at the NN of the 
construction is the JJ NN for VBG JJ 
economic development . 
Figure 3: Sentence with Word-POS mixed stream.
286
