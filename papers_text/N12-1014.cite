Cyril Allauzen, Mehryar Mohri, and Brian Roark. 2003.
Generalized algorithms for constructing statistical lan-
guage models. In Proc. of ACL, pages 40?47.
Shane Bergsma, Dekang Lin, and Randy Goebel. 2009.
Web-scale n-gram models for lexical disambiguation.
In Proc. of IJCAI.
Thorsten Brants and Alex Franz. 2006. Web 1T 5-gram
version 1. Linguistic Data Consortium, Philadelphia.
LDC2006T13.
Thorsten Brants, Ashok C. Popat, Peng Xu, Franz J. Och,
and Jeffrey Dean. 2007. Large language models in
machine translation. In Proc. of EMNLP.
Tim Dawborn and James R. Curran. 2009. CCG
parsing with one syntactic structure per n-gram. In
Australasian Language Technology Association Work-
shop, pages 71?79.
Arthur P. Dempster, Nan M. Laird, and Donald B. Ru-
bin. 1977. Maximum likelihood from incomplete data
via the EM algorithm. Journal of the Royal Statistical
Society. Series B (Methodological), 39(1):1?38.
Jason Eisner. 2002. Parameter estimation for probabilis-
tic finite-state transducers. In Proc. of ACL, pages 1?8.
Yoav Goldberg, Meni Adler, and Michael Elhadad. 2008.
EM can find pretty good HMM POS-taggers (when
given a good start). In Proc. of ACL, pages 746?754.
Sharon Goldwater and Thomas Griffiths. 2007. A fully
Bayesian approach to unsupervised part-of-speech tag-
ging. In Proc. of ACL, pages 744?751.
Aria Haghighi and Dan Klein. 2006. Prototype-driven
learning for sequence models. In Proc. of NAACL,
pages 320?327.
Daniel Hsu, Sham M. Kakade, and Tong Zhang. 2009. A
spectral algorithm for learning hidden Markov models.
In Proc. of COLT.
Mark Johnson. 2007. Why doesn?t EM find good HMM
POS-taggers? In Proc. of EMNLP-CoNLL, pages
296?305.
M. I. Jordan, Z. Ghahramani, T. S. Jaakkola, and L. K.
Saul. 1999. An introduction to variational methods
for graphical models. In M. I. Jordan, editor, Learning
in Graphical Models. Kluwer.
Mirella Lapata and Frank Keller. 2005. Web-based mod-
els for natural language processing. ACM Transac-
tions on Speech and Language Processing.
Zhifei Li and Jason Eisner. 2009. First- and second-order
expectation semirings with applications to minimum-
risk training on translation forests. In Proc. of
EMNLP, pages 40?51.
Percy Liang, Hal Daume? III, and Dan Klein. 2008.
Structure compilation: Trading structure for features.
In International Conference on Machine Learning
(ICML), Helsinki, Finland.
D. Lin, K. Church, H. Ji, S. Sekine, D. Yarowsky,
S. Bergsma, K. Patil, E. Pitler, R. Lathbury, V. Rao,
K. Dalwani, and S. Narsale. 2009. Unsupervised ac-
quisition of lexical knowledge from n-grams. Sum-
mer workshop technical report, Center for Language
and Speech Processing, Johns Hopkins University.
David J. C. MacKay. 1997. Ensemble learning for hid-
den Markov models. http://www.inference.
phy.cam.ac.uk/mackay/abstracts/
ensemblePaper.html.
Mitchell P. Marcus, Mary Ann Marcinkiewicz, and Beat-
rice Santorini. 1993. Building a large annotated cor-
pus of English: The Penn Treebank. Computational
Linguistics.
Andrew McCallum, Dayne Freitag, and Fernando
Pereira. 2000. Maximum entropy Markov models for
information extraction and segmentation. In Proc. of
ICML, pages 591?598.
B. Merialdo. 1994. Tagging English text with a proba-
bilistic model. Computational Linguistics, 20(2):155?
171.
J.-B. Michel, Y. K. Shen, A. P. Aiden, A. Veres, M. K.
Gray, W. Brockman, The Google Books Team, J. P.
Pickett, D. Hoiberg, D. Clancy, P. Norvig, J. Orwant,
S. Pinker, M. A. Nowak, and E. L. Aiden. 2010.
Quantitative analysis of culture using millions of digi-
tized books. Science, 331(6014):176?182.
Mehryar Mohri and Mark-Jan Nederhof. 2001. Regu-
lar approximation of context-free grammars through
transformation. In Jean-Claude Junqua and Gert-
jan van Noord, editors, Robustness in Language and
Speech Technology, chapter 9, pages 153?163. Kluwer
Academic Publishers, The Netherlands, February.
Mehryar Mohri, Fernando Pereira, and Michael Riley.
2000. The design principles of a weighted finite-
state transducer library. Theoretical Computer Sci-
ence, 231(1):17?32, January.
Radford M. Neal and Geoffrey E. Hinton. 1998. A view
of the EM algorithm that justifies incremental, sparse,
and other variants. In M.I. Jordan, editor, Learning in
Graphical Models, pages 355?368. Kluwer.
Mark-Jan Nederhof. 2000. Practical experiments
with regular approximation of context-free languages.
Computational Linguistics, 26(1).
Robert Parker, David Graff, Junbo Kong, Ke Chen, and
Kazuaki Maeda. 2009. English Gigaword fourth
edition. Linguistic Data Consortium, Philadelphia.
LDC2009T13.
V. Punyakanok, D. Roth, W. Yih, and D. Zimak. 2005.
Learning and inference over constrained output. In
Proc. of IJCAI, pages 1124?1129.
Lawrence R. Rabiner. 1989. A tutorial on hidden
Markov models and selected applications in speech
recognition. Proc. of the IEEE, 77(2):257?286, Febru-
ary.
Sujith Ravi and Kevin Knight. 2008. Minimized models
for unsupervised part-of-speech tagging. In Proc. of
ACL, pages 504?512.
Noah A. Smith and Jason Eisner. 2005. Contrastive esti-
mation: Training log-linear models on unlabeled data.
In Proc. of ACL, pages 354?362.
R. Staden. 1979. A strategy of DNA sequencing em-
ploying computer programs. Nucleic Acids Research,
6(7):2601?2610, June.
Andreas Stolcke. 2000. Entropy-based pruning of back-
off language models. In DARPA Broadcast News
Transcription and Understanding Workshop, pages
270?274.
Kristina Toutanova and Mark Johnson. 2007. A
Bayesian LDA-based model for semi-supervised part-
of-speech tagging. In Proc. of NIPS, volume 20.