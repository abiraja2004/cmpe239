Proceedings of the CoNLL Shared Task Session of EMNLP-CoNLL 2007, pp. 952?956,
Prague, June 2007. c?2007 Association for Computational Linguistics
Multilingual Dependency Parsing using Global Features
Tetsuji Nakagawa
Oki Electric Industry Co., Ltd.
2?5?7 Honmachi, Chuo-ku, Osaka 541?0053, Japan
nakagawa378@oki.com
Abstract
In this paper, we describe a two-stage multi-
lingual dependency parser used for the mul-
tilingual track of the CoNLL 2007 shared
task. The system consists of two compo-
nents: an unlabeled dependency parser us-
ing Gibbs sampling which can incorporate
sentence-level (global) features as well as
token-level (local) features, and a depen-
dency relation labeling module based on
Support Vector Machines. Experimental re-
sults show that the global features are useful
in all the languages.
1 Introduction
Making use of as many informative features as pos-
sible is crucial to obtain high performance in ma-
chine learning based NLP. Recently, several meth-
ods for incorporating non-local features have been
investigated, though such features often make mod-
els complex and thus complicate inference. Collins
and Koo (2005) proposed a reranking method for
phrase structure parsing with which any type of
global features in a parse tree can be used. For
dependency parsing, McDonald and Pereira (2006)
proposed a method which can incorporate some
types of global features, and Riedel and Clarke
(2006) studied a method using integer linear pro-
gramming which can incorporate global linguistic
constraints. In this paper, we study dependency
parsing using Gibbs sampling which can incorpo-
rate any type of global feature in a sentence. The
parser determines unlabeled dependency structures
only, and we attach dependency relation labels us-
ing Support Vector Machines afterwards.
We participated in the multilingual track of the
CoNLL 2007 shared task (Nivre et al, 2007), and
evaluated the system on data sets of 10 languages
(Hajic? et al, 2004; Aduriz et al, 2003; Mart?? et
al., 2007; Chen et al, 2003; Bo?hmova? et al, 2003;
Marcus et al, 1993; Johansson and Nugues, 2007;
Prokopidis et al, 2005; Csendes et al, 2005; Mon-
temagni et al, 2003; Oflazer et al, 2003).
The rest of the paper describes the specification of
the system and the evaluation results.
2 Unlabeled Dependency Parsing using
Global Features
2.1 Probabilistic Model
Rosenfeld et al (2001) proposed whole-sentence ex-
ponential language models which can incorporate
arbitrary features in a sentence, and we consider here
a similar probabilistic model for dependency pars-
ing which can incorporate any sentence-level fea-
ture. Let w = w1 ? ? ?w|w| denote an input sentence
consisting of |w| tokens, and h = h1 ? ? ?h|w| denote
the sequence of the indices of each token?s head.
Root nodes of a sentence do not have heads, and we
regard the index of a root node?s head as zero, i.e.,
hi ? {0, 1, ? ? ? , |w|} \ {i}. We define the probabil-
ity distribution of the dependency structure h given
a sentence w using exponential models as follows:
P?,M(h|w)= 1Z?,M(w)QM(h|w)exp
{ K?
k=1
?kfk(w,h)
}
,(1)
Z?,M(w)=
?
h??H(w)
QM(h?|w) exp
{ K?
k=1
?kfk(w,h?)
}
, (2)
where QM(h|w) is an initial distribution, fk(w,h)
is the k-th feature function, K is the number of fea-
ture functions, and ?k is the weight of the k-th fea-
ture. H(w) is the set of possible configurations of
heads for a given sentence w. Although it is ap-
propriate that H(w) is the set of projective trees for
projective languages, and is the set of non-projective
trees (which is a superset of the set of projective
trees) for non-projective languages, in this study, we
define H(w) to be the set of all the possible graphs,
which contains |w||w| elements. P?,M(h|w) and
QM(h|w) are defined over H(w)1. The probabil-
ity distribution P?,M(h|w) is a joint distribution of
all the heads conditioned by a sentence, therefore
we call this model sentence-level model. The fea-
ture function fk(w,h) is defined on a sentence w
with heads h, and we can use any information in the
sentence without the independence assumption for
the heads of the tokens, therefore we call fk(w,h)
1H(w) is a superset of the set of non-projective trees, and
is an unnecessarily large set which contains ill-formed depen-
dency trees such as trees with cycles. This issue may cause
reduction of parsing performance, but we adopt this approach
for computational efficiency.
952
sentence-level (global) feature. We define initial
distribution QM(h|w) as the product of qM(h|w, t)
which is the probability distribution of the head h of
each t-th token calculated with maximum entropy
models:
QM(h|w)=
|w|?
t=1
qM(ht|w, t), (3)
qM(h|w, t)= 1YM(w, t) exp
{ L?
l=1
?lgl(w, t, h)
}
, (4)
YM(w, t)=
|w|?
h?=0
h? 6=t
exp
{ L?
l=1
?lgl(w, t, h?)
}
, (5)
where gl(w, t, h) is the l-th feature function, L is the
number of feature functions, and ?l is the weight of
the l-th feature. qM(h|w, t) is a model of the head
of a single token, calculated independently from
other tokens, therefore we call qM(h|w, t) token-
level model, and gl(w, t, h) token-level (local) fea-
ture.
2.2 Decoding and Parameter Estimation
Let us consider how to find the optimal solution
h?, given a sentence w, parameters of the sentence-
level model ? = {?1, ? ? ? , ?K}, and parameters of
the token-level model M = {?1, ? ? ? , ?L}. Since
the probabilistic model contains global features and
efficient algorithms such as dynamic programming
cannot be used, we use Gibbs sampling to obtain
an approximated solution. Gibbs sampling can ef-
ficiently generate samples from high-dimensional
probability distributions with complex dependencies
among variables (Andrieu et al, 2003), and we as-
sume that R samples {h(1), ? ? ? ,h(R)} are generated
from P?,M(h|w) using Gibbs sampling. Then, the
marginal distribution of the head of the t-th token
given w, Pt(h|w), is approximately calculated as
follows:
Pt(h|w) =
?
h1,???,ht?1,ht+1,???,h|w|
ht=h
P?,M(h|w),
=
?
h
P?,M(h|w)?(h, ht) ' 1R
R?
r=1
?(h, h(r)t ), (6)
where ?(i, j) is the Kronecker delta. In order to
find a solution using the marginal distribution, we
adopt the maximum spanning tree (MST) frame-
work proposed by McDonald et al (2005a). In this
framework, scores for possible edges in dependency
graphs are defined, and the optimal dependency tree
is found as the MST in which the summation of the
edge scores is maximized. Let s(i, j) denote the
score of the edge from a parent node (head) i to a
child node (dependent) j. We define s(i, j) as fol-
lows:
s(i, j)=logPj(i|w). (7)
We use the logarithm of the marginal distribution be-
cause the summation of edge scores is maximized
by the MST search algorithms but the product of the
marginal distributions should be maximized. The
best projective parse tree is obtained using the Eis-
ner algorithm (Eisner, 1996) with the scores, and the
best non-projective one is obtained using the Chu-
Liu-Edmonds (CLE) algorithm (McDonald et al,
2005b).
Although in this method, the factored score s(i, j)
is used to measure likelihood of dependency trees,
the score is calculated taking a whole sentence into
consideration using Gibbs sampling.
Next, we explain how to estimate the parame-
ters of our models, given training data consisting of
N examples {?w1,h1?, ? ? ? , ?wN ,hN ?}. In order
to estimate the parameters of the token-level model
M = {?1, ? ? ? , ?L}, we use maximum a posteriori
estimation with Gaussian priors. We define the fol-
lowing objective function M:
M=log
N?
n=1
QM(hn|wn)? 12?2
L?
l=1
?2l , (8)
where ? is a hyper parameter of Gaussian priors.
The optimal parameters M which maximize M can
be obtained by quasi-Newton methods such as the
L-BFGS algorithm with above M and its partial
derivatives. The parameters of the sentence-level
model ? = {?1, ? ? ? , ?K} can also be estimated in
a similar way with the following objective function
L after the parameters of the token-level model are
estimated.
L=log
N?
n=1
P?,M(hn|wn)? 12??2
K?
k=1
?2k. (9)
This objective function and its partial derivative con-
tain summations over all the possible configura-
tions which are difficult to calculate. We approx-
imately calculate these values using static Monte
Carlo (not MCMC) methods with fixed S samples
{hn(1), ? ? ? ,hn(S)} generated from QM(h|wn)2:
logZ?,M(wn)'log 1S
S?
s=1
exp
{ K?
k=1
?kfk(wn,hn(s))
}
,(10)
?
h??H(wn)
P?,M(h?|wn)fk(wn,h?)
' 1S
S?
s=1
fk(wn,hn(s))
Z?,M(wn) exp
{ K?
k?=1
?k?fk?(wn,hn(s))
}
. (11)
2Static Monte Carlo methods become inefficient when the
dimension of the probabilistic distribution is high, and more so-
phisticated methods would be used for accurate parameter esti-
mation.
953
2.3 Local Features
The token-level features used in the system are the
same as those used in MSTParser version 0.4.23.
The features include lexical forms and (coarse and
fine) POS tags of parent tokens, child tokens, their
surrounding tokens, and tokens between the child
and the parent. The direction and the distance from a
parent to its child, and the FEATS fields of the parent
and the child which are split into elements and then
combined are also included. Features that appeared
less than 5 times in training data are ignored.
2.4 Global Features
Global features can capture any information in de-
pendency trees, and the following nine types of
global features are used (In the following, parent
node means a head token, and child node means a
dependent token):
Child Unigram+Parent+Grandparent This fea-
ture template is a 4-tuple consisting of (1) a
child node, (2) its parent node, (3) the direc-
tion from the parent node to the child node, and
(4) the grandparent node.
Each node in the feature template is expanded
to its lexical form and coarse POS tag in or-
der to obtain actual features. Features that ap-
peared in four or less sentences are ignored.
The same procedure is applied to the following
other features.
Child Bigram+Parent This feature template is a 4-
tuple consisting of (1) a child node, (2) its par-
ent node, (3) the direction from the parent node
to the child node, and (4) the nearest outer sib-
ling node (the nearest sibling node which exists
on the opposite side of the parent node) of the
child node. This feature template is almost the
same as the one used by McDonald and Pereira
(2006).
Child Bigram+Parent+Grandparent This feature
template is a 5-tuple. The first four ele-
ments (1)?(4) are the same as the Child Bi-
gram+Parent feature template, and the addi-
tional element (5) is the grandparent node.
Child Trigram+Parent This feature template is a
5-tuple. The first four elements (1)?(4) are the
same as the Child Bigram+Parent feature tem-
plate, and the additional element (5) is the next
nearest outer sibling node of the child node.
3http://sourceforge.net/projects/mstparser
Parent+All Children This feature template is a tu-
ple with more than one element. The first ele-
ment is a parent node, and the other elements
are all of its child nodes.
Parent+All Children+Grandparent This feature
template is a tuple with more than two ele-
ments. The elements other than the last one
are the same as the Parent+All Children feature
template, and the last element is the grandpar-
ent node.
Child+Ancestor This feature template is a 2-tuple
consisting of (1) a child node, and (2) one of its
ancestor nodes.
Acyclic This feature type has one of two values,
true if the dependency tree is acyclic, or false
otherwise.
Projective This feature type has one of two val-
ues, true if the dependency tree is projective,
or false otherwise.
3 Dependency Relation Labeling
3.1 Model
Dependency relation labeling can be handled as a
multi-class classification problem, and we use Sup-
port Vector Machines (SVMs) which have been suc-
cessfully applied to many NLP tasks. Solving large-
scale multi-class classification problem with SVMs
requires substantial computational resources, so we
use the revision learning method (Nakagawa et al,
2002). The revision learning method combines
a probabilistic model which has smaller computa-
tional cost with a binary classifier which has higher
generalization capacity. In the method, the latter
classifier revises the output of the former model to
conduct multi-class classification with higher ac-
curacy and reasonable computational cost. In this
study, we use maximum entropy (ME) models as
the probabilistic model and SVMs with the second
order polynomial kernel as the binary classifier. The
dependency label of each node is determined inde-
pendently of the labeling of other nodes.
3.2 Features
As the features for SVMs to predict the dependency
relation label of the i-th token, we use the lexical
forms, coarse and fine POS tags, and FEATS fields
of the i-th and the hi-th tokens. We also use lex-
ical forms and POS tags of the tokens surround-
ing and in between them (i.e. the j-th token where
j ? {j|min{i, hi} ? 1 ? j ? max{i, hi} + 1}),
the grandparent (hhi-th) token, the sibling tokens ofi (the j?-th token where j? ? {j?|hj? = hi, j? 6= i}),
954
Arabic Basque Catalan Chinese Czech English Greek Hungarian Italian Turkish Average
LAS 75.08 72.56 87.90 83.84 80.19 88.41 76.31 76.74 83.61 78.22 80.29
UAS 86.09 81.04 92.86 88.88 86.28 90.13 84.08 82.49 87.91 85.77 86.55
Table 1: Results of Multilingual Dependency Parsing
Algorithm Features Arabic Basque Catalan Chinese Czech English Greek Hungarian Italian Turkish
Eisner local 85.15 80.20 91.75 86.75 84.19 88.65 83.31 80.27 86.72 84.82
(proj.) +global 86.09 81.00 92.86 88.88 85.99 90.13 84.08 81.55 87.91 84.82
CLE local 84.80 80.39 91.23 86.71 84.21 88.07 83.03 81.15 86.85 85.35
(non-proj.) +global 85.83 81.04 92.64 88.84 86.28 90.05 83.87 82.49 87.97 85.77
Table 2: Unlabeled Attachment Scores in Different Settings (underlined values indicate submitted results,
and bold values indicate the highest scores)
and the child tokens of i (the j??-th token where
j?? ? {j??|hj?? = i})4. As the features for ME mod-
els, a subset of them is used since ME models are
used just for reducing the search space, and do not
need so many features.
4 Results and Analysis
In order to tune the system, we split each training
data set into two parts, and used the first half for
training and the remaining half for testing in devel-
opment. The CLE algorithm was used for Basque,
Czech, Hungarian and Turkish, and the Eisner algo-
rithm was used for the others. We used lemmas for
Catalan, Czech, Greek and Italian, and word forms
for all others. The values of the parameters to be
fixed were chosen as R = 500, S = 200, ? = 0.25,
and ?? = 0.25. With these parameter settings, train-
ing took 247 hours, and testing took 343 minutes on
an Opteron 250 processor.
Table 1 shows the evaluation results on the test
sets. Accuracy was measured with the labeled at-
tachment score (LAS) and the unlabeled attachment
score (UAS). Among the participating systems in the
shared task, we obtained the second best average
accuracy in the labeled attachment score, and the
best average accuracy in the unlabeled attachment
score. Compared with other systems, the gap be-
tween our labeled and unlabeled scores is relatively
big. In this study, labeling of dependency relations
was performed in a separate post-processing step,
and each label was predicted independently. The la-
beled scores may be improved if the parsing process
and the labeling process are performed at the same
time, and dependencies among labels are taken into
account.
We conducted experiments with different settings.
Table 2 shows the results measured with the unla-
beled attachment score. In the table, Eisner and
4Although polynomial kernels of SVMs can implicitly han-
dle combined features, some of combined features were also in-
cluded explicitly because using unnecessarily high order poly-
nomial kernels decreases performance.
CLE indicate that the Eisner algorithm and the
CLE algorithm are used in decoding, and local and
+global indicate that local features alone, and local
and global features together are used. The CLE al-
gorithm performed better than the Eisner algorithm
for Basque, Czech, Hungarian, Italian and Turkish.
All of these data sets except Italian contain relatively
a large number of non-projective sentences (the per-
centage of sentences with at least one non-projective
relation in the training data is over 20% (Nivre et al,
2007)), though the Greek data set, on which the Eis-
ner algorithm performed better, also contains many
non-projective sentences (20.3%).
By using the global features, the accuracy was
improved in all the cases except for Turkish with
the Eisner algorithm (Table 2). The increase was
rather large in Chinese and Czech. When the global
features were used in these languages, the depen-
dency accuracy for tokens whose heads had con-
junctions as parts-of-speech was notably improved;
from 80.5% to 86.0% in Chinese (Eisner), and from
73.2% to 77.6% in Czech (CLE). We investigated
the trained global models, and found that Parent+All
Children features, whose parents were conjunctions
and whose children had compatible classes, had
large positive weights, and those whose children had
incompatible classes had large negative weights. A
feature with a larger weight is generally more influ-
ential. Riedel and Clarke (2006) suggested to use
linguistic constraints such as ?arguments of a coor-
dination must have compatible word classes,? and
such constraint seemed to be represented by the fea-
tures in our models.
5 Conclusion
In this study, we applied a dependency parser us-
ing global features to multilingual dependency pars-
ing. Evaluation results showed that the use of global
features was effective to obtain higher accuracy in
multilingual dependency parsing. Improving depen-
dency relation labeling is left for future work.
955
References
A. Abeille?, editor. 2003. Treebanks: Building and Using
Parsed Corpora. Kluwer.
I. Aduriz, M. J. Aranzabe, J. M. Arriola, A. Atutxa,
A. Diaz de Ilarraza, A. Garmendia, and M. Oronoz.
2003. Construction of a Basque Dependency Tree-
bank. In Proc. of the 2nd Workshop on Treebanks and
Linguistic Theories (TLT), pages 201?204.
C. Andrieu, N. de Freitas, A. Doucet, and M. I. Jordan.
2003. An Introduction to MCMC for Machine Learn-
ing. Machine Learning, 50:5?43.
A. Bo?hmova?, J. Hajic?, E. Hajic?ova?, and B. Hladka?. 2003.
The PDT: a 3-level annotation scenario. In Abeille?
(Abeille?, 2003), chapter 7, pages 103?127.
K. Chen, C. Luo, M. Chang, F. Chen, C. Chen, C. Huang,
and Z. Gao. 2003. Sinica Treebank: Design Crite-
ria, Representational Issues and Implementation. In
Abeille? (Abeille?, 2003), chapter 13, pages 231?248.
M. Collins and T. Koo. 2005. Discriminative Rerank-
ing for Natural Language Parsing. Computational Lin-
guistics, 31(1):25?69.
D. Csendes, J. Csirik, T. Gyimo?thy, and A. Kocsor. 2005.
The Szeged Treebank. Springer.
J. Eisner. 1996. Three New Probabilistic Models for De-
pendency Parsing: An Exploration. In Proc. of COL-
ING ?96, pages 340?345.
J. Hajic?, O. Smrz?, P. Zema?nek, J. ?Snaidauf, and E. Bes?ka.
2004. Prague Arabic Dependency Treebank: Develop-
ment in Data and Tools. In Proc. of the NEMLAR In-
tern. Conf. on Arabic Language Resources and Tools,
pages 110?117.
R. Johansson and P. Nugues. 2007. Extended
Constituent-to-Dependency Conversion for English.
In Proc. of the 16th Nordic Conference on Computa-
tional Linguistics (NODALIDA).
M. Marcus, B. Santorini, and M. Marcinkiewicz. 1993.
Building a Large Annotated Corpus of English:
the Penn Treebank. Computational Linguistics,
19(2):313?330.
M. A. Mart??, M. Taule?, L. Ma`rquez, and M. Bertran.
2007. CESS-ECE: A Multilingual and Multilevel
Annotated Corpus. Available for download from:
http://www.lsi.upc.edu/?mbertran/cess-ece/.
R. McDonald and F. Pereira. 2006. Online Learning
of Approximate Dependency Parsing Algorithms. In
Proc. of EACL 2006, pages 81?88.
R. McDonald, K. Crammer, and F. Pereira. 2005a. On-
line Large-Margin Training of Dependency Parsers. In
Proc. of ACL 2005, pages 91?98.
R. McDonald, F. Pereira, K. Ribarow, and J. Hajic.
2005b. Non-projective dependency parsing using
Spanning Tree Algorithms. In Proc. of HLT/EMNLP
2005, pages 523?530.
S. Montemagni, F. Barsotti, M. Battista, N. Calzolari,
O. Corazzari, A. Lenci, A. Zampolli, F. Fanciulli,
M. Massetani, R. Raffaelli, R. Basili, M. T. Pazienza,
D. Saracino, F. Zanzotto, N. Nana, F. Pianesi, and
R. Delmonte. 2003. Building the Italian Syntactic-
Semantic Treebank. In Abeille? (Abeille?, 2003), chap-
ter 11, pages 189?210.
T. Nakagawa, T. Kudo, and Y. Matsumoto. 2002. Re-
vision Learning and its Application to Part-of-speech
Tagging. In Proc. of ACL 2002, pages 497?504.
J. Nivre, J. Hall, S. Ku?bler, R. McDonald, J. Nilsson,
S. Riedel, and D. Yuret. 2007. The CoNLL 2007
Shared Task on Dependency Parsing. In Proc. of
the CoNLL 2007 Shared Task. Joint Conf. on Em-
pirical Methods in Natural Language Processing and
Computational Natural Language Learning (EMNLP-
CoNLL).
K. Oflazer, B. Say, D. Zeynep Hakkani-Tu?r, and G. Tu?r.
2003. Building a Turkish Treebank. In Abeille?
(Abeille?, 2003), chapter 15, pages 261?277.
P. Prokopidis, E. Desypri, M. Koutsombogera, H. Papa-
georgiou, and S. Piperidis. 2005. Theoretical and
Practical Issues in the Construction of a Greek Depen-
dency Treebank. In Proc. of the 4th Workshop on Tree-
banks and Linguistic Theories (TLT), pages 149?160.
S. Riedel and J. Clarke. 2006. Incremental Integer Linear
Programming for Non-projective Dependency Parsing.
In Proc. of EMNLP 2006, pages 129?137.
R. Rosenfeld, S. F. Chen, and X. Zhu. 2001. Whole-
Sentence Exponential Language Models: A Vehi-
cle For Linguistic-Statistical Integration. Computers
Speech and Language, 15(1):55?73.
956
