Proceedings of the 5th International Workshop on Semantic Evaluation, ACL 2010, pages 218?221,
Uppsala, Sweden, 15-16 July 2010.
c?2010 Association for Computational Linguistics
ISTI@SemEval-2 Task #8:
Boosting-Based Multiway Relation Classification
Andrea Esuli, Diego Marcheggiani, Fabrizio Sebastiani
Istituto di Scienza e Tecnologie dell?Informazione
Consiglio Nazionale delle Ricerche
56124 Pisa, Italy
firstname.lastname@isti.cnr.it
Abstract
We describe a boosting-based supervised
learning approach to the ?Multi-Way Clas-
sification of Semantic Relations between
Pairs of Nominals? task #8 of SemEval-
2. Participants were asked to determine
which relation, from a set of nine relations
plus ?Other?, exists between two nomi-
nals, and also to determine the roles of the
two nominals in the relation.
Our participation has focused, rather than
on the choice of a rich set of features,
on the classification model adopted to de-
termine the correct assignment of relation
and roles.
1 Introduction
The ?Multi-Way Classification of Semantic Rela-
tions between Pairs of Nominals? (Hendrickx et
al., 2010) we faced can be seen as the composition
of two sub-tasks:
1. Determining which relation r, from a set of
relations R (see Table 1), exists between two
entities e
1
and e
2
.
2. Determining the direction of the relation, i.e.,
determining which of r(e
1
, e
2
) or r(e
2
, e
1
)
holds.
The set R is composed by nine ?semantically
determined? relations, plus a special Other rela-
tion which includes all the pairs which do not be-
long to any of the nine previously mentioned rela-
tions.
The two novel aspects of this task with respect to
the similar task # 4 of SemEval-2007 (Girju et al,
2007) (?Classification of Semantic Relations be-
tween Nominals?) are (i) the definition of the task
as a ?single-label? classification task and (ii) the
1 Cause-Effect
2 Instrument-Agency
3 Product-Producer
4 Content-Container
5 Entity-Origin
6 Entity-Destination
7 Component-Whole
8 Member-Collection
9 Message-Topic
Table 1: The nine relations defined for the task.
need of determining the direction of the relation
(i.e., Item 2 above).
The classification task described can be formal-
ized as a single-label (aka ?multiclass?) text clas-
sification (SLTC) task, i.e., as one in which exactly
one class must be picked for a given object out of
a set of m available classes.
Given a set of objects D (ordered pairs of nom-
inals, in our case) and a predefined set of classes
(aka labels, or categories) C = {c
1
, . . . , c
m
},
SLTC can be defined as the task of estimating
an unknown target function ? : D ? C, that
describes how objects ought to be classified, by
means of a function
?
? : D ? C called the classi-
fier
1
.
In the relation classification task which is the
object of this evaluation, the set C of classes is
composed of 19 elements, i.e., the nine relations
of Table 1, each one considered twice because it
may take two possible directions, plus Other.
2 The learner
As the learner for our experiments we have used a
boosting-based learner called MP-BOOST (Esuli
et al, 2006). Boosting is among the classes of su-
pervised learning devices that have obtained the
best performance in several learning tasks and,
at the same time, have strong justifications from
computational learning theory. MP-BOOST is a
1
Consistently with most mathematical literature we use
the caret symbol (?) to indicate estimation.
218
variant of ADABOOST.MH (Schapire and Singer,
2000), which has been shown in (Esuli et al,
2006) to obtain considerable effectiveness im-
provements with respect to ADABOOST.MH.
MP-BOOST works by iteratively generating, for
each class c
j
, a sequence
?
?
j
1
, . . . ,
?
?
j
S
of classifiers
(called weak hypotheses). A weak hypothesis is a
function
?
?
j
s
: D ? R, where D is the set of doc-
uments and R is the set of real numbers. The sign
of
?
?
j
s
(d
i
) (denoted by sgn(
?
?
j
s
(d
i
))) represents the
binary decision of
?
?
j
s
on whether d
i
belongs to c
j
,
i.e. sgn(
?
?
j
s
(d
i
)) = +1 (resp.,?1) means that d
i
is
believed to belong (resp., not to belong) to c
j
. The
absolute value of
?
?
j
s
(d
i
) (denoted by |
?
?
j
s
(d
i
)|)
represents instead the confidence that
?
?
j
s
has in
this decision, with higher values indicating higher
confidence.
At each iteration s MP-BOOST tests the effec-
tiveness of the most recently generated weak hy-
pothesis
?
?
j
s
on the training set, and uses the results
to update a distributionD
j
s
of weights on the train-
ing examples. The initial distribution D
j
1
is uni-
form by default. At each iteration s all the weights
D
j
s
(d
i
) are updated, yieldingD
j
s+1
(d
i
), so that the
weight assigned to an example correctly (resp., in-
correctly) classified by
?
?
j
s
is decreased (resp., in-
creased). The weight D
j
s+1
(d
i
) is thus meant to
capture how ineffective
?
?
j
1
, . . . ,
?
?
j
s
have been in
guessing the correct c
j
-assignment of d
i
(denoted
by ?
j
(d
i
)), i.e., in guessing whether training doc-
ument d
i
belongs to class c
j
or not. By using this
distribution, MP-BOOST generates a new weak
hypothesis
?
?
j
s+1
that concentrates on the exam-
ples with the highest weights, i.e. those that had
proven harder to classify for the previous weak hy-
potheses.
The overall prediction on whether d
i
belongs to
c
j
is obtained as a sum
?
?
j
(d
i
) =
?
S
s=1
?
?
j
s
(d
i
) of
the predictions made by the weak hypotheses. The
final classifier
?
?
j
is thus a committee of S clas-
sifiers, a committee whose S members each cast
a weighted vote (the vote being the binary deci-
sion sgn(
?
?
j
s
(d
i
)), the weight being the confidence
|
?
?
j
s
(d
i
)|) on whether d
i
belongs to c
j
. For the final
classifier
?
?
j
too, sgn(
?
?
j
(d
i
)) represents the bi-
nary decision as to whether d
i
belongs to c
j
, while
|
?
?
j
(d
i
)| represents the confidence in this decision.
MP-BOOST produces a multi-label classifier,
i.e., a classifier which independently classifies a
document against each class, possibly assigning
a document to multiple classes or no class at
?<e1>People</e1> have been moving back into
<e2>downtown</e2>.?
Entity-Destination(e1,e2)
F People FS Peopl FH group FP NNP
FS1 have FS1S have FS1H have FS1P VBP
FS2 been FS2S been FS2H be FS2P VBN
FP3 moving FP3S move FP3H travel FP3P VBG
SP3 moving SP3S move SP3H travel SP3P VBG
SP2 back SP2S back SP2H O SP2P RB
SP1 into SP1S into SP1H O SP1P IN
S downtown SS downtown SH city district SP NN
SS1 . SS1S . SS1H O SS1P .
Table 2: A training sentence and the features ex-
tracted from it.
all. In order to obtain a single-label classifier,
we compare the outcome of the |C| binary clas-
sifiers, and the class which has obtained the high-
est
?
?
j
(d
i
) value is assigned to d
i
, i.e.,
?
?(d
i
) =
arg max
j
?
?
j
(d
i
).
3 Vectorial representation
We have generated the vectorial representations of
the training and test objects by extracting a number
of contextual features from the text surrounding
the two nominals whose relation is to be identified.
An important choice we have made is to ?nor-
malize? the representation of the two nominals
with respect to the order in which they appear in
the relation, and not in the sentence. Thus, if e
2
appears in a relation r(e
2
, e
1
), then e
2
is consid-
ered to be the first (F) entity in the feature genera-
tion process and e
1
is the second (S) entity.
We have generated a number of features for
each term denoting an entity and also for the three
terms preceding each nominal (P1, P2, P3) and for
the three terms following it (S1, S2, S3):
T : the term itself;
S : the stemmed version of the term, obtained
using a Porter stemmer;
P : the POS of the term, obtained using the Brill
Tagger;
H : the hypernym of the term, taken from Word-
Net (?O? if not available).
Features are prefixed with a proper composition
of the above labels in order to identify their role
in the sentence. Table 2 illustrates a sentence from
the training set and its extracted features.
219
If an entity is composed by k > 1 terms, entity-
specific features are generated for all the term n-
grams contained in the entity, for all n ? [1, ..., k].
E.g., for ?phone call? features are generated for
the n-grams: ?phone?, ?call?, ?phone call?.
In all the experiments described in this paper,
MP-BOOST has been run for S = 1000 iterations.
No feature weighting has been performed, since
MP-BOOST requires binary input only.
4 Classification model
The classification model we adopted in our exper-
iments splits the two tasks of recognizing the rela-
tion type and the one of determining the direction
of the relation in two well distinct phases.
4.1 Relation type determination
Given the training set Tr of all the sentences for
which the classifier outcome is known, vectorial
representations (see Section 3) are built in a way
that ?normalizes? the direction of the relation, i.e.:
? if the training object belongs to one of the
nine relevant relations, the features extracted
from the documents are given proper identi-
fiers in order to mark their role in the relation,
not the order of appearance in the sentence;
? if the training object belongs to Other the
two distinct vectorial representations are gen-
erated, one for relation Other(e
1
, e
2
) and one
for Other(e
2
, e
1
).
The produced training set has thus a larger num-
ber of examples than the one actually provided.
The training set provided for the task yielded 9410
training examples from the original 8000 sen-
tences. A 10-way classifier is then trained on the
vectorial representation.
4.2 Relation direction determination
The 10-way classifier is thus able to assign a rela-
tion, or the Other relation, to a sentence, but not to
return the direction of the relation. The direction
of the relation is determined at test time, by classi-
fying two instances of each test sentence, and then
combining the outcome of the two classifications
in order to produce the final classification result.
More formally, given a test sentence d belong-
ing to an unknown relation r, two vectorial repre-
sentations are built: one, d
1,2
, under the hypoth-
esis that r(e
1
, e
2
) holds, and one, d
2,1
, under the
hypothesis that r(e
2
, e
1
) holds.
Both d
1,2
and d
2,1
are classified by
?
?:
? if both classifications return Other, then d is
assigned to Other;
? if one classification returns Other and the
other returns a relation r, then r, with the
proper direction determined by which vec-
torial representation determined the assign-
ment, is assigned to d;
? if the two classifications return two relations
r
1,2
and r
2,1
different from Other (of the
same or of different relation type), then the
one that obtains the highest
?
? value deter-
mines the relation and the direction to be as-
signed to d.
5 Experiments
We have produced two official runs.
The ISTI-2 run uses the learner, vectorial rep-
resentation, and classification model described in
the previous sections.
The ISTI-1 run uses the same configuration of
ISTI-2, with the only difference being how the
initial distribution D
j
1
of the boosting method is
defined. Concerning this, we followed the ob-
servations of (Schapire et al, 1998, Section 3.2)
on boosting with general utility functions; the ini-
tial distribution in the ISTI-1 run is thus set to be
equidistributed between the portion Tr
+
j
of pos-
itive examples of the training set and the portion
Tr
?
j
of negative examples, for each class j, i.e.,
D
j
1
(d
i
) =
1
2|Tr
+
j
|
iff d
i
? Tr
+
j
(1)
D
j
1
(d
i
) =
1
2|Tr
?
j
|
iff d
i
? Tr
?
j
(2)
This choice of initial distribution, which gives
more relevance to the less frequent type of ele-
ments of the training set (namely, the positive ex-
amples), is meant to improve the performance on
highly imbalanced classes, thus improving effec-
tiveness at the the macro-averaged level.
We have also defined a third method for an addi-
tional run, ISTI-3; unfortunately we were not able
to produce it in time, and there is thus no offi-
cial evaluation for this run on the test data. The
method upon which the ISTI-3 run is based re-
lies on a more ?traditional? approach to the clas-
sification task, i.e., a single-label classifier trained
220
Run pi
?
?
?
F
?
1
pi
M
?
M
F
M
1
Official results
ISTI-1 72.01% 67.08% 69.46% 71.12% 66.24% 68.42%
ISTI-2 73.55% 63.54% 68.18% 72.38% 62.34% 66.65%
10-fold cross-validation
ISTI-1 73.60% 69.34% 71.41% 72.44% 68.17% 69.95%
ISTI-2 75.34% 65.92% 70.32% 73.96% 64.65% 68.52%
ISTI-3 68.52% 61.58% 64.86% 66.19% 59.75% 62.31%
Table 3: Official results (upper part), and results of the three relation classification methods when used in
a 10-fold cross-validation experiment on training data (lower part). Precision, recall, and F
1
are reported
as percentages for more convenience.
on the nine relations plus Other, not considering
the direction, coupled with nine binary classifiers
trained to determined the direction of each rela-
tion. We consider this configuration as a reason-
able baseline to evaluate the impact of the original
classification model adopted in the other two runs.
Table 3 summarizes the experimental results.
The upper part of the table reports the official re-
sults for the two official runs. The lower part
reports the results obtained by the three rela-
tion classification methods when used in a 10-
fold cross-validation experiment on the training
data. The evaluation measures are precison (pi),
recall (?), and the F
1
score, computed both in
a microaveraged (?
?
) and a macroaveraged
(?
M
) way (Yang, 1999).
The results for ISTI-1 and ISTI-2 in the 10-fold
validation experiment are similar both in trend and
in absolute value to the official results, allowing
us to consider the ISTI-3 results in the 10-fold
validation experiment as a good prediction of the
efficacy of the ISTI-3 method on the test data.
The classification model of ISTI-2, which uses
an initial uniform distribution for the MP-BOOST
learner as ISTI-3, improves F
M
1
over ISTI-3 by
9.97%, and F
?
1
by 8.42%.
The use of aF
1
-customized distribution in ISTI-
1 results in a F
1
improvement with respect to
ISTI-2 (F
M
1
improves by 2.66% in official re-
sults, 2.09% in 10-fold validation results), which
is mainly due to a relevant improvement in recall.
Comparing ISTI-1 with ISTI-3 the total im-
provement is 12.26% for F
M
1
and 10.10% for F
?
1
.
6 Conclusion and future work
The original relation classification model we have
adopted has produced a relevant improvement in
efficacy with respect to a ?traditional? approach.
We have not focused on the development of a
rich set of features. In the future we would like to
apply our classification model to the vectorial rep-
resentations generated by the other participants, in
order to evaluate the distinct contributions of the
feature set and the classification model.
The use of a F
1
-customized initial distribution
for the MP-BOOST learner has also produced a
relevant improvement, and it will be further inves-
tigated on more traditional text classification tasks.
References
Andrea Esuli, Tiziano Fagni, and Fabrizio Sebastiani.
2006. MP-Boost: A multiple-pivot boosting al-
gorithm and its application to text categorization.
In Proceedings of the 13th International Sympo-
sium on String Processing and Information Retrieval
(SPIRE?06), pages 1?12, Glasgow, UK.
Roxana Girju, Preslav Nakov, Vivi Nastase, Stan Sz-
pakowicz, Peter Turney, and Deniz Yuret. 2007.
Semeval-2007 task 04: Classification of semantic
relations between nominals. In Proceedings of the
Fourth International Workshop on Semantic Evalu-
ations (SemEval-2007), pages 13?18, Prague, CZ.
Association for Computational Linguistics.
Iris Hendrickx, Su Nam Kim, Zornitsa Kozareva,
Preslav Nakov, Diarmuid
?
O S?eaghdha, Sebastian
Pad?o, Marco Pennacchiotti, Lorenza Romano, and
Stan Szpakowicz. 2010. Semeval-2010 task 8:
Multi-way classification of semantic relations be-
tween pairs of nominals. In Proceedings of the 5th
SIGLEX Workshop on Semantic Evaluation, Upp-
sala, Sweden.
Robert E. Schapire and Yoram Singer. 2000. Boostex-
ter: A boosting-based system for text categorization.
Machine Learning, 39(2/3):135?168.
Robert E. Schapire, Yoram Singer, and Amit Singhal.
1998. Boosting and rocchio applied to text filtering.
In SIGIR ?98: Proceedings of the 21st annual inter-
national ACM SIGIR conference on Research and
development in information retrieval, pages 215?
223, New York, NY, USA. ACM.
Yiming Yang. 1999. An evaluation of statistical ap-
proaches to text categorization. Information Re-
trieval, 1(1/2):69?90.
221
