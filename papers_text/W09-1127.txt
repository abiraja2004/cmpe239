Proceedings of the Thirteenth Conference on Computational Natural Language Learning (CoNLL), pages 219?227,
Boulder, Colorado, June 2009. c?2009 Association for Computational Linguistics
New Features for FrameNet ? WordNet Mapping
Sara Tonelli and Daniele Pighin
FBK-Irst, Human Language Technologies
Via di Sommarive, 18 I-38100 Povo (TN) Italy
{satonelli,pighin}@fbk.eu
Abstract
Many applications in the context of natural
language processing or information retrieval
may be largely improved if they were able to
fully exploit the rich semantic information an-
notated in high-quality, publicly available re-
sources such as the FrameNet and the Word-
Net databases. Nevertheless, the practical use
of similar resources is often biased by the
limited coverage of semantic phenomena that
they provide.
A natural solution to this problem would be to
automatically establish anchors between these
resources that would allow us 1) to jointly use
the encoded information, thus possibly over-
coming limitations of the individual corpora,
and 2) to extend each resource coverage by ex-
ploiting the information encoded in the others.
In this paper, we present a supervised learn-
ing framework for the mapping of FrameNet
lexical units onto WordNet synsets based on
a reduced set of novel and semantically rich
features. The automatically learnt mapping,
which we call MapNet, can be used 1) to ex-
tend frame sets in the English FrameNet, 2)
to populate frame sets in the Italian FrameNet
via MultiWordNet and 3) to add frame labels
to the MultiSemCor corpus. Our evaluation on
these tasks shows that the proposed approach
is viable and can result in accurate automatic
annotations.
1 Introduction
In recent years, the integration of manually-built
lexical resources into NLP systems has received
growing interest. In particular, resources annotated
with the surface realization of semantic roles, like
FrameNet (Baker et al, 1998) or PropBank (Palmer
et al, 2005) have shown to convey an improve-
ment in several NLP tasks, from question answer-
ing (Shen and Lapata, 2007) to textual entailment
(Burchardt et al, 2007) and shallow semantic pars-
ing (Giuglea and Moschitti, 2006). Nonetheless, the
main limitation of such resources is their poor cov-
erage, particularly as regards FrameNet. Indeed, the
latest FrameNet release (v. 1.3) contains 10,195 lex-
ical units (LUs), 3,380 of which are described only
by a lexicographic definition without any example
sentence. In order to cope with this lack of data, it
would be useful to map frame information onto other
lexical resources with a broader coverage. We be-
lieve that WordNet (Fellbaum, 1998), with 210,000
entries in version 3.0, can represent a suitable re-
source for this task. In fact, both FrameNet and
WordNet group together semantically similar words,
and provide a hierarchical representation of the lex-
ical knowledge (in WordNet the relations between
synsets, in FrameNet between frames, see Ruppen-
hofer et al (2006)). On the other hand, WordNet
provides a more extensive coverage particularly for
adjectives and nouns denoting artifacts and natural
kinds, that are mostly neglected in FrameNet.
In this paper, we present an approach using Sup-
port Vector Machines (SVM) to map FrameNet lex-
ical units to WordNet synsets. The proposed ap-
proach addresses some of the limitations of previous
works on the same task (see for example De Cao
et al (2008) and Johansson and Nugues (2007)).
Most notably, as we do not train the SVM on a per-
219
frame basis, our model is able to cope also with
those frames that have little or no annotated sen-
tences to support the frame description. After learn-
ing a very fast model on a small set of annotated
lexical unit-synset pairs, we can automatically es-
tablish new mappings in never-seen-before pairs and
use them for our applications. We will evaluate the
effect of the induced mappings on two tasks: the au-
tomatic enrichment of lexical unit sets in the English
and Italian FrameNet via MultiWordNet (Pianta et
al., 2002), and the annotation of the MultiSemCor
corpus (Bentivogli and Pianta, 2005) with frame la-
bels.
The discussion is structured as follows: in
Section 2 we review the main characteristics of
FrameNet and WordNet; in Section 3 we discuss
previous attempts to establish a mapping between
them; in Section 4 we describe our supervised ap-
proach to map lexical units onto synsets; Section 5
details the dataset that we employed for our experi-
ments; Section 6 describes the novel features that we
used to characterize the mapping; Section 7 details
the results of our experiments; in Section 8 we ap-
ply the mapping to three resource annotation tasks;
finally, in Section 9 we draw our conclusions.
2 FrameNet and WordNet
The FrameNet database (Baker et al (1998), Fill-
more et al (2003)) is an English lexical resource
based on the description of some prototypical sit-
uations, the frames, and the frame-evoking words
or expressions associated to them, the lexical units
(LU). Every frame corresponds to a scenario involv-
ing a set of participants, the frame elements (FEs),
that are typically the semantic arguments shared by
all LUs in a frame.
We report in Table 1 the information recorded
in FrameNet for the CAUSE TO WAKE frame. In
the first row there is the frame definition with the
relevant frame elements, namely AGENT, CAUSE,
SLEEPER and SLEEP STATE. Then there is the list
of all lexical units evoking the frame and the corre-
sponding part of speech. Note that, differently from
WordNet synsets, a frame can contain LUs with dif-
ferent PoS as well as antonymous words. In the
last row, an example for each frame element is re-
ported. The lexical unit is underlined, while the con-
Frame: CAUSE TO WAKE
De
f. An AGENT or CAUSE causes a SLEEPER totransition from the SLEEP STATE to wakeful
consciousness.
LU
s awaken.v, get up.v, rouse.v, wake.v, wake up.v
singe.v, sizzle.v, stew.v
FE
s AGENT We tried to rouse Peter.
CAUSE The rain woke the children.
SLEEPER Neighbors were awakened by screams.
SL STATE He woke Constance from her doze.
Table 1: Frame CAUSE TO WAKE
stituent bearing the FE label is written in italics. The
FrameNet resource is corpus-based, i.e. every lexi-
cal unit should be instantiated by at least one ex-
ample sentence. Besides, every lexical unit comes
with a manual lexicographic definition. The latest
database release contains 795 frame definitions and
10,195 lexical units, instantiated through approxi-
mately 140.000 example sentences. Despite this, the
database shows coverage problems when exploited
for NLP tasks, and is still being extended by the
Berkeley group at ICSI.
WordNet (Fellbaum, 1998) is a lexical resource
for English based on psycholinguistics principles
and developed at Princeton University. It has been
conceived as a computational resource aimed at im-
proving some drawbacks of traditional dictionaries
such as the circularity of definitions and the ambigu-
ity of sense references. At present, it covers the ma-
jority of nouns, verbs, adjectives and adverbs in the
English language, organized in synonym sets called
synsets, which correspond to concepts. WordNet
also includes a rich set of semantic relations across
concepts, such as hyponymy, entailment, antonymy,
similar-to, etc. Each synset is encoded as a set of
synomyms having the same part of speech and de-
scribed by a definition or gloss. In some cases, one
or more example sentences may also be reported.
The Princeton English WordNet has also been aug-
mented with domain labels (Magnini and Cavaglia`,
2000) that group synsets into homogeneous clusters
in order to reduce polysemy in the database.
We believe that mapping FrameNet LUs to Word-
Net synsets would have at least three different ad-
vantages: 1) for the English FrameNet, it would au-
tomatically increase the number of LUs for frame by
220
importing all synonyms from the mapped synset(s),
and would allow to exploit the semantic and lex-
ical relations in WordNet to enrich the informa-
tion encoded in FrameNet. This would help cop-
ing with coverage problems and disambiguating the
LU senses. 2) For WordNet, it would be possible
to add a semantic layer between the synset level
and the domain level represented by frame rela-
tions, and to enrich the synsets with a computa-
tional description of the situation they refer to to-
gether with the semantic roles involved. 3) Since
frames are mostly defined at conceptual level, the
FrameNet model is particularly suitable for cross-
lingual induction (Boas, 2005). In this framework,
the FrameNet-WordNet mapping could help mod-
elling frame-based resources for new languages us-
ing minimal supervision. In fact, the availability of
multilingual resources like MultiWordNet (Pianta et
al., 2002) and EuroWordNet (Vossen, 1998) allows
to easily populate frame sets for new languages with
reduced human effort and near-manual quality by
importing all lemmas from the mapped synsets.
3 Related work
Several experiments have been carried out to de-
velop a FrameNet-WordNet mapping and test its
applications. Shi and Mihalcea (2005) described
a semi-automatic approach to exploit VerbNet as a
bridge between FrameNet and WordNet for verbs,
using synonym and hyponym relations and simi-
larity between Levin?s verb classes and FrameNet
frames. Their mapping was used to develop a rule-
based semantic parser (Shi and Mihalcea, 2004) as
well as to detect target words and assign frames for
verbs in an open text (Honnibal and Hawker, 2005).
Burchardt et al (2005) presented a rule-based
system for the assignment of FrameNet frames by
way of a ?detour via WordNet?. They applied
a WordNet-based WSD system to annotate lexical
units in unseen texts with their contextually de-
termined WordNet synsets and then exploited syn-
onyms and hypernyms information to assign the best
frame to the lexical units. The system was inte-
grated into the SALSA RTE system for textual en-
tailment (Burchardt et al, 2007) to cope with sparse-
data problems in the automatic assignment of frame
labels.
Johansson and Nugues (2007) created a feature
representation for every WordNet lemma and used
it to train an SVM classifier for each frame that tells
whether a lemma belongs to the frame or not. The
best-performing feature representation was built us-
ing the sequence of unique identifiers for each synset
in its hypernym tree and weigthing the synsets ac-
cording to their relative frequency in the SemCor
corpus. They used the mapping in the Semeval-2007
task on frame-semantic structure extraction (Baker
et al, 2007) in order to find target words in open
text and assign frames.
Crespo and Buitelaar (2008) carried out an auto-
matic mapping of medical-oriented frames to Word-
Net synsets applying a Statistical Hypothesis Test-
ing to select synsets attached to a lexical unit that
were statistically significant using a given refer-
ence corpus. The mapping obtained was used
to expand Spanish FrameNet using EuroWordNet
(Vossen, 1998) and evaluation was carried out on the
Spanish lexical units obtained after mapping.
Given a set of lexical units, De Cao et al (2008)
propose a method to detect the set of suitable Word-
Net senses able to evoke a frame by applying a simi-
larity function that exploits different WordNet infor-
mation, namely conceptual density for nouns, syn-
onymy and co-hyponymy for verbs and synonymy
for adjectives. The mapping approach was applied
also to LU induction for the English FrameNet and
for Italian frames via MultiWordNet.
4 Problem formulation
Our objective is to be able to assign to every lex-
ical unit l, belonging to a frame Fi defined in the
FrameNet database, one or more WordNet senses
that best express the meaning of l. More specifically,
for every l ? Fi, we consider the set of all WordNet
senses where l appears, CandSet, and then find the
best WordNet sense(s) bests ? CandSet that express
the meaning of l.
For example, the lexical unit rouse.v belonging to
the CAUSE TO WAKE frame, is defined in FrameNet
as ?bring out of sleep; awaken?. Its CandSet com-
prises 4 senses1: 1# bestir, rouse (become active);
2# rout out, drive out, force out, rouse (force or
drive out); #3 agitate, rouse, turn on, charge, com-
1The gloss is reported between parenthesis
221
move, excite, charge up (cause to be agitated, ex-
cited or roused); #4 awaken, wake, waken, rouse,
wake up, arouse (cause to become awake or con-
scious). In this example, bests = {#4} for rouse.v
in CAUSE TO WAKE.
We aim at creating a mapping system that
can achieve a good accuracy also with poorly-
documented lexical units and frames. In fact, we be-
lieve that under real-usage conditions, the automatic
induction of LUs is typically required for frames
with a smaller LU set, especially for those with only
one element. In the FrameNet database (v. 1.3), 33
frames out of 720 are described only by one lex-
ical unit, and 63 are described by two. Further-
more, more than 3,000 lexical units are character-
ized only by the lexicographic definition and are
not provided with example sentences. For this rea-
son, we suggest an approach that makes also use
of usually unexploited information in the FrameNet
database, namely the definition associated to every
lexical unit, and disregards example sentences.
This is the main point of difference between
our and some previous works, e.g. Johansson and
Nugues (2007) and De Cao et al (2008), where un-
supervised approaches are proposed which strongly
rely either on the number of lexical units in a frame
or on the example sentences available for l in the
FrameNet corpus. We claim that the relative short
time necessary to annotate a small dataset of frame-
synset pairs will result in a more reliable mapping
system and, as a consequence, in consistent time
savings when we actually try to use the mappings
for some tasks. The ability to cope with different
cases while retaining a good accuracy will allow to
bootstrap the mapping process in many cases where
other approaches would have failed due to lack of
training data.
To this end, we can train a binary classifier
that, given l and CandSet, for each pair ?l, s?,
s ? CandSet, delivers a positive answer if s ?
bests, and a negative one otherwise. To follow on
the previous example, for rouse.v we would have
4 classifier examples, i.e. the pairs ?rouse.v,#1?,
?rouse.v,#2?, ?rouse.v,#3? and ?rouse.v,#4?. Of
these, only the last would be considered a positive
instance. As a learning framework, we decided to
use SVMs due to their classification accuracy and
robustness to noisy data (Vapnik, 1998).
5 Dataset description
In order to train and test the classifier, we created
a gold standard by manually annotating 2,158 LU-
synset pairs as positive or negative examples. We
don?t have data about inter-annotator agreement be-
cause the dataset was developed only by one annota-
tor, but De Cao et al (2008) report 0.90 as Cohen?s
Kappa computed over 192 LU-synset pairs for the
same mapping task. This confirms that senses and
lexical units are highly correlated and that the map-
ping is semantically motivated.
The annotation process can be carried out in rea-
sonable time. It took approximately two work days
to an expert annotator to manually annotate the
2,158 pairs that make up our gold standard. The lexi-
cal units were randomly selected from the FrameNet
database regardless of their part of speech or amount
of annotated data in the FrameNet database. For
each lexical unit, we extracted from WordNet the
synsets where the LU appears, and for each of them
we assigned a positive label in case the LU-synset
pairs share the same meaning, and a negative label
otherwise. Statistics about the dataset are reported
in Table 2.
N. of LU-synset pairs 2,158
N. of lexical units 617
Verbal lexical units 39%
Nominal lexical units 51%
Adjectival lexical units 9%
Adverbial lexical units <1%
Targeted frames 386
Pairs annotated as positive 32%
Pairs annotated as negative 68%
Average polysemy 3.49
LUs with one candidate synset 204
LUs with 10 or more cand. synsets 32
Table 2: Statistics on the dataset
The 386 frames that are present in the dataset rep-
resent about one half of all lexicalized frames in
the FrameNet database. This proves that, despite
the limited size of the dataset, it is well representa-
tive of FrameNet characteristics. This is confirmed
by the distribution of the part of speech. In fact,
in the FrameNet database about 41% of the LUs
222
are nouns, 40% are verbs, 17% are adjectives and
<1% are adverbs (the rest are prepositions, which
are not included in our experiment because they are
not present in WordNet). In our dataset, the per-
centage of nouns is higher, but the PoS ranking by
frequency is the same, with nouns being the most
frequent PoS and adverbs the less represented. The
average polysemy corresponds to the average num-
ber of candidate synsets for every LU in the dataset.
Note that the high number of lexical units with only
one candidate does not imply a more straightforward
mapping, because in some cases the only candidate
represents a negative example. In fact, a LU could
be encoded in a frame that does not correspond to
the sense expressed by the synset.
6 Feature description
For every LU-synset pair in the gold standard, we
extracted a set of features that characterize different
aspects of the mapping. In the remainder, we detail
the meaning as well as the feature extraction proce-
dure of each of them.
Stem overlap Both WordNet glosses and LU def-
initions in FrameNet are manually written by lex-
icographers. We noticed that when they share the
same sense, they show high similarity, and some-
times are even identical. For example, the defini-
tion of thicken in the Change of consistency frame
is ?become thick or thicker?, which is identical to
the WordNet gloss of synset n. v#00300319. The
thicken lemma occurs in three WordNet synsets, and
in each of them it is the only lemma available, so no
other information could be exploited for the sense
disambiguation.
We believe that this information could help in the
choice of the best candidate synset, so we stemmed
all the words in the synset gloss and in the lexical
unit definition and measured their overlap. As fea-
tures, we use the ratio between the number of over-
lapping words and the number of words in the defi-
nition, both for the gloss and the LU description.
Prevalent Domain and Synset Since a frame rep-
resents a prototypical situation evoked by the set
of its lexical units, our intuition is that it should
be possible to assign it to a WordNet domain, that
groups homogeneous clusters of semantically simi-
lar synsets (see Section 2).
Given the LU-synset pair ?l, s?, l ? Fi, s ?
CandSet, we extract all the lexical units in Fi and
then build a set AllCandSet of pairs ?sj , cj?, where
sj is a synset in which at least one li ? Fi appears,
and cj is the count of lexical units that are found in
sj .
We exploit the information conveyed by AllCan-
dSet in two ways: i) if there is a prevalent Word-
Net domain that characterizes the majority of the
synsets in AllCandSet, and s ? CandSet belongs
to that same domain, we add a boolean feature to
the feature vector representing ?l, s?; ii) if s is the
synset with the highest count in AllCandSet, i.e. if
s = sj and cj > ci??sj , cj? ? AllCandSet, i 6= j,
then we add another boolean feature to encode this
information.
Cross-lingual parallelism Our idea is that, if an
English lexical unit and its Italian translation belong
to the same frame, they are likely to appear also in
the same MultiWordNet synset, and the latter would
be a good candidate for mapping. In fact, in Multi-
WordNet the Italian WordNet is strictly aligned with
the Princeton WordNet 1.6, with synsets having the
same id for both languages, and also semantic re-
lations are preserved in the multilingual hierarchy.
Since no Italian FrameNet is available yet, we ex-
tended the parallel English-Italian corpus annotated
on both sides with frame information described in
Tonelli and Pianta (2008) by adding and annotating
400 new parallel sentences. The final corpus con-
tains about 1,000 pairs of parallel sentences where
the English and the Italian lexical unit belong to the
same frame.
Given a pair ?l, s?, we check if l appears also in
the corpus with the frame label Fi and extract its
Italian translation lit. If lit appears also in the Italian
version of synset s in MultiWordNet, we consider s
as a good candidate for the mapping of l and encode
this information as a binary feature.
Simple synset-frame overlap Intuitively, the
more lemmas a frame and a synset have in common,
the more semantically similar they are. In order to
take into account this similarity in our feature vec-
tor, given the pair ?l, s?, l ? Fi, we extract all lexical
units in Fi and all lemmas in s and we compute the
number of overlapping elements. Then we divide
223
the value by the number of synsets where the same
overlapping element(s) occur.
As an example, the words tank and tank car in
the Vehicle frame, occur together only in the fourth
synset related to tank, which therefore will have a
higher value for this feature.
Extended synset-frame overlap This feature is a
generalization of overlapping value described above.
In fact, we noticed that the hypernym information
in WordNet can help disambiguating the synsets.
Therefore, we take into account not only the over-
laps according to the previous criterion, but also the
number of overlapping words between the lexical
units in a frame and the hypernyms of a synset. For
example, the party.n lexical unit in the AGGREGATE
frame has 5 senses in WordNet. According to the
previous criterion, there is no overlap between the
LUs in the frame and the lemmas in any of the five
synsets. Instead, if we look at the direct hypernym
relation of party, we find that sense #3 is also de-
scribed as set, circle, band, that are also lexical units
of AGGREGATE.
In those cases where the hypernym relation is not
defined, e.g. adjectives, we used the similar-to rela-
tion.
7 Experimental setup and evaluation
To evaluate our methodology we carried out a 10-
fold cross validation using the available data, split-
ting them in 10 non-overlapping sets. For each itera-
tion, 70% of the data was used for training, 30% for
testing. All the splits were generated so as to main-
tain a balance between positive and negative exam-
ples in the training and test sets.
We used the SVM optimizer SVM-
Light2 (Joachims, 1999), and applied polynomial
kernels (poly) of different degrees (i.e. 1 through
4) in order to select the configuration with the best
generalization capabilities. The accuracy is mea-
sured in terms of Precision, Recall and F1 measure,
i.e. the harmonic average between Precision and
Recall. For the sake of annotation, it is important
that an automatic system be very precise, thus not
producing wrong annotations. On the other hand,
the higher the recall, the larger the amount of data
that the system will be able to annotate.
2Available at http://svmlight.joachims.org/
The macro-average of the classifier accuracy for
the different configurations is shown in Table 3. We
report results for linear kernel (i.e. poly 1), maxi-
mizing recall and f-measure, and for polynomial ker-
nel of degree 2 (i.e. poly 2), scoring the highest pre-
cision. In general , we notice that all our models
have a higher precision than recall, but overall are
quite balanced. Different polynomial kernels (i.e.
conjunction of features) do not produce very rele-
vant differences in the results, suggesting that the
features that we employed encode significant infor-
mation and have a relevance if considered indepen-
dently.
As a comparison, we also carried out the same
evaluation by setting a manual threshold and con-
sidering a LU-synset pair as a positive example if
the sum of the feature values was above the thresh-
old. We chose two different threshold values, the
first (Row 1 in Table 3) selected so as to have com-
parable precision with the most precise SVM model
(i.e. poly2), the second (Row 2) selected to have
recall comparable with poly1, i.e. the SVM model
with highest recall. In the former case, the model has
a recall that is less than half than poly2, i.e. 0.214
vs. 0.569, meaning that such model would establish
a half of the mappings while making the same per-
centage of mistakes. In the latter, the precision of
the SVM classifier is 0.114 points higher, i.e. 0.794
vs. 0.680, meaning the SVM can retrieve as many
mappings but making 15% less errors.
In order to investigate the impact of different fea-
tures on the classifier performance, we also consid-
ered three different groups of features separately:
the ones based on stem overlap, those computed
for prevalent domain and synset, and the features
for simple and extended frame ? synset overlap.
We did not take into account cross-lingual paral-
lelism because it is one single feature whose cover-
age strongly relies on the parallel corpus available.
As a consequence, it is not possible to test the fea-
ture in isolation due to data sparseness.
Results are shown in Table 3, in the second group
of rows. Also in this case, we carried out a 10-
fold cross validation using a polynomial kernel of
degree 2. The stem overlap features, which to our
best knowledge are an original contribution of our
approach, score the highest recall among the three
groups. This confirms our intuition that LU defini-
224
tions and WordNet glosses can help extending the
number of mapped LUs, including those that are
poorly annotated. For instance, if we consider the
KNOT CREATION frame, having only tie.v as LU,
the features about prevalent domain & synset and
about synset-frame overlap would hardly be infor-
mative, while stem overlap generally achieves a con-
sistent performance regardless of the LU set. In
fact, tie.v is correctly mapped to synset v#00095054
based on their similar definition (respectively ?to
form a knot? and ?form a knot or bow in?). Best
precision was scored by the feature group consider-
ing prevalent domain & synset, which are also new
features introduced by our approach. The positive
effect of combining all features is clearly shown by
comparing the results obtained with individual fea-
ture groups against the figures in the row labeled
poly2.
Prec. Recall F1
Man. thresh. (P) 0.789 0.214 0.337
Man. thresh. (F1) 0.680 0.662 0.671
Stem Overlap 0.679 0.487 0.567
Prev.Dom.& Syn. 0.756 0.434 0.551
Syn.- Frame Overlap 0.717 0.388 0.504
poly1 0.761 0.613 0.679
poly2 0.794 0.569 0.663
Table 3: Mapping evaluation
8 MapNet and its applications
Since we aim at assigning at least one synset to ev-
ery lexical unit in FrameNet, we considered all the
frames and for every LU in the database we created
a list of LU-synset pairs. We re-trained the clas-
sifier using the whole annotated gold standard and
classified all the candidate pairs. The mapping pro-
duced between the two resources, that we call Map-
Net, comprises 5,162 pairs. Statistics on MapNet are
reported in table 4.
About one thousand lexical units in FrameNet
have no candidate synsets because the lemma is not
present in WordNet. The remaining LUs have 3.69
candidate synsets each on average, similarly to the
average polysemy reported for the gold standard (see
Table 2). This confirms our hypothesis that the data
used for training are well representative of the char-
N. of LUs in FrameNet 10,100
N. of LUs with at least one syn.cand. 9,120
N. of LU-synset candidate pairs 33,698
N. of mapped pairs 5,162
Table 4: Statistics on the mapping
acteristics of the whole resource. We expect about
80% of these mappings to be correct, i.e. in line
with the precision of the classifier.
8.1 Automatic FrameNet extension
MapNet can be easily exploited to automatically ex-
tend FrameNet coverage, in particular to extend the
set of lexical units for each frame. In fact, we can
assume that all lemmas in the mapped synsets have
the same meaning of the LUs in the corresponding
frames. We use MapNet to extract from WordNet
the lemmas in the mapped synsets and add them to
the frames.
For English FrameNet, we can acquire 4,265 new
lexical units for 521 frames. In this way, we would
extend FrameNet size by almost 42%. In the ran-
dom evaluation of 100 newly acquired LUs belong-
ing to 100 different frames, we assessed a precision
of 78%. For the Italian side, we extract 6,429 lexi-
cal units for 561 frames. Since no Italian FrameNet
has been developed yet, this would represent a first
attempt to create this resource by automatically pop-
ulating the frames. We evaluate the content of 15
complete frames containing 191 Italian LUs. The
assigned LUs are correct in 88% of the considered
cases, which represent a promising result w.r.t. the
unsupervised creation of Italian FrameNet.
The difference in the evaluation for the two lan-
guages most likely lies in the smaller number of
synsets on the Italian side of MultiWordNet if com-
pared to the English, which results in less ambigu-
ity. Furthermore, we should consider that the task
for Italian is easier than for English, since in the for-
mer case we are building a resource from scratch,
while in the latter we are extending an already exist-
ing resource with lexical units which are most likely
peripheral with respect to those already present in
the database.
225
8.2 Frame annotation of MultiSemCor
MultiSemCor (Bentivogli and Pianta, 2005) is an
English/Italian parallel corpus, aligned at word
level and annotated with PoS, lemma and Word-
Net synsets. The parallel corpus was created start-
ing from the SemCor corpus, which is a subset of
the English Brown corpus containing about 700,000
running words. The corpus was first manually trans-
lated into Italian. Then, the procedure of transferring
word sense annotations from English to Italian was
carried out automatically.
We apply MapNet to enrich the corpus with frame
information. We believe that this procedure would
be interesting from different point of views. Not
only we would enrich the resource with a new anno-
tation layer, but we would also automatically acquire
a large set of English and Italian sentences having a
lexical unit with a frame label. For the English side,
it is a good solution to automatically extract a dataset
with frame information and train, for example, a ma-
chine learning system for frame identification. For
the Italian side, it represents a good starting point for
the creation of a large annotated corpus with frame
information, the base for a future Italian FrameNet.
MultiSemCor contains 12,843 parallel sentences.
If we apply MapNet to the corpus, we produce
27,793 annotated instances in English and 23,872 in
Italian, i.e. about two lexical units per sentence. The
different amount of annotated sentences depends on
the fact that in MultiSemCor some synset annota-
tions have not been transferred from English to Ital-
ian. From both sides of the resulting corpus, we
randomly selected 200 sentences labeled with 200
different frames, and evaluated the annotation qual-
ity. As for the English corpus, 75% of the sen-
tences was annotated with the correct frame label,
while on the Italian side they were 70%. This re-
sult is in line with the expectations, since Map-
Net was developed with 0.79 precision. Besides,
synset annotation on the English side of MultiSem-
Cor was carried out by hand, while annotation in
Italian was automatically acquired by transferring
the information from the English corpus (precision
0.86). This explains why the resulting annotation
for English is slightly better than for Italian. In some
cases, the wrongly annotated frame was strictly con-
nected to the right one, i.e. APPLY HEAT instead
of COOKING CREATION and ATTACHING instead
of INCHOATIVE ATTACHING.
9 Conclusions
We proposed a new method to map FrameNet LUs
to WordNet synsets using SVM with minimal super-
vision effort.
To our best knowledge, this is the only approach
to the task that exploits features based on stem over-
lap between LU definition and synset gloss and
that makes use of information about WordNet do-
mains. Differently from other models, the SVM
is not trained on a per-frame basis and we do not
rely on the number of the annotated sentences for a
LU in the FrameNet corpus, thus our mapping al-
gorithm performs well also with poorly-annotated
LUs. After creating MapNet, the mapping be-
tween FrameNet and WordNet, we applied it to three
tasks: the automatic induction of new LUs for En-
glish FrameNet, the population of frames for Italian
FrameNet and the annotation of the MultiSemCor
corpus with frame information. A preliminary eval-
uation shows that the mapping can significantly re-
duce the manual effort for the development and the
extension of FrameNet-like resources, both in the
phase of corpus annotation and of frame population.
In the future, we plan to improve the algorithm
by introducing syntactic features for assessing simi-
larity between LU definitions and WordNet glosses.
We also want to merge all information extracted and
collected for Italian FrameNet and deliver a seed
version of the resource to be validated. Finally, we
plan to extend the mapping to all languages included
in MultiWordNet, i.e. Spanish, Portuguese, Hebrew
and Romanian.
Acknowledgements
We thank Roberto Basili and Diego De Cao for shar-
ing with us their gold standard of frame ? synset
mappings.
226
References
Collin F. Baker, Charles J. Fillmore, and John B. Lowe.
1998. The Berkeley FrameNet Project. In Proceed-
ings of the 36th ACL Meeting and 17th ICCL Confer-
ence. Morgan Kaufmann.
Collin F. Baker, Michael Ellsworth, and Katrin Erk.
2007. SemEval-2007 Task 10: Frame Semantic Struc-
ture Extraction. In Proceedings of the Fourth Interna-
tional Workshop on Semantic Evaluations (SemEval-
2007), pages 99?104, Prague, CZ, June.
Luisa Bentivogli and Emanuele Pianta. 2005. Exploiting
Parallel Texts in the Creation of Multilingual Seman-
tically Annotated Resources: The MultiSemCor Cor-
pus. Natural Language Engineering, Special Issue on
Parallel Texts, 11(03):247?261, September.
Hans C. Boas. 2005. Semantic frames as interlingual
representations for multilingual lexical databases. In-
ternational Journal of Lexicography, 18(4):445?478.
Aljoscha Burchardt, Katrin Erk, and Annette Frank.
2005. A WordNet detour to FrameNet. In B. Fis-
seni, H. Schmitz, B. Schro?der, and P. Wagner, editors,
Sprachtechnologie, mobile Kommunikation und lingis-
tische Resourcen, Frankfurt am Main, Germany. Peter
Lang.
Aljoscha Burchardt, Nils Reiter, Stefan Thater, and An-
nette Frank. 2007. A semantic approach to textual
entailment: System evaluation and task analysis. In
Proceedings of Pascal RTE-3 Challenge, Prague, CZ.
Diego De Cao, Danilo Croce, Marco Pennacchiotti, and
Roberto Basili. 2008. Combining Word Sense and
Usage for modeling Frame Semantics. In Proceedings
of STEP 2008, Venice, Italy.
Mario Crespo and Paul Buitelaar. 2008. Domain-specific
English-to-Spanish Translation of FrameNet. In Proc.
of LREC 2008, Marrakech.
Christiane Fellbaum, editor. 1998. WordNet: An Elec-
tronic Lexical Database. MIT Press.
C.J. Fillmore, C.R. Johnson, and M. R. L. Petruck. 2003.
Background to FrameNet. International Journal of
Lexicography, 16:235?250, September.
Ana-Maria Giuglea and Alessandro Moschitti. 2006. Se-
mantic role labeling via FrameNet, VerbNet and Prop-
Bank. In Proceedings of the 21st International Con-
ference on Computational Linguistics and the 44th an-
nual ACL meeting, pages 929?936, Morristown, NJ,
US. Association for Computational Linguistics.
Matthew Honnibal and Tobias Hawker. 2005. Identify-
ing FrameNet frames for verbs from a real-text corpus.
In Proceedings of Australasian Language Technology
Workshop 2005.
Thorsten Joachims. 1999. Making large-scale sup-
port vector machine learning practical. In Bernhard
Scho?lkopf, Christopher J. C. Burges, and Alexander J
Smola, editors, Advances in kernel methods: support
vector learning, pages 169?184. MIT Press, Cam-
bridge, MA, USA.
R. Johansson and P. Nugues. 2007. Using WordNet to
extend FrameNet coverage. In Proc. of the Workshop
on Building Frame-semantic Resources for Scandina-
vian and Baltic Languages, at NODALIDA, Tartu.
Bernardo Magnini and Gabriela Cavaglia`. 2000. Inte-
grating Subject Field Codes into WordNet. In Pro-
ceedings of LREC 2000, pages 1413?1418, Athens,
Greece.
Martha Palmer, Daniel Gildea, and Paul Kingsbury.
2005. The Proposition Bank: An Annotated Corpus
of Semantic Roles. Computational Linguistics, 31.
Emanuele Pianta, Luisa Bentivogli, and Christian Gi-
rardi. 2002. MultiWordNet: developing an aligned
multilingual database. In First International Confer-
ence on Global WordNet, pages 292?302, Mysore, In-
dia.
Josef Ruppenhofer, Michael Ellsworth, Miriam R.L.
Petruck, Christopher R. Johnson, and Jan
Scheffczyk. 2006. FrameNet II: Ex-
tended Theory and Practice. Available at
http://framenet.icsi.berkeley.edu/book/book.html.
Dan Shen and Mirella Lapata. 2007. Using Semantic
Roles to Improve Question Answering. In Proceed-
ings of EMNLP and CONLL, pages 12?21, Prague,
CZ.
Lei Shi and Rada Mihalcea. 2004. Open Text Semantic
Parsing Using FrameNet and WordNet. In Proceed-
ings of HLT-NAACL 2004.
Lei Shi and Rada Mihalcea. 2005. Putting Pieces To-
gether: Combining FrameNet, VerbNet and WordNet
for Robust Semantic Parsing. In Proceedings of CI-
CLing 2005, pages 100?111. Springer.
Sara Tonelli and Emanuele Pianta. 2008. Frame Infor-
mation Transfer from English to Italian. In European
Language Resources Association (ELRA), editor, Pro-
ceedings of LREC 2008, Marrakech, Morocco.
Vladimir N. Vapnik. 1998. Statistical Learning Theory.
Wiley-Interscience.
Piek Vossen, editor. 1998. EuroWordNet: A Multilingual
Database with Lexical Semantic Networks. Springer,
October.
227
