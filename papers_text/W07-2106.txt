Proceedings of the 4th International Workshop on Semantic Evaluations (SemEval-2007), pages 476?479,
Prague, June 2007. c?2007 Association for Computational Linguistics
UofL: Word Sense Disambiguation Using Lexical Cohesion 
Yllias Chali  
        Department of Computer Science 
University of Lethbridge  
Lethbridge, Alberta, Canada, T1K 3M4 
chali@cs.uleth.ca 
Shafiq R. Joty 
Department of Computer Science 
University of Lethbridge  
Lethbridge, Alberta, Canada, T1K 3M4 
jotys@cs.uleth.ca 
 
 
Abstract 
One of the main challenges in the applica-
tions (i.e.: text summarization, question an-
swering, information retrieval, etc.) of 
Natural Language Processing is to deter-
mine which of the several senses of a word 
is used in a given context. The problem is 
phrased as ?Word Sense Disambiguation 
(WSD)? in the NLP community. This paper 
presents the dictionary based disambigua-
tion technique that adopts the assumption 
of one sense per discourse in the context of 
SemEval-2007 Task 7: ?Coarse-grained 
English all-words?.  
1 Introduction 
Cohesion can be defined as the way certain words 
or grammatical features of a sentence can connect 
it to its predecessors (and successors) in a text. 
(Halliday and Hasan, 1976) defined cohesion as 
?the set of possibilities that exist in the language 
for making text hang together?. Cohesion occurs 
where the interpretation of some element in the 
discourse is dependent on that of another. For ex-
ample, an understanding of the reference of a pro-
noun (i.e.: he, she, it, etc.) requires to look back to 
something that has been said before. Through this 
cohesion relation, two text clauses are linked to-
gether. 
Cohesion is achieved through the use in the text 
of semantically related terms, reference, ellipse and 
conjunctions (Barzilay and Elhadad, 1997). Among 
the different cohesion-building devices, the most 
easily identifiable and the most frequent type is 
lexical cohesion. Lexical cohesion is created by 
using semantically related words (repetitions, 
synonyms, hypernyms, hyponyms, meronyms and 
holonyms, glosses, etc.)  
Our technique used WordNet (Miller, 1990) as 
the knowledge source to find the semantic relations 
among the words in a text. We assign weights to 
the semantic relations. The technique can be de-
composed into two steps: (1) building a representa-
tion of all possible senses of the words and (2) dis-
ambiguating the words based on the highest score.  
The remainder of this paper is organized as fol-
lows. In the next section, we review previous work. 
In Section 3, we define the semantic relations and 
their weights. Section 4 presents our two step pro-
cedure for WSD. We conclude with the evaluation. 
2 Previous Work 
Lexical Chaining is the process of connecting se-
mantically related words, creating a set of chains 
that represent different threads of cohesion through 
the text (Galley and McKeown, 2003). This inter-
mediate representation of text has been used in 
many natural language processing applications, 
including automatic summarization (Barzilay and 
Elhadad, 1997; Silber and McCoy, 2003), informa-
tion retrieval (Al-Halimi and Kazman, 1998), and 
intelligent spell checking (Hirst and St-Onge, 
1998). 
Morris and Hirst (1991) at first proposed a man-
ual method for computing lexical chains and first 
computational model of lexical chains was intro-
duced by Hirst and St-Onge (1997). This linear-
time algorithm, however, suffers from inaccurate 
WSD, since their greedy strategy immediately dis-
ambiguates a word as it is first encountered. Later 
476
research (Barzilay and Elhadad, 1997) significantly 
alleviated this problem at the cost of a worse run-
ning time (quadratic); computational inefficiency is 
due to their processing of many possible combina-
tions of word senses in the text in order to decide 
which assignment is the most likely. Silber and 
McCoy (2003) presented an efficient linear-time 
algorithm to compute lexical chains, which models 
Barzilay?s approach, but nonetheless has inaccura-
cies in WSD. 
More recently, Galley and McKeown (2003) 
suggested an efficient chaining method that sepa-
rated WSD from the actual chaining. It performs 
the WSD before the construction of the chains. 
They showed that it could achieve more accuracy 
than the earlier ones. Our method follows the simi-
lar technique with some new semantic relations 
(i.e.: gloss, holonym, meronym). 
3 Semantic Relations 
We used WordNet2.11 (Miller, 1990) and eXtended 
WordNet (Moldovan and Mihalcea, 2001) as our 
knowledge source to find the semantic relations 
among the words in a context.  We assigned a 
weight to each semantic relation. The relations and 
their scores are summarized in the table 1. 
4 System Overview 
The global architecture of our system is shown in 
Figure 1. Each of the modules of the system is de-
scribed below. 
4.1 Context Processing 
Context-processing involves preprocessing the con-
texts using several tools.  We have used the follow-
ing tools:  
Extracting the main text: This module extracts 
the context of the target word from the source xml 
document removing the unnecessary tags and 
makes the context ready for further processing. 
 
Sentence Splitting, Text Stemming and 
Chunking: This module splits the context into sen-
tences, then stems out the words and chunks those. 
We used OAK systems 2  (Sekine, 2002) for this 
purpose.  
                                                 
1
 http://wordnet.princeton.edu/ 
2
 http://nlp.cs.nyu.edu/oak/ 
 
Candidate Words Extraction: This module ex-
tracts the candidate words (for task 7: noun, verb, 
adjective and adverb) from the chunked text. 
4.2 All Sense Representation 
Each candidate word is expanded to all of its 
senses. We created a hash representation to identify 
all possible word representations, motivated from 
Galley and McKeown (2003). Each word sense is 
inserted into the hash entry having the index value 
equal to its synsetID. For example, athlete and jock 
are inserted into the same hash entry (Figure 2). 
 
 
 
Figure 2.  Hash indexed by synsetID 
 
On insertion of the candidate sense into the hash 
we check to see if there exists an entry into the in-
dex value, with which the current word sense has 
one of the above mentioned relations. No disam-
biguation is done at this point; the only purpose is 
to build a representation used in the next stage of 
the algorithm. This representation can be shown as 
a disambiguation graph (Galley and McKeown, 
2003) where the nodes represent word instances 
with their WordNet senses and weighted edges 
connecting the senses of two different words repre-
sent semantic relations (Figure: 3). 
 
 
 
Figure 3. Partial Disambiguation graph, Bass has 
two senses, 1. Food related 2. Music instrument 
related sense. The instrument sense dominates over 
the fish sense as it has more relations (score) with 
the other words in the context. 
Athlete Jock 
Gymnast 
09675378 
10002518 
???
 
Hypernym/ 
Hyponym 
    
Bass   
Instrument sense 
sound 
property  
      Food sense 
Pitch 
Fish 
ground 
bass 
477
4.3 Sense Disambiguation 
We use the intermediate representation (disam-
biguation graph) to perform the WSD. We sum the 
weight of all edges leaving the nodes under their 
different senses. The one sense with the highest 
score is considered the most probable sense. For 
example in fig: 3 Bass is connected with three 
words: Pitch, ground bass and sound property by 
its instrument sense and with one word: Fish by its 
Food sense. For this specific example all the se-
mantic relations are of Hyponym/Hypernym type 
(score 0.33). So we get the score as in table 2.  
In case of tie between two or more senses, we 
select the one sense that comes first in WordNet, 
since WordNet orders the senses of a word by de-
creasing order of frequency. 
  
Sense Mne-
monic  
Score Disambigu-
ated Sense 
4928349 Musical 
Instru-
ment 
3*0.33
=0.99 
7672239 Fish or 
Food 
0.33 
Musical In-
strument 
(4928349) 
 
Table 2.  Score of the senses of word ?Bass? 
 
 
 
Relation Definition Example Weight 
Repetition Same occurrences of the word Weather is great in Atlanta. Florida is 
having a really bad weather. 
1 
Synonym Words belonging to the same syn-
set in WordNet 
Not all criminals are outlaws. 1 
Hypernym 
and Hypo-
nym 
Y is a hypernym of X if X is a 
(kind of) Y And 
X is a hyponym of Y if X is a (kind 
of) Y. 
Peter bought a computer. It was a Dell 
machine. 
0.33 
Holonym 
And 
Meronym 
Y is a holonym of X if X is a part 
of Y And  
X is a meronym of Y if X is a part 
of Y 
The keyboard of this computer is not 
working. 
0.33 
Gloss Definition and/or example sen-
tences for a synset. 
Gloss of word ?dormitory? is  
{a college or university building con-
taining living quarters for students} 
0.33 
 
      Table 1: The relations and their associated weights 
 
 
 
 
 
                               
   Figure 1: Overview of WSD System 
 
 
Context  
Processing 
Sense Disam-
biguation 
 
All Sense Represen-
tation 
Disambiguated  
Sense 
Candidate words 
Extraction 
Source Con-
text 
Chunked Text 
478
             
5 Evaluation 
In SemEval-2007, we participated in Task 7: 
?Coarse-grained English all-words?. The evalua-
tion of our system is given below: 
 
Cases Precision Recall F1-measure 
Average 0.52592 0.48744 0.50595 
Best 0.61408 0.59239 0.60304 
Worst 0.44375 0.41159 0.42707 
 
6 Conclusion 
In this paper, we presented briefly our WSD sys-
tem in the context of SemEval 2007 Task 7. Along 
with normal WordNet relations, our method also 
included additional relations such as repetition and 
gloss using semantically enhanced tool, eXtended 
WordNet. After disambiguation, the intermediate 
representation (disambiguation graph) can be used 
to build the lexical chains which in tern can be used 
as an intermediate representation for other NLP 
applications such as text summarization, question 
answering, text clustering. This method (summing 
edge weights in selecting the right sense) of WSD 
before constructing the chain (Gallery and McKe-
own, 2003) outperforms the earlier methods of 
Barzilay and Elhadad (1997) and Silber and 
McCoy (2003) but this method is highly dependent 
on the lexical cohesion among words in a context. 
So the length of context is an important factor for 
our system to achieve good performance. For the 
task the context given for a tagged word was not so 
large to capture the semantic relations among 
words. This may be the one of the reasons for 
which our system could not achieve one of the best 
results. 
 
References 
Barzilay, R. and Elhadad, M.  1997. Using Lexical 
Chains for Text Summarization. In Proceedings 
of the 35th Annual Meeting of the Association 
for Computational Linguistics and the 8th Euro-
pean Chapter Meeting of the Association for 
Computational Linguistics, Workshop on Intel-
ligent Scalable Test Summarization, pages 10-
17, Madrid. 
 
Chali, Y. and Kolla, M. 2004. Summarization 
techniques at DUC 2004. In Proceedings of the 
Document Understanding Conference, pages 
105 -111, Boston. NIST. 
 
Galley, M. and McKeown, K. 2003. Improving 
Word Sense Disambiguation in Lexical Chain-
ing. In Proceedings of the 18th International 
Joint Conference on Artificial Intelligence 
(IJCAI?03), pages 1486-1488, Acapulco, Mex-
ico. 
 
Halliday M. and Hasan R. 1976. Cohesion in Eng-
lish. Longman, London. 
 
Harabagiu S. and Moldovan D. 1998. WordNet: 
An Electronic Lexical Database, chapter Knowl-
edge Processing on an Extended WordNet. MIT 
press. 
 
Hirst G. and St-Onge D.  1997. Lexical Chains as 
representation of context for the detection and 
correction of malapropisms. In Christiane Fell-
baum, editor, WordNet: An Electronic Lexical 
Database and Some of its Applications. MIT 
Press, pages 305-332. 
 
Morris J. and Hirst. G. 1991, Lexical Cohesion 
Computed by Thesaural Relations as an Indica-
tor of the Structure of Text .Computational Lin-
guistics, 17(1):21-48. 
 
Silber H.G. and McCoy K.F. 2002. Efficiently Com-
puted Lexical Chains As an Intermediate Representa-
tion for Automatic Text Summarization. Computa-
tional Linguistics, 28(4):487-496. 
479
