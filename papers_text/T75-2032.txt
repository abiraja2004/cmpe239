REPRESENTATION OF KNOWLEDGE: 
NON-LINGUISTIC FORMS 
DO WE NEED IMAGES AND ANALOGUES? 
Zenon W. Pylyshyn 
Department of Psychology 
University of Western Ontario 
London, Canada 
I. OLD HOMONCULI NEVER DIE 
It is no accident that inside most 
psychological theories of representation we 
can, if we look closely enough, discern a 
small person with his eyes on a screen and 
his hands on the controls. The metaphor is 
so seductive that almost all theories of 
perception succumb to it (as Kaufman, 1974 
has noted in his recent review of theories 
in perception). True, we try to deliver the 
homonculus a better and more stable picture 
than falls on the eye of the larger person 
he is controll ing -- in fact we usually go 
to the trouble of presenting him with a 
three-dimensional model (often holographic), 
hoping to lighten his load, but the little 
man seems so friendly and familiar that we 
can't imagine how we could do without him. 
The dilemma this places us in goes back 
several millenia. It runs something like 
this. We need to have some internal 
representation of the world in order to 
think about it (indeed, in order to 
apprehend it at all). But if this internal 
representation is too similar to the world 
itself it cannot help us to apprehend it 
since it merely moves the same problem 
inside. On the other hand if it is too 
dissimilar then how can it represent the 
world at all? Epistemologists have squirmed 
under the horns of this dilemma trying by 
various means to make the problem disappear. 
Psychologists on the other hand have by and 
large dismissed the problem as old-fashioned 
(which it is) and have proceeded to be 
rigorous in their experimental analysis of 
the "functional role of images", Where 
images are not merely "pictures" but are 
artfully becoming much more fleeting and 
sketchy. Sometimes they are referred to as 
perceptual schemas, sometimes as "the 
activation of perceptual processes", and 
more recently as a~alo~ues. The little man 
for his part has been put in a black box 
where he continues to live under such guises 
as "the visual system" or as something which 
responds to the analogues by moving limbs or 
uttering sentences as required. This 
account is admittedly unfair to the many 
investigators who understand the basic 
problem quite well and are struggling to 
develop representation systems adequate to 
the task. But I believe that the caricature 
adequately characterizes the vast majority 
of psychological approaches to the 
phenomenon of so-called "non-verbal 
representation". 
I will confine my written remarks to a 
small subset of questions bearing on this 
dilemma. I would be glad to provide 
reprints of my other relevant papers on 
request. Primarily what I will try to do is 
160 
to point out that many of the ways of 
casting the problem of "alternative forms of 
representation,, are misguided and that by 
blurring certain distinctions and 
emphasizing others we may be burying the 
significant problems in a mire of catchwords 
(e.g., procedural embedding, analogical, 
holistic and even propositional -- which I 
now regret using because of the sentential 
connotations which, despite all my efforts, 
it continues to have). 
II. THE FUNCTION OF REPRESENTING: 
"RESEMBLING" OR "DESCRIBING"? 
Let us look at the representation 
dilemma again. It asked (in part) how an 
entity could represent some object if it was 
too dissimilar from that object. But this, 
like a great many other questions of this 
sort, already presupposes something crucial. 
We normally only speak about two things 
being similar if they are to be examined in 
the same way -- in particular if they are 
both to be viewed. Since we don't want to 
start off with this as the assumption (we 
might then ask "who does the viewing 
inside?") we should drop the idea that the 
representation literally rese~ the thing 
it represents (see Goodman, 1968, for more 
on this point). Well then can the 
representation be any arbitrary symbol? 
Clearly it cannot in general be an 
unstructured atomic symbol since then there 
would be no way to show that the thing 
represented had a structure -- i.e., had 
subparts, relations and attributes. So what 
constraints are there on the structure of 
the representation? Here the going gets 
tougher. One is tempted to give the 
recursive reply that it must have 
substructures, relations, properties, etc. 
which represent the substructures, relations 
and properties of the object(s) being 
represented. But here we have to be careful 
for two reasons. One reason is that if the 
representation maps all the structures, etc. 
of the object we will have an isomorphism 
which has all the disadvantages of the 
picture-in-the-head alternative. The 
representation must not only be highly 
partial but it must be partial in the 
appropriate way (see below). The other 
reason is that it is meaningless to speak of 
~he structure of the representation. 
Structure is relative to the processes which 
construct and use the representation. It is 
these processes which define the semantics 
of the representation: we may speak of the 
structure of a representation relative to a 
Semantic Interpretation Function (SIF). 
Thus the two distinct strings of symbols 
"not (P and q)" and "not-p or not-q" are 
identical structures from the point of view 
of a theorem prover and the distinct strings 
,w +, and "(LEFT-OF STAR PLUS)" may be 
identical structures from the point of view 
of some other SIF. Neglect of the SIF 
represents one of the most ubiquitous 
sources of confusion in discussions about 
representation. It leads some people, for 
example, to assert that non-llngulstic 
representations "preserve the structure of 
that which they represent". They do so of 
course only to the extent that the "same 
I 
I 
I 
I 
I 
I 
I 
I 
I 
I 
I 
I 
I 
I 
I 
I 
I 
I 
I 
structure" is extracted bysome appropr iate 
SIF. In that sense the sentence "the book 
is on the table" can be said to preserve 
part of the structure of a scene containing 
a book on a table. To be sure the latter 
has a lot more structure as well but so does 
the sentence (it has order, length, color, 
etc.). It is up to the SIF to pick out 
those aspects which are signifying from 
those that are not and to process the str ing 
(in the appropr iate contexts) as it would 
the scene. Without knowing what the SIF did 
we could not speak of structural similarity. 
I don't mean to imply by this example that 
sentences provide an adequate representat ion 
of scenes (they don't for other reasons) but 
only that the di f ferences are more subtle 
than captured in the simple claim that the 
scene  and the sentence have dif ferent 
structures. At this level all we can say is 
that they don't "resemble" one another. 
One can of course remove much of the 
arbitrar iness in the above character izat ion 
of the structure of representatons by 
requir ing that the SIF be perceptual in 
nature -- i.e., by assuming that the SIF has 
much in common with visual perception. 
There is a good deal of psychological  
evidence suggesting that imaging and 
perceiving are similar in many ways. 
Although this seems like a reasonable 
proposal it creates many problems and must 
be approached with care. It is tempting to 
"explain" aspects of cognit ion (e.g., 
Moyer's (1973) account of magnftude 
judgments from memory) by pointing out that 
they are "like" their perceptual  
counterparts in respect to such measures as 
reaction time. But since we have no idea of 
how the latter is accompl ished this is a 
case of "obscurum per obscurus". 
Furthermore to note that some cognit ive 
operations bear a (not yet well understood) 
relation to perception is in no sense 
evidence that these cognit ive operatons 
involve pictorial  or analogical or any other 
entit ies which resemble objects in the 
environment. Presumably perception involves 
the construct ion and processing of internal 
representatons Just as does imaging so some 
relations between the two should not be too 
surprising. Furthermore there are some 
major di f ferences as well. These  are 
related to the fact that objects in the 
environment have a stable existence so they 
can be re-examined and to the fact that 
transformations of internal objects (such as 
those studied by Shepard) depend on the 
person's tacit knowledge concerning 
permissible transformations.  The way in 
which this knowledge must be brought to 
bear -- and not intr insic propert ies of the 
representat ion (i.e., not the r igidity of 
patterns being mental ly rotated) are what 
must account for experimental  results on 
mental t ransformat ions (we shall return to 
this point in section III). 
But perhaps the main argument against 
the view that the SIF is 
perceptual -- assuming that we can specify 
what we mean by perceptual  in other than 
hand-waving terms -- is that it implies that 
the representat ion to which it is appl ied is 
something capable of being perceived. 
Unfortunately no matter how hard we try to 
make it sound like we are avoiding pictures 
(or worse, objects) in the head there is no 
coherent intermediate ground: if the SIF has 
perceptual pr imit ives (e.g., operations such 
as those studied in vision for feature 
detection, etc.) it must be applied to 
something which, however fleeting, sketchy, 
vague, dynamic, etc. is still pictorial  or 
isomorphic in a sense which is incompatible 
with the facts of human memory and 
cognition. I want to make it clear that I 
don't object to the rei f icat ion of pictures 
or some such analogues on ontological  
grounds, but simply on the grounds that such 
objects as a class have the wrong 
properties. Our representat ions of the 
visual world are not like any (degraded, 
topological ly  transformed, filtered, etc.) 
project ion of proximal stimulation: they are 
constructed from aspects of the world which 
we not ic~ (and such aspects can be global, 
abstract and highly cognit ive -- i.e., 
knowledge-dr iven and assimi lated into 
avai lable conceptual  categories) and they 
represent equivalence-c lasses of stimuli 
which are physical ly very different from 
each other and from any conceivable 
picture- l ike entity. For example I might 
notice shapes (or at least a class of 
shapes) but not colors, objects but not 
locations, and non-sensory relat ions such as 
causality, potential  actions, intensions, 
etc. Such representatons, derived from 
visual perception, cannot be sharply 
dist inguished from knowledge derived by  
other means; that is why I prefer to refer 
to them as "structured descriptions". The 
vocabulary of such descr ipt ions and the 
accessib i l i ty  relat ions may be quite 
different from that of l inearly ordered 
utterances. Such "visual images" are in 
some ways more like models than logical 
statements insofar as they may not contain 
quanti f iers (at least the current 
computat ional  models of imagery do 
not -- e.g., Baylor 1972, Moran 1973). 
Images in such an approach are data 
structures in which objects are indiv iduated 
(i.e., there is no node for "seven blocks"), 
contain many "default" attr ibutes and 
typical ly use spatial  relat ions as access 
paths. Yet in my view it is more 
appropr iate to refer to them as descr ipt ions 
than images because the term is less 
mis leading since they consist of conceptual  
structures very much like those constructed 
when the input is l inguist ic -- except 
perhaps using a modal i ty-specl f lc  vocabulary 
of symbols. One cannot of course rule out 
the possibi l i ty that there are cognit ive ly  
functional aspects of percepts which cannot 
be captured in such a discrete symbol 
system, but I have yet to hear a persuasive 
argument for that case. Furthermore, I have 
argued elsewhere (Pylyshyn, 1973) that there 
are many conceptual  traps await ing those who 
talk in terms of stor ing and using images. 
III. ANALOGICAL AGAIN 
The most common proposal for an 
alternat ive form of representat ion for 
perceptual ly  derived knowledge is that it is 
analogica l .  This term has become the new 
161 
buzzword in cognit ive psyoh61ogy and is used 
as a synonym for anythlng from "warm and 
cuddly" through "holistic", "continuous" , or 
simply "anything which is not 
language-l ike".  Few psychologists have 
tried to be very specif ic in character iz ing 
the meaning of this term. When people have 
tried to be expl ic it  (as, for example, 
Sloman 1971; Block and Fodor 1973; Lewis 
1971, Goodman 1968) they have found it to be 
a very diff icult concept to character ize and 
have had to d ist inguish several di f ferent 
senses in which the term is used. I hate 
discussed some of these elsewhere (Pylyshyn, 
in press) so I will not repeat myself  here. 
I want merely to add to what I have wr i t ten 
some discussion of why people may be tempted 
to reach  for analogues to account for 
certain psychological  evidence, and to 
suggest why such entit ies whatever they may 
be, fall short of serving the function 
expected of them. 
As a psychologist  one of the main 
object ions that I have to the whole notion 
of analogue representat ion is that it seems 
to me to be a convenient way of hiding a 
large part of the problem we are trying to 
explain -- i.e., how people represent and 
reason about objects and actions. You may 
recall  being at least mildly surprised that 
there is such a thing as a "frame problem" 
in reasoning about actions (McCarthy and 
Hayes, 1969; Simon, 1972). The reason ~hat 
it never occurred to many of us that there 
was a problem is that when we interact with 
the environment (as opposed to th inking 
about it) the laws of physics take care of 
all the relevant interact ions among 
events -- we don't have to worry about 
over looking what wil l  happen to evrything 
else in the world when we carry out some 
action on a part of it. Such relations are 
given to us free by the environment. In the 
case of reasoning, however, the relat ions 
are not free. We must in some way 
expl ic i t ly  build in the knowledge regarding 
what effects do and don't fol low from any 
action. Now it seems to me that the notion 
of an analogue representat ion is in part an 
attempt to get this information for free 
again. Thus the claim that data on the 
t ime-course of mental  rotat ion (c.f., Cooper 
and Shepard, 1973) argues that the process 
is analogue (since, as the proponents 
innocent ly  ask "how can you rotate a data 
structure through its intermediate 
posit ions?") .  This carr ies the impl icat ion 
that once we start a rotation the medium 
wil l  take care of mainta in ing the r ig idity 
of the total pattern and carry along all the 
parts for us -- just as the laws of physics 
take care of this for us in the real 
environment.  But, as in the frame problem, 
we are over looking the fact that the person 
(or the robot) must know what wil l  and wil l  
not happen to the bottom part when the top 
part starts to rotate. In a descr ipt ive 
structure this is precisely what makes 
"mental rotat ion" appear awkward and 
computat ional ly  unduly costly. But this is 
unavoidable unless we have an analogical  
model l ing medium which intr ins ica l ly  fol lows 
the laws of physics. Unless we are wi l l ing 
to ascr ibe such laws to brain t issue (which, 
by the way, is what Gestalt psychologists  
162 
attempted to do) we are stuck with locat ing 
it in what I have called the SIF (which does 
not, incidental ly,  preclude it from being a 
distr ibuted computat ion attached to the data 
structure itself). If we admit this, 
however, there appears l ittle reason to call 
the result ing representat ional  system 
analogical  (though Shepard's use of the term 
is, by his own admission, broad enough to 
cover this case). 
Another example where analogues are 
invoked in a s imi lar role is for the 
representat ion of magnitudes. When we 
"mental ly compare" two objects -- say a dog 
and a horse -- to judge which is larger, the 
answer seems immediate and intu i t ive ly  
appears to depend on a comparison of two 
images or some sort of "analogues". Now we 
have some idea of what sort of operat ion is 
involved when two physical  objects are 
compared by placing them side-by-side.  
Again the laws of physics and optics assure 
us that, as in the frame problem, the right 
things wil l  happen (e.g., the object sizes 
wil l  remain fixed as they are moved, the 
smal ler object wil l  part ia l ly  occlude the 
larger, etc.). But in the mental  compar ison 
case we somehow feel that the analogues wil l  
"do the right thing" because  of intr ins ic  
propert ies of the analogue medium, just as 
in the mental  rotat ion example we feel that 
analogues wil l  intr ins ica l ly  maintain their 
form in a rigid manner during rotation. In 
the mental  compar ison case the assumption is 
that if the process is analogue, the SIF 
does not need to "know" the rules of 
t ransformat ion nor does it need to "know" 
about order re lat ions -- e.g., that such 
relat ions are asymmetr ic  and 
transi t ive -- since it has merely to "read 
off" the answer from the analogue. The 
representat ion again seems to have the 
answer "written on its sleeve". Thus by 
at t r ibut ing such propert ies to the intr ins ic  
nature of the representat ion we beg the very 
quest ion of how magnitudes are encoded and 
compared. 
The phenomenon of at t r ibut ing to the 
intr ins ic  nature of a representat ion some of 
the crucial  aspects that need to be taken 
into account (because these are so 
intu i t ive ly  obvious to the theorist) is not 
confined to analogical  representat ions.  
Woods (1975) has recent ly  shown that we 
frequent ly commit the same oversight in the 
case of semantic networks. This is why it 
is important to attempt to s imulate a 
s igni f icant port ion of cognit ion by machine 
(although even here the existence of such 
bui lt - in funct ions as an ar i thmet ic  
processor may create the i l lus ion that we 
get magnitudes for free -- i.e., we need not 
model them in detail). 
In conclus ion let me reiterate that I 
don't c laim to have made an argument against 
analogical  modes of representat ion -- and 
sti l l  less that I am sat isf ied that semantic 
networks, procedures, etc. are adequate to 
handle all forms of knowledge. I have 
simply tried to argue that many of the 
reasons people have for Jumping on the 
"non- l inguist lc"  (whatever that may be) 
bandwagon are insuff ic ient.  Furthermore we 
I 
I 
I 
I 
I 
I 
I 
I 
I 
i 
I 
I 
I 
I 
i 
i 
i 
i 
I 
are so far from understanding the semantics 
of discrete data structures (as Woods has 
cogently argued) that any mass movement to 
abandon them (or even augment them with 
something radically different) is at the 
very least premature. 
REFERENCES 
Baylor, G.W., A treatise on the mind's eye: 
An empirical investigation of visual 
mental imagery. (Doctoral dissertation, 
Carnegie-Mellon University) Ann Arbor, 
Mich.: University Microfilms 1972. No. 
72-13, 699. 
Block, N.J., & Foder, J.A., Cognitivism and 
the  analog/digital distinction, Mimeo, 
MIT, 1973. 
Cooper, L.A., & Shepard, R.N., Chronometric 
studies of the rotation of mental images. 
In W.G. Chase (Ed.), Visua~ infor~atiQn 
processing. New York: Academic Press, 
1973. 
Kaufman, L., Sight and Mind, New York: 
Oxford University Press, 1974. 
Lewis, D., Analog and digital. Nous, 1971, 
321-327. 
McCarthy, J. & Hayes, P., Some 
philosophical problems from the 
standpoint of artificial intelligence. 
In B. Meltzer & D. Michie (Eds.) 
Machine Inte&llgence ~, Edinburgh: 
University of Edinburgh Press, 1969. 
Moran, T., The symbolic imagery hypothesis: 
a production system model. Unpublished 
Ph.D. dissertation, Carnegie-Mellon 
University, 1973. 
Moyer, R.S., Comparing objects in memory: 
evidence suggesting an internal 
psychophysics. P~r~eption 
Ps?chophysics, 1973, 13, 180-184. 
Pylyshyn, Z.W., What the mind's eye tells 
the mind's brain: a critique of mental 
imagery. Psychological Bulletin, 1973, 
13, 1-24. 
Pylyshyn, Z.W., The symbolic nature of 
mental representaions. In S. Kaneff and 
J.E. O'Callaghan (Eds.) Obieetives aqd 
Methodologies in Artificial Iqte&ligen9e. 
New York: Academic Press (in press). 
Simon, H.A., On reasoning about actions. In 
H.A. Simon and L. Siklossy (Eds.) 
ReDresentation ~d meaning. Englewood 
Cliffs, NJ: Prentice-Hall, 1972. 
Woods, W., What's in a link: foundations for 
semantic networks. In D. Bobrow and A. 
Collins (Eds.), ReDresentatio~ aq~ 
~ndrstanding: studies in cogpi~ive 
science, New York: Academic Press, 1975. 
163 
