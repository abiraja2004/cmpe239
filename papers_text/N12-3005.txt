Proceedings of the NAACL-HLT 2012: Demonstration Session, pages 17?20,
Montre?al, Canada, June 3-8, 2012. c?2012 Association for Computational Linguistics
An Interactive Humanoid Robot Exhibiting Flexible Sub-Dialogues?
Heriberto Cuaya?huitl
DFKI GmbH
hecu01@dfki.de
Ivana Kruijff-Korbayova?
DFKI GmbH
ivana.kruijff@dfki.de
Abstract
We demonstrate a conversational humanoid
robot that allows users to follow their own
dialogue structures. Our system uses a hi-
erarchy of reinforcement learning dialogue
agents, which support transitions across
sub-dialogues in order to relax the strict-
ness of hierarchical control and therefore
support flexible interactions. We demon-
strate our system with the Nao robot play-
ing two versions of a Quiz game. Whilst
language input and dialogue control is au-
tonomous or wizarded, language output is
provided by the robot combining verbal and
non-verbal contributions. The novel fea-
tures in our system are (a) the flexibility
given to users to navigate flexibly in the in-
teraction; and (b) a framework for investi-
gating adaptive and flexible dialogues.
1 Introduction
Hierarchical Dialogue Control (HDC) consists of
behaviours or discourse segments at different lev-
els of granularity executed from higher to lower
level. For example, a dialogue agent can invoke a
sub-dialogue agent, which can also invoke a sub-
sub-dialogue agent, and so on. Task-oriented di-
alogues have shown evidence of following hierar-
chical structures (Grosz and Sidner, 1986; Litman
and Allen, 1987; Clark, 1996). Practically speak-
ing, HDC offers the following benefits. First,
modularity helps to specify sub-dialogues that
may be easier to specify than the entire full dia-
logues. Second, sub-dialogues may include only
relevant dialogue knowledge (e.g. subsets of dia-
logue acts), thus reducing significantly their com-
?*Funding by the EU-FP7 project ALIZ-E (ICT-248116)
is gratefully acknowledged.
(a) strict hierachical 
     dialogue control
Dialogue
Sub-dialogue1 Sub-dialogue2
(b) flexible hierachical 
  dialogue control
Dialogue
Sub-dialogue1 Sub-dialogue2
Figure 1: Hierarchies of dialogue agents with strict
(top down) and flexible control (partial top down).
plexity. Third, sub-dialogues can be reused when
dealing with new behaviours. In this paper we dis-
tinguish two types of hierarchical dialogue con-
trol: strict and flexible. These two forms of dia-
logue control are shown in Figure 1. It can be ob-
served that strict HDC is based on a pure top down
execution, and flexible HDC is based on a com-
bined hierarchical and graph-based execution.
The main limitation of strict HDC is that
human-machine interactions are rigid, i.e. the
user cannot change the imposed dialogue struc-
ture. A more natural way of interaction is by re-
laxing the dialogue structure imposed by the con-
versational machine. The advantage of flexible
HDC is that interactions become less rigid be-
cause it follows a partially specified hierarchical
control, i.e. the user is allowed to navigate across
the available sub-dialogues. In addition, another
important property of the latter form of HDC is
that we can model flexible dialogue structures not
only driven by the user but also by the machine.
The latter requires the machine to learn the dia-
logue structure in order to behave in an adaptive
way. The rest of the paper describes a demo sys-
tem exhibiting both types of behaviour, based on
a reinforcement learning dialogue framework.
17
2 Hierarchical Reinforcement Learning
Dialogue Agents with Flexible Control
Our dialogue controllers use hierarchical rein-
forcement learning as in (Cuaya?huitl et al, 2010).
We extend such a formalization through a hierar-
chy of dialogue agents defined with the following
tuples: M ij = <Sij , Aij , T ij , Rij , Lij , U ij , ?ij , ?ij>,
where Sij is a set of states, Aij is a set of actions,
T ij is a stochastic state transition function, Rij is
a reward function, Lij is a grammar that specifies
tree-based state representations, U ij is a finite set
of user actions (e.g. user dialogue acts), ?ij is a
finite set of models that subtask M ij is being al-
lowed to transition to, and ?ij = P (m? ? ?ij |m ?
?ij , u ? U ij) is a stochastic model transition func-
tion1 that specifies the next model m? given model
m and user action u. Although the hierarchy of
agents can be fully-connected when all models
are allowed to transition from a given particu-
lar model (avoiding self-transitions), in practice,
we may want our hierarchy of agents partially-
connected, i.e. when ?ij is a subset of subtasks
that agent M ij is allowed to transition to.
We implemented a modified version of the
HSMQ-Learning algorithm (Dietterich, 2000) to
simultaneously learn a hierarchy of policies piij .
This algorithm uses a stack of subtasks and op-
erates as illustrated in Figure 2. If during the ex-
ecution of a subtask the user decides to jump to
another subtask, i.e. to change to another sub-
dialogue, the flexible execution of subtasks allows
each subtask to be interrupted in two ways. In the
first case, we check whether the new (active) sub-
task is already on the stack of subtasks to execute.
This would be the case if it was a parent of the
current subtask. In this case, we terminate exe-
cution of all intervening subtasks until we reach
the parent subtask, which would be the new ac-
tive subtask. Notice that termination of all inter-
vening subtasks prevents the stack from growing
infinitely. In the second case, the current subtask
is put on hold, and if the new active subtask is
not already on the stack of subtasks to execute, it
is pushed onto the stack and control is passed to
it. Once the new subtask terminates its execution,
control is transferred back to the subtask on hold.
1This is a very relevant feature in dialogue agents in order
to allow users to say and/or do anything at anytime, and the
learning agents have to behave accordingly.
Initial
stack
Pushing
'dialogue'
Pushing
'sub-dialogue1'
Pushing
'sub-dialogue2'
(two siblings 
in the stack)
Popping
'sub-dialogue2'
Popping
'sub-dialogue1'
Popping
'dialogue'
dialogue dialogue dialogue dialogue dialogue
sub-
dialogue1
sub-
dialogue1
sub-
dialogue2
sub-
dialogue1
Figure 2: Hypothetical operations of stack-based hier-
archical dialogue controllers. Whilst the fourth opera-
tion from left to right is not allowed in strict HDC, all
stack operations are allowed in flexible HDC.
These kinds of transitions can be seen as high-
level transitions in the state space. They can also
be seen as the mechanism to transition from any
state to any other in the hierarchy. To do that we
maintain an activity status for each subtask M ij ,
where only one subtask is allowed to be active at
a time. We maintain a knowledge-rich state that
keeps the dialogue history in order to initialize
or reinitialize states of each subtask accordingly.
Since there is learning when new subtasks are in-
voked and no learning when they are interrupted,
this algorithm maintains its convergence proper-
ties to optimal context-independent policies.
3 A Hierarchy of Dialogue Agents for
Playing Quiz Games
We use a small hierarchy of dialogue agents?
for illustration purposes?with one parent agent
and two children agents (?robot asks? and ?user
asks?). Thus, the hierarchy of agents can ask the
user questions, and vice-versa, the user can ask
the robot questions (described in the next section).
Both conversants can play multiple rounds with a
predefined number of questions.
Due to space restrictions, we describe the hi-
erarchy of agents only briefly. The set of states
and actions use relational representations (they
can be seen as trees) in order to specify the
state-action space compactly, which can grow as
more features or games are integrated. Dialogue
and game features are included so as to inform
the agents of possible situations in the interac-
tion. The action sets use constrained spaces, i.e.
only a subset of actions is available at each state
based on the relational representations. For ex-
ample, the action Request(PlayGame) ? x0
is valid for the dialogue state x0 expressed as
Salutation(greeting)?UserName(known)?
PlayGame(unknown). The sets of primitive
actions (80 in total) assume verbal behaviours
18
with a mapping to non-verbal ones, some sam-
ple dialogue act types are as follows: requests,
apologies, confirmations, provide information,
acknowledgements, feedback, non-verbal expres-
sions, game-related actions. The transition func-
tions use pre-defined parameters, their training
from data is left as future work. The reward func-
tion addresses efficient and effective interactions
by penalizing dialogue length and encouraging to
continue playing. The dialogue agents learnt their
behaviour by interacting with a stochastic simu-
lated user, where the user responses eventually
required transitions across agents. A sample dia-
logue with flexible interaction is shown in Fig. 3.
4 A Humanoid Robot Integrated System
Figure 4 shows the robot?s integrated system,
which equips the robot with the following capa-
bilities: listening, talking, seeing and moving.2 A
sample interaction assuming wizarded behaviour
is as follows. The user says something to the robot
(e.g. ?ask me a question?) and the wizard selects
a user dialogue act for the corresponding utter-
ance such as ?Request(Question)?. Then the di-
alogue manager selects and executes the learned
action by querying/updating the game move gen-
erator and user model components, and by pass-
ing a dialogue act to the language generation and
motor control components. The former provides
the corresponding text to the speech synthesizer
and the latter provides the corresponding non-
verbal behaviour. Then the dialogue manager ob-
serves its new dialogue state, and suggests the
next actions?based on its dialogue policies and
user simulations?in the wizard-of-Oz GUI, see
Figure 5. From this setting, if we remove the
wizard then the system can behave autonomously,
where user inputs are derived from the language
and gesture understanding components.
The attractiveness of this kind of set-up is the
smooth transition from purely wizarded conver-
sational behaviour to fully autonomous behaviour,
where the dialogue policies can be tested and eval-
2We use off-the-shelf technologies such as Sphinx /
Julius / HTK for speech recognition, OpenCV for ges-
ture recognition, Acapela and Mary for speech synthe-
sis, HRL-based dialogue management (as described above),
OpenCCG for language parsing and language generation,
Weka and JavaBayes for maintaining a probabilistic and per-
sonalized user profile of asked and answered questions, the
URBI middleware (www.gostai.com), and the NAO hu-
manoid robot (www.aldebaran-robotics.com).
SYS Hi, my name is NAO, and you?
USR I am Peter
SYS Nice to meet you Peter
Do you want to Play a Quiz game?
USR Ask me questions [jump to ?robot asks?]
SYS The first question is.
What is a typical magic instrument?
Your choices are: One, guitar. Two, drums.
Three ,violin. Four, flute. What is your choice?
USR Number two
SYS That is not quite right. Do you have another choice?
USR Maybe number three
SYS The correct answer is number four, flute.
The next question is: which one of these is
an important artificial channel of the central America?
Your choices are: One, channel five. Two, Panama canal.
Three, Suez canal. Four, English channel.
What is your choice?
USR Now I want to ask you questions [jump to ?user asks?]
SYS Ask me the first question.
USR What does water become at the temperature of
zero degrees?
SYS What are my choices?
USR Your choices are:
One, condensation. Two, ice. Three, steam.
SYS I choose number one
USR That is incorrect.
SYS So what is the right answer?
USR The correct answer is number two.
SYS Okay, ask me another question.
USR The next question is: through which breach did
the Italian army entered into Rome in 1870?
Your choices are: One, porta venezia. Two, porta pia.
Three, porta pazienza. Four, porta nuova.
What is your choice?
SYS Paris
USR Let?s stop playing. [jump to ?root?]
SYS Did you like playing the Quiz Game?
USR Yes
SYS I am glad to hear that.
SYS It was nice playing with you, see you soon. Bye!
Figure 3: Sample dialogue with non-strict hierarchical
control. The groups of utterances represent activity
in different sub-dialogues in the hierarchy of agents.
Note that the user is allowed to override the imposed
dialogue structure. For instance, when the user says
?Ask me questions? the agent interrupts the execution
of the root subtask and transitions to the subtask ?robot
asks?. Similarly, the sub-dialogues do not need to follow
their imposed structure and the user is allowed to talk
about previous and unadressed sub-dialogues such as
the sudden switch from ?robot asks? to ?user asks?.
Middleware
Speech Recognizer,
Voice Act. Detector,
Audio Front End
Gesture
Recognizer
Motor
Control
Speech
Synthesizer
Game Move
Generator
Dialogue Manager
Parser,
Dialogue Act
Classifier
Language
Generator
User
Model
Wizard-of-Oz
GUI
ASR
result
Gesture
act
System
Dialogue
act
Text
ASR
result
Gesture
Act
System
dialogue
Act
Text
User
dialogue
act
Dialogue acts System
dialogue
act
user,
game
results
query,
questions,
answers
Figure 4: High-level architecture of our talking robot.
19
Figure 5: Screen shot of the wizard-of-Oz GUI, where
the dialogue policies and user simulations suggest
highlighted actions to the wizard. This setting allows
fully-wizarded and (semi-) autonomous behaviour.
Figure 6: The Nao robot greeting a user prior to play-
ing a Quiz game. The pieces of paper on the table are
the Quiz questions the child asks the robot.
uated with (semi-) autonomous behaviour. We use
this framework to investigate long-term human-
robot interaction, in particular child-robot inter-
actions for educational purposes. Figure 6 shows
a scene from a pilot evaluation, where the robot
and a child are visibly engaged with each other. A
complete evaluation with simulated and real dia-
logues will be reported in a forthcoming paper.
5 Discussion and Summary
Typically, conversational interfaces impose a di-
alogue structure on the user. Even in dialogue
systems with mixed-initiative interaction that give
flexibility to the user in terms of providing more
than one piece of information at a time, the
user is hardly allowed to navigate flexibly during
the interaction. Notable exceptions without dia-
logue optimization are (Rudnicky and Wu, 1999;
Lemon et al, 2001; Larsson, 2002; Foster et al,
2006). We believe that Hierarchical Reinforce-
ment Learning with global state transitions is an
interesting method to optimize (sub-) dialogues at
different levels of granularity, where the design of
action selection might not be easy to hand-craft.
On the one hand, our HDCs can be applied to
dialogues with user-driven topic shift, where the
user can take control of the interaction by navigat-
ing across sub-dialogues and the system has to re-
spond accordingly. On the other hand, our HDCs
can be applied to dialogues with system-driven
topic shift, where the system can itself terminate a
sub-dialogue, perhaps by inferring the user?s emo-
tional and/or situational state, and the system has
to switch itself to another sub-dialogue.
We have described a conversational humanoid
robot that allows users to follow their own dia-
logue structures. The novelty in our system is
its flexible hierarchical dialogue controller, which
extends strict hierarchical control with transitions
across sub-controllers. Suggested future work
consists in training and evaluating our humanoid
robot from real interactions using either partially
specified or fully learnt dialogue structures.
References
H. Clark. 1996. Using Language. Cambridge Univer-
sity Press.
H. Cuaya?huitl, S. Renals, O. Lemon, and H. Shi-
modaira. 2010. Evaluation of a hierarchical rein-
forcement learning spoken dialogue system. Com-
puter Speech and Language, 24(2):395?429.
T. Dietterich. 2000. An overview of MAXQ hi-
erarchical reinforcement learning. In Symposium
on Abstraction, Reformulation, and Approximation
(SARA), pages 26?44.
M. E. Foster, T. By, M. Rickert, and A. Knoll. 2006.
Human-robot dialogue for joint construction tasks.
In ICMI, pages 68?71.
B. Grosz and C. Sidner. 1986. Attention, intentions
and the structure of discourse. Computational Lin-
guistics, 12(3):175?204.
S. Larsson. 2002. Issue-Based Dialogue Manage-
ment. Ph.D. thesis, University of Goteborg.
O. Lemon, A. Bracy, A. Gruenstein, and S. Peters.
2001. The WITAS multi-modal dialogue system I.
In EUROSPEECH, Aalborg, Denmark.
D. Litman and J. Allen. 1987. A plan recognition
model for subdialogues in conversations. Cognitive
Science, 11:163?200.
A. Rudnicky and W. Wu. 1999. An agenda-based
dialogue management architecture for spoken lan-
guage systems. In IEEE Workshop on Automatic
Speech Recognition and Understanding (ASRU),
pages 337?340, Keystone, Colorado, USA, Dec.
20
