b r i c t m  Journal of C~mputat~~nal  l$ingui~tio Microfiche 23 
C o p y r i g h t  1 9 7 5  by t h e  A s s o c i a t i o n  for. ~ompufational L i n g u i s t i a s  
A U T 0 N 0 T E 2 : NETWORK MEDIATED 
NATURAL LANGUAGE COMMUNICATION 
IN A PERSONAL 
INFORMATION RETRIEVAL SYSTEM 
William E. Linn, Jr . 2 
and 
Walter Reitman 
Upiversity of Michigan 
Ann Arbor 
1 T h i s  paper is based on a doctoral disserfiation by the first author. Support 
from the iUationai Science Foundation under ~ r m t  'No. DCR71-02038 is gratefully 
acknowle8ged. Those wishing more mmplete details about sys tem c a d s  and 
imp.tomentatioa should,write the s-d author for a User's Manual. 
2 lVow a t t  southern Railway System, 125 Spring Street,  S .  W., Atlanta, Georgia 30.303 
ABSTRACT 
Natural language combinesnOuns and adjectives into noun phrases,, and 
links phrases by means of.p,repositions to form complex descriptiops of 
objects and topics. AUTONOTEZ, a file-orsented retrieval systeq, allows 
the user to employ such descriptions to characterize the items of informa- 
tion he wishes to store and retrieve. Tn addition. the system also cm- 
structs a network qpresentation of the user's sub3ect matter, using syntac- 
tic analysis to  derive dependency structures fxhn h h  descriptions. The 
depe~dency information, expressed as subordinate and coordinate linkages 
among the phrases, is representea by a tree of nodes, with simple phrases 
a t  the terminalbranches. The PARSER uses the network to digambiguate dew 
criptions, querying the user only a b h t  regidual ambiguities. 
Associated with the PARSER is a network LOCATOR, which determines 
whether a ckrent user description refers to an existing topic at some level 
in  the network. The LOCATOR also builds a table specifying t;he changes, if 
anp, to be mede in a network in order to represent the topicdnferred from 
the current input description. For example, if the user's description con- 
tains one or more simple phrases (thereafter referred to  as active) directly 
describing at least one existing node in  the network, the description as a 
whole quite likely references an exssting network topic. To locate 1t, the 
PARSER fgrs't deterdaes tlie - focus phrase, the active phrase at the highest 
dependency level. The nodes directly described by the focus phrase are 
w e d  to generate candidate topice. These then are matched against the 
remaining active phrases obtained from the description to determine the 
most l ike ly  referent. 
Manp gf the procedures employed in dsScription and representation also 
are wed in network-mediated' retrieval. The user may* in i t iate  retrieval 
with a FIND comm~nd, supplying a descripti~n as afgument. The resultant 
phrase table is passed along to the network LOCATOR, which returns a node 
ntllhber to the FIND processor. The FIND processor constructs a set of i t e m  
numbers by extracting the tkxttral  refereaces from the node. The system 
then checks for upward pointers from the node. If there ars.tm.-uctura~ly 
xelsted topics, the FIND processor so informs the user. Note that by virtue 
of netwprk midiation of retrieval, i f  a user descr ipt ion  Ys imprecise or 
incorrect, the systemmay be able t o  direct the user to relevant related 
topics. 
meri the system queries the user about a topic, f o r  example to deter- 
mine the intent-of a descriptPon, the eapic node number is passed to a 
SPEAKER component. A phraeal description of the node is returned. To 
minimize redundant c m i c a t i o n ,  a level indicator  may Qe set according to 
the level of &tail in the user's description. For example, if the user 
describes an item as RESULTS OF TBE WPERIMWT and the systemamst ask it he 
i n  rezerring t o  SMITH'S EXPERIMENT ON SHORT TERM MEMIRY OF WHITE RATS, 
the resulting query would be: ARE YOU W R R I N G  TO SMITH'S EXPERIMENT ON 
W O R P ?  
Cmetruct5on of a desclr;iption from the network takes place in mob 
stages. The fitst stage steps thorugh the network recurs&vely, collecting 
the e i q l e  phrases that directly or indirectly describe fhe speoif ied node. 
The l e v e l  indicator blocks collection of simple phrasee below the specified 
level.  The second stage is carried out by a recursive algorithm that 
operaqes on the tabled simple phraygs and their interrelations to construct 
the phrasal description. 
The last major component of the system handle6 network modification 
and reorganization. This enables the user t o  add or remove references and 
phrases, and t o  modify,, delete, or reorganize h i s  t o p i c  structure. 
A de ta i l ed  ease study comparing AUTONOTE2 with a good keyword-based 
retrieval aystxm showed that fol: a coherent body of material, the comuni- 
cati,ve efficiency 0% AUTONOTEL, as measuredfbp the ratio of the number o f  
pords conveyed to the number of words entered, was more than double that of 
the kyword-based system. Retrieval capability was enhanced considerably, 
and the tepresentati~n dewqrk effectxvely distinguished among the many 
topics partially indexed by the same words. Furthermore, SPEAKER output of 
topics from the rep~esentatiorral network proved a useful retrieval inter- 
mediary, greatly reducing the need fo,r perusal of i t e m  texts. 
TABLE OF CONTENTS 
Page 
I . AUTONOTI? SYSTEM . . . . . . . . . . . . . . . . . . . . . . .  9 
. . . . . . . . . . . . . . . . .  Basic~~ONOTECommands~  10 
. . . . . . . . . . . . . . . .  AUTONOTE System Organization 14 
. . . . . . . . . . . . . . . . . . . . . . .  111 . QVER~IEWOFAUTONOTEZ 16 
. . . . . . . . . . . . . . . . . .  The Descripaoh Languagk 1 7  
. . . . . . . . . . . . . . . . . .  Representational Framework 19 
. . . . . . . . . . . . . .  Criteria for the Representation 19 
. . . . . . . . . .  Overview o f  the AUTONOTE2 Implementation 24 
Design of the Network Data Structures . . . . . . . . .  32 
. . . . . . . . . . .  Storqge Implementation of the Network 37 
The Repfesentational Network: An Example . . . . . . . .  40 
. . . . . . . . . . . . . . . . . .  Parsing OF Descriptions 40 
VI . N E T W O R K ~ I A T E D B E T R I W A I  . . . . . . . . . . . . . . . . . . . .  68 
Retrieval via Descriptions, . . . . . . . . . . . . . . . .  68 
Interrogating the Wetwork . . . . . . . . . . . . . . . . .  71 
. . . . . . . . . . . . . . . . . . .  !be S P U R  Component 73 
Page 
. . . . . . . . . . . . . . . . . . . . . .  VXT . I ' T E ~ ~ O R K  MODIFICATION 78 
. . . . . . .  Adding Refetences and Phrases to the Network 79 
. . . . . . . . . . . . . . . .  Moving through the Network 81 
. . . . . . . . . . . . . . . . . . . .  The Caching F a c i l i t y  81 
. . . . . . . . . . . . . . . . . . . .  RetrievalCommands 82 
Removing References and Phrases from the Network . . . 82 
Topic Deletion . . . . . . .  . . .  . . . .  . .  . . . . . .  82 
. . . . . . . . . . . .  Creating New Topic Representations 86 
. . . . . . . . . . . . . . .  VIII . A CASE STUDY OF SYSTEM PlERFORMANCE 87 
. . . . . . . .  The Inapplicability of Recall and precision 87 
. . . . . . . . . . . . .  . . . .  The Sauvain Data Base . . .  88 
. . . . . . . . . . . . . . . . . . . . . . . . . .  Results 88 
. . . . . . . . . . . . . . . . . . . . . . . . .  Conclusion 9 4  
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  REFERENCES 97 
I. INTRODUCTION 
When two humans communicate, each party builds  up a conceptual represen- 
t a t i on  of the  topics  of discussion. Such repreqentations are fundamental t o  
human cormrmnicat%~e fficiency. The l i s t e n e r '  s representat ion of the  topics  
alteacly discussed f a c i l i t a t e s  communication i n  t h a t  t he  speaker i s  spared 
the trouble of describing i n  complete detai l  those t h b g s  t o  which he re fe r s .  
Furthermore, the speaker can proceed to related top ics  without having t o  
describe them in full. For example, a speaker who has been ta lking about the 
design of a particular experiment can safely move on t o  discuss the  results 
of the experiment without specifying anew the experiment he has i n  mind. 
We use the term r e f e r e n t i a l  communication t o  indicate  the process by 
which a speaker communicates a reference t o  some subject  or top ic  t o  a 
l i s t ene r .  ff within the envirbnment of a personal information system, we 
v i e w  t h e  information universe as a collection of textual materials  each 
II per t inent  to one o r  more topics," then one can readi ly  construct an analogy, 
The user  and system take on the  r o l ~ ~ s  of speaker and l i s t e n e r ,  respectively.  
The domain of discourse is a set of topic descript ions characterizing the  
t he r ' s  t ~ t u a l m a t e r i a l s ,  The user en te r s  his materials and describes t o  
the system the topic or topics t o  which they pertain.  Durlng t h i s  process, 
the system constructs its - represiintation for the subjec ts  the user  has 
described, and associatgs each piece of text with its, corresbonding top ic  
representations. 
This paper describes the design and implementation of a personal infor-  
mation storage and retrieval system based on the  foregoing analogy w i t h  
human referential communication. It presents a hierarchical network data 
strqcture foe representing topic descriptions formulated within a phrasal 
description language. ~alied the representational network, this structure 
enables the system to move easily from one Bubject to other  elated ones. 
It provides a means for representing the user's working context, thereby 
enabling the user to describe his materials much more tersely than is possi- 
ble in keyword-based systems. The system makes use of the syntactic depen- 
dencies among the words and phrases of descriptiops in or'der to represent 
structural relationsh'ips among the user's topics. Consequently, the user 
impaats structure to the data base in a particularly natural way, eliminating 
much of the organization activity normalb associated with keyword-based 
systems. Our central thesis is that the network mediated techniques provide 
for m z e  effective mawmachine communication during the processes of des- 
cription, organization, and retrieval within a personally generated informa- 
tion universe 
The procedures used here differ substantially from the typical keyword 
indexing and retrieval mechanisms of other personal retrieval systems. The 
centrab objective is to provide the user with framework for defining the 
important topics or informational objects he deals with, and to enable him to 
easily associate items in his data base with these entities. Rather than 
viewing the data base as a collection of items and associated index terms, 
the user deals with "objects" thet are in some sense meaningful to him. 
Whether retrieving information or indexing new material the user conveys 
references to the appropriate topics. This shift in the user's view of his 
information universe, coupled with the mechanisms we have developed for 
building up and re fe r r ing  t o  the  top ic  framework, oons t i tu t e  the substance 
of our approach t o  personal information s torage and r e t r i e v a l .  
11. THE AWONOTE SYSTEM 
The system described here uses the  AUTONOTE information storage and 
r e t r i e v a l  system (Reibnan - e t  -. al 9 1969) as a base. AUTONOTE is an on-line 
r e t r i e v a l  system t h a t  runs a& a user program under the  Michigan Terminal 
System (MTS) , a time-oharing system implemented on t h e  IBM 370/168. The 
bas ic  u n i t s  o f  information s tored i n  AUTONOTE a're ca l l ed  items. The user 
may en te r  a r b i t r a r y  t e x t u a l  mater ia ls  i n t o  an item and may assign d e s c r i p m r s  
by whfch these mater ia ls  can be re t r ieved.  Ret r ieva l  requests  take t h e  farm 
~f s ing le  descr iptors  or combinations o f  descr ip tors  connected by AND, OR, 9s 
NOT l o g i c a l  operators. F a c i l i t i e s  a r e  provided f o r  de le t ing ,  replacing,  
l inking,  and h ie rarch ica l ly  organizing text i t e m & .  
AUTONOTE makes extensive use of the WS d i sk  f i l e  sys tem EiflIS disk 
f i l e s  ( l ine  f i l e s )  may be read o r  wr i t t en  either sequent ia l ly  o r  i n  an indexed 
fashion by specifying a l i n e  f i l e  number. AUTONOTE maintdins two l i n e  f i l e s  
fo r  each user's data base; one f o r  storing t ex tua l  mater ia l s  and bookkeeping 
information, the  o ther  f o r  s t o r i n g  a descr ip tor  index. Each t e x t  i t e m  
occupies a s p e c i f i c  region of the  l i n e  number range of the  t ex t  f i l e .  The 
descripfor index, on the  other hand, is accessed through an e f f i c i e n t  hash 
coding algorithm t h a t  mdps each descr ip tor  i n t o  an index f i l e  l i n e  number. 
The descr ip tor  index i s  organized a s  an inverted f i l e ,  t h a t  is ,  each l i ne  i n  
the index contains poin te rs  t o  each of the  t e x t  items assigned the  descr ip tor  
f o r  t h a t  line. 
Basic AUTONOTE Commands 
Text entry ,  To e n t e r  a new text i t e m ,  the  user  f i r s t  types the  command 
ENTER and the  eystem responds with a numerical t ag  f o r  the new i t e m .  The 
system then e n t e r s  a "lext i n s e r t i a n  mode" and i n d i c a t e s  its readiness t o  
accept successive text lines with a quest ion mark. Aftex enter ing  text,, the 
user may re tu rn  t o  "command mode" by enter ing a n u l l  l i n e  o r  an end-of-file 
indicat ion,  Should the  user  a t  any t i m e  wish t o  continue i n s e r t i n g  t e x t  i n t o  
the current i t e m ,  he may re-enter t e x t  i n s e r t i o n  mode via the INSERT cormnand. 
Subsequent l i n e s  are placed below the most recent  l i n e  f o r  the  current  i t e m  
i n  the text  file. 
In command mode, the  system prompts the  user  for  input  with a minus sign.  
The user may give each command i n  f u l l  o r  he may abbreviate by giving any 
i n i t i a l  subs t r ing  of the command name. 
Descriptor entry.  To as soc ia t e  one o r  more desc r ip to r s  with the  current  
text i t e m ,  the user  en te r s  a list of words, beginning the  input  l i n e  with an 
a t  sign (@). Any character  s t r i ng  up t o  16 characters  i n  length may be used 
as a descr iptor .  kn addi t ion  t o  updating the descr ip tor  index, t h e  system 
a l s o  places the  actual "@-linet' i n  the t e x t  file i n  a subregion beneath t h e  
text a? che current  item. 
Retrieval, To display a p a r t c i u l a r  t e x t  i t e m  the  user  may en te r  the 
command PRINT followed by the  appropriate item number. Sequential blocks of 
items can a l s o  be specif ied i n  the PRINT commapd, & g o ,  PRINT 77...85. 
In most cases, however, the spec i f i c  i t e m  number(s) w i l l  not be known. 
The LIST command accepts a descr ip tor  o r  log ica l  combination of descr ip tors  
as its argument and ~esponds  with a  list of the i t e m  numbere t h a t  satisfy 
the. query. The functions of the  PRINT and LIST commands are combined i n  the 
RETRIEVE7command. It a l s o  takes a descriptor spec i f i ca t ion  Be argument and 
causes each i t e m  . i ~  the resu l t ing  list t o  be PRIWed. 
Defini t ional  f a c i l i t y .  AUTONOTE a l s o  provides a de f in i t i ona l  f a c i l i t y  
t ha t  allows the user t o  create sets of items referenced by a r b i t r a r y  com- 
binations of descriptors.  For example, the c o m n d  CREATE SIRS= INFORMATION 
AND RETRIJ3VA.L AND SYSTEMS adds a new descr ip tor ,  SIRS, t o  the  index t h a t  
references each i t e m  having the words INFORMATION, RETRI~vAL, and SYSTEMS as 
descriptors.  Any defined term may be used just as any other  descr iptor  i n  
r e t r i e v a l  requests;  they m y  also be used to def other  new terms (e,g., 
CREATE $OTHERSYSTEMS= SIRS NOT AUTONOTE) . 
The definitYona1 f a c i l i t y  is also invoked impl ic i t ly  each time the user 
i ssues  a r e t r i e v a l  query. The set of items referenced by the most recent 
LIST or RETRIEVE command, cal led the ac t ive  s e t ,  i s  assigned the name $, 
Should the user wish t o  r e f i n e  the r e s u l t s  of the  previous query, he has 
access to the active set. To f a c i l i t a t e  t h i s  process, each t i m e  a missing 
descr ip tor  is noted i n  a r e t r i e v a l  request  the descriptor $ is inserted 
a u t o ~ & L c a l l y  by the  system. For example, the  command LIST NOT FPRT i s  
Interpreted as LIST $ NOT FROTRAN, i.e., the  old ac t i ve  set of items is 
restricted t o  include only those not referenced by the  descr ip tor  FQRT 
This operation, of course, redefines the active set. 
Item-iteq l i n k a e .  The a b i l i t y  to define a s s o ~ i a t i v e  l i n k s  between 
any two t e x t  items is provided by t h e  APPEND command. When an i t e m  is  dis-  
played, its assoc ia t ive  l i n k s  t o  o the r  items may opt iona l ly  be pr in ted  along 
with a user-lspecified comment ind ica t ing  the na tu re  of the  assocLation. 
Tu to r i a l  feature. Throughout the course of i t s  development, AUTONOTE 
has been employed t o  c o l l e c t ,  organize, and maintain up-to-date documentation 
af i ts  c a p a b i l i t i e s ,  usage s t r a t e g i e s ,  and s o  ono This information is stored 
i n  a pub l i ca l ly  ava i l ab le  da ta  base. It includes b r i e f  desc r ip t ions  of ea& 
of t h e  commands, announcements of recent  developments and system changes, and 
o t h e r  i n s t r u c t i v e  information. The AUTONOTE u s e r  may ca l l  upon t h i s  s t o r e  of 
w t e r i a l  by enter ing  a HELP command. The user  s d a t a  base is  temporarily set 
a s ide  and the publ ic  data  base i s  attsebed t o  t h e  system. The use r  may then 
r e t r i e v e  i n s t r u c t i v e  informakion i n  the same way t h a t  he operates  wi th  h i s  
own da ta  base. To a s s i s t  novice users ,  t he  system will opt iona l ly  p r i n t  
i n s t r u c t i o n s  f o r  accessing t h e  HELP da ta  base. 
Grouping. AllTONOTE provides a grouping f a c i l i t y  which permits  the  user  
t o  organize t e x t  items i n  severa l  use fu l  ways. It enables the  user t o  def ine  
a "grouping item" which references  an a r b i t r a r i l y  ordered list of o ther  items 
This is done by entering i n t o  an item an @-line o f  the form: 
Since apy item can represent  a g+oup, *it i s  poss ib le  t o  form a complex hier- 
a r c h i c a l  s t r u c t u r e  in t h i s  way. 
A grouping item can be viewed as a node of an inver ted tree s t r u c t u r e  
w;ith downward b ranJ le s  t o  those items l i s t e d  i n  i t s  "@GROW" l i n e .  A request 
to  display a grouping i t e m  i n i t i a t e s  recurs ive  processing of t h e  t r e e  
structure to identify the terminal ad& nonterminal f terns of the hierarchy. 
The user may request tha t  only terminal or',nonterminal items,be displayed, 
or t e entire list of materials be printed, 
The organization of the HELP data base described above provides an 
excellent example of the pmer and flexibility of the grouping f a c i l i t y .  
The HErJe text filelcontains a t  this wri t ing approxinrstely 150 %terns of 
documentation. Using the grouping conventton, these are orgaritzed i n to  
five subgroups: (1) general #nf ormation; (2) input and editing facilities ; 
(3) output (retrieval) facilities; (4) organizational facilities; and (5) 
utflity compands. Thme-is; one major item which groups all of these aub- 
grottps into a single tree structure. The top node of the strusture is 
indexed by the descriptor USERS-MANUAL. As new facil it ies  are incorporated 
into the system, their descriptions are entered .Into the manual structure, 
thus assuring that complete and up-to-date documentat$..on is always avail- 
able. A t  any time, the single command: RETRIEVE U S E R S - W A L  causes the 
entire updated data base to be displayed in  organieed fom: 
Command modifiers. AUTONOTE lacJudes a set of modifiers or option 
eettings that control the execution of many c ds. These include options 
that affect the format o f  displayed items, the etlrpanslon of grouping atruc- 
tures, the nature and extent of system feedback, etc. E&ch 0-f the modifiers 
has a default. value that i s  chosen to  simplify use of the system by a 
novice. The more experienced user may alter the modifiers via the SET c 
mand to. tailor the system to hie awn needs, usage patterns and h v e l  of 
competence. 
AUTONOTE also provides a large number of auxillary commands and f a c i l i -  
ties. A list of the major AUTONOTE commands, each accompanied by a brief 
description, is incldded in Linn (1972, Appendix A). 
AaTONOTE S m Otganization 
AUTONOTE l-@s been des gned as a modular system SQ that as new faci l i -  
ties become a~ailable~they may be tested and later added with' little or no 
reprogramming of the exjgting system. The majority of AUTOMOTE co 
are fmplemented as subroutines, each of which resides permanently in an MTS 
disk f i le .  The basic system $s organized around a central monitor that 
accepts user input and calls upon appropriate modules to service the user's 
requests. In addition to the monitor, the core resident system includes a 
dynamic loader, a disk file interface and a set of frequently used utility 
routines. A number of pridtive commands, text entry, and descriptor assign- 
ment are qlso handled by the resident system. As the user =quests more 
cbmplex sentices (LIST, RETRIEVE, or PRINT, Ear example), the monitor calls 
upon the* dynamic loader to bring the appropriate modules into core storage. 
These routines then becoke a part of the resident system, remining in wre 
etorage until the user explZcitly requests their removd. An organizational 
diagram of the AUTONOTE system appears i n  Fig. 1. 
The modular design of AUTONOTE coupled wtth the dynamic loading facility 
offers two important benefits. From the user s viewpoint, he has access to 
the complete repertory of AUTONOTE seMces, yet he pays core storage 
charges only fm those routines he actually uses during a given session. 
To the developers of the system, the modular framework f a c i l i t a t e s  the 
STORAGE 
mUT/otrrPUT 
ROUTIWS 
J 
A 
d 
MONITOR 
LYIMMIC LOADER I 
(COMMAND 
INTERPRErnR) 
s 
PROCESSOR 
Fig, 1 - AUTONOTE System Organization 
addition of new system components. The latter has been an important factor 
in the implementation of the AUTONOTE2 system. 
111, OVERVIEW OF AUTONOTE2 
The AUTONOTE2 system uses ideas (Reitman, 2965; Reitman - et -* a1 9 1969) 
concerning the use of our "knowledge of the world" to clisambiguate and fill 
in implied facts when conversing with one anathear. Zn parti~ular, the system 
design is based upon the assumption that efficient human communication... 
"depends upon the listener's ability to make inferences from prior informa- 
tion, from context, and from a knowledge of the speaker and the world. Com- 
municating in this way, we risk occasional misunderstanding as the price for 
avoiding verbose, redundant messages largely consisting of material the 
listener already knows" [Reitman - et -* a1 9 19691. 
In b u ~  mare restricted domain of discourse, we view the process of human 
referential c~unication as onq >pided by some f o m  of internal rapresenta- 
tion of the various topfqs or referents discussed earlier. When a listener 
can be assumed to have such a representation, the speaker is spared the dif- 
ficulty of describing in complete detail the things to which he refers. He; 
need only give enough information to allow the referent to be discerned in 
full. Our goal then is to develop a represenratlonal scheme for our retrieval 
system that allows the user analogous conrmunicative efficiencies. 
The Description Language 
The first step in devising a representational framework wa8 the f o m -  
lation of a language for expressing topic dedcriptions to the system. 
Although an underlying factor in the design of AUTONOTEL was to make com- 
It municatloh with the system more natural," it should be noted that the 
emphasis of this research is not upon parsing or "understanding" natural 
language. Rather, our goal is to investigate the notions of topic repre- 
sentation and referential camunication as a means f o r  improving the user's 
ability to describe, organize, and retrieve his materials. Consequently, 
a minimal subset of noun phrases waa chosen-minimal in the sense that it 
excludes most of the complexity of natural English, yet still retains a 
degree of descriptive richness sufficient to explore the underlying ideas of 
this study. 
Natural language enables us to combine nouns and adjectives i n t ~  noun 
phrases and to interlink noun phrases via prepositions to form complex des- 
criptions of objects in the real world. The AUTONOTE2 description language 
provldes such a framework for composing topic references. A form~l grammar 
for the language is given in Fig. 2 along with a few sample descriptions that 
illustrate the flexibility of expression achievable with the language. These 
grammatical rules are not in fact used explicitly by the system in actually 
parsing topic descriptions. The grammar is presented here only to specify 
precisely the set of descriptions acceptable to the system. The actual 
AUTONOTE2 parser i s  heuristic-based, making use of previously analyzed 
phrases, noun-preposition co-occurrences, and a set  of heuristics to guide 
qdeacrip tion> : : = (noun-group, I 
knoun-group> <preposition> <description> 
<noun-group 3 : := (<article>) (<modif ier-group) <noun>a 
/ <preposition> : about 1 to I from 1 in I on etc. 
: := a I an I the 
(a) Grammar for the description language. 
The paper about microprogramming in the proceedings of the fall joint computer 
conference 
Notes on the organization of AUTONOTE2 for use in the presentation of the ACM 
Paper 
The use of recall precision measures in the evaluation of the SMART information 
retrieval system 
Quotes from Peldman's 1969 paper for use in the introduction of the second 
chapterb 
(b) Sample descriptions. 
Fig. 2 - The AUTONOTE2 Description Language 
%odif iers and nouns are arbitrary character strings not recognized as 
articles or prepositions. When a number of consecutive "words" are encountered, 
the last is parsed as a noun and the preceding words as modifiers. 
b Possessive adjectives are treated as a special case of adjectival modifi- 
cation. 
the  parsing process. In  some ins tances ,  the  user  may even be asked f o r  
parsing ass is tance.  
Representational Framework 
Central t o  the design of AUTONOTEZ is the  idea  of viewing the user ' s  
information universe a s  a co l lec t ion  of "informational objects" o r  top ics ,  
each having associated with i t  a number of t e x t  i t e m s .  When the user wishes 
t o  describe a t e x t  item, we assume he has such a topic  i n  mind. Using t h e  
phrasal  language specif ied above, he composes a descr ip t ion  of t h a t  top ic  
and presents  i t  t o  the  system. AUTONOTE2 then constructs  an i n t e r n a l  repre- 
senta t ion of t h a t  topic. When a text  i t e m  i s  described, the system must 
consult  the representat ion t o  determine i f  t he  descr ip t ion  (1) references an 
ex is t ing  topic, (2) is r e l a t e d  t o  an e x i s t i n g  topic ,  o r  (3) def ines  a new 
topic. In any case, the ul t imate  goal  i s  t o  assoc ia te  the text i t e m  with a 
topic representation, possibly augmenting the  representat ion i n  the process. 
Criteria for the Representation 
Efficiency of comunication, E f f i c i e n t  man-machine communication im-  
p l i e s  t h a t  the user  should not i n  general  have t o  formulate a complete des- 
c r ip t ion  of a p a r t i c u l a r  top ic  i n  order t o  convey a reference t o  i t .  The 
system should be capable of accepting and co r rec t ly  i n t e r p r e t i n g  incomplete 
referefices bp f i l l i n g  i n  missing information. A s  an example, a top ic  f u l l y  
described as THE PAPER BY SALTON ABOUT THE SMART SYSTEM might be re fer red  t o  
as THE PAPER, THE PAPER BY SALTON, THE PAPER ABOUT THE SMART SYSTEM and so on. 
A descr ipt ion i n  the AUTONOTE2 language consists of a noun modified by 
adject ives  and preposi t ional  phrases. The words t h a t  modify any given term 
may themselves be modified in exactly the same way. In effect ,  each adjec- 
tive and prepositional phrase functions as a phrase component that imparts 
greater detail to the overall description. In the example above, BY SALTON 
and ABOUT THE SYSTEM provide information about the paper; SMART specifies 
which system is meant. 
To facilitate efficient communication we require a representational 
framework that makes explicit the component phrases of each topic description. 
Given such a framework, we have a basis for comparing incomplete descriptions 
with the representation to determine possible topic referents. 
-. 
A system that makes use of syntax in the user's 
descriptor entries increases descriptive power in that it permits distinctions 
that, in geberal, will not be made in keyword-based retrieval systems. A des- 
cription such as THE ORGANIZATION OF THE PAPER ABOUT MTS is semantically 
quite different from THE PAPER ABOUT THE ORGANIZATION OF MTS, despite the fact 
that both contain the same words, A system that takes into consideration 
the syntactic relationships that hold among the words ORGANIZATION, PAPER, 
and MTS can discriminate between the two. 
The considerations outlined thus far lead quite naturally to some form 
of dependency representation for the user's topics.  Essentially, a depen- 
dency representation for the AUTONOTE2 language would reflect the syntactic 
dependence of each adjective and prepositional phrase upon an appropriate 
noun. Such a framework provides the essential information for enhancing 
descriptive power and communicative efficiency as defined above. 
Hierarchical representations. We view a topic as a group of intercon- 
nected subtopics, each bearing on a central theme yet with varying levels of 
generality. To make this notion more concrete, consider a user of AUTONOTE2 
putting down his thoughts and ideas for a book he is writing. He begins by 
entering some general material which he describes simply as "THE BOOK 
ABOUT.. . ." At some later time he may enter an outline for the book, a list 
of reference materials he will use, publishing arrangements, etc. Still 
later, he wi.11 enter materials for the chapters of his book and perhaps out- 
lines for each chapter, In time he will have defined a host of related des- 
criptions. Fig. 3 gives a pictorla1 representation of the resultant complex 
"topic. " The representational spl~eme of AUTONOTE2 was designed with complex 
hierarchies such as this one in mind. In other words, we want to represent 
related topic descriptions via interconnections in a network, 
The essential idea is that such a network corresponds to a map of the 
organization of the associated textual materials--a map that should reflect 
important structural relationships among the materials from the user' s view- 
point. A hierarchical representation of this kind is especially effective 
during retrieval. If the user requests materials dealing with h i s  book, for 
example, the system can also inform him that he bas more specific items deal- 
ing with the publishing arrangements, the component chapters, and so on. 
The notion of a representational network fits well with the dependency 
framework we require. The syntactic dependencies among the words and phrases 
of a description may be used to represent structural relationships among the 
user's topics. In the example above, the network connection between the 
OF CHAPTER 1 
W E  BOOK 
Fig. 3 - A Topic Hierarchy 
"out line" and the "book1' corresponds to the syntactic dependency of "book" 
upon "outline1' in the descrip tionL THE OUTLINE OF THE BOUK ABOUT. . . . 
Au~plentation of the repre-sentation. In the previous discussion of 
communicative efficiency we were concerned with associating an incomplete 
description with its corresponding topic. In designing the representational 
framedork we also had to consider the cqse in which a reference provides a 
more detailed d'escription of an existing topic. In such instances we want to 
enrich the topic represbntation to include the additional information. 
Whether additional descriptive information is encountered in a subsequent 
item description or in a retrieval request, we want the system to incorporate 
it into its existing knowledge of the user's topics. This requires that the 
representation be stmctured in such a way that dynamic augmentation is easily 
accomplished. 
The representation of context. In providing a framework for interpre- 
ting terse, incomplete references we naturally are confronted with the problem 
of ambiguity. A description such as THE PAPER, or TRE PAPER ABOUT MICROPRO- 
GRAMMING may in fact satisfy a large number of distinctly described topics. 
To deal with this problem we require some kind of contextual framework that 
enables the system to infer, where possible, the intent of a vague or ambigu- 
ous reference. A user who has been entering material for a paper he is 
writing should be able to describe a subsequent item as,say, THE OUTLINE OF 
THE PAPER, and have the system infer which paper he means. In general then, 
we want the representatfonal framework to include information that identifies 
the "working- context ," i. e. , those topics the user has ref erred to recently. 
System interrogation of the user. Presented with an ambiguous descrip- 
tion "out of context," the system is faced with much the same dilemma a human 
listener would face. In such instances, we want the system to be capable of 
asking pertinent questions to resolve the ambiguous reference. This implies, 
of course, that the representation preserve sufficient information to enable 
it to reconstruct descriptions of the user's topics. 
werview of the AUTONOTE2 Irpplementation 
Data structures. We have now presented the major design requirements 
for the representational framework. These preliminary criteria suggest a 
representation organized as a network of (possibly interconnected) dependency 
structures obtained from syntactic analysis of topic descriptions. The net- 
work data structures are- discussed in section IVin terms of the representa- 
tional criteria and also the computational requirements--how they are to be 
accessed, modified, and so on. 
The parser. The parsing of descriptions is guided by the state of the 
representation at the point they are entered. For this reason, the parsing 
algorithm is treated in section IV in conjunction with the representational 
data structures. The&presentation includes detailed dlscussion of the parsing 
problems encountered and the heuristics employed in dealing with them. 
Network,,locati,on. The function of the network locator is to analyze the 
parse tree to decide whether the description references an existing topic or 
defines a new one. Once this decision is made, it constructs a list of any 
network madifications required to represent the topic and its associated item 
reference. The network location algorithm is described in section V. 
Retrieval. The AUTONOTE2 retrieval component is invoked via a FIND 
command. The command takes a topic description as its argument. The FIND 
processor in turn calls upon both the parser and network locator, regaining 
control after the appropriate network topic has been identified. Text items 
directly associated with the topic then may be retrieved from the data base. 
Alternately, the retrieval component will move to structurally related topics 
in the representational network to collect additional item references for 
subsequent display. 
To reconstruct topiq descriptions from the network, AUTONOTE2 includes 
a SPEAKER module. If the user's description is ambiguous, for exmple, the 
network locator may call for a display of the alternative topics. The FIND 
processor employs the SPEAKER to present descriptions of topics structurally 
related to the user's original query. The user also may invoke the SPEAKER 
explicitly, via a DESCRIBE comnd, to obtain descriptions of some subset of 
the topics in the representational network. The retrieval component, the 
SPEAKER, and the DESCRIBE command are treated in section VI. 
Network modification. The last major component obf AUTONOTEP, the net- 
work modification processor, is described in section VIZ. It allows the 
user to delete topic representations, create new ones, and merge multiple 
topics into a single representation. It also enables the user to move 
through clusters of related topics in order to explore associations in the 
network. 
Auxiliary commands. Various auxillary conrmands and facilities are given 
in Linn (1972, Appendix By. This appendix also includes some discussion of 
usage strategies for achieving the most effective use of AUTONOTE2. 
Fig. 4 depicts  the  organization of the  AUTONOTE2 components wi thin  the 
AUTONOTE system framework, 
IV. THE PARSER AND THE REPRESENTATIONAL NETWORK 
Overview 
When the  user  wise$ t o  descr ibe  a t e x t  i t e m ,  w e  assume he has i n  mind 
some subjec t ,  topic ,  o r  informational object t h a t  can be characterized by a 
phrasa l  descript ion.  A descr ip t ion  may convey a r e f e e n c e  t o  a t o p i c  the  user  
has d e a l t  with earlier; o r  i t  may def ine  a new one. The descr ip t ion  is ana- 
lyzed t o  determine a dependency tree--a s t r u c t u r e  that preserves the  o r i g i n a l  
words and phrases of the  descr ip t ion  and the  s y n t a c t i c  dependencies among 
them. 
In  constructing t h i s  tree, the parser  incorporates primary u n i t s  ca l led  
simple phrases. A simple phrase may cons is t  of a modifier and a noun (e .g., 
ACM CONFEFUNCE), o r  of a noun followed by a preposi t ion and modifier (e.g., 
OUTLINE OF PAPER). The parser  e x t r a c t s  these b a s i c  phrases from t h e  o r i g i n a l  
descr ip t ion  and records t h e  s y n t a c t i c  dependencies among them. A descr ip t ion  
such as THE OUTLINE: OF THE PAPER ABOUT AUTONOTE2 FOR THE ACM CONFERENCE will 
be analyzed i n t o  four  simple phrases: (1) THE OUTLINE OF THE PAPER, (2) THE 
PAPER ABOUT AUTONOTE2, (3) THE PAPER FOR THE CONFERENCE, and (4) THE ACM CON- 
FERENCE. Each simple phrase cons i s t s  of a subjec t  noun and a modifier word. 
When two simple phrases have a common subject  noun, w e  say they a re  coordin- 
ate simple phrases. When a modifier word of one simple phrase subsequently 
-
becomes the subjec t  noun of another,  we say the latter phrase is  subordinate 
DESCRIPTION 
PROCESSOR 
Fig. 4 - The Organization of AUTONOTE2 @thin the AUTONOTE System 
t o  the former. In  the above example, THE PAPER ABOUT AUTONOTE2 and THE PAPER 
FOR THE CONFERENCE are coordinate simple phrases--both have PAPER a s  the i r  
subjec t  noun. Both of these  a r e  subordinate t o  the phrase OUTLINE OF THE 
PAPER, i n  which PAPER appears a s  a modifier word. Additioaally, the  simple 
phrase THE ACM CONFERENCE i s  subordinate TO THE PAPER FOR TWE CONFERENCE. 
Subordinate phrases simply qual i fy  t h e  use of t h e i r  subject  words. For ex- 
ample, phrases subordinate t o  THE OUTLINE OF THE PAPER provide a more de ta i led  
descr ipt ion of t h e  paper ("ABOUT AUTONOTE2 , " and "FOR THE CONFERENCE") ; the 
phrase subordinate t o  THE PAPER FOR THE CONFERENCE fu r the r  q u a l i f i e s  the con- 
f erence. 
In  e f f e c t ,  two kinds of dependency information are extracted by the 
parser .  The f i r s t  is the  dependency of ad jec t ives  and preposi t ional  phrases 
upon a noun. This information is  ref lec ted  i n  the  se l ec t ion  of the  simple 
phrases themselves. Second, there  are the  dependency re la t ionships  among 
t h e  simple phrases of the descript ion,  This information, expressed i n  ttrms 
of subordinate and coordinate linkages, may be represented by a tree s t ruc tu re  
consis t ing of nodes with simple phrases a t  the  terminal branches. Fig. 5 * 
gives the  tree s t r u c t u r e  f o r  the  example. Simple phrases wlth an immediate 
lknkage t o  a node are said t o  d i r e c t l y  describe t h a t  node. Note t h a t  the two 
coordinate phrases from the  example d i r e c t l y  describe a common node, node B. 
The subordinate relationship of the node B phrases t o  the  node A phrase, and 
i n  turn, t h a t  of t h e  node C phrase t o  the node B phrases i s  re f l ec ted  by down- 
ward branches connecting those nodes. 
The re su l t an t  t r e e  s t ruc tu re  degines the r e p r e s e n t a t f ~ n  of i t s  correspon- 
ding topic. Representations of each of the  use r ' s  topics  are organized into a 
Fig. 5 - Siaiple Phraqe Dependency Structure 
hierarchica l  data structure cal led the  representat ional  network. The repre- 
sentational fietwork is composed of interconnected nodes, s imple  phrases, and 
words. When descript ion i s  mapped ohto the network, the  number of t he  asso- 
cia ted  text item i s  s tored with the  highest  order node i n  the corresponding 
topic  representation. 
Each node i n  the network may b&ve up to four types of linkages: (I) 
pointers  down t o  simple phrases that d i r e c t l y  describe the node; (2) pointers  
d m  t o  subordinate nodes; (3) pointers  up t o  superior nodes; and (4) poin- 
t e r s  to textual materials  associated with the  node. Each simple phrase or 
single word is d i r ec t l y  accessible  3s a un i t  i n  the network. through hash cod- 
ing procedures similar t o  those used in maintaining the  AUTONOTE keyword in- 
dex. I ~ s o c i a t e d  with each simple phrase are the l inkages t o  the node(s) the 
phrase directly describes. In  turn,  each sdngle word has associated pointers  
that lead the  system t o  the s imple  phrases  containing the  word. Fig. 6 il- 
l u s t r a t e s  the network representation of the eftample. 
Once a topic  is defined i n  t h e  network, t h e  user can r e f e r  t o  i t  using 
a word, a simple phrase or composition of simple phrases, For example, 
should the user  later describe a new text item as say, OUTLINE OF THE PAPER 
or OUTLINE OF THE PAPER ABOUT AUTONOTF2, the system will note that: i t  al- 
ready has a representation for the topic. The only change t o  the  network i n  
such cases i s  the addtkion of new item reference linkage t o  the i d e n t i f f e d  
node (node 1). In  general, the system attempts to relate each new item des- 
cription t o  those it a l ready  "knows" about. For new t o p i c s ,  new nodes are 
al located i n  the network. Should some subset of the simple phrases of a new 
descr ipt ion r e f e r  t o  an exis t ing  topic, the additional simple phrases are 
Pointer  to tex t  
PAPER about 
F i g  6 - Corresponding Representational Network Structure 
linked to that existing representation. For example, if in reference to the 
same paper the user describes another item as THE ABSTRACT OF THE PAPER ABOUT 
AUTONOTE2, the system would modify the network to that shown in Fig. 7. 
Design of the Network Data Structures 
L i s t  structures. As noted above, the representational criteria dictate 
a hierarchical ne4Qork-type organization, based upon dependency analyses of 
topic descriptions. List structures are particularly well suited for this 
kind of application. They provide a convenient representahon for depen- 
dency trees and are especially appropriate for dealing with complex, evol- 
ving structures. 
In designing special purpose list structures for the representational 
net~~ork,  we first specified the logical components of the structure and de- 
fined the interconnections among these primitives. Three logical components 
were forumlated--simple phrases, nodes, and words. The following subsections 
present the major design considerations for each structural component. 
Simple phrases,. Given our goal of communicative efficiency, we chose 
the simple phrase as a primary udit for the network. By analyzing a toplc 
t ? description into simple phrases we are in effect isolating possible short- 
hand" references to the given topic. The representational data structures 
have been designed to allow a topic to be referenced through any of its com- 
ponent simple phrases. 
Simple phrases are formed from either adjectival or prepositional modi- 
fication of a noun. Very often, an adjectival modification can be equiva- 
lently expressed by a prepositional phrase dependent upon the same noun 
Pointer  to 
Pointer to text  
Fig. 7 - Network Representation of a Topic Hierarchy 
(example: THE PAPER ABOUT AUTONOm and THE AUTONOTE PAPER). In  o the r  in-  
stances the  a d j e c t i v a l  form may have m u l t i p l e  i n t e r p r e t a t i o n s ;  THE SMITH 
ARTICLE could r e f e r  t o  an a r t i c l e  by Smith o r  possibly an a r t i c l e  about 
Smith. Some preposi t ions  may be used synonymousLy i n  a p a r t i c u l a r  context 
(THE PAPER ABOUT (ON) SHORT TERM MEMORY); others  convey d i s t i n c t l y  d i f f e r e n t  
meanings (THE MEMO TO THE COMMITTEE versus THE MEMO FROM THE COMMITTEE). We 
do not dea l  with these  problems t o  the  extent  of providing a semantics f o r  
"understanding" n a t u r a l  language. Hmwer, the  representational s t r u c t u r e  
makes e x p l i c i t  the  var ious  p o s s i b i l i t i e s ,  s o  tha t  the  sys t em i s  able t o  gen- 
e r a t e  p laus ib le  alternatives. 
W e  treat a d j e c t i v a l  modification as a s p e c i a l  case, a s  i f  the modifier 
and subjec t  noun were r e l a t e d  by an unspecif ied preposi t ion.  In  terms of 
the  d a t a  s t r u c t u r e  design, a l l  simple phrases composed of the  same two words 
are mapped i n t o  a l a r g e r  u n i t ,  each subunit of which represents  a p a r t i c u l a r  
ins tance of a simple phrase i n  a t o p i c  descr ipt ion.  This arrangement assures  
that all information on simple phrases involving any two words i s  accessible 
co l l ec t ive ly .  Th i s  information w i l l  then be a t  hand t o  provide a b a s l s  f o r  
i n t e r p r e t i n g  the  a l t e r n a t i v e  r e f e r e n t s  of each incoming simple phrase. For 
example, should t he  user  make reference t o  THE SMITH PAPER and the system 
f i n d s  only PAPER ABOUT SMITH i n  the  network, then that s ing le  a l t e r n a t i v e  
is chosen. On the  o the r  hand, i f  PAPER BY SMITH also is present ,  the  system 
considers both p o s s i b i l i t i e s .  
Network nodes. The next structural component of the representa t iona l  
network is  the node, A node groups together a s e t  of simple phrases t h a t  
comprise the descr ip t ion  of the node, m e  node a l s o  functions a s  a  co l l ec to r  
of i t e m  references ,  Each node i n  the representa t iona l  network corresponds 
t o  a top ic  o r  concept pe r t inen t  t o  the items of t e x t u a l  ma te r i a l  associa ted 
with i t .  The simple phrases that d i r e c t l y  descr ibe  a node def ine  the  cor- 
responding concept. Any given node may be l inked t o  more general  (lower) 
nodes, o r  t o  more s p e c i f i c  (higher) nodes. For example, a node t h a t  repre- 
sen t s  a p a r t i c u l a r  paper may be linked downward t o  another tha t  describes 
a conference a t  which t h e  paper was presented; i t  may a l s o  be l inked t o  
severa l  higher order nodes corresponding t o ,  say, a summary, an ou t l ine ,  and 
a review of the paper. As more and more i t e m s  are described,  addi t iona l  
topics  may be t i e d  i n t o  t h e  same conference node. The u l t imate  r e s u l t  w i l l  
be a highly interconnected set  of concept nodes, each with its own s e t  of 
associated t e x t u a l  materials. 
To achieve th i s  kind of s t r u c t u r a l  organization f o r  the network, we 
make use of the dependency re l a t ionsh ips  i n  the  use r ' s  descr ip t ions :  each 
node l e v e l  corresponds t o  a s y n t a c t i c  dependency leve l .  I n  terms of the  
example above, t h e  ad jec t ives  and prepos i t iona l  phrases modifying the  noun 
"paper" a r e  formed i n t o  simple phrases t h a t  w i l l  d i r e c t l y  describe a common 
node. Simple phrases iden t i fy ing  t h e  c o n f e r ~ n c e  w i l l  descr ibe  a subordinate 
node due t o  the syn tac t i c  dependency of "conference" upon "paper" i n  a phrase 
of the  form, PAPER AT THE...CONFERENCE. Superior nodes are assigned t o  the  
out l ine ,  t h e  summary, and the review, r e f l e c t i n g  the  dependence of "paper'' 
upon those nouns i n  appropr ia te  descr ipt ions .  
A node may be viewed as a co l l ec t ion  of po in te r s  t o  simple phrases, 
other nodes, and t e x t  i t e m s .  A l l  node l inkages a r e  two-way. Pointers  d m  
from a node to i t s  simple phrases a r e  required i n  order t o  reconstruct  a 
descr ip t ion  of t h e  node, Po in te r s  down t o  subordinate nodes a r e  necessary f o r  
the  same reason. Both upward and downwa~d po in te r s  t o  o ther  nodes provide a 
means f o r  moving from any top i c  t o  s t r u c t u r a l l y  r e l a t e d  ones. Associated with 
each instance of a simple phrase i s  a po9nter t o  the  node where item re fe r -  
ences are s to red ,  F ina l ly ,  bookkeeping information s to red  with each t e x t  i tem 
includes po in t e r s  t o  each t o p i c  node wi th  which the i t e m  i s  associated.  Item- 
node l inkages enable t h e  system t o  provide the  user  wi th  t op i c  descr ip t ions  of 
any t e x t  i t e m .  
Words. The represen ta t iona l  s t r u c t u r e s  considered thus  far  provide s i m -  
p l e  phrases as the  s o l e  means f o r  accessing the  nodes i n  the  network. A l e s s  
res t rAct ive  access mechanism a l s o  i s  required,  f o r  s e v e r a l  important reasons. 
First, i t  would be u n r e a l i s t i c  t o  assume t h a t  t h e  use r  will always phrase ref- 
erences t o  a p a r t i c u l a r  t o p i c  i n  exac t ly  the  stme way, Second, s i n g l e  word 
descr ip t ions  play an important r o l e  i n  achieving our goal  of communicative 
efficiency. Since we a n t i c i p a t e  t ha t  users w i l l  make frequent use of s i n g l e  
word references when working i n  the  context of a p ~ r t i c u l a r  t o p i c ,  we  want t o  
provide a n a t u r a l  and convenient treatment of such descr ip t ions .  F ina l ly ,  a 
phrasa l  desc r ip t ion  can convey a higher  order  c a t e g ~ r i z a t i o n  of an e x i s t i n g  
top i c  without containing a simple phrase f o r  t h a t  topic .  For example, THE 
REVIEMER'S COMMENTS ON THE PAPER may reference a paper mentioned e a r l i e r ;  ye t  
i t  conta ins  no simple phrases descr ib ing t h a t  paper. 
These considerat ions lead us t o  the t h i r d  l o g i c a l  component of the  network 
da ta  s tmctu\ res ,  the s i n g l e  word. Es sen t i a l l y ,  each component word provldes ac- 
cess t o  a series of po in t e r s  t o  simple phrases i n  which the  word occurs.  
Word-to-phrase po in te r s  a r e  of two types: those ind ica t ing  usage 
as subject noun; and those indicating modifier usage in a particular simple 
phrase. As we shall see later, this distinction is required in order to 
relate new simple phrases to existing topics at an appropriate node level. 
Hadng specified the three logical components and the linkages in the 
representational network, we now turn our attent&on to the storage implemen- 
tation of these structures. 
Storage Implementation of the Network Structure 
There are three directories needed to maintain the representational net- 
work, one for each of the components of the structure. All directory infor- 
matlon must, of course, be saved in permanent storage between AUTONOTE2 ses- 
sions. Two design alternatives were considered for maintaining the network 
during execution of the program. Thedirectories could be accessed and up- 
dated on disk, or they could be brought into core storage for the duratlon 
of the session. We adopted the former strategy for a number of reasons. 
First, AUTONOTE is highly oriented toward the use of disk file storage. 
Several file interface routines were available at the outset for conveniently 
storing and accessing information through the MTS file system. Second, as 
the network grows in complexity, it becomes increasingly unlikely that the 
user will reference the major portion of the network during any given ses- 
sion. By maintaining the network in disk files, the amount of core storage 
required is substantially reduced. Finally, the file approach greatly 
simplified the programming effort, especially in those system components 
that operate recursively on the list structured network. We will elaborate 
on this point further in section VI, which i l lu s t ra te s  the simplification of 
recursive processes in AUTONOTE2. 
Rather than s t o r e  a l l  the d i r e c t o r i e s  i n  a s i n g l e  d fsk  f i l e ,  we  chose 
t o  maintain each d i r e c t o r y  s epa ra t e ly .  This  s t r a t e g y  prese rves  t he  l o g i c a l  
d i s t i n c t i o n  among t h e  t h r e e  types  of d i r e c t o r y  information,  and has  a l s o  
s imp l i f i ed  t he  p rograming  of t he  system. We now desc r ibe  the  o rgan iza t ion  
of each of t he  d i r e c t o r y  f i l e s .  
The node d i r ec to ry .  Each node i n  t h e  r e p r e s e n t a t i o n a l  network has  a 
corresponding i n t e g r a l  node number which is a l s o  the  l i n e  number i n  t he  node 
d i r e c t o r y  f i l e .  As new node numbers are needed t o  r ep re sen t  new t o p i c s ,  the  
next s e q u e n t i a l l y  numbered l i n e  i n  t h e  node d i r e c t o r y  i s  assigned as the  node 
number. Each node d i r e c t o r y  l i n e  contarns  four  fields--one f o r  bookkeeping 
information and t h r e e  f i e l d s  f o r  t h e  upward, downward, and i tem re fe rence  
p o i n t e r s  f o r  t h e  node. The i t e m  r e f e r ence  region con ta ins  a l i s t  o f  I n t e g e r  
i t e m  numbers. The upward p o i n t e r  reg ion  a l s o  con ta ins  a l i s t  of rn t ege r s  
t h a t  r ep re sen t  immediate l inkages  t o  supe r io r  nodes. The two types of down- 
ward p o i n t e r s  ( t o  mdes and t o  phrases)  a r e  s to red  i n  a common reglon.  Each 
node, simple phrase,  and s i n g l e  word has  a corresponding f i l e  l l n e  number I n  
i ts  r e spec t ive  d i r e c t o r y  f i l e .  I n  t he , ca se  of nodes, the  l i n e  number i s  
simply t h e  node number. I n  the case  of words and simple phrases ,  the  l i n e  
nuntiber is the  r e s u l t  of a, hash codPng process  on a compact charac te r represen-  
t a t i o n  of t he  word o r  phrase.  Thus a "pointer" 1s  a c t u a l l y  a f i l e  l i n e  num- 
ber.  Downward p o i n t e r s  t o  nodes and phrases  a r e  d i s t i ngu i shab le  i n  t he  node 
d i r e c t o r y  on the  b a s i s  of t h e  magnitude of t he  l i n e  number. 
Since each of t he  t h r e e  p o i n t e r  f i e l d s  is of f i xed  length ,  t h e r e  is a 
maximum number of each type of p o i n t e r  f o r  a given node d i r e c t o r y  l i n e .  
Each f i e l d  consequently has an  associa ted cont inuat ion p o i n t e r  t o  a l i n e  
where add i t iona l  po in te rs  a r e  stored i f  necessary. 
The phrase di rectory.  To loca te  the  phrase d i r ec to ry  l i n e  f o r  a  par- 
t i c u l a r  simple phrase, a hash coding funct ion i s  appl ied t o  the  character  
s t r i n g  formed by concatenating the  modifier word, a s l a sh ,  and the subjec t  
word. For example, the d i r ec to ry  l i n e  f o r  the  simple phrase PAPER ABOUT 
AUTONOTE i s  the hashcode f o r  the  s t r i n g  "AUTONOTE/PAPER." Since the  hashing 
function operates  only on t h e  modifier and sub jec t  word, simple phrases 
formed from the same two words, but with d i f f e r i n g  (or  no) preposi t ions ,  are 
mapped i n t o  the same d i rec to ry  l i n e  number. 
To d i s t ingu i sh  among the  var ious  ins tances  of the  same two-word combin- 
a t ion ,  the d i rec to ry  line f o r  simple phrases c o n s i s t s  of a s e r i e s  of p o i n t e r  
blocks. Each poin ter  block contains a code f o r  the  p a r t i c u l a r  prepos i t ion  
used, some additional bookkeeping information, and a  po in te r  t o  the  node 
d i r e c t l y  descrsbed by t h a t  occurrence of the simple phrase. 
The word directory.  The word d i rec to ry  incorporates  the  same poin te r  
block p r i n c i p l e  as the  phrase d i rec tory .  The po in te r  f i e l d  of the  block i n  
this case i s  a poin te r  i n t o  the phrase d i r ec to ry .  The prepos i t ion  code f i e l d  
contains a  binary f l a g  ind ica t ing  whether the p a r t i c u l a r  wdrd occurs as t h e  
subjec t  noun o r  modifier word i n  the simple phrase spec i f i ed  by the  poin te r .  
Like phrases, each word d i r ec to ry  l i n e  is  accessed through an e f f i c i e n t  hash 
coding algorithm. 
The word d i rec tory  a l s o  maintains prepos i t ion  usage information f o r e a c h  
word. For example, the entry f o r  MEMO may indicate that the word has 
occurred with the  prepos i t ions  ON, ABOUT, TO, FROM, e t c .  T h i s  information 
is used t o  guide the  pars ing of descr ip t ions .  
The organization of the  th ree  network d i r e c t o r i e s  is depicted i n  Fig. 8. 
$he Representational. Network: An Example 
To help  f i x  iderfs, Qe now present  a more d e t a i l e d  example t h a t  i l l u s -  
t r a t e s  the  s t r u c t u r e  of t h e  r ep resen ta t iona l  netwo2k. Suppose the user  
descr ibes  Items 157, 158, and 159 as THE PAPER ABOUT AUTONOTE FOR THE ACM 
CONFERENCE: he e n t e r s  ma te r i a l s  on t h e  organizat ion of t h a t  paper i n t o  
I t e m s  201 and 202. A summary of the  paper i s  placed i n  Item 230. The user  
a l s o  descr ibes  I t e m  270 as SMITH'S PAPER, and e n t e r s  a summary of t h a t  paper 
i n t o  Item 312. A p i c t o r i a l  representa t ion  of the r e s u l t a n t  por t ion  of the  
network is given i n  Fig. 9, whi le  t h e  corresponding d i rec to ry  contents  appear 
i b  Fig. 10. For s impl ic i ty ,  t he  simple phrase hash codes a r e  represented by 
the  a lphabet ic  charac te rs  U through 2. ( In  subsequent diagrams, w e  a l soomi t  
word-to-phrase l inkages  f o r  s impl ic i ty . )  
Pars ing of Descript ions 
This s e c t i o n  o u t l i n e s  our genera l  approach t o  pars ing t o p i c  descrip- 
t ions .  The parsing of prepos i t iona l  phrases,  consecutive modifiers ,  and 
possessive modifiers  i s  considered. 
Prepos i t iona l  phrases. Despite the  apparent s impl i c i ty  of t h e  descrip- 
t i o n  language the re  are seve ra l  n o n t r i v i a l  pars ing problems. One of these  
i s  t h e  d i f f i c u l t y  in,dletermining the  noun r e f e r e n t  of p repos i t iona l  phrases. 
The determination of noun r e f e r e n t s  is  p a r t i a l l y  a semantic problem r a t h e r  
than a purely s y n t a c t i c  one. Consider the  following two d e s c r i p t ~ o n s :  
(a) Format f o r  the word and phrase d i r ec to r i e s .  
Se r i e s  of Fixed 
Length  locks^ 
(Format Given i n  
(b) Below) 
(b) Pointer  block format i n  the  word and phrase d i r ec to r i e s .  
In te rna l  Form 
of the  Word 
o r  Phrase 
Preposi- 
t i o n  
Usage 
C 
Upward 
Link 
Fig. 8 - Representational Network Directory Formats 
Pointer  t o  
Continua- 
t i on  
Lines 
Number 
of 
Upward 
Links 
Access 
Recency 
Preposition 
codeC 
Number 
of 
Upward 
Links 
%sed i n  conjunction with the hash codihg mechanism. 
Col l is ibn 
pointera 
b For single words, there  is  one block f o r  each phrase containing the 
word. For phrases, there  i s  one block f o r  each - node that the phrase d i r e c t l y  
describes. 
Ar t i c l e  
Codes 
( c )  Format f o r  the node directory.  
Number 
of 
Downward 
Links 
%or s ing le  words, the preposit ion code is  used t o  d i s t inguish  between 
words used as subjects or  modifiers. 
For Future 
Expansion 
' Number 
of 
Items 
Preposi- 
t i o n  
Code f o r  
Each 
Downward 
Pointer  
Access 
Recency 
I 
L i s t  of 
Upward 
Poin- 
ters 
L i s t  
of 
I t e m  
Ref= 
ences 
- 
Continu- 
a t ion  
Line 
Pointers  
L i s t  of 
Downward 
Pointers  
FAg. 9 - A Complex Representation 
(a) Word directory. 
J 
(b) Phrase directbry. 
C 
Word 
10rganization 
Paper 
I Z Z E z c e  
S V 
ACH 
M t h  (poss) 
1 
r 
No 
Blocks 
1 
5 
1 
2 
1 
1 
1 
Blocks 
Line 
I No. 
U 
V 
W 
X 
Y 
Z 
v 
(c) Node directory. 
1 
Blocks 
Line 
No 
1 
2 
3 
4 
5 
6 
Fig.  10 - Corresponding Directory contentsa 
U (sub) 
W (sub) 
X (mod) 
W (mod) 
Z (sub) 
Y (mod) 
V (mod) 
Phrase 
paper/organization 
smikhlpaper (poss) 
con? erence/paper 
autonote/paper 
acm/conference 
paper /summary 
Node 3 (of) 
Node 5 (adj) 
Node 1 (for) 
Node 1 (about) 
Node 2 (adj) 
Node 4 (of) 
a See Fig. 9 .  
U (mod) X (sub) 
Y (sub) 
No. 
Blocks 
1 
1 
1 
1 
1 
2 Node 6 (of) 
Pointers 
UP 
394 
I 
* * *  
* a *  
6 
m e .  
V (sub) 
! 
Pointers 
Down 
2,W,X 
Y 
19u 
2 9 1  
V 
295 
Z (mod) 
- 
I t e m  
References 
8157, 11158, 1,159 
* a *  
#201, #202 
$203 
#270 
11312 
I) I 1 
THE MEMO (FROM THE COMMITTEE) (TO THE CHAIRMAN). 
In the f i r s t  example, both prepos i t ional  phrases r e f e r  t o  the immedi- 
a t e ly  preceding noun. I n  the  second case, both refer back t o  the noun MEMO 
a t  the beginning of t he  s t r i ng ,  Although nei ther  of these examples i s  in- 
t u i t i v e l y  ambiguous, the parsing algorithm must consider each preceding noun 
as  a possible  re fe ren t  of any given prepos i t ional  phrase, 
?he AUTONOTE2 parser  dea ls  with t h i s  problem t o  a l imited extent, by 
u t i l i z i n g  preposi t ional  clues,  For example, i f  the system f inds  t h a t  the 
noun MEMO can form a simple phrase with the  preposi t ions ON, ABOUT, TO, and 
FRW, then phrases introduced by these preposit ions w i l l  be associated with 
that noun. Such clues w i l l  not  always y ie ld  a unique parsing, of course, as 
i n  the caee of inherent ly ambiguous descriptions.  THE PAPER FOR THE CON- 
FERENCE ON GENETICS, for example, could r e f e r  t o  a paper on genetics t o  be 
delivered at a conference, or  t o  a paper which i s  t o  be delivered a t  a con- 
fyence on genetics. 
In  sucfi instances w e  r e ly  upon the  user  t o  supply t he  referent  noun 
upon request. In t he  example above, t he  system may prompt: DOES "ABOUT 
GENETICS" REFER TO PAPER OR CONFERENCE? Should the user  reply CONFERENCE, 
the simple phrase CONFERENCE ON GmETICS w i l l  be added t o  the  network. If 
at  some later t i m e ,  the parser i s  attempting t o  find a referent  f o r  the  pre- 
positional phrase ON GENETICS where CONFERENCE i s  one of the  a l t e rna t ives ,  
ft forms t h a t  simple phrase di rec t ly .  
Consecutive modifiers. A p a r a l l e l  problem arises i n  determining the 
noun referents for a s t r i n g  of consecutive modifiers. Descriptions 
containing at 111ust a single adjective for any particular noun are parsed in 
the obvious manner. A simple phrase is formed from each modifier and the 
noun following it. In the event a noun i s  preceded by two or more modifiers, 
the parser is confronted with a task similar to that of determining the 
referent of a prepositional phrase. The modifier occurring immediately be- 
fore the noun is  first processed as above. Each of the remaining modifiers, 
however, can modify any one of several words depending upon their "distance" 
f r o m  the head noun. Specifically,  any such modifier can refer to either the 
head noun or any of the other modifiers following it. Consider the descrip- 
tions : 
A summary of p 
I 
A summary of personal inform 
In both of the cases above, INFORMATION modifies the modifier RETRIEVAL which 
in turn modifies the head noun SYSTEMS. ~epending upon the user's intent, 
PERSONAL can modify either INFORMATION or SYSTEMS. The choice of modifier 
referents is an especially important problem when there are multiple parslngs, 
each resulting in a different semantic interpretation. For example, LARGE 
COMPUTER CONFEREXCE could refer t o  a conference on large computers, or a 
large conference on computers. Another important reason for our emphasis 
upon correctly identifying modifier referents concerns the use of para- 
phrasing. In the example, PERSONAL INFORMATION RETRIEVAL SYSTEMS, if we 
determine that INFORMATION modifies RETRIEVAL and PERSONAL modifies SYSTEMS, 
then the resultant topic can be paraphrased as (1) PERSONAL SYSTEMS FOR 
INFORMATION RETRIEVAL, or (2) PERSONAL SYSTEMS FOR THE RETRIEVAL OF INFORMA- 
TION. Depending upon context and the nature of other topics in the network, 
the following incomplete descriptions will in most cases identify the topic:  
1. SYSTEMS 
2. SYSTEMS FOR RETRIEVAL (or RETRIEVAL SYSTEMS) 
3. PERSO~AL SYSTEMS 
4. PERSONAL SYSTEMS FOR RETRIEVAL (or PERSONAL RETRIEVAL SYSTEMS) 
5. SYSTENS FOR INFORMATION MTRIEVAL 
6, SYSTEMS FOR RETRIEVAL OF INFORMATION 
A different choice of modif~er referents determines a correspondingly chi- 
ferent set of paraphrases, If PERSONAL was intended to modify INFORMATION, 
we would have the paraphrase SYSTEMS FOR THE ~ T R I E v A L  OF PERSONAL INFORMATION, 
with a corresponding list of incomplete references to the topic. 
As in the prepositional case, the choice of modifier referents is guided 
by the current state of the representational network. After processing the 
last modifier in the string, the parser pos i t i ons  itself a t  t he  preceding 
modifier and moves left in the input string untll the first word in the modi- 
fier string is processed. In the above example, after associating RETRIEVAL 
with SYSTEMS, the parser next examines the modifier INFORMATION. A list of 
simple phrase candidates is formed. In this case, the list contains INFORMA- 
TION RETRIEVAL and LNFORlUTLON SYSTEMS. If neither of the candidate phrases 
has been previously used, the system queries-: WHAT DOES INFORMATION MODIFY? 
The user's reply is matched against the oandidate referents and the appropriate 
simple phrase is formed. 
Possessive adjectives, Possessives are processed in much the same way as 
normal modifiers. The system recognizes the ' s  word stem and marks the root 
word as a possessive. The root word is later stored in the network directories 
along with a possessive flag. Thus the phrase SMITH'S PAPER is stored intern- 
ally as SMITH~PAPER (possessive). The removal of the stem insures that a sub- 
sequent simple phrase incorporating a preposition (PAPER BY SMITH) will hash to 
the same directory lifie thus allowing the use of either prepositional or pos- 
sessive forms in referencing topics. 
A p a r t i c u l a r l y  interesting case arises when a possessive occurs in a string 
of consecutive modifiers as in SMITH'S LATEST MEMORY EXPERIMENT. The string is 
first processed as described above; that is, a check is made to see if SMITH 
has been used in a simple phrase with LATEST, MEMORY, or EXPERIMENT. In the 
event that this yields no clues, the system then checks to see if SMITH was 
rendered as a pbssessive. Upon noting that it was, the parser carries out a 
heuristic that assumes that the possessive modifies the head noun, EXPERIMENT. 
The possessive heuristic can be fully stated as follows. A possessive 
occurring in a stfing of modifiers will be assumed to modify the head noun un- 
less another possessive occurs between it and the head noun. In the latter 
case, the first possessive will be assumed to modify the second. This is simi- 
lar to the possessive feature employed by the REL parser (Dosert & Thompson, 
1971). Thus in SMITH'S RESEARCH GROUP'S MEMORY EXPERIMENT, SMITH'S is assumed 
to modify GROUP, and GROUP'S is assumed to modify the head noun EXPERIMENT. 
The question now arises, why check the phrase directory first instead of 
applying the possessive heuristic immediately? To answer this, suppose a topic 
was or ig ina l ly  described as THE WSULTS OF THE MEMORY EXPERIMENT BY SMXJTH and 
t he  user  now at tempts  t o  r e f e r  t o  i t  as SMITH'S MEMORY EXPERIMENT RESULTS. I f  
t he  possess ive  h e u r i s t i c  were applied immediately, the  system would i n c o r r e c t l y  
form the  simple phrase SMITH'S RESULTS, n o t  SMITH'S EXPERIMENT. By checking 
the  network f i r s t ,  t he  simple phrase EXPERImNT BY SMITH w i l l  be detec ted  and 
the  system w i l l  pa r se  the  desc r ip t i on  appropr ia te ly .  
Implementation of the  Parse r  
The u l t ima te  goal of t he  pa r se r  i s  t o  determine t h e  simple phrases of a 
t o p i c  descr ip t ion .  The pars ing algori thm is implemented as a two s tage  pro- 
cess .  The f i r s t  s t age  is a prel iminary scan t o  a s c e r t a i n  t h a t  the  s t r i n g  i s  
i n  a form acceptable  f o r  ana lys i s .  The desc r ip t i on  i s  segmented i n t o  an 
ordered list of words, each of which i s  marked as e i t h e r  WORD, POSSESSIVE, 
ARTICLE, o r  PEPOSITION. The parse r  makes no d i s t i n c t i o n  between nouns and 
modif iers  u n t i l  completing the  scan. A t  t h i s  po in t ,  the  l a s t  i n  a series of 
consecutive WORDS i s  marked as a NOUN; t h e  preceding words a r e  marked a s  MOD- 
IFIERS. Possessive modif iers  a r e  an exception as they can be recognized ex- 
p l i c i t l y  during t h e  scan. A record of a r t i c l e  usage i s  a l s o  kept ,  but  t he  
a r t i c l e s  themselves a r e  n o t  placed on the  word l i s t .  
The prel iminary scan of the  desc r ip t i on  can be viewed as a simple f i n i t e  
state process.  Of course,  t o  be completely formal, t he  recognizer  would have 
t o  examine each input  charac te r .  For convenience w e  w i l l  assume a f i v e  s t a t e  
automaton wi th  inputs :  WORD, POSSESSIVE, PREPOSITION, and ARTICLE. The state 
t r a n s i t i o n  graph f o r  the  machine i s  given i n  Fig. 11. The machine s t a r t s  i n  
state So, examines t he  next  input  and moves t o  a new s t a t e .  I f  a t  the  end of 
t h e  input  s t r i n g ,  the  machine is i n  state S ca l l ed  the  f i n a l  s t a t e ,  the  in- 1' 
put  is accepted; otherwise,  the  u se r  i s  asked t o  rephrase.  Note t h a t  i n  s t a t e  

S2' the machine has just encountered an article and is anticipating a "word." 
If the machine is in state S upon completion, it has juat recognized a pre- 0 
position and is expecting an object; thus, the string is rejected. The state 
S is reached whenever a possessive is encountered. Since a possessive must 4 
have an object noun, a "word" input is required to reach state  S1. State S 3 
is a trapping state; once entered, the machine remains in that state regard- 
less of the remaining input and the description is consequently rejected. 
State S corresponds to various error conditions--two consecutive prepositions 3 
or articles, an article between two words, a phrase beginning wlth a preposi- 
tion, etc. 
The state transitions for the description BRUNER'S FIRST EXPERIMENT ON THE 
CONSERVATION OF LIQUIDS are given below along with the resultant word list. 
INPUT 
Bruner' s 
First 
Experiment 
On 
The 
Conservation 
Of 
Liquids 
TYPE 
Possessive 
Word 
Word 
Preposition 
Article 
Word 
Preposition 
Word 
WORD 
-
Bruner ' s 
First 
Experiment 
On 
Conservation 
Of 
Liquids 
RESULTANT STATE 
s4 
S1 
S1 
So 
S2 
S1 
$0 
S Accept 1 
TYPE 
-
Modifier 
Modifier 
Noun 
Preposition 
Noun (the) 
Preposition 
Noun 
Descript ions found acceptable by the scanner next undergo ana lys i s  by the  
second stage procedure. This algorithm steps through the  word l i s t  and bu i ld s  
a t a b l e  of simple phrases ca l l ed  the phrase t a b l e .  Each en t ry  i n  the phrase 
t a b l e  Includes (1) the  i n t e r n a l  character  represen ta t ion  of t he  phrase f o r  use  
i n  hash coding, (2) a numerical code f o r  the prepos i t ion  used, (3) the  hash 
code (d i rec to ry  line number) f o r  t h e  phrase, (4) a list of nodes d i r e c t l y  des- 
cr ibed by the  phrase,  and (5) a coordinate o r  subordinate l i n k  t o  another 
phrase t a b l e  ent ry .  
We now i l l u s t r a t e  the  const ruct ion  of the  phrase t a b l e  by following 
through severa l  examples. 
The parser i n  operation. Let  u s  assume t h a t  a u se r  is running the system 
f o r  t he  f i r s t  t i m e ;  consequently, t he  t h r ee  network d i r e c t o r i e s  a r e  i n i t i a l l y  
empty. I t e m  No. 1 is  opened, some text is i n s e r t e d ,  and the  u se r  descr ibes  i t  
as THE PLANNED PAPER ABOUT AUTONOTE FOR THE CONFERENCE. The descr ip t ion  suc- 
ce s s fu l ly  passes the prel iminary scan aqd t h e  word l ist  is  constructed.  The 
parse r  then moves on t o  determine the  simple phrases.  
The modifier PLANNED i s  f i r s t  noted. Since i t  i s  followed immediately by 
a noun, the  simple phrase PLANNED PAPER becomes the  f i r s t  e n t r y  i n  the  phrase 
t ab le .  Next the prepos i t iona l  phrase ABOUT AUTONOTE i s  encountered. Again 
t he re  i s  only one poss ib le  noun r e f e ren t .  The phrase PAPER ABOUT AUTONOTE is  
entered  i n t o  t he  t a b l e  and marked as coordinate w i t h  t he  first entry .  To 
determine the  r e f e r e n t  of FOR CONFERENCE, the  system must consider  two alter- 
nat ives :  AlfTONOTE FOR CONFERENCE and PAPER FOR CONFERENCE. The network i s  in-  
terrogated t o  determine i f  e i t h e r  of t h e  candidate phrases has been previously 
used. This tes t  f a i l s  since the network is empty a t  c h i s  point .  A check is 
then made i n  the  word d i r ec to ry  t o  determine i f  e i t h e r  AUTONOTE o r  PAPER has 
headed a s imple  phrase wi th  the prepos i t ion  FOR* This a l s o  f a i l s  so the  sys-  
t e m  asks t h e  user :  DOES "FOR CONFERENCE" REFER TO PAPER? A yes response 
r e s u l t s  i n  t he  add i t ion  of PAPER FOR CONFERENCE t o  the  phrase t ab le .  Since 
t he  noun r e f e r e n t ,  PAPER, is  the  same a s  the previous phrase,  the new e n t r y  
is  marked as coordinate wi th  PAPER ABOUT AUTONOTEw The completed phrase t a b l e  
i s  given i n  Fig. 12. 
(1) autono te/paper  
(2) planned/paper 
(3) conferenee/paper 
Fig. 12 - Sample Phrase Table 
The phrase t a b l e  fs next  passed t o  t h e  network loca tor .  We w i l l  assume i t  
determines that t he  user is  def in ing a new topic .  Using the  s y n t a c t i c  depen- 
dencies i n  t he  phrase t a b l e ,  the  network loca to r  ass igns  new node numbers t o  
t he  phrases i n  the  descr ip t ion .  I n  t h i s  case,  a l l  t h r ee  phrases are coordin- 
ate; each will directly descr ibe  node No. 1 i n  the  network. I n  add i t ion ,  a 
reference  t o  Item NO* 1 is  s tored with t h e  t o p i c  node ( see  Fig. 13). 
The user next e n t e r s  Text Item Noo 2 describing i t  as THE ORGANIZATION OF 
THE PAPER FOR THE ACM CONFERENCE. The system proceeds as before  untll i t  en- 
counters t h e  p repos i t i ona l  phrase FOR THE CONFERENCE. It forms the  two a l t e r -  
na t ives  PAPER FOR CONFERENCE and ORGANIZATION FOR CONFERENCE0 Upon in t e r ro -  
gating the network, it  finds t h a t  PAPER FOR CONFERENCE has been defined 
previously and accepts that candidate. ACM CONFERENCE is added to the phrase 
table and the parsing is complete (Fig. 14). 
PAPER about 
Autonote 
(I) paper/organization 
(2) con? erence/paper 
(3) acm/ con? erence 
Fig. 14 - Sample Phrase Table 
The network locator must then determine ff the user is referring to the 
same paper or a new one. The operation of the network locator will be dis- 
cussed in detail in the next chapter. Let us assume for now that the current 
description is indeed a reference to the same paper. The simple phrase PAPER 
FOR CONFERENCE is already in the network. The system must then decide what to 
do with THE ORGANIZATION OF PAPER, and with ACM CONFERENCE. Since the  former 
is  super ior  t o  the  node 1 phrase, i t  is assigned t o  node 2 and a downward 
poin te r  from node 2 t o  node 1 i s  added. The phrase ACM CONFERENCE, on the 
other hand, is subordinate t o  a node 1 phrase. Thus i t  is  assigned a new node 
number (node 3) and a po in te r  up from node 3 t o  node 1 is  added. Phrase-to- 
node and node-to-node poin te rs  a r e  two way, thus corresponding poin te rs  down 
from node 1 t o  node 3, and up from node 1 t o  node 2 a r e  a l s o  added. The r e s u l  
tant  network i s  i l l u s t r a t e d  i n  Fig, 15. This example poin ts  out an i n t e r e s t -  
ing f e a t u r e  of the  AUTONOTE2 system. Although I t e m  No, 1 was o r i g i n a l l y  des- 
cribed as alpaper f o r  some unspecified conference, a subsequent reference t o  
t h a t  paper has enriched i t s  descr ipt ion.  
V, THE NETWORK LOCATOR 
The purpose of t h e  network loca to r  i s  t o  determine whether the  use r ' s  des 
c r i p t i o n  makes reference t o  an e x i s t i n g  top ic  i n  the  representat ional  network. 
Its decis ion is  based on the  information i n  the  phrase t ab le  and the current  
s t a t e  of the network. Once the  decis ion i s  made, the  loca tor  bu i lds  a tab le ,  
ca l led  the  l i n k s  tab le ,  t h a t  s p e c i f i e s  the  changes t o  be made i n  the  network 
t o  represent  the descr ipt ion.  
In cases where the  input  descriptiori  matches exac t ly  some s t r u c t u r e  i n  
the  network, the  l i n k s  t a b l e  w i l l  specify  only the addi t ion of an i t e m  re fe r -  
ence. When the description def ines  a new topic ,  every phrase i n  the phrase 
t ab le  w i l l  be assigned a new node and l i n k s  e n t r i e s  w i l l  be made f o r  the pro- 
per node-node linkages. 
F i g .  15 - Network after Augmentation 
I n  order  t o  descr ibe  more p rec i se ly  t he  operat ion of the  network loca to r ,  
l e t  us assume the  network has  evolved t o  t he  s t a t e  depicted i n  F ig .  16. Note 
t h a t  by s t a r t i n g  a t  any node and t r ac ing  downward through the  network, i t  i s  
poss ib le  t o  reconst ruct  the  descr ip t ion  of the  t o p i c  the  node represents .  The 
nodes i n  t he  network represent  the  fo'llowing topics .  
Node 1. THE PLANNED PAPER ABOUT $WONOTE FOR THE ACM CONFEIIENCE. 
Node 2. ORGANIZATION OF THE PLANNBD PAPER ABOUT AUTONOTE FOR THE 
ACM CONFERENCE. 
Node 3. THE ACM CONFERENCE. 
Node 4. AN ABSTRACT OF THE FIRST PAPER ABOUT AUTONOTE. 
Node 5. THIE FIRST PAPER ABOUT AUTQNOTE. 
Node 6. THE REVIEWER'S COMMENTS O@ THE PLANNED PAPER..oo 
Node 7. THE PROCEEDINGS OF THE Am CONFERENCE. 
Node 8. TRAVEL ARRANGEMI3W.S FOR THE ACM CONFERENCE. 
To i l l u s t r a t e  the network loca t ion  procedures, we w i l l  now ga "through seve ra l  
subsequent references  t o  top ics  a l ready defined i n  the r q r m e n t a t i o n .  
Before passing t h e  phrase t a b l e  t o  the l oca to r ,  t he  parse r  f i r s t  checks t o  
see i f  t h e  descr ip t ion  contains any a c t i v e  phrases,  simple phrases t h a t  direc-  
tly descr ibe  one o r  more nodes i n  the  network. When t h e  l oca to r  ge t s  con t ro l ,  
it checks an i n t e r n a l  flag t h a t  i nd i ca t e s  one of t h r ee  condit ions:  the  des- 
c r i p t i o n  contains one o r  more a c t i v e  phrases;  the  descr ip t ion  contains no 
a c t i v e  phrases; o r  the desc r ip t i on  contains only a s ing le  word. 
A s  our  f i r s t  example, consider t h e  subseqaent i t e m  descr ip t ion:  THE PAPER 
ABOUT AUTONOTE FOR THE CONFERENCE. The phrase t ab l e  is  given i n  Fig.  1 7 .  The 
loca to r  notes tliat t h e r e  are two a c t i v e  phrases and focuses i t s  a t t e n t i o n  on 
ARRANGEMENTS 
ORCZANI ZATION 
PROCEEDINGS 
PAPER about 
CONFERENCE u
Fig. 16 - A Cluster o f  Related Topics 
Fig. 1 7  - Sample Phrase Table 
the first of these, PAPER ABOUT AUTONOTE. From information i n  the phrase tab le ,  
it sees t h a t  PAPER ABOUT AUTONOTE plays a r o l e  i n  two d-istinct topics  repre- 
sented by nodes 1 and 5. It then considers bath of these a l t e rna t ives ,  check- 
ing t o  see if t he  remaining phrases i n  the  phrase t ab le  e i t h e r  d i r e c t l y  o r  in- 
d i r e c t l y  descxibe e i t h e r  of the  two nodes. Since both phrases d i r e c t l y  des- 
c r ibe  node 1, the locator  assumes t h a t  i t  is the top ic  node of user  reference. 
As an option, the  user may request the loca tor  t o  display i t s  assumptions, i n  
which case the system rep l i e s :  I ASSUME YOU MEAN THE PLANNED PAPER ABOUTAUTO- 
NOTE FOR THE ACM CONFERENCE. Other than t he  addi t ion of an i t e m  reference t o  
node 1, no network changes are made i n  this example. Note t h a t  the user  has 
e f f i c i e n t l y  made reference t o  tbe desired topic ,  re lying on the  system t o  f i l l  
ia the gaps in h i &  descript ion.  The system would proceed i n  much the same way 
i n  processing shorthand descr ipt ions  such as SUMMARY OF THE PAPER or  REVIEWER'S 
COMMENTS ON THE FAPER, i n  each-caae assumtng t h a t  the user  is  re fe r r ing  t o  the 
same paper about AUTONOTE 
In previous discussion we have alluded t o  the  use of contextual clues i n  
deciding among the a l t e r n a t i v e  r e fe ren t s  of a vague o r  ambiguous descript ion.  
Context i n  the AUTONOTE2 system takes t h e  form of an access recency nwlber 
(context number). Each t i m e  the  user  r e f e r s  to  some top ic  in  the  network, 
k 
Phrase 
- 
(1) autonote/paper 
(2) Conferenae/paper 
e 
1 
Links 
Pode I. 
Node 1 
m 
Article 
the 
the 
- 
Preposit ion 
about 
f o r  
i 
- 
Dependency 
root  
co-ord 1 
each of the component nodes is  assigned the  current  context number. The cur- 
r e n t  context number is incremented a t  the beginning of each AUTONOTE2 session 
and each t i m e  the  user defines a new topic. Thus when deciding among al terna- 
t i v e  topic  nodes, the system can readi ly  determine which was re fer red  t o  most 
recently, 
Another c l a s s  of in t e res t ing  cases a r e  those i~ which the  descript ion 
consis ts  of a s ing le  noun. I? t he  current descr ipt ion is THE PAPER, f o r  ex- 
ample, the system would use the  word directory t o  loca te  those simple phrases 
where PAPER is  the subject  noun. Using the r e su l t an t  l is t  of simple phrases, 
a list of nodes d i r e c t l y  described by these phrases i s  generated, I n  t h i s  
case, t h i s  process generates two a l t e rna t ives  (node 5 and node 1). The system 
then functions as before, e i t h e r  choosing a node i n  context, o r  in terrogat idg 
the user,  
The foregoing discussion has described our approach t o  network location.  
We now give a more deta i led presentat ion of the algorithm. 
Case I: Active phrases i n  the  description. Should t h e  use r ' s  descr ipt ion 
contain one or more ac t ive  phrases, there  is a good p o s s i b i l i t y  t h a t  i t  refer-  
ences an existing network topic. The first s t e p  i n  processing such a descrip- 
tion is to determine the  focus phrase, the a c t i v e  phrase a t  the  highest  depen- 
dency level. Note that the focus phrase may be subordinate to other (non- 
active) phrases i n  the desctipt ion.  The bas ic  idea is  t o  use the  nodes direc- 
t l y  described by the focus phrase to get a set of candidate topics.  Once these 
candidates are determined, they are matched against  the remaining act ivephrases  
i n  the phrase table t o  determine the most l i k e l y  referent .  
Before describing the matching process, let us first consider a few 
special cases. Suppose, for instance, that the focus phrasq directly des- 
cribes only one topic node and that any additional active phrases are also 
present ih that toflic representation. The presence (or absence) of non- 
active phrases in the description is, in this case, an important parameter. 
Any non-active phkases may serve to distinguish the description from the exis- 
ting topic. On the other hand, they could very well represent additional des- 
cription of the topic at hand. If the topic under consideration is recent, we 
first assume the latter case. In addition, when processing descriptions ren- 
dered for retrieval, the netwofk locator naturally rules out the possibility 
that a new topic is being described and accepts the one at hand. 
The_matching process. When the focus phrase directly describes two or 
more nodes, a network matching procedure is used to determine which of the 
associated topics the description references. The matching routine uses a 
list of the candidate nodes, a list of the active phrases in the description, 
and the current contents of the representational network. For each candidate 
node, the routine determines how many of the descripti~n's active phrases 
directly or indirectly describe that node. The matching routine returns a 
table of t h i s  information along with the number of the node, if any, that best 
matches the input- description. The "best" node is the one that has the high- 
est number of matching phrases. If two or more nodes have an equal number of 
matching phrases, an attempt is made to choose one of them on the basis a? con- 
text. 
The simplified flow diagram appearing in Fig. 18 summarizes the decision 
procedure for the case in whikh the description contains one or more active 
#up--the number of upward 
pointers  t o  nodes from 
the focus phrase 
ilevel--a user-specified 
i n t e rac t ion  level 
#nonac t--number of nonac t ive 
phrases i n  the des- 
c r ip t ion  
f indmode--a binary flag, "on" 
fo r  r e t r i e v a l  descrip- 
iions 
Pig. 18 - Network Location Procedure for Descriptions Containing Active Phrases 
phrases. Note i n  p a r t i c u l a r  t h a t  i n  case the descr ip t ion  cons i s t s  of only a 
s i n g l e  active phrase tha t  d i r e c t l y  descr ibes  a s i n g l e  node, t he  network l ~ c a -  
t o r  assumes the  node immediately. The r a t i o n a l e  is t h a t  we  a n t i c i p a t e  the  
user  w i l l  f requently make use of such terse descr ip t ions  i n  reference t o  pre- 
viously define topics .  Recal l ing our earlier d iscuss ion of human referent ia l  
communication, a speaker makes incomplete references wi th  the  assumption t h a t  
the t o p i c  can be i n fe r r ed  by t h e  l i s t e n e r ;  otherwise, he descr ibes  h i s  sub jec t  
more p rec i se ly  t o  avoid being misunderstood. The network loca tor  was designed 
with t h i s  i n  mind. That is, whenever a terse descr ip t ion  references  a s i n g l e  
node directly, or i n  context ,  t h a t  node i s  taken as the r e f e r e n t ,  
Case 11: No. a c t i v e  phrases.  The f i r s t  s t e p  i n  processing a desc r ip t i on  
with no a c t i v e  phrases is  t o  examine i t s  component words, attempting t o  iden- 
t i f y  poss ib le  r e f e r e n t s  by u t i l i z i n g  the  word and phrase d i r e c t o r i e s .  If no 
candidate nodes a r e  generated by the  procedure, the  network loca tor  assumes 
a new t op ic  is being defined and allocates new nodes i n  the  network, 
Non-acttve descr ip t ions  t h a t  reference  e x i s t i n g  top i c s  f a l l  i n t o  two cate- 
gories .  F i r s t ,  t he re  are those t h a t  paraphrase some e x i s t i n g  top i c  descrip- 
t t on ,  For example, a t o p i c  o r i g i n a l l y  described a s  THE USE OF THESAURI IN THE 
SMART S'ISTEMmay subsequently be referred t o  as THESAURI TECHNIQUES I N  SALTON'S 
SYSTEN. Second, the description may c o n s t i t u t e  a more s p e c i f i c  c l a s s i f i c a t i o n  
of some topic.  While working i n  t he  context  of a p a r t i c u l a r  paper, f o r  ex- 
ample, the  user  may describe a new i t e m  as THE ORGANIZATION OF THE PAPER, where 
ORGANIZATION OF PAPER is a non-active phrase. 
The word search procedure involves the use of s e l ec t ed  words from the  des- 
c r i p t i o n  and the wofd d i r e c t o q  t o  ob t a in  a set of a c t i v e  phrases containing 
rhose words. From there ,  a s e t  of nodes i s  obtained by co l l ec t i ng  the  upward 
po in te r s  from those phrases i n  t he  phrase d i rec to ry .  The r e s u l t a n t  set of 
nodes then is  processed as a list of candidate t op i c s  just a s  i f  they had been 
obtained immediately from a descr ip t ion  containing a c t i v e  phrases.  
An important considerat ion here  is which of the  words i n  the  descr ip t ion  
t o  use i n  the  search f o r  candidate topics .  In  an e a r l y  vers ion of the system, 
w e  t r i e d  using each noun and modifier i n  turn.  Although this approach w a s  suc- 
ce s s fu l  i n  many cases, i t  of ten  r e su l t ed  i n  an extremely lengthy list of a l t e r -  
na t ives .  We a l s o  noted t h a t  words a t  the highes t  dependency l e v e l  more o f ten  
l ed  t o  i d e n t i f i c a t i o n  of the  t o p i c  node than those words occurr ing a t  subordin- 
ate levels .  For t h i s  reason, it w a s  decided t o  c u r t a i l  the  word search, using 
1 I only t h e  words i n  t he  roo t  phrase" of t h e  descr ip t ion .  Fop the  non-active 
descr ip t ion  PAPER ON CLUSTERING I N  THE SMART SYSTEM, the  words PAPSR and CLUS- 
TERING would be used in the  search f o r  candidate nodes. A s  a user option,  the  
system w i l l  expand t h e  search t o  inc lude  the  remaining words i n  the  descr ip t ion .  
There a r e  four  stages i n  the search f o r  candidate top ics  (see below). 
Stages 1 and 2 deal with the sub jec t  word of t h e  roo t  phrase; Stages 3 and 4 
with the modifier word. In  Stages 1 and%3, only those nodes d i r e c t l y  described 
by phrases having the p a r t i c u l a r  word i n  sub jec t  pos i t i on  a r e  considered. In 
Stages 2 and 4, t op i c  nodes with t he  word i n  modifier pos i t i on  are considered. 
Stage 1 
Stage 2 
S,tage 3 
Stage 4 
Role of wordtin 
the  descr ip t ion  
Subject 
Subject 
Modifier 
Modifier 
Role of word i n  
t h e  network 
Subject 
Modifier 
Subject 
Modifier 
After completion of each stage, i f  there  were any nodes generated they 
are passed through the recency check. I f  no node is  dist inguished,  the  user  
i s  presented with a l i s t  of the  a l t e rna t ives .  The user  may then choose one of 
the topics  o r  reply t h a t  none i s  the  intended re feren t ,  i n  which case the  next 
s tage is  t r i e d .  
I f  a node eventually is iden t i f i ed  by t h i s  process, the  locator  must note 
the  s tage i t  i s  i n ,  s ince each case implies a d i s t i n c t  links table .  Fig.  19 
gives an example of each case. The s t a t e  of the  network before processing the 
descr ipt ion i s  i l l u s t r a t e d  $y s o l i d  l i n e s ;  the network addi t ions  by dashed 
l ines .  Note tha t  is the Stage 2 example, the  user  o r ig ina l ly  described a new 
topic  simply a s  ORGANIZATION OF THE PAPER and then gave a more complete des- 
c r ip t ion  of the  paper. The descr ipt ion of the paper was a l so  l e f t  pending in 
the  Stage 4 example. In f a c t ,  Case 2 and 4 can only occur i n  t h i s  s i t u a t i o n  
s ince the  presence of a simple phrase with paper a s  the subject  noun would have 
been picked up earlier i n  e i t h e r  Stage 1 or 3. 
The s tage i n  which top ic  iden t i f i ca t ion  i s  made a l s o  is  important when 
processing r e t r i e v a l  descript ions,  Recall  t h a t  a p r i ac ipa l  advantage of the 
r e f e r e n t i a l  system i s  t h a t  i t  enriches i t s  representat ion of the  user 's  topics  
during r e t r i e v a l .  Whenever a r e t r i e v a l  descr ipt ion contains s i m p l e  phrases not 
asready present  i n  the  representat ion of the  iden t i f i ed  topic ,  they a re  added 
t o  the representation. However, i f  top ic  iden t i f i ca t ion  occurs i n  Stage 2 ,  
note t h a t  a simple phrase w i l l  be added a t  one l eve l  higher than the decided 
topic. I f  processing a r e t r i e v a l  descr ipt ion,  the addit ion would be meaning- 
less a s  i t  w i l l  not enrich the  descr ipt ion of the iden t i f i ed  node. For example, 
i f  the user  has previously described a paper and l a t e r  c a l l s  f o r  the r e t r i e v a l  
I 1 
i Acm I 
I CONFERENCE I 
\ 
- 
- 
Z 
'4 
'CI 
- 
2. 
- 
\ 
'. 
'. 
\ 
(a) Stage 1. User input: The paper for the Acm conference. 
I PAPER about I PAPER f o r  I 
1 
I PAPER for I i , conference I 
L,,, _I 
planned 
PAPER 
I Autonote I I conference 1 
I I I I 
L -  - -, L - - - - - -  J 
PAPER about 
Autonote 
(b) Stage 2. User input: The paper about Autonote for the conference. 
Fig.  19 - Network Alterations Arising from a Successful Word Search in Each 
of the Four Stages 
1 of paper 
\ 
\ 
PAPER about 
( c )  Stage 3.  User inpu t :  The organizat ion  of t h e  paper .  
/ 
/ - \  
I \ 
\ I 
/ 
4- - * \ 
\\ \ / \ 
\ / \ 
\ / \ 
\ / 
4, - % b r - - -  --1 Y 
/ \ I 
ORGANIZATION I \ ' I SUMMARY 
I 1 of paper , \ 
N' - 0 v L - - - - -  / \ A 
I I I 
PAPER about 1 I PAPER f o r  , 
I Autonote i 1 conference 
1 I 
(d) Stage 4 ,  User input: Summary of the pape r  about Autdnote f o r  the  confer- 
ence. 
Fig, 19 - Continued 
of MATERIAL FOR THE PAPER, the  add i t ion  of a higher  order  node po in t ing  down 
t o  the "paper" node i s  of no value  i n  l a t e r  referencing the  top ic .  In  such 
cases,  the  network loca to r  r e tu rns  the  located  node t o  the  r e t r i e v a l  processor 
and suppresses the  network addi t ion .  To s t a t e  t h i s  more genera l ly ,  r e t r i e v a l  
desc r ip t ions  are employed t o  augment t he  represen ta t ion  only when the  addi- 
t i o n a l  phrases c o n s t i t u t e  co-ordinate o r  subordinate descr ip t ion  of the  loca ted  
topic .  
Although w e  have found the  word searching procedure q u i t e  e f f e c t i v e ,  i t s  
success u l t imate ly  depends upon a co-occurrance of some word i n  both the  des- 
c r i p t i o n  and the  Yepresentational network. A proposed extension t o  AUTONOTE2, 
as described in  Linn (1972), would augment t h i s  procedure t o  inc lude  word s t e m  
and synonym processing. 
The major objec t ion  t o  t h i s  procedure is  t h a t  as t h e  network grows larger 
i t  generates  too many candidate nodes and consequently more quer ies  t o  t heuse r .  
To alleviate t h i s  problem, we al low the  use r  t o  cancel  processing of the des- 
c r i p t i o n  any t i m e  he decides t he  system is  having d i f f i c u l t y  r e l a t i n g  h i s  des- 
c r i p t i o n  t o  t h e  cur ren t  representa t ion ,  I n  add i t i on ,  i f  the  u se r  i s  unsure 
how he previously described a p a r t i c u l a r  topic, a facility is  provided t h a t  
allows him t o  obtain t o p i c  descr ip t ions  from a spec i f i ed  region of the  network. 
Upon not ing t h e  t o p i c  he o r i g i n a l l y  intended, he  may then give a more p rec i se  
descr ip t ion .  
Case 111: One word descr ip t ions .  Descript ions cons i s t ing  of a s i n g l e  
noun are processed i n  much the  same manner as non-active d e s c r i p t i ~ n s ,  The 
noun i s  treated as i f  i t  r e su l t ed  from a d e l e t i o n  on a simple phrase. The w r d  
d i r ec to ry  is f i r s t  searched f o r  simple phrases i n  which the  word appears as the 
subject and, if necessary, the modifier. The nodes obtained from the phrase 
directory then are processed as described earlier. 
VI. NETWORK MEDIATED RETRIEVAL 
The previous sections dealt primarily with the process of item descrip- 
tion, that is, the process of constructing a representation from descriptions 
of the user's textual materials. This section discusses the AUTONOTE2 proced- 
ures that retrieve information through the representational network. 
Retrieval via Descriptions 
Many of the procedures described earlier for item description and repre- 
sentation are used in retrieval. The user initiates retrieval by giving a FIND 
command, supplying a description as argument. Retrieval descriptions are first 
passed to the parser, and are therefore subject to exactly the same constraints 
as item descriptions. If the description is acceptable, the resultant phrase 
table is passed along to the netw~rn locator which ultimately returns a node 
number to the FIND processor. 
The FIND processor constructs a set of item numbers by extracting the 
textual references from the node returned by the network locator. The system 
then checks for upward poipters from the node, to more specifically described 
materials, If there are ~tructurally related topics, the FIND processor so 
informs the user and asks if he would like to explore further. If so, the 
user is presented with descriptions of the higher order alternatives. Using 
the network depicted in Fig. 16, for example, consider the retrieval request 
FIND THE PLANNED PAPER ABOUT AUTONOTE. The network locator would determine 
t h a t  node 1 i s  the desired referent  and re turn  t h a t  fact t o  the  FIND processor. 
After s tor ing  away the  item references of node 1 the system would ask: 
DO YOU WANT: 
A. THE ORGANIZATION OF THE PAPER 
B w  THE REVIEWER'S COMMENTS ON THE PAPER 
The user m y  respond with an appropriate letter indicating which topic he 
desires.  If the top ic  selected a l s o  has higher order nodes, the  process is  
repeated u n t i l  the user  terminates the  search. 
I f  the  node returned by the  network locator  has no associated item refer-  
ences, the system searches upward i n  the  network f o r  a node with t e x t  i t e m  
pointers. I f  a node is reached with multiple upward paths, the  system stops 
and queries the user. For example, i f  a user has entered only an out l ine  and 
some bibliographic references f o r  a paper he is wri t ing,  then a r e t r i e v a l  des- 
c r ip t ion  tha t  maps onto the "paper" node would e l i c i t  a query such as: 
DO YOU WANT: 
A. THE OUTLINE OF THE PAPER 
B. BIBLIOGRAPHIC WFERENCES FOR THP, PAPER 
This example i l l u s t r a t e s  a d i s t i n c t  advantage of the  r e f e r e n t i a l  system 
over sfmple keyword indexing. When the  user ' s  descript ion i s  imprecise, AUTO- 
NOTE2 d i r e c t s  the  user  t o  re la ted  top ic  nodes with associated tex tua l  materials ,  
Upon termination of the search, the r e su l t an t  set of t ex tua l  references is  
stored internal ly .  Depending upon the  user' s option se t t ings  , a reference 
count and the  set of ftem numbers then may be displayed on the  user ' s  consoh.  
The user may PRINT those pa r t i cu la r  items he wishes ta see,  o r  he may simply 
RETRIEVE the  e n t i r e  s e t ,  
I n  dea l ing  wi th  groups of r e l a t e d  i t e m s ,  network mediated r e t r i e v a l  has  
three major advantages over simple keyword-based technfques. F i r s t ,  the  u s e r  
I I need only make his desc r ip t i ons  more specific in order  t o  zero in" upon cor- 
respondingly specific t e x t u a l  materials. Second, the  r ep re sen ta t i ona l  network 
enables  the system t o  use the use r ' s  o r i g i n a l  de sc r ip t i on  as a s t a r t i n g  p o i n t  
i n  guiding h i m  t o  s t r u c t u r a l l y  r e l a t e d  t o p i c  nodes. F i n a l l y ,  the p o s s i b i l i t y  
of network exp lora t ion  can help the  use r  recal l  the s t r u c t u r e  of t he  materials 
represented i n  some por t ion  of t he  network. This can be quite valuable after 
the user has spent an extended period working with  o ther  t o p i c s ,  or  as t he  
number of t o p i c s  and t h e i r  in te rconnec t ions  become large. 
After processing a r e t r i e v a l  reques t ,  t h e  system determines i f  the u s e r ' s  
de sc r ip t i on  contained any p repos i t i ona l  phrases  o r  ad j ec t ives  n o t  already 
presen t  i n  the i d e n t i f i e d  t o p i c ' s  r epresen ta t ion .  I f  so ,  t h e  t o p i c  descr ip  
t i o n  is enriched accordingly.  For example, if the  represen ta t ion  of the 
located node is THE PAPER FOR TNEl ACM CONFERENCE, and the user  referred to it 
by the retrieval desc r ip t i on  TKE PAPFR FOR THE FALL CONFERENCE, the system 
will augment i ts  represen ta t ion  t o  inc lude  the simple phrase FALL CONFERENCE. 
This  is an important  aspect of AUTONOTEZ. Whether desc r ip t i ons  are employed 
for t h e  purpose of charac te r iz ing  text  i t e m s  o r  retrieviag them, the  system 
continually updates i ts  represen ta t ion  of t he  user ' s  topics ,  I n  add i t ion ,  
t h i s  example i l l u s t r a t e s  how the  system i s  a b l e  t o  establish a limited form of 
phrase synonomy. There will subsequently be a node i n  the network directly 
described by both  ACM CONFERENCE and FALL CONFERENCE, and any t o p i c  assoc ia ted  
w i t h  that node may l a t e r  be referenced using e i t h e r  o r  both of t he  two simple 
phrases. 
Interrogating .the Network 
As the network grows complex, the user must be able  t o  question the sys- 
tem about the current  representation. This capability may help him recall  the 
structure of some set of related topics. O r ,  p r i o r  t o  formulating a new topic 
description, the user may wish to examine the representat ional  network f o r  
possible re la ted topics.  Finally,  per iodic  perusal  of the network may 
strengthen the user ' s  own conceptual representat ion of the various topics and 
their interrelationships. 
The DESCRIBE command r e t r i eves  top ic  descr ipt ions  ?tom the representa- 
tional network. It accepts 9 variety of arguments and first generates a set  
of topic nodes. Then, using the SPEAKER routine, it outputs a description of 
esch n ~ d e  in the set. The various input forms include t h e  following. 
DESCRIBE ITEM <list). Each time the description processor adds a t ex tua l  
reference t o  a node, the node number is  placed in a predetermined location in 
the text f i l e  region of the,item. The DESCRIBE processor consequently has 
access t o  the desired set of associated node numbers. For any par t i cu la r  t ex t  
i tem,  the user may wish to know which topics  it currently is associated with. 
Initially, when an i t e m  is first described by t h e  user, t h e  actual descript ion 
line i s  placed in the data base beneath the text. To recall how he described 
an item origfnally, the user need only request that the item be printed (omit- 
ting the text  i.f he chooses). But the o r ig ina l  descript ion may have been only 
a terse reference, i n  contex t , to  amore fully described node. Furthermore, the 
description of that node may have been enriched o r  altered subsequent t o  the 
entry of the item. To obtain a full description of each topic presently 
associa ted  wi th  the  i t e m ,  r egard less  of how t h e  i tem o r i g i n a l l y  was described,  
the user  employs DESCRIBE ITEM. 
DESCRIBE CURRENT [TOPICL. A po in te r  t o  t he  node most recen t ly  referenced 
i n  t h e  repxesentat ion i s  maintained i n  t he  node d i rec to ry .  I n  response t o  
t h i s  command, the  DESCRIBE rou t ine  simply determines the node number and dis-  
p lays  i ts  descr ip t ion .  The cur ren t  node number is saved between AUTONOTE2 
sess ions ;  t h i s  command i s  o f t e n  employed a t  the  beginning of a sess ion t o  
remind the  u se r  of the  previotis working context .  
DESCRIBE TOPICS. This command causes every node i n  t h e  network having 
associa ted  i t e m  references  t o  be described. Because of the  voEuminous output ,  
i t  i s  most f requent ly  employed i r i  batch mode. 
DESCRIBE <descript ion>.  When the  DESCRIBE rou t ine  encounters an argument 
t h a t  is no t  i n  one of the s p e c i a l  forms discussed above, i t  t r e a t s  the inpu t  as 
a phrasa l  descr ip t ion .  Using the  parse r  and network loca to r ,  an attempt i s  
made t o  map the input  i n t o  a unique t o p i c  node. T f  successful ,  a complete des- 
c r i p t i o n  of t h e  node i s  presented t o  the  user .  Thus, i f  the  user  cannot re- 
call prec i se ly  how he described some top ic ,  he may supply an incomplete rder- 
ence t o  ob ta in  t h e  t op i c  descr ip t ion  i n  f u l l .  
The network loca tor  funct ions  somewhat d i f f e r e n t l y  when processing a des. 
c r i p t i o n  f o r  t he  DESCRIBE command. I f  i t  is  unable t o  d i sce rn  a unique node 
using the  matching procedure and context,  a list of the  a l t e r n a t i v e s  i s  re- 
turned f o r  subsequent display.  
The FULLY modifier. The user  may reques t  t h e  d isplay  of a  hos t  of r e l a t e d  
topics by employing the. JXJLLY modifier. Spec i f i ca l l y ,  t he  user  types DESCRIBE 
FULLY, followed by any of t he  argument forms discussed above. As before,  t h i s  
generates a node or  set of nodes. When describing FULLY, each node i s  i n  turn 
expanded i n t o  a set of s t r u c t u r a l l y  re la ted  nodes a l so  having associated text- 
ua l  references. 
A s  an example, consider again the network i n  Fig. 16. The user  types DES- 
CRIBE 'FULLY, THE PAPER ABOUT AUTONOTE. Assuming no choice i s  possible  i n  con- 
text, the  descr ipt ion i s  ambiguous, and the  network loca tor  r e tu rns  nodes 1 
and 5 .  
The two nodes themare  passed t o  a rout ine  that displays  an indented out- 
l ine representing the s t r u c t u r a l l y  r e l a t ed  top ics  reached by moving upward i n  
the network. Each l e v e l  of indentat ion represents  a node l e v e l  traversed i n  
the network. In th i s  example the  following o u t l i n e  would be pr inted:  
A. THE PLANNED PAPER FOR THE ACM CONFE3ENCE 
THE: ORGANIZATION OF THE PAPER 
THE REVIEWER'S COMMENTS ON THE PAPER 
B. THE FIRST PAPER ABOUT AUTONOTE 
THE ABSTRACT OF THE PAPER 
DESCRIBE STRUCTURES. This  command functions as if FULLY was specif ied,  
diaplaying ou t l ines  of each top ic  c l u s t e r  i n  t h e  representat ional  network. To 
accomplish t h i s ,  the network is  searched f o r  nodes having nowdownward pointers  
t o  other nodes. Each such node corresponds t o  the lowest order node level i n  
a pa r t i cu la r  c l u s t e r  of related topics. When described FULLY, t he  e f f e c t  is  
t o  reveal t he  s t r u c t u r a l  ou t l ine  of i ts  associa ted c lus te r .  
The SPEAKER Conrpanent 
A s  we have seen, SPEAKER i s  invoked during many phases of AUTONOTE2's 
operation. The calling rout ine  passes the SPEAKER a node number. A buffer 
containing a phrasal descr ipt ion of the node i s  returned. A second, opt ional  
input  parameter spec i f i e s  the  level of d e t a i l  desired i n  the r e su l t an t  des- 
c r ip t ion ,  The level ind ica tor  corresponds t o  the  number of node l eve l s  i n  
the representat ion t o  be employed i n  formulating t h e  descr ipt ion.  
The l e v e l  ind ica tor  is p a r t i c u l a r l y  use fu l  when the  system must question 
the  i n t e n t  of a descript ion.  When querying the user  during the network loca- 
t i o n  process,  f o r  example, the system requests  top ic  descr ip t ions  from the  
SPEAKER with  the  l e v e l  ind ica to r  set according t o  the use r ' s  current preferred 
l e v e l o f d e t a i l , a s  in fer red  from h i s  most recent  descr ipt ion.  For example, i f  
the user describes an i t e m  as RESULTS OF THE EXPERIMENT and the system must 
ask i f  he is re fe r r ing  t o  SMITH'S EXPERIMENT ON THE SHORT TERM MENORY OF WHITE 
RATS, the  r e s u l t i n g  query would be ARE YOU REFlERRING TO SMITH'S EXPERIMENT ON 
MEMORY? 
The p rocess  of constructing a descr ip t ion  from the  network takes place i n  
two stages. The f i r s t  s tage  s t e p s  through t h e  network recurs ively ,  co l l ec t ing  
the  simple phrases that d i r e c t l y  o r  i n d i r e c t l y  describe the specif ied node. 
The level ind ica tor ,  i f  appl icable ,  blocks the  co l lec t ion  of simple phrases 
below the  spec i f ied  level .  During t h i s  s tage ,  the  SPEAKER constructs  two 
t ab les  of words, one f o r  subjec t  nouns and another f o r  modifiers.  Each en t ry  
i n  the  sub jec t s  t ab le  is  l inked t o  a l ist  of ad jec t ives  f o r  t h a t  subject ,  and 
a l ist  (ca l led  the modification chain) of preposi t ional  modifications of the  
subjec.t noun. For example, t h e  subjects  t a b l e s  en t ry  f o r  PAPER may have an 
adject ive  list containing PLANNED, and a modification chain consis t ing of 
(ABOUT) AUTONOTE and (FOR) CONEI3RENCE. Both of the  lists are chained through 
the  t a b l e  oE modifiers. Note t h a t  some words w i l l  appear i n  both the subjec t  
and modifier tables .  For example, PAPER may be i n  the modifler t ab le  a s  p a r t  
of the  modification chain of the word ORGANTZATION, and also is the subjects 
table with a modification chain of i t s  own, 
The subjects  t ab le  also maintains ar t ic le  usage information f o r  each of 
i ts  en t r ies .  Fig. 20 i l l u s t r a t e s  the subject  and modi f i e r  tables constructed 
from a typ ica l  top ic  node, 
(a) Subjects tab le  
A 
(b) Modifier tab le  
t 
Subject 
Noun 
organization 
Paper 
conference 
s 
Fig. 20 - SPEAKER tab les  generated from the  network representat ion of 
ORGANIZATION OF TTB PLANNED PAPER ABOUT AUTONOTE FOR THE 
ACM C O m R E N C E  . 
Art ic le  
the 
the  
the 
A 
Chain 
Link 
... 
. * a  
(5) 
... 
... 
- i 
C - 
Modifier 
Word 
(13 planned 
(2) paper 
(3) autonote 
(4) acm 
(5) conf erence 
The second stage i s  carried out by a recursive algorithm that  operates on 
- Y 
Modification 
Chain 
(2) 
(3) 
... 
Level 
1 
3 
3 
Preposition 
adj 
of 
about 
adj  
f o r  
the two tables  t o  construct the phrasal  descript ion.  The process begins with 
the f i r s t  word i n  the subjects  table, i n  t h i s  case ORGANIZATION. If an a r t i c l e  
applies, i t  is added t o  the descr ipt ion buffer. Next, the adject ive  chain i s  
-. ,. 
_L 
Adjective 
Chain 
. . . 
(1) 
( 4 )  
t raversed adding each a d j e c t i v e  i n  tu rn  t o  t h e  buf fe r .  I n  t h i s  case t h e r e  a r e  
no ad jec t ive8  so  the cur ren t  sub jec t  word (ORGANIZATION) i s  added t o  t h e  buf- 
f e r  and t h e  systetn continues wi th  the modificat ion chain. This l eads  t o  the  
second e n t r y  i n  t h e  modif ier  t a b l e ,  (OF) PAPER. The prepos i t ion  i s  then added 
t o  the buffer  y i e ld ing  THE ORGANIZATION OF. Next, a check i s  made i n  the  sub- 
j e c t s  t a b l e  t o  determine if the cur ren t  modif ier  word (PAPER) is  f u r t h e r  des- 
cribed. Since t he re  i s  an en t ry  f o r  PAPER, t h e  cur ren t  p o s i t i o n  i n  the  modi- 
f i c a t i o n  chain f o r  ORGANIZATION i s  placed on a  push down s t ack  ( t h e  goa l  s tacw 
and the  algori thm recurses  on t h e  word paper. After  adding the  a r t i c l e ,  the  
a d j e c t i v e  (PLANNED), and t h e  sub jec t  word (PAPER), the  desc r ip t i on  bu f f e r  con- 
t a i n s  THE ORGANIZATION OF THE PLANNED PAPER. The system now begins processing 
the  modif icat ion chain of PAPER. The f i r s t  p iece  of t h e  chain adds ABOUT AUTS 
NOTE t o  t he  bu f f e r ,  Note tha t  t he re  was no recurs ion on AUTONOTE because t h a t  
word does not have a sub jec t s  table entry .  The po in te r  t o  the  next p i ece  of 
t he  modif icat ion chain,  (FOR) CONFERENCE, i s  then picked up from the  l i nk  f i e l d  
of the AUTONOTE entry.  Af te r  adding the  p repos i t ion  (FOR), the  algori thm re- 
curses  on CONFERENCE, adding THE, ACM, and CONFERENCE i n  t u r n  t o  the  bu f f e r .  
The goa l  stack is  then popped i n  search of remaining modif icat ion chain poin- 
ters. The f i r s t  "pop" r e s t o r e s  t he  PAPER modif icat ion chain. Since t h e r e  is  
no a d d i t i o n a l  modif icat ion of t he  paper, t h e  goal  s t ack  i s  popped again t o  
r e s t o r e  the ORGANIZATION chain,  We a r e  a t  the  end of t h i s  chain a l so ,  and 
thus the process terminates with t he  desc r ip t i on  bu f f e r  reading: THE ORGANZ- 
ATION OF THE P W E D  PAPER ABOUT AUTONOTE FOR THE ACM CONFERNECE. 
SPEAKER h e u r i s t i c s .  The add i t ion  of phrases t o  a t o p i c  i n  many cases  
could reduce the r e a d a b i l i t y  of i t s  SPEAKER-generated descr ip t ion .  For 
example, suppose a t o p i c  is f i r s t  defined as SAMPLE DESCRIPTIONS FOR USE IN 
THE ACM PRESENTATION, and l a t e r  i s  r e f e r r ed  t o  a s  SAMPLE DESCRIPTIONS FOR USE 
IN THE NSF PROPOSAL. Given only t he  algorithm j u s t  presented,  t h e  SPEAKER 
generated descr ip t ion  would be SAMPLE DESCRIPTIONS FOR USE I N  THE ACM PRESEN- 
TATION IN THE NSF PROPOSAL. To avoid such unreadable descr ip t ions ,  whenever 
the  modification chain f o r  a sub jec t  noun contains two o r  more p repos i t i ona l  
phrases headed by the same preposi t ion ,  the SPEAKER sets off  each phrase a f t e r  
the f i r s t  with parentheses. The above example then becomes SAMPLE DESCRIP- 
TIONS FOR USE I N  THE ACM PRESENTATION (AND THE NSF PROPOSAL). Note t h a t  a 
descr ip t ion  such a s  C O W T S  - ON SMITH'S ARTICLE - ON CLUSTERING i s  no t  processed 
i n  t h i s  manner s i n c e  (ON) ARVTCLE i s  i n  the  modif icat ion chain of COMMENTS, 
while (ON) CLUSTERING is i n  the  modif icat ion chain of t h e  work ARTICLE. Note 
a l s o  t h a t  although p a r e n t h e t i ~ a l  phfases a r e  excluded from t o p i c  descr ip t ions  
generated f o r  the purpoSe of Lnterrogating the  u se r ,  when the use r  reques ts  a 
descr ip t ion  of a t p p i c  v i a  t he  DESCRIBE command, t h e  complete desc r ip t i on  is 
provided . 
Simpl i f ica t ion  of l i s t  processing. It may be added here  t h a t  our decis- 
ion t o  maintain the  represen ta t iona l  network i n  d i sk  file s to rage  has g r e a t l y  
s impl i f ied  t he  l is t  processing i n  recurs ive  algorithms such as the SPEAKER, 
The network can be envisioned as a complex list structure where the l i n k s  are 
simply l i n e  file numbers. To i l l u s t r a t e  t h i s  po in t ,  consider t h e  recurs ive  
co l l ec t i on  of simple phrases carried out  i n  the f i r s t  s t e p  of t he  SPEAKER. 
The main body of t h e  rou t ine  c o l l e c t s  the simple phrases t h a t  d i r e c t l y  descr ibe  
a node. I f  the node processed has downward links t o  subordinate nodes, they 
are placed on a push down stack.  Next t he  s t a c k  i s  popped and the rou t ine  i s  
c a l l e d  recurs ive ly  t o  opera te  on a new node number. Thus a l l  the  concomitant 
problems of s to rage  management t h a t  are normally present i n  l i s t  processing 
systems are avoided. Recursive de le t ion ,  discussed i n  the  next s ec t ion ,  
s imi l a r ly  is  s impl i f ied .  To d e l e t e  a po r t i on  of the  l i s t  s t r u c t u r e  requ i res  
only the  removal of a l i n e  from a d i r ec to ry  f i l e .  Thus the process of "garbage 
col lec t ion"  i s  both automatic and t ransparen t  t o  AUTONOTE2. 
V I I .  NETWORK MODIFICATION 
Procedures f o r  modifying the  r ep re sen ta t i ona l  network a r e  required f o r  
several reasons.  Should t h e  system i n c o r r e c t l y  parse  a descr ip t ion ,  the  user 's  
a b i l i t y  t o  r e f e r e n c e ~ t h e  associa ted  t o p i c  w i l l  be i m p a i r e d .  The user  may wish 
t o  alter t h e  descr ip t ion  of a top i c  t o  (a) make i t  more p rec i se ,  (b) i n s u r e  
that  i t  i s  not confused with s i m i l a r l y  described top ics ,  o r  (c) enable a t o p i c  
t o  be  referenced i n  more than one way, Af ter  i n i t i a l l y  descr ib ing a t e x t  i t e m ,  
t he  user  may discover  t h a t  t he  i t e m  should a l s o  be associa ted  with o ther  t op i c s  
i n  the  representa t ion .  Al te rna t ive ly ,  he may decide t h a t  a text item should 
be dissociated from some topic .  The user may wish t o  d e l e t e  an obsolete  t o p i c  
from the  represen ta t ion  a l t oge the r ,  o r  rep lace  a descr ip t ion  i n  i t s  e n t i r e t y  
by a more s u i t a b l e  one while  maintaining t h e  same l is t  of associa ted  t e x t u a l  
references.  F ina l ly ,  when deal ing wi th  a group of s t r u c t u r a l l y  r e l a t e d  t op i c s ,  
t h e  user  may wish t o  d e l e t e  an e n t i r e  s t r u c t u r e ,  or c e r t a i n  components of a 
s t r u c t u r e ,  from the  network. 
We cannot expect a t y p i c a l  use r  t o  t h ink  i n  terms of l ist  s t r u c t u r e s ,  
nodes, linkages, e t c .  Thus we sought t o  provide a command language and 
feedback more or less independent of the internal data structures that imple- 
ment the representation. In addition, care was taken to avoid(the possibility 
of accidental damage to the representation steming from misunderstanding or 
misapplication of the modification procedures. 
The resultant processor includes procedures for removing or adding item 
references to a topic, deleting topics, adding or removing simple phrases from 
the description of a topic, e t c .  Rather than require the user to identify the 
particular topic to be altered each time a modification is to be performed, 
primitives are implemented as local commands to a generalized modificatton 
processor. 
The modification processor is invoked by issuing a CHANGE command which 
accepts a phrasal description as its argument. A node in the network is estab- 
lished as the currentjidentified topic. The processor then prompts the user 
for modification instructions. After all modifications are completed, the 
user types DONE and control is returned to the regular command monitor. The 
CHANGE command also may be issued while in modification mode, thereby changing 
the current topic. Each of the local commands is discussed separately below, 
using the hypothetical representation depicted in Fig. 21 for illustration. 
Adding References and Phrases to the Network 
The ADD command associates additional text references with the current 
topic, and adds simple phrases to the topic's description. To add item refer- 
ences, the user types ADD ITEM[S] followed by a list of item numbers. This 
procedure is quite useful if the user has a large set of items that pertain to 
a particular topic. He simply identifies the topic and adds the list of refer- 
ences. 
Fig. 21 - Sample Representation for Discussion of Network Modification 
I f  the supplied argument i s  a phrase, it i s  added t o  the current  node. 
For example, i f  the  current  topic  is THE PAPER FOR THE ACM CONFERENCE, the  
command ADD PAPER ABOUT AUTONOTE causes the  prepos i t iona l  phrase ABOUT AUTO- 
NOTE t o  become a p a r t  of the top ic  descript ion.  Adjectives may a l s o  be  added 
t o  a descr ipt ion (example: ADD SMITH'S PAPER). I f  only a s ing le  word occurs 
a s  the  argument, i t  i s  assumed t o  be an ad jec t ive  which i s  t o  modify the  cur- 
r e n t  subject  noun. 
Moving through the Network 
The MOVE command allows the user  t o  change the  current  node pointer  from 
its present pos i t ion  t o  s t r u c t u r a l l y  proximate top ics  without having t o  en ter  
a  description. For example, i f  cur ren t ly  located a t  the  "paper" node, the  
command MOVE DOWN causes the ACM CONFERENCE t o  become the  current  topic.  I f  
t he  current top ic  i s  the  ACM CONFERENCE, MOVE UP w i l l  produce th ree  
higher order topics .  Each i s  saved, and the  leftmost  node becomes the current  
topic.  Subsequently, t he  user m y  MOVE LEFT o r  RIGHT t o  the other  topics.  
Mter a successful  move, a b r i e f  descr ipt ion of the new topic  i s  displayed. 
The Caching F a c i l i t y  
The CACHE command s t o r e s  i t e m  references f o r  subsequent use. If the com- 
mand i s  given with no argument, the set of text references associated with the  
current  top ic  is  added t o  an i n t e r n a l  cache. The caching f a c i l i t y  may be w e d  
t o  manipulate l a r g e  s e t s  of i t e m  references, f o r  example, i n  t ransfer ing  all 
i t e m  references from one top ic  t o  another. This may be accomplished by ident i -  
fying the f i r s t  t o p i c  and issuing a CACHE command. After  ident i fy ing  the 
second top i c ,  t he  command ADD CACHE causes t he  s e t  of cached i t e m s  t o  be 
merged with those  of the  new topic .  
Re t r i eva l  Commands 
The r e t r i e v a l  commands of t he  network modification processor  a r e  analo- 
gous t o  t h e i r  counterpar ts  i n  AUTONOTE, LIST outputs  a l ist  of the  i t e m  num- 
bers associa ted  wi th  the  cur ren t  topic.  LIST CACHE d i s p l a y s  the  numbers of 
t he  i tems i n  t he  cache. PRINT outputs  s e l ec t ed  text i t e m s .  A 1 1  i t e m s  associ-  
a ted  wi th  t h e  current  t op i c ,  o r  those In t h e  cache, dl1 be pr in ted  i n  response 
t o  RETRIEVE and RETRIEVE CACHE, respect Lvely, 
By employing the  IDENTIFY and MOVE commands, the  u se r  may explore the  
representa t ion ,  LISTing t h e  associa ted  references  f o r  each topic .  During the 
explora t ion ,  t h e  CACHE command can be used t o  s t o r e  s e l ec t ed  references f o r  
later retrieval, o r  t he  u se r  may choose t o  PRINT o r  RETRIEVE pe r t i nen t  re fe r -  
ences as he goes. These procedures allow the  r e t r i e v a l  set t o  be shaped i n t e r -  
ac t i ve ly ,  and more s e l e c t i v e l y  than i s  poss ib le  wi th  the  FIND command discussed 
earlier. 
Removing References and Phrases from t h e  Network 
The REMOVE command accepts  t he  same argument forms as the  ADD command and 
simply performs the inverse  operat ions.  The argument ALL also i s  recognized, 
causing a l l  i t e m  references  t o  be removed from the  cur ren t  topic.  
Topic Delet ion 
DELETE may be employed t o  remove obso le te  top ics  from the  representa t ion ,  
o r  as the f irs t  s t e p  i n  replac ing a t o p i c  descr ip t ion  with a more appropr ia te  
one. CREATE then may be used t o  enter the replacement t o p i c  i n t o  t he  network. 
The major problem i n  the  design of the  top ic  de le t ion  algorithm can be 
s t a t e d  as follows. When de le t ing  a topic,  under what circumstances a r e  
s t r u c t u r a l l y  r e l a t ed  nodes t o  be deleted as w e l l ?  Consider the  following 
cases. I n  the  hypothetical  network, a request t o  d e l e t e  the  ''paper" node in- 
volves a decision about de le t ing  (a) the  ou t l ine  of the  paper, and (b) smith's 
comments on the  paper. Note that i f  the  paper node were deleted and the two 
higher order nodes were not ,  the  higher order nodes would no longer be struc- 
t u r a l l y  re la ted .  I n  addit ion,  t h e i r  descr ipt ions  w i l l  s t i l l  contain the word 
"paper," but  which paper no longer i s  specif ied.  For these  reaaons, we con- 
cluded t h a t  a top ic  de le t ion  should also e n t a i l  the  de le t ion  of more spec i f i -  
cally described topics .  I n  many cases, t h i s  convention is  an advantage, s ince 
the  user can d e l e t e  & entire s t r u c t u r e  by ident i fy ing  and de le t ing  a s ing le  
lower order node. 
The considerations involved i n  dealing with lower order nodes are a b i t  
more complex. Some lower order nodes serve only t o  augment the  descr ipt ion 
of superior  nodes. In THE EXPERIMENT ON BLIND RATS, there w i l l  be  a subordin- 
ate node d i r e c t l y  described as BLIND RATS. I n  t h i s  case, de le t ion  of the  EX- 
PERIMENT node should include de le t ion  of the  subordinate node. On the  other 
hand, dele t ion of the "paper" node i n  the  previous example does not  imply 
dele t ion of the  ACM CONEXRENCE topic .  The ACM CONFERENCE node a l s o  plays a 
r o l e  i n  other  topics .  
In  the ins tances  we have examined, the  d i s t i n c t i o n  between the two cases 
seems t o  be t h a t  "unimportant" nodes have n e i t h e r  t ex tua l  references  nor up- 
ward pointers  t o  other  topics.  The dele t ion  process employs a h e u r i s t i c  based 
upon t h i s  observation. When a subordinate node i s  deemed unimportant, i t  i s  
de le ted ;  otherwise,  t h e  u se r  i s  asked t o  confirm i t 8  de le t ion .  
The d e l e t i o n  algorithm. F i r s t ,  a list of a l l  nodes t o  be de le ted  i s  con- 
s t ruc t ed .  Af te r  t he  l i s t  is complete, the  u se r  i s  presented wi th  a b r i e f  sum- 
mary of the  de l e t i ons  t o  be  made and i s  prompted f o r  confirmation. 
The algori thm f o r  const ruct ing  t h e  d e l e t i o n s  l i s t  i s  recurs ive .  Two push- 
down stacks are employed: one f o r  s t o r i n g  upward node pa ths  y e t  t o  be ex- 
plored,  and one f o r  saving downward paths.  The procedure i s  most e a s i l y  ex- 
p la ined wi th  an example. Suppose the  user  i d e n t i f i e s  t he  "paper" node and re- 
ques t s  its de le t ion .  The algori thm begins wi th  node 2 ,  f i r s t  pushing down any 
upward po in t e r s  along wi th  t h e  node number (2) t h a t  w a s  being processed when 
t 1 t h e  po in t e r s  w e r e  added t o  t he  up stack." I n  t h i s  case the  p a i r s  (1,Z) and 
(3,Z) are pushed down. Next, t h e  downward po in t e r s  are placed on the  "down 
stack" along wi th  t h e  cur ren t  node number. The cur ren t  node number i s  then 
added t o  t h e  de l e t i ons  list. The cur ren t  s t a t e  of t he  pushdown s tacks  and the 
de l e t i bns  list i s  now: 
The down s t a c k  is  then popped and node 4 i s  es tab l i shed  as the next node 
t o  be examined. Af ter  s e t t i n g  a f l a g  i n d i c a t i n g  t h a t  w e  have j u s t  moved down 
a level i n  the network, t h e  algorithm recurses  on node 4. The system d e t e c t s  
t h r e e  upward po in t e r s  ( t o  nodes 2, 5, and 6 ) .  It should now be apparent why 
we save t h e  fact  t h a t  node 4 was reached by moving down fram node 2. When 
. 
UP STACK 
(1,2) 
(392) 
k 
DOWN STACK 
(4 ,2 )  
J 
DELETIONS LIST 
2 
placing a node's upward po in te r s  on the  up s tack ,  t h e  node t h a t  led down t o  
the current  node must be ignored. 
Upon not ing t h a t  node 4 has upward po in t e r s  i n  add i t ion  t o  node 2 ,  the  
system checks t o  see i f  i t  has just moved down. In this case it  has; conse- 
quently, node-4 i s  deemed "important" and the  system asks DO YOU WANT THE ACM 
CONFERENCE DELETED? Assume the  reply  i s  NO. Since the ACM CONFERENCE node 
will remain, the system records t h a t  the l inkage between nodes 2 and 4 must be 
severed. The algorithm then recurses  without adding node 4 t o  the  de l e t i ons  
list. Note a l s o  t h a t  the  upward po in t e r s  from node 4 t o  nodes 5 and 6 are not 
placed on the up stack. The cur ren t  s t a t e  of the process i s  now: 
DOWN STACK DELETIONS LIST 
The attempt t o  pop the  down s t a c k  f a i l s ,  so  the qp stack i s  popped and a 
f l ag  set t o  i n d i c a t e  upward movement ( t o  node 3).  Node 3 has no upward poin- 
ters but  i t  has two downward po in te r s ,  t o  nodes 2 and 7. Node 2 i s  ignored be- 
cause it l e d  up t o  node 3. Node 7 i s  placed on t h e  down stack and node 3 i s  
added t o  the de l e t i ons  l i s t  yie ld ing:  
The down stack is popped qnd the algorithm recurses  on node 7. Node 7 has 
neither text references, nor upward po in t e r s  (besides node 3 ) .  Consequently, i t  
l e  deemed unimportant and is added t o  the deletions l i s t .  We now have: 
The down s t a c k  is  empty s o  the  up s t ack  i s  popped and the  system recurses  
on node 1. The node has no new upward o r  downwardpointers SO i t  i s  added t o  
the de l e t i ons  list. Both stacks are now empty and the  algorithm terminates  
having co l l ec t ed  nodes 2, 3, 7 ,  and 1 f o r  de le t ion .  
Carrying out  t h e  de l e t i on  involves several s teps .  F i r s t ,  any l inkages  be- 
tween those nodes t h a t  are t o  be dele ted  and those that w i l l  remain a r e  sewzed. 
These changes w i l l  have been detec ted  and recorded during t h e  recurs ive  col- 
lection process. Next the system executes a REMOVE ALL f o r  each node on the  
de l e t i ons  l is t  so t h a t  no associa ted  t e x t  reference  po in t s  t o  a non-existent 
topic .  Then the system removes a l l  po in t e r s  from simple phrases t o  the obso- 
lete nodes. Fina l ly ,  each deleted node i s  removed from the node d i r ec to ry  
f i l e .  
Creat ing New Topic Representations 
CREATE enables the  use r  t o  def ine  a new top ic  f o r  the  representa t ion .  The 
command takes  as argument a descr ip t ion  which i s  processed i n  the normal way, 
except t h a t  no i t e m  references  a r e  associa ted  with the  top ic .  The new t o p i c  
becomes the  cur ren t  node. AI)D i s  used t o  a s soc i a t e  any appropriate t e x t  refer- 
ences. During top i c  de le t ion ,  the  system adds t o  the  cache a l l  t e x t  references  
previously associa ted  wi th  dele ted  topics .  Consequently,  AD^ CACHE w i l l  now 
associate those items wi th  the  new descr ip t ion .  
J 
t 
L I 
UP STACK 
(1,2) 
* 
DOWN STACK 
empty 
DELETTONS LIST 
2 
3 
7 
When processing a CREATE descr ip t ion ,  the  network loca tor  at tempts  t o  as- 
s o c i a t e  the descr ip t ion  with an e x i s t i n g  top i c ,  f o r  two reasons. I f  the  des- 
c r i p t i o n  i s  t o  be a new top ic  but t he  network loca to r  confuses i t  wi th  another 
one, the user  may want t o  a l t e r  the  descr ip t ion .  Second, t h i s  permits use of 
the CREATE command i n  adding t o  an e x i s t i n g  descr ip t ion .  
VXfI. A ,CASE STUDY OF SYSTEM PERFORMANCE 
The Inapp l i cab i l i t y  of Recal l  and Prec i s ion  
The most widely accepted methods f o r  r e t r i e v a l  systgm evaluat ion  a r e  based 
upon recall  and prec i s ion  measures. A s  applied t o  the  r e s u l t s  of r e t r i e v a l  
quer ies ,  p r ec i s ion  is defined as the  proportion of r e t r i eved  ma te r i a l  t ha t  i s  
deemed re levant  t o  a query; r e c a l l  is the r a t i o  of r e levan t  documents re t r i eved  
t o  the  total re levan t  i n  the data base. But r e c a l l  and prec i s ion  cannot mean- 
i ng fu l ly  be applied t o  the  evaluat ion of AUTONOTE2. The AUTONOTE2 user  des- 
c r ibes  each piece of t e x t u a l  mate r ia l  himself. Even within a l a r g e  personal  
da t a  base,  t he  user  w i l l  c e r t a in ly  r e c o l l e c t  some of h i s  t o p i c s  and the key 
words and phrases t h a t  de f ine  them. Furthermore, sub jec t  t o  the u s e r ' s  own 
l imi t a t i ons  i n  describing h i s  mate r ia l s ,  the top i c  framework of AUTONOTE2 im- 
p l i e s  "perfect" p rec i s ion  and recall  once a p a r t i c u l a r  t o p i c  is  i d e n t i f i e d  dur- 
ing r e t r i e v a l .  
A pr inc ipa l  motivation f o r  the  AUTONOTE2 system w a s  the d e s i r e  t o  overcome 
the disadvantages of keyword indexing techniques, which force  the  user t o  t r a p  
late ideas and concepts per t inen t  t o  a given document i n t o  d i s c r e t e  content in- 
d ica tors .  In  developing AUTONOTE2 we have sought t o  provide mechanisms f o r  
defining and efficiently referencing these concepts directly. An evaluation 
of AUTONOTE2 should therefore provide some comparisons of keyword indexing vs. 
indexing by topic. To achieve a direct comparison, protocols of both types of 
indexing activity with a common data base are required. 
The Sauvain Data Base 
The original AUTONOTE system was employed in a study (Sauvain, 1970) 
aimed at uncovering structural communication problems within a keyword-based 
system. The resulting data base is related primarily to Sauvain's dissertatlon 
research. It includes reading notes, bibliographic references, research ideas, 
expository material, and so on. The collection brings together a broad range 
of topics and ideas touching upon various aspects of computer science, infor- 
mation retrieval, man-machine interaction, and psychology. 
Copies of the item texts, the originally assigned keywords, and protocols 
o f  Sauvain's activities during data base indexing, organi8ation, and rekrieval 
were acquired. We then proceeded to re-index the collection with AUTONOTE2 
topic descriptions. Each of the roughly 400 items in the data base was viewed 
and described in a sequential fashion; that is, there was no look-ahead or pre- 
planning of topic phrasings to facilitate network structuring. Protocols were 
collected of all interaction with the system and the state of the network was 
recorded at periodic intervals. (For details, see Linn, 1972). 
Results 
For brevity, AUTONOTE2 reports of parsing assumptions are excluded. 
However, system responses tha t  elicit a user reply are shown to provide a 
feeling for user interaction under AUTONOTEZ. 
Indexing activity. The AUTONOTEL protocols show a high degree of terse, 
efficient referencing of previously defined topics. The communicative effi- 
ciency was especially great in instances where several consecutive items were 
entered on a common topic. This situation frequently occurred when entering 
a set of reading notes on a particular paper or collection of papers. Typi- 
cally, the first item in such a set of entries was assigned to one or more 
new topics, In describing the subsequent items, references to these topics 
often were conveyed by a s$ngle word or phrase, or by a null description (a 
description line consisting of only a slash i s  treated as a reference to the 
topic just mentioned). 
To illustrate, consider the materials dealing with various aspects of 
artificial intelligence. A total of 17 of these items contained notes taken 
at a 1968 conference at Case Western Reserve University. Of the AUTONOTE2 
descriptions supplied for these items, three mention only the word CONFERENCE; 
five include the subphrase 1968 CONFERENCE; two include CWRU CONFERENCE; and 
seven make no explicit reference to the conference at all. Each of the items, 
t t  however, was associated with a topic node linked in efome way to the confer- 
ence" node. Furthermore, though none of the descriptions contain the wor'ds 
ARTIFICIAL o r  INTELLIGENCE, each of the associated items can bedaccesseb In  
the network through the "artificial intelligence" node. 
In the AUTONOTE protocol for these materials, there was frequent use of 
descriptor abbreviations and other idiosyncratic tags (CWRUAICONF, AT, COGPSY, 
e t c . ) .  These suggest  a s t rong  d e s i r e  t o  e l imina te  repeated e n t r y  n f  lengthy 
desc r ip to r s  and phrases.  The major drawback of t h i s  s t r a t e g y ,  however, is  
that abbrevia t ions  ( e spec i a l l y  t he  more uncommon ones) are no t  as e a s i l y  
remembered as t h e  words they represent .  I n  add i t i on ,  once an abbrevia t ion  has  
been used, the  u se r  q ~ u s t  remember t h a t  he has  done so  i n  order  t o  maintain 
cons i s t en t  indexing. I n  con t r a s t ,  there was l i t t l e  motivation f o r  desc r ip to r  
abbrevia t ions  under t he  AUTONOTE2 system. Once a lengthy phrase had been de- 
f i ned  i n  the  network the re  was generally no need t o  reference  i t  again wi th  a 
full desc r ip t i on ,  
The Sauvain s tudy i d e n t i f i e d  a c l e a r  need f o r  mechanisms t o  assist the  
user i n  maintaining cons i s t en t  indexing. 
The second type  of need (how -a d e s c r i p t o r  has been used) 
f requen t ly  occurs when a text  i t e m  is  being entered.  The user  
has  some ideas  f o r  candidate d e s c r i p t o r s ,  suspects  t h a t  t he re  
has  been p r i o r  usage of these words, and needs a way t o  check 
t h e  p r i o r  usage t o  keep h i s  indexing cons i s t en t .  He a l s o  may 
want t o  look a t  p r i o r  usage contexts  t o  g e t  i deas  about o the r  
desc r ip to r s  t o  use,  o r  t o  weed out  candidates  t h a t  look too general.  
The t o p i t a l  view of the d a t a  base under AWONOTE2 e l imina tes  p a r t  of t h i s  
problem. When descr ib ing a - new top ic  t he  AUTONOTE2 user  need not  be a s  con- 
cerned about p r i o r  word usage i n  o the r  contexts .  The represen ta t iona l  network 
provides a means f o r  d i sc r imina t ing  among t h e  var ious  t op i c s  i n  which a par- 
t i c u l a r  word occurs. 
I f ,  on t h e  o the r  hand, the  user  suspects  t h a t  the  item a t  hand i s  somehow 
r e l a t e d  t o  a previously e x i s t i n g  top i c ,  t he re  i s  an analogous need t o  i n t e r ro -  
gate the  r ep re sen ta t i ona l  network f o r  candidate top ics .  This capab i l i t y  i s  
provided by the  DESCRIBE command. There were, i n  f a c t ,  numerous ins tances  in 
the  AUTONOTE2 protocols  of network in t e r roga t ion  p r i o r  t o  en t e r ing  descrip-  
t ions .  An example i s  given i n  Fig.  22. I n  response t o  t h e  u se r ' s  descript ion 
USER: OPEN 
USBR: /SALTON'S ccs COLLOQUIUM ON EVALUATION 
EJEW TOPIC ASSUMED 
USER: RELOCATE 
WHICH DO YOU MEAN: 
A. THIE COMPUTER EVALUATION OF INDEXING (AND TEXT PROCESSING) 
B. EVALUATION OF CRT DISPLAY USAGE 
Fig. 22 - Network in t e r roga t ion  d u r h g  desc r ip t i on  en t ry  
t he  system indicates that  no assoc ia t ion  w i l l  be made wi th  a p r i o r  top ic .  The 
user  r e c a l l s  talking about t h e  eva lua t ion  of automatic indexing techniques 
earlier so  he reques ts  the  system t o  search f u r t h e r  by en te r ing  a RELOCATE com- 
mand. Two candidates are generated, one of which is  the  des i red  r e f e r en t .  
Under the,keyword system, searching f o r  candidate desc r ip to r s  and usage 
contexts  was much more tedious.  Typical ly,  a RETRIEVE: command was i ssued cal-  
l i n g  f o r  the  d i sp lay  of a l l  keyword l ines  of i t e m s  indexed by a p a r t i c u l a r  term 
o r  l o g i c a l  combination of terms. I n  some cases a l a r g e  number of i tems were 
accessed neces s i t a t i ng  t i m e  consuming perusal  of  t h e  da t a  base. 
The d iscuss ion  thus  far should convey some f e e l i n g  for the degree of com- 
municative e f f i c i ency  achievable wi th  AUTONOTE2. To provide a more precise 
i nd i ca t ion  of t h i s  aspect  of system performance w e  ca lcu la ted  the  r a t i o  of 
content  words conveyed t o  content  words entered  f o r  th ree  samples of da ta  base 
items ( a r t i c l e s  and preposi t ions  were excluded). The average number of AUTO- 
NOTE2 words entered  and conveyed were compared wi th  the  average number of 
AUTONOTE keywords assigned wi th in  each sample (under the  keyword system t h i s  
r a t i o  w i l l  always equal one). The th ree  samples taken were (1) a random sample 
of 50 items, (2) 41 sequen t ia l  items, and (3)  a l l  items deal ing with some as- 
pect  of a r t i f i c i a l  i n t e l l i gence .  
The r e s u l t s  of t h i s  t abu la t ion  are summarized i n  Fig. 23. In  a l l  t h r ee  
samples more than th ree  content words were conveyed f o r  every two entered,  on 
the  average. The conveyed-entered r a t i o  was lowest f o r  the  random sample and 
highes t  f o r  t h e  a r t i f i c i a l  i n t e l l i g e n c e  i t e m s .  This i s  because most of the  
items deal ing wi th  a r t i f i c i a l  i n t e l l i g e n c e  were entered wi th  a r i c h  g lobal  con- 
t e x t  of t op i c  nodes defined. The sequen t ia l  items, on the  o ther  hand, were re- 
l a t e d  t o  several smaller, more local ized t o p i c  s t ruc tu re s .  Consequently, mapy 
more of these  items were described i n  f u l l .  The random sample lacked a consis- 
t e n t  contextual  framework, and consequently had the  l e a s t  communicative e f f i -  
ciency on the  average. 
Ret r ieval  a c t i v i t y .  W e  have seen t h a t  r e t r i e v a l  a c t i v i t y  i s  an e s s e n t i a l  
p a r t  of the  indexing and organizat ional  processes.  The protocols  show a f re -  
quent need t o  search f o r  r e l a t e d  mate r ia l  and i t e m  numbers i n  the keyword sys- 
t e m  and a corresponding need f o r  network in t e r roga t ion  p r i o r  t o  descr ip t ion  
en t ry  under AUTONOTE2. However, the  AUTONOTE2 t op i c  framework el iminates  much 
of the  t e x t  file perusa l  so common i n  the AUTONOTE protocols .  Each top ic  des- 
c r i p t i o n  typ i ca l ly  provides a c l ea r  i nd i ca t ion  of the  content of i t s  associa ted  
Fig. 23 - A comparison of entered and conveyed content words 
f o r  t h r ee  samples of d a t a  base i t e m s  
1 
A r t i f i c i a l  
Random Sequential  I n t e l l i g e n c e  
Sample Sample Sample 
No. of items i n  sample 50 41 30 
No. of keywords o r i g i n a l l y  assigned 270 251 155 
Avg. No. of keywords pe r  item 5.4 6.1 5.1 
No. of content words entered 256 233 109 
Avg. Now of content words entered per  5 .1  5.7 3 . 6  
i t e m  
No. of content words conveyed 388 396 235 
Avg. Now of content words conveyed p e r  7.9 9.7 7.8 
i t e m  
No. of words conveyed per  word entered 1.5 1.7 2.2 
I L1 
items. Consequently, the re  w a s  very l i t t l e  need t o  examine the  text  f i l e  
p r i o r  t o  describing new items or  r e l a t i n g  them t o o t h e r s  i n  t h e  d a t a  base. A 
perusal  of candidate top ics  generated by the  DESCRIBE command was s u f f i c i e n t  i n  
most cases. 
The most outstanding improvement during r e t r i e v a l  a c t i v i t y  occurred i n  in- 
s tances of very general  queries .  Under the  keyword system a request  f o r  all 
items pe r t i nen t  to, say, ARTIFICIAL INTELLIGENCE o r  PROBLEM SOLVING w i l l  access 
a l a r g e  set of items. Queries of t h i s  kind were employed t o  peruse large seg- 
ments of t h e  data  base re levant  t o  a general  top ic  area--for example, i n  search 
of i t e m  candidates f o r  a p a r t i c u l a r  grouping. The important d i f fe rence  between 
the  two systems i n  t h i s  s i t u a t i o n  is  t h a t  AUTONOTE g ives  the  user  no ind i ca t ion  
of the subtopics wi th in  the  general topic area. The AUT.ONOTE user e s s e n t i a l l y  
has two a l t e rna t ives :  he may display  each of t he  accessed i temsCoptionally 
suppressing t e x t ) ;  o r  he may f u r t h e r  r e s t r i c t  the  set of i t e m s w i t h  an addi- 
J 
additional set of descriptors. Both options have notable drawbacks. The 
first entails time-consuming perusal of the data base. The second raises a 
more significant problem. Which descriptors should be used to restrict the 
size of the accessed set of items? Some descriptors may restrict the set too 
greatly, eliminating relevant material; others may discriminate very little or 
not at all. In the absence of system feedback, this discrimination process 
places a major burden on the user's memory. 
The AUTONOTE2 system, on the other hand, provides the user with very 
meaningful feedback in response to general queries. Consider, fbr example, 
the retrieval protocol presented in Fig, 24. At each level in the representa- 
tional network, the user is given an opportunity to choose among several sub- 
topics. This example very effectively demonstrates a marked improvement over 
keyword indexing--the ability to discriminate among subsets of material indexed 
under a common set of general descriptors. 
Conclusion 
An analysis of man-machine dialogs collected during the description of a 
realistically diverse collection of textual materials has shown the communica- 
tive ease and efficiency and the descriptive power attainable under the refer- 
ential system. The results Indicate that the referential mechanisms developed 
in this study copstitute a viable alternative to keyword indexing techniques 
as applied to personal information systems. The referential approach offers 
four primary contributions toward the improvement of man-machine communication; 
each corresponds to a particular kind of facilitation during storage and re- 
trieval activity. 
L S 
USER: FIND ARTIFICIAL INTELLIGENCE 
DO YOU WANT: 
A. THE 1968 ARTIFICIAL INTELLIGENCE CONFERENCE AT CWRU 
Be THE I N F L ~ c E  OF ARTIFICIAL INTELLIGENCE ON COGNITIVE 
PSYCHOLOGY 
C. THE GENERAZ APPROACH TO ARTIFICIAL INTELLIGENCE 
D. ARTIFICIAL INTELLIGENCE USEARCH AT MIT 
E. RETATION OF ARTIFICIAL INTELLIGENCE TO PSYCHOLOGY 
USER: A 
1 ITEM SAnD. WANT TO EXPLORE? 
USER: YES 
DO YOU WANT: 
A. M L ' S  TALK AT THE CONFERENCE ON THE REPRESENTATION OF A 
PROBLEM SOLVING SYSTEM 
B. ROBINSON'S TALK AT THE CONFERENCE ON THEOREM PROVING SYSTEMS 
C. LIN'S PAPER AT THE CONFERENCE ON THE HEURISTIC SOLUTION OF 
'LARGE COMBINATORIAL PROBLEMS 
D. BANERJI'S OVERVIEW OF GAME PLAYING PROGRAMS AT THE CONFERENCE 
E. SIMMONS REVIEW OF QUESTION ANSWERING SYSTEMS AT THE CONFERENCE 
F. OTHER TALKS AT THE CONFERENCE 
G. SLAGLE'S DISCUSSION AT THE CONFERENCE ON HEURISTIC SEARCH 
PROGRAMS 
He FImS PRESENTATION AT THE CONFE'IIENCE OF AN ALGOL-LIKE 
LANGUAGE FOR PROBLEM SOLVING PROCEDURES 
I. FEIGENBAUM'S DISCUSSION AT THE CONFERENCE OF THE DENDRAL 
J. BANERJI'S 
Fig. 24 - Topic descriminat ion during 
retrieval a c t i v i t y  
F i r s t ,  t he  concept of a r ep re sen ta t i ona l  network provides the use r  with a 
p a r t i c u l a r l y  n a t u r a l  view of both t he  content  and organiza t ion  of h i s  d a t a  base 
In essence, the  user  e x p l i c i t l y  de f ines  the important concepts and top i c s  w i t h -  
i n  h i s  own area of i n t e r e s t ;  he spec i f i ed  s t r u c t u r a l  r e l a t i onsh ips  among con- 
cep t s  and, i n  general, manipulates these informat ional  ob j ec t s  during a l l  phases 
of  problem solving a c t i v i t y .  This t o p i c a l  view of the  d a t a  base i s ,  i n  a very 
real sense,rnore "meaningful" td t h e  user  than the a r t i f i c i a l  view inherent i n  
keyword indexing systems. 
Second, t he  developed techniques provide a un i f i ed  treatment f o r  bo th  in- 
dexing and organiza t ional  a c t i v i t y .  The communication of s t r uc tu r a l  
associations is achieved through exactly the same descriptive mechanisms used 
in categorizing material. In effect, the topic serves as the focal point in 
all aspects of communication with the system. 
Third, retrieval capability is considerably enhanced by the discriminatory 
power of the referential system. The representational network provides an 
effective means for distinguishing among the many topics that may be partially 
indexed under a c o m n  set of words. As noted earlier, this discriminatory 
power is especially useful in providing meaningful user feedback in response to 
general retrieval queries. Further, since each topic description serves to 
identify the content of its associated items, the representational network may 
be used as a retrieval intermediary. That is, the user can essentially engage 
in retrieval activity by utilizing mechanisms for exploring the topic struc- 
tures in the network, This aspect of the system greatly reduces the need for 
lengthy perusal of document texts in search of desired materials. 
Finally, the utilization of the structural context provided by the network 
approach taakes it possible for the user to describe, organize, and retrieve 
materials with considerable communicative efficiency, This is a fundamental 
aspect of the system design--to provide a framework for interpreting terse, 
efficient, sometimes ambiguous references to the topics in the information uni- 
verse. 
In light of the increasing availability of on-line computing facilities 
today, it seems reasonable to expect that personalized retrieval systems will 
play an expanding role in the computer support of individual research activity. 
It is hoped that thisstudywill suggest new directions for the design of such 
systems. 
REFERENCES 
Dosert, B. H., & Th~mpson, F. B. How features resolve syntactic ambiguity. 
In J. Minker & S. Rosenf ield ( ~ d s .  ) , Proceedings of Sytnposiwn of Infor- 
mation Storage and Retrieval, University of Maryland, April, 1971. 
Linn, W. E. Jr. Man-machine referential communication in a personal informa- 
tion retrieval system. (Doctoral dissertation, The University of 
Michigan) Ann Arbor, Michigan: University Microfilms, 1972. No. 73-6867. 
Reitman, W. Cognition and thought. New York: Wiley , 1965. 
Reitman, W,, Roberts, R. B., Sauvain, R e  W,, Wheeler, D, D., & Linn, W. 
AUTONOTE: A personal information storage and retrieval system, Proceed- 
ings of the 24th National Conference of the Associati~n for Computinq 
Machinery, New York: Association for Computing Machinery, 1969. 
Pp. 67-76. 
Sauvain, Re W. Structural communication in a personal information storage and 
retrieval system. (~octoral dissertation, The University of Michigan) 
Ann Arbor, Michigan: University Microfilms, 1970. No, 70-21782. 

