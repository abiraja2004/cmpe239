A Structure-Sharing Representation 
for 
Unification-Based Grammar Formalisms 
Fernando C .  N .  Pere i ra  
Ar t i f i c ia l  In te l l igence  Center ,  SR I  In ternat iona l  
and  
Center  fo r  the  S tudy  o f  Language and  In fo rmat ion  
S tanford  Un ivers i ty  
Abst ract  
This paper describes a structure-sharing method for the rep- 
resentation of complex phrase types in a parser for PATR-\[I, 
a unification-based grammar formalism. 
In parsers for unification-based grammar formalisms, 
complex phrase types are derived by incremental refinement 
of rite phrase types defined in grammar rules and lexical 
entries. In a naive implementation, a new phrase type is 
built by copying older ones and then combining the copies 
according to the constraints stated in a grammar ule. The 
structure-sharing method was designed to eliminate most 
such copying; indeed, practical tests suggest hat the use of 
this technique reduces parsing time by as much as 60%. 
The present work is inspired by the structure-sharing 
method for theorem proving introduced by Boyer and Moore 
and on the variant of it that is used in some Prolog imple- 
mentations. 
1 Overv iew 
In this paper I describe a method, structure sharing, for 
the representation of complex phrase types in 'a parser for 
PATR-II, a unification-based grammar formalism. 
In parsers for unification-based grammar formalisms, 
cfmtplex phrase types are derived by incremental refinement 
of the phrase types defined in grammar rules anti h, xical 
emries. In a naive implementation, a new phrase t.vpe is 
built by" copying older ones and then combining the copies 
according to the constraints tated in a grammar uh,. The 
structure-sharing method eliminates most such copying by 
This research, made possible in part by a gift from the Systems De* 
velol.~ment Foundation, wa~ also supported by the Defense Advanced 
Research Projects Agency under Contracts N00039*80-C-OG75 and 
N00039-84-C-0,524 with the Naval Electronic Systems Command. The 
views and conclusions contained in this document are those of the au- 
thor and should not be inierpreted as representative ol the official 
policies, either expressed or implied, of the Defense Advanced Re* 
s,,arrh Projects Agency, or the United States government. 
Thanks are due to Stuart Shieber, Lauri Karttunen. aml Ray Per- 
rault for their comments on earlier presentations of this materiM. 
representing updates to objects (phrase types) separately 
from the objects themselves. 
The present work is inspired by the structure-sharing 
method for theorem proving introduced by Boyer and Moore 
\[11 and on the variant of it that is used in some Prolog im- 
plementations \[9\]. 
2 Grammars  w i th  Un i f i ca t ion  
The data representation discussed in this paper is applicable, 
with but minor changes, to a variety of grammar formalisms 
based on unification, such as definite-clause grammars \[61, 
functional-unification grammar \[4\], lexical-fimctional gram- 
mar \[21 and PATR-II \[8i. For the sake of concreteness, how- 
ever, our discussion will be in terms of the PATR-II formal- 
ism. 
The basic idea of unification-ba.se, I grammar formalisms is 
very simple. As with context-free ~rammars. granlmar ules 
stafe how phrase types con,blue t(, yiehl ol her phr:~se types. 
\[h,t where:m a context-free grammar allows only a finite 
nl,mber ,~f predefined atomic phrase types or nonlerminal.~, 
a unification-based grammar will in general define implicitly 
an infinity of phra.se types. 
A phrase type is defined by a net of constraints. A gram- 
mar m,le is a set of ronsl.rnints b,,twe,,u the type .\,~ . f  a 
phr:me ;lnd the types .\', . . . . . .  \ ' ,  of its ,'on..,iitm,nis. The 
rt,h, niay I,, applied It, It,. analysis ~,f a -,Ir'irlg s,, ;is the 
c<mc;ih,nalion of rcmslil.m'nls "~1,.....%t if and <rely if tho 
types ,,f the .~i arc' rOml);~iible with the lypes .\', ;tml the 
constraints in the ruh,. 
Unification is the operation that determines whether two 
types are compauble by buihling the most general type com- 
patible with both. 
if the constramls arc, Cqllationn I)elween at tril-iI,,s (~f 
phra.se types, ;is is the ,'ase in PAT I I - I I .  i~, ,  ltl ir:l~e l.x t)e- 
can lie uni lh,d wlH,iI~,~,l,r ih,,y ,Io l iol ;l~-.ii.rli , l i~i inci  ~,;ihie.~ 
I.o I l ie ,~;llll?, al, l .r i l l i lh,.  The  i l l l i l i l ; i l  i l l i i i~, lhcl l  jil.~l Ih~, ~'llii- 
junct ion  (,sOt I l i l i( l l l)  Of the ro r res lX lad ing  sets of  COll.~trailll~, 
lsl. 
Ilere is a sample rule, in a simplified version (if the PATR- 
137 
II notation: 
Xo - -  Xt  X2 : (Xo cat) = $ 
(X, cat) = NP 
(X, cat) = VP (l) 
(Xt agr) = (X~ agr) 
(Xo trans) = (X2 trans) 
(Xo trans argt) = (Xt trans) 
This rule may be read as stating that a phrase of type Xo 
can be the concatenation f a phrase of type Xt and a phrase 
of type X:, provided that the attribute quations of the rule 
are satisfied if the phrases axe substituted for their types. 
The equations tate that phrases of types X0, Xt, and X: 
have categories S, NP, and VP, respectively, that types Xt 
and X~ have the same agreement value, that types Xo and 
X2 have the same translation, and that the first argument 
of X0's translation is the translation of Xt. 
Formally, the expressions of the form (it..-I,,,) used in 
attribute quations axe path8 and each I~ is a label. 
When all the phrase types in a rule axe given constant 
cat (category} values by the rule, we can use an abbreviated 
notation in which the phrase type vaxiables X~ axe replaced 
by their category values and the category-setting equations 
are omitted. For example, rule (1) may be written as 
S -* NP  VP : (NP aor) = (VP agr) 
(5' trana) = (VP teens) (2) 
(8 trana args) -- (NP  trans) 
In existing PATR-II implementations, phrase types are 
not actually represented by their sets of defining equations. 
Instead, they are represented by symbolic solutions of the 
equations in the form of directed acyclic graphs (dacs) with 
arcs labeled by the attributes used in the equations. Dag 
nodes represent the values of attributes and an arc labeled 
by l goes from node m to node n if and only if, according 
to the equations, the value represented by m has n as the 
value of its t attribute \[~\]. 
A dag node (and by extension a dag) is said to be atomic 
if it represents a constant value; complex if it has some out- 
going arcs; and a leaf if is is neither atomic or complex, that 
is, if it represents an as yet completely undetermined value. 
The domain dora(d) of a complex dag d is the set of labels 
on arcs leaving the top node of d. Given a dag d and a label 
l E dora(d) we denote by d/I the subdag of d at the end of 
the arc labeled I from the top node of d. By extension, for 
any path p whose labels are in the domains of the appropri- 
ate subdags, d/p represents the subdag of d at the end of 
path p from the root of d. 
For uniformity, lexical entries and grammar rules are also 
represented by appropriate dags. For example, the dag for 
rule (t) is shown in Figure 1. 
3 The Prob lem 
In a chart parser \[31 all the intermediate stages of deriva- 
tions are encoded in ed0es, representing either incomplete 
0 2 
arg I I~  
trans 
Figure 1: Dag Representation f a Rule 
(active) or complete (pensive) phra.ses. For PATR-\[I, each 
edge contains adag instance that represents he phrase type 
of that edge. The problem we address here is how to encode 
multiple dag instances efficiently. 
\[n a chart parser for context-free grammars, the solution 
is trivial: instances can be represented by the unique inter- 
hal names (that is, addresses) of their objects because the 
information contained in an instance is exactly the same a.s 
that in the original object. 
\[n a parser for PATR-|I or any other unification-based for- 
realism, however, distinct instances of an object will in gen- 
eral specify different values for attributes left unspecified in 
the original object. Clearly, the attribute values pecified for 
one instance are independent of those for another instance 
of the same object. 
One obvious solution is to build new instances by copy- 
ing the original object and then updating the copy with the 
new attribute values. This was the solution adopted in the 
first PATR-II parser \[8\]. The high cost of this solution both 
in time spent copying and in space required for the copies 
thenmelves constitutes the principal justification for employ- 
ing the method described here. 
4 Structure Shar ing 
Structure sharing is based on the observation that an ini- 
tial object, together with a list of update records, contains 
the same information as the object that results from apply- 
ing the updates to the initial object. In this way, we can 
trade the cost of actually applying the updates (with pos- 
sible copying to avoid the destruction of the source object) 
against he cost of having to compute the effects of updates 
when examining the derived object. This reasoning applies 
in particular to dag instances that are the result of adding 
attribute values to other instances. 
138 
As in the variant of Boyer and Moore's method \[1\] used 
in Prolog \[9\], I shall represent a dag instance by a molecule 
(see Figure 2) consisting of 
1. \[A pointer to\] the initial dag, the instance's keleton 
2. \[A pointer to\] a table of updates of the skeleton, the 
instance's environment. 
Environments may contain two kinds of updates: reroutings 
that replace a dag node with another dag; are bindings that 
add to a node a new outgoing arc pointing to a dag. Figure 
3 shows the unification of the dags 
1, "- \ [a :z ,b :y \ ]  
z= = \[c. \[d: eli 
After unification, the top node of/2 is rerouted to It and the 
top node of \[i gets an arc binding with label c and a value 
that is the subdag \[d : e\] of/2. As we shall see later, any up- 
date of a dag represented by a molecule is either an update 
of the molecule's keleton or an update of a dag (to which 
the same reasoning applies) appearing in the molecule's en- 
viroment. Therefore, the updates in a molecule's environ- 
ment are always shown in figures tagged by a boxed number 
identifying the affected node in the molecule's skeleton. 
The choice of which dag is rerouted and which one gets 
arc bindings is arbitrary. 
For reasons discussed later, the cost of looking up instance 
node updates in Boyer and Moore's environment represen- 
tation is O(\]dl), where \[d\[ is the length of the derivation (a 
~equence of resolutions) of the instance. In the present rep- 
resentation, however, this cost is only O(Iog \]d\]). This better 
performance is achieved by particularizing the environment 
representation a d by splitting the representational scheme 
into two components: a memory organization and a daft rep- 
re.sentation. 
A dag representation is & way of mapping the mathemat- 
ical entity dag onto a memory. A memory organization is a 
way of putting together a memory that has certain proper- 
ties with respect o lookup, updating and copying. One can 
think of the memory organization as the hardware and the 
dag representation as the data structure. 
5 Memory  organ izat ion  
In practice, random-access memory can be accessed and up- 
dated in constant ime. However, updates destroy old val- 
ues, which is obviously unacceptable when dealing with al- 
ternative updates of the same data structure. If we want to 
keep the old version, we need to copy it first into a sepa- 
rate part of memory and change the copy instead. For the 
normal kind of memory, copying time is proportional to the 
size of the object copied. 
The present scheme uses another type of memory orga- 
nization - -  virtual-copy array~ ~ which requires O(logn) 
time to access or update an array with highest used index 
k=2 
a\[nl = f a:  
f 
n = 30 = 132 (base 4) 
O(a) = 3 
Figure 4: Virtual-Copy Array 
of n, but in which the old contents are not destroyed by up- 
dating. Virtual-copy arrays were developed by David H. D. 
Warren \[10\] as an implementation of extensible arrays for 
Prolog. 
Virtual-copy arrays provide a fully general memory ~truc- 
ture: anything that can be stored in r,'tndom-a,-ces~ mem- 
ory can be stored in virtual-copy arrays, althoqlgh p,~mters 
in machine memory correspond to indexes in a virtual-copy 
array. An updating operation takes a virtual-copy array, an 
index, and a new value and returns a new virtual-copy array 
with the new value stored at the given index. An access op- 
eration takes an array and an index, and returns the value 
at that index. 
Basically, virtual-copy arrays are 2k-ary trees for some 
fixed k > 0. Define the depth d(n) of a tree node n 
to be 0 for the root and d(p) + I if p is the parent of 
n. Each virtual-copy array a has also a positive depth 
D(a) > max{d(n) : n is a node of a}. A tree node at depth 
D(a) (necessarily a leaf) can be either an array element 
or the special marker .L for unassigned elements. All leaf 
nodes at depths lower than D(a) are also ?, indicating that 
no elements have yet been stored in the subarray below the 
node. With this arrangement, he array can store at most 
2 k?('l elements, numbered 0 through 2 k?~*l - l, but unused 
sdbarrays need not be allocated. 
By numbering the 2 h daughters of a nonleaf node from 0 
to 2 k - 1, a path from a's root to an array element (a leaf at 
depth D(a)) can be represented by a sequence no. . .  no(ab-t 
in which n, is the number of the branch taken at depth d. 
This sequence is just the base 2 k representation f the index 
n of the array element, with no the most significant digit 
and no(.} the least significant (Figure .t). 
When a virtual-copy array a is updated, one of two things 
may happen. If the index for the updated element exceeds 
the maximum for the current depth (,a~ in the a\[8\] := ~/up- 
date in Figure 5), a new root node is created for the updated 
array and the old array becomes the leftmost daughter of the 
new root. Other node,, are also created, as appropriate, to 
reach the position of the new element. If, on the other hand, 
the index for the update is within the range for the current 
139 
mo,.~,2~  _ m 
I 
skeleton ~ "~ environment 
own I ref I ref 
Spot Daniel 
initial update 
?-? I,ef I,.f 
Daniel Spot 
Figure 2: Molecule 
X unification 
. / ~ ~ < > ~  <-/ \  <> 
? -  "_L_ J ? -  ' :_L_ 
III 
xa y~d 
Figure 3: Unification of Two Molecules 
140 
a{21: = h 
a: \[O:e, 2:h, 8:gl 
o{81: = g 
? ? 
a: \[0:e, 2:f, 8:gl 
I g 
a: \[0:e, 2:fl 
e f 
Figure 5: Updating Virtual-Copy Arrays 
depth, the path from the root to the element being updated 
is copied and the old element is replaced in the new tree by 
the new element (as in the a\[21 := h update in Figure 5). 
This description assumes that the element being updated 
has alroady been set. If not, the branch to the element may 
T,,rminate prematurely in a 2. leaf, in which case new nodes 
are created to the required depth and attached to the ap- 
propriate position at the end of the new path from the root. 
6 Dag representation 
Any dug representation can be implemented with virtual- 
copy memory instead of random-access memory. If that were 
,lone for the original PATR-II copying implementation, a 
certain measure of structure sharing would be achieved. 
The present scheme, however, goes well b~yond that by 
using the method of structure sharing introduced in Section 
4. As we saw there, an instance object is represented by a 
molecule, a pair consisting of a skeleton dug {from a rule 
or iexical entry) and an update environment. We shall now 
examine the structure of environments. 
In a chart parser for PATR-ll, dug instances in the chart 
fall into two classes. 
Base in.stances are those associated with edges that are 
created directly from lexical entries or rules. 
Derived instances occur in edges that result from the com- 
bination of a left and a right parent edge containing the left 
and right parent instances of the derived instance. The left 
ancestors of an instance {edge) are its left parent and that 
parent's ancestors, and similarly for right ancestors, l will 
assume, for ease of exposition, that a derived instance is 
always a subdag of the unification of its right parent with 
a subdag of its left parent. This is the case for most com- 
mon parsing algorithms, although more general schemes are 
possible \[7\]. 
If the original Boyer-Moore scheme were used directly, the 
environment for a derived instance would consist of point- 
ers to left and right parent instances, as well as a list of 
the updates needed to build the current instance from its 
parents. As noted before, this method requires a worst-case 
O(Idl} search to find the updates that result in the current 
instance. 
The present scheme relies on the fact that in the great 
majority of cases no instance is both the left and the right 
ancestor of another instance. \[ shall assume for the moment 
that this is always the case. In Section 9 this restriction will 
be removed. 
It is asimple observation about unification that an update 
of a node of an instance \]" is either an update of \[ 's skeleton 
or of the value (a subdag of another instance) of another 
update of L If we iterate this reasoning, it becomes clear 
that every update is ultimately an update of the skeleton of 
a base instance ancestor of \[. Since we assumed above that 
no instance could occur more than once in it's derivation, we 
can therefore conclude that \[ 's environment consists only of 
updates of nodes in the skeletons of its base instance an- 
cestors. By numbering the base instances of a derivation 
consecutively, we can then represent an environment by an 
array of frames, each containing all the updates of the skele- 
ton of a given base instance. 
Actually, the environment of an instance \[ will be a branch 
environment containing not only those updates directly rele- 
vant to \[, but also all those that are relevant o the instances 
o f / ' s  particular branch through the parsing search space. 
In the context of a given branch environment, it is then 
possible to represent a molecule by a pair consisting of a 
skeleton and the index of a frame in the environment. In 
particular, this representation can be used for all the value~ 
(dags) in updates. 
More specifically, the frame of a base instance is an array 
of update records indexed by small integers representing the 
nodes of the instance's skeleton. An update record is either 
a list of arc bindings for distinct arc labels or a rerouting 
update. An arc binding is a pair consisting of a label and 
a molecule (the value of the arc binding). This represents 
an addition of an arc with that label and that value at th,, 
given node. A rerouting update is just a pointer to another 
molecule; it says that the subdag at that node in the updated 
dug is given by that molecule (rather than by whatever w,xs 
in the initial skeleton). 
To see how skeletons and bindings work together to rep- 
resent a dag, consider the operation of finding the sub(tag 
d/ ( I t ' " lm)  of dug d. For this purpose, we use a current 
skeleton s and a current frame f, given initially by the skele- 
ton and frame of the molecule representing d. Now assume 
141 
that the current skeleton s and current frame ,f correspond 
to the subdag d' -- d/(ll.., l~-l). To find d/(l~.., l~) -" ~/l~, 
we use the following method: 
I. If the top node of s has been rerouted in j" to a dag v, 
dereference ? by setting s and .f from v and repeating 
this step; otherwise 
2. If the top node of s has an arc labeled by l~ with value 
s', the subdag at l~ is given by the moledule (g,\[); 
otherwise 
3. If .f contains an arc binding labeled l~ for the top node 
of s, the subdag at l~ is the value of the binding 
If none of these steps can be applied, (It .-. l~) is not a path 
from the root in d. 
The details of the representation are illustrated by the 
example in Figure 6, which shows the passive edges for the 
chart analysis of the string ab according to the sample gram- 
S-*AB:  (5" a) = (A) 
(S b) = (B) 
(S==)  = (Shy)  
mar  
A-*a :  (Auv)  = a 
(3) 
8-. . .b:  (Buy)  = b 
For the sake of simplicity, only the subdags corresponding 
to the explicit equations in these rules are shown (ie., the 
cat dug arcs and the rule arcs 0, 1,... are omitted}. In 
the figure, the three nonterminal edges (for phrase types S, 
.4 and B) are labeled by molecules representing the corre- 
sponding dags. The skeleton of each of the three molecules 
comes from the rule used to build the nonterminal. Each 
molecule points (via a frame index not shown in the figure) 
to a frame in the branch environment. The frames for the 
A and B edges contain arc bindings for the top nodes of 
the respective skeletons whereas the frame for the S edge 
reroute nodes 1 and 2 of the S rule skeleton to the A and B 
molecules respectively. 
7 The Unification Algorithm 
I shall now give the u~nification algorithm for two molecules 
(dags} in the same branch environment. 
We can treat a complex dug d a8 a partial function from 
labels to dags that maps the label on each arc leaving the top 
node of the dag to the dug at the end of that arc. This allows 
us to define the following two operations between dags: 
d~ \ d2 = {{l ,d}ed~l i~dom{d:}} 
di <3 d= = {(l,d) Edl  J I Gdorn(d:)} 
It is clear that dom(dl <~ d~) = dom(d2 <~ dl). 
We also need the notion of dug dereferencing introduced 
in the last section. As a side effect of successive unifications, 
the top node of a dag may be rerouted to another dag whose 
top node will also end up being rerouted. Dereferencing is 
the process of following such chains of rerouting pointers to 
reach a dug that has not been rerouted. 
The unification of dags dl and d~ in environment e consists 
of the following steps: 
1. Dereference dl and d2 
2. If dl and d: are identical, the unification is immediately 
successful 
3. 
4. 
5. 
6. 
If dl is a leaf, add to e a rerouting from the top node of 
dl to d~; otherwise 
If d2 is a leaf, add to e a rerouting from the top node of 
d2 to dl; otherwise 
If dl and d2 are complex dags, for each arc (l, d) E dl <~ 
d= unify the dag d with the dag d' of the corresponding 
arc (i,d') G d~ <l dl. Each of those unifications may 
add new bindings to e. If this unification of subdags i.~ 
successful, all the arcs in dl \ d~ are are cab'red in e ~ 
arc bindings for the top node of d: and tinnily the top 
node of dl is rerouted to d~. 
If none of the conditions above applies, the unification 
fails. 
To determine whether a dag node is a leaf or com- 
plex, both the skeleton and the frame of the corresponding 
molecule must be examined. For a dereferenced molecule. 
the set of arcs leaving a node is just the union of the skele- 
ton arcs and the arc bindings for the node. For this to make 
sense, the skeleton arcs and arc bindings for any molecule 
node must be disjoint. The interested reader will have no 
di~cuhy in proving that this property is preserved by the 
unification algorithm and therefore all molecules built from 
skeletons and empty frames by unification wiU satisfy it. 
? 
8 Mapping dags onto virtual-copy 
memory 
As we saw above, any dag or set of dags constructed by 
the parser is built from just two kinds of material: (I) 
frames; (21 pieces of the initial skeletons from rules and 
\[exical entries. The initial skeletons can be represented triv- 
ially by host language data structures, as they never change. 
F~'ames, though, are always being updated. A new frame is 
born with the creation of an instance of a rule or lexical 
entry when the rule or entry is used in some parsing step 
(uses of the same rule or entry in other steps beget their own 
frames). A frame is updated when the instance it belongs 
to participates in a unification. 
During parsing, there are in general several possible ways 
of continuing a derivation. These correspond to alternative 
ways of updating a branch environment. In abstract terms, 
142 
\[\] \[\] 
{7) i 
Figure 6: Structure-Sharing Chart 
on coming to a choice point in the derivation with n possi- 
ble continuations, n - 1 copies of the environment are made, 
giving n environments - - namely, one for each alternative. 
In fact. the use of virtual-copy arrays for environments and 
frames renders this copying unnecessary, so each continu- 
ation path performs its own updating of its version of the 
environment without interfering with the other paths. Thus, 
all unchanged portions of the environment are shared. 
In fact, derivations as such are not explicit in a ,'hart 
parser. Instead, the instance in each edge has its own branch 
,,nvironment, as described previously. Therefore. when two 
e,lges are combined, it is necessary to merge their environ- 
ments. The cost of this merge operation is at most the same 
the worst case cost for unification proper (O(\[d\[ log JdJ)). 
However, in the very common case in which the ranges of 
frame indices of the two environments do not overlap, the 
merge cost is only O(log \[d\[). 
To summarize, we have sharing at two levels: the Boyer- 
Moore style dag representation allows derived (lag in- 
stances to share input data structures (skeletons), and the 
virtual-copy array environment representation allows differ- 
ent branches of the search space to share update records. 
9 The Renaming Problem 
In the foregoing discussion of the structure-sharing method, 
\[ assumed that the left and right ancestors of a derived in- 
stance were disjoint. In fact, it is easy to show that the con- 
dition holds whenever the graHtm;tr d. 's  n?)t ~.llow elllpty 
deriv(,d edges. 
In ,',mtrast, it is p,)ssible t,) construct a grammar in which 
an empty derived edge with dag D is b. th a left and a right 
ancestor of another edge with dag E. Clearly, tile two uses 
(~f D a.s an ancestor of E are mutually independent and 
the corresponding updates have to be seqregated. In ,~ther 
words, we need two ,'~l)ies of tile instance D. 13v anal,,~' 
with theorem proving, \[ call Ihi~ lhe renaminq pr~d,h,m. 
The ('nrreflt sol|,t.i(,n is t,) us,, real ,'(,I)YiV|g t,) turn th,, 
empty edge into a skelet(>n, which is the|| adde~l t~ the chart. 
The new skeleton is then used in the norn|al fa.shion to pro- 
duce multiple instances that are free of mutual interference. 
10 Imp lementat ion  
The representation described here has been used in a PATR- 
II parser implemented in I)r,~l,)g ". Two versions of the parser 
exist - cme using all Ea,-h,y-st.vle algorithn| related to Ear- 
ley deduction \[7\], the other using a left-,'.rner algorithm. 
Preliminary tests of the left-corner algorithm with struc- 
ture sharing on various grammars and input have shown 
parsing times as much as 60% faster (never less, in fact, 
than 40% faster) than those achieved by the same parsing 
algorithm with structure copying. 
14,3 
References 
\[1\] R. S. Boyer and J S. Moore. The sharing of structure in 
theorem-proving program& In Machine Intelligence 7, 
pages 101-116, John Wiley and Sons, New York, New 
York, 1972. 
\[21 J. Bresnan and R. Kaplan. Lexical-functional gram- 
mar: a formal system for grammatical representation. 
In J. Bresnan, editor, The Mental Representation of 
Grammatical Relations, pages 173-281, MIT Press, 
Cambridge, Massachusetts, 1982. 
\[3\] M. Kay. Algorithm Schemata nd Data Structures in 
Syntactic Processing. Technical Report, XEROX Palo 
Alto Research Center, Palo Alto, California, 1980. A 
version will appear in the proceedings of the Nobel 
Symposium on Text Processing, Gothenburg, 1980. 
I4\] M. Kay. Functional grammar. In Pro?. of the Fifth 
Annual Meeting of the Berkeley Linguistic Society, 
pages 142-158, Berkeley Linguistic Society, Berkeley, 
California, February 17-19 1979. 
\[5\] Fernando C. N. Pereira nd Stuart M. Shieber. The se- 
mantics of grammar formalisms een as computer lan- 
guages. |n Proe. of Coling8~, pages 123-129, Asso,-ia- 
tion for Computational Linguistics, 1984. 
\[6\] Fernando C. N. Pereira and David H. D. Warren. Defi- 
nite clause grammars for language analysis - a survey of 
the formalism and a comparison with augmented transi- 
tion networks. Artificial Inteilicence, 13:231-278, 1980. 
\[7\] Fernando C. N. Pereira and David H. D. Warren. Pars- 
ing as deduction. In Proc. of the 9lst Annual 3Iectin~ 
of the Association for Computational Linguistics, MIT, 
Cambridge, Massachusetts, June 15-17 1983. 
\[8\[ Stuart M. Shieber. The design of a computer lan- 
guage for linguistic information. In Proc. of Colinf8j, 
pages 362-366, Association for Computational l,inguis- 
tics, 1984. 
\[9\] David H. D. Warren. Applied Logic - its use and intple. 
menlalion as proqramming tool. PhD thesis, University 
of FMinburgh, Scotland, 1977. Reprinted as T~,,'hnical 
Note 290, Artificial Intelligence Center, SRI, Intorna- 
tional, Menlo Park, California. 
{10\] David H. D. Warren, Logarithmic access arrays for 
Prolog. Unpublished program, 1983. 
144 
