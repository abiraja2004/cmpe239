Proceedings of the 2009 Workshop on the People?s Web Meets NLP, ACL-IJCNLP 2009, pages 42?50,
Suntec, Singapore, 7 August 2009. c?2009 ACL and AFNLP
Construction of Disambiguated Folksonomy Ontologies Using Wikipedia
Noriko Tomuro and Andriy Shepitsen
DePaul University, College of Digital Media
243 S. Wabash, Chicago, IL USA
tomuro@cs.depaul.edu, ashepits@cdm.depaul.edu
Abstract
One of the difficulties in using Folk-
sonomies in computational systems is tag
ambiguity: tags with multiple meanings.
This paper presents a novel method for
building Folksonomy tag ontologies in
which the nodes are disambiguated. Our
method utilizes a clustering algorithm
called DSCBC, which was originally de-
veloped in Natural Language Processing
(NLP), to derive committees of tags, each
of which corresponds to one meaning or
domain. In this work, we use Wikipedia
as the external knowledge source for the
domains of the tags. Using the commit-
tees, an ambiguous tag is identified as one
which belongs to more than one commit-
tee. Then we apply a hierarchical agglom-
erative clustering algorithm to build an on-
tology of tags. The nodes in the derived
ontology are disambiguated in that an am-
biguous tag appears in several nodes in
the ontology, each of which corresponds
to one meaning of the tag. We evaluate the
derived ontology for its ontological den-
sity (how close similar tags are placed),
and its usefulness in applications, in par-
ticular for a personalized tag retrieval task.
The results showed marked improvements
over other approaches.
1 Introduction
In recent years, there has been a rapid growth in
social tagging systems ? so-called Folksonomies
where users assign keywords or tags to categorize
resources. Typically, the sources of folksonomies
are web resources, and virtually any kind of infor-
mation available on the Internet, ranging from web
pages (e.g. Delicious (delicious.com)), scientific ar-
ticles (e.g. Bibsonomy (www.bibsonomy.org)) to me-
dia resources (e.g. Flickr (www.flickr.com), Last.fm
(www.last.fm)). Although tags in folksonomies are
essentially semantic concepts, they have distinct
characteristics as compared to conventional se-
mantic resources which are often used in Natu-
ral Language Processing (NLP), such as WordNet
(Miller, 1990). First, folksonomy tags are unre-
stricted ? users are free to choose any words or
set of characters to formulate tags. One significant
problem arising from such free-formedness is tag
ambiguity: tags that have several meanings (e.g.
?Java? as coffee or a programming language or an
island in Indonesia). Second, folksonomy tags are
unstructured ? tags assigned to a given resource
are simply enumerated in a list (although often-
times using a varying font size to indicate popu-
larity), and no special organization or categoriza-
tion of the tags is made (by the Folksonomy site).
There have been several work recently which ex-
tracted structures from folksonomy tags and con-
structed ontologies (e.g. (Clough et al, 2005),
(Schmitz, 2006)). However, most of them evalu-
ate the effect of the extracted structures only in the
context of specific applications, for instance gen-
erating user recommendations (e.g. (Shepitsen et
al., 2008)).
In this work, we develop a novel method for
constructing ontologies from folksonomy tags.
In particular, we employ a clustering algorithm
called Domain Similarity Clustering By Commit-
tee (DSCBC) (Tomuro et al, 2007). DSCBC is an
extension of an algorithm called CBC (Pantel and
Lin, 2002), and was originally developed for lexi-
cal semantics in NLP to automatically derive sin-
gle/unambiguous word meanings (as committees)
from ambiguous words. In this work, DSCBC is
effectively adopted to derive disambiguated folk-
sonomy tag committees, where a committee in this
context is a cluster of tags in which the members
share the same or very similar concept in one of
their meanings. By using DSCBC, an ambiguous
tag is identified as one which belongs to more than
42
one committee. One of the key ideas in DSCBC is
the notion of feature domain similarity: the sim-
ilarity between the features themselves, obtained
a priori from sources external to the dataset used
at hand. For example, if data instances x and y
are represented by features f1 and f2, the feature
domain similarity refers to the similarity between
f1 and f2 (not between x and y). DSCBC uti-
lizes this feature domain similarity to derive clus-
ters whose domains are ?close?, thereby produc-
ing unambiguous committees. In this work, we in-
corporate Wikipedia as the external knowledge re-
source, and use the similarity between Wikipedia
articles to derive the committees of disambiguated
tags. Finally using the tag committees derived by
DSCBC, we build an ontology of tags by using a
modified hierarchical agglomerative clustering al-
gorithm. Ambiguous tags are mapped to several
nodes in this ontology.
Note that in this paper, we refer to the structure
derived by the hierarchical clustering algorithm as
an ?ontology? instead of a ?taxonomy?. That is be-
cause, in the algorithm, the parent-child relation is
determined by a similarity measure only, therefore
sometimes does not correspond to the subsump-
tion relation in the strict sense.
For evaluation, we construct an ontology from
the Delicious tags, and measure the quality (onto-
logical density) of the derived ontology by com-
paring with the ontologies obtained without using
Wikipedia. We also use the derived ontology in
a personalized information retrieval task. The re-
sults show that our method achieved marked im-
provements over other approaches.
2 Related Work
Several efforts have been made recently which fo-
cused on extracting structures from folksonomies.
Clough (Clough et al, 2005) and Schmitz
(Schmitz, 2006) derived hierarchical structures
from image folksonomies (St. Andrew collection
(specialcollections.st-and.ac.uk/photcol.htm) and Flickr,
respectively). In addition to the hierarchi-
cal relation, they also derived other relations
such as ?type of?, ?aspect of?, ?same-as?, etc.
Mika (Mika, 2007) and Heymann (Heymann and
Garcia-Molina, 2006) proposed an automatic cre-
ation of tags in folksonomy networks based on
the tag co-occurrences among resources and users.
They then used a graph clustering algorithm to
connect tags which were used by the same users
and for the same resources to identify tag ?clouds?
and communities of like-minded users. However,
none of those work used NLP techniques, nor did
they deal with the tag ambiguity problem; Often-
times, highly ambiguous tags are even removed
from the data.
In our previous work (Shepitsen et al, 2008),
we used a standard hierarchical agglomerative
clustering algorithm to build a tag hierarchy. We
also considered only the most popular sense of an
ambiguous tag and ignored all other senses.
Wikipedia has been attracting much atten-
tion in the recent NLP research. For exam-
ple, Wikipedia as a lexical resource was ex-
ploited for thesauri construction (Milne et al,
2006) and for word sense disambiguation (Mi-
halcea and Csomai, 2007). Other NLP tasks in
which Wikipedia was utilized to provide contex-
tual and domain/encyclopedia knowledge include
question-answering (Ahn et al, 2004) and infor-
mation extraction (Culotta et al, 2006). In a simi-
lar vein, (Gabrilovich and Markovitch, 2006) also
used Wikipedia to improve the accuracy for text
categorization. An interesting text retrieval appli-
cation was done by Gurevych (Gurevych et al,
2007), in whichWikipedia was utilized to improve
the retrieval accuracy in matching the professional
interests of job applicants with the descriptions of
professions/careers.
The work presented in this paper applies an
NLP technique (the DSCBC algorithm), which in-
corporates the domain knowledge (Wikipedia) as
a critical component, to the task of extracting se-
mantic structure, in particular an ontology, from
folksonomies. Our method is novel, and the ex-
perimental results indicate that the derived ontol-
ogy was of high semantic quality.
3 Deriving Unambiguous Tag
Committees
The DSCBC algorithm, which we had developed
in our previous work (Tomuro et al, 2007), is
an extension of CBC Clustering (Pantel and Lin,
2002), modified to produce unambiguous clusters
when the data contained ambiguous instances. As-
suming the instances are represented by vectors of
features/domains, consider the following data:
a b c d
x: 1 1 0 0
y: 1 0 1 0
z: 1 0 0 1
43
where x, y, z are data instances, and a, b, c, d
are features. In most clustering algorithms, fea-
tures are assumed to be independent to each other,
or their dependencies are ignored. So in the ex-
ample, x is equally likely clustered with y or z,
because the similarity between x and y, and x and
z are the same (based on the Euclidean distance,
for example). However if we have a priori, gen-
eral knowledge about the features that b?s domain
is more similar to that of c than to d, it is better
to cluster x and y instead of x and z, because the
{x, y} cluster is ?tighter? than the {x, z} cluster
with respect to the domains of the features.
3.1 Feature Domain Similarity
In DSCBC, the general knowledge about the fea-
tures is incorporated as a measure called Fea-
ture Domain Similarity: the similarity between
the features themselves, obtained a priori from
sources external to the dataset used at hand. In this
work, we used Wikipedia as the external knowl-
edge source, and as the features to represent the
folksonomy tags. To this end, we first obtained the
most recent dump of Wikipedia and clustered the
articles to reduce the size of the data. We call such
a cluster of Wiki articles a Wiki concept. Cluster-
ing was based on the similarity of the terms which
appeared in the articles. Detailed descriptions of
the Wikipedia data and this clustering process are
given in section 5.1. Then given a set of folkson-
omy tags T , a set of folksonomy resources R and
a set of Wiki concepts W , we defined a matrix M
of size |T | ? |W |, where the rows are tags and the
columns/features are Wiki concepts. Each entry
in this matrix, for a tag t ? T and a Wiki con-
cept w ? W , was computed as the cosine between
two term vectors: one for t where the features are
terms used in (all of) the resources in R to which
t was assigned (by the folksonomy users), and an-
other for w where the features are terms used in
(all of) the Wiki articles in w. Thus, the matrix
M contains the similarity values for a given tag
to all Wikipedia concepts, thereby identifying the
(Wikipedia) domains of the tag.
Using the matrix M , we define the feature do-
main similarity between two tags f and g, denoted
fdSim(f, g), as:
fdSim(f, g) =
?
i
?
j fi ? gj ? cos(wi, wj)
?
?
i f2i ?
?
i g2i
where fi is the similarity of the tag f to the ith
Wiki concept (and likewise for g), and cos(wi, wj)
is the cosine (thus similarity) between the ith and
jth Wiki concepts. In this formula, the domain
knowledge is incorporated not only through the
way a tag is represented (as a vector of Wiki con-
cepts), but also directly by cos(wi, wj), the simi-
larity between Wiki concepts themselves.
In addition to Feature Domain Similarity, we
also incorporated a measure of reference tight-
ness for folksonomy tags and Wiki concepts. This
metric measures and takes advantage of the link
structure in the folksonomy system as well as
Wikipedia. For example, when a tag was assigned
to several web pages in the folksonomy system,
some of those pages may be reachable from each
other through hyperlinks ? in which case, we can
consider the tag?s domains are tight. Likewise for
Wiki concepts, if a folksonomy tag is ?similar?
to several Wiki concepts (for which the similar-
ity value is above some threshold), some of those
Wiki concepts may be reachable in the Wikipedia
structure ? then we can consider the tag?s domains
are tight as well. Furthermore, based on the notion
of reference tightness within a set of resources, we
define the connectedness between two sets of re-
sources as the fraction of the resources (web pages
orWiki concepts) in one set which are reachable to
resources in another set. We define the reference
tightness between two sets of resources S and U ,
denoted srt(S, U), as follows.
srt(S, U) =
?
s?S,u?U reach(s, u) + reach(u, s)
?
s?S nRef(s) +
?
u?U nRef(u)
where nRef(k) is the number of outgoing refer-
ence links in the resource k, and reach(a, b) is an
indicator function which returns 1 if any reference
link from the resource in a is reachable from any
resource in b or 0 otherwise. There are two terms
in the numerator because the reachability relation
is directional.
3.2 The DSCBC Algorithm
Using the notions of feature domain similarity and
reference tightness, we define the similarity be-
tween two tags f and g as follows.
dsSim(f, g) = ? ? fdSim(f, g)
+(1 ? ?) ? srt(Rf , Rg)
where Rf is the set of references from all web
pages to which the tag f is assigned, srt(Rf , Rg)
is the reference tightness between Rf and Rg, and
44
? is a weighting coefficient. In our experiments
(discussed in section 5), we set ? to be 0.8 based
on the results of the preliminary runs.
The DSCBC algorithm is shown in Algo-
rithm 1. DSCBC is an unsupervised clustering
algorithm which automatically derives a set of
committees. A committee is a group of folkson-
omy tags which are very similar to each other. In
Phase I, a set of preliminary tag clusters are first
created. In Phase II, some of those tag clusters are
selected as committees ? those which are dissimi-
lar/orthogonal to all other committees selected so
far. Then in Phase III, each tag is assigned to com-
mittees which are similar to the tag. The dsSim
function is used in Phase I and II to measure
the similarity between clusters and committees
respectively. In Phase III, an ambiguous tag is
assigned to one of more committees, where each
time the features of the assigned committee are
removed from the tag. Thus, ambiguous tags are
identified as those which belong to more than one
committee.
4 Building Folksonomy Tag Ontology
After obtaining the committees by DSCBC, we or-
ganize the tags into a ontology by using a modified
hierarchical agglomerative clustering algorithm.1
We first compute the pair-wise similarity between
any two tags and sort those pairs according to the
similarity values. Then we take the most similar
pair and create the first cluster. Afterwards, we it-
erate through the whole tag/cluster pairs and sub-
stitute all instances in which either tag is a mem-
ber, if the tag is not ambiguous, by the obtained
cluster, and repeat the process until the list of pairs
is empty. The committees derived by DSCBC are
utilized to identify ambiguous tags ? when a tag
belonged to more than one committee. When we
process an ambiguous tag, we first find its ?core
meaning? by finding the committee to which the
tag is most similar, then remove all (non-zero) fea-
tures that are encoded in committee from all in-
stances left in the dataset. With this scheme, we
can cover all senses of an ambiguous tag, for all
such tags, during ontology generation. The simi-
larity is computed using the dsSim function de-
scribed in the previous section; the only difference
that, if one member of a pair is a cluster, it is rep-
1Our algorithm is essentially a modification of the
Average-Link Clustering by (OConnor andHerlocker, 2001).
Input: Set of tags T. Tuning coefficients:
n - number of the most similar tags chosen for
the target tag
q - number of features for finding the centroid
? - similarity threshold for adding tags to
committees
? - similarity threshold for assigning tags to
committees
Output: Set of committees C. Set of tags T
where each t ? T is assigned to
committees in C.
Phase I. Finding set of clusters L
foreach ti ? T do
Select a set k of n most similar tj : i 6= j
add k to L if it is not already in L.
end
Phase II. Find Communities C
foreach c ? L do
Find the centroid of c using only q
features shared by most of tags in the
cluster
Add c to C if its similarity to every other
cluster is lower than ?
end
Phase III. Assign tags to committees
foreach t ? T do
Assign t to committee c in C if the
similarity is higher than ?
end
Algorithm 1: Clustering tags using DSCBC
45
resented by its centroid. Figure 1 shows an exam-
ple folksonomy ontology. The modified hierarchi-
cal agglomerative clustering algorithm is shown in
Algorithm 2.
Sport
Chess Fitness Soccer
Fi
sh
er
_g
en
Ru
ss
io
n_
bo
ok
s
66_games Iceland Spassky
G
ym
_c
om
pl
ex
Lo
os
in
g_
we
ig
ht
Po
ol
s
Tr
ad
e_
m
ea
ls
Figure 1: Example Folksonomy Ontology
Input: Set of tags T. Set of Committees C.
Output: An ontology of folksonomy tags.
L is a list containing pairs of tag/clusters with
associated similarity, initially empty.
foreach ti ? T do
Compute the similarity to all other tags tj
(i 6= j), and add a pair ?ti, tj? in L.
end
while L is not empty do
1. Sort L by the similarity of the pairs.
2. Pop the pair with the highest similarity
from L. Let it ?ti, ??. ? can be a single
tag or a cluster of tags.
3. Make ti the parent of ?.
4. Join ti with ?, and create a new cluster
?.
if ti belongs to more than one committee
in C then
1. Find the committee c which is the
most similar to ti.
2. Remove all features intersecting
with c from ti.
end
else
1. Substitute all instances of ti in the
pairs in L by ?.
end
end
Algorithm 2: Ontology Construction Algorithm
5 Experimental Evaluations
We applied our proposed algorithm to data from
a real-world social tagging system Delicious and
derived a tag ontology. Then we evaluated the de-
rived ontology on two aspects: the density of the
ontology, and the usefulness of the ontology in a
personalized Information Retrieval (IR) task. Note
that in the experiments, we determined the values
for all tuning coefficients in the algorithms during
the preliminary test runs.
5.1 Datasets
We first crawled the Delicious site and ob-
tained data consisting of 29,918 users, 6,403,442
resources and 1,035,177 tags. In this data,
47,184,492 annotations were made by just one
user, or for one resource, or by one tag. This dis-
tribution followed the Zipf?s law ? small numbers
of tags were in frequent use and large numbers of
tags were rarely used. Our intuitions were that the
effect of using the semantic/encyclopedia knowl-
edge from Wikipedia would probably be better re-
flected in the low frequency ?long tail? part of
the Zipf?s distribution rather than the high fre-
quency part. Likewise for users, we have dis-
covered in our previous research that search per-
sonalization algorithms often produce different re-
sults for users with rich profiles and for users who
have sparse profiles. This problem is known as the
?Cold Start? problem in search personalization: a
new user has very little information/history in the
profile, therefore the system cannot reliably infer
his/her interests. Since our experiments included
a personalized IR task, we decided to extract two
subsets from the data: one set containing high fre-
quency tags assigned by users with rich profiles
(randomly selected 1,000 most frequent tags en-
tered by 100 high profile users), and another con-
taining low frequency tags assigned by users with
sparse profiles (randomly selected 1,000 least fre-
quent tags entered by 100 sparse profile users). We
refer to the former set as the ?Frequent Set? and
the latter set as the ?Long Tail Set?. The total
number of resources in each dataset was 16,635
and 3,356 respectively.
Then for both datasets, we applied a part-
of speech tagger to all resources and extracted
all nouns (and discarded all other parts of
speech). We also applied the Porter Stemmer
(tartarus.org/?martin/PorterStemmer) to eliminate terms
with inflectional variations. Finally, we repre-
46
sented each resource page as a vector of stemmed
terms, and the values were term frequencies.
As for Wikipedia, we used its English
version available from BitTorrent Network
(www.bittorrent.com). The original data (the most
recent dump, as of 24 July, 2008) contained
13,916,311 pages. In order to reduce the size
to make the computation feasible, we randomly
chose 75,000 pages (which contained at least 50
words) and applied the Maximal Complete Link
clustering algorithm to further reduce the size.
After clustering, we obtained a total of 43,876
clusters, most of which contained one or twoWiki
articles, but some of which had several articles.
We call such a Wiki article cluster Wiki concept.
As with the tag datasets, for each Wiki article
we applied the Porter Stemmer to reduce the num-
ber of the terms. Then we represented each Wiki
concept page as a vector of stemmed terms, and
the values were term frequencies.
5.2 Evaluation 1: Ontological Density
For the first evaluation, we evaluated the derived
Delicious tag ontology directly by measuring the
topological closeness of similar semantic concepts
in the ontology. To that end, we developed a no-
tion of ontological density: all tags assigned to a
specific resource should be located close to each
other in the ontology. For instance, a web resource
java.sun.com in Delicious is assigned with various
tags such as ?Java?, ?Programming? and ?Technol-
ogy?. Those tags should be concentrated in one
place rather than scattered over various sections in
the ontology. By measuring the distance as the
number of edges in the ontology between tags as-
signed to a specific resource, we can obtain an es-
timate of the ontology density for the resource.
Then finding the average density of all resources
can give us an approximation of the overall den-
sity of the ontology?s quality.
But here a difficulty arises for ambiguous tags
? when a tag is ambiguous and located in several
places in the ontology. In those cases, we chose
the sense (an ontology node) which is the clos-
est to the unambiguous tags assigned to the same
resource. For example, Figure 2 shows a part of
the ontology where an ambiguous tag ?NLP? (with
two senses) is mapped: 1) Natural Language Pro-
cessing (the left one in the figure), and 2) Neuro-
linguistic programming (the right one in the fig-
ure). The target web resource is tagged with three
tags: two unambiguous tags ?POS? and ?Porter?,
and an ambiguous tag ?NLP?. To identify the sense
of ?NLP? for this resource, we count the number
of edges from the two unambiguous tags (?POS?,
?Porter?) to both ?NLP? tag nodes, and select the
one which has the shortest distance. In the figure,
the first sense has the total distance of 4 (= 2 edges
from ?Pos? + 2 edges from ?Porter?), while the sec-
ond sense has the distance 10 (= 5 edges from
?Pos? + 5 edges from ?Porter?). Therefore, we
select the first sense (?Natural Language Process-
ing?) as the meaning of ?NLP? for this resource.
Communic
Research
Psychology
Mind
Linguistics
Language
Dictionary
NLPTwitter
NLP POS Porter
POS Porter NLPWeb-resource
Web2.0 Media
Figure 2: Example of Ambiguous Tags in the On-
tology
Formally we define the density of the ontology
T for the set of resourcesR, denotedDens(T, R),
as the average density over all resources in R, as
follows.
Dens(T, R) = 1|R|
?
r?R
density(r, T )
where density(r, T ) denotes the density for the
given resource r for the ontology T , defined as:
density(r, T ) = nTags(r) ? 1argmini,j dist(node(i, T ), node(j,T ))
and nTags(r) is the number of tags assigned to
r, node(k, T ) is the node in T for the kth tag (as-
signed to r), and dist(n1, n2) is the number of
edges between nodes n1 and n2 in T . So the
density for the given resource is essentially the
inverse of the minimum distance among the tags
assigned to it. We computed the density value
for the ontology derived by our approach (?On-
tology Enhanced with Wiki Concepts?) and com-
pared with the ontologies obtained by using only
the resources (where a tag vector is presented by
47
the stemmed terms in the resources to which the
tag is assigned), and only the tags (where a tag
vector is presented by the resource to which they
were assigned). Figures 3 and 4 show the results,
for the two datasets. For both datasets, the dif-
ferences between the three ontologies were statis-
tically significant (at p=0.05), indicating that the
encyclopedia knowledge obtained from Wikipedia
was indeed effective in deriving a semantically
dense ontology.
Here, one observation is that the relative im-
provement was more significant for the ?Frequent
Set? than the ?Long Tail Set?. The reason is be-
cause frequent tags are generally more ambigu-
ous than less frequent tags (as with words in gen-
eral), therefore the effect of tag disambiguation by
DSCBC was more salient, relatively, for the fre-
quent tags.
0,035
0,037
0,039
0,041
0,043
0,045
De
ns
ity
Ontology Enhanced
withWiki Concepts
Ontology Enhanced
by Resources
Ontology Based
on Tags
Figure 3: Ontological Density for ?Frequent Set?
Ontology Enhanced
with Wiki Concepts
Ontology Enhanced
by Resources
Ontology Based
on Tags
0,1
0,05
0,15
0,2
0,25
0,3
De
ns
ity
Figure 4: Ontological Density for ?Long Tail Set?
5.3 Evaluation 2: Personalized Information
Retrieval
For the second evaluation, we used the derived De-
licious ontology in an IR task and measured its
utility. In particular, we personalized the search
results for a given user by utilizing the tag ontol-
ogy as a way to present the user profile and infer
his/her information needs.
Using the derived ontology, we search in the on-
tology for the query tag entered by a specific user.
We first match the ontology with the user?s profile
and derive a score distribution for the nodes in the
tree which reflects the user?s general interest. To
do so, we take each tag in the user?s profile as the
initial activation point, then spread the activation
up and down the ontology tree, for all tags.
To spread activation from a given node, we
use two parameters: decay factor, which deter-
mines the amount of the interest to be transfered
to the parent/child of the current node; and damp-
ing threshold - if the interest score becomes less
than this value we stop further iteration. Thus the
resulting score distributionof the tree is effectively
personalized to the user?s general interest.
Using the obtained score distribution of a given
user, we search the tree for a query tag (of this
user). In the same way as the tags in the profile, we
spread activation over the ontology from the node
to which the tag belongs, but this time we add a
weight to emphasize the relative importance of the
query tag compared to the tags from the profile,
because the query reflects the user?s current infor-
mation needs. Finally we feed the preference vec-
tor to the modified FolkRank algorithm (Hotho et
al., 2006) to retrieve and rank the relevant web re-
sources which reflect the user-specific preferences.
Figure 5 shows the overall scheme of the person-
alized ranked retrieval using an ontological user
profile.
Sport
Chess Fitness Soccer
Fi
sh
er
_g
en
Ru
ss
io
n_
bo
ok
s
66_games Iceland Spassky
G
ym
_c
om
pl
ex
Lo
os
in
g_
we
ig
ht
Po
ol
s
Tr
ad
e_
m
ea
ls
Sport
Chess Fitness Soccer
Fi
sh
er
_g
en
Ru
ss
io
n_
bo
ok
s
66_games Iceland Spassky
G
ym
_c
om
pl
ex
Lo
os
in
g_
we
ig
ht
Po
ol
s
Tr
ad
e_
m
ea
ls
TnSpasskiy Loosing_weight
Users
Tags
Preference vector
Ranked Resourses
Resourses
...
User Profiles
Spreading
Activation
Figure 5: Ranked Retrieval in Folksonomies using
Ontological User Profile
We evaluated the retrieval results by 5-fold
cross validation. Given a test user profile, we used
48
the leave-one-out method for tags ? we removed a
target tag from the user profile and treated it as a
query. All resources which the user assigned with
that tag was the relevant set. For the final results,
we computed the F-score, which is defined as stan-
dard:
F = 2 ? Precision ? RecallPrecision + Recall
Figure 6 and 7 show the F-scores for the two
datasets. Note that ?TopN? indicates the top N
retrieved resources. As you can see, the ontol-
ogy enhanced with the Wiki concepts was able to
better reflect the users? interest and produced sig-
nificant improvements compared to the ontologies
built only with the Delicious resources. Moreover,
the improvements were much more significant for
the ?Long Tail Set? than the ?Frequent Set?, as
consistent with our intuitions ? Wikipedia?s en-
cyclopedia knowledge helped enhance the infor-
mation about the less-frequent tags (assigned by
the users with sparse profiles), thereby overcom-
ing the ?Cold Start? problem in search personal-
ization.
0
0 10 15
0,05
0,03
0,08
0,1
0,13
0,15
TopN
F-
va
lu
e
20 25 30 35 40 45 50 60 65 70 75 80 85 90 95 10055
OntologyEnhanced
by Resources
Ontology Based
on Tags
Ontology Enhanced
with Wiki Concepts
Figure 6: F-score of the Ontology for ?Frequent
Set?
TopN
Ontology Enhanced
by Resources
Ontology Based
on Tags
Ontology Enhanced
with Wiki Concepts
0
0 10 15
0,1
0,05
0,15
0,2
0,25
0,3
0,35
0,4
0,45
0,5
20 25 30 35 40 45 50 60 65 70 75 80 85 90 95 10055
F-
va
lu
e
Figure 7: F-score of the Ontology for ?Long Tail
Set?
6 Conclusions and Future Work
In this paper, we presented a novel method for dis-
ambiguating tags and incorporating encyclopedia
knowledge from Wikipedia in building folkson-
omy ontologies for social tagging systems. We
applied our method to the data from Delicious and
showed that, not only was the derived ontology se-
mantically more dense (i.e., similar tags/concepts
are clustered in close proximity), it also proved to
be very effective in a search personalization task
as well.
For future work, we are planning on investigat-
ing different ways of incorporating the link struc-
tures of Wikipedia and web pages in the tag sim-
ilarity function (in DSCBC). Possible ideas in-
clude adding different weights on various types of
links (or links appearing in various sections of a
page/article), and using distance in the reachabil-
ity relation, for example using the work done in
Wikipedia Mining (Nakayama et al, 2008).
Finally, we are planning on applying informa-
tion extraction or summarization techniques on
Wikipedia articles to focus on sentences which
provide relevant and important information about
the subject.
References
D. Ahn, V. Jijkoun, G. Mishene, K. Muller, M. DeR-
ijke, and S. Schlobach. 2004. Using Wikipedia at
the TREC QA Track. In Proceedings of the 13th
Text Retrieval Conference (TREC 2004).
P. Clough, H. Joho, and M. Sanderson. 2005. Auto-
matically Organizing Images Using Concept Hier-
archies. In Proceedings of the SIGIR Workshop on
Multimedia Information Retrieval.
A. Culotta, A. Mccallum, and J.Betz. 2006. Integrat-
ing Probabilistic Extraction Models and Data Min-
ing to Discover Relations and Patterns in Text. In
Proceedings of the Human Language Technology
Conference.
E. Gabrilovich and S. Markovitch. 2006. Over-
coming the Brittleness Bottleneck UsingWikipedia:
Enhancing Text Categorization with Encyclopedic
Knowledge. In Proceedings of the National Con-
ference on Artificial Intelligence.
I. Gurevych, C. Muler, and T. Zesch. 2007. What to
be? - Electronic Career Guidance Based on Seman-
tic Relatedness. In Proceedings of the 45th Annual
Meeting of the Association for Computational Lin-
guistics.
P. Heymann and H. Garcia-Molina. 2006. Collab-
orative Creation of Communal Hierarchical Tax-
onomies in Social Tagging Systems. Technical Re-
port 2006-10, Computer Science Department, April.
49
A. Hotho, R. Jaschke, C. Schmitz, and G. Stumme.
2006. Folkrank: A Ranking Algorithm for Folk-
sonomies. In Proceedings of the FGIR.
R. Mihalcea and A. Csomai. 2007. Wikify!: Linking
Documents to Encyclopedic Knowledge. In Pro-
ceedings of the sixteenth ACM conference on Con-
ference on information and knowledge management.
P. Mika. 2007. Ontologies Are Us: A Unified Model
of Social Networks and Semantics. Web Semantics:
Science, Services and Agents on the World Wide
Web, 5(1).
G. Miller. 1990. WordNet: An Online Lexical
Database. International Journal of Lexicography,
3(4).
D. Milne, O. Medelyan, and I. Witten. 2006. Mining
Domain-Specific Thesauri from Wikipedia: A Case
Study. In Proceedings of the 2006 IEEE/WIC/ACM
International Conference on Web Intelligence.
K. Nakayama, T. Hara, and S. Nishio. 2008.
Wikipedia Mining - Wikipedia as a Corpus for
Knowledge Extraction. In Proceedings of Annual
Wikipedia Conference (Wikimania).
M. OConnor and J. Herlocker. 2001. Clustering
Items for Collaborative Filtering. In Proceedings of
SIGIR-2001 Workshop on Recommender Systems.
P. Pantel and D. Lin. 2002. Discovering Word Senses
from Text. In Proceedings of the 8th ACM Con-
ference on Knowledge Discovery and Data Mining
(KDD-02).
P. Schmitz. 2006. Inducing Ontology From Flickr
Tags. In Proceedings of the CollaborativeWeb Tag-
ging Workshop (WWW 06).
A. Shepitsen, J. Gemmell, B. Mobasher, and R. Burke.
2008. Personalized Recommendation in Social Tag-
ging Systems UsingHierarchical Clustering. InPro-
ceedings of the 2008 ACM conference on Recom-
mender Systems.
N. Tomuro, S. Lytinen, K. Kanzaki, and H. Isahara.
2007. Clustering Using Feature Domain Similarity
to Discover Word Senses for Adjectives. In Pro-
ceedings of the 1st IEEE International Conference
on Semantic Computing (ICSC-2007).
50
