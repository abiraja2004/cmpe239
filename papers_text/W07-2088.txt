Proceedings of the 4th International Workshop on Semantic Evaluations (SemEval-2007), pages 398?401,
Prague, June 2007. c?2007 Association for Computational Linguistics
UNIBA: JIGSAW algorithm for Word Sense Disambiguation
P. Basile and M. de Gemmis and A.L. Gentile and P. Lops and G. Semeraro
Department of Computer Science - University of Bari - Via E. Orabona, 4 70125 Bari ITALY
{basilepp, degemmis, al.gentile, lops, semeraro}@di.uniba.it
Abstract
Word Sense Disambiguation (WSD) is tra-
ditionally considered an AI-hard problem.
A breakthrough in this field would have a
significant impact on many relevant web-
based applications, such as information re-
trieval and information extraction. This pa-
per describes JIGSAW, a knowledge-based
WSD system that attemps to disambiguate
all words in a text by exploiting WordNet1
senses. The main assumption is that a spe-
cific strategy for each Part-Of-Speech (POS)
is better than a single strategy. We evalu-
ated the accuracy of JIGSAW on SemEval-
2007 task 1 competition2. This task is an
application-driven one, where the applica-
tion is a fixed cross-lingual information re-
trieval system. Participants disambiguate
text by assigning WordNet synsets, then the
system has to do the expansion to other lan-
guages, index the expanded documents and
run the retrieval for all the languages in
batch. The retrieval results are taken as a
measure for the effectiveness of the disam-
biguation.
1 The JIGSAW algorithm
The goal of a WSD algorithm consists in assigning
a word w
i
occurring in a document d with its appro-
priate meaning or sense s, by exploiting the context
C in where w
i
is found. The context C for w
i
is de-
fined as a set of words that precede and follow w
i
.
The sense s is selected from a predefined set of pos-
sibilities, usually known as sense inventory. In the
proposed algorithm, the sense inventory is obtained
from WordNet 1.6, according to SemEval-2007 task
1 instructions. JIGSAW is a WSD algorithm based
on the idea of combining three different strategies to
disambiguate nouns, verbs, adjectives and adverbs.
The main motivation behind our approach is that
1http://wordnet.princeton.edu/
2http://www.senseval.org/
the effectiveness of a WSD algorithm is strongly
influenced by the POS tag of the target word. An
adaptation of Lesk dictionary-based WSD algorithm
has been used to disambiguate adjectives and ad-
verbs (Banerjee and Pedersen, 2002), an adaptation
of the Resnik algorithm has been used to disam-
biguate nouns (Resnik, 1995), while the algorithm
we developed for disambiguating verbs exploits the
nouns in the context of the verb as well as the nouns
both in the glosses and in the phrases that WordNet
utilizes to describe the usage of a verb. JIGSAW
takes as input a document d = {w
1
, w
2
, . . . , w
h
} and
returns a list of WordNet synsets X = {s
1
, s
2
, . . . ,
s
k
} in which each element s
i
is obtained by disam-
biguating the target word w
i
based on the informa-
tion obtained from WordNet about a few immedi-
ately surrounding words. We define the context C of
the target word to be a window of n words to the left
and another n words to the right, for a total of 2n
surrounding words. The algorithm is based on three
different procedures for nouns, verbs, adverbs and
adjectives, called JIGSAW
nouns
, JIGSAW
verbs
,
JIGSAW
others
, respectively. More details for each
one of the above mentioned procedures follow.
1.1 JIGSAW
nouns
The procedure is obtained by making some varia-
tions to the algorithm designed by Resnik (1995) for
disambiguating noun groups. Given a set of nouns
W = {w
1
, w
2
, . . . , w
n
}, obtained from document
d, with each w
i
having an associated sense inven-
tory S
i
= {s
i1
, s
i2
, . . . , s
ik
} of possible senses, the
goal is assigning each w
i
with the most appropri-
ate sense s
ih
? S
i
, according to the similarity of
w
i
with the other words in W (the context for w
i
).
The idea is to define a function ?(w
i
, s
ij
), w
i
? W ,
s
ij
? S
i
, that computes a value in [0, 1] representing
the confidence with which word w
i
can be assigned
with sense s
ij
. The intuition behind this algorithm
is essentially the same exploited by Lesk (1986) and
other authors: The most plausible assignment of
senses to multiple co-occurring words is the one that
maximizes relatedness of meanings among the cho-
398
sen senses. JIGSAW
nouns
differs from the original
algorithm by Resnik (1995) in the similarity mea-
sure used to compute relatedness of two senses. We
adopted the Leacock-Chodorow measure (Leacock
and Chodorow, 1998), which is based on the length
of the path between concepts in an IS-A hierarchy.
The idea behind this measure is that similarity be-
tween two synsets, s
1
and s
2
, is inversely propor-
tional to their distance in the WordNet IS-A hierar-
chy. The distance is computed by finding the most
specific subsumer (MSS) between s
1
and s
2
(each
ancestor of both s
1
and s
2
in the WordNet hierar-
chy is a subsumer, the MSS is the one at the lowest
level) and counting the number of nodes in the path
between s
1
and s
2
that traverse their MSS. We ex-
tended this measure by introducing a parameter k
that limits the search for the MSS to k ancestors (i.e.
that climbs the WordNet IS-A hierarchy until either
it finds the MSS or k + 1 ancestors of both s
1
and
s
2
have been explored). This guarantees that ?too
abstract? (i.e. ?less informative?) MSSs will be ig-
nored. In addition to the semantic similarity func-
tion, JIGSAW
nouns
differs from the Resnik algo-
rithm in the use of:
1. a Gaussian factor G, which takes into account the dis-
tance between the words in the text to be disambiguated;
2. a factor R, which gives more importance to the synsets
that are more common than others, according to the fre-
quency score in WordNet;
3. a parametrized search for the MSS between two concepts
(the search is limited to a certain number of ancestors).
Algorithm 1 describes the complete procedure for
the disambiguation of nouns. This algorithm consid-
ers the words in W pairwise. For each pair (w
i
,w
j
),
the most specific subsumer MSS
ij
is identified, by
reducing the search to depth1 ancestors at most.
Then, the similarity sim(w
i
, w
j
, depth2) between
the two words is computed, by reducing the search
for the MSS to depth2 ancestors at most. MSS
ij
is
considered as supporting evidence for those synsets
s
ik
in S
i
and s
jh
in S
j
that are descendants of
MSS
ij
. The MSS search is computed choosing the
nearest MSS in all pairs of synsets s
ik
,s
jh
. Like-
wise, the similarity for (w
i
,w
j
) is the max similarity
computed in all pairs of s
ik
,s
jh
and is weighted by
a gaussian factor that takes into account the posi-
tion of w
i
and w
j
in W (the shorter is the distance
Algorithm 1 The procedure for disambiguating
nouns derived from the algorithm by Resnik
1: procedure JIGSAW
nouns
(W, depth1, depth2) 
finds the proper synset for each polysemous noun in the set
W = {w
1
, w
2
, . . . , w
n
}, depth1 and depth2 are used in
the computation of MSS
2: for all w
i
, w
j
? W do
3: if i < j then
4: sim ? sim(w
i
, w
j
, depth1) ?
G(pos(w
i
), pos(w
j
))  G(x, y) is a Gaussian
function which takes into account the difference between
the positions of w
i
and w
j
5: MSS
ij
? MSS(w
i
, w
j
, depth2) 
MSS
ij
is the most specific subsumer between w
i
and w
j
,
search for MSS restricted to depth2 ancestors
6: for all s
ik
? S
i
do
7: if is-ancestor(MSS
ij
,s
ik
) then  if
MSS
ij
is an ancestor of s
ik
8: sup
ik
? sup
ik
+ sim
9: end if
10: end for
11: for all s
jh
? S
j
do
12: if is-ancestor(MSS
ij
,s
jh
) then
13: sup
jh
? sup
jh
+ sim
14: end if
15: end for
16: norm
i
? norm
i
+ sim
17: norm
j
? norm
j
+ sim
18: end if
19: end for
20: for all w
i
? W do
21: for all s
ik
? S
i
do
22: if norm
i
> 0 then
23: ?(i, k) ? ? ? sup
ik
/norm
i
+ ? ? R(k)
24: else
25: ?(i, k) ? ?/|S
i
| + ? ? R(k)
26: end if
27: end for
28: end for
29: end procedure
between the words, the higher is the weight). The
value ?(i, k) assigned to each candidate synset s
ik
for the word w
i
is the sum of two elements. The
first one is the proportion of support it received, out
of the support possible, computed as sup
ik
/norm
i
in Algorithm 1. The other element that contributes
to ?(i, k) is a factor R(k) that takes into account
the rank of s
ik
in WordNet, i.e. how common is the
sense s
ik
for the word w
i
. R(k) is computed as:
R(k) = 1 ? 0.8 ?
k
n ? 1
(1)
where n is the cardinality of the sense inventory S
i
for w
i
, and k is the rank of s
ik
in S
i
, starting from 0.
Finally, both elements are weighted by two pa-
rameters: ?, which controls the contribution given
399
to ?(i, k) by the normalized support, and ?, which
controls the contribution given by the rank of s
ik
.
We set ? = 0.7 and ? = 0.3. The synset assigned
to each word in W is the one with the highest ?
value. Notice that we used two different parameters,
depth1 and depth2 for setting the maximum depth
for the search of the MSS: depth1 limits the search
for the MSS computed in the similarity function,
while depth2 limits the computation of the MSS
used for assigning support to candidate synsets. We
set depth1 = 6 and depth2 = 3.
1.2 JIGSAW
verbs
Before describing the JIGSAW
verbs
procedure, the
description of a synset must be defined. It is the
string obtained by concatenating the gloss and the
sentences that WordNet uses to explain the usage
of a synset. First, JIGSAW
verbs
includes, in the
context C for the target verb w
i
, all the nouns in
the window of 2n words surrounding w
i
. For each
candidate synset s
ik
of w
i
, the algorithm computes
nouns(i, k), that is the set of nouns in the descrip-
tion for s
ik
.
max
jk
= max
w
l
?nouns(i,k)
{sim(w
j
,w
l
,depth)} (2)
where sim(w
j
,w
l
,depth) is defined as in
JIGSAWnouns. In other words, max
jk
is the
highest similarity value for w
j
wrt the nouns related
to the k-th sense for w
i
. Finally, an overall simi-
larity score among s
ik
and the whole context C is
computed:
?(i, k) = R(k) ?
P
w
j
?C
G(pos(w
i
), pos(w
j
)) ? max
jk
P
h
G(pos(w
i
), pos(w
h
))
(3)
where R(k) is defined as in Equation 1 with a differ-
ent constant factor (0.9) and G(pos(w
i
), pos(w
j
)) is
the same Gaussian factor used in JIGSAWnouns,
that gives a higher weight to words closer to the tar-
get word. The synset assigned to w
i
is the one with
the highest ? value. Algorithm 2 provides a detailed
description of the procedure.
1.3 JIGSAW
others
This procedure is based on the WSD algorithm pro-
posed by Banerjee and Pedersen (2002). The idea is
to compare the glosses of each candidate sense for
Algorithm 2 The procedure for the disambiguation
of verbs
1: procedure JIGSAW
verbs
(w
i
, d, depth)  finds the
proper synset of a polysemous verb w
i
in document d
2: C ? {w
1
, ..., w
n
}  C is
the context for w
i
. For example, C = {w
1
, w
2
, w
4
, w
5
},
if the sequence of words {w
1
, w
2
, w
3
, w
4
, w
5
} occurs in d,
w
3
being the target verb, w
j
being nouns, j 6= 3
3: S
i
? {s
i1
, ...s
im
}  S
i
is the sense inventory for w
i
, that is the set of all candidate
synsets for w
i
returned by WordNet
4: s ? null  s is the synset to be returned
5: score ? ?MAXDOUBLE  score is the
similarity score assigned to s
6: p ? 1  p is the position of the synsets for w
i
7: for all s
ik
? S
i
do
8: max ? {max
1k
, ..., max
nk
}
9: nouns(i, k) ? {noun
1
, ..., noun
z
} 
nouns(i, k) is the set of all nouns in the description of s
ik
10: sumGauss ? 0
11: sumTot ? 0
12: for all w
j
? C do  computation of the similarity
between C and s
ik
13: max
jk
? 0  max
jk
is the highest similarity
value for w
j
, wrt the nouns related to the k-th sense for w
i
.
14: sumGauss ? G(pos(w
i
), pos(w
j
)) 
Gaussian function which takes into account the difference
between the positions of the nouns in d
15: for all noun
l
? nouns(i, k) do
16: sim ? sim(w
j
, noun
l
, depth)  sim is
the similarity between the j-th noun in C and l-th noun in
nouns(i, k)
17: if sim > max
jk
then
18: max
jk
? sim
19: end if
20: end for
21: end for
22: for all w
j
? C do
23: sumTot ? sumTot+G(pos(w
i
), pos(w
j
))?
max
jk
24: end for
25: sumTot ? sumTot/sumGauss
26: ?(i, k) ? R(k) ? sumTot  R(k) is defined as in
JIGSAW
nouns
27: if ?(i, k) > score then
28: score ? ?(i, k)
29: p ? k
30: end if
31: end for
32: s ? s
ip
33: return s
34: end procedure
the target word to the glosses of all the words in its
context. Let W
i
be the sense inventory for the tar-
get word w
i
. For each s
ik
? W
i
, JIGSAW
others
computes the string targetGloss
ik
that contains the
words in the gloss of s
ik
. Then, the procedure
computes the string contextGloss
i
, which contains
the words in the glosses of all the synsets corre-
400
sponding to each word in the context for w
i
. Fi-
nally, the procedure computes the overlap between
contextGloss
i
and targetGloss
ik
, and assigns the
synset with the highest overlap score to w
i
. This
score is computed by counting the words that occur
both in targetGloss
ik
and in contextGloss
i
. If ties
occur, the most common synset in WordNet is cho-
sen.
2 Experiment
We performed the experiment following the instruc-
tions for SemEval-2007 task 1 (Agirre et al, 2007).
JIGSAW is implemented in JAVA, by using JWNL
library3 in order to access WordNet 1.6 dictionary.
We ran the experiment on a Linux-based PC with
Intel Pentium D processor having a speed of 3 GHz
and 2 GB of RAM. The dataset consists of 29,681
documents, including 300 topics. Results are re-
ported in Table 1. Only two systems (PART-A and
PART-B) partecipated to the competition, thus the
organizers decided to add a third system (ORGA-
NIZERS) developed by themselves. The systems
were scored according to standard IR/CLIR mea-
sures as implemented in the TREC evaluation pack-
age4. Our system is labelled as PART-A.
system IR documents IR topics CLIR
no expansion 0.3599 0.1446
full expansion 0.1610 0.1410 0.2676
1st sense 0.2862 0.1172 0.2637
ORGANIZERS 0.2886 0.1587 0.2664
PART-A 0.3030 0.1521 0.1373
PART-B 0.3036 0.1482 0.1734
Table 1: SemEval-2007 task 1 Results
All systems show similar results in IR tasks, while
their behaviour is extremely different on CLIR task.
WSD results are reported in Table 2. These re-
sults are encouraging as regard precision, consid-
ering that our system exploits only WordNet as
kwnoledge-base, while ORGANIZERS uses a su-
pervised method that exploits SemCor to train a
kNN classifier.
3 Conclusions
In this paper we have presented a WSD algorithm
that exploits WordNet as knowledge-base and uses
3http://sourceforge.net/projects/jwordnet
4http://trec.nist.gov/
system precision recall attempted
SENSEVAL-2
ORGANIZERS 0.584 0.577 93.61%
PART-A 0.498 0.375 75.39%
PART-B 0.388 0.240 61.92%
SENSEVAL-3
ORGANIZERS 0.591 0.566 95.76%
PART-A 0.484 0.338 69.98%
PART-B 0.334 0.186 55.68%
Table 2: WSD results on all-words task
three different methods for each part-of-speech. The
algorithm has been evaluated by SemEval-2007 task
1. The system shows a good performance in all
tasks, but low precision in CLIR evaluation. Prob-
ably, the negative result in CLIR task depends on
complex interaction of WSD, expansion and index-
ing. Contrarily to other tasks, organizers do not plan
to provide a ranking of systems on SemEval-2007
task 1. As a consequence, the goal of this task - what
is the best WSD system in the context of a CLIR
system? - is still open. This is why the organizers
stressed in the call that this was ?a first try?.
References
E. Agirre, B. Magnini, o. Lopez de Lacalle, A. Otegi,
G. Rigau, and Vossen. 2007. Semeval-2007 task
1: Evaluating wsd on cross-language information re-
trieval. In Proceedings of SemEval-2007. Association
for Computational Linguistics.
S. Banerjee and T. Pedersen. 2002. An adapted lesk
algorithm for word sense disambiguation using word-
net. In CICLing?02: Proc. 3rd Int?l Conf. on Com-
putational Linguistics and Intelligent Text Processing,
pages 136?145, London, UK. Springer-Verlag.
C. Leacock and M. Chodorow. 1998. Combining local
context and wordnet similarity for word sense identifi-
cation. In C. Fellbaum (Ed.), WordNet: An Electronic
Lexical Database, pages 305?332. MIT Press.
M. Lesk. 1986. Automatic sense disambiguation using
machine readable dictionaries: how to tell a pine cone
from an ice cream cone. In Proceedings of the 1986
SIGDOC Conference, pages 20?29. ACM Press.
P. Resnik. 1995. Disambiguating noun groupings with
respect to WordNet senses. In Proceedings of the
Third Workshop on Very Large Corpora, pages 54?68.
Association for Computational Linguistics.
401
