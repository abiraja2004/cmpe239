Proceedings of the 10th Conference on Parsing Technologies, pages 39?47,
Prague, Czech Republic, June 2007. c?2007 Association for Computational Linguistics
Improving the Efficiency of a Wide-Coverage CCG Parser
Bojan Djordjevic and James R. Curran
School of Information Technologies
University of Sydney
NSW 2006, Australia
{bojan,james}@it.usyd.edu.au
Stephen Clark
Computing Laboratory
Oxford University
Wolfson Building, Parks Road
Oxford, OX1 3QD, UK
stephen.clark@comlab.ox.ac.uk
Abstract
The C&C CCG parser is a highly efficient
linguistically motivated parser. The effi-
ciency is achieved using a tightly-integrated
supertagger, which assigns CCG lexical cat-
egories to words in a sentence. The integra-
tion allows the parser to request more cat-
egories if it cannot find a spanning anal-
ysis. We present several enhancements to
the CKY chart parsing algorithm used by the
parser. The first proposal is chart repair,
which allows the chart to be efficiently up-
dated by adding lexical categories individu-
ally, and we evaluate several strategies for
adding these categories. The second pro-
posal is to add constraints to the chart which
require certain spans to be constituents. Fi-
nally, we propose partial beam search to fur-
ther reduce the search space. Overall, the
parsing speed is improved by over 35% with
negligible loss of accuracy or coverage.
1 Introduction
A recent theme in parsing research has been the
application of statistical methods to linguistically
motivated grammars, for example LFG (Kaplan et
al., 2004; Cahill et al, 2004), HPSG (Toutanova
et al, 2002; Malouf and van Noord, 2004), TAG
(Sarkar and Joshi, 2003) and CCG (Hockenmaier
and Steedman, 2002; Clark and Curran, 2004b). The
attraction of linguistically motivated parsers is the
potential to produce rich output, in particular the
predicate-argument structure representing the under-
lying meaning of a sentence. The disadvantage of
such parsers is that they are typically not very effi-
cient, parsing a few sentences per second on com-
modity hardware (Kaplan et al, 2004). The C&C
CCG parser (Clark and Curran, 2004b) is an order
of magnitude faster, but is still limited to around 25
sentences per second.
The key to efficient CCG parsing is a finite-state
supertagger which performs much of the parsing
work (Bangalore and Joshi, 1999). CCG is a lex-
icalised grammar formalism, in which elementary
syntactic structures ? in CCG?s case lexical cate-
gories expressing subcategorisation information ?
are assigned to the words in a sentence. CCG su-
pertagging can be performed accurately and effi-
ciently by a Maximum Entropy tagger (Clark and
Curran, 2004a). Since the lexical categories contain
so much grammatical information, assigning them
with low average ambiguity leaves the parser, which
combines them together, with much less work to do
at parse time. Hence Bangalore and Joshi (1999), in
the context of LTAG parsing, refer to supertagging as
almost parsing.
Clark and Curran (2004a) presents a novel
method of integrating the supertagger and parser:
initially only a small number of categories, on av-
erage, is assigned to each word, and the parser at-
tempts to find a spanning analysis using the CKY
chart-parsing algorithm. If one cannot be found, the
parser requests more categories from the supertagger
and builds the chart again from scratch. This process
repeats until the parser is able to build a chart con-
taining a spanning analysis.1
1Tsuruoka and Tsujii (2004) investigate a similar idea in the
context of the CKY algorithm for a PCFG.
39
The supertagging accuracy is high enough that
the parser fails to find a spanning analysis using the
initial category assignment in approximately 4% of
Wall Street Journal sentences (?). However, parsing
this 4%, which largely consists of the longer sen-
tences, is disproportionately expensive.
This paper describes several modifications to the
C&C parser which improve parsing efficiency with-
out reducing accuracy or coverage by reducing the
impact of the longer sentences. The first involves
chart repair, where the CKY chart is repaired when
extra lexical categories are added (according to the
scheme described above), instead of being rebuilt
from scratch. This allows an even tighter integra-
tion of the supertagger, in that the parser is able to
request individual categories. We explore methods
for choosing which individual categories to add, re-
sulting in an 11% speed improvement.
The next modification involves parsing with con-
straints, so that certain spans are required to be con-
stituents. This reduces the search space consider-
ably by eliminating a large number of constituents
which cross the boundaries of these spans. The best
set of constraints results in a 10% speed improve-
ment over the original parser. These constraints are
general enough that they could be applied to any
constituency-based parser. Finally, we experiment
with several beam strategies to reduce the search
space, finding that a partial beam which operates on
part of the chart is most effective, giving a further
6.1% efficiency improvement.
The chart repair and constraints interact in an in-
teresting, and unexpected, manner when combined,
giving a 35.7% speed improvement overall without
any loss in accuracy or coverage. This speed im-
provement is particularly impressive because it in-
volves techniques which only apply to 4% of Wall
Street Journal sentences.
2 The CCG Parser
Clark and Curran (2004b) describes the CCG parser.
The grammar used by the parser is extracted from
CCGbank, a CCG version of the Penn Treebank
(Hockenmaier, 2003). The grammar consists of 425
lexical categories plus a small number of combi-
natory rules which combine the categories (Steed-
man, 2000). A Maximum Entropy supertagger first
assigns lexical categories to the words in a sen-
tence, which are then combined by the parser using
the combinatory rules. A log-linear model scores
the alternative parses. We use the normal-form
model, which assigns probabilities to single deriva-
tions based on the normal-form derivations in CCG-
bank. The features in the model are defined over
local parts of the derivation and include word-word
dependencies. A packed chart representation allows
efficient decoding, with the Viterbi algorithm find-
ing the most probable derivation.
The supertagger uses a log-linear model to de-
fine a distribution over the lexical category set for
each word and the previous two categories (Ratna-
parkhi, 1996) and the forward backward algorithm
efficiently sums over all histories to give a distribu-
tion for each word. These distributions are then used
to assign a set of lexical categories to each word (?).
The number of categories in each set is determined
by a parameter ?: all categories are assigned whose
forward-backward probabilities are within ? of the
highest probability category (?). If the parser can-
not then find a spanning analysis, the value of ? is
reduced ? so that more lexical categories are as-
signed ? and the parser tries again. This process re-
peats until an analysis spanning the whole sentence
is found.
In our previous work, when the parser was unable
to find a spanning analysis, the chart was destroyed
and then rebuilt from scratch with more lexical cate-
gories assigned to each word. However, this rebuild-
ing process is wasteful because the new chart is al-
ways a superset of the old one and could be created
by just updating the previous chart. We describe the
chart repair process in Section 3 which allows addi-
tional categories to be assigned to an existing chart
and the CKY algorithm run over just those parts of
the chart which require modification.
2.1 Chart Parsing
The parser uses the CKY chart parsing algorithm
(Kasami, 1965; Younger, 1967) described in Steed-
man (2000). The CKY algorithm applies naturally to
CCG since the grammar is binary. It builds the chart
bottom-up, starting with the lexical categories span-
ning single words, incrementally increasing the span
until the whole sentence is covered. Since the con-
stituents are built in order of span size, at every stage
40
all the sub-constituents which could be used to cre-
ate a particular new constituent are already present
in the chart.
The charts are packed by grouping together equiv-
alent chart entries, which allows a large number of
derivations to be represented efficiently. Entries are
equivalent when they interact in the same manner
with both the generation of subsequent parse struc-
ture and the statistical parse selection. In practice,
this means that equivalent entries have the same
span; form the same structures, i.e. the remain-
ing derivation plus dependencies, in any subsequent
parsing; and generate the same features in any sub-
sequent parsing.
The Viterbi algorithm is used to find the most
probable derivation from a packed chart. For each
equivalence class of individual entries, we record the
entry at the root of the subderivation which has the
highest score for the class. The equivalence classes
are defined so that any other individual entry can-
not be part of the highest scoring derivation for the
sentence. The highest-scoring subderivations can
be calculated recursively using the highest-scoring
equivalence classes that were combined to create the
individual entry.
Given a sentence of n words, we define pos ?
{0, . . . , n ? 1} to be the starting position of an en-
try in the chart (represented by a CCG category) and
span ? {1, . . . , n} its length. Let cell(pos, span)
be the set of categories which span the sentence from
pos to pos + span. These will be combinations of
categories in cell(pos, k) and cell(pos+k, span?k)
for all k ? {1, . . . , span? 1}. The chart is a two di-
mensional array indexed by pos and span. The valid
(pos, span) pairs correspond to pos + span ? n,
that is, to spans that do not extend beyond the end
of the sentence. The squares represent valid cells in
Figure 1. The span from position 3 with length 4,
i.e. cell(3, 4), is marked with a diamond in Figure 2.
3 Chart Repair
The parser interacts with the supertagger by decreas-
ing the value of the ? parameter when a spanning
analysis cannot be found for a sentence. This has
the effect of adding more lexical categories to the
chart. Instead of rebuilding the chart from scratch
when new categories are added, it can be repaired
affected cells
cell with a new
category added10
5
0 1 2 3 4 5 6 7 8 9
1
span
pos
2
3
4
6
7
8
9
Figure 1: Cells affected by chart repair.
by modifying cells that are affected by the new cat-
egories. Considering the case where a single lexical
category is added to the ith word in an n word sen-
tence, the new category can only affect the cells that
satisfy pos ? i and pos+ span > i. These cells are
shown in Figure 1 for the word at position 3.
The number of affected cells is (n?pos)(pos+1),
and so the average over the sentence is approxi-
mately 1n
? n?1
0 (n ? p)(p + 1) dp ?
n2
6 cells. The
total number of cells in the chart is n(n+1)2 . The chart
can therefore be repaired bottom up, in CKY order,
by updating a third of the cells on average.
Additional lexical categories for a word are in-
serted into the corresponding cell in the bottom row,
with the additional categories being marked as new.
For each cell C in the second row, each pair of cells
A and B is considered whose spans combine to cre-
ate the span of C. In the original CKY, all categories
from A are combined with all categories from B. In
chart repair, categories are only combined if at least
one of them is new, because otherwise the result is
already in C. The categories added to C are marked,
and the process is repeated for all affected cells in
CKY order.
Chart repair speeds up parsing for two reasons.
First, it reuses previous computations and eliminates
wasteful rebuilding of the chart. Second, it allows
lexical categories to be added to the chart one at a
41
affected cells
invalid cells
required cell
6 7 8 9
1
span
pos
2
3
4
6
7
8
9
10
5
0 1 2 3 4 5
Figure 2: Cells affected by adding a constraint.
time until a spanning derivation is found. In the orig-
inal approach extra categories were added in bulk by
changing the ? level, which significantly increased
the average ambiguity. Chart repair allows the min-
imum amount of ambiguity to be added for a span-
ning derivation to be found.
The C&C parser has a predefined limit on the num-
ber of categories in the chart. If this is exceeded
before a spanning analysis is found then the parser
fails on the sentence. Our new strategy allows a
chart containing a spanning analysis to be built with
the minimum number of categories possible. This
means that some sentences can now be parsed that
would have previously exceeded the limit, slightly
increasing coverage.
3.1 Category selection
The order in which lexical categories are added to
the chart will impact on parsing speed and accu-
racy, and so we evaluate several alternatives. The
first ordering (? VALUE) is by decreasing ? value,
where the ? value is the ratio between the probabil-
ity of the most likely category and the probability of
the given category for that word.2 The second or-
dering (PROB) is by decreasing category probability
2We are overloading the use of ? for convenience. Here, ?
refers to the variable ratio dependent on the particular category,
whereas the ? value used in supertagging is a cutoff applied to
the variable ratio.
as assigned by the supertagger using the forward-
backward algorithm.
We also investigated ordering categories using in-
formation from the chart. Examining the sentences
which required chart repair showed that, when a
word is missing the correct category, the cells af-
fected (as defined in Section 3) by the cell are often
empty. The CHART ordering uses this observation to
select the next lexical category to assign. It selects
the word corresponding to the cell with the high-
est number of empty affected cells, and then adds
the highest probability category not in the chart for
that word. Finally, we included a RANDOM ordering
baseline for comparison purposes.
4 Constraints
The set of possible derivations can be constrained
if we know in advance that a particular span is re-
quired to be the yield of a single constituent in the
correct parse. A constraint on span p reduces the
search space because p must be the yield of a single
cell. This means that cells with yields that cross the
boundary of p cannot be part of a correct derivation,
and do not need to be considered (the grey cells in
Figure 2). In addition, if a cell yields p as a prefix or
suffix (the hashed cells in Figure 2) then it also has
constraints on how it can be created.
Figure 2 shows an example constraint requiring
words 3?6 to be a constituent, which corresponds to
p = cell(3, 4). Consider cell(3, 7): it yields words
3?9 and so contains p as the prefix. Normally it can
be created by combining cell(3, 1) with cell(4, 6),
or cell(3, 2)with cell(5, 5), and so on up to cell(3, 6)
with cell(9, 1). However the first three combinations
are not allowed because the second child crosses the
boundary of p. This gives a lower limit for the span
of the left child. Similarly, if p is the suffix of the
span of a cell then there is a lower limit on the span
of the right child.
As the example demonstrates, a single constraint
can eliminate many combinations, reducing the
search space significantly, and thus improving pars-
ing efficiency.
4.1 Creating Constraints
How can we know in advance that the correct deriva-
tion must yield specific spans, since this appears to
require knowledge of the parse itself? We have ex-
42
plored constraints derived from shallow parsing and
from the raw sentence. Our results demonstrate that
simple constraints can reduce parsing time signifi-
cantly without loss of coverage or accuracy.
Chunk tags were used to create constraints. We
experimented with both gold standard chunks from
the Penn Treebank and also chunker output from the
C&C chunk tagger. The tagger is very similar to the
Maximum Entropy POS tagger described in Curran
and Clark (2003). Only NP chunks were used be-
cause the accuracy of the tagger for other chunks is
lower. The Penn Treebank chunks required modi-
fication because CCGbank analyses some construc-
tions differently. We also created longer NPs by con-
catenating adjacent base NPs, for example in the case
of possessives.
A number of punctuation constraints were used
and had a significant impact especially for longer
sentences. There are a number of punctuation rules
in CCGbank which absorb a punctuation mark by
combining it with a category and returning a cate-
gory of the same type. These rules are very produc-
tive, combining with many constituent types. How-
ever, in CCGbank the sentence final punctuation is
always attached at the root. A constraint on the first
n ? 1 words was added to force the parser to only
attach the sentence final punctuation once the rest of
the sentence has been parsed.
Constraints are placed around parenthesised and
quoted phrases that usually form constituents be-
fore attaching elsewhere. Constraints are also placed
around phrases bound by colons, semicolons, or hy-
phens. These constraints are especially effective
for long sentences with many clauses separated by
semicolons, reducing the sentence to a number of
smaller units which significantly improves parsing
efficiency.
In some instances, adding constraints can be
harmful to parsing efficiency and/or accuracy. Lack
of precision in the constraints can come from noisy
output from NLP components, e.g. the chunker, or
from rules which are not always applicable, e.g.
punctuation constraints. We find that the punctua-
tion constraints are particularly effective while the
gold standard chunks are required to gain any ben-
efit for the NP constraints. Adding constraints also
has the potential to increase coverage because the re-
duced search space means that longer sentences can
be parsed without exceeding the pre-defined limits
on chart size.
5 Selective Beam Search
Beam search involves greedy elimination of low
probability partial derivations before they can form
complete derivations. It is used in many parsers to
reduce the search space, for example Collins (2003).
We use a variable width beam where all categories
c in a particular cell C that satisfy score(c) <
max{score(x)|x ? C} ? B, for some beam cut-
off B, are removed. The category scores score(c)
are log probabilities.
In the C&C parser, the entire packed chart is con-
structed first and then the spanning derivations are
marked. Only the partial derivations that form part
of spanning derivations are scored to select the best
parse, which is a small fraction of the categories in
the chart. Because the categories are scored with
a complex statistical model with a large number of
features, the time spent calculating scores is signif-
icant. We found that applying a beam to every cell
during the construction of the chart was more expen-
sive than not using the beam at all. When the beam
was made harsh enough to be worthwhile, it reduced
accuracy and coverage significantly.
We propose selective beam search where the
beam is only applied to spans of particular lengths.
The shorter spans are most important to cull because
there are many more of them and removing them has
the largest impact in terms of reducing the search
space. However, the supertagger already acts like
a beam at the lexical category level and the parser
model has fewer features at this level, so the beam
may be more accurate for longer spans. We there-
fore expect the beam to be most effective for spans
of intermediate length.
6 Experiments
The parser was trained on CCGbank sections 02-21
and section 00 was used for development. The per-
formance is measured in terms of coverage, F-score
and parsing time. The F-score is for labelled depen-
dencies compared against the predicate-argument
dependencies in CCGbank. The time reported in-
cludes loading the grammar and statistical model,
which takes around 5 seconds, and parsing the 1913
43
sentences in section 00.
The failure rate (opposite of coverage) is broken
down into sentences with length ? 40 and > 40
because longer sentences are more difficult to parse
and the C&C parser already has very high coverage
on shorter sentences. There are 1784 1-40 word sen-
tences and 129 41+ word sentences. The average
length and standard deviation in the 41+ set are 50.8
and 31.5 respectively.
All experiments used gold standard POS tags.
Original and REPAIR do not use constraints. The
NP(GOLD) experiments use Penn Treebank gold
standard NP chunks to determine an upper bound
on the utility of chunk constraints. The times re-
ported for NP(C&C) using the C&C chunker include
the time to load the chunker model and run the chun-
ker (around 1.3 seconds). PUNCT adds all of the
punctuation constraints.
Finally the best system was compared against the
original parser on section 23, which has 2257 sen-
tences of length 1-40 and 153 of length 41+. The
maximum length is only 65, which explains the high
coverage for the 41+ section.
6.1 Chart Repair Results
The results in Table 1 show that chart repair gives
an immediate 11.1% improvement in speed and a
small 0.21% improvement in accuracy. 96.1% of
sentences do not require chart repair because they
are successfully parsed using the initial set of lexi-
cal categories supplied by the supertagger. Hence,
11% is a significant improvement for less than 4%
of the sentences.
We believe the accuracy was improved (on top of
the efficiency) because of the way the repair process
adds new categories. Adding categories individually
allows the parser to be influenced by the probabil-
ities which the supertagger assigns, which are not
directly modelled in the parser. If we were to add
this information from the supertagger into the parser
statistical model directly we would expect almost
no accuracy difference between the original method
and chart repair.
Table 2 shows the impact of different category
ordering approaches for chart repair (with PUNCT
constraints). The most effective approach is to use
the information from the chart about the proportion
of empty cells, which adds half as many categories
METHOD secs % F-SCORE CATS
RANDOM 70.2 -16.2 86.57 23.1
? VALUE 60.4 ? 86.66 15.7
PROB 60.1 0.5 86.65 14.3
CHART 57.2 5.3 86.61 7.0
Table 2: Category ordering for chart repair.
on average as the ? value and probability based ap-
proaches. All of our approaches significantly out-
perform randomly selecting extra categories. The
CHART category ordering is used for the remaining
experiments.
6.2 Constraints Results
The results in Table 1 show that, without chart re-
pair, using gold standard noun phrases does not im-
prove efficiency, while using noun phrases identi-
fied by the C&C chunker decreases speed by 10.8%.
They both also slightly reduce parsing accuracy.
The number of times the parsing process had to be
restarted with the constraints removed, was more
costly than the reduction of the search space. This
is unsurprising because the chunk data was not ob-
tained from CCGbank and the chunker is not ac-
curate enough for the constraints to improve pars-
ing efficiency. The most frequent inconsistencies
between CCGbank and chunks extracted from the
Penn Treebank were fixed in a preprocessing step as
explained in Section 4.1, but the less frequent con-
structions are still problematic.
The best results for parsing with constraints (with-
out repair) were with both punctuation and gold
standard noun phrase constraints, with 20.5% im-
provement in speed and 0.42% in coverage, but an
F-score penalty of 0.3%. This demonstrates the pos-
sible efficiency gain with a perfect chunker ? the
corresponding results with the C&C chunker are still
worse than without constraints. The best results
without a decrease in accuracy use only punctuation
constraints, with 10.4% increase in speed and 0.37%
in coverage. The punctuation constraints also have
the advantage of being simple to implement.
The best overall efficiency gain was obtained
when punctuation and gold standard noun phrases
were used with chart repair, with a 45.4% improve-
ment in speed and 0.63% in coverage, and a 0.4%
drop in accuracy. The best results without a drop in
44
METHOD secs % F-SCORE COVER n ? 40 n > 40
Original 88.3 ? 86.54 98.85 0.392 11.63
REPAIR 78.5 11.1 86.75 99.01 0.336 10.08
NP(GOLD) 88.4 -0.1 86.27 99.06 0.224 10.85
NP(C&C) 97.8 -10.8 86.31 99.16 0.224 9.30
PUNCT 79.1 10.4 86.56 99.22 0.168 9.30
NP(GOLD) + PUNCT 69.8 20.5 86.24 99.27 0.168 8.53
NP(C&C) + PUNCT 97.0 -9.9 86.31 99.16 0.168 10.08
NP(GOLD) + REPAIR 65.0 26.4 86.04 99.37 0.224 6.20
NP(C&C) + REPAIR 77.5 12.2 86.35 99.37 0.224 6.20
PUNCT + REPAIR 57.2 35.2 86.61 99.48 0.168 5.43
NP(GOLD) + PUNCT + REPAIR 48.2 45.4 86.14 99.48 0.168 5.43
NP(C&C) + PUNCT + REPAIR 63.2 28.4 86.43 99.53 0.163 3.88
Table 1: Parsing performance on section 00 with constraints and chart repair
METHOD secs % F-SCORE COVER n ? 40 n > 40
Original 88.3 ? 86.54 98.85 0.392 11.63
PUNCT 79.1 10.4 86.56 99.22 0.168 9.30
REPAIR 78.5 11.1 86.75 99.01 0.336 10.08
PUNCT + REPAIR 57.2 35.2 86.61 99.48 0.168 5.43
PUNCT + REPAIR + BEAM 52.4 40.7 86.56 99.48 0.168 5.43
Table 3: Best performance on Section 00
accuracy were with only punctuation constraints and
chart repair, with improvements of 35.2% speed and
0.63% coverage. Coverage on both short and long
sentences is improved ? the best results show a 43%
and 67% decrease in failure rate for sentence lengths
in the ranges 1-40 and 41+ respectively.
6.3 Partial Beam Results
We found that using the selective beam on 1?2 word
spans had negligible impact on speed and accuracy.
Using the beam on 3?4 word spans had the most im-
pact without accuracy penalty, improving efficiency
by another ?5%. Experiments with the selective
beam on longer spans continued to improve effi-
ciency, but with a much greater penalty in F-score,
e.g. a further ?5% at a cost of 0.5% F-score for 3?6
word spans. However, we are interested in efficiency
improvements with negligible cost to accuracy.
6.4 Overall Results
Table 3 summarises the results for section 00. The
chart repair and punctuation constraints individually
increase parsing efficiency by around 10%. How-
ever, the most interesting result is that in combina-
tion they increase efficiency by over 35%. This is
because the cost of rebuilding the chart when the
constraints are incorrect has been significantly re-
duced by chart repair. Finally, the use of the selec-
tive beam gives modest improvement of 5.5%. The
overall efficiency gain on section 00 is 40.7% with
an additional 0.5% coverage, halving both the num-
ber of short and long sentences that fail to be parsed.
Table 4 shows the performance of the punctuation
constraints, chart repair and selective beam system
on section 23. The results are consistent with sec-
tion 00, showing a 30.9% improvement in speed and
0.29% in coverage, with accuracy staying at roughly
the same level. The results show a consistent 35-
40% reduction in parsing time and a 40-65% reduc-
tion in parse failure rate.
7 Conclusion
We have introduced several modifications to CKY
parsing for CCG that significantly increase parsing
efficiency without an accuracy or coverage penalty.
45
METHOD secs % F-SCORE COVER n ? 40 n > 40
Original 91.3 ? 86.92 99.29 0.621 1.961
PUNCT + REPAIR + BEAM 58.7 35.7 86.82 99.58 0.399 0.654
Table 4: Best performance on Section 23
Chart repair improves efficiency by reusing the
chart from the previous parse attempts. This allows
us to further tighten the parser-supertagger integra-
tion by adding one lexical category at a time until a
spanning derivation is found. We have also explored
several approaches to selecting which category to
add next. We intend to further explore strategies
for determining which category to add next when a
parse fails. This includes combining chart and prob-
ability based orderings. Chart repair alone gives an
11.1% efficiency improvement.
Constraints improve efficiency by avoiding the
construction of sub-derivations that will not be used.
They have a significant impact on parsing speed and
coverage without reducing the accuracy, provided
the constraints are identified with sufficient preci-
sion. Punctuation constraints give a 10.4% improve-
ment, but NP constraints require higher precision NP
chunking than is currently available for CCGbank.
Constraints and chart repair both manipulate the
chart for more efficient parsing. Adding categories
one at a time using chart repair is almost a form of
agenda-based parsing. We intend to explore other
methods for pruning the space and agenda-based
parsing, in particular A* parsing (Klein and Man-
ning, 2003), which will allow only the most proba-
ble parts of the chart to be built, improving efficiency
while still ensuring the optimal derivation is found.
When all of our modifications are used parsing
speed increases by 35-40% and the failure rate de-
creases by 40-65%, both for sentences of length 1-40
and 41+, with a negligible accuracy penalty. The re-
sult is an even faster state-of-the-art wide-coverage
CCG parser.
Acknowledgements
We would like to thank the anonymous reviewers
for their feedback. James Curran was funded under
ARCDiscovery grants DP0453131 and DP0665973.
References
Srinivas Bangalore and Aravind Joshi. 1999. Supertag-
ging: An approach to almost parsing. Computational
Linguistics, 25(2):237?265.
A. Cahill, M. Burke, R. O?Donovan, J. van Genabith,
and A. Way. 2004. Long-distance dependency resolu-
tion in automatically acquired wide-coverage PCFG-
based LFG approximations. In Proceedings of the
42nd Meeting of the ACL, pages 320?327, Barcelona,
Spain.
Stephen Clark and James R. Curran. 2004a. The impor-
tance of supertagging for wide-coverage CCG pars-
ing. In Proceedings of COLING-04, pages 282?288,
Geneva, Switzerland.
Stephen Clark and James R. Curran. 2004b. Parsing the
WSJ using CCG and log-linear models. In Proceed-
ings of ACL-04, pages 104?111, Barcelona, Spain.
Michael Collins. 2003. Head-driven statistical models
for natural language parsing. Computational Linguis-
tics, 29(4):589?637.
James R. Curran and Stephen Clark. 2003. Investigating
GIS and smoothing for maximum entropy taggers. In
Proceedings of the 10th Meeting of the EACL, pages
91?98, Budapest, Hungary.
James R. Curran, Stephen Clark, and David Vadas.
2006. Multi-tagging for lexicalized-grammar parsing.
In Proceedings of COLING/ACL-06, pages 697?704,
Sydney, Austrailia.
Julia Hockenmaier and Mark Steedman. 2002. Gener-
ative models for statistical parsing with Combinatory
Categorial Grammar. In Proceedings of the 40th Meet-
ing of the ACL, pages 335?342, Philadelphia, PA.
Julia Hockenmaier. 2003. Data and Models for Statis-
tical Parsing with Combinatory Categorial Grammar.
Ph.D. thesis, University of Edinburgh.
Ron Kaplan, Stefan Riezler, Tracy H. King, John
T. Maxwell III, Alexander Vasserman, and Richard
Crouch. 2004. Speed and accuracy in shallow and
deep stochastic parsing. In Proceedings of the Human
Language Technology Conference and the 4th Meeting
of the North American Chapter of the Association for
Computational Linguistics (HLT-NAACL?04), Boston,
MA.
46
J. Kasami. 1965. An efficient recognition and syntax
analysis algorithm for context-free languages. Techni-
cal Report AFCRL-65-758, Air Force Cambridge Re-
search Laboratory, Bedford, MA.
Dan Klein and Christopher D. Manning. 2003. A* pars-
ing: Fast exact Viterbi parse selection. In Proceed-
ings of Human Language Technology and the North
American Chapter of the Association for Computa-
tional Linguistics Conference, pages 119?126, Ed-
mond, Canada.
Robert Malouf and Gertjan van Noord. 2004. Wide
coverage parsing with stochastic attribute value gram-
mars. In Proceedings of the IJCNLP-04 Workshop:
Beyond shallow analyses - Formalisms and statistical
modeling for deep analyses, Hainan Island, China.
Adwait Ratnaparkhi. 1996. A maximum entropy part-
of-speech tagger. In Proceedings of the EMNLP Con-
ference, pages 133?142, Philadelphia, PA.
Anoop Sarkar and Aravind Joshi. 2003. Tree-adjoining
grammars and its application to statistical parsing. In
Rens Bod, Remko Scha, and Khalil Sima?an, editors,
Data-oriented parsing. CSLI.
Mark Steedman. 2000. The Syntactic Process. The MIT
Press, Cambridge, MA.
Kristina Toutanova, Christopher Manning, Stuart
Shieber, Dan Flickinger, and Stephan Oepen. 2002.
Parse disambiguation for a rich HPSG grammar. In
Proceedings of the First Workshop on Treebanks
and Linguistic Theories, pages 253?263, Sozopol,
Bulgaria.
Yoshimasa Tsuruoka and Jun?ichi Tsujii. 2004. Iterative
cky parsing for probabilistic context-free grammars.
In Proceedings of the IJCNLP conference, pages 52?
60, Hainan Island, China.
D. Younger. 1967. Recognition and parsing of context-
free languages in time n3. Information and Control,
10(2):189?208.
47
