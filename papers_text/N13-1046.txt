Proceedings of NAACL-HLT 2013, pages 439?444,
Atlanta, Georgia, 9?14 June 2013. c?2013 Association for Computational Linguistics
Dudley North visits North London:
Learning When to Transliterate to Arabic
Mahmoud Azab Houda Bouamor
Carnegie Mellon University
P.O. Box 24866, Doha, Qatar
{mazab, hbouamor, behrang, ko}@qatar.cmu.edu
Behrang Mohit Kemal Oflazer
Abstract
We report the results of our work on automat-
ing the transliteration decision of named en-
tities for English to Arabic machine trans-
lation. We construct a classification-based
framework to automate this decision, evalu-
ate our classifier both in the limited news and
the diverse Wikipedia domains, and achieve
promising accuracy. Moreover, we demon-
strate a reduction of translation error and
an improvement in the performance of an
English-to-Arabic machine translation sys-
tem.
1 Introduction
Translation of named entities (NEs) is important
for NLP applications such as Machine Translation
(MT) and Cross-lingual Information Retrieval. For
MT, NEs are major subset of the out-of-vocabulary
terms (OOVs). Due to their diversity, they cannot
always be found in parallel corpora, dictionaries or
gazetteers. Thus, state-of-the-art of MT needs to
handle NEs in specific ways. For instance, in the
English-Arabic automatic translation example given
in Figure 1, the noun ?North? has been erroneously
translated to ? ?J
?A?
??@ /Al$mAlyp ? (indicating the
north direction in English) instead of being translit-
erated to ? HP?	K / nwrv?.
As shown in Figure 1, direct translation of in-
vocabulary terms could degrade translation quality.
Also blind transliteration of OOVs does not neces-
sarily contribute to translation adequacy and may ac-
tually create noisy contexts for the language model
and the decoder.
English Input: Dudley North was an English merchant.
SMT output: . ?K

	Q
?m.
	'B @ Qk. A
K

?J
?A?
??@ ?


?X?X 	?A?
kAn dwdly Al$mAlyp tAjr AlInjlyzyp.
Correct Translation: . ?


	Q
?m.
	' @ Qk. A
K HP?	K ?


?X?X 	?A?
kAn dwdly nwrv tAjr Injlyzy.
Figure 1: Example of a NE translation error.
An intelligent decision between translation and
transliteration should use semantic and contextual
information such as the type of the named-entity
and the surrounding terms. In this paper, we con-
struct and evaluate a classification-based framework
to automate the translation vs. transliteration deci-
sion. We evaluate our classifier both in the limited
news and diverse Wikipedia domains, and achieve
promising accuracy. Moreover, we conduct an ex-
trinsic evaluation of the classifier within an English
to Arabic MT system. In an in-domain (news) MT
task, the classifier contributes to a modest (yet sig-
nificant) improvement in MT quality. Moreover, for
a Wikipedia translation task, we demonstrate that
our classifier can reduce the erroneous translation of
60.5% of the named entities.
In summary our contributions are: (a) We au-
tomatically construct a bilingual lexicon of NEs
paired with the transliteration/translation decisions
in two domains.1 (b) We build a binary classi-
fier for transliteration and translation decision with
a promising accuracy (c) We demonstrate its utility
1The dataset can be found at
http://www.qatar.cmu.edu/?behrang/NETLexicon
.
439
within an MT framework.
2 Learning when to transliterate
We model the decision as a binary classification at
the token level. A token (within a named-entity)
gets translation or transliteration label. In ?Dudley
North? and ?North London?, our classifier is ex-
pected to choose transliteration of ?North? in the
former case, as opposed to translation in the latter.
The binary decision needs to use a rich set of local
and contextual features. We use the Support Vector
Machines as a robust framework for binary classifi-
cation using a set of interdependent features.2 We
build two classifiers: (a) Classifier Cnews, trained
on a large set of distinct NEs extracted from news-
related parallel corpora; and (b) Classifier Cdiverse,
trained on a combination of the news related NEs
and a smaller set of diverse-topic NEs extracted
from Wikipedia titles. We evaluate the two classi-
fiers in both news and the diverse domains to ob-
serve the effects of noise and domain change.
2.1 Preparing the labeled data
Our classifier requires a set of NEs with token-level
gold labels. We compile such data from two re-
sources: We heuristically extract and label parallel
NEs from a large word aligned parallel corpus and
we use a lexicon of bilingual NEs collected from
Arabic and Wikipedia titles. Starting with a word
aligned parallel corpus, we use the UIUC NE tag-
ger (Ratinov and Roth, 2009) to tag the English
sentences with four classes of NEs: Person (PER),
Location (LOC), Organization (ORG) and Miscella-
neous (MISC). Furthermore, we use the word align-
ments to project and collect the span of the asso-
ciated Arabic named-entities. To reduce the noisy
nature of word alignments, we designed a procedure
to clean up the noisy Arabic NE spans by POS ver-
ification, and heuristically filtering impossible items
(e.g. verbs). This results in a bilingual lexicon of
about 57K named-entity pairs. The distribution of
NEs categories is reported in Table 1.
To train and evaluate the Cdiverse classifier, we
expand our labeled data with Wikipedia NEs us-
ing the cross-lingual hyperlinks. Wikipedia article
titles often correspond to NEs (Kazama and Tori-
2We use the LIBSVM package (Chang and Lin, 2011).
PER LOC ORG MISC
News/57K 43.0% 10.0% 40.0% 7.0%
Wiki/4K 73.0% 19.0% 2.5% 5.5%
Table 1: Distribution of the four NE categories used in
57K News and 4K Wiki datasets.
sawa, 2007) and have been already used in different
works for NEs recognition (Nothman et al, 2013)
and disambiguation (Cucerzan, 2007). We improve
the Arabic-English Wikipedia title lexicon of Mo-
hit et al (2012) and build a Wikipedia exclusive
lexicon with 4K bilingual entities. In order to test
the domain effects, our lexicon includes only NEs
which are not present in the parallel corpus. The
statistics given in Table 1 demonstrate different na-
ture of the labeled datasets. The two datasets were
labeled semi-automatically using the transliteration
similarity measure (Frscore) proposed by Freeman et
al. (2006), a variant of edit distance measuring the
similarity between an English word and its Arabic
transliteration. In our experiments, English tokens
having an Frscore > 0.6 are considered as translit-
eration, others having Frscore < 0.5 as transla-
tion. These thresholds were determined after tuning
with a held out development set. For tokens having
Frscore between 0.5 and 0.6, the decision is not ob-
vious. To label these instances (around 5K unique
tokens), we manually transliterate them using Mi-
crosoft Maren tool.3 We again compute the Frscore
between the obtained transliteration, in its Buckwal-
ter form and the corresponding English token and
use the same threshold to distinguish between the
two classes. Some examples of NEs and their ap-
propriate classes are presented in Table 2.
Transliteration Translation
Minnesota ? AK??
 	JJ
?/mynyswta : 0.77 Agency ? ??A??/wkAlp : 0.33
Fluke ? ??? 	? /flwk : 0.57 Islamic ? ?J
?C?B@/AlAslAmyp : 0.55
Table 2: Examples of NEs labeled using Freeman Score.
2.2 Classification Features
We use a total of 32 features selected from the fol-
lowing classes:
Token-based features: These consist of several
features based on the token string and indicate
3http://afkar.microsoft.com/en/maren
440
whether the token is capital initial, composed en-
tirely of capital letters, ends with a period (such
as Mr.), contains a digit or a Latin number (e.g.
Muhammad II) or contains punctuation marks. The
string of the token is also added as a feature. We
also add the POS tag, which could be a good indica-
tor for proper nouns that should mainly be translit-
erated. We also check if the token is a regular noun
in the WORDNET (Fellbaum, 1998) which increases
its chance of being translated as opposed to translit-
erated.
Semantic features: These features mainly indi-
cate the NE category obtained using an NE tag-
ger. We also define a number of markers of person
(such as Doctor, Engineer, etc.) and organization
(such as Corp.) names. We used the list of mark-
ers available at: http://drupal.org/node/
1439292, that we extended manually.
Contextual features: These features are related
to the token?s local context within the NE. These
include information about the current token?s sur-
rounding tokens, its relative position in the NE (be-
ginning, middle or end). Another feature represents
the length of the NE in number of tokens.
2.3 Experiments
We train two classifiers and tune their parameters us-
ing a held out development set of 500 NEs drawn
randomly from the news parallel corpus. We use 55k
NEs from the same corpus to train the Cnews clas-
sifier. Furthermore, we train the Cdiverse classifier
cumulatively with the 55K news NEs and another
4600 NEs from Wikipedia titles.
The classifiers are evaluated on three different
datasets: TestNews which consists of 2K of NEs
selected randomly from the news corpus, TestWiki
consisting of 1K NEs extracted from the Wikipedia
and TestCombination, an aggregation of the two pre-
vious sets. We manually reviewed the labels of these
test sets and fixed any incorrect labels. Table 3 com-
pares the accuracy of the two classifiers under dif-
ferent training and test data settings. Starting with
a majority class baseline, our classifiers achieve a
promising performance in most settings. The major-
ity class for both classifiers is the translation which
performs as a baseline approach with an accuracy
equal to the distribution of the two classes. We also
TestNews TestWiki TestCombination
Baseline 56.70 57.09 56.89
Cnews 90.40 84.10 88.64
Cdiverse 90.42 86.00 89.18
Table 3: Accuracy results for the two classifiers and the
baseline on the three test datasets
observe that the addition of a small diverse training
set in Cdiverse provides a relatively large improve-
ment (about 2%) when tested on Wikipedia. Fi-
nally, Figure 2 illustrates the contribution of differ-
ent classes of features on our diverse classifier (eval-
uated on TestWiki). We observe a fairly linear rela-
tionship between the size of the training data and the
accuracy. Furthermore, we observe that the features
describing the category of the NE are more impor-
tant than the token?s local context. For example, in
the case of ?Dudley North? and ?North London?, the
most effective feature for the decision is the category
of the named entities.
  20,000 30,000 40,000 50,000 60,00076
81
86 All \Token \Context \Semantic
# of examples in the train set
Accu rac
y
Figure 2: Learning curves obtained on Wiki dataset by
removing features individually.
3 Extrinsic MT evaluation
We evaluate the effects of the classifier on an En-
glish to Arabic statistical MT system. Our first eval-
uation focuses on the utility of our classifier in pre-
venting erroneous translation of NEs which need to
be transliterated. In the following experiments we
use Cnews classifier. In order to experiment with a
diverse set of NEs, we conducted a study on a small
corpus (98,197 terms) of Wikipedia articles from a
441
diverse set of topics. We use 10 Wikipedia articles
describing: Anarchism, Artemis, Buddhism, Isfa-
han, Shawn Michaels, Turkey, etc. We first use our
classifier to locate the subset of NEs which should
be transliterated. An annotator validates the deci-
sion and examines the phrase table on the default
MT decision on those NEs. We observe that out of
1031 NE tokens, 624 tokens (60.5%) which would
have been translated incorrectly, are directed to the
transliteration module.
Finally, we deploy the transliteration classifier as
a pre-translation component to the MT system.4 Our
MT test set is the MEDAR corpus (Maegaard et
al., 2010). The MEDAR corpus consists of about
10,000 words English texts on news related to the
climate change with four Arabic reference transla-
tions. Due to the lack of non-news English-Arabic
corpus, we have to limit this experiment only to
the news domain. However, we expect that many
of the NEs may already exist in the training cor-
pus and the effects of the classifier is more limited
than using a diverse domain like Wikipedia. We au-
tomatically locate the NEs in the source language
sentences and use the classifier to find those which
should be transliterated. For such terms, we offer
the transliterated form as an option to the decoder
aiming to improve the decoding process. For that
a human annotator selected the transliterations from
the suggested list that is provided by the automatic
transliterator (Maren) without any knowledge of the
reference transliterations.
Table 4 shows the impact of adding the classifier
to the SMT pipeline with a modest improvement.
Moreover, a bilingual annotator examined the au-
tomatically tagged NEs in the MT test set and la-
beled them with the translation vs. transliteration
4The baseline MT system is the MOSES phrase-based de-
coder (Koehn et al, 2007) trained on a standard English-Arabic
parallel corpus. The 18 million parallel corpus consists of
the non-UN parts of the NIST corpus distributed by the Lin-
guistic Data Consortium. We perform the standard prepro-
cessing and tokenization on the English side. We also use
MADA+TOKAN (Habash et al, 2009) to preprocess and tok-
enize the Arabic side of the corpus. We use the standard setting
of GIZA++ and the grow-diagonal-final heuristic of MOSES
to get the word alignments. We use a set of 500 sentences
to tune the decoder parameters using the MERT (Och, 2003).
We use El Kholy and Habash (2010) detokenization framework
for the Arabic decoding. We evaluate the MT system with the
BLEU metric (Papineni et al, 2002).
MT Baseline MT Baseline + Classifier
BLEU 16.63 16.91
Table 4: Results of the extrinsic usage of the classifier in
SMT
decisions. Having such gold standard decisions, we
evaluated the classifier against the MT test set. The
classifier?s accuracy was 89% which is as strong as
the earlier intrinsic evaluation. The false positives
are 5% which represents around 12.6% of the total
errors.
The following example shows how our classifier
prevents the MT to choose a wrong decoding for
the NE Python (being transliterated rather than
translated). Moreover, the MT system transliterates
the term Monty that is unknown to the underlying
system. Such entities tend to be unseen in the
standard news corpora and consequently unknown
(UNK) to the MT systems. Using our classi-
fier in such conditions is expected to reduce the
domain gap and improve the translation quality.
English Input: The British comedy troupe Monty Python.
Baseline MT: . ?


?
	
? @ UNK ?J
 	K A?
Q. ? @

?K
YJ
????@

?

Q?
	
?? @
Alfrqp Alkwmydyp AlbryTAnyp UNK AfEY
MT+Classifier: . 	??JK
AK. ?

? 	K??

?J

	K A?
Q. ? @

?K
YJ
????@

?

Q?
	
?? @
Alfrqp Alkwmydyp AlbryTAnyp mwnty
bAyvwn.
4 Related work
A number of efforts have been made to undertake the NE
translation problem for different language pairs. Among
them some use sequence of phonetic-based probabilistic
models to convert names written in Arabic into the En-
glish script (Glover-Stalls and Knight, 1998) for translit-
eration of names and technical terms that occurs in Ara-
bic texts and originate in English. Others rely on spelling-
based model that directly maps an English letter sequence
into an Arabic one (Al-Onaizan and Knight, 2002a). In a
related work, Al-Onaizan and Knight (2002b) describe a
combination of a phonetic-based model and a spelling-
based one to build a transliteration model to generate
Arabic to English name translations. In the same direc-
tion, Hassan et al (2007) extracted NE translation pairs
from both comparable and parallel corpora and evaluate
their quality in a NE translation system. More recently,
Ling et al (2011) propose a Web-based method that trans-
lates Chinese NEs into English. Our work is similar in
its general objectives and framework to the work pre-
442
sented by Hermjakob et al (2008), which describes an
approach for identifying NEs that should be transliter-
ated from Arabic into English during translation. Their
method seeks to find a corresponding English word for
each Arabic word in a parallel corpus, and tag the Ara-
bic words as either NEs or non-NEs based on a match-
ing algorithm. In contrast, we tackle this problem in the
reverse direction (translating/transliterating English NEs
into Arabic). We also present a novel binary classifier for
identifying NEs that should be translated and those that
should be transliterated.
5 Conclusion and future work
We reported our recent progress on building a classi-
fier which decides if an MT system should translate or
transliterate a given named entity. The classifier shows
a promising performance in both intrinsic and extrinsic
evaluations. We believe that our framework can be ex-
panded to new languages if the required data resources
and tools (mainly parallel corpus, Named Entity tagger
and transliteration engine) are available. We plan to ex-
pand the features and apply the classifier to new lan-
guages and conduct MT experiments in domains other
than news.
6 Acknowledgements
We thank Nizar Habash and colleagues for the MADA,
Arabic detokenization and the transliteration similarity
software and also their valuable suggestions. We thank
anonymous reviewers for their valuable comments and
suggestions. This publication was made possible by
grants YSREP-1-018-1-004 and NPRP-09-1140-1-177
from the Qatar National Research Fund (a member of
the Qatar Foundation). The statements made herein are
solely the responsibility of the authors.
References
Yaser Al-Onaizan and Kevin Knight. 2002a. Named-
Entity translation. In Proceedings of HLT, San Fran-
cisco, USA.
Yaser Al-Onaizan and Kevin Knight. 2002b. Translating
Named Entities Using Monolingual and Bilingual Re-
sources. In Proceedings of ACL, Philadelphia, USA.
Chih-Chung Chang and Chih-Jen Lin. 2011. LIB-
SVM: A Library for Support Vector Machines. ACM
Transactions on Intelligent Systems and Technology,
2:27:1?27:27. Software available at http://www.
csie.ntu.edu.tw/?cjlin/libsvm.
Silviu Cucerzan. 2007. Large-Scale Named-Entity Dis-
ambiguation Based on Wikipedia Data. In Proceed-
ings of EMNLP-CoNLL, Prague, Czech Republic.
Ahmed El Kholy and Nizar Habash. 2010. Techniques
for Arabic Morphological Detokenization and Ortho-
graphic Denormalization. In Proceedings of LREC,
Valletta, Malta.
Christiane Fellbaum. 1998. WordNet: An Electronic
Lexical Database. The MIT Press.
Andrew Freeman, Sherri Condon, and Christopher Ack-
erman. 2006. Cross Linguistic Name Matching in
English and Arabic. In Proceedings of NAACL, New
York City, USA.
Bonnie Glover-Stalls and Kevin Knight. 1998. Trans-
lating Named and Technical Terms in Arabic Text. In
Proceeding of the COLING/ACL Workshop on Compu-
tational Approaches to Semitic Languages, Montreal,
Canada.
Nizar Habash, Owen Rambow, and Ryan Roth. 2009.
Mada+Tokan: A Toolkit for Arabic Tokenization, Dia-
critization, Morphological Disambiguation, POS Tag-
ging, Stemming and Lemmatization. In Proceed-
ings of the Second International Conference on Ara-
bic Language Resources and Tools (MEDAR), Cairo,
Egypt.
Ahmed Hassan, Haytham Fahmy, and Hany Hassan.
2007. Improving Named Entity Translation by Ex-
ploiting Comparable and Parallel Corpora. In Pro-
ceedings of RANLP, Borovets, Bulgaria.
Ulf Hermjakob, Kevin Knight, and Hal Daume? III. 2008.
Name Translation in Statistical Machine Translation
- Learning When to Transliterate. In Proceedings of
ACL-HLT, Columbus, Ohio.
Jun?ichi Kazama and Kentaro Torisawa. 2007. Ex-
ploiting Wikipedia as External Knowledge for Named-
Entity Recognition. In Proceedings of EMNLP-
CoNLL, Prague, Czech Republic.
Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Marcello Federico, Nicola Bertoldi,
Brooke Cowan, Wade Shen, Christine Moran, Richard
Zens, Chris Dyer, Ondrej Bojar, Alexandra Con-
stantin, and Evan Herbst. 2007. Moses: Open Source
Toolkit for Statistical Machine Translation. In Pro-
ceedings of ACL: Demo session, Prague, Czech Re-
public.
Wang Ling, Pavel Calado, Bruno Martins, Isabel Tran-
coso, and Alan Black. 2011. Named-Entity Transla-
tion using Anchor Texts. In Proceedings of IWSLT,
San Francisco, USA.
Bente Maegaard, Mohamed Attia, Khalid Choukri,
Olivier Hamon, Steven Krauwer, and Mustafa Yaseen.
2010. Cooperation for Arabic Language Resources
and Tools?The MEDAR Project. In Proceedings of
LREC, Valetta, Malta.
Behrang Mohit, Nathan Schneider, Rishav Bhowmick,
Kemal Oflazer, and Noah A. Smith. 2012. Recall-
443
Oriented Learning of Named Entities in Arabic
Wikipedia. In Proceedings of EACL, Avignon, France.
Joel Nothman, Nicky Ringland, Will Radford, Tara Mur-
phy, and James R. Curran. 2013. Learning Multilin-
gual Named Entity Recognition from Wikipedia. Ar-
tificial Intelligence, 194(0):151 ? 175.
Franz Josef Och. 2003. Minimum Error Rate Training
in Statistical Machine Translation. In Proceedings of
ACL, Sapporo, Japan.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. BLEU: a Method for Automatic
Evaluation of Machine Translation. In Proceedings of
ACL, Philadelphia, USA.
Lev Ratinov and Dan Roth. 2009. Design Challenges
and Misconceptions in Named Entity Recognition. In
Proceedings of CONLL, Boulder, USA.
444
