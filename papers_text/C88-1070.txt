Schema Method:  A F ramework  
fo r  Cor rec t ing  Grammat ica l ly  I l l - fo rmed Input  
Ikuo KUD01) , Hideya KOSHINO2) , Moonkyung CHUNG2) and Tsuyosi MORIMOTO1) 
1)ATR Interpreting Telephony Research Laboratories 
Twin 21 Building MID Tower 
2-1-61 Shiromi, Higashi-ku 
Osaka 540, Japan 
2)CSK Research Institute 
3-22-17 Higashi-Ikebukuro, Toshima-ku 
Tokyo 170, Japan 
Abstract 
The schema method is a framework for correcting 
grammatically ill-formed input. In a natural language 
processing system ill-formed input cannot be overlooked. A
computer assisted instruction (CAD system, in particular, 
needs to show the user's errors. This framework diagnoses 
ill-formed input, corrects it and explains the error, if an 
input is ill-~'ormed. The framework recognizes a sentence at 
two steps: first parses weak grammar, and then strongly 
filters the parsed sentence. When it is known what 
sentences are passed by the filter, it can be used even if it is 
imperfect. As the strong filter, a new method is used: an 
interpretation schema and an interpretation rule. An 
interpretation schema collects input information schemata 
and then an interpretation rule judges whether the 
collected schemata re correct or incorrect. This approach 
overcomes the problem of relaxation control, the major 
drawback of the previous yntactically-oriented methods, 
and is also more efficient. 
1? Introduction 
Ill-formed input cannot be ignored when a natural 
language processing system such as a computer assisted 
instruction (CAD system or a machine translation system 
is built. Particularly in a CAI System, students often 
make mistakes, such as mispunctuation, lack of agreement, 
misplaced/improperly-used words, etc. In these cases, a 
CAI system needs to point out input errors, and show why 
the input it~ wrong. In order to do so, the system needs to 
diagnose and correct ill-formed input to explain the errors. 
The schema method as a framework for correcting 
grammatically ill-formed input is suggested and the 
diagnosis and correction of errors is discussed. 
There have been many studies for processing ill-formed 
input for English. The point of those studi.es is the 
diagnosis: how does the system find an error? The 
approaches are classif ied into two groups:  the 
syntactically-oriented group and the frame-based group. 
The syntactically-oriented group includes robust 
parsers based on Augmented Transition Networks (ATN) 
which Use the relaxation technique/Kwansny 1981./or the 
meta-rule/Weisehedel 1980, 82, 87/, and the EPISTLE 
system which addresses the problems of the checking 
grammar and style of texts, such as letters, reports and 
manuals, written in ordinary English/Heidorn 1982/, 
/Jensen 1983/. 
The frame-based group attempts to deal with 
ungramnmtical input through extensions to pattern 
matching parsing/Hayes 1981/, through conceptual case 
frame instantiation/Schank 1980/and through approaches 
involving multiple cooperating pars ing strategies 
/Carbonell 1983/. The target of that study is dialogue 
phenomena in communication with l imited-domain 
systems, such as data-base systems, electronic mail 
systems, etc. 
The aim of this study is error-correction of non-native 
speakers written Engl ish text. This approach is 
syntactically oriented. 
The syntactically-oriented approaches/Kwansny 1981/ 
/Weischedel 1980,82,87/,/Heidorn 1982/,/Jensen 1983/are 
very similar. Their basic idea is relaxation. They first 
attempt to parse the input, using fully grammatical rules. 
If the sentence is not parsed, some of the conditions are 
relaxed. However these approaches have two major 
drawback. 
(1)Relaxation control strategies: when inputs are ill- 
formed, some means of ranking alternatives i  appropriate. 
The number of relaxed configurations may be large. 
One of the most critical problems is control. The need to 
relax the very rules that constrain the search for an 
interpretation is like opening Pandora's box./Weischedel 
1987(PP.117)/ 
(2)Computational inefficiency: the relaxation approach 
cannot recognize ill-formed input before the analysis with 
well-formed grammar is finished. Furthermore, fully well- 
formed grammar is needed. To make fully well-formed 
grammar, subcategorization f parts of speech is needed 
and other conditions are added. As a result, there are too 
many rules. 
In comparison to previous approaches, this approach 
does not use the relaxation technique. The difference 
between previous approaches and this one is the method of 
recognizing an ill-formed sentence. Previous approaches 
first use a strong filter, then relax the conditions. This 
approach, however, first uses weak grammars, and then 
strongly filters the passed sentence. This approach 
recognizes a sentence at two steps. 
An attempt is made to expand lexical-functional 
grammar (LFG) /Kaplan 1982/to deal with ill-formed 
input. LFG has two drawbacks: (1) LFG can't deal with 
errors of omission and (2) LFG has no framework for error 
correction. If an input sentence is well-formed, this 
framework obtains an LFG f-structure. If not, the sentence 
is corrected. 
Examples of error correction are given in the next 
section. In the section following the basic idea is described 
3~i 
and the problem of a unification mechanism for processing 
ill-formed input is discussed. This framework is shown in 
section 4. 
2. Non-nat ive  speaker ' s  i l l - formed phenomena 
In this section, treated examples of non-native speaker's 
ill-formed phenomena re given. The application is a CAI 
system for Japanese junior  high school s tudents  in a 
primary English course. Their  errors are different from a 
native speaker's. Typical errors are shown in Table 1. 
Engl ish is very different from Japanese in parts of 
speech, word-order, tense, etc. For a Japanese, there is no 
concept of( l )  countable and uncountable nouns ~:> ~ ~> in 
Table 1, (2) singular and plural forms <~ (3) articles ~> ~> 
(4) agree-merit between subject and verb @ (5) adverb 
word-order ~.  
Japanese interfered with the students'  acquision of 
English. The following errors are often made by Japanese 
adults as well. (4)verb style <~ (5) category mistakes, word 
misuse ~>. Furthermore, junior high school students are 
reading and hearing a foreign language (English) for the 
first time, and thus have no concept of foreign language 
whatsoever. (6) Logical error @: the student who made the 
mistake explained that "are + not -* aren't", "is + not -* 
isn't" so" am+ not --* amn't". (7) Pr imary students are not 
fami l iar  with Eng l i sh  grammar  and can't  d is t inguish 
between "Who" or "Where" @ @. (8)Surface rror: letter or 
punctuation problems 
Table 1. Examples of errors by junior high school students 
<~*He plays piano. <~*He plsy the baseball. 
He plays the piano. He plays baseball. 
@*some good advices '<~*I am student. 
some good advice I am a student. 
@*A moon is smaller than an erath. 
The moon is smaller than the earth. 
~*He is one of those men who is difficult to please. 
He is one of those men who are difficult to please. 
<~*I have finished my homework already. 
I have already finished my homework . 
~>*He is listening music on the radio now. 
He is listening to music on the radio now. 
<~*We cannot play baseball in here. 
We cannot play baseball here. 
@*Yes, I amn't. 
Yes, I am not. Yes, I'm not. 
~*Who does cook breakfast? ~*Where they live? 
Who cooks breakfast? Where do they live? 
@*Does mr. brown have a book 
Does Mr. Brown have a book? 
@*We must stop to complain. 
We must stop complaining. 
Grammatical  errors ~ @ are treated, but not 
semantic errors ~> and absolutely ill-formed sentences 
which are not comprehensible. The aim is to diagnose 
grammatical  errors and show a reason for the error. For 
example: 
Input sentence; Mr Brown has a pen, 
correction; Mr. Brown has a pen. 
the reason; A period is needed after"  Mr". 
The comma after "pen" should be a period. 
342 
3. Basic idea 
In this section, the basic idea of the frsmework and ~be 
problem of the LFG unification mechanism in dealing with 
ill-formed input is described. 
3.1 Two - level f i l ter 
The framework uses two-level filters for input sentence 
classification: a well-formed sentence, a relat ively ill- 
formed sentence or an absolutely i l l-formed sentence as 
shown in Figure 1. 
(1)First an attempt to parse the input,  us ing normal  
context-free grammar  (Fi l ter I ) is made~ Both a wello 
formed sentence and the relat ively illoformed sentence 
which includes feature errors are passed through the filter 
(Filter I ). 
(2)Secondly, these inputs are checked with a strong filter 
(FilterII). A well-formed sentence passes, but a relatively 
ill-formed sentence does noL 
(3)An input which is not passed through the first f i lter 
(Filter I ), includes word-order or omitted-word errors~ or 
unnecessary words @ @. The input is classified by a filter 
(~), called Improper Grammar, as relatively ill-formed or 
absolutely i l l -formed. 
j al~essed ~In iu t  . . . . .  "~.- . .  ~'--~rejected 
Filter ( I ) \] 
F-S:iltor( ) 1 
\[ Improper Grammar / 
7 
Well-formed error corection failure 
(relatively ill-formed} (absolutely ill-formed) 
<~<~ <~ @ :sentence 
~>~ number in Table1 
Figure 1 Two-level filter 
3.2 F i l ter  test  
Fi lter ( I ) is a context~free grammar. This filter is a 
weak filter. Therefore some relatively ill-formed inputs are 
passed. Consider how many sentences are derived from the 
grammar rules in Figure 2. 25 (5 ? 1?5) sentences are 
generated by the grammar ules and dictionary entries. Of 
course, not only well-formed sentences as in (1) below, but 
also i l l -formed sentences as in (2), (3), (4) below~ are 
included. 
Grammar rules Dictionary 
S--*NP VP : Verbal Phrase (VP)  pronoun-*this 
VP--~verb NP verb -~is 
NP-*pronoun : Noun Phrase (NP) det ~an 
NP-~det noun noun -~apple 
NP-*noun noun --,apples 
The generated sentences 
(1)This is an apple. (2)This is apple. 
(3)This is an apples. (4)This is apples. 
Figure 2 The generated sentences 
3.3 The prob lem of the LFG uni f icat ion mechan ism f~o 
ill-formed input 
Relat ively i l l -formed sentences,  as well  as feature 
errors, pas;~ t~rough Filter( I ). Fi lter(I I)  must work as a 
strong grammatical filter. LFG contains such a strong 
f i l ter ,  callc,d the unit ' icat ion mechan ism,  '"front F-. 
Descriptions to F-Structures fKaplan 1.982 (pp.203)/". For 
exmnpl% 
"This is a apple" 
In LFG a-disagreement, "a apple", is rejected because 
the following equations are not unified. 
.; ( t  ~\]PEC) :a  froma 
( 1' SPEC) = an from apple 
I~owever~ for diagnosis and error-correctlon there are 
:~ome drawbacks in LFG framework : 
(1)LFG canq: check an error of omission as in the noun 
phrase '~  apple' in the sentence 
"This is apple". 
As tile sentence lacks the article "an", there  is no 
determiner equation and the unification mechanism does 
not work. Thus the sentence is recognized as a well-formed 
sentence. 
f O from (h :lack of article 
( 1' iIPEC) = an from apple 
(2)LFG has no error-correction framework. It only rejects 
the i l l -formed input. Addit ion of an error-correct ion 
mechanism i'~ thus necessary. 
304 Improper  Grammar  \[Fi l ter (liD\] 
In this application, users are non-nat ive speakers 
unfamil iar with English grammar. Thus, a user often 
makes word-order errors, includes unnecessary words, or 
leaves out words @ @. A teacher could show why "does" is 
not necessary in the sentence @ "*Who does cook 
breakfast'S", or wily "do" is needed in @ "*Where they 
live?". If a :~ystem diagnoses uch sentences, it needs to 
provide the grammar ules tbr analysis. The type of error 
shown in Figure 3 is called improper grammar. 
*S *S 
q-pron *AUX VERB3 NP q-adv NP VERBI 
( ~ SUBJ)= 4 ( t OBJ)= ~ I ( t SUBJ)= 
I I I 1 
*wire doe~ cook breakfast ? *where they live ? 
Figure 3 Examples of improper grammar 
4, '~?he fl?am(~wo~'k 
In Ibis section an overv iew of the f ramework  is 
explained. Unif icagon approach has some drawbacks for 
diagnosis as we described in 3.3. A new method is used as a 
filter (lI). The idea is to compare input style with proper 
m, rfi~ce sty\]~.s which are synthesized from lexical  and 
grarmmaticai conditions. An interpretation schema collects 
l:he conditions (surface schema and LFG schema) and an 
L~\[erpretation rule synthesizes proper styles and judges 
whether the sentence is  ill- or well,formed as shown in 
Figure 4. In this section, at first, new schemata are 
notated: surface schema (4.1), surface constraint (4.2), 
in~e~?pre~ation schema,  in terpreta t ion  schema wi th  
condition, conditional schema and kill schema (4.3). And 
then the ins~mnfiation mechanism and interpretat ion of 
Input sentence 
.................... Jnpu~\[q)ParsingPl'oce s sing . . . . . . . . . .  ~ IFG schema'U" rfa e s cjlem a. . . .  
wm,~{ I ~ l@Instantiation * J Surface constraint 
Filter( II ) J ~"~T ~ ~  
I I mlnputsty le
i - - - - -~  (~Synthesize styles (= Proper styles) 
Success Error lfDCorrect sentence 
f-structure ~ Explanation of the errors 
Figure 4 A schema method overview 
new schemata are described (4.4) (4.5). F inal ly  error- 
correction is i l lustrated (4.6). 
4.1 Inl~ut p rocess ing  
\ [Surface schema\[  
A capital etter and a punctuation indicate surface of an 
input sentence. In this framework such inibrmation is 
represented as a schema, called a surface schema. In the 
input processing, the input sentence is converted into 
surface schemata. The schema is notated as follows. 
(gn f-name) =value 
"gn" is the designator which shows the word-order "n". "f- 
name" is a function name of schema, like word, letter or 
mark, etc. "value" is its schema's value. 
For example, tile ill-formed input, "MR.Brown have eat 
a apple," is represented as surface schemata in Figure 5. 
"MR." is represented as lout-surface schemata: 
"(gl word) -- mr"; the word is "mr". 
"(gl mark) =period"; the mark after the word is a period. 
"(gl letter) = 1"; the first letter of the word is a capital ("M"). 
"(gl letter) = 2"; the second of the word letter is a capital ("R'). 
Input sentence: *MR. Brown have eat a -apl~ieV--I 
/ 
I I I I I * , MR. , Brown , have , eat , a , apple, 
designators L . . . . .  ~ . . . . . . . . .  J. . . . . .  ~_ . . . . .  _L ...... ~ . . . . . . . . . .  r . . . . .  - v  . . . . . . .  ~ . . . . .  " I -  . . . . .  - r  . . . . .  c . . . . . . . . .  
ga ', gl ', g2 ', g3 I g4 *, g5 I g6 
Surface schemata 
Word = \[(gl word) = mr, (g2 word) = brown, (g3 word) = have, 
(g4 word) = eat, (g5 word)-- a, (g6 word) = apple\] 
Mark = \[(gl mark) = period, (g6 mark) =comma\] 
Letter -- i(gl letter) = 1, (gl letter) = 2, (g2 letter) = 1\] 
Figure 5 Examples of surface schema 
4.2 Lex icon  
\[Lexical  sur face  constra int \ [  
In the lexicon, lexical features and constraints are 
involved as schemata. A constraint for a surface schema is 
called a surface constraint. A surface constraint is notated 
as follows: 
(IT f-name) = ?value. 
"IT" means meta-vm: iable .  "It" is substituted for "gn", 
when the surface constraint is instantiated. 
There are two kinds of surface constraints: lexical and 
granmaatical. The capital letter "M" in "Mr." is a lexieal 
343 
constraint, because it  is capitalized regardless of sentence 
position. A lexical surface constraint is assigned to the 
dictionary (Figure 6). 
(IT word) =cmr; the word must be "mr". 
(IT mark) = cperiod; the mark after the word must be a period. 
(IT letter) =el; the first letter of the word"mr" must be a capital. 
Lexicon Lexical surface constraints and LFG schemata 
neun3 Mr. (IT word) =cmr (t  PRED-1) =mr 
(IT mark) = cperiod ( t GENDER) = male 
(IT letter) = cl ( 1' CATEGORY) = noun3 
nounl Brown (ITword)=cbrown (~PRED)=Brown 
(IT letter) = cl ( 1' PERSON) = 3 
( 1' NUM) = SG 
( 1' CATEGORY) = nounl 
Figure 6 Lexicon 
4.3 Grammar  
\ ]Grammat ica l  sur face  constra int \ ]  
The first letter in a sentence is always a capital letter 
and the last punctuation in a sentence is noted as a mark ( a 
period, a question mark or an exclamation point, etc.). 
These are regarded as grammatica l  constraints. In our 
h'amework these grammatical  constraints are represented 
as grammatical surface constraints. They are assigned to 
grammar ul~ as shown in Figure 7. 
(ITF letter) = ?1; This means the first letter in the sentence must be 
acapital etter. ITFshows firstorderinthesentence. 
(ITL mark)=cperiod; This means the last mark in the sentence 
must be a period. IT L shows last order in the sentence. 
Grammar rule 
S --* NP VP 
( 1' SUBJ)= $ 1' = 
(ITF letter)=cl (ITL mark)=cperiod 
Figure 7 Grammar rule with surface constraints 
\ [ In terpretat ion  schema\]  
In order to diagnose and correct errors, our framework 
has three steps; (1)collecting information on the input  
sentence, (2)synthesis of interpretation and (3) comparison 
of( l )  and (2). 
The interpretation schema collects LFG schemata nd 
surface schemata. It is assigned to lexicon or grammar  
rules. In the parsing process, it is instantiated and collects 
schemata. The schemata cor rec ted  by in terpretat ion  
schema are conveyed to the interpretat ion rule. This  
schema is notated as follows. 
( T f-name) = i{values} 
T is a meta:variable as well as LFG notation and "f- name" 
is a functional name of the interpretat ion schema. Its 
Values are sets of schemata? 
For example an interpretation schema for agreement  
between determiner and noun is notated as follows. 
(~) ( t DET-NOUN)=i{\[DET\],\[NOUN\]} 
\[DET\] means set of schemata from determiner, and \[NOUN\] 
means from noun. 
(Example 1) For the correctly-formed noun phrase "an 
apple", the interpretation schema, DET-NOUN, is attached 
to grammar ule (1) as shown in Figure 8. In instantiation, 
the interpretation schema collects LFG schemata in lexicon 
and surface schemata s its values below. 
344 
Grammar Rule and Interpretation schema 
(1)NP -* DET NOUN 
( 1' DET-NOUN) =i{\[DET\],\[NOUN\]} 
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  
NP:fn 
( 1' DET-NOUN) = i{\[DET\],\[NOUN\]} 
DET z / NOUN ~ 
1 ! I x 
~exico. I ( t  SPEC)='an' I I(1' PRED)='apple' '~  
LFGschemata I?* NUM)=SG I I?t NUM)=SG \[ 
. . . . . . .  J , , l J ( t  SPECl)='an/the'| 
An instantiated interpretation schema 
(~fn SPEC)='an' \[fin PRED)='apple' -
(fn DET_NOUN)=i~\[ (fn NUM)= SG |(fn NUM)=SG 
U (giwOrD)=an I / ( t .  SPEC1)='an/the' A,  \[(gi+ 1WORD) = apple _ 
Figure 8 An example of interpretation schema of"an apple" 
(Example 2) In another case, the ill-formed noun phrase 
"0  apple", lacks an article. As above, an interpretation 
schema collects chemata in Figure 9. 
Other examples of interpretation schemata and their  
attached grammar are shown in Figure 10. 
Grammar Rule and Interpretation schema 
(2)NP -,  NOUN 
(~' DEW-NOUN) = i{\[ ~\],\[NOUN\]} 
An instantiatsd interpretation schema 
(fn DET-NOUN)=i O 1 \[fin NUM)=SG | / I(t- SPEC1)='ar~the' | /
? J2Lg j WORD):apple A J 
Figure 9 An example of interpretation schema of "0  apple" 
\ [ Interpretat ion schema with a condi t ion  
and condi t iona l  schema\]  
An interpretation schema with a condition, and its 
conditional schema are a pair and act as an interpretation 
schema. An interpretation schema with condition can act 
when there is a conditional schema. These schemata re 
notated as (a) an interpretation schema with a condition: 
( ~' f-name) = i -  CON{Values} 
and (b) a conditionalschema: 
( 1' f-name) = CON{Values}. 
For example, this schema (~) means that  i f  a noun 
phrase \[NP:f2\] is a pronoun \[PRONOUN\], it checks whether 
the case of pronoun is subjective \[subj\[. I f the noun phrase is 
not a pronoun, such as "an apple", there is no need to 
check. 
(~ (f2 CASE) = i-CON\[\[NP:f2l,\[subj\]}. 
The following schema (~) is its conditional schema. It is 
attached to grammar ule (5) and means the noun phrase is 
a pronoun. 
(~ (f2 CASE)= CON{\[PRONOUN\]} 
\[Kill schema\]  
A k i l l  schema is the  ins tant ia t ion  inh ib i t ion  
mechanism. It works to kil l  the interpretation schemata 
and is notated as follows: 
( ~ f-name)=k{( ~f-name-l), ( t f-name-2) ........ }. 
(3)N~P ~-> D~T .... AOJ .~ ' NOUN 
~(~' ~I)ET2ADJ-NOUN) =i{\[I)ET\],\[ADJ\],\[NOUN\]} 
(4)NP -~ ADJ NOUN 
(~' DET-ADJ-NOUN) = i{\[O \],\[ADJ\],\[NOUN\]} 
(5)NP ~ PRONOUN 
(~ CASE) :~ CON{\[PRONOUN\]} 
(6)S:f1 --~ NF:f2 VERB3:Q NP:~ 
(fi SUBJ) :~ i'2 (h oBJ)  = 5 
(ITF letter) :: ?1 (ITL mark) = cPeriod 
(Q SUBJ&V-.FORM) = i{\[NP:f2\],\[VERB3\]} 
(f2 CAGE) = i--CON{\[NP:f2\],\[subj\]} 
(f3 CAGE) :: i--. OON{\[NP:fa\],\[obj/poss\]} 
(7)S:fl .-~ NP:t2 AUX:Q VERB3:fI NP:f3 
(il SUB J) ~: i2 (it onJ) = i'a 
(IT F letter) = cl (ITL mark) = cperiod 
(f~ SUBJ&A-FORM) = i{\[NP:f21,\[AUX\]} 
(fl AUX&V-FORM) = i{\[AUX\],\[VERB3\]} 
(f2 CASE) =i._CON(\[NP:f2\],\[subj\]} 
(f3 CASE) =~i~- C0~{\[NP:f~l,\[obj/poss\]} 
(8)S:it -,~ NP: f2  VERB-be:fl NP:f 3 
(fl SUBJ) = f2 (fl COMP) = f3 
(ITI,, letter) = c I (IT L mark) = cperiod 
(t' 1 SUBJ&V-FORM&COMP) = i{\[NP:f2I,\[VERB~be\],\[NP:f3\] } 
(h SUBJ&V.-FORM&COMP) = k{(f2 DET-NOUN), 
(f2 DET-ADJ-NOUN)} 
Interpretation Schemata Grammar rule 
~) (T DET~NOUN)=I{\[DET\],\[NOUN\]} Rule(I)(2) 
(~ (I' DET-AI)J-NOUN)=i{\[DET\],\[A1)J\],\[NOUN\]} Rule(3)(4) 
(~ (t'I SUBJ&V-FORM)=i{\[NP:f2\],\[VERB3\]} Rule(6)(8) 
(.4) (fl SUBJ&A-FORM) =i{\[NP:f2\],\[AUX\]} Rule('/) 
(f~ AUX&V-FORM) = d\[AUXI,\[VERB3\]} Rule(7) 
(fl SUBJ&V-FORM&COMP) = i{\[NP:f~\],\[VERB-be\],\[NP:fs\]} 
Rule(8) 
knterpretation Schemata with condition Gramlnar ule 
~) (f2 CASE) = i.~ CON{\[NP:f?.\],\[subj\]} Rule(6)(7)(8) 
Conditional ~chema Grarmnar rule 
(0_) (1" CASE)=cON{\[PRONOUN\] } Rule(5) 
Kill schema Grammar rule 
(9) (f2 SUBJ&V-FORM&COMP) = k{(f2 DE'r-NOUN), Rule(8) 
(f2 I)V.T-A~)J-NOON)} 
@)This schema checks agreement  between deter- 
miner, adjective and noun such as 'the same name',  
'*some good advices', '*a good jobs', and '*a interesting 
book'. 
?Th is  schema checks whether verb ibrm (V-FORM} is 
a proper tbrm for subject style (SUBJ). \[NP:f2\] is subject. 
For example "Tom gives...", "*He laugh ...", "You 
made _.." and "*Mr,and Mrs. Brown laughs ...". 
(~)This schema checks whether auxi l iary verb form 
(A-FORM) i?,; a proper form for subject ~tyle (SUBJ). \[NP:f2\] 
is subject. For example "*Tom have  given..." and "He 
can laugh .. . ' .  
@ This schema checks whether verb form (V-FORM) is 
a proper titan for auxi l iary verb. For example '~l~om has 
given...", '~*Tom has give..,", "*You can laughed ..." and 
"He is speaking ..." 
@This ~chema checks agreement between subjective 
"be" noun phrase, verb . and compliment. \[NP:f2\] is 
subjective ~aoun phrase and \[NP:fS\] is compliment. For 
exaraple "*These is apples." , "*He is students." and 
"*They are a student." 
Figure 10 Examples of grammar and interpretation schema 
1' is a metaovariable and "f-name" is a kil l-schema's name. 
Its value in { ....... } is the kil led schmnata's name. 
There are hierarchy and priority between interpretation 
schemata. A kill schema is used to keep interpretation 
schemata independent. The schema attached to noun 
phrase can collect schemata only wiflfin the noun phrase, 
while the schema attached to sentence level can collect 
schemata in the sentence. Thus, the former is local and the 
latter is global. For example, 
"* This is a apples. "
Tile noun phrase, " a apples ", is wrong and should be 
"an apple". But the local interpretation schema ~ (Figure 
10) can't determine which is correct, "an apple" or "apples", 
while the global interpretation schema @ can judge that 
"an apple" is correct. The global interpretation schema ? 
checks ibr agreements within \[NP:fS\] instead of the local 
interpretation schemata (~) or ?.  Therefore, the local 
interpretation schemata (J) and (.2), are not necessary. 
Thus, the kill schema @, which corresponds to the global 
in terpretat ion  schema @, k i l l s  local in te rpreta t ion  
schemata Q) and ?. 
@ (f2SUBJ&V-FORM&COMP) =k{(f2 DET-NOUN), 
(f2 DET-ADJ-NOUN)} 
(~) (f2 DEW-NOUN) = i{\[DET\],\[NOUN\]} 
(~ (f2 DET-ADJ-NOUN) = i{\[DET\],\[ADJ\],\[NOUN\]} 
4.4 lns tant ia t ion  
How to instantiate schema is explained. Both t and ~ - 
meta-variables are assigned to actual variables (f l, f2....) as 
well as LFG. 
A surface schema,  a sur face const ra in t  and an 
interpretation schema include "IT" meta-variables. "IT" 
recta-variables are assigned as follows. 
(Din input processing, the designator "gn" which shows the 
word-order in the input sentence is assigned to surface 
schema. 
(2)When' the dictionary is looked up, surface constraints in 
the lexicon are instantiated. "IT" meta-var iab le  in a 
surface constraint is bound to the designator "gn" in surface 
schema. 
(3)When a grammar ule is fitted, surface constraints in the 
S: fl Grammar 
NP:f2 AUX:It VERB3:fl NP:fa 
(fl SUBJ)=f2 (fl SUBJ&A-FORM)=i (it OBJ)=fa ~ (gl letter)~-?l {\[NP:f2\],\[AUX\]} (g6 mark) =cperiod CASE)=i-CON (fl AUX&V-FORM)=i f ( f3  CASE)---i--CON {\[NP:f2\],\[subj\]} {\[AUX\],\[VERB3\]}/ {\[NP:fa\],\[obj\]} 
noun3 nounl l det noun 
! ~(  f3 DET-NOUN) = i 
\] | \[ \[ ~ {\[DET\],\[NOUN\]} 
\ : Lexicon \ : 
(~. (gl word) --cmr ~ : 
~ : ~ ~ ~ ~" ~'~ 6wOrd)-~ capple 
(~) (gl word) = mr g2 g3 g4 g5 (g6 word) = apple 
Mr. Brown have eat an apple 
Figure 11 An example of a parsing tree and instantiation mechanism 
345 
grammar  ule are bound to tire designator "gn'.  
An example is shown in F igure 11. 
4.5 In terpretat ion  (F i l ter  It) 
After the pars ing proces.% in terpretat ion  schemata,  
in terpretat ion  schemata  wi th  a condit ion, condit ional  
schemata nd kil l  schemata re instant iated.  Interpreta-  
t ion schemata re interpreted by interpretat ion rule. Input  
is judged for consistency or inconsistency. 
The interp, 'etat ion schemata re independent,  thus the 
interpreted order is free. The in terpretat ion  flow is as 
follows. 
(1)check condit ional  schema: if i t  is an in terpretat ion  
schema with condit ion, f ind the paired condit ion.  I f  
condit ional schema are not paired, inh ib i t  the instant iated 
interpretat ion schema with a condition. 
(2)check k i l l  schemata :  i f  the k i l l  schema inc ludes  
interpretat ion schemata which should be killed, inh ib i t  the 
instant ia ted interpretat ion schema. 
(3) Interpretat ion rule: if i t  is not included, interpret  it. 
\ [ In terpretat ion  ru le  I 
An interpretat ion rule diagnoses the input  sentence.  
The schemata collected by an interpretat ion schema are 
checked by an interpretat ion rule. An interpretat ion rule 
synthesizes the word by us ing collected schemata.  The 
diagnosis process is as follows. 
(1)Find input  style from an interpretat ion schemata.  
(2)Synthesize correct style by ?using an interpretat ion rule. 
(3 )Compare  input  s ty le  w i th  synthes ized  s ty le ,  i f  
consistent, he input  style is right. If not, correct he input  
style to the synthesized correct style. 
An in terpretat ion  ru le synthes izes  the resu l t  w i th  
conditions from interpretat ion schema. For example, the 
I)ET-NOUN rule is Shown :in Table 2. This rule determines if 
the noun is corrected and  synthes izes the specif ication 
(SPEC) tbrm as adapted for the noun. 
(Example 1) In the case 0f correctly-formed noun phrase 
"an apple", the interpretat ion rule is shown in F igure 8. 
(1)input style: (gi word)=an,  (g i+l  word) = apple from 
surface schemata in F igure 8. 
(2 )synthes ized  s ty le :  cond i t ions  are  (~'NUM)=SG, 
( '~ SPEC1)= 'an/the' f rom noun and  ( i" SPEC) ='an'  f rom 
determinant  in F igure 8, the result  is (~ SPEC)=an from 
Table 2 Interpretation Rule for DET-NO_ UN 
Rule No. I 
1 
2 
3 
4 
5 
7 - - ,  
9 
10 I 
I__!L_A 
Condit ions 
NUM SPEC1 
From noun From noun 
PL the 
PL a 
PL an 
PL ~D 
SG a/the 
SG a/the 
SG a/the 
SG an\]the 
SG an\]the 
SG an\]the 
SG X 
Result  
SPEC I SPEC 
Frem dot 
~-- I the 
"- I O 
*- I O 
a i a 
the I the 
-" I a 
an , an 
the I the 
- -  I an  
I X 
Rule B in Table E. 
(3)Compare '(gn word)== an' with '( t SeEC)=an '. Th~ value 
is the same. Thus this noun phrase is correctly.-ibrmedo 
(Example 2) In the case of' the ill~tbrmed noun phrase 
"(D apple" which lacks an article, the interpretat ion rules 
are shown in F igure 9. 
(1) input style: ~, (gj word) :--= apple fYom surface schemata. 
(2 )synthes ized  s ty le :  cond i t ions  are  (\]'NUM):=::\[~G, 
( 1" SPEC1) =: ~an/the' from noun,  the re~';ult is ( ~ SPI~C)---- an 
from rule 10 in Table 2. 
(3)Comparison O with ( $ SI'EC)=an, as a result  it lacl~:s the 
article "an". Add the surface constra int  "(gn -0.5 wo, rd):::c 
an"  beibre "(gn word) = capple". 
4.6 Er ror  eorrecL ion 
The error correction phase expla ins  the erroz to the 
user. For example, "*MR. F, rown have eat apple/~ the f:low 
of'error correction is shown in F igure 12. input  sentence i~ 
converted into surface schemata  and  parsed.  Sur face 
constraints and interpretat ion schemata re then obtained. 
These interpretat ion rules are diagnosed and three errors 
found; (1)SUBJ&A-FORM, (2)AUX&V.FORM and (3)DleT-.i'~OUN 
Input sentence: *MR. Brown have eat apple, 
. . . . . . .  -~-- - (Input processing) ............................... 
Surface schemata 
Word = \[(gl word):= mr, (g2 word) = brown, (g3 word) =: have, 
(g4 word) :: eat, (g5 word) =: apple\] 
Mark-: \[(gl mark) : period, (g5 mark) : comma\] 
Letter = \[(gl etter) := 1, (gI letter) == 2, (g2 letter) : 1\] 
:~ (Parsing and instantiation) 
Surface constraints from lexicon and grammar rules 
Word: ?\[(gl word) := cmr, (g2 word) : thrown, (g3 word) : ehave, 
(g4 word) :: coat, (g5 word) : eapple\] 
Mark:  c\[(gl mark) = cperiod, (g5 mark) =: cperiod\] 
Letter: c\[(gl letter) --- ?1, (g2 letter) : ?1 \] 
. . . . . .  -~- .... (Interpretation) "-~ .... . . . . . . . . . . . . . . . . . . . . . .  
Convert 
(1)SUBJ&A-FORM: (g3 word) = chave -~ (g3 word) :=(:has 
(2)AUX&V-FORM: (g4 word) = coat ~ (g4 word) =ecaten 
(3)DET-NOUN: (g5 word) ~: apple 
~-~ (g4.5 word) = can, (g5 word) = apple 
(4)MARK: (g5 mark) : comma-+ (g5 mark) =:cperiod 
(5)LETTER: (gl letter) --~ 2 -~ 
. . . . . . .  -~- .... (Error corection) . . . . . . . . . . . . . . . . . . . . . . . . . . .  
Surface constraints replaced by synthesized schemata 
Word = e\[(gl word) = cmr, (g2 word) := ebrown, (g3 word) = ehas, 
(g4 word) = eeaten, (g4.5 word) = can, (g5 word) ::: eapple\] 
Mark-- e\[(gl mark) = epcriod, (g5 mark) = cperiod\] 
Letter =~ ?\[(gl letter) --- el, (g2 letter) =: el \] 
the correct sentence : )\]/r. Brown has eaten an apple. 
the reason : 
1)"have" must be "has". 
2)"eat" must be "eaten". 
3)" an" is needed befbx'e "apple". 
4)"W' in "MR" must be a small etter. 
5)"comma" af~er "apple" mu~t bc "period'*. 
Figure 12 An example of error correction 
346, 
(;,Vigure 10), Fmih~('w_ore, surface errors, (4)MARK and 
(5)I,ETTER, a~'e l~rlmd by the difference between surface 
:~chen-mta at~d surface constraints. The surface constraints 
are replac?~d by ~;ynthesized schemata. The corrected 
seaten,:e, "Mr. Brown has eaten an apple. ", is then 
synthe~:.;zed ~Yom surface constraints. The explanat ions 
1) ~ ?5) are g, mcrated by tim result of interpretation rule. 
This i}'m~,ework toa CAI ~;ystem, cal led" :\],~ :,i{}(English) 
(JA\["~ was applied and designed to teach English to junior 
hiKh ;-mimol students. This :.~y~tem has two main modules; 
( l)machine translat ion/Kudo 19g(i/and (2)this Crm,lework. 
If stm!e~t~: p~'oda(:?~ ill..fiwmed English int)nL, the sy~tem 
corrects the errors arid shows why they are wren F. If there 
are no erro~'s~ gi~e sentence i.~ translated into Japanese. 
This sy,~i.em was implemented i~ Prolog (about 120KB). 
Performam~e is reul-.tir~,e (answers wi th in  5 seconds). 
Actually t,his system was ilscd by jun ior  h igh school 
st,dents? We collected mistakes and then ted back to th,; 
system? 
This ~Lystem is one of applications of this \]Yamework in a 
limited d(m) aii). The framework is easy to apply to another 
domain. To construct a m',,v system, only need be changed 
the grammar, dictionary and interpretation rulcs. 
6, i~imitati,, m and fu tm,e  worl~ 
The ti'a:mework/b.c grammatical ly ill...Ibrmed input was 
described~ (1'he following problems remain unsolved: 
(1)The _ Im ui(m of semantically i l ldbrmed input: in this 
framework a semantically ill-..formed sentence is passed. A 
scma~,~.ic i i ~er mast be added alter filter ( l I ). 
(2)The problem of interpretation: interpretation is often 
changed by context and situation. Human beings correct 
ill-formed sentences by recognizing context and situation. 
Fo~" example, I1, is a boy? 
Which ic Lerpre~ation is right, dialogue situation, word.. 
order error Cls he a boy ?) or misimnctuation (He is a bay.)? A 
system wil) need a context recognizer and a s i tuat ion 
recognizer~ 
C(meiasio~ 
This paper has suggested the schema method, a new 
i~amework tbr correcting ill-formed input. This fl'amework 
recognizes input at two steps with weak and strong filters. 
When it is known what sentences are passed by the filter, 
it ca~ be u:~ed even if' imperfect. This method has the 
tbllowing ad vantages: 
Cl)the proL(\[cul of control strategies for relaxation can be 
avoided beet ase the relaxation teelmiqae is not used, and 
(2)comfmtational efficiency? 
The LF(i~ floamework tbr correcting grannaatically ill- 
fi)~-med input was extended; a. mlrface schema and an 
i~terpreta t ion  schema have  bee~ proposed.  Th is  
fl"arnework ca~, correct enters wi thout  break ing  LFG 
fi 'amework, because these schm~mta, as well  as LFG 
schema, cab be treated. Therefbre to make an applied 
system is very easy. This tYamework was implemented in 
Prolog to devise.a ~J~ef'ul CAI system? 
Acknowledgment  
We would like to thank Akira Kurematu, president of 
ATR Interpreting Telephony Research Laboratories (ATR) 
and Mr.Yada, president of CSK Research Institute (CRI) 
for their constant encouragement. And we would also like 
to acknowledge the helpful comments of Hitoshi Iida 
(ATR). Many thanks also to Hideo Kobayashi (Nishi- 
Sugamo Junior High School), Kenji Okamoto, Yoshio 
Ooyama, Kei Okabe and Syuuichi Tanaka (CRI). 
References  
Carboneli, J.G.&IIayes, P.J. (1983)' Recovery Strategies for Parsing 
Extragramnmtical L nguage' American Journal of Computatienal 
Linguistics, Volume 9, pp.123-146. 
/iayes, P.J & Mouradian, G.V. (1981) 'Flexible Parsing' American 
Journal of Computational Linguistics, 7(4), pp.232-242. 
lteidorn, G.E. (1982) 'Experience with an Easily Computed Metric for 
Ranking Alternative Parses' Proceeding of 20tll Annual Meeting of 
the ACL. Totont, Canada, pp.82-84. 
lleidorn, G.E,, Jensen, K., Miller, L.A. Byrd, R.J. and Codoro, M.S. 
(1982} 'The EPISTLE Text-Critiquing System' IBM Systems 
Journal 21 (3), pp.305-326. 
Jensen, K., IIeidorn, G.E., Miller, I,A. and Ravin, Y. (1983) 'Parse 
Fitting and Prose Fixing: Getting a Hold on ill-formedness' 
American Journal of Computational Linguistics, Volume 9, 
Number 3-4, July-December, pp.147-160. 
Kaplan, R.M.& Bresnau, J. (1982) 'Lexical-Functional Gramnmr: A
Formal System for Grammatical Representation' In:Bresnan, d. 
(ed) 'The Mcmtal Representation of Grammatical Relations', The 
MIT Press, Cambrige, Massachusetts, pp. 173-281. 
Katie, 1. & Nomura, H. (1986) 'LexicaLfunctional Transfer: A Transfer 
Framework in a Machine Translation System Based on LFG', 
Proceeding of 11th International Conference on Computational 
Linguistics, Bonn, August, pp.112-114. 
Kwasny, S.C. & Sondheimer, N.K. (1981) 'Relaxation Techniques for 
Parsing Grammatically Ill-formed Input in Natural Language 
Understanding Systems' Ammqcan Journal of Computational 
Linguistics, Vol. 7, Number 2, April-June, pp.99-108. 
Matmnoto, I.& Matumoto, Y. (1976) 'A Practical IIandbook of 
Common Mistakes in English among Japanese Students and 
Businessmen', ltokuseido 
Schank, R.C .& Leboeitz, M. & Birnbaum, L. (1980) 'An Integrated 
Understander' American Journal of Cmnputational Linguistics, 
Volume 6, Number 1, January-March, pp.13-30. 
Schuster, E.(1985) 'Grammar as user models' Proceedings ofthe Nineth 
International Joint Conference on Artificial Intelligence, August, 
Los Angeles, California, pp.20-22 
Weischedel, R.M. & Black, I.E. (1980) 'Responding Intelligently to
Unparsable Inputs' American Journal of Computational 
Linguistics, Volume 6, Number 2, pp.97-109. 
Weischedel, R.M. & Sondheimer, N.K. (1982) 'An hnproved Ileuristic 
for Ellipsis Processing' Proceeding of 20th Annual Meeting of the 
ACL. To(on(, Canada, pp.85-88. 
Weischedel, R.M. &'Sondheimer, N.K. (1987) 'Meta-rules as a Basic for 
Processing Ill-formed Input' ln;R.G.Reilly (ed.) Cmnmunieation 
Failure in Dialogue and Discourse, Elsevier Science Publishers 
B.V. (North-Holland), pp.99-120. 
347 
