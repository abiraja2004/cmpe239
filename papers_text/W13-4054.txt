Proceedings of the SIGDIAL 2013 Conference, pages 349?353,
Metz, France, 22-24 August 2013. c?2013 Association for Computational Linguistics
Counseling Dialog System with 5W1H Extraction 
 
 
Sangdo Han, Kyusong Lee, Donghyeon Lee, Gary Geunbae Lee 
Department of Computer Science and Engineering, POSTECH, South Korea 
{hansd,kyusonglee,semko,gblee}@postech.ac.kr 
 
  
 
Abstract 
In this paper, we introduce our counseling dia-
log system. Our system interacts with users by 
recognizing what the users say, predicting the 
context, and following the users? feelings. For 
this interaction, our system follows three basic 
counseling techniques: paraphrasing, asking 
open questions, and reflecting feelings. To fol-
low counseling techniques, we extracted 
5W1H information and user emotions from 
user utterances, and we generated system ut-
terances while using the counseling techniques. 
We used the conditional random field algo-
rithm to extract 5W1H information, and con-
structed our counseling algorithm using a dia-
log strategy that was based on counseling 
techniques. A total of 16 adults tested our sys-
tem and rated it with a higher score as an in-
teractive communicator compared with the 
baseline system. 
1 Introduction 
Over the past 45 years, suicide rates have in-
creased by 60% worldwide.1 To prevent suicide, 
suicide people need to counsel with counselors. 
However, counseling with a human counselor 
requires a substantial cost, and in addition, there 
is a location restriction. Developing a counseling 
dialog system could be an effective solution to 
address this problem because the system has no 
limitations with respect to time and location. 
In this study, we present a counseling dialog 
system. The system interacts with users by rec-
ognizing what the users say, predicting the con-
text, and following the users? feelings. We used 
three counseling techniques for our system, to 
interact with the users. The system performs par-
aphrasing, asks open questions, and reflects feel-
ings. 
                                                 
1 
http://www.who.int/mental_health/prevention/suicide/suicid
eprevent/en/ 
Paraphrasing is a technique that paraphrases 
user utterances. For example, when a user utter-
ance is ?My dog picked up the ball?, then it 
could be paraphrased by ?Oh, your dog picked 
up the ball?. The technique of asking open ques-
tions is to ask some questions to the user, to ob-
tain more information. For example, when a user 
says ?I played computer games?, then the coun-
selor could say ?When did you play?? or ?Where 
did you play??. Finally, reflecting a feeling is a 
similar technique to paraphrasing, but it includes 
emotional comments. For example, when a user 
says ?My dog died. I?m so sad?, then the counse-
lor could say, ?Oh, your dog died. You look de-
pressed.? or ?You look so sad?. 
In our approach, we extract 5W1H (who, what, 
when, where, why, how) information and four 
basic emotions (happy, afraid, sad, and angry) 
from user utterances. We generate system utter-
ances using 5W1H information and basic emo-
tions. 
2 Counseling Techniques 
Counselors show empathy with clients by listen-
ing and understanding them. Clients feel com-
fortable by a counselor?s attention. Counselors 
listen, ask questions, answer questions, and con-
centrate on clients. Attention and empathy is im-
portant for counseling. Counselors show interest 
and care about the clients? emotions. Our coun-
seling dialog system also focused on attending 
and empathy. 
Many counseling techniques are used in coun-
seling. Basic attending, self-expression, and mi-
cro-training skills are introduced in Theron et al 
(2008). Basic attending and self-expression skills 
are about non-verbal behavior, such as tone of 
voice and eye contact. Micro-training skills are 
the basic verbal counseling techniques that are 
learned for counseling beginners: open and 
closed questions, minimal encouragement, para-
phrasing, reflection of feelings and summariza-
tion. 
349
We chose three micro-training skills to attend 
and show empathy with clients. These skills are 
open questions, paraphrasing, and reflection of 
feelings because they are basic techniques to 
show emphasize effectively. 
3 Related Work 
The SEMAINE project aims to build a Sensitive 
Artificial Listeners (SAL) ? conversational 
agents that are designed to interact with a human 
user through robust recognition and the genera-
tion of non-verbal behavior (Schr?der et al, 
2008). This system detects user emotions by 
multimodal sensors (camera, microphone). A 
virtual face in this system shows facial expres-
sions based on user emotions, and it encourages 
the user to speak by reacting and asking ques-
tions. These techniques could show empathy 
with users. However, it has limited verbal skills 
because SEMAINE does not have language un-
derstanding module. In our research, our system 
follows user utterances and generates system ut-
terances based on user?s 5W1H. 
4 Data Collection 
We generated 4,284 utterances by using fifty-
three 5W1H information sets and four basic 
emotions (Figure 1). Each utterance could be 
generated by using part of the 5W1H information 
and four emotions. 
 
Wh When Where What How Why
My 
om
Yesterday Park Key Lost
Her pocket
was punctured
Emotion
Sad
My mom lost key yesterday.
Yesterday, my mom lost key at the park.
Sadly, my mom lost key yesterday.
My mom lost key because her pocket was punctured.
Given Situation
Collected Corpus
 
Figure 1. Counseling Corpus Collecting Process 
 
We tagged each 5W1H element in each utter-
ance and the user intention for each utterance 
(Table 1). The system?s actions were labeled by 
following counseling strategies which will be 
discussed in section 5.3. 
 
Tagged Corpus User Intention System Action
<who>My mom</who> <how>lost</how> <what>a 
key</what> <when>yesterday</when>.
Inform_5W1H Ask_Open_Question
<when>Yesterday</when>, <who>my mom</who> 
<how>lost</how> <what>a key</what> at the 
<where>park</where>.
Inform_5W1H Paraphrase
<who>My mom</who> <how>lost</how> <what>a 
key</what> <when>yesterday</when>. I?m so sad.
Inform_5W1H_
Emotion
Reflect_Feeling
I?m so sad. Inform_Emotion Reflect_Feeling
Thank you. Thank Welcome
Good bye. Bye Bye
 
Table 1.  Corpus Tagging Examples 
 
User intentions we defined can be separated in 
two groups: ?counseling? and ?others?. Utterances 
in ?counseling? group include 5W1H information 
or emotional information. Utterances which do 
not including them are in ?others? group. Greet-
ings, thanks, and farewells are included (Table 2). 
 
Couns ing group Others group
Inform_5W1H,
Inform_emotion, 
Inform_5W1H_emotion, ?
Thank, Bye, Greeting, Agree, 
Disagree,?
 
Table 2. Two Separated Groups of User Intentions 
5 Method 
5.1 Architecture 
Our system architecture is given in graph 2. 
When a user inputs a sentence, a natural lan-
guage understanding (NLU) module understands 
the main action (the user?s intention) and extracts 
the 5W1H entities from the user?s utterance. The 
emotion detection module detects the user?s 
emotions using the emotional keyword diction-
ary. The dialog management module decides the 
system?s action from the main action and the 
5W1H information from the trained module from 
the example dialog corpus. The natural language 
generation (NLG) module generates the system 
utterance using a system utterance template. We 
can generate the system utterance by replacing 
5W1H slots with entities. 
 
User
Natural 
Language 
Understanding
Dialog 
Manager
Natural 
Language 
Generation
Dialog 
Template
Emotion 
Detector
Output
Emotional 
Keyword
 
Figure 2. Counseling Dialog System Hierarchy 
350
5.2 Natural Language Understanding 
In our approach, the NLU module understands 
the user utterance by classifying the main action 
and the 5W1H entities from the user utterance. 
To classify user intention, we used maximum 
entropy model (Ratnaparkhi, 1998) trained on a 
linguistically motivated features. We used a lexi-
cal word features for the utterance model. The 
lexical word features are lexical trigrams using 
previous, current, and next lexical words. To ex-
tract 5W1H entities, we used a conditional ran-
dom field (CRF) model (Laffery et al, 2001). 
We also used lexical word features (lexical tri-
grams) to train model. 
5.3 Dialog Management with Counseling 
Strategy 
When we extract 5W1H information or user 
emotions, the dialog management module keeps 
them in the emotion slot or in the six 5W1H slots. 
This slot information is discussed in a dialog. 
The dialog management module decides the 
system?s action by the main action, the 5W1H 
entities, and the user?s emotions. Dialog man-
agement follows the rules in figure 3, which is 
our dialog strategy for the counseling system. In 
figure 3, ?Counseling group?? node finds users 
intentions included in ?others group? (rejection or 
thanks could be included). The ?User Emotion 
Detection? node figures out whether the user ut-
terance is to include emotional keywords or 
whether the user emotion is already known by 
the discourse. The ?6 slot empty? node checks 
whether the user utterance includes at least one 
of the 5W1H elements or whether the 5W1H en-
tity is already known. The ?6 slot full? node de-
cides whether the user utterance with a discourse 
has all six 5W1H entries. From this strategy, we 
can notice that we cannot reflect a user?s feeling 
without the user?s emotion. We cannot ask open 
questions when all of the 5W1H slots are filled. 
 
Yes
No
No
No
No
No
Yes
No
Yes
YesYes
Yes
6 slot 
empty
6 slot 
full
6 slot 
empty
6 slot 
full
Counseling 
group?
User 
Utterance
User 
Emotion 
Detection
Particular 
System Actions
Ask Open 
Question
Reflect
Feeling
Ask Open 
Question
Reflect
Feeling
Paraphrase
Ask Open 
Question
Paraphrase
Reflect 
Feeling
Paraphrase
Ask Open 
Question
Paraphrase
 
Figure 3. Dialog Strategy Architecture 
5.4 Emotion Detection 
The emotion detection module decides the user?s 
emotion with respect to the four basic emotions. 
To detect the user?s emotions, we find emotional 
keywords in the user?s utterances. If any emo-
tional keyword appears in a user utterance, we 
decide that the user?s emotion which includes 
that keyword. For this approach, we made a dic-
tionary of emotional keywords for each basic 
emotion. The dictionary has approximately 15 
emotional keywords for each basic emotion (Ta-
ble 3). 
 
E otion Keywords
Happy happy, joy, glad, pleasure, ?
Sad sad, depress, grief, sorrow,?
Angry anger, rage, indignation, wrath, ?
Afraid afraid, fear, terror, dread, ?
 
Table 3. Emotional Keywords for Emotions 
5.5 Natural Language Generation 
The NLG module generates the system?s utter-
ances by selecting an utterance template from the 
template database. There are various system 
templates for each system action, for the 5W1H 
slot entities, and for the user?s emotions (Figure 
4). When the system template is chosen, we can 
generate system utterances by replacing the 
5W1H slot with a 5W1H discourse. ?O? means 
we should have the entity, ?X? means we do not 
have the entity, and ?*? means we do not care 
whether we have the entity or not. 
 
Who When Where What How Why Emotion System Action
O X O O O X O Reflect Emotion
O X O O O X * Paraphrase
System Action System Template
Reflect Emotion Oh, <who> <how> <what>. You look so sad.
Paraphrase Oh, did <who> <how> <what>?
System Utterance
Oh, your mom lost a key. You look so sad.
Oh, did your mom lost a key?
Who When Where What How Why
My 
mom
Yesterday Park Key Lost
Her pocket
was punctured
Emotion
Sad
 
Figure 4. System Utterance Generation 
 
Our overall counseling dialog example is shown 
in (Table 4). 
351
 User My mom lost a key yesterday.
System Oh, where did you mom lost a key?
User At the park.
System Your mom lost a key at the park, right?
User Yes, that?s right. I?m so sad.
System You look so sad. Cheer up.
User Thank you.
System My pleasure.
 
Table 4. Counseling Dialog Example 
6 Experiment 
We measured how systems show empathy with 
users. Our baseline system is a Korean chat-
oriented dialog system (Kim et al, 2012). The 
chat-oriented dialog system shows empathy by 
understanding user utterances and making a con-
versation. In our experiment, 7 basic situations 
are given for each person. Situations are ex-
plained by 5W1H, and users generated various 
utterances using that information. Each person 
generated approximately 100 utterances during 
30 minutes and made estimates for each system. 
We recruited 16 volunteers to use our system and 
to estimate its effectiveness. Each user checked 
17 questions from 1 to 10. The questions ask us-
ers how does each system understand the user 
utterance, is it appropriate for counseling, and 
does it satisfy the users (Table 5). 
 
Question
Chat-
Oriented
Counseling
1-1. The system used counseling techniques: 
paraphrasing, open question, reflect feeling.
3.50 7.06
1-2. The system knows my emotion. 3.44 6.88
1-3. There was no break in the conversation. 2.63 6.88
1-4. The system acts like a counselor. 2.88 6.69
1-5. The system shows empathy with me. 4.69 7.31
1-6. I feel the system understands me. 2.56 6.50
2-1. The system understands what I said. 2.88 6.81
2-2. The system understands 5W1H information. 4.13 7.44
2-3. System utterances are appropriate. 2.75 6.94
2-4. System utterances have no problem. 3.50 5.50
3-1. I could speak about various situations. 4.31 6.38
3-2. I had a casual conversation. 4.75 6.88
3-3. Scenarios look expandable. 5.50 7.63
4-1. I satisfied overall conversation. 3.10 6.56
4-2. I satisfied overall counseling. 2.38 6.56
4-3. The system looks appropriate as a counselor. 2.50 6.38
4-4. I?ll recommend the system as a counselor to my
friends.
2.31 5.38
Mean 3.40 6.69
Standard Deviation 0.96 0.59
 
Table 5. Experiment Results 
 
Questions 1-1 to 1-6 ask users how each sys-
tem is appropriate as a counselor. Counseling 
system rated 6.89 for mean. Questions 2-1 to 2-4 
are about users? tterances understandability. In 
these questions, counseling system rated 6.67 on 
the average. Questions 3-1 to 3-3 show how var-
ious dialogs covered. Our system got 6.96 for 
mean. Finally, questions 4-1 to 4-4 are about 
overall satisfaction. These questions rated 6.22 
for mean. Our p-value through t-test was 
3.77*10-11. 
Counseling system got higher score than chat-
oriented system because users felt empathy better 
with our system than baseline system. As a coun-
selor, counseling system is much better than 
chat-oriented system. Our baseline system was 
not appropriate as a counselor because it rated 
3.39 for average. However, our system scored 
over 6.5 overall. It means our system is valuable 
as a counselor.  
7 Conclusion 
In this study, we introduced counseling tech-
niques that we used to implement counseling 
dialog system. The experimental results showed 
that our system shows empathy with users. Alt-
hough the results of this study bring us a step 
closer to implementing counseling dialog system, 
the results are only valid with 5W1H information 
in Korean. Our future works are to improve our 
counseling dialog system using new NLU mod-
ule which extracts 5W1H information from more 
general utterances, with new emotion detection 
method, and with more counseling techniques. 
 
Acknowledgments 
This research was supported by the Basic Sci-
ence Research Program through the National Re-
search Foundation of Korea(NRF) funded by the 
Ministry of Education, Science and Technolo-
gy(2012-0008835). 
This research was supported by the 
MSIP(Ministry of Science, ICT&Future Plan-
ning), Korea, under the ITRC(Information Tech-
nology Research Center) support program super-
vised by the NIPA(National IT Industry Promo-
tion Agency) (NIPA-2013-H0301-13-3002) 
References  
Kim, Y., Noh, H., & Lee, G. G. (2012). Dialog man-
agement on chatting system based on lexico-
syntactic patterns and named entity types. Proceed-
ings of Spring Conference of Korean Society of 
Speech Sciences, 41-42,  Seoul, Korea. 
352
Lafferty, J., McCallum, A., & Pereira, F. (2001). 
Conditional random fields: Probabilistic mod-
els for segmenting and labeling sequence data. 
Proceedings of the 18th International Confer-
ence on Machine Learning, 282-289. 
Ratnaparkhi, A. (1998). Maximum entropy models 
for natural language ambiguity resolution. 
Computer and Information Science, University 
of Pennsylvania, Philadelphia, USA.  
Schr?der, M., Cowie, R., Heylen, D., Pantic, M., Pe-
lachaud, C., & Shuller, B. (2008). Towards re-
sponsive sensitive artificial listeners. Workshop 
on Human-Computer Conversation, Bellagio, Italy. 
Theron, M. J. (2008). A manual for basic relational 
skills training in psychotherapy. Masters of Arts 
in Clinical Psychology, University of South Africa, 
South Africa. 
353
