Packing of Feature Structures for 
Efficient Unification of Disjunctive Feature Structures 
Yusuke  Miyao  
Department of Information Science, University of Tokyo 
7-3-1 Hongo, Bunkyo-ku, Tokyo 113-0033 Japan 
E-mail: yusuke~is ,  s .u - tokyo ,  ac. jp  
Abst rac t  
This paper proposes a method for packing fea- 
ture structures, which automatically collapses 
equivalent parts of lexical/phrasal feature struc- 
tures of HPSG into a single packed feature struc- 
ture. This method avoids redundant repetition 
of unification of those parts. Preliminary exper- 
iments show that this method can significantly 
improve a unification speed in parsing. 
1 In t roduct ion  
Efficient treatment of syntactic/semantic ambi- 
guity is a key to making efficient parsers for 
wide-coverage rammars. In feature-structure- 
based grammars 1, such as HPSG (Pollard and 
Sag, 1994), ambiguity is expressed not only 
by manually-tailored disjunctive feature struc- 
tures, but also by enumerating non-disjunctive 
feature structures. In addition, there is ambigu- 
ity caused by non-determinism when applying 
lexical/grammar rules. As a result, a large num- 
ber of lexical/phrasal feature structures are re- 
quired to express ambiguous syntactic/semantic 
structures. Without efficient processing of these 
feature structures, a sufficient parsing speed is 
unattainable. 
This paper proposes a method for packing 
feature structures, which is an automatic op- 
timization method for parsers based on feature 
structure unification. This method automati- 
cally extracts equivalent parts of feature struc- 
tures and collapses them into a single packed 
feature structure. A packed feature structure 
can be processed more efficiently because we can 
avoid redundant repetition of unification of the 
equivalent parts of original feature structures. 
There have been many studies on efficient 
1In this paper we consider typed feature structures 
described in (Carpenter, 1992). 
unification of disjunctive feature structures 
(Kasper and Rounds, 1986; Hasida, 1986; DSrre 
and Eisele, 1990; Nakano, 1991; Blache, 1997; 
Blache, 1998). All of them suppose that dis- 
junctive feature structures hould be given by 
grammar writers or lexicographers. However, 
it is not practical to specify all ambiguity us- 
ing only manually-tailored disjunctive feature 
structures in grammar development. Where dis- 
junctive feature structures cannot be given ex- 
plicitly those algorithms lose their advantages. 
Hence, an automatic onversion method, such 
as the packing method escribed hereafter, is re- 
quired for further optimization of those systems. 
In addition, this packing method converts gen- 
eral feature structures to a suitable form for a 
simple and efficient unification algorithm which 
is also described in this paper. 
Griffith (Griffith, 1995; Griffith, 1996) points 
out the same problem and proposes a compila- 
tion method for feature structures called mod- 
ularization. However, modularization is very 
time-consuming, and is not suitable for opti- 
mizing feature structures produced uring pars- 
ing. An earlier paper of myself (Miyao et al, 
1998) also discusses the same problem and pro- 
poses another packing method. However, that 
method can pack only pre-specified parts of 
input feature structures, and this characteris- 
tic limits the overall efficient gain. The new 
method in this paper can pack any kind of fea- 
ture structures as far as possible, and is more 
general than the previous method. 
2 Data  Structure and Algor i thms 
This section describes the data structure of 
packed feature structures, and the algorithms 
for packing and unification of packed feature 
structures. Through of this section, I will refer 
to examples from the XHPSG system (Tateisi 
579 
PHON <'o'ed~o'~ 
r F F.E~O verb ] ]  
? CArl HEAD / L , I  r:- [] =_=o,,]> / I u~ /VAL I L 
SYNSEM ILOC~LI p ICOMP$ Am 
/ I L LSPR <> 
/ ::l tv~. rcred.edl -I I .  I-:'"' LA~G~ [~J 
- word 
PHON <'cre~eo'> 
s~se~ 
.NONLOC IINHERISLASH ~T~ 
" ',~ocd 
PHON <'cr~led> 
r FHEAO ,,~, 
I I P FCATIHEAD r.o~ - I -  
/~T  L: I.SUm <Lco~ [] ~o~J, ! Iv" m 
; " CATI HEAD noun 
NONLOCII~HERISLASH<[cONT [ ]  nom_obJ] > 
FHE~ verb "1 
CATI HEAD noun SUBJ < : > r [] 1/ / >// 
L LSPR < > J J 
r r .~  .~  ] ]  
? CATI HF.),D ~o~ t., I <[co,, [] _oJ> 1// 
I ''~ /VAL/coMP ~ noun - I>/ / /  
 -1:1 / 
I: L LSPR <> J J /  
I 
Figure 1 :4  out of 37 lexical entries which the 
XHPSG system assigns to the word "credited". 
Parts shaded with the same pattern are equivalent. 
et al, 1998), an HPSG-based grammar for En- 
glish. 
2.1 Packed Feature  St ructure  
Figure 1 shows 4 out of 37 lexical entries which 
the XHPSG system assigns to the word "cred- 
ited". These lexical entries have various equiva- 
lent parts in their respective feature structures. 
In Figure 1, equivalent parts are shaded with 
the same pattern. 
Figure 2 shows a packed feature structure for 
the lexical entries shown in Figure 1. Note that 
the equivalent parts of the original feature struc- 
tures are collapsed into a feature structure seg- 
ment, which is denoted by Si in Figure 2. So is 
a special segment called the root segment, which 
"word 
; PHON <'crecl~ad'> 
I" ['HEAD ,~b 
/ / [SU=<[CATI"EAD"?"] 1 So : LOCAL CAT VAL CONT A, 
1 / L LSPR o 
l LCOm 
LNONLOCI NHERI SLASH A,  
S,  : nomobj rcreditedl ] 
S= : I~] S ,  : LARG1 AT] 
$ 4 : noun 
i-CATIH~O no.n'l S e : nomobj  S 1, " < > 
s,: ,o~_o~j L~ A,o J 
~, ' ->  S I' 
I a2 -*  S ~/ I /%- )  S ,  
D,=Iz~s-*Ss/  D=_IzS,-*S,,  
I ~ , ' *  S,ol - I  ~5c-* S ,  
LL~,-* S, J  I z36-~$6 
kZ~o-* S e 
I /%-* S 31 I ~- - "  S =/ I /%-* S o/ 
I A~-*S , |  D,_IZ~,-*S,ol D~ =1 A, -*  S . I  I ~5~'-* S ~/ -I ~Sr* S 5/ I ZS,-" S,/ I zSs--* S 6/ I ~Se-" S , /  LZS,~ S U LZ~9_~ S , j  
Figure 2: A packed feature structure xpressing 
the same information as the set of feature structures 
in Figure 1. Shaded parts correspond to the parts 
with the same pattern in Figure 1. 
describes the root nodes of all original feature 
structures. Each segment can have disjunctive 
nodes, which are denoted by Ai. For example, 
53 has two disjunctive nodes, A 5 and A6. A de- 
pendency function, denoted by Di, is a mapping 
from a disjunctive node to a segment, and each 
Di corresponds to one original feature structure. 
We can obtain each original feature structure by 
replacing each disjunctive node with the output 
of the respective dependency function. 
For applying the unification algorithm de- 
scribed in Section 2.3, we introduce a con- 
dition on segments: a segment cannot have 
inter- or intra-segment shared nodes. For ex- 
ample, the disjunctive node i 1 in Figure 2 
must be introduced for satisfying this con- 
dition, even though the value of this node 
is the same in all the original feature struc- 
tures. This is because this path is structure- 
shared with another path (SYNSEHILOCALJCONT j 
ARG1 and SYNSEHJLOCALJCONTJARG2). Structure- 
sharing in original feature structures is instead 
expressed by letting the dependency function 
return the same value for different inputs. For 
example, result values of applying D1 to A1 and 
A7 are both S1. 
The reason why we introduce this condition 
is to guarantee that a disjunctive node in the 
580 
r _  
IPHON <'cmd~e~> 
So: /  FCAT F HEAD verb 
0 T credited/ L P" L,.o, ,,,J 
$1 : John 
$2 : Yusuke 
D,=E At-~S,3 D2=EA,-~S2\] 
Figure 3: A sample packed feature structure. If it is 
unified with the top feature structure in Figure 1, a 
new disjunctive node must he introduced to SYNSRM I
LOCALICATJVALJSUBJ IFIRSTICONT. 
result of unification will appear only at a path 
where a disjunctive node appears in either of the 
input feature structures at the same path. For 
example, suppose we unify the top feature struc- 
ture in Figure 1 with the packed feature struc- 
ture in Figure 3. In the result of unification, a
new disjunctive node must appear at SYNSEM I 
LOCALJCATIVALJSUBJJFIRSTJCONT , while no dis- 
junctive nodes appear in either of the input fea- 
ture structures at this path. By introducing 
such a disjunctive node in advance, we can sim- 
plify the algorithm for unification described in 
Section 2.3. 
Below I first describe the algorithm for pack- 
ing feature structures, and then the algorithm 
for unification of packed feature structures. 
2.2 A lgor i thm for Pack ing  
The procedure pack_feature_structures in 
Figure 4 describes the algorithm for packing two 
packed feature structures, denoted by (S',:D') 
and (,9", D"). ,9' and S" denote sets of seg- 
ments, and 7)' and 7)" denote sets of depen- 
dency functions. We start from comparing the 
types of the root nodes of both feature struc- 
tures. If either of the nodes is a disjunctive node 
(Case 1 ), we compare the type of the other fea- 
ture structure with the type of each disjunct, 
and recursively pack nodes with the same type 
if they exist (Case 1.1). Otherwise, we just 
add the other feature structure to the disjunc- 
tive node as a new disjunct (Case 1.2). If the 
types of the nodes are equivalent (Case 2), we 
collapse them into one node, and apply packing 
recursively to all of their subnodes. If they are 
not equivalent (Case 3), we create a new dis- 
junctive node at this node, and let each original 
procedure pack.~eatureJtructures((S', Do), (S", D"))  
begin 
~o ~ s'. s~' ~ s" 
7:) :=  ~)t U "/3 II  
re~ura (S, D) 
end 
procedure pach(F s, F H) 
hesin 
i~ F / (o r  F Is) is d is jzuct ion then 
i f  BG(G E diojuncts(F'). 
G a .d  F"  ha~e equivalent types) 1;hen 
S := SUd io juncts (F ' )  
pack(G. F" )  
Y~" := {DID"  E DH,D = D" U(F '  -- F")} 
else 
S := SUd is juncts (F I )u{F / '}  
7)" := {DID 'I E ~9", D = D"  u (F '  -- F")} 
endi:f 
e lse i:f F/ and F"  ha~e equivalent types then 
F' := F"  
~oreach f in features (F  I) 
pack(:foUoe(.f, F'), :follou(.f, F"))  
eloe 
S:= SU{F ' ,F"}  
F := 4io3uuctiYe-node 
D' := {DID' E ~) ' ,D  = D' U(F  -- F')} 
D"  := {DID"  6 D" ,D  = D"  U(F  -- F")} 
endif 
cud 
disjuucts: return a set of disjuncts of the disjunctive node 
:features: return a set of features 
:folios: return a substructure reached by the specified feature 
? Cuae  1 
? Case  1 ,1  
? (:~.ue 1.2 
? Case 2 
? Cese 3 
Figure 4: Algorithm for packing two packed feature 
structures (S',:D') and (S", $)"). 
feature structure from this node become a new 
segment. 
For simplicity, Figure 4 omits the algorithm 
for introducing disjunctive nodes into shared 
nodes. We can easily create disjunctive nodes 
in such places by preprocessing input feature 
structures in the following way. First each input 
feature structure is converted to a packed fea- 
ture structure in advance by converting shared 
nodes to disjunctive nodes. Then the above 
algorithm can be applied to these converted 
packed feature structures. 
2.3 Algor i thm for Uni f icat ion 
Below I describe the algorithm for unification of 
packed feature structures, referring to the exam- 
ple in Figure 2. Suppose that we are unifying 
this packed feature structure with the feature 
structure in Figure 5. This example consid- 
ers unification of a non-packed feature structure 
with a packed feature structure, although this 
algorithm is capable of unifying two packed fea- 
ture structures. 
The process itself is described by the pro- 
cedure unify_packed_feature_structures in 
Figure 6. It is quite similar to a normal uni- 
581 
"word 
PHON <'ged#eo'> I I - ;YNSEM LOCAL CAT / ~SUBJ < ECONT \ [ \ ]  -\] |VAL|c(:~PS \ [ \ ]  <> 
L LSPR < > 
CONTI ARG1 \ [ \ ]  
.NONLOC I INHER I SLASH list 
Figure 5: A sample feature structure to be unified 
with the packed feature structure in Figure 2. 
procedure unify.p?cked.te=ture.=tructuree((S e, ~)e). (Se, 7)1,)) 
begin 
S:=?.  Z>:=@ 
fore,oh D e E ~Ot and D ee E ~H 
IEXT: 
besin 
push-eeSm.~-sCack(S~0 E S/, S~' E S ' )  
do unti l  seipnen~-lCack.As-emp~y 
best.  
pop_ee~ment.o~ack(S I ,S/e) 
i~ S / ie  d i# j~ct lon  chert S* := D~(S ~) . . .  ( t )  
i f  S H is dlsj~nction ~hen S" := DH(S//) 
SEOHIIJ\]IIF? : 
if alread~-nni~ied(S/,S H) th~n ' ' .  (2) 
S :=restore2Jnify.reeul~( st,s/I ) 
~' := S, S" := S . . -  (3) 
else 
i f  S := un i fy (~,$ / I )  fa i l s  then 
Ko~o Ig l t  
else 
S:= ~u{S} 
s~s_unificasien.reeul~(S, S ~, ~e) 
S e := 5. S" := S (a) 
4ed~f 
endif 
e~d 
7:' := "D u {D ~ U D '}  
e~d 
recur. (S, ~)) 
e~d 
procedure unify(F',F '~) 
besin 
i~ F ~ or F ee le d~oj~.c~ion ~heu (6) 
F := disjunctive.node 
push_se~nt_stack(F / ,  F ?/) 
else 
IODB.UIIF? : 
F := uni fy Jype(F  ~, F ~ ) 
forea?h \] ~n featureo(F) 
fo l lou( f ,F ) :=  un i fy ( fe l lou( f ,F / ) ,  fellou(f,FH)) 
endif 
re~urn F 
oud 
already-unified: t~e when unification is already computed 
res~ere_uui~y_result: restore the result of unific&tion from 
the table 
seS_unify.xesul~: store the result of unification into the table 
unifyJype: return the unification of both types 
Figure 6: Algorithm for unifying two packed fea- 
ture structures (S',:D'} and (S",:D"}. 
fication algorithm. The only difference is the 
part that handles disjunctive nodes. When we 
reach a disjunctive node, we put it onto a stack 
(segment_stack), and postpone further unifi- 
cation from this node ((5) in Figure 6). In this 
example, we put A1, A2, A3, and A4 onto the 
stack. At the end of the entire unification, we 
"word 
PHON <'cred/ted> 
T A ,  SuN < 
So:  LOCAL CAT VAL COMPS 
SYNSEM | \] L LS PR <> 
| LCONT A ,  
LNONLOCIINHER\[ SLASH A4 
S,  : nom_obj ~credltedl 
S=: <> Ss: LARGt ATJ 
\[-CA~HEAD ~s  1 r'credited2 q 
s~: <Lco.T A, ." s s: IARa~ Ael 
$4 : .ou. LARG2 A*J 
Ss : bY S~o: <> 
Ss  : nom obj FCAT~HEAO noun-\] 
s ,  : .om obj s,,: <LCoNT A,o J> 
1~ . \ ] .  I As--* S sl 
O,=l ~s--" S e/ L,21" _-I\[/k,-* S,ol\]ks._. S , \ [  O~ .... 04 .. . .  
I/'.,-~ S ,ol I/Xs--* Sol 
L~7 -> S , J  I Ge-" S , /  
kL~s-* S sJ 
ae~t_s t=~ = ( As As A ,  } 
D =CZ~I'* S , \]  
Figure 7: Intermediate data structure after unify- 
ing A 1 with \[~. Disjunction is expressed by non- 
determinism when applying the dependency func- 
tions. When we unify a feature structure segment 
for A2, we unify $2 if we are applying Dz, or 53 if 
D2. 
apply a dependency function to each member 
of the stack, and unify every resulting segment 
with a corresponding part of the other feature 
structure ((1) in Figure 6). In this example, 
we apply D1 to A1, which returns segment 51. 
We therefore unify 5z with the feature structure 
tagged as \[~\] in Figure 5. 
Disjunction is expressed by non-determinism 
when applying the dependency functions. Fig- 
ure 7 shows the intermediate data structure af- 
ter unifying A1 with \[~\]. We are now focusing 
on the disjunctive node A2 which is now on the 
top of segment_stack. When we are applying 
Dz, we unify $2 with the corresponding feature 
structure \[~\]. Should we instead apply D2, 53 
would be unified. 
A benefit of this unification algorithm is that 
we can skip unification of feature structure seg- 
ments whose unification is already computed 
((2) in Figure 6). For example, we unify seg- 
ment So with the other feature structure only 
once. We can also skip unification of $1 and 5z0 
for /:)2, because the result is already computed 
582 
So:  
-word PHON <'credited'> 
/ / / Fsu~<F c^TIHEA?"?" 
/~OCAL/CAT/V~./ LCONT A, 
WNSEM| | | |CO~ /k= 
| | L LSPR <> 
/ L cONT Z~, 
LNON'OCIINHERISLASH Z~, 
F c'd''al 7 s,  : ,,om_~j s~ : LARG~ /k,J 
S= : <> S~o: <> 
FZ~,-, S,3 \ ]~-*  S =/ 
u, =1 4~s ''~ S ~/ 
I Z l , -*  S ,ol 
LZI~-" S,J 
D==... Ds=... D4=... 
aegmeat stac):  = ( A, } 
F~,-- S,7 
_ I A=- ,  S ~/ 
L/I, -~ S ,~1 
"word PHON <'cmditeo'> 
/ / / I-SU~<I-CATIH~O "" 
So: { LOCAL /CM/V/~L/COMPS LL~TT A, 
~YNSEM| / L LSPR <> 
| L c-,ONT Z~ 
LNONLOCIiNHERISLASH /k, 
S i : nom obj S s : nom_obj 
S~ : <> Ss  : <> 
F credi'ed! I rCATIHEAD noun\] 
S 3 : LABG I /ks_\] S, : < Lco~ A,  ? 
F credited# \]
S,  : |ARG1 L~| 
LARG2 /k,J 
FA,--> S ,7 
\[ ~=--> S , /  
u,=l/_~-~ S ~\] 
I ZM-" S e/ 
L/Is-* S ,J 
t/k,-~ S ,7 
I As*  S ~/ 
D,=I \]~,-> S, /  
I ~ , - "  S , /  
I/k7 -~ S s/ 
LZI,-* S 5J 
Figure 8: Intermediate data structure after the uni- 
fication of A4. Because the result of applying Dz to 
AT is already overwritten by the result of unifying 
51 within\], we unify this resulting feature structure 
with ff\]y 
for D1. This operation preserves the validity of 
unification because ach segment does not have 
inter- or intra-segment shared nodes, because of 
the condition we previously introduced. 
Note that this method can correctly unify fea- 
ture structures with reentrancies. For example, 
Figure 8 shows the intermediate data structure 
after unifying A4, and the process currently 
reached A7 and E\]" The result of the appli- 
cation of D1 to A7 is the result of unifying Sz 
with \[~, because Sz is overwritten with the re- 
sult of this previous unification ((3) and (4) in 
Figure 6). Hence, we unify E\] with this result. 
Above unification algorithm is applied to ev- 
ery combination of dependency functions. The 
result of the entire unification is shown in Fig- 
ure 9. 
3 Exper iments  
I implemented the algorithms for packing and 
unification in LiLFeS (Makino et al, 1998). 
LiLFeS is one of the fastest inference ngines 
for processing feature structure logic, and effi- 
cient parsers have already been realized using 
this system. For performance evaluation I mea- 
sure the execution time for a part of application 
of grammar ules (i.e. schemata) of XHPSG. 
Table 1 shows the execution time for uni- 
fying the resulting feature structure of apply- 
Figure 9: The resulting packed feature structure 
of unifying the packed feature structure of Figure 2 
with the feature structure of Figure 5. 
ing schemata to lexical entries of "Mary" as 
a left daughter, with lexical entries of "cred- 
ited"/"walked" as right daughters. Unification 
of packed feature structures achieved a speed- 
up by a factor of 6.4 to 8.4, compared to the 
naive approach. Table 2 shows the number of 
unification routine calls. NODE_UNIFY shows the 
number of nodes for which unification of types 
is computed. As can be seen, it is significantly 
reduced. On the other hand, SEGNENT_UNIFY 
shows the number of check operations whether 
unification is already computed. It shows that 
the number of node unification operations i sig- 
nificantly reduced by the packing method, and 
segment unification operations account for most 
of the time taken by the unification. 
These results indicate that a unification speed 
can be improved furthermore by reducing the 
number of the segment unification. The data 
structure of dependency functions has to be 
improved, and dependency functions can be 
packed. I observed that at least a quarter of 
the segment unification operations can be sup- 
pressed. This is one of the future works. 
4 Conc lus ion  
The packing method I described in this paper 
automatically extracts equivalent parts from 
feature structures and collapses them into a sin- 
gle packed feature structure. It reduces redun- 
dant repetition of unification operations on the 
583 
Table 1: Execution time for unification. Test data shows the word used for the experiment. # of LEs 
shows the number of lexical entries assigned to the word. Naive shows the time for unification with a naive 
method. PFS shows the time for unification of packed feature structures (PFS). Improvement shows the 
ratio ( gaive)/( PFS). 
Test data # of LEs Naive (msec.) PFS (msec.) Improvement (factor) 
credited 37 36.5 5.7 6.4 
walked 79 77.2 9.2 8.4 
Table 2: The number of calling each part of the unification routines. Naive shows the number of node 
unification operations in the naive unification algorithm (corresponds to NODE_UNIFY of my algorithm). 
NODE_UNIFY and SEGMENT_UNIFY are specified in Figure 6. 
Test data Naive NODE_UNIFY SEGMENT_UNIFY 
credited 30929 256 5095 
walked 65709 265 10603 
equivalent parts. I implemented this method in 
LiLFeS, and achieved a speed-up of the unifica- 
tion process by a factor of 6.4 to 8.4. For realiz- 
ing efficient NLP systems, I am currently build- 
ing an efficient parser by integrating the packing 
method with the compilation method for HPSG 
(Torisawa and Tsujii, 1996). While the compi- 
lation method reduces the number of unification 
operations during parsing, it cannot prevent in- 
efficiency caused by ambiguity. The packing 
method will overcome this problem, and will 
hopefully enable us to realize practical and effi- 
cient NLP systems. 
References 
Philippe Blache. 1997. Disambiguating with 
controlled disjunctions. In Proc. Interna- 
tional Workshop on Parsing Technologies. 
Philippe Blache. 1998. Parsing ambigu- 
ous structures using controlled disjunctions 
and unary quasi-trees. In Proc. COLING- 
ACL'98, pages 124-130. 
Bob Carpenter. 1992. The Logic of Typed Fea- 
ture Structures. Cambridge University Press. 
Jochen DSrre and Andreas Eisele. 1990. Fea- 
ture logic with disjunctive unification. In 
Proc. 13th COLING, volume 2, pages 100- 
105. 
John Griffith. 1995. Optimizing feature struc- 
ture unification with dependent disjunctions. 
In Proc. Workshop on Grammar Formalism 
for NLP at ESSLLI-94, pages 37-59. 
John Griffith. 1996. Modularizing contexted 
constraints. In Proc. COLING'96, pages 448- 
453. 
KSiti Hasida. 1986. Conditioned unification for 
natural language processing. In Proc. 11th 
COLING, pages 85-87. 
Robert T. Kasper and William C. Rounds. 
1986. A logical semantics for feature struc- 
tures. In Proc. 24th ACL, pages 257-266. 
Takaki Makino, Minoru Yoshida, Kentaro Tori- 
sawa, and Jun'ichi Tsujii. 1998. LiLFeS - -  
towards a practical HPSG parser. In Proc. 
COLING-A CL '98, pages 807-811. 
Yusuke Miyao, Kentaro Torisawa, Yuka Tateisi, 
and Jun'ichi Tsujii. 1998. Packing of fea- 
ture structures for optimizing the HPSG- 
style grammar translated from TAG. In Proc. 
TAG+4 Workshop, pages 104-107. 
Mikio Nakano. 1991. Constraint projection: An 
efficient treatment of disjunctive feature de- 
scriptions. In Proc. P9th ACL, pages 307-314. 
C. Pollard and I. A. Sag. 1994. Head-Driven 
Phrase Structure Grammar. University of 
Chicago Press. 
Yuka Tateisi, Kentaro Torisawa, Yusuke Miyao, 
and Jun'ichi Tsujii. 1998. Translating the 
XTAG English grammar to HPSG. In Proc. 
TAG+4 Workshop, pages 172-175. 
Kentaro Torisawa and Jun'ichi Tsujii. 1996. 
Computing phrasal-signs in HPSG prior to 
parsing. In Proc. 16th COLING, pages 949- 
955. 
584 
