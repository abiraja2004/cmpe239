An Expectation Maximization Algorithm for Textual Unit Alignment 
Radu Ion 
Research Institute for AI 
Calea 13 Septembrie nr. 13 
Bucharest 050711, Romania 
radu@racai.ro 
Alexandru Ceau?u 
Dublin City University 
Glasnevin, Dublin 9, Ireland 
[address3] 
aceausu@computing.dcu.ie 
Elena Irimia 
Research Institute for AI 
Calea 13 Septembrie nr. 13 
Bucharest 050711, Romania 
elena@racai.ro 
 
 
Abstract 
The paper presents an Expectation Maximiza-
tion (EM) algorithm for automatic generation 
of parallel and quasi-parallel data from any 
degree of comparable corpora ranging from 
parallel to weakly comparable. Specifically, 
we address the problem of extracting related 
textual units (documents, paragraphs or sen-
tences) relying on the hypothesis that, in a 
given corpus, certain pairs of translation 
equivalents are better indicators of a correct 
textual unit correspondence than other pairs of 
translation equivalents. We evaluate our 
method on mixed types of bilingual compara-
ble corpora in six language pairs, obtaining 
state of the art accuracy figures. 
1 Introduction 
Statistical Machine Translation (SMT) is in a con-
stant need of good quality training data both for 
translation models and for the language models. 
Regarding the latter, monolingual corpora is evi-
dently easier to collect than parallel corpora and 
the truth of this statement is even more obvious 
when it comes to pairs of languages other than 
those both widely spoken and computationally 
well-treated around the world such as English, 
Spanish, French or German. 
Comparable corpora came as a possible solu-
tion to the problem of scarcity of parallel corpora 
with the promise that it may serve as a seed for 
parallel data extraction. A general definition of 
comparability that we find operational is given by 
Munteanu and Marcu (2005). They say that a (bi-
lingual) comparable corpus is a set of paired doc-
uments that, while not parallel in the strict sense, 
are related and convey overlapping information.  
Current practices of automatically collecting 
domain-dependent bilingual comparable corpora 
from the Web usually begin with collecting a list 
of t terms as seed data in both the source and the 
target languages. Each term (in each language) is 
then queried on the most popular search engine and 
the first N document hits are retained. The final 
corpus will contain t ? N documents in each lan-
guage and in subsequent usage the document 
boundaries are often disregarded. 
At this point, it is important to stress out the 
importance of the pairing of documents in a com-
parable corpus. Suppose that we want to word-
align a bilingual comparable corpus consisting of 
M documents per language, each with k words, 
using the IBM-1 word alignment algorithm (Brown 
et al, 1993). This algorithm searches for each 
source word, the target words that have a maxi-
mum translation probability with the source word. 
Aligning all the words in our corpus with no regard 
to document boundaries, would yield a time com-
plexity of      operations. The alternative would 
be in finding a 1:p (with p a small positive integer, 
usually 1, 2 or 3) document assignment (a set of 
aligned document pairs) that would enforce the ?no 
search outside the document boundary? condition 
when doing word alignment with the advantage of 
reducing the time complexity to      operations. 
When M is large, the reduction may actually be 
vital to getting a result in a reasonable amount of 
time. The downside of this simplification is the 
loss of information: two documents may not be 
correctly aligned thus depriving the word-
alignment algorithm of the part of the search space 
that would have contained the right alignments. 
128
Proceedings of the 4th Workshop on Building and Using Comparable Corpora, pages 128?135,
49th Annual Meeting of the Association for Computational Linguistics,
Portland, Oregon, 24 June 2011. c?2011 Association for Computational Linguistics
Word alignment forms the basis of the phrase 
alignment procedure which, in turn, is the basis of 
any statistical translation model. A comparable 
corpus differs essentially from a parallel corpus by 
the fact that textual units do not follow a transla-
tion order that otherwise greatly reduces the word 
alignment search space in a parallel corpus. Given 
this limitation of a comparable corpus in general 
and the sizes of the comparable corpora that we 
will have to deal with in particular,  we have de-
vised one variant of an Expectation Maximization 
(EM) algorithm (Dempster et al, 1977) that gener-
ates a 1:1 (p = 1) document assignment from a par-
allel and/or comparable corpus using only pre-
existing translation lexicons. Its generality would 
permit it to perform the same task on other textual 
units such as paragraphs or sentences. 
In what follows, we will briefly review the lit-
erature discussing document/paragraph alignment 
and then we will present the derivation of the EM 
algorithm that generates 1:1 document alignments. 
We will end the article with a thorough evaluation 
of the performances of this algorithm and the con-
clusions that arise from these evaluations. 
2 Related Work 
Document alignment and other types of textual 
unit alignment have been attempted in various sit-
uations involving extracting parallel data from 
comparable corpora. The first case study is offered 
by Munteanu and Marcu (2002). They align sen-
tences in an English-French comparable corpus of 
1.3M of words per language by comparing suffix 
trees of the sentences. Each sentence from each 
part of the corpus is encoded as a suffix tree which 
is a tree that stores each possible suffix of a string 
from the last character to the full string. Using this 
method, Munteanu and Marcu are able to detect 
correct sentence alignments with a precision of 
95% (out of 100 human-judged and randomly se-
lected sentences from the generated output). The 
running time of their algorithm is approximately 
100 hours for 50000 sentences in each of the lan-
guages. 
A popular method of aligning sentences in a 
comparable corpus is by classifying pairs of sen-
tences as parallel or not parallel. Munteanu and 
Marcu (2005) use a Maximum Entropy classifier 
for the job trained with the following features: sen-
tence lengths and their differences and ratios, per-
centage of the words in a source sentence that have 
translations in a target sentence (translations are 
taken from pre-existing translation lexicons), the 
top three largest fertilities, length of the longest 
sequence of words that have translations, etc. The 
training data consisted of a small parallel corpus of 
5000 sentences per language. Since the number of 
negative instances (50002 ? 5000) is far more large 
than the number of positive ones (5000), the nega-
tive training instances were selected randomly out 
of instances that passed a certain word overlap fil-
ter (see the paper for details). The classifier preci-
sion is around 97% with a recall of 40% at the 
Chinese-English task and around 95% with a recall 
of 41% for the Arabic-English task. 
Another case study of sentence alignment that 
we will present here is that of Chen (1993). He 
employs an EM algorithm that will find a sentence 
alignment in a parallel corpus which maximizes 
the translation probability for each sentence bead 
in the alignment. The translation probability to be 
maximized by the EM procedure considering each 
possible alignment  is given by 
 
 (     )   ( )? ([  
    
 ])
 
   
 
 
The following notations were used:   is the 
English corpus (a sequence of English sentences), 
  is the French corpus, [  
    
 ] is a sentence bead 
(a pairing of m sentences in English with n 
sentences in French),  ([  
    
 ]   [  
    
 ]) 
is the sentence alignment (a sequence of sentence 
beads) and p(L) is the probability that an alignment 
contains L beads. The obtained accuracy is around 
96% and was computed indirectly by checking 
disagreement with the Brown sentence aligner 
(Brown et al, 1991) on randomly selected 500 
disagreement cases. 
The last case study of document and sentence 
alignment from ?very-non-parallel corpora? is the 
work from Fung and Cheung (2004). Their contri-
bution to the problem of textual unit alignment 
resides in devising a bootstrapping mechanism in 
which, after an initial document pairing and conse-
quent sentence alignment using a lexical overlap-
ping similarity measure, IBM-4 model (Brown et 
al., 1993) is employed to enrich the bilingual dic-
tionary that is used by the similarity measure. The 
129
process is repeated until the set of identified 
aligned sentences does not grow anymore. The 
precision of this method on English-Chinese sen-
tence alignment is 65.7% (out of the top 2500 iden-
tified pairs). 
3 EMACC 
We propose a specific instantiation of the well-
known general EM algorithm for aligning different 
types of textual units: documents, paragraphs, and 
sentences which we will name EMACC (an acro-
nym for ?Expectation Maximization Alignment for 
Comparable Corpora?). We draw our inspiration 
from the famous IBM models (specifically from 
the IBM-1 model) for word alignment (Brown et 
al., 1993) where the translation probability (eq. (5)) 
is modeled through an EM algorithm where the 
hidden variable a models the assignment (1:1 word 
alignments) from the French sequence of words (? 
indexes) to the English one. 
By analogy, we imagined that between two sets 
of documents (from now on, we will refer to doc-
uments as our textual units but what we present 
here is equally applicable ? but with different per-
formance penalties ? to paragraphs and/or sentenc-
es) ? let?s call them   and  , there is an assignment 
(a sequence of 1:1 document correspondences1), 
the distribution of which can be modeled by a hid-
den variable   taking values in the set {true, false}. 
This assignment will be largely determined by the 
existence of word translations between a pair of 
documents, translations that can differentiate be-
tween one another in their ability to indicate a cor-
rect document alignment versus an incorrect one. 
In other words, we hypothesize that there are cer-
tain pairs of translation equivalents that are better 
indicators of a correct document correspondence 
than other translation equivalents pairs. 
We take the general formulation and derivation 
of the EM optimization problem from (Borman, 
2009). The general goal is to optimize  (   ), that 
is to find the parameter(s)   for which  (   ) is 
maximum. In a sequence of derivations that we are 
not going to repeat here, the general EM equation 
is given by: 
                                                          
1 Or ?alignments? or ?pairs?. These terms will be used with 
the same meaning throughout the presentation. 
    
       
 
? (      )    (     )
 
 (1) 
where  ?  (      )   . At step n+1, we try to 
obtain a new parameter      that is going to max-
imize (the maximization step) the sum over z (the 
expectation step) that in its turn depends on the 
best parameter    obtained at step n. Thus, in 
principle, the algorithm should iterate over the set 
of all possible   parameters, compute the expecta-
tion expression for each of these parameters and 
choose the parameter(s) for which the expression 
has the largest value. But as we will see, in prac-
tice, the set of all possible parameters has a dimen-
sion that is exponential in terms of the number of 
parameters. This renders the problem intractable 
and one should back off to heuristic searches in 
order to find a near-optimal solution. 
We now introduce a few notations that we will 
operate with from this point forward. We suggest 
to the reader to frequently refer to this section in 
order to properly understand the next equations: 
?   is the set of source documents,     is the 
cardinal of this set; 
?   is the set of target documents with     its 
cardinal; 
?     is a pair of documents,      and 
    ; 
?    is a pair of translation equivalents 
?     ? such that    is a lexical item that 
belongs to    and    is a lexical item that 
belongs to   ; 
?   is the set of all existing translation 
equivalents pairs ?     ?.   is the transla-
tion probability score (as the one given for 
instance by GIZA++ (Gao and Vogel, 
2008)). We assume that GIZA++ transla-
tion lexicons already exist for the pair of 
languages of interest. 
In order to tie equation 1 to our problem, we de-
fine its variables as follows: 
?   is the sequence of 1:1 document align-
ments of the form              ,     
{              }. We call   an assign-
ment which is basically a sequence of 1:1 
document alignments. If there are     1:1 
document alignments in   and if        , 
then the set of all possible assignments has 
130
the cardinal equal to     (
   
   
) where n! is 
the factorial function of the integer n and 
.
 
 
/ is the binomial coefficient. It is clear 
now that with this kind of dimension of the 
set of all possible assignments (or   pa-
rameters), we cannot simply iterate over it 
in order to choose the assignment that 
maximizes the expectation; 
?   *          + is the hidden variable that 
signals if a pair of documents     repre-
sents a correct alignment (true) or not 
(false); 
?   is the sequence of translation equivalents 
pairs    from T in the order they appear 
in each document pair from  . 
Having defined the variables in equation 1 this 
way, we aim at maximizing the translation equiva-
lents probability over a given assignment,  (   ). 
In doing so, through the use of the hidden variable 
z, we are also able to find the 1:1 document align-
ments that attest for this maximization. 
We proceed by reducing equation 1 to a form 
that is readily amenable to software coding. That 
is, we aim at obtaining some distinct probability 
tables that are going to be (re-)estimated by the 
EM procedure. Due to the lack of space, we omit 
the full derivation and directly give the general 
form of the derived EM equation 
           
 
,   (   )     (      )- (2) 
Equation 2 suggests a method of updating the as-
signment probability  (      )  with the lexical 
alignment probability  (   ) in an effort to pro-
vide the alignment clues that will ?guide? the as-
signment probability towards the correct 
assignment. All it remains to do now is to define 
the two probabilities. 
The lexical document alignment probability 
 (   ) is defined as follows: 
 (   )  ?
?  (   |   )     
      
     
 (3) 
where  (       )  is the simplified lexical docu-
ment alignment probability which is initially equal 
to  (   ) from the set  . This probability is to be 
read as ?the contribution    makes to the correct-
ness of the     alignment?. We want that the 
alignment contribution of one translation equiva-
lents pair    to distribute over the set of all possi-
ble document pairs thus enforcing that 
?  (   |   )   
    {              }
 (4) 
The summation over   in equation 3 is actually 
over all translation equivalents pairs that are to be 
found only in the current     document pair and 
the presence of the product        ensures that we 
still have a probability value. 
The assignment probability  (      ) is also 
defined in the following way: 
 
 (      )  ?  (        )
     
 (5) 
for which we enforce the condition: 
?  (        )   
    {             }
 
(6) 
Using equations 2, 3 and 5 we deduce the final, 
computation-ready EM equation 
     
       
 
[  ?
?  (       )     
      
     
   ?  (        )
     
]
       
 
? [  
?  (       )     
      
     
    (        )] 
(7) 
As it is, equation 7 suggests an exhaustive search 
in the set of all possible   parameters, in order to 
find the parameter(s) for which the expression that 
is the argument of ?argmax? is maximum. But, as 
we know from section 3, the size of this this set is 
prohibitive to the attempt of enumerating each   
assignment and computing the expectation expres-
sion. Our quick solution to this problem was to 
directly construct the ?best?   assignment2 using a 
                                                          
2 We did not attempt to find the mathematical maximum of the 
expression from equation 7 and we realize that the conse-
131
greedy algorithm: simply iterate over all possible 
1:1 document pairs and for each document pair 
    {              }  compute the align-
ment count (it?s not a probability so we call it a 
?count? following IBM-1 model?s terminology) 
 
  
?  (   |   )     
      
    (        ) 
 
Then, construct the best 1:1 assignment      by 
choosing those pairs     for which we have counts 
with the maximum values. Before this cycle 
(which is the basic EM cycle) is resumed, we per-
form the following updates: 
 (        )   (        )
 
?  (   |   )     
      
 
(7a) 
 
 (   |   )  ?  (   |   )
        
 (7b) 
and normalize the two probability tables with 
equations 6 and 4. The first update is to be inter-
preted as the contribution the lexical document 
alignment probability makes to the alignment 
probability. The second update equation aims at 
boosting the probability of a translation equivalent 
if and only if it is found in a pair of documents be-
longing to the best assignment so far. In this way, 
we hope that the updated translation equivalent 
will make a better contribution to the discovery of 
a correct document alignment that has not yet been 
discovered at step n + 1. 
Before we start the EM iterations, we need to 
initialize the probability tables  (        ) and 
 (   |   ) . For the second table we used the 
GIZA++ scores that we have for the     translation 
equivalents pairs and normalized the table with 
equation 4. For the first probability table we have 
(and tried) two choices: 
? (D1) a uniform distribution: 
 
      
; 
? (D2) a lexical document alignment meas-
ure  (   ) (values between 0 and 1) that is 
computed directly from a pair of docu-
                                                                                           
quence of this choice and of the greedy search procedure is not 
finding the true optimum. 
ments     using the    translation equiva-
lents pairs from the dictionary  : 
 (   )  
 
?    (  )        ?    (  )        
        
 
(8) 
where      is the number of words in document    
and    (  ) is the frequency of word    in docu-
ment    (please note that, according to section 3, 
    is not a random pair of words, but a pair of 
translation equivalents). If every word in the 
source document has at least one translation (of a 
given threshold probability score) in the target 
document, then this measure is 1. We normalize 
the table initialized using this measure with equa-
tion 6. 
EMACC finds only 1:1 textual units alignments 
in its present form but a document pair     can be 
easily extended to a document bead following the 
example from (Chen, 1993). The main difference 
between the algorithm described by Chen and ours 
is that the search procedure reported there is inva-
lid for comparable corpora in which no pruning is 
available due to the nature of the corpus. A second 
very important difference is that Chen only relies 
on lexical alignment information, on the parallel 
nature of the corpus and on sentence lengths corre-
lations while we add the probability of the whole 
assignment which, when initially set to the D2 dis-
tribution, produces a significant boost of the preci-
sion of the alignment. 
4 Experiments and Evaluations 
The test data for document alignment was com-
piled from the corpora that was previously collect-
ed in the ACCURAT project3 and that is known to 
the project members as the ?Initial Comparable 
Corpora? or ICC for short. It is important to know 
the fact that ICC contains all types of comparable 
corpora from parallel to weakly comparable docu-
ments but we classified document pairs in three 
classes: parallel (class name: p), strongly compa-
rable (cs) and weakly comparable (cw). We have 
considered the following pairs of languages: Eng-
lish-Romanian (en-ro), English-Latvian (en-lv), 
English-Lithuanian (en-lt), English-Estonian (en-
et), English-Slovene (en-sl) and English-Greek 
                                                          
3 http://www.accurat-project.eu/ 
132
(en-el). For each pair of languages, ICC also con-
tains a Gold Standard list of document alignments 
that were compiled by hand for testing purposes. 
We trained GIZA++ translation lexicons for 
every language pair using the DGT-TM4 corpus. 
The input texts were converted from their Unicode 
encoding to UTF-8 and were tokenized using a 
tokenizer web service described by Ceau?u (2009). 
Then, we applied a parallel version of GIZA++ 
(Gao and Vogel, 2008) that gave us the translation 
dictionaries of content words only (nouns, verbs, 
adjective and adverbs) at wordform level. For Ro-
manian, Lithuanian, Latvian, Greek and English, 
we had lists of inflectional suffixes which we used 
to stem entries in respective dictionaries and pro-
cessed documents. Slovene remained the only lan-
guage which involved wordform level processing. 
The accuracy of EMACC is influenced by three 
parameters whose values have been experimentally 
set: 
? the threshold over which we use transla-
tion equivalents from the dictionary   for 
textual unit alignment; values for this 
threshold (let?s name it ThrGiza) are 
from the ordered set *             +; 
? the threshold over which we decide to up-
date the probabilities of translation equiva-
lents with equation 7b; values for this 
threshold (named ThrUpdate) are from 
the same ordered set *             +; 
? the top ThrOut% alignments from the 
best assignment found by EMACC. This 
parameter will introduce precision and re-
call with the ?perfect? value for recall 
equal to ThrOut%. Values for this pa-
rameter are from the set *         +. 
We ran EMACC (10 EM steps) on every possible 
combination of these parameters for the pairs of 
languages in question on both initial distributions 
D1 and D2. For comparison, we also performed a 
baseline document alignment using the greedy al-
gorithm of EMACC with the equation 8 supplying 
the document similarity measure. The following 4 
tables report a synthesis of the results we have ob-
tained which, because of the lack of space, we 
cannot give in full. We omit the results of EMACC 
with D1 initial distribution because the accuracy 
                                                          
4 http://langtech.jrc.it/DGT-TM.html 
figures (both precision and recall) are always lower 
(10-20%) than those of EMACC with D2. 
cs P/R Prms. P/R Prms. # 
en-
ro 
1/ 
0.69047 
0.4 
0.4 
0.7 
0.85714/ 
0.85714 
0.4 
0.4 
1 
42 
en-
sl 
0.96666/ 
0.28807 
0.4 
0.4 
0.3 
0.83112/ 
0.83112 
0.4 
0.4 
1 
302 
en-
el 
0.97540/ 
0.29238 
0.001 
0.8 
0.3 
0.80098/ 
0.80098 
0.001 
0.4 
1 
407 
en-
lt 
0.97368/ 
0.29191 
0.4 
0.8 
0.3 
0.72978/ 
0.72978 
0.4 
0.4 
1 
507 
en-
lv 
0.95757/ 
0.28675 
0.4 
0.4 
0.3 
0.79854/ 
0.79854 
0.001 
0.8 
1 
560 
en-
et 
0.88135/ 
0.26442 
0.4 
0.8 
0.3 
0.55182/ 
0.55182 
0.4 
0.4 
1 
987 
Table 1: EMACC with D2 initial distribution on strong-
ly comparable corpora 
 
cs P/R Prms. P/R Prms. # 
en-
ro 
1/ 
0.69047 
0.4 
0.7 
0.85714/ 
0.85714 
0.4 
1 
42 
en-
sl 
0.97777/ 
0.29139 
0.001 
0.3 
0.81456/ 
0.81456 
0.4 
0.1 
302 
en-
el 
0.94124/ 
0.28148 
0.001 
0.3 
0.71851/ 
0.71851 
0.001 
1 
407 
en-
lt 
0.95364/ 
0.28514 
0.001 
0.3 
0.72673/ 
0.72673 
0.001 
1 
507 
en-
lv 
0.91463/ 
0.27322 
0.001 
0.3 
0.80692/ 
0.80692 
0.001 
1 
560 
en-
et 
0.87030/ 
0.26100 
0.4 
0.3 
0.57727/ 
0.57727 
0.4 
1 
987 
Table 2: D2 baseline algorithm on strongly comparable 
corpora 
 
cw P/R Prms. P/R Prms. # 
en-
ro 
1/ 
0.29411 
0.4 
0.001 
0.3 
0.66176/ 
0.66176 
0.4 
0.001 
1 
68 
en-
sl 
0.73958/ 
0.22164 
0.4 
0.4 
0.3 
0.42767/ 
0.42767 
0.4 
0.4 
1 
961 
en-
el 
0.15238/ 
0.04545 
0.001 
0.8 
0.3 
0.07670/ 
0.07670 
0.001 
0.8 
1 
352 
en-
lt 
0.55670/ 
0.16615 
0.4 
0.8 
0.3 
0.28307/ 
0.28307 
0.4 
0.8 
1 
325 
en-
lv 
0.23529/ 
0.07045 
0.4 
0.4 
0.3 
0.10176/ 
0.10176 
0.4 
0.4 
1 
511 
en-
et 
0.59027/ 
0.17634 
0.4 
0.8 
0.3 
0.27800/ 
0.27800 
0.4 
0.8 
1 
483 
Table 3: EMACC with D2 initial distribution on weakly 
comparable corpora 
133
cw P/R Prms. P/R Prms. # 
en-
ro 
0.85/ 
0.25 
0.4 
0.3 
0.61764/ 
0.61764 
0.4 
1 
68 
en-
sl 
0.65505/ 
0.19624 
0.4 
0.3 
0.39874/ 
0.39874 
0.4 
1 
961 
en-
el 
0.11428/ 
0.03428 
0.4 
0.3 
0.06285/ 
0.06285 
0.4 
1 
352 
en-
lt 
0.60416/ 
0.18012 
0.4 
0.3 
0.24844/ 
0.24844 
0.4 
1 
325 
en-
lv 
0.13071/ 
0.03921 
0.4 
0.3 
0.09803/ 
0.09803 
0.4 
1 
511 
en-
et 
0.48611/ 
0.14522 
0.001 
0.3 
0.25678/ 
0.25678 
0.4 
1 
483 
Table 4: D2 baseline algorithm on weakly comparable 
corpora 
 
In every table above, the P/R column gives the 
maximum precision and the associated recall 
EMACC was able to obtain for the corresponding 
pair of languages using the parameters (Prms.) 
from the next column. The P/R column gives the 
maximum recall with the associated precision that 
we obtained for that pair of languages.  
The Prms. columns contain parameter settings 
for EMACC (see Tables 1 and 3) and for the D2 
baseline algorithm (Tables 2 and 4): in Tables 1 
and 3 values for ThrGiza, ThrUpdate and 
ThrOut are given from the top (of the cell) to the 
bottom and in Tables 2 and 4 values of ThrGiza 
and ThrOut are also given from top to bottom 
(the ThrUpdate parameter is missing because the 
D2 baseline algorithm does not do re-estimation). 
The # column contains the size of the test set: the 
number of documents in each language that have to 
be paired. The search space is # * # and the gold 
standard contains # pairs of human aligned docu-
ment pairs.  
To ease comparison between EMACC and the 
D2 baseline for each type of corpora (strongly and 
weakly comparable), we grayed maximal values 
between the two: either the precision in the P/R 
column or the recall in the P/R column. 
In the case of strongly comparable corpora (Ta-
bles 1 and 2), we see that the benefits of re-
estimating the probabilities of the translation 
equivalents (based on which we judge document 
alignments) begin to emerge with precisions for all 
pairs of languages (except en-sl) being better than 
those obtained with the D2 baseline. But the real 
benefit of re-estimating the probabilities of transla-
tion equivalents along the EM procedure is visible 
from the comparison between Tables 3 and 4. Thus, 
in the case of weakly comparable corpora, in 
which EMACC with the D2 distribution is clearly 
better than the baseline (with the only exception of 
en-lt precision), due to the significant decrease in 
the lexical overlap, the EM procedure is able to 
produce important alignment clues in the form of 
re-estimated (bigger) probabilities of translation 
equivalents that, otherwise, would have been ig-
nored. 
It is important to mention the fact that the re-
sults we obtained varied a lot with values of the 
parameters ThrGiza and ThrUpdate. We ob-
served, for the majority of studied language pairs, 
that lowering the value for ThrGiza and/or 
ThrUpdate (0.1, 0.01, 0.001?), would negative-
ly impact the performance of EMACC due to the 
fact of introducing noise in the initial computation 
of the D2 distribution and also on re-estimating 
(increasing) probabilities for irrelevant translation 
equivalents. At the other end, increasing the 
threshold for these parameters (0.8, 0.85, 0.9?) 
would also result in performance decreasing due to 
the fact that too few translation equivalents (be 
they all correct) are not enough to pinpoint correct 
document alignments since there are great chances 
for them to actually appear in all document pairs. 
So, we have experimentally found that there is a 
certain balance between the degree of correctness 
of translation equivalents and their ability to pin-
point correct document alignments. In other words, 
the paradox resides in the fact that if a certain pair 
of translation equivalents is not correct but the re-
spective words appear only in documents which 
correctly align to one another, that pair is very im-
portant to the alignment process. Conversely, if a 
pair of translation equivalents has a very high 
probability score (thus being correct) but appears 
in almost every possible pair of documents, that 
pair is not informative to the alignment process and 
must be excluded. We see now that the EMACC 
aims at finding the set of translation equivalents 
that is maximally informative with respect to the 
set of document alignments. 
We have introduced the ThrOut parameter in 
order to have better precision. This parameter actu-
ally instructs EMACC to output only the top (ac-
cording to the alignment score probability 
 (        )) ThrOut% of the document align-
ments it has found. This means that, if all are cor-
rect, the maximum recall can only be ThrOut%. 
134
But another important function of ThrOut is to 
restrict the translation equivalents re-estimation 
(equation 7b) for only the top ThrOut% align-
ments. In other words, only the probabilities of 
translation equivalents that are to be found in top 
ThrOut% best alignments in the current EM step 
are re-estimated. We introduced this restriction in 
order to confine translation equivalents probability 
re-estimation to correct document alignments 
found so far. 
Regarding the running time of EMACC, we can 
report that on a cluster with a total of 32 CPU 
cores (4 nodes) with 6-8 GB of RAM per node, the 
total running time is between 12h and 48h per lan-
guage pair (about 2000 documents per language) 
depending on the setting of the various parameters. 
5 Conclusions 
The whole point in developing textual unit align-
ment algorithms for comparable corpora is to be 
able to provide good quality quasi-aligned data to 
programs that are specialized in extracting parallel 
data from these alignments. In the context of this 
paper, the most important result to note is that 
translation probability re-estimation is a good tool 
in discovering new correct textual unit alignments 
in the case of weakly related documents. We also 
tested EMACC at the alignment of 200 parallel 
paragraphs (small texts of no more than 50 words) 
for all pairs of languages that we have considered 
here. We can briefly report that the results are bet-
ter than the strongly comparable document align-
ments from Tables 1 and 2 which is a promising 
result because one would think that a significant 
reduction in textual unit size would negatively im-
pact the alignment accuracy. 
Acknowledgements 
This work has been supported by the ACCURAT 
project (http://www.accurat-project.eu/) funded by 
the European Community?s Seventh Framework 
Program (FP7/2007-2013) under the Grant Agree-
ment n? 248347. It has also been partially support-
ed by the Romanian Ministry of Education and 
Research through the STAR project (no. 
742/19.01.2009). 
 
 
References 
 
Borman, S. 2009. The Expectation Maximization Algo-
rithm. A short tutorial. Online at: 
http://www.isi.edu/natural-
language/teaching/cs562/2009/readings/B06.pdf 
Brown, P. F., Lai, J. C., and Mercer, R. L. 1991. Align-
ing sentences in parallel corpora. In Proceedings of 
the 29th Annual Meeting of the Association for 
Computational Linguistics, pp. 169?176, June 8-21, 
1991, University of California, Berkeley, California, 
USA. 
Brown, P. F., Pietra, S. A. D., Pietra, V. J. D., and Mer-
cer, R. L. 1993. The Mathematics of Statistical Ma-
chine Translation: Parameter Estimation. 
Computational Linguistics, 19(2): 263?311. 
Ceau?u, A. 2009. Statistical Machine Translation for 
Romanian. PhD Thesis, Romanian Academy (in Ro-
manian). 
Chen, S. F. 1993. Aligning Sentences in Bilingual Cor-
pora Using Lexical Information. In Proceedings of 
the 31st Annual Meeting on Association for Compu-
tational Linguistics, pp. 9?16, Columbus, Ohio, 
USA. 
Dempster, A. P., Laird, N. M., and Rubin, D. B. 1977. 
Maximum likelihood from incomplete data via the 
EM algorithm. Journal of the Royal Statistical Socie-
ty, 39(B):1?38. 
Fung, P., and Cheung, P. 2004. Mining Very-Non-
Parallel Corpora: Parallel Sentence and Lexicon Ex-
traction via Bootstrapping and EM. In Proceedings of 
EMNLP 2004, Barcelona, Spain: July 2004. 
Gao, Q., and Vogel, S. 2008.  Parallel implementations 
of word alignment tool.  ACL-08 HLT: Software En-
gineering, Testing, and Quality Assurance for Natu-
ral Language Processing, pp. 49?57, June 20, 2008, 
The Ohio State University, Columbus, Ohio, USA.  
Munteanu, D. S., and Marcu, D. 2002. Processing com-
parable corpora with bilingual suffix trees. In Pro-
ceedings of the 2002 Conference on Empirical 
Methods in Natural Language Processing (EMNLP 
2002), pp. 289?295, July 6-7, 2002, University of 
Pennsylvania, Philadelphia, USA. 
Munteanu, D. S., and Marcu, D. 2005. Improving ma-
chine translation performance by exploiting non-
parallel corpora. Computational Linguistics, 
31(4):477?504. 
135
