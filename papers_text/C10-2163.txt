Coling 2010: Poster Volume, pages 1426?1434,
Beijing, August 2010
Cross-Lingual Induction for Deep Broad-Coverage Syntax: A Case
Study on German Participles
Sina Zarrie? Aoife Cahill Jonas Kuhn Christian Rohrer
Institut fu?r Maschinelle Sprachverarbeitung (IMS), University of Stuttgart
{zarriesa,cahillae,jonas.kuhn,rohrer}@ims.uni-stuttgart.de
Abstract
This paper is a case study on cross-lingual
induction of lexical resources for deep,
broad-coverage syntactic analysis of Ger-
man. We use a parallel corpus to in-
duce a classifier for German participles
which can predict their syntactic category.
By means of this classifier, we induce a
resource of adverbial participles from a
huge monolingual corpus of German. We
integrate the resource into a German LFG
grammar and show that it improves pars-
ing coverage while maintaining accuracy.
1 Introduction
Parallel corpora are currently exploited in a wide
range of induction scenarios, including projection
of morphologic (Yarowsky et al, 2001), syntactic
(Hwa et al, 2005) and semantic (Pado? and Lap-
ata, 2009) resources. In this paper, we use cross-
lingual data to learn to predict whether a lexi-
cal item belongs to a specific syntactic category
that cannot easily be learned from monolingual re-
sources. In an application test scenario, we show
that this prediction method can be used to obtain
a lexical resource that improves deep, grammar-
based parsing.
The general idea of cross-lingual induction is
that linguistic annotations or structures, which are
not available or explicit in a given language, can
be inferred from another language where these an-
notations or structures are explicit or easy to ob-
tain. Thus, this technique is very attractive for
cheap acquisition of broad-coverage resources, as
is proven by the approaches cited above. More-
over, this induction process can be attractive for
the induction of deep (and perhaps specific) lin-
guistic knowledge that is hard to obtain in a mono-
lingual context. However, this latter perspective
has been less prominent in the NLP community
so far.
This paper investigates a cross-lingual induc-
tion method based on an exemplary problem aris-
ing in the deep syntactic analysis of German. This
showcase is the syntactic flexibility of German
participles, being morphologically ambiguous be-
tween verbal, adjectival and adverbial readings,
and it is instructive for several reasons: first, the
phenomenon is a notorious problem for linguistic
analysis and annotation of German, such that stan-
dard German resources do not represent the under-
lying analysis. Second, in Zarrie? et al (2010),
we showed that integrating the phenomenon of
adverbial participles in a naive way into a broad-
coverage grammar of German leads to significant
parsing problems, due to spurious ambiguities.
Third, it is completely straightforward to detect
adverbial participles in cross-lingual data since in
other languages, e.g. English or French, adverbs
are often morphologically marked.
In this paper, we use instances of adverbially
translated participles in a parallel corpus to boot-
strap a classifier that is able to identify an ad-
verbially used participle based on its monolingual
syntactic context. In contrast to what is commonly
assumed, we show that it is possible to detect ad-
verbial participles using only a relatively narrow
context window. This classifier enables us to iden-
tify an occurence of an adverbial participle inde-
pendently of its translation in a parallel corpus,
going far beyond the induction methodology in
Zarrie? et al (2010). By means of the participle
classifier, we can extract new types of adverbial
participles from a larger corpus of German news-
paper text and substantially augment the size of
the resource extracted only on Europarl data. Fi-
nally, we integrate this new resource into the Ger-
man LFG grammar and show that it improves cov-
erage without negatively affecting performance.
1426
The paper is structured as follows: in Sec-
tion 2, we describe the linguistic and computa-
tional problems related to the parsing of adver-
bial participles in German. Section 3 introduces
the general idea of using the translation data to
find instances of different participle categories. In
Section 4, we illustrate the training of the clas-
sifier, evaluating the impact of the context win-
dow and the quality of the training data obtained
from cross-lingual text. In Section 5, we apply the
classifier to new, monolingual data and describe
the extension of the resource for adverbial partici-
ples. Section 6 evaluates the extended resource by
means of parsing experiments using the German
LFG grammar.
2 The Problem
In German, past perfect participles are ambiguous
with respect to their morphosyntactic category. As
in other languages, they can be used as part of
the verbal complex (Example (1-a)) or as adjec-
tives (Example (1-b)). Since German adjectives
can generally undergo conversion into adverbs,
participles can also be used adverbially (Example
(1-c)). The verbal and adverbial participle forms
are morphologically identical.
(1) a. Sie haben das Experiment wiederholt.
?They have repeated the experiment.?
b. Das wiederholte Experiment war erfolgreich.
?The repeated experiment was succesful.?
c. Sie haben das Experiment wiederholt abge-
brochen.
?They cancelled the experiment repeatedly.?
Moreover, German adjectival modifiers can be
generally used as predicatives that can be either
selected by a verb (Example (2-a)) or that can oc-
cur as free predicatives (Example (2-b)).
(2) a. Er scheint begeistert von dem Experiment.
?He seems enthusiastic about the experiment.?
b. Er hat begeistert experimentiert.
?He has experimented enthusiastic.?
Since predicative adjectives are not inflected,
the surface form of a German participle is ambigu-
ous between a verbal, predicative or adverbial use.
2.1 Participles in the German LFG
In order to account for sentences like (1-c), an in-
tuitive approach would be to generally allow for
adverb conversion of participles in the grammar.
However, in Zarrie? et al (2010), we show that
such a rule can have a strong negative effect on
the overall performance of the parsing system, de-
spite the fact that it produces the desired syntac-
tic and semantic analysis for specific sentences.
This problem was illustrated using a German LFG
grammar (Rohrer and Forst, 2006) constructed as
part of the ParGram project (Butt et al, 2002).
The grammar is implemented in the XLE, a gram-
mar development environment which includes a
very efficient LFG parser and a stochastic dis-
ambiguation component which is based on a log-
linear probability model (Riezler et al, 2002).
In Zarrie? et al (2010), we found that the
naive implementation of adverbial participles in
the German LFG, i.e. in terms of a general gram-
mar rule that allows for participles-adverb conver-
sion, leads to spurious ambiguities that mislead
the disambiguation component of the grammar.
Moreover, the rule increases the number of time-
outs, i.e. sentences that cannot be parsed in a pre-
defined amount of time (20 seconds). Therefore,
we observe a drop in parsing accuracy although
grammar coverage is improved. As a solution, we
induced a lexical resource of adverbial participles
based on their adverbial translations in a paral-
lel corpus. This resource, comprising 46 partici-
ple types, restricts the adverb conversion such that
most of the spurious ambiguities are eliminated.
To assess the impact of specific rules in a broad-
coverage grammar, possibly targeting medium-to-
low frequency phenomena, we have established a
fine-grained evaluation methodology. The chal-
lenge posed by these low-frequent phenomena is
typically two-fold: on the one hand, if one takes
into account the disambiguation component of the
grammar and pursues an evaluation of the most
probable parses on a general test set, the new
grammr rule cannot be expected to show a positive
effect since the phenomenon is not likely to occur
very often in the test set. On the other hand, if one
is interested in a linguistically precise grammar,
it is very unsatisfactory to reduce grammar cov-
erage to statistically frequent phenomena. There-
fore, we combined a coverage-oriented evaluation
on specialised testsuites with a quantitative evalu-
ation including disambiguation, making sure that
1427
the increased coverage does not lead to an overall
drop in accuracy. The evaluation methodolgy will
also be applied to evaluate the impact of the new
participle resource, see Section 6.
2.2 The Standard Flat Analysis of Modifiers
The fact that German adjectival modifiers can gen-
erally undergo conversion into adverbs without
overt morphological marking is a notorious prob-
lem for the syntactic analysis of German: there
are no theoretically established tests to distinguish
predicative adjectives and adverbials, see Geuder
(2004). For this reason, the standard German tag
set assigns a uniform tag (?ADJD?) to modifiers
that are morphologically ambiguous between an
adjectival and adverbial reading. Moreover, in
the German treebank TIGER (Brants et al, 2002)
the resulting syntactic differences between the two
readings are annotated by the same flat structure
that does not disambiguate the sentence.
Despite certain theoretical problems related to
the analysis of German modifiers, their interpre-
tation in real corpus sentences is often unambigu-
ous for native speakers. As an example, consider
example (3) from the TIGER treebank. In the
sentence, the participle unterschrieben (signed)
clearly functions as a predicative modifier of the
sentence?s subject. The other, theoretically possi-
ble reading where the participle would modify the
verb send is semantically not acceptable. How-
ever, in TIGER, the participle is analysed as an
ADJD modifier attached under the VP node which
is the general analysis for adjectival and adverbial
modifiers.
(3) Die
It
sollte
should
unterschrieben
signed
an
to
die
the
Leitung
administration
zuru?ckgesandt
sent back
werden.
be.
?It should be sent back signed to the administation.?
Sentence (4) (also taken from TIGER) illus-
trates the case of an adverbial participle. In this
example, the reading where angemessen (ade-
quately) modifies the main verb is the only one
that is semantically plausible. In the treebank, the
participle is tagged as ADJD and analysed as a
modifier in the VP.
(4) Der
The
menschliche
human
Geist
mind
la??t
lets
sich
itself
rechnerisch
computationally
nicht
not
angemessen
adequately
simulieren.
simulate.
?The human mind cannot be adequately simulated in a
computational way.?
The flat annotation strategy adopted for modi-
fiers in the standard German tag set and in the tree-
bank TIGER entails that instances of adverbs (and
adverbial participles) cannot be extracted from au-
tomatically tagged, or parsed, text. Therefore,
it would be very hard to obtain training mate-
rial from German resources to train a system that
automatically identifies adverbially used partici-
ples. However, the intuition corroborated by the
examples presented in this section is that the struc-
tures can actually be disambiguated in many cor-
pus sentences.
In the following sections, we show how we ex-
ploit parallel text to obtain training material for
learning to predict occurences of adverbial par-
ticiples, without any manual effort. Moreover, by
means of this technique, we can substantially ex-
tend the grammatical resource for adverbial par-
ticiples compared to the resource that can be di-
rectly extracted from the parallel text.
3 Participles in the Parallel Corpus
The intuition of the cross-lingual induction ap-
proach is that adverbial participles can easily be
extracted from parallel corpora since in other lan-
guages (such as English or French) adverbs are
often morphologically marked and easily labelled
by statistical PoS taggers. As an example, con-
sider sentence (5) extracted from Europarl, where
the German participle versta?rkt is translated by an
English adverb (increasingly).
(5) a. Nicht
Not
ohne
without
Grund
reason
sprechen
speak
wir
we
versta?rkt
increasingly
vom
of a
Europa
Europe
der
of the
Regionen.
Regions.
b. It is not without reason that we increasingly speak
in terms of a Europe of the Regions.
The idea is to project specific morphological
information about adverbs which is overt in lan-
guages like English onto German where adverbs
cannot be directly extracted from tagged data.
While this idea might seem intuitively straightfor-
1428
ward, we also know that translation pairs in paral-
lel data are not always lingusitically parallel, and
as a consequence, word-alignment is not always
reliable. To assess the impact of non-parallelism
in adverbial translations of German participles,
we manually annotated a sample of 300 transla-
tions. This data also constitutes the basis for the
experiments reported in Section 4.
3.1 Data
Our experiments are based on the same data as in
(Zarrie? et al, 2010). For convenience, we pro-
vide a short description here.
We limit our investigations to non-lexicalised
participles occuring in the Europarl corpus and
not yet recorded as adverbs in the lexicon of the
German LFG grammar (5054 participle types in
total). Given the participle candidates, we ex-
tract the set of sentences that exhibit a word align-
ment between a German participle and an English,
French or Dutch adverb. The word alignments
have been obtained with GIZA++. The extrac-
tion yields 27784 German-English sentence pairs
considering all alignment links, and 5191 sen-
tence pairs considering only bidirectional align-
ments between a participle and an English adverb.
3.2 Systematic Non-Parallelism
For data exploration and evaluation, we anno-
tated 300 participle alignments out of the 5191
German-English sentences (with a bidirectional
participle-adverb alignment). We distinguish the
following annotation categories: (i) parallel trans-
lation, adverb information can be projected, (ii)
incorrect alignment, (iii) correct alignment, but
translation is a multi-word expression, (iv) correct
alignment, but translation is a paraphrase (possi-
bly involving a translation shift).
Parallel Cases In our annotated sample of En-
glish adverb - German participle pairs, 43%1 of
the translation instances are parallel in the sense
that the overt adverb information from the English
side can be projected onto the German participle.
This means that if we base the induction technique
1The diverging figures we report in Zarrie? et al (2010)
were due to a small bug in the script and it does not affect the
overall interpretation of the data.
on word-alignments alone, its precision would be
relatively low.
Non-Parallel Cases Taking a closer look at the
non-parallel cases in our sample (57% of the
translation pairs), we find that 47% of this set are
due to incorrect word alignments. The remain-
ing 53% thus reflect regular cases of non-parallel
translations. A typical configuration which makes
up 30% of the the non-parallel cases is exempli-
fied in (6) where the German main verb vorlegen
is translated by the English multiword expression
put forward.
(6) a. Wir haben eine Reihe von Vorschla?gen vorgelegt.
b. We have put forward a number of proposals.
An example for the general paraphrase or trans-
lation shift category is given in Sentence (7).
Here, the translational correspondence between
gekommen (arrived) and the adverb now is due
to language-specific, idiomatic realisations of an
identical underlying semantic concept. The para-
phrase translations make up 23% of the non-
parallel cases in the annotated sample.
(7) a. Die
That
Zeit
time
ist
is
noch
yet
nicht
not
gekommen
arrived.
.
b. That time is not now .
Furthermore, it is noticeable that the cross-
lingual approach seems to inherently factor out
the ambiguity between predicative and adverbial
participles. In our annotated sample, there are no
predicative participles that have been translated by
an English adverb.
3.3 Filtering Mechanisms
The data analysis in the previous section, show-
ing only 43% of parallel cases in English adverb
translations for German participles, mainly con-
firms other studies in annotation projection which
find that translational correspondences only allow
for projection of linguistic analyses in a more or
less limited proportion (Yarowsky et al, 2001;
Hwa et al, 2005; Mihalcea et al, 2007).
In previous studies on annotation projection,
quite distinct filtering methods have been pro-
posed: in Yarowsky et al (2001), projection er-
rors are mainly attributed to word alignment er-
rors and filtered based on translation probabilities.
1429
Hwa et al (2005) find that errors in the projec-
tion of syntactic relations are also due to system-
atic grammatical divergences between languages
and propose correcting these errors by means of
specific, manually designed filters. Bouma et al
(2008) make similar observations to Hwa et al
(2005), but try to replace manual correction rules
by filters from additional languages.
In Zarrie? et al (2010), we compared a num-
ber of filtering techniques on our participle data.
The 300 annotated translation instances are used
as a test set for evaluation. In particular, we
have established that a combination of syntactic
dependency-based filters and multilingual filters
can very accurately separate non-parallel transla-
tions from parallel ones where the adverb infor-
mation can be projected. In Section 4, we show
that these filtering techniques are also very useful
for removing noise from the training material that
we use to build a classifier.
4 Bootstrapping a German Participle
Classifier from Crosslingual Data
In the previous section, we have seen that German
adverbial participles can be easily found in cross-
lingual text by looking at their translations in a
language that morphologically marks adverbials.
In previous work, we exploited this observation
by directly extracting types of adverbial partici-
ples based on word alignment links and the filter-
ing mechanisms mentioned in Section 3. How-
ever, this method is very closely tied to data in
the parallel corpus, which only comprises around
5000 participle-adverb translations in total, which
results in 46 types of adverbial participles after fil-
tering. Thus, we have no means of telling whether
we would discover new types of adverbial partici-
ples in other corpora, from different domains to
Europarl. As this corpus is rather small and genre
specific, it even seems very likely that one could
find additional adverbial participles in a bigger
corpus. Moreover, we cannot be sure that certain
adverbial participles have systematically diverg-
ing translations in other languages, due to cross-
lingual lexicalisation differences. Generally, it is
not clear whether we have learned something gen-
eral about the syntactic phenomenon of adverbial
participles in German or whether we have just ex-
tracted a small, corpus-dependent subset of the
class of adverbial participles.
In this section, we use instances of adverbially
translated participles as training material for a
classifier that learns to predict adverbial partici-
ples based on their monolingual syntactic context.
Thus, we exploit the translations in the parallel
corpus as a means of obtaining ?annotated? or dis-
ambiguated training data without any manual ef-
fort. During training, we only consider the mono-
lingual context of the participle, such that the fi-
nal application of the classifier is not dependent
on cross-lingual data anymore.
4.1 Context-based Identification of
Adverbial Participles
Given the general linguistic problems related to
adverbial participles (see Section 2), one could
assume that it is very difficult to identify them
in a given context. To assess the general dif-
ficulty of this syntactic problem, we run a first
experiment comparing a grammar-based identifi-
cation method against a classifier that only con-
siders relatively narrow morpho-syntactic context.
For evaluation, we use the 300 annotated partici-
ple instances described in Section 3. This test
set divides into 172 negative instances, i.e. non-
adverbial participles, and 128 positive instances.
We report accuracy of the identification method,
as well as precision and recall relating to the num-
ber of correctly predicted adverbial participles.
For the grammar-based identification, we use
the German LFG which integrates the lexical
resource for adverbial participles established in
(Zarrie? et al, 2010). We parse the 300 Europarl
sentences and check whether the most probable
parse proposed by the grammar analyses the re-
spective participle as an adverb or not. The gram-
mar obtains a complete parse for 199 sentences
out of the test set and we only consider these in
the evaluation. The results are given in Table 1.
The high precision and accuracy of the
grammar-based identification of adverbial partici-
ples suggests that in a lot of sentences, the adver-
bial analysis is the only possible reading, i.e. the
only analysis that makes the sentence grammati-
cal. But of course, we have substantially restricted
the adverb participle-conversion in the grammar,
1430
Training Data Precision Recall Accuracy
Grammar 97.3 90.12 94.97
Classifier Unigram 87.10 84.38 87.92
Classifier Bigram 88.28 88.28 89.93
Classifier Trigram 89.60 87.5 90.27
Table 1: Evaluation on 300 participle instances
from Europarl
so that it does not propose adverbial analyses for
participles that are very unlikely to function as
modifiers of verbs.
For the classifier-based identification, we use
the adverbially translated participle tokens in our
Europarl data (5191 tokens in total) as training
material. We remove the 300 test instances from
this training set, and then divide it into a set of
positive and negative instances. To do this, we
use the filtering mechanisms already proposed in
Zarrie? et al (2010). These filters apply on the
type level, such that we first identify the positive
types (46 total) and then use all instances of these
types in the 4891 sentences as positive instances
of adverbial participles (1978 instances). The re-
maining sentences are used as negative instances.
For the training of the classifier, we use
maximum-entropy classification, which is also
commonly used for the general task of tagging
(Ratnaparkhi, 1996). In particular, we use the
open source TADM tool for parameter estimation
(Malouf, 2002). The tags of the words surround-
ing the participles are used as features in the clas-
sification task. We explore different sizes of the
context window, where the trigram window is the
most succesful (see Table 1). Beyond the trigram
window, the results of the classifier start decreas-
ing again, probably because of too many mislead-
ing features. Generally, this experiment shows
that the grammar-based identification is more pre-
cise, but that the classifier still performs surpris-
ingly well. Compared to the results from the
grammar-based identification, the high accuracy
of the classifier suggests that even the narrow syn-
tactic contexts of adverbial vs. non-adverbial par-
ticiples are quite distinct.
4.2 Designing Training Data for Participle
Classification
There are several questions related to the design
of the training data that we use to build our clas-
sifier. First, it is not clear how many negative
instances are helpful for learning the adverbial -
non-adverbial distinction. In the above experi-
ment, we simply use the instances that do not pass
the cross-lingual filters. In this section, we exper-
iment with an augmented set of negative instances
that was also obtained by extracting German par-
ticiple that are bi-directionally aligned to an En-
glish participle in Europarl. This is based on the
assumption that these participles are very likely
to be verbal. Second, it is not clear whether we
really need the filtering mechanisms proposed in
Zarrie? et al (2010) and whether we could im-
prove the classifier by training it on a larger set
of positive instances. Therefore, we also experi-
ment with two further sets of positive instances:
one where we used all participles (not necessarily
bidirectionally) aligned to an adverb, one where
we only use the bidirectional alignments. The re-
sults obtained for the different sizes of positive
and negative instance sets are given in Table 2.
The picture that emerges from the results in Ta-
ble 2 is very clear: the stricter the filtering of the
training material (i.e. the positive instances) is,
the better the performance of the classifier. The
fact that we (potentially) loose certain positive in-
stances in the filtering does not negatively impact
on the classifier which substantially benefits from
the fact that noise gets removed. Moreover, we
find that if the training material is appropriately
filtered, adding further negative instances does not
help improving the accuracy. By contrast, if we
train on a noisy set of positive instances, the clas-
sifier benefits from a larger set of negative in-
stances. However, the positive effect that we get
from augmenting the non-filtered training data is
still weaker than the positive effect we get from
the filtering.
5 Induction of Adverbial Participles on
Monolingual Data
Given the classifier from Section 4 that predicts
the syntactic category of a participle instance
1431
Training Data Pos. Instances Neg. Instances Precision Recall Accuracy
Non-Filtered Instances (all alignments) 27.184 10.000 43.10 100 43.10
Non-Filtered Instances (all alignments) 27.184 50.000 74.38 92.97 83.22
Non-Filtered Instances (symm. alignments) 4891 10.000 78.08 89.06 84.56
Non-Filtered Instances (symm. alignments) 4891 50.000 82.31 83.59 85.23
Filtered Instances 1978 10.000 91.60 85.16 90.27
Filtered Instances 1978 50.000 90.83 77.34 86.91
Table 2: Evaluation on 300 participle instances from Europarl
based on its monolingual syntactic context, we
can now detect new instances or types of adver-
bial participles in any PoS-tagged German corpus.
In this section, we investigate whether the classi-
fier can be used to augment the resource of ad-
verbial participles directly induced from Europarl
with new types.
5.1 Data Extraction
We run our extraction experiment on the Huge
German Corpus (HGC), a corpus of 200 million
words of newspaper and other text. This corpus
has been tagged with TreeTagger (Schmid, 1994).
For each of the 5054 participle candidates, we ex-
tract all instances from the HGC which have not
been tagged as finite verbs (at most 2000 tokens
per participle). For each participle token, we also
extract its syntactic context in terms of the 3 pre-
ceding and the 3 following tags. For classification,
we use only those participles that have more than
50 instances in the corpus (2953 types).
In contrast to the cross-lingual filtering mech-
anisms developed in Zarrie? et al (2010) which
operate on the type-level, the classifier makes a
prediction for every token of a given participle
candidate. Thus, for each of the participle can-
didates, we obtain a percentage of instances that
have been classified as adverbs. As we would ex-
pect, the percentage of adverbial instances is very
low for most of the participles in our candidate set:
for 75% of the 2953 types, the percentage is below
5%. This result confirms our initial intuition that
the property of being used as an adverb is strongly
lexically restricted to a certain class of participles.
5.2 Evaluation
Since we know that the classifier has an accu-
racy of 90% on the Europarl data, we only con-
sider participles as candidates for adverbs where
the classifier predicted more than 14% adverbial
instances. This leaves us with a set of 210 partici-
ples, which comprises 13 of the original 46 par-
ticiples extracted from Europarl, meaning we have
discovered 197 new adverbial participle types.
We performed a manual evaluation of 50 ran-
domly selected types out of the set of 197 new
participle types. Therefore, we looked at the in-
stances and their context which the classifier pre-
dicted to be adverbial. If there was at least one ad-
verbial instance among these, the participle type
was evaluated as correctly annotated by the clas-
sifier. By this means, we find that 76% of the par-
ticiples were correctly classified.
This evaluation suggests that the accuracy of
our classifier which we trained and tested on Eu-
roparl data is lower on the HGC data. The rea-
son for this drop in performance will be explained
in the following Section 5.3. However, assuming
an accuracy of 76%, we have discovered 150 new
types of adverbial participles. We argue that this is
a very satisfactory result given that we have not in-
vested any manual effort into the annotation or ex-
traction of adverbial participles. This results also
makes clear that the previous resource we induced
on Europarl data, comprising only 46 participle
types, was a very limited one.
5.3 Error Analysis
Taking a closer look at the 12 participle candi-
dates that the classifier incorrectly labels as adver-
bial, we observe that their adverbially classified
instances are mostly instances of a predicative use.
This means that our Europarl training data does
not contain enough evidence to learn the distinc-
tion between adverbial and predicative participles.
This is not surprising since the set of negative
instances used for training the classifier mainly
comprises verbal instances of participles. More-
over, the syntactic contexts and constructions in
which some predicatives and adverbials are used
1432
Grammar Prec. Rec. F-Sc. Time
in sec
46 Part-Adv 84.12 78.2 81.05 665
243 Part-Adv 84.12 77.67 80.76 665
Table 3: Evaluation on 371 TIGER sentences
are very similar. Thus, in future work, we will
have to include more data on predicatives (which
is more difficult to obtain) and analyse the syntac-
tic contexts in more detail.
6 Assessing the Impact of Resource
Coverage on Grammar-based Parsing
In this section, we evaluate the classifier-based in-
duction of adverbial participles from a grammar-
based perspective. We integrate the entire set of
induced adverbial participles (46 from Europarl
and 197 from the HGC) into the German LFG
grammar. As a consequence, the grammar al-
lows the adverb conversion for 243 lexical par-
ticiple types. We use the evaluation methodolgy
explained in Section 2.
First, we conduct an accuracy-oriented evalua-
tion on the standard TIGER test set. We compare
against the German LFG that only integrates the
small participle resource from Europarl. The re-
sults are given in Table 3. The difference between
the 46 Part-Adv and 243 Part-Adv resource is not
statistically signficant. Thus, the larger participle
resource has no overall negative effect on the pars-
ing performance. As established by an automatic
upperbound evaluation in Zarrie? et al (2010),
we cannot not expect to find a positive effect in
this evaluation because the phenomenon does not
occur in the standard test set.
To show that the augmented resource indeed
improves the coverage of the grammar, we built
a specialised testsuite of 1044 TIGER sentences
that contain an instance of a participle from the
resource. Since this testsuite comprises sen-
tences from the training set, we can only report
a coverage-oriented evaluation here, see Table 4.
The 243 Part-Adv increases the coverage by 8%
on the specialised testsuite.
Moreover, we manually evaluated 20 sentences
covered by the 243-Part-Adv grammar and not
by 46-Part-Adv as to whether they contain a cor-
rectly analysed adverbial participle. In two sen-
Grammar Parsed
Sent.
Starred
Sent.
Time-
outs
Time
in sec
No Part-Adv 665 315 64 3033
46 Part-Adv 710 269 65 3118
243 Part-Adv 767 208 69 3151
Table 4: Performance on the specialised TIGER
test set (1044 sentences)
tences, the grammar obtained an adverbial analy-
sis for clearly predicative modifiers, based on the
enlarged resource. In three different sentences, it
was difficult to decide whether the participle acts
as an adverb or a predicative. In the remaining 15
sentences, the grammar established the the correct
analysis of a clearly adverbially used participle.
7 Conclusion
We have proposed a cross-lingual induction
method to automatically obtain data on adverbial
participles in German. We exploited this cross-
lingual data as training material for a classifier that
learns to predict the syntactic category of a partici-
ple from its monolingual syntactic context. Since
this category is usually not annotated in German
resources and hard to describe in theory, the find-
ing that adverbial participles can be predicted rel-
atively precisely is of general interest for theo-
retic and computational approaches to the syntac-
tic analysis of German.
We showed that, in order to obtain an accurate
participle classifier, the quality of the training ma-
terial induced from the parallel corpus is of crucial
importance. By applying the filtering techniques
from Zarrie? et al (2010), the accuracy of the
classifier increases between 5% and 7%. In future
work, we plan to include more data on predicative
participles to learn a more accurate distinction be-
tween predicative and adverbial participles.
Finally, we used the participle classifier to ex-
tract a lexical resource of adverbial participles for
the German LFG grammar. In comparison to the
relatively small resource of 46 types that can be
directly induced from Europarl, we discovered a
large number of new participle types (197 types
in total). In a parsing experiment, we showed that
this much bigger resource does not negatively im-
pact on parsing performance and improves gram-
mar coverage.
1433
References
Bouma, Gerlof, Jonas Kuhn, Bettina Schrader, and
Kathrin Spreyer. 2008. Parallel LFG Grammars
on Parallel Corpora: A Base for Practical Trian-
gulation. In Butt, Miriam and Tracy Holloway
King, editors, Proceedings of the LFG08 Confer-
ence, pages 169?189, Sydney, Australia. CSLI Pub-
lications, Stanford.
Brants, Sabine, Stefanie Dipper, Silvia Hansen, Wolf-
gang Lezius, and George Smith. 2002. The TIGER
Treebank. In Proceedings of the Workshop on Tree-
banks and Linguistic Theories.
Butt, Miriam, Helge Dyvik, Tracy Holloway King, Hi-
roshi Masuichi, and Christian Rohrer. 2002. The
Parallel Grammar Project.
Geuder, Wilhelm. 2004. Depictives and transpar-
ent adverbs. In Austin, J. R., S. Engelbrecht,
and G. Rauh, editors, Adverbials. The Interplay of
Meaning, Context, and Syntactic Structure, pages
131?166. Benjamins.
Hwa, Rebecca, Philip Resnik, Amy Weinberg, Clara
Cabezas, and Okan Kolak. 2005. Bootstrapping
parsers via syntactic projection across parallel texts.
Nat. Lang. Eng., 11(3):311?325.
Malouf, Robert. 2002. A comparison of algorithms
for maximum entropy parameter estimation. In Pro-
ceedings of the Sixth Conference on Natural Lan-
guage Learning (CoNLL-2002), pages 49?55.
Mihalcea, Rada, Carmen Banea, and Jan Wiebe.
2007. Learning multilingual subjective language
via cross-lingual projections. In Proceedings of
the Association for Computational Linguistics (ACL
2007), pages 976?983, Prague.
Pado?, Sebastian and Mirella Lapata. 2009. Cross-
lingual annotation projection of semantic roles.
Journal of Artificial Intelligence Research, 36:307?
340.
Ratnaparkhi, Adwait. 1996. A maximum entropy
model for part-of-speech tagging. In Proceedings
of EMNLP 96, pages 133?142.
Riezler, Stefan, Tracy Holloway King, Ronald M. Ka-
plan, Richard Crouch, John T. Maxwell, and Mark
Johnson. 2002. Parsing the Wall Street Journal
using a Lexical-Functional Grammar and Discrim-
inative Estimation Techniques . In Proceedings of
ACL 2002.
Rohrer, Christian and Martin Forst. 2006. Improving
coverage and parsing quality of a large-scale LFG
for German. In Proceedings of LREC-2006.
Schmid, Helmut. 1994. Probabilistic part-of-speech
tagging using decision trees. In Proceedings of In-
ternational Conference on New Methods in Lan-
guage Processing.
Yarowsky, David, Grace Ngai, and Richard Wicen-
towski. 2001. Inducing multilingual text analy-
sis tools via robust projection across aligned cor-
pora. In Proceedings of HLT 2001, First Interna-
tional Conference on Human Language Technology
Research.
Zarrie?, Sina, Aoife Cahill, Jonas Kuhn, and Christian
Rohrer. 2010. A Cross-Lingual Induction Tech-
nique for German Adverbial Participles. In Pro-
ceedings of the 2010 Workshop on NLP and Lin-
guistics: Finding the Common Ground, ACL 2010,
pages 34?42, Uppsala, Sweden.
1434
