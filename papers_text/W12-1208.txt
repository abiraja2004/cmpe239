JEP-TALN-RECITAL 2012, Atelier DEGELS 2012: D?fi GEste Langue des Signes, pages 93?98,
Grenoble, 4 au 8 juin 2012. c?2012 ATALA & AFCP
Un syst?me de segmentation automatique de gestes appliqu?
? la Langue des Signes
Matilde Gonzalez
IRIT (UPS - CNRS UMR 5505) Universit? Paul Sabatier,
118 Route de Narbonne,
F-31062 TOULOUSE CEDEX 9
gonzalez@irit.fr
R?SUM?
De nombreuses ?tudes sont en cours afin de d?velopper des m?thodes de traitement automa-
tique de langues des signes. Plusieurs approches n?cessitent de grandes quantit?s de donn?es
segment?es pour l?apprentissage des syst?mes de reconnaissance. Nos travaux s?occupent de la
segmentation semi-automatique de gestes afin de permettre d?identifier le d?but et la fin d?un
signe dans un ?nonc? en langue des signes. Nous proposons une m?thode de segmentation des
gestes ? l?aide des caract?ristiques de mouvement et de forme de la main.
ABSTRACT
An automatic gesture segmentation system applied to Sign Language
Many researches focus on the study of automatic sign language recognition. Many of them need
a large amount of data to train the recognition systems. Our work address the segmentation of
gestures in sign language video corpus in order to identify the beginning and the end of signs.
We propose an approach to segment gestures using motion and hand shape features.
MOTS-CL?S : Segmentation de gestes, langue des signes, segmentation de signes.
KEYWORDS: Gesture segmentation, sign language, sign segmentation.
1 Introduction
La langue des signes (LS) est une langue gestuelle d?velopp?e par les sourds pour communiquer.
Un ?nonc? en LS consiste en une s?quence de signes r?alis?s par les mains, accompagn?s
d?expressions du visage et de mouvements du haut du corps, permettant de transmettre des
informations en parall?les dans le discours. M?me si les signes sont d?finis dans des dictionnaires,
on trouve une tr?s grande variabilit? li?e au contexte lors de leur r?alisation. De plus, les
signes sont souvent s?par?s par des mouvements de co-articulation (aussi appel? ?transition?).
Un exemple est montr? dans la Figure 1. Cette extr?me variabilit? et l?effet de co-articulation
repr?sentent un probl?me important dans la segmentation automatique de gestes.
Une m?thode permettant de segmenter semi-automatiquement des ?nonc?s en LS, sans utiliser
d?apprentissage automatique est pr?sent?. Plus pr?cis?ment, nous cherchons ? d?tecter les limites
de d?but et fin de signes. Cette m?thode de segmentation de gestes n?cessite plusieurs traitements
de bas niveau afin d?extraire les caract?ristiques de mouvement et de forme de la main. Les
93
United States Tower (co-articulation) 
FIGURE 1 ? Exemple de co-articulation : geste netre la fin du signe "Etats-Unis" et le debout du
signe "tour" en Langue de Signes Fran?aise.
caract?ristiques de mouvement sont utilis?es pour r?aliser une premi?re segmentation qui est par
la suite am?lior?e gr?ce ? l?utilisation de caract?ristiques de forme. En effet,celles-ci permettent
de supprimer les limites de segmentation d?tect?es en milieu des signes.
Cet article est structur? comme suit. La section 2 pr?sente une synth?se des m?thodes de
segmentation automatique appliqu?es ? la LS. Nous montrons ensuite dans la section 3 l?extraction
de caract?ristiques de mouvement et de forme afin de segmenter les gestes dans la s?quence
vid?o. Des r?sultats exp?rimentaux sont ensuite pr?sent?s en section 4. Enfin, en section 5,
une conclusion rappelle les principaux r?sultats obtenus et ?voque quelques perspectives de
recherche.
2 Segmentation Automatique des Signes : ?tat de l?art
Actuellement plusieurs recherches s?int?ressent au probl?me de l?analyse automatique de la
LS (Ong et Ranganath, 2005), plus particuli?rement de sa reconnaissance (Imagawa et al,
1998; Starner et Pentland, 1995; Zieren et al, 2006). Dans (Grobel et Assan, 1997) les donn?es
d?apprentissage sont des signes isol?s r?alis?s plusieurs fois par un ou plusieurs signeurs. La
r?alisation des signes est d?pendante du contexte et, dans le cas des signes isol?s, la co-articulation
n?est pas prise en compte. En ce qui concerne la segmentation automatique de gestes en LS,
Nayak et al (Nayak et al, 2009) ont propos? une m?thode qui permet d?extraire automatiquement
les limites d?un signe ? l?aide de plusieurs occurrences du signe dans la vid?o. Ils consid?rent
la forme et la position relative des mains par rapport au corps. Pour la plupart des signes ces
caract?ristiques varient ?norm?ment selon le contexte cantonnant cette approche ? quelques
exemples typiques. Lefebvre et Dalle (Lefebvre-Albaret et Dalle, 2010) ont pr?sent? une m?thode
utilisant des caract?ristiques de bas niveau afin de segmenter semi-automatiquement les signes.
Ils ne consid?rent que le mouvement dans le but d?identifier plusieurs types de sym?tries. Or
plusieurs signes sont compos?s de plusieurs s?quences avec diff?rents types de sym?trie, ces
signes seront sur-segment?s.
Afin de r?soudre certains probl?mes ?mergents de l??tat de l?art nous proposons une m?thode de
segmentation automatique des signes qui exploite le caract?ristiques de mouvement, et de forme
de la main.
94
Choqu? 
? 
Main droite Main gauche 
Vitesse  
Image 
FIGURE 2 ? Signe "choqu?" en LSF et vitesse des deux mains.
3 Segmentation automatique de gestes
La segmentation des signes correspond ? la d?tection du d?but et de la fin d?un signe. Pour cela
nous utilisons les r?sultats de suivi de composantes corporelles (Gonzalez et Collet, 2011) afin
de segmenter les signes gr?ce ? des caract?ristiques de mouvement. Ensuite la forme de la main
est utilis?e pour am?liorer les r?sultats de segmentation (Gonzalez et Collet, 2010).
3.1 Classification du mouvement
Les caract?ristiques de mouvement sont extraites ? partir des r?sultats du suivi des composantes
corporelles. Les vitesses des mains droite et gauche, v1(t) et v2(t) sont calcul?es ? l?aide despositions des mains pour chaque image. La norme de la vitesse est utilis?e pour le calcul de la
vitesse relative vr(t), c?est-?-dire la diff?rence entre la vitesse de la main gauche et celle de lamain droite. Quand les mains bougent ensemble nous remarquons un l?ger d?calage entre les
profils de vitesses des deux mains bien que leur allure reste tr?s proche comme on peut le voir
avec le signe "Choqu?" (Fig. 2).
Gr?ce ? la vitesse relative nous d?terminons les s?quences statiques, aucune main ne bouge, ou
celles r?alis?es avec une ou deux mains. A partir de cette classification nous pouvons identifier les
?v?nements d?finis comme les d?but et fin potentiels de signes et d?tect?s comme un changement
de classe. Toutefois cette approche d?tecte des ?v?nements en milieu de signe. On dit alors que les
s?quences ont ?t? sur-segment?es. Par exemple la figure 3(gauche) illustre la r?alisation du signe
"Quoi ?" en LSF. Il s?agit d?un signe sym?trique r?p?t? o? les deux mains bougent simultan?ment
en direction oppos?e. La figure 3(droite) montre les ?v?nements d?tect?s en fonction des classes
d?finies pr?c?demment. La segmentation peut ?tre am?lior?e en tenant compte de la forme
des mains car, pour ce signe comme pour beaucoup d?autres, la configuration des mains reste
inchang?e.
95
Quoi? 
?v?nements d?tect?s 
Quoi? 
FIGURE 3 ? Signe ?Quoi ?? en LSF et les vitesses pour les deux mains, la vitesse relative et les
?v?nements d?tect?s.
= = ? ? 
D?tection automatique 
                               Signe ( Quoi?)                                            Signe Annotation manuelle 
67 68 69 66 65 N? d??v?nement 
FIGURE 4 ? Illustre les mains segment?es pour chaque ?v?nement d?tect? ainsi que la v?rit?-
terrain.
3.2 Caract?risation de la forme des mains
Dans cette ?tape nous introduisons des informations sur la forme de la main afin de corriger la
sur-segmentation. La reconnaissance de la configuration de la main est un probl?me complexe
du fait de la grande variabilit? de la forme 2D obtenue ? l?aide d?une seule cam?ra.
Afin d?extraire les caract?ristiques de forme, nous devons d?abord segmenter les mains pour
chaque ?v?nement. La forme de la main est syst?matiquement compar?e avec celle des ?v?-
nements adjacents. Nous utilisons deux mesures de similarit? : le diam?tre ?quivalent ?d etl?excentricit? ?. L?avantage d?utiliser ces types de mesures est l?invariance en translation et en
rotation. Cependant l?inconv?nient est la sensibilit? au changement d??chelle et au bruit. La
figure 4 montre les r?sultats de segmentation du signe "Quoi ?" en LSF. L??tape pr?c?dente a
segment? le signe en tenant compte des caract?ristiques de mouvement ce qui a entrain? la
sur-segmentation du signe. Nous remarquons que la forme des mains reste similaire entre certains
?v?nements d?tect?s. On supprime donc celui du milieu pour corriger la segmentation.
96
4 R?sultats exp?rimentaux
Nous avons r?alis? l??valuation ? l?aide de deux s?quences vid?o sans aucune contrainte sur la
langue : LS Colin et DEGELS. L?algorithme de segmentation a ?t? appliqu? sur 2500 images. Les
v?rit?s-terrain pour les deux s?quences ont ?t? manuellement r?alis?es par un signeur sourd-n?.
L??valuation consiste ? ? compter les ?v?nements correctement segment?s en tenant compte d?une
tol?rance (TP : true positifs) et les ?v?nements d?tect?s mais qui ne correspondent pas ? une
limite annot?e (FP : False positif). La tol?rance ? pour le calcul du taux de TP a ?t? d?termin?e
exp?rimentalement. Un signeur exp?riment? a annot? une s?quence vid?o plusieurs fois afin de
d?terminer sa variabilit? qui s??l?ve dans notre cas ? 1,7 images en moyenne. La segmentation
est consid?r?e comme correcte si le nombre d?images entre l?annotation et l??v?nement d?tect?
est proche ? la variabilit? du signeur. Le tableau 4 montre les r?sultats pour les deux s?quences
vid?o avec une tol?rance de deux images. On remarque qu?? l?introduction des caract?ristiques
de forme de la main le taux de TP reste le m?me alors que le taux de FP diminue de 3% pour
LS-Colin et de 10% pour le corpus Degels.
Motion Motion + Hand
Shape
TP(%) FP(%) TP(%) FP(%)
LS- Colin 81.6 46.2 81.6 44.9
DEGELS 74.5 54.2 74.5 44.7
TABLE 1 ? R?sultats de segmentation de gestes
5 Conclusion
Nous pr?sentons ici un syst?me de segmentation temporelle de s?quences vid?o en LS. La
segmentation a ?t? r?alis?e en ne consid?rant que des caract?ristiques de bas niveau, ce qui
rend notre m?thode g?n?ralisable pour toutes les LS. Nous utilisons d?abord les caract?ristiques
de mouvement extraites ? l?aide de notre algorithme de suivi qui est robuste aux occultations.
Ensuite gr?ce aux caract?ristiques de forme de la main nous sommes capable de corriger la
segmentation. Cette m?thode a montr? des r?sultats prometteurs qui peuvent ?tre utilis?s pour
la reconnaissance de signes et pour l?annotation en gloses des s?quences ? l?aide d?un mod?le
linguistique de la LS.
Remerciements
Ces recherches sont financ?es par le 7?me programme cadre Communaut? Europ?enne
(FP7/2007-2013) accord no 231135.
97
R?f?rences
GONZALEZ, M. et COLLET, C. (2010). Head tracking and hand segmentation during hand over
face occlusion in sign language. In Int. Workshop on Sign, Gesture, and Activity (ECCV).
GONZALEZ, M. et COLLET, C. (2011). Robust body parts tracking using particle filter and dynamic
template. In 18th IEEE ICIP, pages 537?540.
GROBEL, K. et ASSAN, M. (1997). Isolated sign language recognition using hidden markov
models. In IEEE Int. Conference on Systems, Man, and Cybernetics, volume 1, pages 162?167.
IEEE.
IMAGAWA, K., LU, S. et IGI, S. (1998). Color-based hands tracking system for sign language
recognition. In Proc. 3rd IEEE International Conference on Automatic Face and Gesture Recognition,
pages 462?467.
LEFEBVRE-ALBARET, F. et DALLE, P. (2010). Body posture estimation in sign language videos.
Gesture in Embodied Communication and HCI, pages 289?300.
NAYAK, S., SARKAR, S. et LOEDING, B. (2009). Automated extraction of signs from continuous
sign language sentences using iterated conditional modes. CVPR, pages 2583?2590.
ONG, S. et RANGANATH, S. (2005). Automatic sign language analysis : A survey and the future
beyond lexical meaning. IEEE Tran. on Pattern Analysis and Machine Intelligence, pages 873?891.
STARNER, T. et PENTLAND, A. (1995). Real-time american sign language recognition from video
using hidden markov models. In Proc. International Symposium on Computer Vision, pages
265?270.
ZIEREN, J., CANZLER, U., BAUER, B. et KRAISS, K. (2006). Sign language recognition. Advanced
Man-Machine Interaction, pages 95?139.
98
