Best-First Surface Realization 
Stephan Busemann* 
DFKI  GmbH 
Stuhlsatzenhausweg 3 
D-66123 Saarbriicken 
emaih busemann@dfki ,  un i - sb ,  de 
Abst rac t  
Current work in surface realization concen- 
trates on the use of general, abstract algo- 
rithms that interpret large, reversible gram- 
mars. Only little attention has been paid 
so far to the many small and simple appli- 
cations that require coverage of a small sub- 
language at different degrees of sophistica- 
tion. The system TG/2 described in this pa- 
per can be smoothly integrated with deep gen- 
eration processes, it integrates canned text, 
templates, and context-free rules into a sin- 
gle formalism, it allows for both textual and 
tabular output, and it can be parameterized 
according to linguistic preferences. These fea- 
tures are based on suitably restricted produc- 
tion system techniques and on a generic back- 
tracking regime. 
1 Mot ivat ion  
Current work in surface realization concen- 
trates on the use of general, abstract algo- 
rithms that interpret declaratively defined, 
non-directional grammars. It is claimed that 
this way, a grammar can be reused for parsing 
*This work has been supported by a grant from 
The Federal Ministry for Research and Technology 
(FKZ ITW 9402). I am grateful to Michael Wein, 
who implemented the interpreter,  and to Jan  Alexan- 
dersson for influential work on a previous version of 
the system. Finally, I wish to thank  two anonymous 
reviewers for useful suggestions. All errors contained 
in this paper are my own. 
and generation, or a generator can interpret 
different grammars (e.g. in machine transla- 
tion). A prominent example for this type 
of abstract algorithm is semantic-head-driven 
generation \[Shieber et al, 1990\] that has been 
used with HPSG, CUG, DCG and several oth- 
er formalisms. 
In practice, this type of surface realization 
has several drawbacks. First, many existing 
grammars have been developed with parsing 
as the primary type of processing in mind. 
Adapting their semantics layer to a genera- 
tion algorithm, and thus achieving reversibil- 
ity, can turn out to be a difficult enterprise 
\[Russell et al, 1990\]. Second, many linguisti- 
cally motivated grammars do not cover com- 
mon means of information presentation, such 
as filling in a table, bulletized lists, or semi- 
frozen formulae used for greetings in letters. 
Finally, the grammar-based logical form rep- 
resentation hardly serves as a suitable inter- 
face to deep generation processes. Grammar- 
based semantics is, to a large extent, a com- 
positional reflex of the syntactic structure and 
hence corresponds too closely to the surface 
form to be generated. As a consequence, on- 
ly little attention has been paid to interfacing 
this type of realizers adequately to deep gen- 
eration processes, e.g. by allowing the latter 
to influence the order of results of the former. 
The system TG/2, which is presented in 
this contribution, overcomes many flaws of 
grammar-based surface realization systems 
that arise in concrete applications. In par- 
ticular, TG/2 
101 
? can be smoothly integrated with 'deep' 
generation processes, 
? integrates canned text, templates, and 
context-free rules into a single formalism, 
? allows for both textual and tabular out- 
put, 
? efficiently reuses generated substrings for 
additional solutions, and 
? can be parameterized according to lin- 
guistic properties (regarding style, gram- 
mar, fine-grained rhetorics etc.). 
TG/2 is based on restricted production sys- 
tem techniques that preserve modularity of 
processing and linguistic knowledge, hence 
making the system transparent and reusable 
for various applications. Production systems 
have been used both for modeling human 
thought (e.g. \[Newell, 1973\]) and for the con- 
struction of knowledge-based xpert systems 
(e.g. \[Shortliffe, 1976\]). In spite of the modu- 
larity gained by separating the rule basis from 
the interpreter, production systems have dis- 
appeared from the focus of current research 
because of their limited transparency aused 
by various types of side effects. In particu- 
lar, side effects could modify the data base in 
such a way that other rules become applicable 
\[Davis and King, 1977\]. 
However, precondition-action pairs can be 
used in a more restricted way, preserving 
transparency by disallowing side effects that 
affect the database. In TG/2 preconditions 
are tests over the database contents (the gen- 
erator's input structure), and actions typical- 
ly lead to a new subset of rules the applicabil- 
itv of which would be tested on some selected 
portion of the database. By constraining the 
effects of production rules in such a way, the 
disadvantages of early production systems are 
avoided. At the same time, considerable flex- 
ibility is maintained with regard to linguistic 
knowledge used. A production rule may 
? involve a direct mapping to surface forms 
(canned text), 
? require to fill in some missing portion 
from a surface text (template), or 
? induce the application of other rules 
(classical grammar rules) 
Early template-based generation methods 
have correctly been criticized for beeing too 
inflexible to account adequately for the com- 
municative and rhetorical demands of many 
applications. On the other hand, templates 
have been successfully used when these de- 
mands could be hard-wired into the rules. In 
TG/2 the rule writer can choose her degree 
of abstraction according to the task at hand. 
She can freely intermix all kinds of rules. 
The rest of the paper is organized as fol- 
lows. TG/2 assumes as its input a predicate- 
argument structure, but does not require any 
particular format. Rather, a separate transla- 
tion step is included that translates the out- 
put of feeding components into expressions 
of the Generator Interface Language (GIL) 
(Section 2). In Section 3 the formalism TGL 
(Template Generation Language) for produc- 
tion rules is introduced. The properties of 
TGL allow for efficient generation of all pos- 
sible solutions in any order. The TGL inter- 
preter and its generic backtracking regime are 
presented in Section 4. It is used to param- 
eterize TG/2 by inducing an order in which 
the solutions are generated (Section 5). 
Figure 1 gives an overview of the system 
and its components. 
2 The Generation Interface 
Language (GIL) 
Although the level of logical form is consid- 
ered a good candidate for an interface to sur- 
face realization, practice shows that notation- 
al idosyncrasies can pose severe translation 
problems. TG/2 has an internal language, 
GIL, that corresponds to an extended pred- 
icate argument structure. GIL is the basis for 
the precondition test predicates and the se- 
lector functions of TGL. Any input to TG/2 
102 
Input structure 
translation 
G IL-Structure 
f G Substructure 
stack i -  
t ~ GIL 
N E i = m  m 
T J 
o m 
R 
TGL Production Rules 
l~l EZ3 I---I r--11EE3 I'--I r~l 
mm~mmummm 
m m m m m  
- -  m m m m m m  
TGL E 
? test rules 
? select a rule 
? apply the rule 
Output String 
N 
G 
I 
N 
E 
Figure 1: Overview of the system TG/2. 
is first translated into GIL before being pro- 
cessed. It is of considerable practical benefit 
to keep the rule basis as independent as possi- 
ble from external conditions (such as changes 
to the output specification of the feeding sys- 
tem). 
GIL is designed to be a target language 
suited for deep generation processes. Similar 
aims have been pursued with the development 
of the Sentence Plan Language (SPL) \[Kasper 
and V'hitney, 1989\] that is used in a variety of 
generation systems. Like SPL, GIL assumes 
only little grammatical information. GIL can 
represent DAG-like feature structures. Fig- 
ure 2 contains a sample GIL expression. The 
example shows the major language lements: 
? The top level consists of a speech act 
predicate and arguments for author, ad- 
dressee and theme (the speechact prop- 
er). 
? Discourse objects can be assigned unique 
constants (I.D) that denote SETs of dis- 
course objects. 
? SMOOD expresses entence modalities in- 
103 
\[(PRED request) 
(HEARER \[(ID refo365) (SET < nussbaum >)\]) 
(SPEAKER \[(ID refo752) (SET < digisec >)\]) 
(THEME \[(SMOOD \[(TOPIC #i) (MODALITY unmarked) (TIME pres)\]) 
(PRED meet) 
(DREF \[(ID refo610) (SET < meetl >)\]) 
(ARGS < #1= \[(ROLE agent) 
(CARD single) 
(CONTENT \[(DREF \[(ID refo621) (SET < zweig >)\]) 
(QFORCE noquant) 
(PRED humname) 
(NAME \[(TITLE \"Prof.\") 
(SURNAME \"Zweig\") 
(SORT female)\])\])\], 
\[(ROLE patient) 
(CARD single) 
(CONTENT \[(DREF \[(ID refo365) (SET < nussbaum >)\]) 
(QFORCE iota) 
(PRED object)\])\] >) 
(TIME-ADJ \[(ROLE on) (CONTENT \[(WEEKDAY 5)\])\])\])\] 
Figure 2: A sample GIL input structure (Prof. Zweig will Sic am Freitag treffen \[Prof. Zweig 
wants to meet you on Friday\]. < and > are list delimiters; # denotes coreferences. 
cluding sentence type, time, a specifica- 
tion of which constituents to topicalize in 
a German declarative sentence, etc. 
? The predicate argument structure is re- 
flected by corresponding features: ARGS 
contains a list of arguments. 
? Different sorts of free temporal and local 
adjuncts can be specified by correspond- 
ing features. In Figure 2, a temporal ad- 
junct is represented under TIME-ADJ. 
? Arguments and, in part, adjuncts are 
specified for their role, for cardinal- 
ity, for quantificational force (under 
C0NTENT.QFORCE), and further details 
such as name strings and natural gender. 
? Temporal adjuncts relate to some context 
(e.g. tomorrow) or are indexical (e.g. on 
Wednesday, February 7, 1996). All com- 
mon combinations in German are cov- 
ered. 
3 The Template Generation 
Language (TGL) 
TGL defines a general format for expressing 
production rules as precondition-action pairs 
(cf. Figure 3). A TGL rule is applicable if its 
preconditions are met. A TGL rule is suc- 
cessfully applied, if the action part has been 
executed without failure. Failure to apply a 
TGL rule signals that the rule does not cover 
the portion of the input structure submitted 
to it. 
Figure 4 shows a sample TGL rule. It cor- 
responds to an infinitival VP covering a direct 
object, an optional temporal adjunct, an op- 
tional expression for a duration (such as for 
an hour), an optional local adjunct (such as 
at the DFKI  building) , and the infinite verb 
form. Given the input GIL structure of Fig- 
ure 2, the VP Sic am Freitag treffen \[to meet 
you on Friday\] could be genorated from this 
rule. Among the optional constituents, only 
the temporal adjunct would find appropriate 
104 
<rule> 
<tgl-rule> 
<category> 
<template> 
::= (DEFPRODUCTION <string> <tgl-rule>) 
::= (:PRECOND (:CAT <category> 
:TEST (<lisp-code>+)) 
:ACTIONS (:TEMPLATE <template>+ 
{:SIDE-EFFECTS <lisp-code>} 
{:CONSTRAINT <feature-equation>+})) 
::= TXT I S l VP I NP J PP \] PPdur \] INF J ADJ \] ... 
::= (:RULE <category> <lisp-code>) \] 
(:0PTRULE <category> <lisp-code>) I 
(:FUN <lisp-code>) I 
<string> 
Figure 3: An excerpt of TGL Syntax. 
material in the GIL input structure (under 
THEME. TIME-ADJ). 
Every TGL rule has a unique name, denot- 
ed by the initial string. This name is used for 
expressing preferences on alternative rules (cf. 
Section 5). 
Category i  The categories can be defined as 
in a context-free grammar. Correspond- 
ingly, categories are used for rule selec- 
tion (see below). They ensure that a 
set of TGL rules possesses a context-free 
backbone. 
Test: The Lisp code under : TEST is a boolean 
predicate (usually about properties of the 
portion of input structure under investi- 
gation or about the state of some mem- 
ory). In the sample rule, an argument is 
required that fills the patient role. 
Template :  Actions under :TEMPLATE 1 in- 
clude the selection of other rules ( : RULE, 
: 0PTRULE), executing a function (:FUN), 
or returning an ASCII string as a (par- 
tial) result. 
When selecting other rules by virtue of 
a category, a Lisp function is called that 
1The notion of template is preserved for histori- 
cal reasons: the predecessor system TG/1 was strictly 
template-based, 
identifies the relevant portion of the in- 
put structure for which a candidate rule 
must pass its associated tests. In Fig- 
ure 4, the first action selects all rules with 
category NP; the relevant substructure is 
the argument filling the patient role (cf. 
the second element of the ARGS list in Fig- 
ure 2). If there is no such substructures 
an error is signalled 2 unless an 0PTRULE 
slot (for "optional rule") was executed. 
In this case, processing continues with- 
out results from that slot. 
Functions must return an ASCII string. 
They are mostly used for word inflection; 
otherwise, for German every inflection- 
al variant would have to be encoded as a 
rule. TG/2  uses the morphological inflec- 
tion component MORPHIX \[Finkler and 
Neumann, 1988\]. 
Side effects: The Lisp code under 
: SIDE-EFFECTS is a function whose value 
is ignored. It accounts for non-local de- 
pendencies between substructures, uch 
as updates of a discourse memory. Note 
that these effects can be traced and un- 
done in the case of backtracking. 
2In the case at hand, the grammar writer preferred 
to ensure availability of the substructure by virtue of 
the test predicate. 
105 
(defproduction "VPinf with temp/loc adjuncts" 
(:PRECOND (:CAT VP 
:TEST ((role-filler-p 'patient))) 
:ACTIONS (:TEMPLATE (:RULE NP (role-filler 'patient)) 
(:0PTRULE PP (temp-adjunct)) 
(:0PTRULE PPdur (temp-duration)) 
(:0PTRULE PP (lot-adjunct)) 
(:RULE INF (theme)) 
:CONSTRAINTS (CASE (NP) :VAL 'akk)))) 
Figure 4: A sample production rule for a VP with an infinitive verb form placed at the end. 
Constraints:  Agreement relations are en- 
coded into the rules by virtue of a PATR 
style \[Shieber et al, 1983\] feature per- 
colation mechanism. The rules can be 
annotated by equations that either as- 
sert equality of a feature's value at two 
or more constituents or introduce a fea- 
ture value at a constituent. Attempt- 
ing to overwrite a feature specification 
yields an error. In Figure 4, the right- 
hand side constituent NP is assigned ac- 
cusative case. Any of these effects are 
subject to backtracking. 
Using TGL, small task- and domain-specific 
grammars can be written quickly. For in- 
stance, in the domain of appointment schedul- 
ing the system COSMA \[Busemann et al, 
1994\] has to accept, reject, modify, or re- 
fine suggested meeting dates via email. The 
sublanguage ncoded in TGL only needs a 
few speech acts, about twenty sentential tem- 
plates, and a complete account of German 
date expressions. Moreover, formal as well 
as informal opening and closing phrases for 
emails are covered. 
Larger grammars may become difficult to 
maintain unless special care is taken by the 
grammar writer to preserve a global struc- 
ture of rules, both by defining suitable cat- 
egories and by documenting the rules. TGL 
rules are presently written using a text editor. 
A specialized TGL grammar editor could im- 
prove the development and the organization of 
grammars considerably. Syntactic orrectness 
is checked at compile-time by an LR-Parser 
generated by Zebu \[Laubsch, 1992\] on the ba- 
sis of a BNF syntax for TGL. 
4 An interpreter with 
generic backtracking 
TG/2 has a simple interpretation proce- 
dure that corresponds to the classical three- 
step evaluation cycle in production systems 
(matching, conflict resolution, firing) \[Davis 
and King, 1977\]. The algorithm receives a 
GIL structure as its input and uses a distin- 
guished category, TXT, to start from. 
1. Match ing :  Select all rules carrying the 
current category. Execute the tests for 
each of these rules on the input structure 
and add those passing their test to the 
conflict set. 
2. Conf l ict  reso lut ion:  Select an element 
from the conflict set. 
3. F i r ing:  Execute its side effect code (if 
any). Evaluate its constraints (if any). 
For each action part, read the catego- 
ry, determine the substructure of the in- 
put by evaluating the associated func- 
tion, and goto 1. 
The processing strategy is top-down and 
depth-first. The set of actions is fired from 
106 
B1 
/32 
B2~ \[ 
pre context ego post context 
st ~\ -- {s2i\[1 _< i _< Isll} s3.v2.ss 
.51.v1.83 ~? = {s4jll _< j _< IB21} ss 
st.Vl.sa's5j = {s6kll _< k < IB2,1} 
where 84j -~- 85j'V21 "87j 
87j "88 
Figure 5: Table of Backtrack Points: B2 is encountered outside of the ego of Bt. B2~ is 
encountered inside the ego of B2. 
left to right. Failure of executing some action 
causes the rule to be backtracked. 
The interpreter yields all solutions the 
grammar can generate. It attempts to gener- 
ate and output a first solution, producing pos- 
sible alternatives only on external demand. 
Any alternative is based on backtracking at 
least one rule. Backtrack points correspond 
to conflict sets containing more than one ele- 
ment. 
Backtracking may turn out to be inefficient 
if it involves recomputation of previously gen- 
erated substrings. In TG/2  this effort is re- 
duced considerably because it is only neces- 
sary to recompute the part licensed by the 
newly selected rule. What has been generat- 
ed before or after it remains constant (modulo 
some word forms that need to agree with new 
material) and can thus be reused for subse- 
quent solutions. This is possible due to the 
design properties of TGL: rules cannot irre- 
vocably influence other parts of the solution. 
In particular, the context-free backbone im- 
plicit in any solution and the restrictions to 
side effects mentioned above keep the struc- 
tural effects of TGL rules local. 
In the sequel, technical aspects of the back- 
tracking regime are discussed. Let us as- 
sume that the interpreter compute a back- 
track point. Let us call the sequence of strings 
generated by previous actions its pre-context, 
the set of string sequences generated from the 
elements of the conflict set its ego, and the se- 
quence of strings generated from subsequent 
actions its post-context. For every ego, the 
pre- or the post context may be empty. 
Each time a backtrack point is encountered 
during processing, an entry into a global table 
is made by specifying its pre-context (which is 
already known due to the left-to-right process- 
ing), a variable for the ego (which will collect 
the sequences of strings generated by the el- 
ements of the conflict set), and a variable for 
the post-context (which is unknown so far). a 
Figure 5 shows the state of a sample table 
comprising three backtrack points after all so- 
lutions have been computed. The ego vari- 
able is shown using indices running over the 
elements of the respective conflict sets. The 
operator '.' denotes concatenation of strings 
with strings or sets of strings, delivering all 
possible combinations. 
After the first solution has been found (i.e. 
Sl"S21 '83"851 "861"871 "S8), every ego set contains 
one element. The post contexts for all back- 
track points can be entered into the table. 
The next solution is generated by selecting 
anyone of the backtrack points and adding a 
new element o the ego set. At the same time. 
all other entries of the table are updated, and 
the set of additional solutions can be read off 
straightforwardly from the entry of the back- 
track point just processed. Assume, for in- 
stance, that B21 generates a second solution. 
thus causing V2~ to have two elements. We 
then get Sl'S21"83"851"862"871"88. Now assume 
that Bi also generates a second solution. This 
3In fact, it is preterminal rather than terminal ele- 
ments that are stored in the table in order to account 
for modified constraints. This can be neglected in the 
present discussion, but will be taken up again below. 
107 
directly yields two more solutions since the 
post context of B1 includes, via 84j, the two 
elements of V21. 
This way only the alternative lements of a 
conflict set have to be expanded from scratch. 
All other material can be reused. This is 
highly efficient for backtrack points introduc- 
ing "cheap" alternatives (e.g. different word- 
ings). Since the ego must be recomputed from 
scratch, much less is gained with backtrack 
points occurring at a higher level (e.g. active 
vs. passive sentence). In order to avoid hav- 
ing to recompute successfully generated par- 
tial results within the ego, such results are 
stored during processing together with the 
part of the input structure and the current 
category. They can be reused when passing 
an applicability test that requires the stored 
category and input structure to be identical 
to the current ones. 
The backtracking approach described is 
based on the assumption that any constraints 
introduced for some ego can be undone and 
recomputed on the basis of rules generating 
an alternative go. Clearly, features instanti- 
ated for some ego may have effects onto the 
pre- or post-context. If an agreement feature 
receives a different value during backtracking 
and it relates to material outside the ego, in- 
flectional processes for that material must be 
computed again. These cases can be detected 
by maintaining a trace of all constraint ac- 
tions. The recomputation is rendered possi- 
ble by adding, in addition to storing terminal 
strings in the table, the underlying calls to the 
inflection component as well. 
5 Parameter i za t ion  
Parameterization of TG/2  is based on spec- 
ifying the way how the generic backtracking 
regime should operate. It can be influenced 
with regard to 
? the element in the conflict set to be pro- 
cessed next, and 
? the backtrack point to be processed next. 
Both possibilities taken together allow a sys- 
tem that feeds TG/2  to specify linguistic cri- 
teria of preferred solutions to be generated 
first. 
The criteria are defined in terms of rule 
names, and a criterion is fulfilled if some cor- 
responding rule is successfully applied. We 
call such a rule c-rule. TG/2 implements 
a simple strategy that processes those back- 
track points first that have conflict sets con- 
taining c-rules, and preferrably choses a c-rule 
from a conflict set. When applied incremen- 
tally, this procedure yields all solutions fulfill- 
ing (some of) the criteria first. 
It would be desirable to see the solution ful- 
filling most criteria first. However, incremen- 
tal application enforces decisions to be taken 
locally for each conflict set. Any c-rule chosen 
may be the last one in a derivation, whereas 
chosing a non-c-rule may open up further op- 
portunities of chosing c-rules. These limits 
are due to a lack of look-ahead information: 
it is not known in general which decisions will 
have to be taken until all solutions have been 
generated. 4 Clearly, sacrificing incrementali- 
ty is not what should be desired although it 
may be acceptable for some applications. The 
drawbacks include a loss of efficiency and run- 
time. This leaves us with two possible direc- 
tions that can lead to improved results. 
Ana lyz ing  dependenc ies  of criteria: 
The solution fulfilling most criteria is gener- 
ated first if sets of mutually independent cri- 
teria are applied: fulfilling one criterion must 
not exclude the applicability of another one. 
unless two criteria correspond to rules of the 
same conflict set. In this case, they must allow 
for the the application of the same subset of 
criteria. If these conditions are met, chosing a 
c-rule from every conflict set, if possible, will 
lead to a globally best solution first. There is, 
however, the practical problem that the con- 
ditions on the criteria can only be fulfilled by 
4Note that this conclusion does not depend on the 
processing strategy chosen. 
108 
analyzing, and possibly modifying, the TGL 
grammar used. This contradicts the idea of 
having the user specify her preferences inde- 
pendent of TG/2 properties. 
Learning dependencies of criteria: 
Missing look-ahead information could be ac- 
quired automatically by exploiting the deriva- 
tional history of previously generated texts. 
For every applied rule, the set of c-rules ap- 
plied later in the current subtree of a deriva- 
tion is stored. From this information, we can 
derive off-line for any set of criteria which c- 
rules have applied in the corpus and how of- 
ten each c-rule has applied within a deriva- 
tion. Computing such information from the 
context-free backbone of TGL grammars in- 
stead would be less effective since it neglects 
the drastic filtering effects of preconditions. 
However. checking the grammar this way in- 
dicates which c-rules will not appear in some 
subtree. 
During processing, TG/2 can then judge 
the global impact of chosing the locally best 
c-rule and decide to fulfill or violate a cri- 
terion. The success of this method depends 
on how well the derivation under construction 
fits with the sample data. The more examples 
the system observes, the more reliable will be 
its decisions. 
The latter approach is in fact independent 
on how the criteria influence each other. In 
addition, it can be extended to cope with 
weighted criteria. A weight is specified by the 
user (e.g. a feeding system) and expresses the 
relative importance of the criterion being ful- 
filled in a solution. TG/2 would give prefer- 
ence to derivations leading to the maximum 
global weight. The global weight of a solution 
is the sum of the c-rule weights, each divided 
by the number of times the c-rule occurs. 
However, different GIL structures may, for 
a TGL rule, lead to different sets of follow-up 
c-rules. This causes the decision to be non- 
deterministic unless the reasons for the dif- 
ference are learned and applied to the case 
at hand. We must leave it to future research 
to identify ard apply suitable learning algo- 
rithms to solving this problem. 
Criteria have been implemented for choos- 
ing a language, for chosing between active and 
passive sentences, for preferring paratactical 
over hypotactical style, and for choice of for- 
mal vs. informal wordings. Additional uses 
could include some rhetorical structuring (e.g. 
order of nucleus and satellites in RST-based 
analyses \[Mann and Thompson. 1988\]). 
The approach presented offers a technical 
framework that allows a deep generation pro- 
cess to abstract away from many idiosyn- 
crasies of linguistic knowledge by virtue of 
meaningful weighting functions. Ideally, these 
functions must implement a theory of how 
mutual dependencies of criteria should be 
dealt with. For instance, lexical choice and 
constituent order constraints may suggest he 
use of passive voice (cf. e.g. \[Danlos, 1987\]). It 
is a yet open question whether such a theory 
can be encoded by weights. However, for some 
sets of preferences, this approach as proven 
to be sufficient and very useful. 
6 Conc lus ion  
In this contribution, we have introduced 
TG/2, a production-rule based surface gen- 
erator that can be parameterized to generate 
the best solutions first. The rules are encoded 
in TGL, a language that allows the definition 
of canned text items, templates, and context- 
free rules within the same formalism. TGL 
rules can, and should, be written with gen- 
eration in mind, i.e. the goal of reversibility 
of grammars pursued with many constraint- 
based approaches has been sacrificed. This is 
justified because of the limited usefulness of 
large reversible grammars for generation. 
TGL is particularly well suited for the de- 
scription of limited sublanguages specific to 
the domains and the tasks at hand. Par- 
tial reuse of such descriptions depends on 
whether the grammar writer keeps general. 
reusable definitions independent from the spe- 
cific, non-reusable parts of the grammar. For 
109 
instance, time and date descriptions encod- 
ed for the COSMA domain can be reused in 
other TG/2 applications. On the other hand, 
TGL sublanguage grammars can be devel- 
oped using existing resources. For instance, 
suitable fragments of context-free grammars 
translated into TGL could be augmented by 
the domain and task specific properties need- 
ed. Practical experience must show whether 
this approach saves effort. 
The system is fully implemented in Allegro 
Common Lisp and runs on different platforms 
(SUN workstations, PC, Macintosh). Com- 
puting the first solution of average-length sen- 
tences (10-20 words) takes between one and 
three seconds on a SUN SS 20. TG/2 is being 
used in the domain of appointment scheduling 
within DFKI's COSMA system. In the near 
future, the system will be used within an NL- 
based information kiosk, where information 
about environmental data must be provided 
in both German and French language, includ- 
ing tabular presentations if measurements of 
several substances are involved. 
References  
\[Busemann et al, 1994\] S. Busemann, S. Oe- 
pen, E. Hinkelman, G. Neumann, and 
H. Uszkoreit. COSMA-multi-participant 
NL interaction for appointment scheduling. 
Research Report RR-94-34, DFKI, Saar- 
brficken, 1994. 
\[Danlos, 1987\] L. Danlos. The Linguistic Ba- 
sis of Text Generation. Cambridge Univer- 
sity Press, Cambridge, 1987. 
\[Davis and King, 1977\] R. Davis and J. King. 
An overview of production systems. In 
E. W. Elcock and D. Michie. editors, Ma- 
chine Intelligence 8, pages 300-332. Ellis 
Horwood, Chichester, 1977. 
\[Finkler and Neumann, 1988\] W. Finkler and 
G. Neumann. Morphix: A fast realizatiop 
of a classification-based approach to mor- 
phology. In H. Trost, editor, Proc. der 
4. dJsterreichischen Artificial-Intelligence 
Tagung, pages 11-19, Berlin, August 1988. 
Springer. 
\[Kasper and Whitney, 1989\] R. Kasper and 
R. Whitney. SPL: A sentence plan language 
for text generation. Technical report, USC- 
ISI. Marina del Rey, 1989. 
\[Laubsch, 1992\] J. Laubsch. Zebu: A Tool 
for Specifying Reversible LALR(1) Parsers. 
Technical Report HPL-92-147. Hewlett- 
Packard Labs, Palo Alto, CA, July 1992. 
\[Mann and Thompson, 1988\] W. C. Mann 
and S. A. Thompson. Rhetorical structure 
theory: Toward a functional theory of text 
organization. Text, 8(3):243-281. 1988. 
\[Newell, 1973\] A. Newell. Production sys- 
tems: Models of control structures. In 
W. G. Chase, editor, Visual Informa- 
tion Processing, pages 463-526. Academic 
Press, New York, 1973. 
\[Russell et al, 1990\] G. Russell. S. Warwick, 
and J. Carroll. Asymmetry in parsing 
and generating with unification grammars: 
Case studies from ELU. In Proc. 28th A CL, 
pages 205-211., Pittsburgh, 1990. 
\[Shieber et al, 1983\] S. Shieber, H. Uszko- 
reit, F. Pereira, J. Robinson, and M. Tyson. 
The formalism and implementation of 
PATR-II. In B. J. Grosz and M. E. Stick- 
el, editors, Research on Interactive Acqui- 
sition and Use of Knowledge, pages 39-79. 
AI Center, SRI International, Menlo Park. 
CA, 1983. 
\[Shieber et al, 1990\] S. Shieber, G. van 
Noord, R. C. Moore, and F. Pereira. A 
semantic-head-driven g eration algorithm 
for unification-based formalisms. Compu- 
tational Linguistics, 16(1):30-42, 1990. 
\[Shortliffe, 1976\] E. H. Shortliffe. Computer- 
based Medical Consultations: MYCIN. El- 
sevier, New York, 1976. 
110 
