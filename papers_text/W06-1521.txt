Proceedings of the 8th International Workshop on Tree Adjoining Grammar and Related Formalisms, pages 141?146,
Sydney, July 2006. c?2006 Association for Computational Linguistics
Parsing TAG with Abstract Categorial Grammar
Sylvain Salvati
National Institute of Informatics
2-1-2 Hitotsubashi, Chiyoda-ku,
Tokyo 101-8430, JAPAN
salvati@nii.ac.jp
Abstract
This paper presents informally an Earley
algorithm for TAG which behaves as the
algorithm given by (Schabes and Joshi,
1988). This algorithm is a specialization
to TAG of a more general algorithm ded-
icated to second order ACGs. As second
order ACGs allows to encode Linear Con-
text Free Rewriting Systems (LCFRS) (de
Groote and Pogodalla, 2004), the presen-
tation of this algorithm gives a rough pre-
sentation of the formal tools which can
be used to design efficient algorithms for
LCFRS. Furthermore, as these tools allow
to parse linear ?-terms, they can be used
as a basis for developping algorithms for
generation.
1 Introduction
The algorithm we present is a specialization to
TAGs of a more general one dedicated to second
order Abstract Categorial Grammars (ACGs) (de
Groote, 2001). Our aim is to give here an informal
presentation of tools that can be used to design ef-
ficient parsing algorithms for formalisms more ex-
pressive than TAG. Therefore, we only give a rep-
resentation of TAGs with linear ?-terms together
with simple derivation rules; we do not give in
complete details the technical relation with ACGs.
For some more information about ACGs and their
relation to TAGs, one may read (de Groote, 2001)
and (de Groote, 2002).
The advantage of using ACG is that they are
defined with very few primitives, but can encode
many formalisms. Thus they are well suited to
study from a general perspective a full class of for-
malisms. In particular, a special class of ACGs
(second order ACGs) embeds LCFRS (de Groote
and Pogodalla, 2004), i.e. mildly context sensi-
tive languages. Therefore, the study of second
order ACGs leads to insights on mildly context
sensitive languages. Having a general framework
to describe parsing algorithms for mildly context
sensitive languages may give some help to trans-
fer some interesting parsing technique from one
formalism to another. It can be, for example, a
good mean to obtain prefix-valid algorithms, LC
algorithms, LR algorithms. . . for the full class of
mildly context sensitive languages.
The class of languages described by second or-
der ACGs is wider than mildly context sensitive
languages. They can encode tree languages, and
more generally languages of linear ?-terms. As
Montague style semantics (Montague, 1974) is
based on ?-calculus, being able to parse linear ?-
term is a first step towards generation algorithms
seen as parsing algorithm. Furthermore, since this
parsing algorithm is a generalization of algorithms
a` la Earley for CFGs and TAGs, the more general
algorithm that can be used for generation (when
semantic formulae are linear) can be considered
as efficient.
The paper is organized as follows: section two
gives basic defintions and tools concerning the lin-
ear ?-calculus. Section three explains how the in-
dices usually used by parsers are represented for
the linear ?-calculus. Section four gives a rough
explaination of the encoding of TAGs within a
compiled representation of second order ACGs.
Section five explains the parsing algorithm and we
conclude with section six.
2 The linear ?-calculus
We begin by giving a brief definition of linear
types and linear ?-terms together with some stan-
141
dard notations. We assume that the reader is famil-
iar with the usual notions related to ?-calculus (?-
conversion, free variables, capture-avoiding sub-
stitutions. . . ); for more details about ?-calculus,
one may consult (Barendregt, 1984).
Definition 1 The set of linear types, T , is the
smallest set containing {?} and such that if ?, ? ?
T then (?( ?) ? T .
Given a type (?1 ( (? ? ? (?n ( ?) ? ? ? )), we
write it (?1, . . . , ?n)( ?.
Definition 2 Given a infinite enumerable set of
variables, X , and an alphabet ?, we define the
set of linear ?-terms of type ? ? T , ??, as the
smallest set satisfying the following properties:
1. x ? X ? x? ? ??
2. t ? ?? ? x? ? FV (t) ? ?x?.t ? ??(?
3. a ? ? ? a ? ??(?
4. t1 ? ??(??t2 ? ???FV (t1)?FV (t2) ?
(t1t2) ? ??
In general, we write ?x1 . . . xn.t for
?x1. . . . ?xn.t and we write t0t1 . . . tn for
(. . . (t0t1) . . . tn). Strings are represented by
closed linear ?-terms of type str = ? ( ?.
Given a string abcde, it is represented by the
following linear ?-term: ?y?.a(b(c(d(e y?))));
/w/ represents the set of terms which are
?-convertible to the ?-term representing the
string w. Concatenation is represented by
+ = ?xstr1 xstr2 y?.xstr1 (xstr2 y?), and (+w1)w2
will be written w1 + w2. The concatenation
is moreover associative, we may thus write
w1 + ? ? ? + wn.
For the description of our algorithm, we rely on
contexts:
Definition 3 A context is a ?-term with a hole.
Contexts are defined by the following grammar:
C = [] | ?C | C? | ?V.C
The insertion of a term within a context is done
the obvious way. One has nevertheless to remark
that when a term t is inserted in a context C[], the
context C[] can bind variables free in t. For exam-
ple, if C[] = ?x.[] and t = x then C[t] = ?x.x
and x which was free in t is not free anymore in
C[t].
3 Indices as syntactic descriptions
Usually the items of Earley algorithms use indices
to represent positions in the input string. The algo-
rithm we describe is a particular instance of a more
general one which parses linear ?-terms rather
than strings. In that case, one cannot describe in a
simple way positions by means of indices. Instead
of indices, positions in a term t will be represented
with zippers ((Huet, 1997)), i.e. a pair (C[], v) of
a context and a term such that C[v] = t. Figure 1
explicits the correspondence between indices and
zippers via an example.
The items of Earley algorithms for TAGs use
pairs of indices to describe portions of the input
string. In our algorithm, this role is played by lin-
ear types built upon zippers; the parsing process
can be seen as a type-checking process in a par-
ticular type system. We will not present this sys-
tem here, but we will give a flavor of the mean-
ing of those types called syntactic descriptions
(Salvati, 2006). In order to represent the portion
of a string between the indices i and j, we use
the zippers (Ci[], vi) and (Cj [], vj) which respec-
tively represent the position i and j in the string.
The portion of string is represented by the syntac-
tic description (Cj [], vj) ( (Ci[], vi); this syn-
tactic description can be used to type functions
which take vj as argument and return vi as a re-
sult. For example, given the syntactic description:
(?x.a(b(c[])), d(e x)) ( (?x.a[], b(c(d(e x)))),
it represents the set of functions that result in
terms that are ?-convertible to b(c(d(e x))) when
they take d(e x) as an argument; this set is
exactly /bc/. Our algorithm uses representa-
tions of string contexts with syntactic descrip-
tions such as d = ((C1[], v1) ( (C2[], v2)) (
(C3[], v3)( (C4[], v4) (in the following we write
((C1[], v1)( (C2[], v2), (C3[], v3))( (C4[], v4)
for such syntactic descriptions). Assume that
(C1[], v1) ( (C2[], v2) represents /bc/ and that
(C3[], v3) ( (C4[], v4) represents /abcde/, then
d describes the terms which give a result in
/abcde/ when they are applied to an element
of /bc/. Thus, d describes the set of terms ?-
convertible to ?fy.a(f(d(e y))), the set of terms
representing the string context a[ ]de.
Some of the syntactic descriptions we use may
contain variables denoting non-specified syntactic
descriptions that may be instanciated during pars-
ing. In particular, the syntactic description vari-
able F will always be used as a non-specified syn-
142
0 (?x.[], a(b(c(d(e x))))) 1 (?x.a[], b(c(d(e x))))
2 (?x.a(b[]), c(d(e x))) 3 (?x.a(b(c[])), d(e x))
4 (?x.a(b(c(d[]), e x) 5 (?x.a(b(c(d(e[])))), x)
?a?b?c?d?e?
Figure 1: Correspondence indices/zippers for the string abcde
tactic description representing strings (i.e. F may
only be substituted by a syntactic description of
the form (C1[], v1) ( (C2[], v2)), such syntac-
tic descriptions will represent the foot of an auxil-
iary tree. We will also use Y to represent a non-
specifed point in the input sentence (i.e. Y may
only be substituted by syntactic descriptions of
the form (C[], v)), such syntactic descriptions will
represent the end of an elementary tree.
As syntactic desccriptions are types for the lin-
ear ?-calculus, we introduce the notion of typing
context for syntactic descriptions.
Definition 4 A typing context ? (context for
short), is a set of pairs of the form x : d where x
is a variable and d is a syntactic description such
that x : d ? ? and x : e ? ? iff d = e.
If x : d ? ?, then we say that x is declared with
type d in ?.
Typing contexts ? must not be confused with
contexts C[]. If a typing context ? is the set
{x1 : d1; . . . ;xn : dn} then we will write if by
x1 : d1, . . . , xn : dn. In the present paper, typing
contexts may declare at most two variables.
4 Representing TAG with second order
ACGs
We cannot give here a detailed definition of second
order ACGs here. We therefore directly explain
how to transform TAGs into lexical entries repre-
senting a second order ACG that can be directly
used by the algorithm.
We represent a TAG G by a set of lexical en-
tries LG. Lexical entries are triples (?, t, ?) where
? is a typing context, t is a linear ?-term and ?
is either Na, Ns or Na.1 if N is a non-terminal
of the considered TAG. Without loss of general-
ity, we consider that the adjunction at an interior
node of an elementary tree is either mandatory
or forbidden1 . We adopt the convention of rep-
1We do not treat here the case of optional adjunction, but
our method can be straightforwardly extended to cope with
it, following ideas from (de Groote, 2002). It only modifies
the way we encode a TAG with a set of lexical entries, the
algorithm remains unchanged.
resenting adjunction nodes labeled with N by the
variable xstr(strNa , the substitution nodes labeled
with N ? by the variable xstrNs , the foot node of
an auxiliary tree labeled with N? by the variable
f strNa.1 and the variable y? will represent the end
of strings. When necessary, in order to respect
the linearity constraints of the ?-terms, indices are
used to distinguish those variables. This conven-
tion being settled, the type annotation on variables
is not necessary anymore, thus we will write xNa ,
xNs , fNa.1 and y. To translate the TAG, we use
the function ? defined by figure 2. Given an initial
tree T whose root is labeled by N and t the normal
form of ?(T ), ( , t,Ns)2 is the lexical entry asso-
ciated to T ; if T is an auxiliary tree whose root
is labeled by N and t is the normal form of ?(T )
then ( , ?fNa.1.t,Na)2 is the lexical entry associ-
ated to T . A TAG G is represented by LG the
smallest set verifying:
1. if T is an elementary tree of G then the lexi-
cal entry associated to T is in LG.
2. if ( , t, ?) ? LG, with ? equals to Na or Ns,
and t = C[xNat1t2] then (?, t1, Na.1) ? LG
where ? = fMa.1 : F if fMa.1 ? FV (t1)
otherwise ? is the empty typing context.
Given a term t such that x? ? FV (t), and
(?, t?, ?) ? LG, then we say that t is rewritten
as t[x? := t?], t ? t[x? := t?]. Furthermore if x?
is the leftmost variable we write t ?l t[x? := t?].
It is easy to check that if t ?? t? with FV (t?) = ?,
then t ??l t?. A string w is generated by a LG
whenever xSs
?? t and t ? /w/ (S being the start
symbol of G). Straightforwardly, the set of strings
generated by LG is exactly the language of G.
5 The algorithm
As we want to emphasize the fact that the algo-
rithm we propose borrows much to type checking,
we use sequents in the items the algorithm manip-
ulates. Sequents are objects of the form ? ` t : d
2In that case the typing context is empty.
143
??
?
?
?
N
T1 Tn. . .
?
?
?
?
?? ?y.xNa(?(T1) + ? ? ? + ?(Tn))y xNa and y are fresh
?
?
?
?
?
NNA
T1 Tn. . .
?
?
?
?
?? ?(T1) + ? ? ? + ?(Tn)
?(N?) ?? ?y.xNa(?y.fN.1y)y
?(N?NA) ?? ?y.fN.1y
?(N ?) ?? ?y.xNsy
?(a) ?? ?y.ay
?() ?? ?y.y
Figure 2: Translating TAG into ACG: definition of ?
where ? is a typing context, t is a linear ?-term,
and d is a syntactic description.
The algorithm uses two kinds of items; either
items of the form (?; ? ` t : d;L) (where L is
a list of sequents, the subgoals, here L contains
either zero or one element) or items of the form
[Na.1; ?; t; (C1[], v1) ( (C2[], v2)]. All the pos-
sible instances of the items are given by figure 3.
The algorithm is a recognizer but can easily be ex-
tended into a parser3. It fills iteratively a chart until
a fixed-point is reached. Elements are added to the
chart by means of inference rules given by figure
4, in a deductive parsing fashion (Shieber et al,
1995). Inference rules contain two parts: the first
part is a set of premises which state conditions on
elements that are already in the chart. The second
part gives the new element to add to the chart if
it is not already present. For the more general al-
gorithm, the rules are not much more numerous as
they can be abstracted into more general schemes.
An item of the form (?; ?1 ` t1 : d; ?2 ` t2 :
(C1[], v1)) verifies:
1. (??1, t1, ?) ? LG where ??1 = fNa.1 : F if
?1 = fNa.1 : e or ??1 = ?1 otherwise.
2. there is a context C[] such that t1 = C[t2] and
if d is of the form (d1, . . . ,dn)( (C2[], v2)
(n must be 1, or 2) then C[y] ??l t? so that t?
is described by (C1[], v1)( (C2[], v2).
3. if ?1 = fNa.1 : (C3[], v3) ( (C4[], v4)
or if d = ((C3[], v3) ( (C4[], v4), Y ) (
3Actually, if it is extended into a parser, it will ouput the
shared forest of the derivation trees; (de Groote, 2002) ex-
plains how to obtain the derived trees from the derivation
trees in the framework of ACGs
(C2[], v2) and t1 = ?fNa.1y.v then fNa.1 ?l
t?? and t?? is described by (C3[], v3) (
(C4[], v4)
An item of the form (?; ? ` t : d; ) verifies:
1. (??, t, ?) ? LG where ?? = fNa.1 : F if
? = fNa.1 : e or ?? = ? otherwise
2. d does not contain non-specified syntactic
descriptions4 .
3. t ??l t? and t? is described by d (d may either
represent a string context or a string).
4. if ? = fNa.1 : (C3[], v3) ( (C4[], v4) or if
d = ((C3[], v3) ( (C4[], v4), (C1[], v1)) (
(C2[], v2) and t1 = ?fNa.1y.t? then fMa.1
??l
t?? and t?? is described by (C3[], v3) (
(C4[], v4)
Finally an item of the form
[Na.1; ?; t; (C1[], v1) ( (C2[], v2)] im-
plies the existence of t?, (C3[], v3) and
(C4[], v4) such that (Na;` t? : ((C3[], v3) (
(C4[], v4), (C1[], v1)) ( (C2[], v2); ) and
(Na.1; ? ` t : (C3[], v3) ( (C4[], v4)); ) are in
the chart.
An input ?y.C[y] is recognized iff when the
fixed-point is reached, the chart contains an item
of the form (Ss; ` t : (?y.C[], y) (
(?y.[], C[y]); ) (where S is the start symbol of the
TAG G.
4There is no occurence of F or Y in d.
144
General items
(Na ; ` ?fNa.1y.t1 : (F, Y )( (C1[], v1) ; fNa.1 : F, y : Y ` t2 : (C2[], v2))
(Na ; ` ?fNa.1y.t : ((C1[], v1)( (C2[], v2), Y )( (C3[], v3) ; y : Y ` t2 : (C4[], v4))
(Na ; ` ?fNa.1y.t : ((C1[], v1)( (C2[], v2), (C3[], v3))( (C4[], v4) ; )
(? ; ` ?y.t1 : Y ( (C1[], v1) ; y : Y ` t2 : (C2[], v2))
(? ; ` ?y.t : (C1[], v1)( (C2[], v2) ; )
(Na.1 ; fMa.1 : F ` ?y.t : Y ( (C[], v) ; fMa.1 : F, y : Y ` t2 : (C2[], v2)
(Na.1 ; fMa.1 : (C1[], v1)( (C2[], v2) ` ?y.t : Y ( (C3[], v3) ; y : Y ` t2 : (C4[], v4))
(Na.1 ; fMa.1 : (C1[], v1)( (C2[], v2) ` ?y.t : (C3[], v3)( (C4[], v4) ; )
Wrapped subtrees
[Na.1 ; ; t ; (C1[], v1)( (C2[], v2)]
[Na.1 ; fMa.1 : (C1[], v1)( (C2[], v2) ; t ; (C3[], v3)( (C4[], v4)]
Figure 3: Possible items
6 Conclusion and perspective
In this paper, we have illustrated the use for TAGs
of general and abstract tools, syntactic descrip-
tions, which can be used to parse linear ?-terms.
Even though ACGs are very general in their def-
inition, the algorithm we describe shows that this
generality is not a source of unefficiency. Indeed,
this algorithm, a special instance of a general one
which can parse any second order ACG and it be-
haves exactly the same way as the algorithm given
by (Schabes and Joshi, 1988) so that it parses a
second order ACG encoding a TAG in O(n6).
The technique used enables to see generation as
parsing. In the framework of second order ACG,
the logical formulae on which generation is per-
formed are bound to be obtained from semantic re-
cipies coded with linear ?-terms and are therefore
not really adapted to Montague semantics. Nev-
ertheless, syntactic descriptions can be extended
with intersection types (Dezani-Ciancaglini et al,
2005) in order to cope with simply typed ?-
calculus. With this extension, it seems possible
to extend the algorithm for second order ACGs
so that it can deal with simply typed ?-terms and
without loosing its efficiency in the linear case.
References
Henk P. Barendregt. 1984. The Lambda Calculus: Its
Syntax and Semantics, volume 103. Studies in Logic
and the Foundations of Mathematics, North-Holland
Amsterdam. revised edition.
Philippe de Groote and Sylvain Pogodalla. 2004. On
the expressive power of abstract categorial gram-
mars: Representing context-free formalisms. Jour-
nal of Logic, Language and Information, 13(4):421?
438.
Philippe de Groote. 2001. Towards abstract categorial
grammars. In Association for Computational Lin-
guistic, editor, Proceedings 39th Annual Meeting
and 10th Conference of the European Chapter,
pages 148?155. Morgan Kaufmann Publishers.
Philippe de Groote. 2002. Tree-adjoining grammars
as abstract categorial grammars. TAG+6, Proceed-
ings of the sixth International Workshop on Tree Ad-
joining Grammars and Related Frameworks, pages
145?150.
Mariangiola Dezani-Ciancaglini, Furio Honsell, and
Yoko Motohama. 2005. Compositional Characteri-
zation of ?-terms using Intersection Types. Theoret.
Comput. Sci., 340(3):459?495.
Ge?rard Huet. 1997. The zipper. Journal of Functional
Programming, 7(5):549?554.
Richard Montague. 1974. Formal Philosophy: Se-
lected Papers of Richard Montague. Yale University
Press, New Haven, CT.
Sylvain Salvati. 2006. Syntactic descriptions: a type
system for solving matching equations in the linear
?-calculus. In to be published in the proceedings
of the 17th International Conference on Rewriting
Techniques and Applications.
Yves Schabes and Aravind K. Joshi. 1988. An earley-
type parsing algorithm for tree adjoining grammars.
In Proceedings of the 26th annual meeting on Asso-
ciation for Computational Linguistics, pages 258?
269, Morristown, NJ, USA. Association for Compu-
tational Linguistics.
Stuart M. Shieber, Yves Schabes, and Fernando C. N.
Pereira. 1995. Principles and implementation of
deductive parsing. Journal of Logic Programming,
24(1?2):3?36, July?August. Also available as cmp-
lg/9404008.
145
The initializer
(?y.t, Ss) ? LG
(Ss; ` ?y.t : Y ( (?y.[], u); y : Y ` t : (?y.[], u))
The scanner
(?; ?1 ` t1 : d; ?2 ` at2 : (C[], av))
(?; ?1 ` t1 : d; ?2 ` t2 : (C[a[]], v))
(?; ? ` t : d; y : Y ` y : (C[], v)) ? = [Y := (C[], v)]
(?; ? ` t : d.?; )
The predictor
(?; ?1 ` t1 : d; ?2 ` xNat2t3 : (C[], v)) ( , ?fNa.1y.t,Na) ? LG
(Na; ` ?fNa.1y.t : (F, Y )( (C[], v); fNa.1 : F, y : Y ` t : (C[], v))
(?; ?1 ` t1 : d; ?2 ` xNst2 : (C[], v)) ( , ?y.t,Ns) ? LG
(Ns; ` ?y.t : Y ( (C[], v); y : Y ` t : (C[], v))
(?; ?1 ` t1 : d; ?2 ` fNa.1t2 : (C2[], v2))
(?3, ?y.t3, Na.1) ? LG
(Na.1; ?3 ` ?y.t3 : Y ( (C2[], v2); ?3, y : Y ` t3 : (C2[], v2))
The completer
(Na; ` t1 : ((C1[], v1)( (C2[], v2), (C3[], v3))( (C4[], v4); )
(Na.1; ?2; t2 : (C1[], v1)( (C2[], v2); )
[Na.1; ?2; t2; (C3[], v3)( (C4[], v4)]
(?; ?1 ` t1 : d; y : Y,??2 ` xNat2t3 : (C1[], v1))
[Na.1; ?2; t2; (C2[], v2)( (C1[], v1)]
if ?2 = fMa.1 : f then ? = [F := f ] else ? = Id
(?; ?1.? ` t1 : d.?; ?2 ` t3 : (C2[], v2))
(?; ?1 ` t1 : d; fNa.1 : F, y : Y ` fNa.1t2 : (C1[], v1))
(Na.1; ?2 ` t2 : (C2[], v2)( (C1[], v1); )
? = [F := (C2[], v2)( (C1[], v1)]
(?; ?1.? ` t1 : d.?; y : Y ` t2 : (C2[], v2))
(?; ?1 ` t1 : d; ?2 ` xNst2 : (C1[], v1))
(Ns; ` t2 : (C2[], v2)( (C1[], v1); )
(?; ?1 ` t1 : d; ?2 ` t2 : (C2[], v2))
Figure 4: The rules of the algorithm
146
