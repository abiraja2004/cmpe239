Proceedings of the SIGDIAL 2011: the 12th Annual Meeting of the Special Interest Group on Discourse and Dialogue, pages 272?278,
Portland, Oregon, June 17-18, 2011. c?2011 Association for Computational Linguistics
An Annotation Scheme for Cross-Cultural Argumentation
and Persuasion Dialogues
Kallirroi Georgila?, Ron Artstein?, Angela Nazarian?
Michael Rushforth??, David Traum?, Katia Sycara?
?Institute for Creative Technologies, University of Southern California
?Robotics Institute, Carnegie Mellon University
kgeorgila@ict.usc.edu
Abstract
We present a novel annotation scheme for
cross-cultural argumentation and persuasion
dialogues. This scheme is an adaptation of
existing coding schemes on negotiation, fol-
lowing a review of literature on cross-cultural
differences in negotiation styles. The scheme
has been refined through application to cod-
ing both two-party and multi-party negotia-
tion dialogues in three different domains, and
is general enough to be applicable to differ-
ent domains with few if any extensions. Di-
alogues annotated with the scheme have been
used to successfully learn culture-specific di-
alogue policies for argumentation and persua-
sion.
1 Introduction
In both cooperative and non-cooperative negotiation
the nature of the arguments used can be crucial for
the outcome of the negotiation. Argumentation and
persuasion are basic elements of negotiation. More-
over, different cultures favor different types of argu-
ments (Koch, 1983; Han and Shavitt, 1994; Zaharna,
1995; Brett and Gelfand, 2006). For example, it is
claimed that Western individualistic cultures favor
arguments based on logic over arguments that appeal
to emotions. On the other hand, people from East-
ern collectivistic cultures are more likely to use ar-
guments in which the beneficiary is not themselves.
Furthermore, Arab cultures tend to favor more indi-
rect ways of argumentation and expression (Koch,
1983; Zaharna, 1995).
?Now at the University of Texas at San Antonio.
In order to analyze negotiation in detail, including
aspects such as persuasion, negotiation, and cross-
cultural differences, we have developed a novel
annotation scheme. General purpose annotation
schemes such as DAMSL (Core and Allen, 1997)
and DIT++ (Bunt, 2006) represent moves in the dia-
logue but do not capture enough details of the inter-
action to distinguish between different styles of per-
suasion and argumentation, especially cross-cultural
differences.
Our goal for developing this coding scheme is
two-fold. First, we aim to fill the gap in the litera-
ture of cross-cultural argumentation and persuasion.
To our knowledge this is the first annotation scheme
designed specifically for coding cross-cultural argu-
mentation and persuasion strategies. Previous work
on cross-cultural negotiation, e.g. Brett and Gelfand
(2006), has not focused on argumentation or per-
suasion in particular. Also, previous work on argu-
mentation, e.g. Prakken (2008), has not attempted to
capture cross-cultural differences in argumentation
and persuasion strategies. Second, we use this cod-
ing scheme to annotate negotiation dialogues to au-
tomatically learn argumentation and persuasion di-
alogue policies for different cultures (Georgila and
Traum, 2011).
2 Related Work
2.1 Non-Culture Related Argumentation and
Persuasion
The topic of negotiation has widely been studied
across various fields including social and behavioral
science (Kern et al, 2005), and computer science
(Sidner, 1994; Rose? and Torrey, 2004). Our spe-
cific focus is on the role of argumentation and per-
272
suasion. Sycara (1990) studied the role of argumen-
tation in negotiation with regard to the role of ar-
guments in changing the decision process of the in-
terlocutor. Most attempts have focused on study-
ing the structure of argumentation and persuasion,
often using formal logic (Cohen, 1987; Prakken,
2008). Dung (1995) showed that argumentation can
be viewed as a special form of logic programming
with negation as failure. An argumentation scheme
is defined as a structure or template for forming an
argument. Schemes are necessary for identifying
arguments, finding missing premises, analyzing ar-
guments, and evaluating arguments (Pollock, 1995;
Katzav and Reed, 2004; Walton et al, 2008).
Recently, there has been some work on using ma-
chine learning techniques for automatically inter-
preting (George et al, 2007) and generating argu-
ments (Zukerman, 2001). Note also the work of Pi-
wek (2008) who performed a study on how argu-
ments can be presented as fictive dialogues. Finally,
there are a few persuasive dialogue systems, e.g.
Daphne (Grasso et al, 2000) and BIAS (Bayesian In-
teractive Argumentation System) (Zukerman, 2001).
2.2 Cross-Cultural Argumentation and
Persuasion
There is a vast amount of research on cultural ef-
fects on negotiation. Brett and Gelfand (2006) iden-
tify three aspects in cross-cultural negotiation: indi-
vidualism vs. collectivism, egalitarianism vs. hierar-
chy, and low context vs. high context communica-
tion. Typically Western individuals are individualis-
tic, egalitarian, and use low context communication
while Eastern individuals are collectivistic, hierar-
chical, and use high context communication.1
Although there has been a considerable amount of
work on building agents that can negotiate (Traum
et al, 2003; Rose? and Torrey, 2004), little has been
done towards building agents that can take into ac-
count culture aspects of negotiation (Cassell, 2009;
Paruchuri et al, 2009; Traum, 2009).
Our literature review on cross-cultural argumen-
tation and persuasion showed that there are com-
paratively few papers related to cross-cultural argu-
mentation and persuasion in dialogue. Most work
on cross-cultural studies is based on survey experi-
1In high-context cultures the listener must understand the
contextual cues in order to grasp the full meaning of the mes-
sage. In low-context cultures communication tends to be spe-
cific, explicit, and analytical.
ments rather than dialogue analysis. Below we sum-
marize the works that we were influenced by the
most.
Peng and Nisbett (1999) studied the way Chinese
vs. European-American people reason about con-
tradiction. By contradiction, here, we mean op-
posing pieces of information. Chinese individuals
adopt a dialectical or compromise approach by re-
taining basic elements of the opposing perspectives.
European-American people select one of the per-
spectives as correct and dismiss the opposing ones.
Koch (1983) linguistically analyzed several per-
suasive texts in contemporary Arabic in which there
was both repetition of form and repetition of con-
tent. She found that Arabs use repetition as a means
for persuasion. This strategy is called ?presentation
as proof? or ?argumentation by presentation?. Thus
in Arabic argumentation it is the presentation of an
idea that is persuasive, not the logical structure of
proof which Westerners see behind the words. Za-
harna (1995) examined how the Arab and American
cultures have two distinct perspectives for viewing
the role of language, for structuring persuasive mes-
sages, and for communicating effectively with their
audiences. For Arabs emphasis is on form over func-
tion, affect over accuracy, and image over meaning,
which is in line with the work of Koch (1983).
Finally, Cialdini?s work (1998) identified six prin-
ciples of persuasion: reciprocation (tendency to re-
turn favors), scarcity (associated with high value),
authority (tendency to follow authority figures), so-
cial proof (one is looking to the behavior of other in-
dividuals to determine her own actions), liking (one
tends to do things for people that she likes), and
commitment and consistency (one has difficulty to
reverse her commitments).
3 Our Annotation Scheme
We have developed a novel scheme for coding cross-
cultural argumentation and persuasion strategies.
This scheme is based on the literature review pre-
sented in section 2.2, as well as our own analysis of
three very different kinds of negotiation (section 4).
To develop this annotation scheme, we started by
adapting existing coding schemes on negotiation de-
veloped by Pruitt and Lewis (1975), Carnevale et al
(1981), and Sidner (1994). We were also influenced
by the work of Prakken on argumentation and di-
alogue (2008), and the work of Cialdini (1998) on
persuasion (see section 2.2). Our annotation scheme
273
was further refined by iteratively applying it to three
different negotiation domains.
In our coding scheme, we use three dimensions
for annotating an utterance: speech act, topic, and
response or reference to a previous utterance. We
have divided our codes for speech acts in categories.
Below we can see each category and the codes that
are included in it with explanatory examples, mostly
drawn from the florist-grocer dialogues described in
section 4.1.
3.1 Topic Tracking
start topic Let?s talk about the design.
end topic We are done with the design.
redirect topic We need to get back to the task.
3.2 Information Exchange
This category includes providing and requesting in-
formation, broken down into three kinds of informa-
tion that are about the negotiation (priority, value,
preference) as well as a fourth category (fact) which
can be further subdivided, depending on the issue
being negotiated (e.g. for the toy domain in sec-
tion 4.3, there are specializations for origin, func-
tion, and utility of the toy).
request info.priority Which issue is the most impor-
tant to you?
request info.value How much money will I get if I
give you this?
request info.preference What do you think about
the blue color?
request info.fact What will happen to the flowers if
the temperature gets higher?
provide info.priority I care most about tempera-
ture.
provide info.value You get $50 more if you agree to
lower the temperature by one degree.
provide info.preference I like design A.
provide info.fact (just a simple fact, neither prefer-
ence nor priority nor value) So one of them will
be yours and one mine.
3.3 Information Comparison
note similarities We both need the temperature to
be relatively low.
note differences It seems that you want design A
and I prefer design C.
project othersposition So you want an equal distri-
bution of rent.
3.4 Clarifications/Confirmations
request clarification I am not getting any more
money with more customers coming in?
provide clarification Not necessarily.
request confirmation Did you say 68 degrees?
self clarification (when the speaker tries to expand
on her ideas) Because when I thought temper-
ature, I was thinking temperature for the prod-
ucts, not temperature for the atmosphere.
3.5 Offer
We use the following format for an offer:
offer.?type?.?beneficiary?.?directness?. For a ?re-
quest offer?, generally only the directness field is
used.
Type can take the following values: ?standard?,
?tradeoff?, ?compromise?, ?concession?, and ?re-
traction?. The difference between ?compromise?
and ?concession? is subtle. ?Concession? means
that ?I don?t really want to do this but I?ll do it be-
cause there is no other way?. ?Compromise? is like
splitting the difference and it does not imply that the
speaker does not like the option.
Beneficiary can be ?me?, ?you?, ?both?, ?else?,
or ?null?. By beneficiary we mean who the offer or
argument would be good for (see also section 3.7).
So for example, if one?s argument is ?it will be too
cold for the customers? then ?beneficiary=else?.
Directness can be ?direct? or ?indirect?. An of-
fer or argument is ?indirect? when it needs to be in-
ferred. For example, when the grocer says ?well let?s
say there are lots of other local florists competing for
your prices?, she means that this is why advertising
is important, but this needs some kind of inference,
so the argument is indirect.
Below we can see examples of various types of
offers (the beneficiary and directness dimensions are
omitted for brevity).
offer.standard How about 62 degrees?
offer.tradeoff (between different issues) I?ll agree
on 64 degrees if you agree on design A.
offer.compromise Well should we just say 50/50?
offer.concession There is no other way so I agree
on 64 degrees.
offer.retraction I changed my mind, I don?t want de-
sign A.
request offer What temperature do you suggest?
274
3.6 General Reaction
accept Okay, 62 degrees is fine. or Yes, I said 62
degrees.
reject 62 degrees is too low for me. or No, I didn?t
say that.
acknowledge I see.
Note that ?accept? is used for accepting offers and
confirmation requests but also for agreement, for ex-
ample, when one interlocutor agrees with the argu-
ment of the other interlocutor. ?Reject? is used for
rejecting offers and confirmation requests but also
for disagreement.
3.7 Argumentation
An argument follows the following format:
?role?.?type?.?beneficiary?.?directness?. The role
can be ?provide argument?, ?attack argument?,
?rebut argument?, ?undercut argument?, and ?ac-
cept defeat?. Beneficiary and directness are defined
as in section 3.5. Below we can see examples of dif-
ferent argument roles.
provide argument The temperature must be low for
my flowers to stay fresh.
attack argument (without necessarily providing a
counter-argument) What you say does not make
sense.
rebut argument (provide a counter-argument) Yes,
but my customers wouldn?t want to shop in such
a low temperature.
undercut argument (invalidate an argument) You
don?t need a low temperature in the shop. Your
flowers can be refrigerated to stay fresh.
accept defeat You are right, I could use a refriger-
ator.
We have identified the following argument types:
ideology (what is ?right?), logic, fairness, prece-
dent, God?s will, promise for the future, honor, duty,
identity, authority, refer to relationship, appeal to
feelings, social responsibility, assurance (abstract
promises), stories/metaphors, ordinance, design
(aesthetics and functionality), effect/consequence,
cost/means. These types are mostly inspired by our
literature review (see section 2.2), as well as our ob-
servations in the domains that we used for develop-
ing the annotation scheme.
An example logical argument is ?my flowers need
low temperatures to stay fresh?. An example argu-
ment that appeals to fairness is ?I helped you last
time so it?s fair to help me now?. Arguments that
appeal to logic are more likely to appear in indi-
vidualistic cultures. Arguments that appeal to duty,
honor, social responsibility, ideology, and fairness
are more common in collectivistic cultures. Sto-
ries/metaphors are very common in Arab cultures
(Koch, 1983; Zaharna, 1995).
3.8 Other Speech Acts
repetition I prefer design A. I said design A.
heavy commitment $50 is all I can give, not a cent
more.
weak commitment Let?s assume that we agree on
this and continue.
meta task discussion (try to figure out the task) You
are the grocer and I am the florist.
self contradiction Speaker A: I like design C.
Speaker A (later): Design C is terrible.
show concern I understand that this solution would
not be good for you.
putdown You are stubborn.
show frustration I?m really sick and tired of this.
threat If you don?t accept my offer I won?t do busi-
ness with you again.
miscellaneous Yes, flowers are beautiful.
4 Applications of the Annotation Scheme
on Various Corpora
In order to prove its generality we applied this cod-
ing scheme to three different negotiation domains.
4.1 Florist-Grocer Domain
The first domain was dialogues between American
undergraduates playing the role of a florist and a gro-
cer who share a retail space. The dialogues were
collected by Laurie R. Weingart, Jeanne M. Brett,
and Mary C. Kern at Northwestern University. The
florist and the grocer negotiate on four issues: the
design of the space, the temperature, the rent, and
their advertising policy. Using the above coding
scheme we annotated 21 dialogues. Example anno-
tations of speech acts are given in Figure 1, as well
as the examples in section 3, above.
The final scheme was the result of several cy-
cles of dialogue annotations and revisions of the
coding manual. We used the florist-grocer annota-
tions to measure inter-annotator reliability between
four annotators. In three cycles of annotation, we
275
measured agreement on speech acts only and com-
plex speech acts were unified, for example, all the
?provide argument? are treated as a single category.
Krippendorff?s ? (Krippendorff, 1980) rose from
0.375 to 0.463 to 0.565.2
After analyzing these results we noticed that the
main problems in terms of inter-annotator relia-
bility were the confusion between ?accept? and
?acknowledge? (e.g. the utterance ?yeah? could
be either, depending on the context), and the
confusion between ?provide argument.logic?, ?pro-
vide argument.effect?, and ?provide info?. So we
revised the manual as follows: in order for some-
thing to be annotated as ?accept? vs. ?acknowledge?
we need to look forward in the dialogue; if an ar-
gument?s type is both ?logic? and ?effect? then ?ef-
fect? supersedes; ?provide info? is just provision of
a piece of information with no argumentative role.
4.2 SASO Domain
In this second domain (Traum et al, 2008), we an-
notated role-play dialogues in English between a US
Army captain and a Spanish doctor in Iraq. We have
annotated five dialogues so far. An example is given
in Figure 2.
4.3 Toy-Naming Domain
Finally, in the third domain groups of four people
negotiate in English, Spanish, and Arabic about how
to name a toy. The dialogues were part of the UTEP-
ICT Cross-Cultural dialogue corpus (Herrera et al,
2010). We have annotated five dialogues in English
and three in Arabic so far, and are currently work-
ing on Spanish. An example is given in Figure 3.
The ?redirect topic? act was added based on this do-
main (to cover cases where one person consciously
redirects the group?s attention to the task when they
drift off-topic for an extended period of time). Also,
we added three domain-specific specializations of
?provide info.fact? and ?request info.fact?: ?pro-
vide info.fact.function? (discussion about what one
can do with the toy or things that it does or has, e.g.
a secret compartment); ?provide info.fact.origin?
(where the toy was manufactured or bought); ?re-
quest info.fact.utility? (a person prompts the others
for ideas or examples of how the toy could be used
and marketed).
2Krippendorff?s ? is 0.460 in the first cycle if we exclude
one of the annotators who annotated only 72% of the items.
5 Discussion
We believe that this annotation scheme can be used
for analyzing and modeling the fine differences of
argumentation and negotiation styles, cross-task,
and cross-culture, as well as providing a basis for
artificial agents to engage in differentiated negotia-
tion behavior.
Our first use of the annotated florist-grocer di-
alogues was for learning dialogue policies using
simulated users and Reinforcement Learning (RL)
(Georgila and Traum, 2011). To facilitate RL we
had to make a few simplifications, for example, fo-
cus only on the temperature issue. In particular, we
built policies for individualistic vs. altruistic florists
(and grocers). Our results in simulation were consis-
tent with our reward functions, i.e. the florist individ-
ualist agreed on low temperatures while interacting
with the grocer altruist, the florist altruist agreed on
high temperatures vs. the grocer individualist, etc.
Details are given in (Georgila and Traum, 2011).
6 Conclusion
We presented a novel annotation scheme for cross-
cultural argumentation and persuasion dialogues.
This scheme is based on a review of literature on
cross-cultural argumentation and persuasion, and
adaptation of existing coding schemes on negotia-
tion. Our annotation scheme is also based on our ob-
servations from its application to coding both two-
party and multi-party negotiation dialogues in three
different domains, and is general enough to be ap-
plicable to different domains with minor or no mod-
ifications at all. Furthermore, dialogues annotated
with the scheme have been used to successfully learn
culture-specific dialogue policies for argumentation
and persuasion.
Acknowledgments
This research was funded by a MURI award through
ARO grant number W911NF-08-1-0301. We are
grateful to Laurie R. Weingart, Jeanne M. Brett,
and Mary C. Kern who provided us with the florist-
grocer dialogues, and to David A. Herrera, David G.
Novick, and Dusan Jan who developed the UTEP-
ICT corpus, as well as Hussein Sadek for transcrip-
tions and translations of the Arabic dialogues.
276
References
J.M. Brett and M.J. Gelfand. 2006. A cultural analysis of
the underlying assumptions of negotiation theory. In
Frontiers of Negotiation Research, L. Thompson (Ed),
pages 173?201. Psychology Press.
H. Bunt. 2006. Dimensions in dialogue act annotation.
In Proc. of LREC.
P.J. Carnevale, D.G. Pruitt, and S.D. Seilheimer. 1981.
Looking and competing: Accountability and visual ac-
cess in integrative bargaining. Journal of Personality
and Social Psychology, 40(1):111?120.
J. Cassell. 2009. Culture as social culture: Being en-
culturated in human-computer interaction. In Proc. of
HCI International.
R.B. Cialdini. 1998. Influence: The psychology of per-
suasion, Revised. Collins.
R. Cohen. 1987. Analyzing the structure of argumen-
tative discourse. Computational Linguistics, 13(1-
2):11?24.
M.G. Core and J.F. Allen. 1997. Coding dialogs with the
DAMSL annotation scheme. In Proc. of the AAAI Fall
Symposium on Communicative Actions in Humans and
Machines.
P.M. Dung. 1995. On the acceptability of arguments and
its fundamental role in nonmonotonic reasoning, logic
programming and n-person games. Artificial Intelli-
gence, 77(2):321?357.
S. George, I. Zukerman, and M. Niemann. 2007. In-
ferences, suppositions and explanatory extensions in
argument interpretation. User Modeling and User-
Adapted Interaction, 17(5):439?474.
K. Georgila and D. Traum. 2011. Learning culture-
specific dialogue models from non culture-specific
data. In Proc. of HCI International.
F. Grasso, A. Cawsey, and R. Jones. 2000. Dialectical ar-
gumentation to solve conflicts in advice giving: A case
study in the promotion of healthy nutrition. Interna-
tional Journal of Human-Computer Studies, 53:1077?
1115.
S. Han and S. Shavitt. 1994. Persuasion and culture:
Advertising appeals in individualistic and collectivistic
societies. Journal of Experimental Social Psychology,
30:326?350.
D. Herrera, D. Novick, D. Jan, and D. Traum. 2010. The
UTEP-ICT cross-cultural multiparty multimodal dia-
log corpus. In Proc. of the LREC Multimodal Corpora
Workshop: Advances in Capturing, Coding and Ana-
lyzing Multimodality (MMC).
J. Katzav and C. Reed. 2004. On argumentation schemes
and the natural classification of arguments. Argumen-
tation, 18(2):239?259.
M.C. Kern, J.M. Brett, and L.R. Weingart. 2005. Get-
ting the floor: Motive-consistent strategy and individ-
ual outcomes in multi-party negotiations. Group De-
cision and Negotiation, 14:21?41.
B. Johnstone Koch. 1983. Presentation as proof: The
language of Arabic rhetoric. Anthropological Linguis-
tics, 25(1):47?60.
K. Krippendorff. 1980. Content analysis: An introduc-
tion to its methodology, chapter 12. Sage, Beverly
Hills, CA.
P. Paruchuri, N. Chakraborty, R. Zivan, K. Sycara,
M. Dudik, and G. Gordon. 2009. POMDP based ne-
gotiation modeling. In Proc. of the IJCAI Workshop on
Modeling Intercultural Collaboration and Negotiation
(MICON).
K. Peng and R.E. Nisbett. 1999. Culture, dialectics,
and reasoning about contradiction. American Psychol-
ogist, 54(9):741?754.
P. Piwek. 2008. Presenting arguments as fictive dia-
logue. In Proc. of the ECAI Workshop on Computa-
tional Models of Natural Argument (CMNA).
J.L. Pollock. 1995. Cognitive Carpentry: A blueprint for
how to build a person. Bradford Books, MIT Press.
H. Prakken. 2008. A formal model of adjudication dia-
logues. Artificial Intelligence and Law, 16:305?328.
D.G. Pruitt and S.A. Lewis. 1975. Development of in-
tegrative solutions in bilateral negotiation. Journal of
Personality and Social Psychology, 31(4):621?633.
C. Rose? and C. Torrey. 2004. DReSDeN: Towards a
trainable tutorial dialogue manager to support negoti-
ation dialogues for learning and reflection. In Proc. of
ITS.
C.L. Sidner. 1994. An artificial discourse language for
collaborative negotiation. In Proc. of the National
Conference on Artificial Intelligence.
K. Sycara. 1990. Persuasive argumentation in negotia-
tion. Theory and Decision, 28(3):203?242.
D. Traum, J. Rickel, S. Marsella, and J. Gratch. 2003.
Negotiation over tasks in hybrid human-agent teams
for simulation-based training. In Proc. of AAMAS.
D. Traum, S. Marsella, J. Gratch, J. Lee, and A. Hartholt.
2008. Multi-party, multi-issue, multi-strategy negotia-
tion for multi-modal virtual agents. In Proc. of IVA.
D. Traum. 2009. Models of culture for virtual human
conversation. In Proc. of HCI International.
D. Walton, C. Reed, and F. Macagno. 2008. Argumenta-
tion Schemes. Cambridge University Press.
R.S. Zaharna. 1995. Understanding cultural preferences
of Arab communication partners. Public Relations Re-
view, 21(3):241?255.
I. Zukerman. 2001. An integrated approach for generat-
ing arguments and understanding rejoinders. In Proc.
of the International Conference on User Modeling.
277
Appendix
Florist: How does that work for you? (request info.preference)
Grocer: Well, personally for the grocery I think it is better to have a higher temperature. (pro-
vide argument.logic.me.indirect)
Grocer: Just because I want the customers to feel comfortable. (elaborate)
Florist: Okay. (acknowledge)
Grocer: And also if it is warm, people are more apt to buy cold drinks to keep themselves comfortable and
cool. (elaborate)
Florist: That?s true. (accept)
Florist: But what about your products staying fresh? Don?t they have to stay fresh or otherwise? (re-
but argument.logic.you.direct)
Figure 1: Example annotated dialogue with speech acts in the florist-grocer domain.
Captain: I think if you just made the compromise, we could provide so much for you if you just agreed to
let us move the clinic. (offer.standard.you.direct)
Doctor: Look I need to get back to my patients. They?re dying now. They?re dying. (show frustration)
Captain: They wouldn?t be dying if you let us move the clinic to the US Army base with the additional
medical support. (provide argument.logic.else.direct)
Doctor: Well they wouldn?t be dying if I was there. (rebut argument.logic.else.direct)
Doctor: Why don?t you provide us with additional medical support and get out of our lives? (re-
quest offer.direct)
Figure 2: Example annotated dialogue with speech acts in the SASO domain.
Speaker 3: Blue pal. (offer.standard.null.direct)
Speaker 4: Blue pal. (acknowledge)
Speaker 2: Blue pal. (acknowledge)
Speaker 4: That sounds pretty good. I actually like the idea. (accept)
Speaker 1: What if it?s a different color? (provide argument.logic.null.direct)
Speaker 2: Yeah, what if it?s like pink and purple. . . (elaborate)
Speaker 4: Uh I like blue pal. I think that one?s pretty cool. . . (provide info.preference)
Speaker 2: Something pal like your pal. (offer.standard.null.direct)
Speaker 4: Blue pal the singing singing pal the singing pal the singing and dancing buddy. The beast you
don?t want to get angry. (offer.standard.null.direct)
Speaker 2: That?s too long. (reject)
Speaker 2: It has to be short. (provide argument.logic.null.direct)
Speaker 1: Furball. (offer.standard.null.direct)
Speaker 4: A short name... Actually a good really long name might work because everything out there is
short... (rebut argument.logic.null.direct)
Figure 3: Example annotated dialogue with speech acts in the toy-naming domain.
278
