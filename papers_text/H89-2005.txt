SUMMARY OF SESSION 2: 
Spoken Language Systems I 
Chairperson- P. Price 
This session included descriptions of Spoken Language Systems under development at BBN Systems 
and Technologies, Carnegie Mellon University, Massachusetts Institute of Technology and Unisys. The 
topics covered a variety of issues including semantic interpretation (BBN), modeling "noise words" for 
spontaneous (vs. read) speech (CMU), dialogue management (Unisys) and systems issues (MIT and 
Unisys). 
Dave Stallard presented a survey of the natural anguage understanding effort at BBN. The principal topic 
presented was the change in formalism for semantic interpretation from a Montague-style rule-for-rule 
mirror of syntax to a unification framework, as has been used at various sites, including SRI and TI. 
Wayne Ward presented results in dealing with "noise" in speech. The "noise" in question included 
pause-filler words, mouth sounds, paper rustling, etc. The technique for dealing with the noise was simply 
to model these noises as words and to train them as other words are trained in the CMU SPHINX system. 
The result did not seem to affect performance much for "clean" speech (speech without these "words") 
and dramatically reduced the error rates for speech containing these "words". These are encouraging 
results for spoken language systems. 
The MIT Voyager system was presented principally in the form of a videotape that showed a complete SLS 
system for getting directions concerning the Harvard-MIT area: a subject speaks a sentence which is 
recognized by the SUMMIT system, sent to TINA for interpretation and then sent to the VOYAGER back- 
end for execution. The system is not yet real-time, but represents an important first step in developing 
spoken language systems. 
Lynette Hirschman presented an analysis of the Unisys experience in porting the PUNDIT system, 
originally designed for message processing, to a query-answering system for the VOYAGER application. 
The resulting architecture includes a general dialogue manager which can be used for a variety of 
interactive applications to maintain and control discourse coherency. Lynette also presented the last 
paper in the session: Computational Requirement for a Spoken Language System, in which she 
presented ways of parallelizing parsing steps and the resulting effects on computation. 
37 
