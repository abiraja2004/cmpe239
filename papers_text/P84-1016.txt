QUASI-INDEXICAL REFERENCE IN PROPOSITIONAL SEMANTIC NETWORKS 
William J. Rapaport 
Department of Philosophy, SUNY Fredonia, Fredonia, NY 14063 
Departmeot of Computer Science, SUNY Buffalo, Buffalo, NY 14260 
Stuart C. Shapiro 
Department of Computer Science, SUNY Buffalo, Buffalo, NY 14260 
ABSTRACT 
We discuss how a deductive question-answering sys- 
tem can represent the beliefs or other cognitive 
states of users, of other (interacting) systems, 
and of itself. In particular, we examine the 
representation of first-person beliefs of others 
(e.g., the ~/v .~ '~ representation of a user'A 
belief that he himself is rich). Such beliefs 
have as an essential component "'quasi-indexical 
pronouns" (e.g., 'he himself'), and, hence, 
require for their analysis a method of represent- 
ing these pronominal constructions and performing 
valid inferences with them. The theoretical jus- 
tification for the approach to be discussed is the 
representation of nested "'de ditto" beliefs (e.g., 
the system's belief that user-I believes that 
system-2 believes that user-2 is rich). We dis- 
cuss a computer implementation of these represen- 
tations using the Semantic Network Processing Sys- 
tem (SNePS) and an ATN parser-generator with a 
question-answering capability. 
I- INTRODUCTION 
Consider a deductive knowledge-representation 
system whose data base contains information about 
various people (e.g., its users), other (perhaps 
interacting) systems, or even itself. In order 
for the system to learn more about these 
entities--to expand its "'knowledge" base--it 
should contain information about the beliefs (or 
desires, wants, or other cognitive states) of 
these entities, and it should be able to reason 
about them (cf. Moore 1977, Creary 1979, Wilks and 
Bien 1983, Barnden 1983, and Nilsson 1983: 9). 
Such a data base constitutes the "knowledge" (more 
accurately, the beliefs) of the system about these 
entities and about their beliefs. 
Among the interrelated issues in knowledge 
representation that can be raised in such a 
context are those of multiple reference and the 
proper treatment of pronouns. For instance, is the 
person named 'Lucy' whom John believes to be rich 
the same as the person named 'Lucy' who is 
believed by the system to be young? How can the 
system (a) represent the person named 'Lucy' who 
is an object of its own belief without (b) confus- 
ing her with the person named 'Lucy' who is an 
object..of. John'~ belief, yet (c) be. ..able to 
merge its representations of those two people 
if it is later determined that they are the same? 
A solution to this problem turns out to be a side 
effect of a solution to a subtler problem in pro- 
nominal reference, namely, the proper treatment of 
pronouns occurring within belief-contexts. 
i. OUASI-INDICATORS 
Fo l lowing  Casta~eda (1967: 85).  an ind ic , to t  
i s  a persona l  or  demonst ra t ive  pronoun or adverb 
used to make a s t r i c t ly  demonst ra t ive  re ference .  
and a ouasi-indicator is an expression within a 
'believes-that' context that represents a use of 
an indicator by another person. Consider the fol- 
lowing statement by person A addressed to person 
at time ~ and ~lace ~: A says, "I am going to 
kill you here now. Person ~, who overheard this, 
ca l l s  the po l i ce  and says .  "A sa id  .to ~ at  ~ at  A 
that  he* was going to k i l l  him* there*  then* . "  The 
starred words are quasi-indicators representing 
uses by A of the indicators 'I'. 'you'. 'here', 
and 'now'. There are two properties (among many 
others) of quasi-indicators that must be taken 
into account: (i) They occur only within inten- 
tional contexts, and (ii) they cannot be replaced 
salva veritate by any co-referential expressions. 
The general question is: "How can we attri- 
bute indexical references to others?" (Casta~eda 
1980: 794). The specific cases that we are con- 
cerned with are exemplified in the following 
scenario. Suppose that John has just been 
appointed editor of Byte. but that John does not 
yet know this. Further. suppose that, because of  
the well-publicized salary accompanying the office 
of Byte'A editor, 
(1) John believes that the editor of Byte is rich. 
And suppose f ina l ly  that .  because of  severe  losses  
in the s tock  market .  
(2) John believes that he himself is not rich. 
Suppose that  the system had in fo rmat ion  about each 
of the following: John's appointment as editor, 
Johnts (lack of) knowledge of this appointment. 
and John's belief about the wealth of the editor. 
We would not want the system to infer 
(3) John believes that he* is rich 
because (2) is consistent with the system's infor- 
mation. The 'he himself' in (2) is a quasi- 
indicator, for (2) is the sentence that we use to 
express the belief that John would express as 'I 
am not rich'. Someone pointing to John. saying. 
65 
(4) He \[i.e., that man there\] believes that he* 
is not rich 
could just as well have said (2). The first 'he' 
in (4) is not a quasi-indicator: It occurs outside 
the believes-that context, and it can be replaced 
by 'John' or by 'the editor of Byte', salva veri- 
tare. But the 'he*' in )4) and the 'he himself' 
in (2) could not be thus replaced by 'the editor 
of Byte' - given our scenario - even though John 
is the editor of Byte. And if poor John also suf- 
fered from amnesia, it could not be replaced by 
'John' either. 
~. REPRESENTATIONS 
Entities such as the Lucy who is the object 
of John's belief are intentional (mental), hence 
intensional. (Of. Frege 1892; Meinong 1904; Cas- 
ta~eda 1972; Rapaport 1978, 1981.) Moreover, the 
entities represented in the data base are the 
objects of the ~y .~ '~ beliefs, and, so, are also 
intentional, hence intensional. We represent sen- 
tences by means of propositional semantic net- 
works, using the Semantic Network Processing Sys- 
tem (SNePS; Shapiro 1979), which treats nodes as 
representing intensional concepts (of. Woods 1975, 
Brachman 1977, Maida and Shapiro 1982). 
We claim that in the absence of prior 
knowledge of co-referentiality, the entities 
within belief-contexts should be represented 
separately from entities outside the context that 
might be co-referential with them. Suppose the 
system's beliefs include that a person named 
'Lucy' is young and that John believes that a 
(possibly different) person named 'Lucy' is rich. 
We represent this with the network of Fig. I. 
Fig. I. Lucy is young (m3) and John believes that 
someone named 'Lucy' is rich (m12). 
The section of network dominated by nodes m7 
and m9 is the system's de ditto representation of 
John's belief. That is, m9 is the system'~ 
representation of a belief that John might express 
by 'Lucy is rich', and it is represented as one of 
John's beliefs. Such nodes are considered as 
being in the system's representation of John's 
i"belief space".  Non-dominated nodes, such as ml4, 
m12, m15, mS, and m3, are the system's representa- 
tion of its own belief space (i.e., they can be 
thought of as the object of an implicit 'I believe 
that' case-frame; cf. Casta~eda 1975: 121-22, Kant 
1787: BI31). 
If it is later determined that the "two" 
Lucies are the same, then a node of co- 
referentiality would be added (m16, in Fig. 2). 
Fig. 2. Lucy is young (m3), John believes that 
someone named 'Lucy' is rich (mlS), and John's 
Lucy is the system's Lucy (m16). 
Now consider the case where the system has no 
information about the "content" of John's belief, 
but does have information that John's belief is 
about the ~.7_~/.f.~'E Lucy. Thus, whereas John might 
express his belief as, 'Linus's sister is rich', 
the system would express it as, '(Lucy system) is 
believed by John to be rich' (where '(Lucy sys- 
tem)' is the system's Lucy). This is a de re 
representation of John's belief, and would be 
represented by node ml2 of Figure 3. 
The strategy of separating entities in dif- 
ferent belief spaces is needed in order to satisfy 
the two main properties of quasi-indicators. 
Consider the possible representations of sen- 
tence (3) in Figure 4 (adapted from Maida and 
Shapiro 1983: 316). This suffers from three major 
problems. First, it is ambiguous: It could be 
the representation of (3) or of 
(5) John believes that John is rich. 
But, as we have seen, (3) and (5) express quite 
different propositions; thus, they should be 
separate items in the data base. 
Second, Figure 4 cannot represent (5). For 
then we would have no easy or uniform way to 
represent (3) in the case where John does not know 
that he is named 'John': Figure 4 says that the 
person (m3) who is named 'John' and who believes 
m6, believes that that person is rich; and this 
would be false in the amnesia case. 
66 
Fig. 3. The system's young Lucy is believed by 
John to be rich. 
Fig. 4. A representation for 
"John believes that he* is rich" 
Third, Figure 4 cannot represent (3) either, 
for it does not adequately represent the quasi- 
indexical nature of the 'he' in (3): Node m3 
represents both 'John' and 'he', hence is both 
inside and outside the intentional context, con- 
trary to both of the properties of quasi- 
indicators. 
Finally, because of these representational 
inadequacies, the system would invalidly "'infer" 
(6iii) from (6i)-(6ii): 
(6) (i) John believes that he is rich. 
(ii) he = John 
(iii) John believes that John is rich. 
simply because premise (6i) would be represented 
by the same network as conclusion (6iii). 
Rather, the general pattern for representing 
such sentences is illustrated in Figure 5. The 
'he*' in the English sentence is represented by 
node m2; its quasi-indexical nature is represented 
by means of node ml0. 
"I 
Fig. 5. John believes that he* is rich 
(m2 is the s~stem's representation of John's 
"'self-concept , expressed by John as 'I' and by 
the system as 'he*') 
That nodes m2 and m5 must be distinct follows 
from our separation principle. But, since m2 is 
the system's representation of Johnts representa- 
tion of himself, it must  be within the system's 
representation of John's belief space; this is 
accomplished via nodes ml0 and m9, representing 
John's belief that m2 is his "self- 
representation". Node m9, with its EGO arc to m2, 
represents, roughly, the proposition 'm2 is me'. 
Our representation of quasi-indexical de se 
sentences is thus a special case of the general 
schema for de ditto representations of belief sen- 
tences. When a de se sentence is interpreted de 
re, it does not contain quasi-indicators, and can 
be handled by the general schema for de re 
representations. Thus, 
(7) John is  be l ieved by h imsel f  to be r i ch  
would be represented by the network of Figure 4. 
~. INFERENCES 
Using an ATN parser-generator with a 
question-answering capability (based on Shapiro 
1982), we are implementing a system that parses 
English sentences representing beliefs de re or de 
ditto into our semantic-network representations, 
and that generates appropriate sentences from such 
networks. 
I t  a lso  " recogn izes"  the inva l id i ty  of argu- 
ments such as (5) s ince the premise and conclus ion 
(when interpreted de d in ,o )  are no longer 
represented by the same network. When given an 
appropriate inference rule, however, the system 
67 
will treat as valid such inferences as the follow- 
ing: 
(81 (i) John believes that the editor of Byte is 
rich. 
(ii) John believes that he* is the editor of 
Byte. 
Therefore, (iii) John believes that he* is rich 
In this case, an appropriate inference rule would 
be: 
(9) (?x,y,z,F)\[x believes F(y) b x believes z=y 
-> x believes FCz)\] 
In SNePS, in fe rence  ru les  are t reated  as propos i -  
t ions  represented  by nodes in the network. Thus, 
the network for  (9) would be bu i l t  by the SNePS 
User Language command given in Figure 6 (c f .  
Shapiro 1979). 
(build 
avb ($x $y Sz $F) 
&ant (build agent *x 
verb (build lex believe) 
object (build which *y 
adj (build lex *F))) 
&ant (build agent *x 
verb (find lex believe) 
object (build equiv *z equiv *y)) 
cq (build agent *x 
verb (find lex believe) 
object (build which *z 
adj (find lex *F)))) 
Fig. 6. SNePSUL command for building rule (9), 
for argument (8). 
~. ITERATED BELIEF CONTEXTS 
Our system can a lso handle sentences  invo lv -  
ing i te ra ted  be l ie f  contexts .  Consider 
(10) John believes that Mary believes that Lucy 
is rich. 
The interpretation of this that we are most 
interested in representing treats (I0) as the 
system's de ditto representation of John's de 
ditto representation of Mary's belief that Lucy is 
rich. On this interpretation, we need to 
represent the system'~ John--(John system)--the 
system's representation of John'~ Mary--(Mary John 
system)--and the system's representation of John's 
representation of Mary'~ Lucy--(Lucy Mary John 
system). This is done by the network of Figure 7. 
Such a network is built recursively as fol- 
lows: The parser maintains a stack of "believers". 
Each time a belief-sentence is parsed, it is made 
the object of a belief of the previous believer in 
the stack. Structure-sharing is used wherever 
possible. Thus, 
(II) John believes that Mary believes that Lucy 
is sweet 
Fig. 7. John believes that Mary believes that 
Lucy is rich. 
would modify the network of Figure 7 by adding new 
beliefs to (John system)'s belief space and tO 
(Mary John system)'s belief space, but would use 
the same nodes to represent John, Mary, and Lucy. 
~. NEW INFORMATION 
The system is  a lso capable of handl ing 
sequences of new in fo rmat ion .  For ins tance ,  sup- 
pose that  the system is  given the fo l lowing in fo r -  
mation at th ree  success ive  t imes:  
t l :  (121 The system's  Lucy be l ieves  that  Lucy's 
Lucy is  sweet.  
t2:  (13) The sys tem's  Lucy is sweet.  
t3:  (14) The systemIs Lucy = LucyIs Lucy. 
Then it will build the networks of Figures 8-I0, 
successively. At tl (Fig. 8), node m3 represents 
the systemts Lucy and m7 represents Lucy's Lucy. 
At t2 (Fig. 9), m13 is built, representing the 
system's belief that the system's Lucy (who is not 
yet believed to be--and, indeed, might not be-- 
Lucy's Lucy) is sweet.\[l\] At t3 (Fig. II), m14 is 
built, representing the system's new belief that 
there is really only one Lucy. This is a merging 
of the two "'Lucy"-nodes. From now on, all proper- 
ties of "either" Lucy will be inherited by the 
"'other", by means of an inference rule for the 
EQUIV case-frame (roughly, the indiscernibility of 
id___@enticals). 
It\]We are assumin B that tile system's concept of 
sweetness (node me) is also the system's concept 
of (Lucy system)'s concept of sweetness. This as- 
sumption seems warranted, since all nodes are in 
the system's belief space. If the system had rea- 
son to believe that its concept of sweetness dif- 
fered from Lucy's, this could--and would have to-- 
be  represented. 
68 
Fig. 8. Lucy believes that Lucy is sweet. 
I \ 
Fig. 9. Lucy believes that Lucy is sweet, 
and Lucy (the believer) is sweet. 
i. FUTURE WORK 
There are several directions for future 
modifications. First, the node-merging mechanism 
of the EQUIV case-frame with its associated rule 
needs to be generalized: Its current interpreta- 
tion is co-referentiality; but if the sequence 
(12)-(14) were embedded in someone else's belief- 
space, then co-referentiality might be incorrect. 
What is needed is a notion of "co-refere~tiality- 
within-a-belief-space'. The relation of consoct- 
ation" (Casta~eda 1972) seems to be more appropri- 
ate. 
Second, the system needs to be much more 
flexible. Currently, it treats all sentences of 
the form 
(15) x believes that F(y) 
as canonically de dicto and all sentences of the 
form 
(16) y is believed by x to  be F 
Fig. I0. Lucy believes that Lucy is sweet, Lucy 
is sweet, and the system's Lucy is Lucy's Lucy. 
as canonically de re. I n  ordinary conversation, 
however, both sentences can be understood in 
either way, depending on context, including prior 
beliefs as well as idiosyncracies of particular 
predicates. For instance, given (I), above, and 
the fact that John is the editor of Byte, most 
people would infer (3). But given 
(17) John believes that a l l  identical twins are  
conceited. 
(18) Unknown to John, he is an identical twin 
most  peop le  wou ld  not  infer 
(19) John believes that he* is conceited. 
Thus, we want to allow the system to make the most 
"reasonable" interpretations (de re vs. de d?cto) 
of users' belief-reports, based on prior beliefs 
and on subject matter, and to modify its initial 
representation as more information is received. 
SUNIqARY 
A deductive knowledge-representation system that 
is to be able to reason about the beliefs of cog- 
nitive agents must have a scheme for representing 
beliefs. This scheme must be able to distinguish 
among the "belief spaces" of different agents, as 
yell as be able to handle "nested belief spaces", 
i.e., second-order beliefs such as the beliefs of 
one agent about the beliefs of another. We have 
shown how a scheme for representing beliefs as 
either de re or de d?cto can distinguish the items 
in different belief spa~es (including nested 
belief spaces), yet merge the items on the basis 
of new information. This general scheme also 
enables the system to adequately represent sen- 
tences containing quasi-indicators, while not 
allowing invalid inferences to be drawn from them. 
69 
REFERENCES 
J. A. Barnden, "Intensions as Such: An Outline," 
IJCAI-83 (1983)280-286. 
R. J. Brachman, "What's in a Concept: Structural 
Foundations for Semantic Networks," Interna- 
tional Journal for Man-Machine Studies 
9(1977)127-52. 
Hector-Neri Casta~eda, "Indicators and Quasi- 
Indicators," ~ Philosoohical Ouarterlv 
4(1967)85-100. 
__ ,  "Thinking and the St ructure  of the World" 
(1972), Ph i losooh ia  4(1974)3-40. 
"Identity and Sameness," PhilosoDhia 
5~1975)121-50. 
__ ,  "Reference, Reality and Perceptual Fields," 
Proceedings and Addresses of the ~er ican  
~hilosophical Association 53(1980)763-823. 
L. G. Creary, "Propositional Attitudes: Fregean 
Representation and Simulative Reasoning," 
IJCAI-79 (1979)176-81. 
Gottlob Frege, "On Sense and Reference" (1892), in 
Translations from the Philosophical Writings of 
~ottlob Fre~e, ed. by P. Geach and M. Black 
(Oxford: Basil Blackwell, 1970): 56-78. 
Immanuel Kant, Critique of Pure Reason, 2nd ed. 
(1787), trans. N. Kemp Smith (New York: St. 
Martin's Press, 1929). 
Anthony S. Maida and Stuart C. Shapiro, "Inten- 
sional Concepts in Propositional Semantic Net- 
works." Cognit ive Science 6(1982)291-330. 
Alexius Meinong, -Ueber Gegenstandstheorie" 
(1904), in Alexius Meinon~ Gesamtaus~ahe, Vol. 
II, ed. R. Haller (Graz, Austria: Akademische 
Druck- u. Verlagsanstalt, 1971): 481-535. 
English translation in R. Chisholm (ed.), Real- 
ism and the Background of Phenomenolo~y (New 
York: Free Press, 1960): 76-117. 
R. C. Moore, "'Reasoning about Knowledge and 
Action," IJCAI-77 (1977)223-27. 
Nils J. Nilsson, "Artificial Intelligence Prepares 
for 2001," AI Ma~azine 4.4(Winter 1983)7-14. 
William J. Rapaport, "Meinongian Theories and a 
Russellian Paradox," NoGs 12(1978)153-80; 
errata, 13(1979)125. 
__ ,  "How to Make the World Fit Our Language: An 
Essay in Meinongian Semantics," Grazer Philoso- 
nhische Studien 14(1981)I-21. 
Stuart C. Shapiro, "The SNePS Semantic Network 
Processing System," in N. V. Findler (ed.), 
Associative Networks (New York: Academic Press, 
1979): 179-203. 
__ ,  "Generalized Augmented Transition Network 
Grammars For Generation From Semantic Networks," 
~ Journal  of ~ Linguistics 
8(1982)12-25. 
Yorick Wilks and Janusz Bien, "Beliefs, Points of 
View, and Multiple Environments," Cognitive Sci- 
ence 7(1983)95-119. 
William A. Woods, "'What's in a Link: The Semantics 
of Semantic Networks," in D. G. Bobrow and A. M. 
Collins (eds.), Reuresentation and ~ 
(New York: Academic Press, 1975): 35-79. 
70 
