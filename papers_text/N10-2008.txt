Proceedings of the NAACL HLT 2010: Demonstration Session, pages 29?32,
Los Angeles, California, June 2010. c?2010 Association for Computational Linguistics
Serious Game Environments for Language and Culture Education 


Alicia Sagae, W. Lewis Johnson, and Rebecca Row 
Alelo, Inc. 
12910 Culver Boulevard, Suite J 
Los Angeles, CA 90066, USA 
{asagae, ljhonson, rrow}@alelo.com 
 
 
 
 
 
 
Abstract 
In this demonstration we will present technol-
ogies that enable learners to engage in spoken 
conversations in foreign languages, integrat-
ing intelligent tutoring and serious game ca-
pabilities into a package that helps learners 
quickly acquire communication skills.  Con-
versational AI technologies based on the 
SAIBA framework for dialog modeling are 
realized in this 3-D game environment.  Par-
ticipants will be introduced to tools for author-
ing dialogs in this framework, and will have 
an opportunity to experience learning with 
Alelo products, including the Operational 
Language and Culture Training System 
(OLCTS). 
1 Introduction 
Alelo's language and culture education environ-
ments, including The Tactical Language and Cul-
ture Training System (TLCTS) and the Operational 
Language and Culture Training System (OLCTS), 
are AI-enhanced learning platforms that help 
learners quickly acquire communication skills in 
foreign languages and cultures.  They have been 
developed by Alelo, Inc. based on a prototype de-
veloped at the University of Southern California 
(USC).   
These environments utilize an integrated combi-
nation of intelligent tutoring system and serious 
game technologies.  Trainees work through a series 
of interactive lessons and exercises, called the Skill 
Builder, focusing on mission-oriented communica-
tion skills.  The lessons make extensive use of au-
tomated speech recognition focused on learner 
language, and provide learners with feedback on 
their performance.  Cultural notes describing cus-
toms and nonverbal gestures are integrated into the 
Skill Builder lessons.  Trainees apply their skills in 
an interactive Arcade Game, where they use spo-
ken commands in the target language to navigate a 
town grid, and in a Mission Game, where they par-
ticipate in real-time dialog with simulated local 
people in order to accomplish their mission. 
2 Systems that Impact Learners  
Five TLCTS/OLCTS training courses have been 
developed so far: Tactical IraqiTM, focusing on Ira-
qi Arabic, Tactical PashtoTM and Tactical DariTM 
focusing on the predominant dialects spoken in 
Afghanistan, Tactical FrenchTM for Sahel Africa, 
and Operational IndonesianTM.  TLCTS courses are 
complete training courses, providing all of the 
training materials needed to conduct basic training 
in foreign language and culture.  For example, Tac-
tical IraqiTM includes eighteen Mission Game 
scenes, ten Arcade Game levels, and sixty-three 
Skill Builder scenes comprising over 2000 lesson 
pages.  Additional scenes and lessons are under 
development.   
While the platform imposes no limit on content 
size, the material developed so far or these systems 
typically covers 80-120 hours of training.  In-game  
reference materials, including glossaries, summa-
ries of lesson content, and grammar notes, are 
29
available both as part of the training package and 
as is a support Web site.  Manuals, comprising tu-
torials and training guidelines, help with initial 
orientation, training management, and trouble-
shooting.  The OLCTS versions of these courses 
include supplementary exercises delivered on 
handheld devices and on the web, giving trainees a 
range of platforms for "train-anywhere" access. 
TLCTS rapidly transitioned into widespread use.  
Computer labs for training with TLCTS courses 
have been established in numerous locations in the 
USA and around the world.  An estimated twenty-
five thousand US military users have trained with 
the system, and consistently rate it highly.  It has 
also been made available to service members in 
allied military forces. 
Although the Tactical Language and Culture 
concept was originally developed under military 
funding, the approach can be applied quite general-
ly to language and culture learning.  The key is that 
the courses are task-oriented: the learner has a task 
to carry out, the Skill Builder helps the learner to 
acquire the skills necessary to carry out the task, 
and the Mission Game gives the learner an oppor-
tunity to practice the task in compelling simulated 
settings. 
 
 
3 Conversational Agent Technologies 
Simulated dialogs are executed by the virtual hu-
man architecture described in (Johnson & Valente, 
2008).  The architecture adopts a variant of the 
SAIBA framework (Vilhjalmsson & Marsella, 
2005), which separates intent planning (the choice 
of what to communicate) from production of be-
lievable behavior (how to realize the communica-
tion).  An overview of the social simulation 
process is given in Figure 1.   
3.1 Rule-Driven Behavior 
Virtual human behavior is generated by a series of 
components that include explicit models of speech 
and language (for natural language understanding 
and generation) as well as behavior-mapping rules 
that implicitly reflect the subject-matter expertise 
of the rule authors.  These rules generally occur at 
the level of communicative acts (Traum & Hin-
kelman, 1992).  A simple example of such a rule, 
expressed in natural language, is shown below: 
 
IF the learner says that your home is beautiful,  
THEN reply that it is quite plain 
(1) 
Utterance
Automated
Speech
Recognizer
Interpretation
Rules
Environmental
Context
Cultural
Context
Dialog 
Context
Intent Planning
Agent
Behavior 
Interpretation
Communicative 
Act <FML>
Behavior
Generation
Translation 
Rules
Behavior 
Specification
<BML>
Behavior
Realization
Communicative 
Act <FML>
Input Processing
Conversation
Cache
Personality Model
Language Model
Culture Model
World Model
(physical/social)
Agent Models 
Input
Processing
Social Simulation
Module
Game
Engine
Simulation 
Management
AgentAgent
Social Simulation Manager (API)
Player
Player Speech 
+- Gesture
Figure 1.  Dialog simulation architecture in Alelo language and culture training systems 
30
 3.2 Collaborative Authoring 
Rules like (1) are created by a content development 
team with expertise in linguistics and cultural anth-
ropology.  This work is supported by a set of web-
based collaborative authoring tools, called Kona 
and TIDE.  Kona is used to create lesson content 
for the Skill Builder, while TIDE is a graphical 
editor used to encode dialog rules as transitions in 
a Finite State Machine.   
Kona gives authors access to a database of les-
son content, specified in XML format.  The authors 
can selectively lock and edit lessons in the data-
base, and view and edit different fields in the spe-
cification of each page in the lesson.  The author 
can edit the written descriptions of the image on 
the page, the cultural notes, and the enabling learn-
ing objectives (ELOs) covered in the page.  In oth-
er views, authors can link in images and sound 
recordings, and make notes and comments for oth-
er authors to review.  The lesson specifications are 
then automatically translated into the internal data 
format used in OLCTS, so that authors can review 
the lessons as they appear in the training applica-
tion.  
4 The Demonstration 
The demonstration will give participants an oppor-
tunity to use OLCTS, and other Alelo interactive 
language and culture training products, and learn 
about their supporting authoring tools.  It is in-
tended for people who are interested in gaining an 
in-depth understanding of AIED (artificial intelli-
gence in education) technology for serious games, 
and the development tools used to create them.  
The demo will be conducted by a presenter, who 
will give live demonstrations of the software, and 
an assistant presenter who will coach the partici-
pants in the use of the game and supporting author-
ing tools. 
 
4.1 Overview 
First, the participants will get a hands-on intro-
duction to one of the Operational Language and 
Culture courses.  Under supervision of a presenter, 
 
Figure 2.  Screen shot of a Mission Game dialog in Operational DariTM 
31
the participants will learn to say a few phrases in 
the Skill Builder and use the phrases that they have 
learned in the Mission Game.  This portion can be 
tailored on the fly to the interests of participants, 
and can take from 5 to 30 minutes to complete. 
Depending on time and interest, participants 
may also have an opportunity to work with an 
OLCTS course in more depth.  They can be called 
upon to learn some basic communication skills in 
Dari and apply them in the Mission Game.  This 
will give participants a firsthand understanding of 
how each component of OLCTS supports learning, 
how the components support each other, and how 
artificial intelligence technology is applied in the 
learning experience.   
Finally, the presenter will demo some of the au-
thoring tools used to create OLCTS content.  The 
participants will propose modifications or exten-
sions to an existing OLCTS course.  The presenter 
will use the authoring tools in real time to make the 
modifications, following the recommendations of 
the participants. 
4.2 Example: Engaging in a Dialog in Opera-
tional DariTM 
For a video summary of the demonstration, please 
visit http://www.alelo.com/movie_tlt-6min.html. 
The user experience in the Mission Game is one 
engaging component of this demonstration.  An 
example script for a Mission Game interaction in 
Alelo's Operational DariTM course is given in the 
following sections. 
A sample of a Mission Game screen is shown in 
Figure 2.  The player controls the figure in the cen-
ter-left.  At this point in the demonstration, the 
player has received a briefing that describes a 
communication task that he or she should accom-
plish in this exercise.  To complete the task, the 
player must engage the virtual human, or non-
player character (NPC) shown on the right.   
Organizing rebuilding operations is one example 
of such a task.  The NPC is a host-national charac-
ter in Afghanistan.  The player should check on the 
status of their shared plan for rebuilding and give 
constructive feedback.  This type of communica-
tion task can require finesse and delicacy on the 
part of the player in order to be culturally appro-
priate.  It draws on the learner's understanding and 
skill with face-saving, a prominent feature of many 
cultures worldwide. 
The learner must initiate the conversation by 
speaking into a headset-mounted microphone.  He 
or she clicks on the microphone icon, shown in 
Figure 3, speaks, then clicks on the icon again to 
indicate the end of the turn. 
 
 
 
Figure 2.  Push the microphone button to speak during a 
dialog, push again to stop. 
 
Recognized player speech is posted to a dialog his-
tory window that appears near the top of the virtual 
scene, as shown in Figure 1.  The NPC responds 
using spoken output, creating a realistic and engag-
ing practice environment.  During the dialog, the 
player may view hints that display key phrases in 
Dari.  Once the player has discussed all of the host 
national's training mistakes, the dialog ends in suc-
cess. 
 
References  
H. Vilhjalmsson and S. Marsella. "Social Performance 
Framework", in Proceedings of the AAAI Workshop 
on Modular Construction of Human-Like Intelli-
gence. 2005. 
W. L. Johnson and A. Valente. ?Tactical Language and 
Culture Training Systems: Using Artificial Intelli-
gence to Teach Foreign Languages and Cultures?, in 
Proceedings of IAAI 2008. March 2008. 
David R. Traum and Elizabeth A. Hinkelman. "Conver-
sation Acts in Task-Oriented Spoken Dialogue", in 
Computational Intelligence, 8(3):575--599, 1992. 
 
32
