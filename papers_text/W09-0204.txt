Proceedings of the EACL 2009 Workshop on GEMS: GEometical Models of Natural Language Semantics, pages 25?32,
Athens, Greece, 31 March 2009. c?2009 Association for Computational Linguistics
A Study of Convolution Tree Kernel with Local Alignment
Lidan Zhang
Department of Computer Science
HKU, Hong Kong
lzhang@cs.hku.hk
Kwok-Ping Chan
Department of Computer Science
HKU, Hong Kong
kpchan@cs.hku.hk
Abstract
This paper discusses a new convolu-
tion tree kernel by introducing local
alignments. The main idea of the new
kernel is to allow some syntactic al-
ternations during each match between
subtrees. In this paper, we give an
algorithm to calculate the composite
kernel. The experiment results show
promising improvements on two tasks:
semantic role labeling and question
classification.
1 Introduction
Recently kernel-based methods have become
a state-of-art technique and been widely used
in natural language processing applications.
In this method, a key problem is how to de-
sign a proper kernel function in terms of dif-
ferent data representations. So far, there are
two kinds of data representations. One is to
encode an object with a flat vector whose ele-
ment correspond to an extracted feature from
the object. However the feature vector is sen-
sitive to the structural variations. The ex-
traction schema is heavily dependent on dif-
ferent problems. On the other hand, kernel
function can be directly calculated on the ob-
ject. The advantages are that the original
topological information is to a large extent
preserved and the introduction of additional
noise may be avoided. Thus structure-based
kernels can well model syntactic parse tree
in a variety of applications, such as relation
extraction(Zelenko et al, 2003), named en-
tity recognition(Culotta and Sorensen, 2004),
semantic role labeling(Moschitti et al, 2008)
and so on.
To compute the structural kernel function,
Haussler (1999) introduced a general type of
kernel function, called? Convolution kernel?.
Based on this work, Collins and Duffy (2002)
proposed a tree kernel calculation by count-
ing the common subtrees. In other words,
two trees are considered if and only if these
two trees are exactly same. In real sentences,
some structural alternations within a given
phrase are permitted without changing its us-
age. Therefore, Moschitti (2004) proposed
partial trees to partially match between sub-
trees. Kashima and Koyanagi (2002) general-
ize the tree kernel to labeled order tree kernel
with more flexible match. And from the idea
of introducing linguistical knowledge, Zhang
et al (2007) proposed a grammar-driven tree
kernel, in which two subtrees are same if and
only if the corresponding two productions are
in the same manually defined set. In addi-
tion, the problem of hard matching can be al-
leviated by processing or mapping the trees.
For example, Tai mapping (Kuboyama et al,
2006) generalized the kernel from counting
subtrees to counting the function of mapping.
Moreover multi-source knowledge can benefit
kernel calculation, such as using dependency
information to dynamically determine the tree
span (Qian et al, 2008).
In this paper, we propose a tree kernel cal-
culation algorithm by allowing variations in
productions. The variation is measured with
local alignment score between two derivative
POS sequences. To reduce the computation
complexity, we use the dynamic programming
algorithm to compute the score of any align-
ment. And the top n alignments are consid-
ered in the kernel.
25
Another problem in Collins and Duffy?s
tree kernel is context-free. It does not con-
sider any semantic information located at the
leaf nodes of the parsing trees. To lexicalized
tree kernel, Bloehdorn et al (2007) consid-
ered the associated term similarity by virtue
of WordNet. Shen et al (2003) constructed a
separate lexical feature containing words on a
given path and merged into the kernel in linear
combination.
The paper is organized as follows. In sec-
tion 2, we describe the commonly used tree
kernel. In section 3, we propose our method
to make use of the local alignment informa-
tion in kernel calculation. Section 4 presents
the results of our experiments for two differ-
ent applications ( Semantic Role Labeling and
Question Classification). Finally section 5
provides our conclusions.
2 Convolution Tree Kernel
The main idea of tree kernel is to count
the number of common subtrees between
two trees T1 and T2. In convolutional
tree kernel (Collins and Duffy, 2002), a
tree(T ) is represented as a vector h(T ) =
(h1(T ), ..., hi(T ), ..., hn(T )), where hi(T ) is
the number of occurrences of the ith tree frag-
ment in the tree T . Since the number of sub-
trees is exponential with the parse tree size,
it is infeasible to directly count the common
subtrees. To reduce the computation complex-
ity, a recursive kernel calculation algorithm
was presented. Given two trees T1 and T2,
K(T1, T2) = < h(T1), h(T2) > (1)
=
?
i
hi(T1)hi(T2)
=
?
i
(
?
n1?NT1
Ii(n1)
?
n2?NT2
Ii(n2))
=
?
n1?NT1
?
n2?NT2
4(n1, n2)
where, NT1 and NT2 are the sets of all nodes in
trees T1 and T2, respectively. Ii(n) is the indi-
cator function to be 1 if i-th subtree is rooted
at node n and 0 otherwise. And 4(n1, n2) is
the number of common subtrees rooted at n1
and n2. It can be computed efficiently accord-
ing to the following rules:
(1) If the productions at n1 and n2 are differ-
ent, 4(n1, n2) = 0
(2) If the productions at n1 and n2 are same,
and n1 and n2 are pre-terminals, then
4(n1, n2) = ?
(3) Else, 4(n1, n2) = ?
?nc(n1)
j (1 +
4(ch(n1, j), ch(n2, j)))
where nc(n1) is the number of children of
n1 in the tree. Note that n1 = n2 be-
cause the productions at n1 and n2 are same.
ch(n1, j) represents the jth child of node
n1. And 0 < ? ? 1 is the parameter
to downweight the contribution of larger tree
fragments to the kernel. It corresponds to
K(T1, T2) =
?
i ?sizeihi(T1)hi(T2), where
sizei is the number of rules in the i?th frag-
ment. The time complexity of computing this
kernel is O(|NT1| ? |NT2|).
3 Tree Kernel with Local Alignment
3.1 General Framework
As we referred, one of problems in the ba-
sic tree kernel is its hard match between two
rules. In other words, at each tree level,
the two subtrees are required to be perfectly
equal. However, in real sentences, some
modifiers can be added into a phrase with-
out changing the phrase?s function. For ex-
ample, two sentences are given in Figure 1.
Considering ?A1? role, the similarities be-
tween two subtrees(in circle) are 0 in (Collins
and Duffy, 2002), because the productions
?NP?DT ADJP NN? and ?NP?DT NN?
are not identical. From linguistical point of
view, the adjective phrase is optional in real
sentences, which does not change the corre-
sponding semantic role. Thus the modifier
components(like ?ADJP? in the above exam-
ple) should be neglected in similarity compar-
isons.
To make the hard match flexible, we can
align two string sequences derived from the
same node. Considering the above example,
26
S
NP
NNP
Richard
VP
VPAUX
has VBN
taken
NP
DT
a
NN
approach
ADJP
RBR
more
JJ
audience-friendly
S
NP
NNP
Richard
VP
VPAUX
has VBN
taken
NP
DT
a
NN
approach
S
NP
NNP
Richard
VP
VPAUX
has VBN
taken
NP
DT
a
NN
approach
NULL
v
A0
A1
A1
A1
(a) (b) (c)
Figure 1: Syntactic parse tree with ?A1? semantic role
an alignment might be ?DT ADJP NN? vs
?DT - NN?, by inserting a symbol(-). The
symbol(-) corresponds to a ?NULL? subtree
in the parser tree. And the ?NULL? subtree
can be regarded as a null character in the sen-
tence, see Figure 1(c).
Convolution kernels, studied in (Haussler,
1999) gave the framework to construct a com-
plex kernel from its simple elements. Suppose
x ? X can be decomposed into x1, ..., xm ?
~x. Let R be a relation over X1? ...?Xm?X
such that R(~x) is true iff x1, ..., xm are parts
of x. R?1(x) = {~x|R(~x, x)}, which returns
all components. For example, x is any string,
then ~x can be its characters. The convolution
kernel K is defined as:
K(x, y) =
?
~x?R?1(x),~y?R?1(y)
m?
d=1
Kd(xd, yd)
(2)
Considering our problem, for example, a
derived string sequence x by the rule ?n1 ?
x?. R(xi, x) is true iff xi appears in the right
hand of x. Given two POS sequences x and
y derived from two nodes n1 and n2, respec-
tively, A(x, y) denotes all the possible align-
ments of the sequence. The general form of
the kernel with local alignment is defined as:
K ?(n1, n2) =
?
(i,j)?A(x,y)
K(ni1, nj2) (3)
4?(n1, n2) = ?
?
(i,j)?A(x,y)
AS(i,j)
nc(n1,i)?
d=1
(1 +4?(ch(n1, i, d), ch(n2, j, d))
where, (i, j) denotes the ith and jth variation
for x and y, AS(i,j) is the score for alignment i
and j. And ch(n1, i, d) selects the dth subtree
for the ith aligned schema of node n1.
It is easily to prove the above kernel is pos-
itive semi-definite, since the kernel K(ni1, nj2)
is positive semi-definite. The native computa-
tion is impractical because the number of all
possible alignments(|A(x, y)|) is exponential
with respect to |x| and |y|. In the next sec-
tion, we will discuss how to calculate AS(i,j)
for each alignment.
3.2 Local Alignment Kernel
The local alignment(LA) kernel was usually
used in bioinformatics, to compare the sim-
ilarity between two protein sequences(x and
y) by exploring their alignments(Saigo et al,
2004).
KLA(x, y) =
?
pi?A(x,y)
exp?s(x,y,pi) (4)
where ? ? 0 is a parameter, A(x, y) denotes
all possible local alignments between x and y,
and s(x, y, pi) is the local alignment score for
a given alignment schema pi, which is equal
to:
s(x, y, pi) =
|pi|?
i=1
S(xpii1 , ypii2)?
|pi|?1?
j=1
[g(pii+11 ? pii1) + g(pii+12 ? pii2)]
(5)
In equation( 5), S is a substitution matrix, and
g is a gap penalty function. The alignment
score is the sum of the substitution score be-
tween the correspondence at the aligned posi-
tion, minus the sum of the gap penalty for the
27
case that ?-? symbol is inserted. In natural lan-
guage processing, the substitution matrix can
be selected as identity matrix and no penalty
is accounted.
Obviously, the direct computation of the
original KLA is not practical. Saigo (2004)
presented a dynamic programming algorithm
with time complexity O(|x|?|y|). In this paper,
this dynamic algorithm is used to compute the
kernel matrix, whose element(i, j) is used as
AS(i,j) measurement in equation(3).
3.3 Local Alignment Tree Kernel
Now we embed the above local alignment
score into the general tree kernel computation.
Equation(3) can be re-written into following:
4? (n1, n2) = ?
?
pi?A(x,y)
(exp?s(x,y,pi)?
nc(n1,i)?
k=1
(1 +4?(ch(n1, i, k), ch(n2, j, k))))
(6)
To further reduce the computation com-
plexity, a threshold (?) is used to filter out
alignments with low scores. This can help to
avoid over-generated subtrees and only select
the significant alignments. In other words,
by using the threshold (?), we can select the
salient subtree variations for kernels. The fi-
nal kernel calculation is shown below:
4? (n1, n2) = ?
?
pi ? A(x, y)
s(x, y, pi) > ?
(??s(x,y,pi)?
nc(n1,i)?
k=1
(1 +4?(ch(n1, i, k), ch(n2, j, k))))
(7)
After filtering, the kernel is still positive
semi-definite. This can be easily proved using
the theorem in (Shin and Kuboyama, 2008),
since this subset selection is transitive. More
specifically, if s(x, y, pi) > ?? s(y, z, pi?) >
?, then s(x, z, pi + pi?) > ?.
The algorithm to compute the local align-
ment tree kernel is given in algorithm 1. For
any two nodes pair(xi and yj), the local align-
ment score M(xi, yj) is assigned. In the ker-
nel matrix calculation, the worst case occurs
when the tree is balanced and most of the
alignments are selected.
Algorithm 1 algorithm for local alignment
tree kernel
Require: 2 nodes n1,n2 in parse trees;The
productions are n1 ? x1, ..., xm and n2 ?
y1, ..., yn
return 4?(n1, n2)
if n1 and n2 are not same then
4?(n1, n2) = 0
else
if both n1 and n2 are pre-terminals then
4?(n1, n2) = 1
else
calculate kernel matrix by equation( 4)
for each possible alignment do
calculate 4?(n1, n2) by equation(7)
end for
end if
end if
4 Experiments
4.1 Semantic Role Labeling
4.1.1 Experiment Setup
We use the CoNLL-2005 SRL shared task
data(Carreras and Marquez, 2005) as our ex-
perimental data. It is from the Wall Street
Journal part of the Penn Treebank, together
with predicate-arguments information from
the PropBank. According to the shared task,
sections 02-21 are used for training, section
24 for development and section 23 as well as
some data from Brown corpus are left for test.
The data sets are described in Table 1.
Sentences Arguments
Training 39,832 239,858
Dev 1,346 8,346
Test WSJ 1,346 8,346Brown 450 2,350
Table 1: Data sets statistics
28
Considering the two steps in semantic role
labeling, i.e. semantic role identification and
recognition. We assume identification has
been done correctly, and only consider the
semantic role classification. In our experi-
ment, we focus on the semantic classes in-
clude 6 core (A0-A5), 12 adjunct(AM-) and
8 reference(R-) arguments.
In our implementation, SVM-Light-TK1
(Moschitti, 2004) is modified. For SVM
multi-classifier, the ONE-vs-ALL (OVA)
strategy is selected. In all, we prepare the data
for each semantic role (r) as following:
(1) Given a sentence and its correct full syn-
tactic parse tree;
(2) Let P be the predicate. Its potential argu-
ments A are extracted according to (Xue
and Palmer, 2004)
(3) For each pair < p, a >? P ? A: if a
covers exactly the words of semantic role
of p, put minimal subtree < p, a > into
positive example set (T+r ); else put it in
the negative examples (T?r )
In our experiments, we set ? = 0.5.
4.1.2 Experimental Results
The classification performance is evalu-
ated with respect to accuracy, precision(p),
recall(r) and F1 = 2pr/(p+ r).
Accuracy(%)
(Collins and Duffy, 2002) 84.35
(Moschitti, 2004) 86.72
(Zhang et al, 2007) 87.96
Our Kernel 88.48
Table 2: Performance comparison between
different kernel performance on WSJ data
1http://dit.unitn.it/ moschitt/Tree-Kernel.htm
P(%) R(%) F?=1
Development 81.03 68.91 74.48
WSJ Test 84.97 79.45 82.11
Brown Test 76.95 70.94 73.51
WSJ+Brown 82.98 75.40 79.01
WSJ P(%) R(%) F
A0 81.28 83.90 82.56
A1 84.22 66.39 74.25
A2 77.27 62.36 69.02
A3 93.33 21.21 34.57
A4 82.61 51.35 63.33
A5 100.00 40.00 57.41
AM-ADV 74.21 56.21 63.92
AM-CAU 75.00 46.09 57.09
AM-DIR 57.14 16.00 25.00
AM-DIS 77.78 70.00 73.68
AM-EXT 75.00 53.10 62.18
AM-LOC 89.66 74.83 81.57
AM-MNR 84.62 48.20 61.41
AM-MOD 96.64 92.00 94.26
AM-NEG 99.30 95.30 97.26
AM-PNC 48.20 28.31 35.67
AM-PRD 50.00 30.00 37.50
AM-TMP 87.87 73.43 80.00
R-A0 81.08 67.80 73.85
R-A1 77.50 49.60 60.49
R-A2 58.00 42.67 49.17
R-AM-CAU 100.00 25.00 40.00
R-AM-EXT 100.00 100.00 100.00
R-AM-LOC 100.00 55.00 70.97
R-AM-MNR 50.00 25.00 33.33
R-AM-TMP 85.71 52.94 65.46
Table 3: top: overall performance result on
data sets ; bottom: detail result on WSJ
data
Table 2 compares the performance of our
method and other three famous kernels on
WSJ test data. We implemented these three
methods with the same settings described
in the papers. It shows that our kernel
achieves the best performance with 88.48%
accuracy. The advantages of our approach
are: 1). the alignments allow soft syntactic
structure match; 2). threshold can avoid over-
generation and selected salient alignments.
Table 3 gives our performance on data sets
and the detail result on WSJ test data.
29
Similarity Definition
Wu and Palmer simWUP (c1, c2) = 2dep(lso(c1,c2))d(c1,lso(c1,c2))+d(c2,lso(c1,c2))+2dep(lso(c1,c2))
Resnik simRES(c1, c2) = ? logP (lso(c1, c2))
Lin simLIN(c1, c2) = 2 logP (lso(c1,c2))logP (c1)+logP (c2)
Table 4: popular semantic similarity measurements
4.2 Question Classification
4.2.1 Semantic-enriched Tree Kernel
Another problem in the tree kernel (Collins
and Duffy, 2002) is the lack of semantic in-
formation, since the match stops at the pre-
terminals. All the lexical information is en-
coded at the leaf nodes of parsing trees. How-
ever, the semantic knowledge is important in
some text applications, like Question Classi-
fication. To introduce semantic similarities
between words into our kernel, we use the
framework in Bloehdorn et al (2007) and
rewrite the rule (2) in the iterative tree kernel
calculation(in section 2).
(2) If the productions at n1 and
n2 are same, and n1 and n2 are
pre-terminals, then 4(n1, n2) =
??kw(w1, w2)
where w1 and w2 are two words derived from
pre-terminals n1 and n2, respectively, and the
parameter ? is to control the contribution of
the leaves. Note that each preterminal has
one child or equally covers one word. So
kw(w1, w2) actually calculate the similarity
between two words w1 and w2.
In general, there are two ways to mea-
sure the semantic similarities. One is to de-
rive from semantic networks such as Word-
Net (Mavroeidis et al, 2005; Bloehdorn et
al., 2006). The other way is to use statisti-
cal methods of distributional or co-occurrence
(O? Se?aghdha and Copestake, 2008) behavior
of the words.
WordNet2 can be regarded as direct graphs
semantically linking concepts by means of
relations. Table 4 gives some similarity
measures between two arbitrary concepts c1
2http://wordnet.princeton.edu/
and c2. For our application, the word-to-
word similarity can be obtained by maximiz-
ing the corresponding concept-based similar-
ity scores. In our implementation, we use
WordNet::Similarity package3(Patwardhan et
al., 2003) and the noun hierarchy of WordNet.
In Table 4, dep is the length of path from a
node to its global root, lso(c1, c2) represents
the lowest super-ordinate of c1 and c2. The
detail definitions can be found in (Budanitsky
and Hirst, 2006) .
As an alternative, Latent Semantic Anal-
ysis(LSA) is a technique. It calculates the
words similarities by means of occurrence
of terms in documents. Given a term-by-
document matrix X , its singular value decom-
position is: X = U?V T , where ? is a diago-
nal matrix with singular values in decreasing
arrangement. The column of U are singular
vectors corresponding to the individual singu-
lar value. Then the latent semantic similarity
kernel of terms ti and tj is:
simLSA =< U ik(U jk)T > (8)
where Uk = IkU is to project U onto its first
k dimensions. Ik is the identity matrix whose
first k diagonal elements are 1 and all the other
elements are 0. And U ik is the i-th row of
the matrix Uk. From equation (8), the LSA-
based similarity between two terms is the in-
ner product of the two projected vectors. The
details of LSA can be found in (Cristianini et
al., 2002; Choi et al, 2001).
4.2.2 Experiment Results
In this set of experiment, we evaluate differ-
ent types of kernels for Question Classifica-
tion(QC) task. The duty of QC is to cat-
egorize questions into different classes. In
3http://search.cpan.org/dist/WordNet-Similarity
30
Accuracy(%) 1000 2000 3000 4000 5500
BOW 77.1 83.3 87.2 87.3 89.2
TK 80.2 86.2 87.4 88.6 91.2
LATK 80.4 86.5 87.5 88.8 91.6
? = 1
WUP 81.3 87.3 88.0 89.8 92.5
RES 81.0 87.1 87.9 89.5 92.2
LIN 81.1 87.0 88.0 89.3 92.4
LSA(k = 50) 80.8 86.9 87.8 89.3 91.7
Table 5: Classification accuracy of different kernels on different data sets
this paper we use the same dataset as intro-
duced in(Li and Roth, 2002). The dataset is
divided4 into 5500 questions for training and
500 questions from TREC 20 for testing. The
total training samples are randomly divided
into 5 subsets with sizes 1,000, 2,000, 3,000,
4,000 and 5,500 respectively. All the ques-
tions are labeled into 6 coarse grained cate-
gories and 50 fine grained categories: Abbre-
viations (abbreviation and expansion), Entity
(animal, body, color, creation, currency, med-
ical, event, food, instrument, language, let-
ter, plant, product, religion, sport, substance,
symbol, technique, term, vehicle, word), De-
scription (definition, description, manner, rea-
son), Human (description, group, individual,
title), Location (city, country, mountain, state)
and Numeric (code, count, date, distance,
money, order, percent, period, speed, temper-
ature, size, weight).
In this paper, we compare the linear ker-
nel based on bag-of-word (BOW), the original
tree kernel (TK), the local alignment tree ker-
nel (section 3, LATK) and its correspondences
with LSA similarity and a set of semantic-
enriched LATK with different similarity met-
rics.
To obtain the parse tree, we use Charniak
parser5 for every question. Like the previ-
ous experiment, SVM-Light-TK software and
the OVA strategy are implemented. In all ex-
periments, we use the default parameter in
SVM(e.g. margin parameter) and set ? = 1.
In LSA model, we set k = 50. Finally, we
use multi-classification accuracy to evaluate
4http://l2r.cs.uiuc.edu/ cogcomp/Data/QA/QC/
5ftp://ftp.cs.brown.edu/pub/nlparser/
the performance.
Table 5 gives the results of the experiments.
We can see that the local alignment tree ker-
nel increase the multi-classification accuracy
of the basic tree kernel by about 0.4%. The
introduction of semantic information further
improves accuracy. Among WordNet-based
metrics, ?Wu and Palmer? metric achieves
the best result, i.e. 92.5%. As a whole,
the WordNet-based similarities perform better
than LSA-based measurement.
5 Conclusion
In this paper, we propose a tree kernel calcula-
tion by allowing local alignments. More flex-
ible productions are considered in line with
modifiers in real sentences. Considering text
related applications, words similarities have
been merged into the presented tree kernel.
These similarities can be derived from dif-
ferent WordNet-based metrics or document
statistics. Finally experiments are carried on
two different applications (Semantic Role La-
beling and Question Classification).
For further work, we plan to study exploit-
ing semantic knowledge in the kernel. A
promising direction is to study the different
effects of these semantic similarities. We are
interested in some distributional similarities
(Lee, 1999) given certain context. Also the
effectivenss of the semantic-enriched tree ker-
nel in SRL is another problem.
References
Stephan Bloehdorn, Roberto Basili, Marco Cammisa,
and Alessandro Moschitti. 2006. Semantic kernels
for text classification based on topological measures
31
of feature similarity. In ICDM ?06: Proceedings of
the Sixth International Conference on Data Mining,
pages 808?812, Washington, DC, USA. IEEE Com-
puter Society.
Alexander Budanitsky and Graeme Hirst. 2006. Eval-
uating wordnet-based measures of lexical semantic
relatedness. Computational Linguistics, 32(1):13?
47.
X. Carreras and L. Marquez. 2005. Introduction to the
conll-2005 shared task: Semantic role labeling. In
CoNLL ?05: Proceedings of the 9th Conference on
Computational Natural Language Learning.
Freddy Y. Y. Choi, Peter Wiemer-hastings, and Johanna
Moore. 2001. Latent semantic analysis for text
segmentation. In In Proceedings of EMNLP, pages
109?117.
Michael Collins and Nigel Duffy. 2002. New rank-
ing algorithms for parsing and tagging: Kernels over
discrete structures, and the voted perceptron. In
ACL, pages 263?270.
Nello Cristianini, John Shawe-Taylor, and Huma
Lodhi. 2002. Latent semantic kernels. J. Intell.
Inf. Syst., 18(2-3):127?152.
Aron Culotta and Jeffrey Sorensen. 2004. Dependency
tree kernels for relation extraction. In ACL ?04:
Proceedings of the 42nd Annual Meeting on Asso-
ciation for Computational Linguistics, pages 423?
429, Morristown, NJ, USA. Association for Com-
putational Linguistics.
David Haussler. 1999. Convolution kernels on discrete
structures. Technical report.
Tetsuji Kuboyama, Kilho Shin, and Hisashi Kashima.
2006. Flexible tree kernels based on counting the
number of tree mappings. In ECML/PKDD Work-
shop on Mining and Learning with Graphs.
Lillian Lee. 1999. Measures of distributional similar-
ity. In 37th Annual Meeting of the Association for
Computational Linguistics, pages 25?32.
Xin Li and Dan Roth. 2002. Learning question clas-
sifiers. In Proceedings of the 19th international
conference on Computational linguistics, pages 1?
7, Morristown, NJ, USA. Association for Computa-
tional Linguistics.
Dimitrios Mavroeidis, George Tsatsaronis, Michalis
Vazirgiannis, Martin Theobald, and Gerhard
Weikum. 2005. Word sense disambiguation for
exploiting hierarchical thesauri in text classification.
In Al??pio Jorge, Lu??s Torgo, Pavel Brazdil, Rui
Camacho, and Gama Joao, editors, Knowledge
discovery in databases: PKDD 2005 : 9th Eu-
ropean Conference on Principles and Practice
of Knowledge Discovery in Databases, volume
3721 of Lecture Notes in Computer Science, pages
181?192, Porto, Portugal. Springer.
Alessandro Moschitti, Daniele Pighin, and Roberto
Basili. 2008. Tree kernels for semantic role label-
ing. Comput. Linguist., 34(2):193?224.
Alessandro Moschitti. 2004. A study on convolution
kernels for shallow semantic parsing. In ACL ?04:
Proceedings of the 42nd Annual Meeting on Asso-
ciation for Computational Linguistics, pages 335?
342, Morristown, NJ, USA. Association for Com-
putational Linguistics.
Diarmuid O? Se?aghdha and Ann Copestake. 2008. Se-
mantic classification with distributional kernels. In
Proceedings of the 22nd International Conference
on Computational Linguistics (Coling 2008), pages
649?656, Manchester, UK, August. Coling 2008 Or-
ganizing Committee.
Siddharth Patwardhan, Satanjeev Banerjee, and Ted
Pedersen. 2003. Using measures of semantic re-
latedness for word sense disambiguation. In In Pro-
ceedings of the Fourth International Conference on
Intelligent Text Processing and Computational Lin-
guistics (CICLING-03), pages 241?257.
Longhua Qian, Guodong Zhou, Fang Kong, Qiaoming
Zhu, and Peide Qian. 2008. Exploiting constituent
dependencies for tree kernel-based semantic relation
extraction. In Proceedings of the 22nd International
Conference on Computational Linguistics (Coling
2008), pages 697?704, Manchester, UK, August.
Coling 2008 Organizing Committee.
Hiroto Saigo, Jean-Philippe Vert, Nobuhisa Ueda, and
Tatsuya Akutsu. 2004. Protein homology detec-
tion using string alignment kernels. Bioinformatics,
20(11):1682?1689.
Kilho Shin and Tetsuji Kuboyama. 2008. A gener-
alization of haussler?s convolution kernel: mapping
kernel. In ICML, pages 944?951.
Nianwen Xue and Martha Palmer. 2004. Calibrat-
ing features for semantic role labeling. In Dekang
Lin and Dekai Wu, editors, Proceedings of EMNLP
2004, pages 88?94, Barcelona, Spain, July. Associ-
ation for Computational Linguistics.
Dmitry Zelenko, Chinatsu Aone, and Anthony
Richardella. 2003. Kernel methods for relation ex-
traction. J. Mach. Learn. Res., 3:1083?1106.
Min Zhang, Wanxiang Che, Aiti Aw, Chew Lim Tan,
Guodong Zhou, Ting Liu, and Sheng Li. 2007.
A grammar-driven convolution tree kernel for se-
mantic role classification. In Proceedings of the
45th Annual Meeting of the Association of Compu-
tational Linguistics, pages 200?207, Prague, Czech
Republic, June. Association for Computational Lin-
guistics.
32
