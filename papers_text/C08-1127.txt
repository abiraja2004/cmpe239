Proceedings of the 22nd International Conference on Computational Linguistics (Coling 2008), pages 1009?1016
Manchester, August 2008
Linguistically Annotated BTG for Statistical Machine Translation
Deyi Xiong, Min Zhang, Aiti Aw and Haizhou Li
Human Language Technology
Institute for Infocomm Research
21 Heng Mui Keng Terrace, Singapore 119613
{dyxiong, mzhang, aaiti}@i2r.a-star.edu.sg
Abstract
Bracketing Transduction Grammar (BTG)
is a natural choice for effective integration
of desired linguistic knowledge into sta-
tistical machine translation (SMT). In this
paper, we propose a Linguistically Anno-
tated BTG (LABTG) for SMT. It conveys
linguistic knowledge of source-side syn-
tax structures to BTG hierarchical struc-
tures through linguistic annotation. From
the linguistically annotated data, we learn
annotated BTG rules and train linguisti-
cally motivated phrase translation model
and reordering model. We also present an
annotation algorithm that captures syntac-
tic information for BTG nodes. The ex-
periments show that the LABTG approach
significantly outperforms a baseline BTG-
based system and a state-of-the-art phrase-
based system on the NISTMT-05 Chinese-
to-English translation task. Moreover, we
empirically demonstrate that the proposed
method achieves better translation selec-
tion and phrase reordering.
1 Introduction
Formal grammar used in statistical machine trans-
lation (SMT), such as Bracketing Transduction
Grammar (BTG) proposed by (Wu, 1997) and the
synchronous CFG presented by (Chiang, 2005),
provides a natural platform for integrating lin-
guistic knowledge into SMT because hierarchical
structures produced by the formal grammar resem-
ble linguistic structures.1 Chiang (2005) attempts
to integrate linguistic information into his formally
c
? 2008. Licensed under the Creative Commons
Attribution-Noncommercial-Share Alike 3.0 Unported li-
cense (http://creativecommons.org/licenses/by-nc-sa/3.0/).
Some rights reserved.
1We inherit the definitions of formal and linguistic from
(Chiang, 2005) which makes a distinction between formally
syntax-based SMT and linguistically syntax-based SMT.
syntax-based system by adding a constituent fea-
ture. Unfortunately, the linguistic feature does not
show significant improvement on the test set. In
this paper, we further this effort by integrating lin-
guistic knowledge into BTG.
We want to augment BTG?s formal structures
with linguistic structures since they are both hier-
archical. In particular, our goal is to learn a more
linguistically meaningful BTG from real-world bi-
texts by projecting linguistic structures onto BTG
formal structures. In doing so, we hope to (1)
maintain the strength of phrase-based approach
since phrases are still used on BTG leaf nodes; (2)
obtain a tight integration of linguistic knowledge in
the translation model; (3) and finally avoid induc-
ing a complicated linguistic synchronous grammar
with expensive computation. The challenge, of
course, is that BTG hierarchical structures are not
always aligned with the linguistic structures in the
syntactic parse trees of source or target language.
Along this line, we propose a novel approach:
Linguistically Annotated BTG (LABTG) for SMT.
The LABTG annotates BTG rules with linguistic
elements that are learned from syntactic parse trees
on the source side through an annotation algo-
rithm, which is capable of labelling both syntactic
and non-syntactic phrases. The linguistic elements
extracted from parse trees capture both internal
lexical content and external context of phrases.
With these linguistic annotations, we expect the
LABTG to address two traditional issues of stan-
dard phrase-based SMT (Koehn et al, 2003) in a
more effective manner. They are (1) phrase trans-
lation: translating phrases according to their con-
texts; (2) phrase reordering: incorporating richer
linguistic features for better reordering.
The proposed LABTG displays two unique
characteristics when compared with BTG-based
SMT (Wu, 1996; Xiong et al, 2006). The first
is that two linguistically-informed sub-models are
introduced for better phrase translation and re-
ordering: annotated phrase translation model and
1009
annotated reordering model. The second is that
our proposed annotation algorithm and scheme are
capable of conveying linguistic knowledge from
source-side syntax structures to BTG structures.
We describe the LABTG model and the annota-
tion algorithm in Section 4. To better explain the
LABTG model, we establish a unified framework
of BTG-based SMT in Section 3. We conduct
a series of experiments to study the effect of the
LABTG in Section 5.
2 Related Work
There have been various efforts to integrate lin-
guistic knowledge into SMT systems, either from
the target side (Marcu et al, 2006; Hassan et al,
2007; Zollmann and Venugopal, 2006), the source
side (Quirk et al, 2005; Liu et al, 2006; Huang
et al, 2006) or both sides (Eisner, 2003; Ding et
al., 2005; Koehn and Hoang, 2007), just to name a
few. LABTG can be considered as, but not limited
to, a new attempt that enriches translation model
with source-side linguistic annotations.
(Huang and Knight, 2006) and (Hassan et al,
2007) introduce relabeling and supertagging on the
target side, respectively. The former re-annotates
syntactified phrases to learn grammatical distinc-
tions while the latter supertags standard plain
phrases, both applied on the target side. The differ-
ence between their work and LABTG is significant
because we annotate standard plain phrases using
linguistic elements on the source side. Compared
with the target side annotation which improves flu-
ency and grammaticality of translation output, lin-
guistic annotation on the source side helps to im-
prove translation adequacy.
Recently, some researchers have extended and
created several variations of BTG/ITG. Zhang et
al. (2005) propose lexicalized ITG for better word
alignment. Xiong et al (2006) demonstrate that
their MEBTG, a BTG variation with MaxEnt-
based reordering model, can improve phrase re-
ordering significantly. Similarly, Setiawan et al
(2007) use an enhanced BTG variation with func-
tion words for reordering. LABTG differs from
these BTG variations in that the latter does not use
any external linguistic knowledge.
Zhang et al (2007) describe a phrase reorder-
ing model based on BTG-style rules which inte-
grates source-side syntactic knowledge. Our an-
notated reordering model of LABTG differs from
their work in two key aspects. Firstly, we al-
low any phrase reorderings while they only reorder
syntactic phrases. In their model, only syntactic
phrases can use linguistic knowledge from parse
trees for reordering while non-syntactic phrases
are combined monotonously with a constant re-
ordering score since no syntactic knowledge can
be used at all. Our proposed LABTG successfully
overcomes this limitation by supporting linguis-
tic annotation on both syntactic and non-syntactic
phrases. Moreover, we show that excluding non-
syntactic phrase from reordering does hurt the
performance. Secondly, we use richer linguistic
knowledge in reordering, including head words
and syntactic labels of context nodes, when com-
pared with their model. Our experiments show that
these additional information can improve reorder-
ing.
3 BTG Based SMT
We establish a unified framework for BTG-based
SMT in this section. There are two kinds of rules
in BTG, lexical rules (denoted as rl) and merging
rules (denoted as rm):
r
l
: A ? x/y
and
r
m
: A ? [A
l
, A
r
]|?A
l
, A
r
?
Lexical rules translate source phrase x into target
phrase y and generate a leaf node A in BTG tree.
Merging rules combine left and right neighboring
phrases A
l
and A
r
into a larger phrase A in an or-
der o ? {straight, inverted}.
We define a BTG derivation D as a sequence
of independent applications of lexical and merging
rules (D = ?rl
1..n
l
, r
m
1..n
m
?). Given a source sen-
tence, the decoding task of BTG-based SMT is to
find a best derivation, which yields the best trans-
lation.
Similar to (Xiong et al, 2006), we can as-
sign a probability to each rule using a log-linear
model with different features and corresponding ?
weights, then multiply them to obtain P (D). For
convenience of notation and keeping in line with
the common understanding of standard phrase-
based model, here we re-organize these features
into translation model (P
T
), reordering model
(P
R
) and target language model (P
L
) as follows
P (D) = P
T
(r
l
1..n
l
) ? P
R
(r
m
1..n
m
)
?
R
?P
L
(e)
?
L
? exp(|e|)
?
w (1)
where exp(|e|) is the word penalty.
1010
The translation model is defined as:
P
T
(r
l
1..n
l
) =
n
l
?
i=1
P (r
l
i
)
P (r
l
) = p(x|y)
?
1
? p(y|x)
?
2
? p
lex
(x|y)
?
3
?p
lex
(y|x)
?
4
? exp(1)
?
5 (2)
where p(?) represent the phrase translation proba-
bilities in both directions, p
lex
(?) denote the lexi-
cal translation probabilities in both directions, and
exp(1) is the phrase penalty.
Similarly, the reordering model is defined on the
merging rules as follows
P
R
(r
m
1..n
m
) =
n
m
?
i=1
P (r
m
i
) (3)
In the original BTGmodel (Wu, 1996), P (rm) was
actually a prior probability which can be set based
on the order preference of the language pairs. In
MEBTG (Xiong et al, 2006), however, the prob-
ability is calculated more sophisticatedly using a
MaxEnt-based classification model with boundary
words as its features.
4 Linguistically Annotated BTG Based
SMT
We extend the original BTG into the linguistically
annotated BTG by adding linguistic annotations
from source-side parse trees to both BTG lexical
rules and merging rules. Before we elaborate how
the LABTG extends the baseline, we introduce an-
notated BTG rules.
In the LABTG, both lexical rules and merging
rules are annotated with linguistic elements as fol-
lows
ar
l
: A
a
? x#a/y
and
ar
m
: A
a
? [A
a
l
l
, A
a
r
r
]|?A
a
l
l
, A
a
r
r
?
The annotation a comprises three linguistic ele-
ments from source-side syntactic parse tree: (1)
head word hw, (2) the part-of-speech (POS) tag
ht of head word and (3) syntactic label sl. In an-
notated lexical rules, the three elements are com-
bined together and then attached to x as an anno-
tation unit. In annotated merging rules, each node
involved in merging is annotated with these three
elements individually.
There are various ways to learn the annotated
rules from training data. The straight-forward way
is to first generate the best BTG tree for each sen-
tence pair using the way of (Wu, 1997), then an-
notate each BTG node with linguistic elements
by projecting source-side syntax tree to BTG tree,
and finally extract rules from these annotated BTG
trees. This way restricts learning space to only the
best BTG trees2, and leads to the loss of many use-
ful annotated rules.
Therefore, we use an alternative way to extract
the annotated rules as illustrated below. Firstly, we
run GIZA++ (Och and Ney, 2000) on the train-
ing corpus in both directions and then apply the
ogrow-diag-finalp refinement rule (Koehn et al,
2003) to obtain many-to-many word alignments.
Secondly, we extract bilingual phrases from the
word-aligned corpus, then annotate their source
sides with linguistic elements to obtain the an-
notated lexical rules.3 Finally, we learn reorder-
ing examples (Xiong et al, 2006), annotate their
two neighboring sub-phrases and whole phrases,
and then generalize them in the annotated merging
rules. Although this alternative way may also miss
reorderings due to word alignment errors, it is still
more flexible and robust than the straight-forward
one, and can learn more annotated BTG rules with-
out constructing BTG trees explicitly.
4.1 LABTG Annotation Algorithm
During the process of rule learning and decod-
ing, we need to annotate bilingual phrases or BTG
nodes generated by the decoder given a source
sentence together with its parse tree. Since both
phrases and BTG nodes can be projected to a span
on the source sentence, we run our annotation al-
gorithm on source-side spans and then assign an-
notation results to the corresponding phrases or
nodes. If the span is exactly covered by a single
subtree in the source-side parse tree, it is called
syntactic span, otherwise non-syntactic span.
One of the challenges in this annotation algorithm
is that BTG nodes (or phrases) are not always cov-
ering syntactic span, in other words, are not always
aligned to constituent nodes in the source-side tree.
To solve this problem, we use heuristic rules to
generate pseudo head word and composite label
which consists of syntactic labels of three relevant
constituents for the non-syntactic span.
The annotation algorithm is shown in Fig. 1.
For a syntactic span, the annotation is trivial. An-
notation elements directly come from the subtree
that exactly covers the span. For a non-syntactic
2Producing BTG forest for each sentence pair is very time-
consuming.
3This makes the number of extracted annotated lexical
rules proportional to that of bilingual phrases.
1011
1: Annotator (span s = ?i, j?, source-side parse tree t)
2: if s is a syntactic span then
3: Find the subtree c in t which exactly covers s
4: s.a := {c.hw, c.ht, c.sl}
5: else
6: Find the smallest subtree c? subsuming s in t
7: if c?.hw ? s then
8: s.a.hw := c?.hw and s.a.ht := c?.ht
9: else
10: Find the word w ? s which is nearest to c?.hw
11: s.a.hw := w and s.a.ht := w.t /*w.t is the POS
tag of w*/
12: end if
13: Find the left context node ln of s in c?
14: Find the right context node rn of s in c?
15: s.a.sl := ln.sl-c?.sl-rn.sl
16: end if
Figure 1: The LABTG Annotation Algorithm.
span, the process is much complicated. Firstly,
we need to locate the smallest subtree c? subsum-
ing the span (line 6). Secondly, we try to identify
the head word/tag of the span (line 7-12) by us-
ing c??s head word hw directly if it is within the
span. Otherwise, the word within the span which
is nearest to hw will be assigned as the head word
of the span. Finally, we determine the composite
label of the span (line 13-15), which is formulated
as L-C-R. L/R refers to the syntactic label of the
left/right context node of s which is a sub-node of
c
?
. There are different ways to define the context
node of a span in the source-side parse tree. It can
be the closest neighboring node or the boundary
node which is the highest leftmost/rightmost sub-
node of c? not overlapping the span. If there is no
such context node (the span s is exactly aligned to
the left/right boundary of c?), L/R will be set to
NULL. C is the label of c?. L, R and C together
define the external syntactic context of s.
Fig. 2 shows a syntactic parse tree for a Chinese
sentence, with head word annotated for each inter-
nal node.4 Some sample annotations are given in
Table 1. We also show different composite labels
for non-syntactic spans with different definitions
of their context nodes. sl
1
is obtained when the
boundary node is defined as the context node while
sl
2
is obtained when the closest neighboring node
is defined as the context node.
4.2 LABTG Model
To better model annotated rules, the LABTG con-
tributes two significant modifications to formula
(1). First is the annotated phrase translation model
4In this paper, we use phrase labels from the Penn Chinese
Treebank (Xue et al, 2005).
IP(??)
?
?
?
?
?
H
H
H
H
H
NP(??)
?
?
H
H
NP(??)
NR
??1
Tibet
NP(??)
?H
NN
??2
financial
NN
??3
work
VP(??)
?
?
?
?
?
H
H
H
H
H
VV
??4
gain
AS
?5
NP(??)
?
?
H
H
ADJP(??)
JJ
??6
remarkable
NP(??)
NN
?7?
achievement
Figure 2: A syntactic parse tree with head word
annotated for each internal node. The superscripts
of leaf nodes denote their surface positions from
left to right.
span hw ht sl
1
(boundary node) sl
2
(neighboring node)
?1, 2? ?? NN NULL-NP-NN NULL-NP-NN
?2, 3? ?? NN NP NP
?2, 4? ?? VV NP-IP-NP NP-IP-AS
?3, 4? ?? VV NP-IP-NP NN-IP-AS
Table 1: Annotation samples according to the tree
shown in Fig. 2. hw/ht represents head word/tag,
respectively. sl means the syntactic label.
with source side linguistically enhanced to replace
the standard phrase translation model, and second
is the additional MaxEnt-based reordering model
that uses linguistic annotations as features. The
LABTG model is formulated as follows
P (D) = P
T
a
(ar
l
1..n
l
) ? P
R
b
(r
m
1..n
m
)
?
R
b
?P
R
a
(ar
m
1..n
m
)
?
R
a
? P
L
(e)
?
L
? exp(|e|)
?
w (4)
Here P
T
a
is the annotated phrase translation
model, P
R
b
is the reordering model from MEBTG
using boundary words as features and P
R
a
is the
annotated reordering model using linguistic anno-
tations of nodes as features.
Annotated Phrase Translation Model The
annotated phrase translation model P
T
a
is sim-
ilar to formula (2) except that phrase transla-
tion probabilities on both directions are p(x#a|y)
and p(y|x#a) respectively, instead of p(x|y) and
p(y|x). By introducing annotations into the trans-
lation model, we integrate linguistic knowledge
into the statistical selection of target equivalents.
Annotated Reordering Model The annotated
reordering model P
R
a
is a MaxEnt-based classi-
fication model which uses linguistic elements of
each annotated node as its features. The model can
be formulated as
P
R
a
(ar
m
) = p
?
(o|A
a
, A
a
l
l
, A
a
r
r
)
1012
=exp(
?
i
?
i
h
i
(o,A
a
, A
a
l
l
, A
a
r
r
))
?
o
exp(
?
i
?
i
h
i
(o,A
a
, A
a
l
l
, A
a
r
r
))
where the functions h
i
? {0, 1} are reordering fea-
tures and ?
i
are weights of these features.
Each merging rule involves 3 nodes
(Aa, Aal
l
, A
a
r
r
) and each node has 3 linguistic
elements (hw, ht, sl). Therefore, the model has 9
features in total. Taking the left node Aal
l
as an
example, the model could use its head word w as
feature as follows
h
i
(o,A
a
, A
a
l
l
, A
a
r
r
) =
{
1, A
a
l
l
.hw = w, o = straight
0, otherwise
4.3 Training
To train the annotated translation model, firstly we
extract all annotated lexical rules from source-side
parsed, word-aligned training data. Then we es-
timate the annotated phrase translation probabili-
ties p(x#a|y) and p(y|x#a) using relative counts
from all collected annotated lexical rules. For ex-
ample, p(y|x#a) can be calculated as follows
p(y|x#a) =
count(x#a, y)
?
y
count(x#a, y)
One might think that linguistic annotations would
cause serious data sparseness problem and the
probabilities should be smoothed. However, ac-
cording to our statistics (described in the next sec-
tion), the differences in annotations for the same
source phrase x are not so diverse. So we take
a direct backoff strategy to map unseen annotated
lexical rules to their un-annotated versions on the
fly during decoding, which is detailed in the next
subsection.
To train the annotated reordering model, we
generate all annotated reordering examples, then
obtain features using linguistic elements of these
examples, and finally estimate feature weights
based on the maximum entropy principle.
4.4 Decoding
A CKY-style decoder with beam search is devel-
oped, similar to (Xiong et al, 2006). Each in-
put source sentence is firstly parsed to obtain its
syntactic tree. Then the CKY-style decoder tries
to generate the best annotated BTG tree using the
trained annotated lexical and merging rules. We
store all annotated lexical rules and their proba-
bilities in a standard phrase table ?, where source
phrases are augmented with annotations. During
the application of annotated lexical rules, we la-
bel each source phrase x with linguistic annota-
tion a through the annotation algorithm given the
source-side parse tree, and retrieve x#a from ?.
In the case of unseen combination x#a, we map
it to x and lookup x in the phrase table so that we
can use the un-annotated lexical rule A ? x/y.
We set p(y|x) = max
a
?
p(y|x#a
?
) and p(x|y) =
max
a
?
p(x#a
?
|y) where (x, a?, y) ? ?. When two
neighboring nodes are merged in a specific order,
the two reordering models, P
R
b
and P
R
a
, will eval-
uate this merging independently with individual
scores. The former uses boundary words as fea-
tures while the latter uses the linguistic elements
as features, annotated on the BTG nodes through
the annotation algorithm according to the source-
side parse tree.
5 Experiments and Analysis
In this section we conducted a number of ex-
periments to demonstrate the competitiveness of
the proposed LABTG based SMT when compared
with two baseline systems: Moses (Koehn et al,
2007), a state-of-the-art phrase-based system and
MEBTG (Xiong et al, 2006), a BTG based sys-
tem. We also investigated the impact of differ-
ent annotation schemes on the LABTG model and
studied the effect of annotated phrase translation
model and annotated reordering model on transla-
tion selection and phrase reordering respectively.
All experiments were carried out on the Chinese-
to-English translation task of the NISTMT-05 with
case-sensitive BLEU scores reported.
The systems were trained on the FBIS cor-
pus. We removed 15,250 sentences, for which
the Chinese parser (Xiong et al, 2005) failed to
produce syntactic parse trees. The parser was
trained on the Penn Chinese Treebank with a F1
score of 79.4%. From the remaining FBIS corpus
(224, 165 sentence pairs), we obtained 4.55M stan-
dard bilingual phrases (including 2.75M source
phrases) for the baseline systems and 4.65M an-
notated lexical rules (including 3.13M annotated
source phrases augmented with linguistic anno-
tations) for the LABTG system using the algo-
rithm mentioned above. These statistics reveal
that there are 1.14 (3.13M/2.75M) annotations per
source phrase, which means our annotation algo-
rithm does not increase the number of extracted
rules exponentially.
We extracted 2.8M reordering examples, from
1013
System BLEU
Moses 0.2386
MEBTG 0.2498
LABTG 0.2667
Table 2: LABTG vs. Moses and MEBTG.
which we generated 114.8K reordering features for
the reordering model P
R
b
(shared by both MEBTG
and LABTG systems) using the right boundary
words of phrases and 85K features for the anno-
tated reordering model P
R
a
(only included in the
LABTG system) using linguistic annotations. We
ran the MaxEnt toolkit (Zhang, 2004) to tune re-
ordering feature weights with iteration number be-
ing set to 100 and Gaussian prior to 1 to avoid over-
fitting.
We built our four-gram language model using
Xinhua section of the English Gigaword corpus
(181.1M words) with the SRILM toolkit (Stolcke,
2002). For the efficiency of minimum-error-rate
training (Och, 2003), we built our development set
(580 sentences) using sentences not exceeding 50
characters from the NIST MT-02 evaluation test
data.
5.1 LABTG vs. phrase-based SMT and
BTG-based SMT
We compared the LABTG system with two base-
line systems. The results are given in Table 2.
The LABTG outperforms Moses and MEBTG by
2.81 and 1.69 absolute BLEU points, respectively.
These significant improvements indicate that BTG
formal structures can be successfully extended
with linguistic knowledge extracted from syntac-
tic structures without losing the strength of phrase-
based method.
5.2 The Effect of Different Annotation
Schemes
A great amount of linguistic knowledge is con-
veyed through the syntactic label sl. To obtain
this label, we tag syntactic BTG node with single
label C from its corresponding constituent in the
source-side parse tree while annotate non-syntactic
BTG node with composite label formulated as L-
C-R. We conducted experiments to study the effect
of different annotation schemes on the LABTG
model by comparing three different annotation
schemes for non-syntactic BTG node: (1) using
single label C from its corresponding smallest sub-
tree c? (C), (2) constructing composite label using
Annotation scheme BLEU
C 0.2626
N-C-N 0.2591
B-C-B 0.2667
Annotating syntactic nodes with com-
posite label
0.2464
Table 3: Comparison of different annotation
schemes.
neighboring node as context node (N-C-N), and (3)
constructing composite label using boundary node
as context node (B-C-B). The results are shown in
Table 3.
On the one hand, linguistic annotation provides
additional information for LABTG, transferring
knowledge from source-side linguistic structures
to BTG formal structures. On the other hand, how-
ever, it is also a constraint on LABTG, guiding the
annotated translation model and reordering model
to the selection of target alernatives and reorder-
ing patterns, respectively. A tight constraint al-
ways means that annotations are too specific, al-
though they incorporate rich knowledge. Too spe-
cific annotations are more sensitive to parse errors,
and easier to make the model lose correct transla-
tions or use wrong reordering patterns. That is the
reason why the annotation scheme ?N-C-N? and
?Annotating syntactic nodes with composite label?
5 both hurt the performance. Conversely, a loose
constraint means that annotations are too generic
and have less knowledge incorporated. The an-
notation scheme ?C? is such a scheme with loose
constraint and less knowledge.
Therefore, an ideal annotation scheme should
not be too specific or too generic. The annota-
tion scheme ?B-C-B? achieves a reasonable bal-
ance between knowledge incorporation and con-
straint, which obtains the best performance. There-
fore we choose boundary node as context node for
label annotation of non-syntactic BTG nodes in ex-
periments described later.
5.3 The Effect of Annotated Translation
Model
To investigate the effect of the annotated transla-
tion model on translation selection, we compared
the standard phrase translation model P
T
used
in MEBTG with the annotated phrase translation
5In this annotation scheme, we produce composite label
L-C-R for both syntactic and non-syntactic BTG nodes. For
syntactic node, sibling node is used as context node while for
non-syntactic node, boundary node is used as context node.
1014
Translation model BLEU
P
T
0.2498
P
T
a
0.2581
P
T
a
(-NULL) 0.2548
Table 4: The effect of annotated translation model.
model P
T
a
. The experiment results are shown in
Table 4. The significant improvement in the BLEU
score indicates that the annotated translation model
helps to select better translation options.
Our study on translation output shows that anno-
tating phrases with source-side linguistic elements
can provide at least two kinds of information for
translation model to improve the adequacy: cate-
gory and context. The category knowledge of a
phrase can be used to select its appropriate trans-
lation related to its category. For example, Chi-
nese phrase ??? can be translated into ?value? if
it is a verb or ?at/on? if it is a proposition. How-
ever, the baseline BTG-based system always se-
lects the proposition translation even if it is a verb
because the language model probability for propo-
sition translation is higher than that of verb trans-
lation. This wrong translation of content words is
similar to the incorrect omission reported in (Och
et al, 2003), which both hurt translation adequacy.
The annotated translation model can avoid wrong
translation by filtering out phrase candidates with
unmatched categories.
The context information (provided by context
node) is also quite useful for translation selection.
Even the ?NULL? context, which we used in label
annotation to indicate that a phrase is located at the
boundary of a constituent, provides some informa-
tion, such as, transitive or intransitive attribute of
a verb phrase. The last row of Tabel 4 shows that
if we remove ?NULL? in label annotation, the per-
formance is degraded. (Huang and Knight, 2006)
also reported similar result by using sisterhood an-
notation on the target side.
5.4 The Effect of Annotated Reordering
Model
To investigate the effect of the annotated reorder-
ing model, we integrate P
R
a
with various settings
in MEBTG while keeping its original phrase trans-
lation model P
T
and reordering model P
R
b
un-
changed. We augment P
R
a
?s feature pool incre-
mentally: firstly using only single labels 6(SL)
6For non-syntactic node, we only use the single label C,
without constructing composite label L-C-R.
Reordering Configuration BLEU
P
R
b
0.2498
P
R
b
+ P
R
a
(SL) 0.2588
P
R
b
+ P
R
a
(+BNL) 0.2627
P
R
b
+ P
R
a
(+BNL+HWT) 0.2652
P
R
b
+ P
R
a
(SL+BNL+HWT): only al-
lowed syntactic phrase reordering
0.2512
Table 5: The effect of annotated reordering model.
as features (132 features in total), then construct-
ing composite labels for non-syntactic phrases
(+BNL) (6.7K features), and finally introducing
head words into the feature pool (+BNL+HWT)
(85K features). This series of experiments demon-
strate the impact and degree of contribution made
by each feature for reordering. We also conducted
experiments to investigate the effect of restrict-
ing reordering to syntactic phrases using the best
reordering feature set (SL+BNL+HWT) for P
R
a
.
The experimental results are presented in Table 2,
from which we have the following observations:
(1) Source-side syntactic labels (SL) capture re-
ordering patterns between source structures and
their target counterparts. Even when the base-
line feature set SL with only 132 features is used
for P
R
a
, the BLEU score improves from 0.2498
to 0.2588. This is because most of the frequent
reordering patterns between Chinese and English
have been captured using syntactic labels. For ex-
ample, the pre-verbal modifier PP in Chinese is
translated into post-verbal counterpart in English.
This reordering can be described by a rule with an
inverted order: V P ? ?PP, V P ?, and captured
by our syntactic reordering features.
(2) Context information, provided by labels of
context nodes (BNL) and head word/tag pairs
(HWT), also improves phrase reordering. Produc-
ing composite labels for non-syntactic BTG nodes
(+BNL) and integrating head word/tag pairs into
P
R
a
as reordering features (+BNL+HWT) are both
effective, indicating that context information com-
plements syntactic label for capturing reordering
patterns.
(3) Restricting phrase reordering to syntactic
phrases is harmful. The BLEU score plummets
from 0.2652 to 0.2512.
6 Conclusions
In this paper, we have presented a Linguistically
Annotated BTG based approach to effectively in-
tegrate linguistic knowledge into SMT by merging
1015
source-side linguistic structures with BTG hierar-
chical structures. The LABTG brings BTG-based
SMT towards linguistically syntax-based SMT and
narrows the linguistic gap between them. Our
experimental results show that the LABTG sig-
nificantly outperforms the state-of-the-art phrase-
based SMT and the baseline BTG-based SMT. The
proposed method also offers better translation se-
lection and phrase reordering by introducing the
annotated phrase translation model and the anno-
tated reordering model with linguistic annotations.
We conclude that (1) source-side syntactic in-
formation can improve translation adequacy; (2)
linguistic annotations of BTG nodes well capture
reordering patterns between source structures and
their target counterparts; (3) integration of linguis-
tic knowledge into SMT should be carefully con-
ducted so that the incorporated knowledge could
not have negative constraints on the model7.
References
David Chiang. 2005. A hierarchical phrase-based model
for statistical machine translation. In Proceedings of ACL
2005.
Yuan Ding and Martha Palmer. 2005. Machine Transla-
tion Using Probabilistic Synchronous Dependency Inser-
tion Grammars. In Proceedings of ACL 2005.
Jason Eisner. 2003. Learning non-isomorphic tree mappings
for machine translation. In Proceedings of ACL 2003.
Hany Hassan, Khalil Sima?an and Andy Way. 2007. Su-
pertagged Phrase-based Statistical Machine Translation.
In Proceedings of ACL 2007.
Bryant Huang, Kevi Knight. 2006. Relabeling Syntax Trees
to Improve Syntax-Based Machine Translation Quality. In
Proceedings of NAACL-HLT 2006.
Liang Huang, Kevi Knight and Aravind Joshi. 2006. Statisti-
cal Syntax-directed Translation with Extended Domain of
Locality. In Proceedings of AMTA 2006.
Philipp Koehn, Franz Joseph Och, and Daniel Marcu. 2003.
Statistical Phrase-Based Translation. In Proceedings of
HLT/NAACL.
Philipp Koehn, Hieu Hoang. 2007. Factored Translation
Models. In Proceedings of EMNLP 2007.
Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris Callison-
Burch, Marcello Federico, Nicola Bertoldi, Brooke
Cowan, Wade Shen, Christine Moran, Richard Zens, Chris
Dyer, Ondrej Bojar, Alexandra Constantin, Evan Herbst.
2007. Moses: Open Source Toolkit for Statistical Machine
Translation. ACL 2007, demonstration session, Prague,
Czech Republic, June 2007.
7For example, the annotation scheme ?N-C-N? incorpo-
rates rich syntactic knowledge, but also tightens the constraint
on the model, which therefore loses robustness.
Yang Liu, Qun Liu, Shouxun Lin. 2006. Tree-to-String
Alignment Template for Statistical Machine Translation.
In Proceedings of ACL-COLING 2006.
Daniel Marcu, Wei Wang, Abdessamad Echihabi, and Kevin
Knight. 2006. SPMT: Statistical Machine Translation
with Syntactified Target Language Phraases. In Proceed-
ings of EMNLP.
Franz Josef Och and Hermann Ney. 2000. Improved statisti-
cal alignment models. In Proceedings of ACL 2000.
Franz Josef Och. 2003. Minimum Error Rate Training in
Statistical Machine Translation. In Proceedings of ACL
2003.
Franz Josef Och, Daniel Gildea, Sanjeev Khudanpur, Anoop
Sarkar, Kenji Yamada, Alex Fraser, Shankar Kumar, Libin
Shen, David Smith, Katherine Eng, Viren Jain, Zhen Jin,
Dragomir Radev. 2003. Final Report of Johns Hopkins
2003 SummerWorkshop on Syntax for Statistical Machine
Translation.
Chris Quirk, Arul Menezes and Colin Cherry. 2005. Depen-
dency Treelet Translation: Syntactically Informed Phrasal
SMT. In Proceedings of ACL 2005.
Hendra Setiawan, Min-Yen Kan and Haizhou Li. 2007. Or-
dering Phrases with Function Words. In Proceedings of
ACL 2007.
Andreas Stolcke. 2002. SRILM - an extensible language
modeling toolkit. In Proceedings of International Con-
ference on Spoken Language Processing, volume 2, pages
901-904.
Dekai Wu. 1996. A Polynomial-Time Algorithm for Statisti-
cal Machine Translation. In Proceedings of ACL 1996.
Dekai Wu. 1997. Stochastic Inversion Transduction Gram-
mars and Bilingual Parsing of Parallel Corpora. Computa-
tional Linguistics, 23(3):377-403.
Deyi Xiong, Shuanglong Li, Qun Liu, Shouxun Lin, Yueliang
Qian. 2005. Parsing the Penn Chinese Treebank with Se-
mantic Knowledge. In Proceedings of IJCNLP, Jeju Is-
land, Korea.
Deyi Xiong, Qun Liu and Shouxun Lin. 2006. Maximum En-
tropy Based Phrase Reordering Model for Statistical Ma-
chine Translation. In Proceedings of ACL-COLING 2006.
Nianwen Xue, Fei Xia, Fu-Dong Chiou, and Martha Palmer.
2005. The Penn Chinese TreeBank: Phrase Structure An-
notation of a Large Corpus. Natural Language Engineer-
ing, 11(2):207-238.
Dongdong Zhang, Mu Li, Chi-Ho Li and Ming Zhou. 2007.
Phrase Reordering Model Integrating Syntactic Knowl-
edge for SMT. In Proceedings of EMNLP-CoNLL 2007.
Hao Zhang and Daniel Gildea. 2005. Stochastic Lexicalized
Inversion Transduction Grammar for Alignment. In Pro-
ceedings of ACL 2005.
Le Zhang. 2004. Maximum Entropy Model-
ing Tooklkit for Python and C++. Available at
http://homepages.inf.ed.ac.uk/s0450736
/maxent toolkit.html.
Andreas Zollmann and Ashish Venugopal. 2006. Syntax
Augmented Machine Translation via Chart Parsing. In
NAACL 2006 - Workshop on statistical machine transla-
tion, New York. June 4-9.
1016
