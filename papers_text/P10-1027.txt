Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 257?265,
Uppsala, Sweden, 11-16 July 2010. c?2010 Association for Computational Linguistics
Recommendation in Internet Forums and Blogs
Jia Wang
Southwestern Univ.
of Finance &
Economics China
wj96@sina.cn
Qing Li
Southwestern Univ.
of Finance &
Economics China
liq t@swufe.edu.cn
Yuanzhu Peter Chen
Memorial Univ. of
Newfoundland
Canada
yzchen@mun.ca
Zhangxi Lin
Texas Tech Univ.
USA
zhangxi.lin
@ttu.edu
Abstract
The variety of engaging interactions
among users in social medial distinguishes
it from traditional Web media. Such a fea-
ture should be utilized while attempting to
provide intelligent services to social me-
dia participants. In this article, we present
a framework to recommend relevant infor-
mation in Internet forums and blogs using
user comments, one of the most represen-
tative of user behaviors in online discus-
sion. When incorporating user comments,
we consider structural, semantic, and au-
thority information carried by them. One
of the most important observation from
this work is that semantic contents of user
comments can play a fairly different role
in a different form of social media. When
designing a recommendation system for
this purpose, such a difference must be
considered with caution.
1 Introduction
In the past twenty years, the Web has evolved
from a framework of information dissemination to
a social interaction facilitator for its users. From
the initial dominance of static pages or sites, with
addition of dynamic content generation and pro-
vision of client-side computation and event han-
dling, Web applications have become a preva-
lent framework for distributed GUI applications.
Such technological advancement has fertilized vi-
brant creation, sharing, and collaboration among
the users (Ahn et al, 2007). As a result, the role
of Computer Science is not as much of designing
or implementing certain data communication tech-
niques, but more of enabling a variety of creative
uses of the Web.
In a more general context, Web is one of the
most important carriers for ?social media?, e.g. In-
ternet forums, blogs, wikis, podcasts, instant mes-
saging, and social networking. Various engaging
interactions among users in social media differ-
entiate it from traditional Web sites. Such char-
acteristics should be utilized in attempt to pro-
vide intelligent services to social media users.
One form of such interactions of particular inter-
est here is user comments. In self-publication, or
customer-generated media, a user can publish an
article or post news to share with others. Other
users can read and comment on the posting and
these comments can, in turn, be read and com-
mented on. Digg (www.digg.com), Yahoo!Buzz
(buzz.yahoo.com) and various kinds of blogs are
commercial examples of self-publication. There-
fore, reader responses to earlier discussion provide
a valuable source of information for effective rec-
ommendation.
Currently, self-publishing media are becoming
increasingly popular. For instance, at this point of
writing, Technorati is indexing over 133 million
blogs, and about 900,000 new blogs are created
worldwide daily1. With such a large scale, infor-
mation in the blogosphere follows a Long Tail Dis-
tribution (Agarwal et al, 2010). That is, in aggre-
gate, the not-so-well-known blogs can have more
valuable information than the popular ones. This
gives us an incentive to develop a recommender
to provide a set of relevant articles, which are ex-
pected to be of interest to the current reader. The
user experience with the system can be immensely
enhanced with the recommended articles. In this
work, we focus on recommendation in Internet fo-
rums and blogs with discussion threads.
Here, a fundamental challenge is to account for
topic divergence, i.e. the change of gist during
the process of discussion. In a discussion thread,
the original posting is typically followed by other
readers? opinions, in the form of comments. Inten-
1http://technorati.com/
257
tion and concerns of active users may change as
the discussion goes on. Therefore, recommenda-
tion, if it were only based on the original posting,
can not benefit the potentially evolving interests of
the users. Apparently, there is a need to consider
topic evolution in adaptive content-based recom-
mendation and this requires novel techniques in
order to capture topic evolution precisely and to
prevent drastic topic shifting which returns com-
pletely irrelevant articles to users.
In this work, we present a framework to recom-
mend relevant information in Internet forums and
blogs using user comments, one of the most rep-
resentative recordings of user behaviors in these
forms of social media.
It has the following contributions.
? The relevant information is recommended
based on a balanced perspective of both the
authors and readers.
? We model the relationship among comments
and that relative to the original posting us-
ing graphs in order to evaluate their combined
impact. In addition, the weight of a comment
is further enhanced with its content and with
the authority of its poster.
2 Related Work
In a broader context, a related problem is content-
based information recommendation (or filtering).
Most information recommender systems select ar-
ticles based on the contents of the original post-
ings. For instance, Chiang and Chen (Chiang and
Chen, 2004) study a few classifiers for agent-based
news recommendations. The relevant news selec-
tions of these work are determined by the textual
similarity between the recommended news and the
original news posting. A number of later proposals
incorporate additional metadata, such as user be-
haviors and timestamps. For example, Claypool et
al. (Claypool et al, 1999) combine the news con-
tent with numerical user ratings. Del Corso, Gull??,
and Romani (Del Corso et al, 2005) use times-
tamps to favor more recent news. Cantador, Bel-
login, and Castells (Cantador et al, 2008) utilize
domain ontology. Lee and Park (Lee and Park,
2007) consider matching between news article at-
tributes and user preferences. Anh et al (Ahn
et al, 2007) and Lai, Liang, and Ku (Lai et al,
2003) construct explicit user profiles, respectively.
Lavrenko et al (Lavrenko et al, 2000) propose
the e-Analyst system which combines news stories
with trends in financial time series. Some go even
further by ignoring the news contents and only us-
ing browsing behaviors of the readers with similar
interests (Das et al, 2007).
Another related problem is topic detection and
tracking (TDT), i.e. automated categorization of
news stories by their themes. TDT consists
of breaking the stream of news into individual
news stories, monitoring the stories for events
that have not been seen before, and categorizing
them (Lavrenko and Croft, 2001). A topic is mod-
eled with a language profile deduced by the news.
Most existing TDT schemes calculate the similar-
ity between a piece of news and a topic profile to
determine its topic relevance (Lavrenko and Croft,
2001) (Yang et al, 1999). Qiu (Qiu et al, 2009)
apply TDT techniques to group news for collabo-
rative news recommendation. Some work on TDT
takes one step further in that they update the topic
profiles as part of the learning process during its
operation (Allan et al, 2002) (Leek et al, 2002).
Most recent researches on information recom-
mendation in social media focus on the blogo-
sphere. Various types of user interactions in the
blogosphere have been observed. A prominent
feature of the blogosphere is the collective wis-
dom (Agarwal et al, 2010). That is, the knowledge
in the blogosphere is enriched by such engaging
interactions among bloggers and readers as post-
ing, commenting and tagging. Prior to this work,
the linking structure and user tagging mechanisms
in the blogosphere are the most widely adopted
ones to model such collective wisdom. For ex-
ample, Esmaili et al (Esmaili et al, 2006) fo-
cus on the linking structure among blogs. Hayes,
Avesani, and Bojars (Hayes et al, 2007) explore
measures based on blog authorship and reader tag-
ging to improve recommendation. Li and Chen
further integrate trust, social relation and semantic
analysis (Li and Chen, 2009). These approaches
attempt to capture accurate similarities between
postings without using reader comments. Due
to the interactions between bloggers and readers,
blog recommendation should not limit its input to
only blog postings themselves but also incorporate
feedbacks from the readers.
The rest of this article is organized as follows.
We first describe the design of our recommenda-
tion framework in Section 3. We then evaluate
the performance of such a recommender using two
258
  
 
		

 








 



ff
fi

fl



ffi






 




 


  
 


!


 
"
fi

#


$

$

"
fi

#
 $





"
fi

#
%
&





Figure 1: Design scheme
different social media corpora (Section 4). This
paper is concluded with speculation on how the
current prototype can be further improved in Sec-
tion 5.
3 System Design
In this section, we present a mechanism for rec-
ommendation in Internet forums and blogs. The
framework is sketched in Figure 1. Essentially,
it builds a topic profile for each original posting
along with the comments from readers, and uses
this profile to retrieve relevant articles. In par-
ticular, we first extract structural, semantic, and
authority information carried by the comments.
Then, with such collective wisdom, we use a graph
to model the relationship among comments and
that relative to the original posting in order to eval-
uate the impact of each comment. The graph is
weighted with postings? contents and the authors?
authority. This information along with the original
posting and its comments are fed into a synthe-
sizer. The synthesizer balances views from both
authors and readers to construct a topic profile to
retrieve relevant articles.
3.1 Incorporating Comments
In a discussion thread, comments made at differ-
ent levels reflect the variation of focus of read-
ers. Therefore, recommended articles should re-
flect their concerns to complement the author?s
opinion. The degree of contribution from each
comment, however, is different. In the extreme
case, some of them are even advertisements which
are completely irrelevant to the discussion topics.
In this work, we use a graph model to differenti-
ate the importance of each comment. That is, we
model the authority, semantic, structural relations
of comments to determine their combined impact.
3.1.1 Authority Scoring Comments
Intuitively, each comment may have a different de-
gree of authority determined by the status of its
author (Hu et al, 2007). Assume we have n users
in a forum, denoted by U = {u1, u2, . . . , un}.
We calculate the authority ai for user ui. To do
that, we employ a variant of the PageRank algo-
rithm (Brin and Page, 1998). We consider the
cases that a user replies to a previous posting and
that a user quotes a previous posting separately.
For user uj , we use lr(i, j) to denote the number
of times that uj has replied to user ui. Similarly,
we use lq(i, j) to denote the number of times that
uj has quoted user ui. We combine them linearly:
l?(i, j) = ?1lr(i, j) + ?2lq(i, j).
Further, we normalize the above quantity to record
how frequently a user refers to another:
l(i, j) = l
?(i, j)?n
k=1 l?(i, k) + ?
.
Inline with the PageRank algorithm, we define
the authority of user ui as
ai = ?n + (1? ?)?
n?
k=1
(l(k, i)? ak) .
3.1.2 Differentiating comments with
Semantic and Structural relations
Next, we construct a similar model in terms of the
comments themselves. In this model, we treat the
original posting and the comments each as a text
node. This model considers both the content simi-
larity between text nodes and the logic relationship
among them.
On the one hand, the semantic similarity be-
tween two nodes can be measured with any com-
monly adopted metric, such as cosine similarity
and Jaccard coefficient (Baeza-Yates and Ribeiro-
Neto, 1999). On the other hand, the structural re-
lation between a pair of nodes takes two forms
as we have discussed earlier. First, a comment
can be made in response to the original posting
or at most one earlier comment. In graph theo-
retic terms, the hierarchy can be represented as a
tree GT = (V,ET ), where V is the set of all text
nodes and ET is the edge set. In particular, the
original posting is the root and all the comments
are ordinary nodes. There is an arc (directed edge)
eT ? ET from node v to node u, denoted (v, u), if
the corresponding comment u is made in response
to comment (or original posting) v. Second, a
comment can quote from one or more earlier com-
ments. From this perspective, the hierarchy can
be modeled using a directed acyclic graph (DAG),
259
M0.8 0.50.8 0 0000.5
0
0 00 000
001
0 00 100 00
0.50 100.8
C
MT
MD
2
1
3
2
1
3
Semantic Relation
Quotation Relation
Reply Relation
M
0
0 01.5
0.8
Figure 2: Multi-relation graph of comments based
on the structural and semantic information
denoted GD = (V,ED). There is an arc eD ? ED
from node v to node u, denoted (v, u), if the corre-
sponding comment u quotes comment (or original
posting) v. As shown in Figure 2, for either graph
GT or GD, we can use a ?V ? ? ?V ? adjacency ma-
trix, denoted MT and MD, respectively, to record
them. Similarly, we can also use a ?V ? ? ?V ? ma-
trix defined on [0, 1] to record the content similar-
ity between nodes and denote it by MC . Thus, we
combine these three aspects linearly:
M = ?1 ?MC + ?2 ?MT + ?3 ?MD.
The importance of a text node can be quantized
by the times it has been referred to. Considering
the semantic similarity between nodes, we use an-
other variant of the PageRank algorithm to calcu-
late the weight of comment j:
s?j =
?
?V ? + (1? ?)?
?V ??
k=1
rk,j ? s?k,
where ? is a damping factor, and rk,j is the nor-
malized weight of comment k referring to j de-
fined as
r(k, j) = Mk,j?
j
Mk,j + ? ,
where Mk,j is an entry in the graph adjacency ma-
trix M and ? is a constant to avoid division by zero.
In some social networking media, a user may
have a subset of other users as ?friends?. This can
be captured by a ?U ???U ? matrix of {0, 1}, whose
entries are denoted by fi,j . Thus, with this infor-
mation and assuming poster i has made a comment
k for user j?s posting, the final weight of this com-
ment is defined as
sk = s?k ?
(ai + fi,j
2
)
.
3.2 Topic Profile Construction
Once the weight of comments on one posting is
quantified by our models, this information along
with the entire discussion thread is fed into a syn-
thesizer to construct a topic profile. As such, the
perspectives of both authors and readers are bal-
anced for recommendation.
The profile is a weight vector of terms to model
the language used in the discussion thread. Con-
sider a posting d0 and its comment sequence
{d1, d2, ? ? ? , dm}. For each term t, a compound
weight W (t) = (1? ?) ? W1(t) + ? ? W2(t)
is calculated. It is a linear combination of the
contribution by the posting itself, W1(t), and that
by the comments, W2(t). We assume that each
term is associated with an ?inverted document fre-
quency?, denoted by I(t) = log Nn(t) , where N is
the corpus size and n(t) is the number of docu-
ments in corpus containing term t. We use a func-
tion f(t, d) to denote the number of occurrences of
term t in document d, i.e. ?term frequency?. Thus,
when the original posting and comments are each
considered as a document, this term frequency can
be calculated for any term in any document. We
thus define the weight of term t in document d, be
the posting itself or a comment, using the standard
TF/IDF definition (Baeza-Yates and Ribeiro-Neto,
1999):
w(t, d) =
(
0.5 + 0.5? f(t, d)maxt? f(t?, d)
)
? I(t).
The weight contributed by the posting itself, d0,
is thus:
W1(t) = w(t, d0)maxt? w(t?, d0)
.
The weight contribution from the comments
{d1, d2, ? ? ? , dm} incorporates not only the lan-
guage features of these documents but also their
importance in the discussion thread. That is, the
contribution of comment score is incorporated into
weight calculation of the words in a comment.
W2(t) =
m?
i=1
( w(t, di)
maxt? w(t?, di)
)
?
( s(i)
maxi? s(i?)
)
.
Such a treatment of compounded weight W (t)
is essentially to recognize that readers? impact on
selecting relevant articles and the difference of
their influence. For each profile, we select the top-
n highest weighted words to represent the topic.
260
With the topic profile thus constructed, the re-
triever returns an ordered list of articles with de-
creasing relevance to the topic. Note that our
approach to differentiate the importance of each
comment can be easily incorporated into any
generic retrieval model. In this work, our retriever
is adopted from (Lavrenko et al, 2000).
3.3 Interpretation of Recommendation
Since interpreting recommended items enhances
users? trusting beliefs (Wang and Benbasat, 2007),
we design a creative approach to generate hints
to indicate the relationship (generalization, spe-
cialization and duplication) between the recom-
mended articles and the original posting based on
our previous work (Candan et al, 2009).
Article A being more general than B can be in-
terpreted as A being less constrained than B by
the keywords they contain. Let us consider two ar-
ticles, A and B, where A contains keywords, k1
and k2, and B only contains k1.
? If A is said to be more general than B, then
the additional keyword, k2, of article A must
render A less constrained than B. Therefore,
the content of A can be interpreted as k1?k2.
? If, on the other hand, A is said to be more
specific than B, then the additional keyword,
k2, must render A more constrained than B.
Therefore, the content of A can be interpreted
as k1 ? k2.
Note that, in the two-keyword space ?k1, k2?, A
can be denoted by a vector ?aA, bA? and B can be
denoted by ?aB, 0?. The origin O = ?0, 0? cor-
responds to the case where an article does contain
neither k1 nor k2. That is, O corresponds to an
article which can be interpreted as ?k1 ? ?k2 ?
? (k1 ? k2). Therefore, if A is said to be more
general than B, ?A = d(A,O) should be greater
than ?B = d(B,O). This allows us to measure
the degrees of generalization and specialization of
two articles. Given two articles, A and B, of the
same topic, they will have a common keyword
base, while both articles will also have their own
content, different from their common base. Let
us denote the common part of A by Ac and com-
mon part of B by Bc. Note that ?AC and ?BC
are usually unequal because the same words in the
common part have different term weights in article
A and B respectively. Given these and the gener-
alization concept introduced above for two similar
articles A and B, we can define the degree of gen-
eralization (GAB) and specialization (SAB) of B
with respect to A as
GAB = ?A/?Bc, SAB = ?B/?Ac.
To alleviate the effect of document length, we
revise the definition as
GAB = ?A/ log(?A)?Bc/ log(?A+?B) ,
SAB = ?B/ log(?B)?Ac/ log(?A+?B) .
The relative specialization and generalization
values can be used to reveal the relationships be-
tween recommended articles and the original post-
ing. Given original posting A and recommended
article B, if GAB > ?g, for a given generalization
threshold ?g, then B is marked as a generalization.
When this is not the case, if SAB > ?s, for a given
specialization threshold, ?s, then B is marked as
a specialization. If neither of these cases is true,
then B is duplicate of A.
Such an interpretation provides a control on de-
livering recommended articles. In particular, we
can filter the duplicate articles to avoid recom-
mending the same information.
4 Experimental Evaluation
To evaluate the effectiveness of our proposed rec-
ommendation mechanism, we carry out a series of
experiments on two synthetic data sets, collected
from Internet forums and blogs, respectively. The
first data set is called Forum. This data set is
constructed by randomly selecting 20 news arti-
cles with corresponding reader comments from the
Digg Web site and 16,718 news articles from the
Reuters news Web site. This simulates the sce-
nario of recommending relevant news from tradi-
tional media to social media users for their further
reading. The second one is the Blog data set con-
taining 15 blog articles with user comments and
15,110 articles obtained from the Myhome Web
site 2. Details of these two data sets are shown in
Table 1. For evaluation purposes, we adopt the tra-
ditional pooling strategy (Zobel, 1998) and apply
to the TREC data set to mark the relevant articles
for each topic.
2http://blogs.myhome.ie
261
Table 1: Evaluation data set
Synthetic Data Set Forum Blog
Topics
No. of postings 20 15
Ave. length of postings 676 236
No. of comments per posting 81.4 46
Ave. length of comments 45 150
Target No. of articles 16718 15110Ave. length of articles 583 317
The recommendation engine may return a set of
essentially the same articles re-posted at different
sites. Therefore, we introduce a metric of novelty
to measure the topic diversity of returned sugges-
tions. In our experiments, we define precision and
novelty metrics as
P@N = ?C ?R??R? and D@N =
?E ?R?
?R? ,
where R is the subset of the top-n articles returned
by the recommender, C is the set of manually
tagged relevant articles, and E is the set of man-
ually tagged relevant articles excluding duplicate
ones to the original posting. We select the top 10
articles for evaluation assuming most readers only
browse up to 10 recommended articles (Karypis,
2001). Meanwhile, we also utilize mean aver-
age precision (MAP) and mean average novelty
(MAN) to evaluate the entire set of returned ar-
ticle.
We test our proposal in four aspects. First, we
compare our work to two baseline works. We then
present results for some preliminary tests to find
out the optimal values for two critical parameters.
Next, we study the effect of user authority and
its integration to comment weighting. Fourth, we
evaluate the performance gain obtained from inter-
preting recommendation. In addition, we provide
a significance test to show that the observed differ-
ences in effectiveness for different approaches are
not incidental. In particular, we use the t-test here,
which is commonly used for significance tests in
information retrieval experiments (Hull, 1993).
4.1 Overall Performance
As baseline proposals, we also implement two
well-known content-based recommendation meth-
ods (Bogers and Bosch, 2007). The first method,
Okapi, is commonly applied as a representa-
tive of the classic probabilistic model for rele-
vant information retrieval (Robertson and Walker,
1994). The second one, LM, is based on statisti-
cal language models for relevant information re-
trieval (Ponte and Croft, 1998). It builds a proba-
Table 2: Overall performance
Precision Novelty
Data Method P@10 MAP D@10 MAN
Forum
Okapi 0.827 0.833 0.807 0.751
LM 0.804 0.833 0.807 0.731
Our 0.967 0.967 0.9 0.85
Blog
Okapi 0.733 0.651 0.667 0.466
LM 0.767 0.718 0.70 0.524
Our 0.933 0.894 0.867 0.756
bilistic language model for each article, and ranks
them on query likelihood, i.e. the probability of the
model generating the query. Following the strat-
egy of Bogers and Bosch, relevant articles are se-
lected based on the title and the first 10 sentences
of the original postings. This is because articles
are organized in the so-called inverted pyramid
style, meaning that the most important informa-
tion is usually placed at the beginning. Trimming
the rest of an article would usually remove rela-
tively less crucial information, which speeds up
the recommendation process.
A paired t-test shows that using P@10 and
D@10 as performance measures, our approach
performs significantly better than the baseline
methods for both Forum and Blog data sets as
shown in Table 2. In addition, we conduct t-tests
using MAP and MAN as performance measures,
respectively, and the p-values of these tests are all
less than 0.05, meaning that the results of experi-
ments are statistically significant. We believe that
such gains are introduced by the additional infor-
mation from the collective wisdom, i.e. user au-
thority and comments. Note that the retrieval pre-
cision for Blog of two baseline methods is not as
good as that for Forum. Our explanation is that
blog articles may not be organized in the inverted
pyramid style as strictly as news forum articles.
4.2 Parameters of Topic Profile
There are two important parameters to be consid-
ered to construct topic profiles for recommenda-
tion. 1) the number of the most weighted words
to represent the topic, and 2) combination coeffi-
cient ? to determine the contribution of original
posting and comments in selecting relevant arti-
cles.We conduct a series of experiments and find
out that the optimal performance is obtained when
the number of words is between 50 and 70, and
? is between 0.65 and 0.75. When ? is set to 0,
the recommended articles only reflect the author?s
opinion. When ? = 1, the suggested articles rep-
resent the concerns of readers exclusively. In the
262
Table 3: Performance of four runs
Precision Novelty
Method P@10 MAP D@10 MAN
Forum
RUN1 0.88 0.869 0.853 0.794
RUN2 0.933 0.911 0.9 0.814
RUN3 0.94 0.932 0.9 0.848
RUN4 0.967 0.967 0.9 0.85
Blog
RUN1 0.767 0.758 0.7 0.574
RUN2 0.867 0.828 0.833 0.739
RUN3 0.9 0.858 0.833 0.728
RUN4 0.933 0.894 0.867 0.756
following experiments, we set topic word number
to 60 and combination coefficient ? to 0.7.
4.3 Effect of Authority and Comments
In this part, we explore the contribution of user
authority and comments in social media recom-
mender. In particular, we study the following sce-
narios with increasing system capabilities. Note
that, lacking friend information (Section 3.1.2) in
the Forum data set, fi,j is set to zero.
? RUN 1 (Posting): the topic profile is con-
structed only based on the original posting
itself. This is analogous to traditional rec-
ommenders which only consider the focus of
authors for suggesting further readings.
? RUN 2 (Posting+Authority): the topic profile
is constructed based on the original posting
and participant authority.
? RUN 3 (Posting+Comment): the topic profile
is constructed based on the original posting
and its comments.
? RUN 4 (All): the topic profile is constructed
based on the original posting, user authority,
and its comments.
Here, we set ?1 = ?2 = ?3 = 1. Our t-test
shows that using P@10 and D@10 as performance
measures, RUN4 performs best in both Forum and
Blog data sets as shown in Table 3. There is a step-
wise performance improvement while integrating
user authority, comments and both. With the as-
sistance of user authority and comments, the rec-
ommendation precision is improved up to 9.8%
and 21.6% for Forum and Blog, respectively. The
opinion of readers is an effective complementarity
to the authors? view in suggesting relevant infor-
mation for further reading.
Moreover, we investigate the effect of the se-
mantic and structural relations among comments,
i.e. semantic similarity, reply, and quotation. For
this purpose, we carry out a series of experiments
based on different combinations of these relations.
CR RR QR CQR CRR QRR All
MA
P
0.6
0.7
0.8
0.9
1.0 Forum Data SetBlog Data Set
Figure 3: Effect of content, quotation and reply
relation
? Content Relation (CR): only the content rela-
tion matrix is used in scoring the comments.
? Quotation Relation (QR): only the quotation
relation matrix is used in scoring the com-
ments.
? Reply Relation (RR): only the reply relation
matrix is used in scoring the comments.
? Content+Quotation Relation (CQR): both the
content and quotation relation matrices is
used in scoring the comments.
? Content+Reply Relation(CRR): both the con-
tent and reply relation matrices are used in
scoring the comments.
? Quotation+Reply Relation (QRR): both the
quotation and reply relation matrices are used
in scoring the comments.
? All: all three matrices are used.
The MAP yielded by these combinations for
both data sets is plotted in Figure 3. For the case of
Forum, we observe that incorporating content in-
formation adversely affects recommendation pre-
cision. This concurs with what we saw in our pre-
vious work (Wang et al, 2010). On the other hand,
when we test the Blog data set, the trend is the op-
posite, i.e. content similarity does contribute to re-
trieval performance positively. This is attributed
by the text characteristics of these two forms of
social media. Specifically, comments in news fo-
rums usually carry much richer structural informa-
tion than blogs where comments are usually ?flat?
among themselves.
4.4 Recommendation Interpretation
To evaluate the precision of interpreting the re-
lationship between recommended articles and the
263
original posting, the evaluation metric of success
rate S is defined as
S =
m?
i=1
(1? ei)/m,
where m is the number of recommended articles,
ei is the error weight of recommended article i.
Here, the error weight is set to one if the result
interpretation is mis-labelled.
From our studies, we observe that the success
rate at top-10 is around 89.3% and 87.5% for the
Forum and Blog data sets, respectively. Note that
these rates include the errors introduced by the ir-
relevant articles returned by the retrieval module.
To estimate optimal thresholds of generalization
and specialization, we calculate the success rate at
different threshold values and find that neither too
small nor too large a value is appropriate for inter-
pretation. In our experiments, we set generaliza-
tion threshold ?g to 3.2 and specialization thresh-
old ?s to 1.8 for the Forum data set, and ?g to 3.5
and ?s to 2.0 for Blog. Ideally, threshold values
would need to be set through a machine learning
process, which identifies proper values based on a
given training sample.
5 Conclusion and Future Work
The Web has become a platform for social net-
working, in addition to information dissemination
at its earlier stage. Many of its applications are
also being extended in this fashion. Traditional
recommendation is essentially a push service to
provide information according to the profile of in-
dividual or groups of users. Its niche at the Web
2.0 era lies in its ability to enable online discus-
sion by serving up relevant references to the par-
ticipants. In this work, we present a framework for
information recommendation in such social media
as Internet forums and blogs. This model incor-
porates information of user status and comment
semantics and structures within the entire discus-
sion thread. This framework models the logic con-
nections among readers and the innovativeness of
comments. By combining such information with
traditional statistical language models, it is capa-
ble of suggesting relevant articles that meet the dy-
namic nature of a discussion in social media. One
important discovery from this work is that, when
integrating comment contents, the structural infor-
mation among comments, and reader relationship,
it is crucial to distinguish the characteristics of var-
ious forms of social media. The reason is that the
role that the semantic content of a comment plays
can differ from one form to another.
This study can be extended in a few interest-
ing ways. For example, we can also evaluate its
effectiveness and costs during the operation of a
discussion forum, where the discussion thread is
continually updated by new comments and votes.
Indeed, its power is yet to be further improved and
investigated.
Acknowledgments
Li?s research is supported by National Natural Sci-
ence Foundation of China (Grant No.60803106),
the Scientific Research Foundation for the Re-
turned Overseas Chinese Scholars, State Educa-
tion Ministry, and the Fok Ying-Tong Education
Foundation for Young Teachers in the Higher Ed-
ucation Institutions of China. Research of Chen
is supported by Natural Science and Engineering
Council (NSERC) of Canada.
References
Nitin Agarwal, Magdiel Galan, Huan Liu, and Shankar
Subramanya. 2010. Wiscoll: Collective wis-
dom based blog clustering. Information Sciences,
180(1):39?61.
Jae-wook Ahn, Peter Brusilovsky, Jonathan Grady,
Daqing He, and Sue Yeon Syn. 2007. Open user
profiles for adaptive news systems: help or harm?
In Proceedings of the 16th International Conference
on World Wide Web (WWW), pages 11?20.
James Allan, Victor Lavrenko, and Russell Swan.
2002. Explorations within topic tracking and detec-
tion. Topic detection and tracking: event-based in-
formation organization Kluwer Academic Publish-
ers, pages 197?224.
Ricardo Baeza-Yates and Berthier Ribeiro-Neto. 1999.
Modern information retrieval. Addison Wesley
Longman Publisher.
Toine Bogers and Antal Bosch. 2007. Comparing and
evaluating information retrieval algorithms for news
recommendation. In Proceedings of 2007 ACM con-
ference on Recommender Systems, pages 141?144.
Sergey Brin and Lawrence Page. 1998. The
anatomy of a large-scale hypertextual web search
engine. Computer networks and ISDN systems,
30(1-7):107?117.
K. Selc?uk Candan, Mehmet E. Do?nderler, Terri Hedg-
peth, Jong Wook Kim, Qing Li, and Maria Luisa
Sapino. 2009. SEA: Segment-enrich-annotate
paradigm for adapting dialog-based content for im-
proved accessibility. ACM Transactions on Informa-
tion Systems (TOIS), 27(3):1?45.
264
Ivan Cantador, Alejandro Bellogin, and Pablo Castells.
2008. Ontology-based personalized and context-
aware recommendations of news items. In Pro-
ceedings of IEEE/WIC/ACM international Confer-
ence on Web Intelligence and Intelligent Agent Tech-
nology (WI), pages 562?565.
Jung-Hsien Chiang and Yan-Cheng Chen. 2004. An
intelligent news recommender agent for filtering and
categorizing large volumes of text corpus. Inter-
national Journal of Intelligent Systems, 19(3):201?
216.
Mark Claypool, Anuja Gokhale, Tim Miranda, Pavel
Murnikov, Dmitry Netes, and Matthew Sartin. 1999.
Combining content-based and collaborative filters in
an online newspaper. In Proceedings of the ACM
SIGIR Workshop on Recommender Systems.
Abhinandan S. Das, Mayur Datar, Ashutosh Garg, and
Shyam Rajaram. 2007. Google news personaliza-
tion: scalable online collaborative filtering. In Pro-
ceedings of the 16th International Conference on
World Wide Web (WWW), pages 271?280.
Gianna M. Del Corso, Antonio Gull??, and Francesco
Romani. 2005. Ranking a stream of news. In
Proceedings of the 14th International Conference on
World Wide Web(WWW), pages 97?106.
Kyumars Sheykh Esmaili, Mahmood Neshati, Mohsen
Jamali, Hassan Abolhassani, and Jafar Habibi.
2006. Comparing performance of recommendation
techniques in the blogsphere. In ECAI 2006 Work-
shop on Recommender Systems.
Conor Hayes, Paolo Avesani, and Uldis Bojars. 2007.
An analysis of bloggers, topics and tags for a blog
recommender system. In Workshop on Web Mining
(WebMine), pages 1?20.
Meishan Hu, Aixin Sun, and Ee-Peng Lim. 2007.
Comments-oriented blog summarization by sen-
tence extraction. In Proceedings of the sixteenth
ACM Conference on Conference on Information and
Knowledge Management(CIKM), pages 901?904.
David Hull. 1993. Using statistical testing in the eval-
uation of retrieval experiments. In Proceedings of
the 16th Annual International ACM SIGIR Confer-
ence on Research and Development in Information
Retrieval, pages 329?338.
George Karypis. 2001. Evaluation of item-based Top-
N recommendation algorithms. In Proceedings of
the 10th International Conference on Information
and Knowledge Management (CIKM), pages 247?
254.
Hung-Jen Lai, Ting-Peng Liang, and Yi Cheng Ku.
2003. Customized internet news services based on
customer profiles. In Proceedings of the 5th Interna-
tional Conference on Electronic commerce (ICEC),
pages 225?229.
Victor Lavrenko and W. Bruce Croft. 2001. Rele-
vance based language models. In Proceedings of
the 24th Annual International ACM SIGIR Confer-
ence on Research and Development in Information
Retrieval, pages 120?127.
Victor Lavrenko, Matt Schmill, Dawn Lawrie, Paul
Ogilvie, David Jensen, and James Allan. 2000.
Language models for financial news recommenda-
tion. In Proceedings of the 9th International Confer-
ence on Information and Knowledge Management
(CIKM), pages 389?396.
Hong Joo Lee and Sung Joo Park. 2007. MONERS:
A news recommender for the mobile web. Expert
Systems with Applications, 32(1):143?150.
Tim Leek, Richard Schwartz, and Srinivasa Sista.
2002. Probabilistic approaches to topic detection
and tracking. Topic detection and tracking: event-
based information organization, pages 67?83.
Yung-Ming Li and Ching-Wen Chen. 2009. A synthet-
ical approach for blog recommendation: Combining
trust, social relation, and semantic analysis. Expert
Systems with Applications, 36(3):6536 ? 6547.
Jay Michael Ponte and William Bruce Croft. 1998.
A language modeling approach to information re-
trieval. In Proceedings of the 21st Annual Interna-
tional ACM SIGIR Conference on Research and De-
velopment in Information Retrieval, pages 275?281.
Jing Qiu, Lejian Liao, and Peng Li. 2009. News
recommender system based on topic detection and
tracking. In Proceedings of the 4th Rough Sets and
Knowledge Technology.
Stephen E. Robertson and Stephen G Walker. 1994.
Some simple effective approximations to the 2-
poisson model for probabilistic weighted retrieval.
In Proceedings of the 17th ACM SIGIR conference
on Research and Development in Information Re-
trieval, pages 232?241.
Weiquan Wang and Izak Benbasat. 2007. Recommen-
dation agents for electronic commerce: Effects of
explanation facilities on trusting beliefs. Journal of
Management Information Systems, 23(4):217?246.
Jia Wang, Qing Li, and Yuanzhu Peter Chen. 2010.
User comments for news recommendation in social
media. In Proceedings of the 33rd ACM SIGIR Con-
ference on Research and Development in Informa-
tion Retrieval, pages 295?296.
Yiming Yang, Jaime Guillermo Carbonell, Ralf D.
Brown, Thomas Pierce, Brian T. Archibald, and Xin
Liu. 1999. Learning approaches for detecting and
tracking news events. IEEE Intelligent Systems,
14(4):32?43.
Justin Zobel. 1998. How reliable are the results of
large-scale information retrieval experiments? In
Proceedings of the 21st International ACM SIGIR
Conference on Research and Development in Infor-
mation Retrieval, pages 307?314.
265
