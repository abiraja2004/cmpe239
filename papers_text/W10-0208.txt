Proceedings of the NAACL HLT 2010 Workshop on Computational Approaches to Analysis and Generation of Emotion in Text, pages 62?70,
Los Angeles, California, June 2010. c?2010 Association for Computational Linguistics
Evaluation of Unsupervised Emotion Models                                          
to Textual Affect Recognition
Sunghwan Mac Kim
School of Electrical
and Information Engineering
University of Sydney
Sydney, Australia
skim1871@uni.sydney.edu.au
Alessandro Valitutti
Department of Cognitive Science
and Education
University of Trento
Trento, Italy
a.valitutti@email.unitn.it
Rafael A. Calvo
School of Electrical
and Information Engineering
University of Sydney
Sydney, Australia
rafa@ee.usyd.edu.au
Abstract
In this paper we present an evaluation of new 
techniques for automatically detecting emo-
tions in text. The study estimates categorical 
model and dimensional model for the recogni-
tion of four affective states: Anger, Fear, Joy, 
and Sadness that are common emotions in 
three datasets: SemEval-2007 ?Affective 
Text?, ISEAR (International Survey on Emo-
tion Antecedents and Reactions), and child-
ren?s fairy tales. In the first model, WordNet-
Affect is used as a linguistic lexical resource 
and three dimensionality reduction techniques 
are evaluated: Latent Semantic Analysis 
(LSA), Probabilistic Latent Semantic Analysis 
(PLSA), and Non-negative Matrix Factoriza-
tion (NMF). In the second model, ANEW (Af-
fective Norm for English Words), a normative 
database with affective terms, is employed. 
Experiments show that a categorical model us-
ing NMF results in better performances for 
SemEval and fairy tales, whereas a dimension-
al model performs better with ISEAR.
1 Introduction
Supervised and unsupervised approaches have 
been used to automatically recognize expressions 
of emotion in text such as happiness, sadness,
anger, etc? Supervised learning techniques 
have the disadvantage that large annotated data-
sets are required for training. Since the emotional 
interpretations of a text can be highly subjective, 
more than one annotator is needed, and this 
makes the process of the annotation very time 
consuming and expensive. For this reason, unsu-
pervised methods are normally preferred in the 
realm of Natural Language Processing (NLP)
and emotions.
Supervised and unsupervised techniques have 
been compared before. (Strapparava and Mihal-
cea 2008) describe the comparison between a 
supervised (Na?ve Bayes) and an unsupervised
(Latent Semantic Analysis - LSA) method for 
recognizing six basic emotions.
These techniques have been applied to many 
areas, particularly in improving Intelligent Tutor-
ing Systems. For example, (D?Mello, Craig et al 
2008) used LSA but for detecting utterance types 
and affect in students? dialogue within Autotutor.
(D'Mello, Graesser et al 2007) proposed five 
categories for describing the affect states in stu-
dent-system dialogue.
Significant differences arise not only between 
these two types of techniques but also between 
different emotion models, and these differences 
have significant implications in all these areas. 
While considering emotions and learning, (Kort, 
Reilly et al 2001) proposed (but provided no 
empirical evidence) a model that combines two
emotion models, placing categories in a valence-
arousal plane. This mixed approach has also been 
used in other domains such as blog posts where 
(Aman and Szpakowicz 2007) studied how to 
identify emotion categories as well as emotion 
intensity. To date, many researchers have, how-
ever, utilized and evaluated supervised methods, 
mainly based on the categorical emotion model.
In this study, the goal is to evaluate the merits 
of two conceptualizations of emotions (a cate-
gorical model and a dimensional model) in 
which an unsupervised approach is used. The 
evaluation incorporates three dimensionality re-
62
duction methods and two linguistic lexical re-
sources.
The rest of the paper is organized as follows: 
In Section 2 we present representative research 
of the emotion models used to capture the affec-
tive states of a text. Section 3 describes the tech-
niques of affect classification utilizing lexical 
resources. More specifically, it describes the role 
of emotion models and lexical resources in the 
affect classification. In addition, we give an 
overview of the dimension reduction methods
used in the study. In Section 4 we go over the
affective datasets used. Section 5 provides the
results of the evaluation, before coming to our 
discussion in Section 6.
2 Emotion Models
There are two significantly different models for 
representing emotions: the categorical model and 
dimensional model (Russell 2003).
The categorical model assumes that there are 
discrete emotional categories such as Ekman?s
six basic emotions - anger, disgust, fear, joy,
sadness, and surprise - (Ekman 1992). There are 
a number of primary and unrelated emotions in 
the model. Each emotion is characterized by a 
specific set of features, expressing eliciting con-
ditions or responses. Some researchers have ar-
gued that a different set of emotions is required 
for different domains. For instance, the following 
emotion classes are used in the field of teaching 
and education: boredom, delight, flow, confusion,
frustration, and surprise. The advantage of such 
a representation is that it represents human emo-
tions intuitively with easy to understand emotion 
labels.
A second approach is the dimensional model, 
which represents affects in a dimensional form
(Russell 2003). Emotional states are related each 
other by a common set of dimensions (e.g. va-
lence or arousal) and are generally defined in a 
two or three dimensional space. Each emotion 
occupies some location in this space. A valence 
dimension indicates positive and negative emo-
tions on different ends of the scale. The arousal
dimension differentiates excited vs. calm states. 
Sometimes a third, dominance dimension is used 
to differentiate if the subject feels in control of 
the situation or not.
The categorical model and the dimensional 
model have two different methods for estimating 
the actual emotional states of a person. In the 
former, a person is usually required to choose 
one emotion out of an emotion set that represents 
the best feeling. On the other hand, the latter ex-
ploits rating scales for each dimension like the 
Self Assessment Manikin (SAM) (Lang 1980),
which consists of pictures of manikins, to esti-
mate the degree of valence, arousal, and domi-
nance.
3 Automatic Affect Classification
3.1 Categorical classification with features 
derived from WordNet-Affect
WordNet-Affect (Strapparava and Valitutti 2004)
is an affective lexical repository of words refer-
ring to emotional states. WordNet-Affect extends 
WordNet by assigning a variety of affect labels 
to a subset of synsets representing affective con-
cepts in WordNet (emotional synsets). In addi-
tion, WordNet-Affect has an additional hierarchy 
of affective domain labels. There are publicly 
available lists relevant to the six basic emotion 
categories extracted from WordNet-Affect and 
we used four of the six lists of emotional words 
among them for our experiment.
In addition to WordNet-Affect, we exploited a
Vector Space Model (VSM) in which terms and 
textual documents can be represented through a
term-by-document matrix. More specifically,
terms are encoded as vectors, whose components
are co-occurrence frequencies of words in corpo-
ra documents. Frequencies are weighted accord-
ing to the log-entropy with respect to a tf-idf
weighting schema (Yates and Neto 1999). Final-
ly, the number of dimensions is reduced through 
the dimension reduction methods.
The vector-based representation enables words, 
sentences, and sets of synonyms (i.e. WordNet 
synsets) to be represented in a unifying way with 
vectors. VSM provides a variety of definitions of 
distance between vectors, corresponding to dif-
ferent measures of semantic similarity.  In par-
ticular, we take advantage of cosine angle be-
tween an input vector (input sentence) and an 
emotional vector (i.e. the vector representing an 
emotional synset) as similarity measures to iden-
tify which emotion the sentence connotes.
3.2 Dimension Reduction Methods
The VSM representation can be reduced with 
techniques well known in Information Retrieval: 
LSA, Probabilistic LSA (PLSA), or the Non-
negative Matrix Factorization (NMF) representa-
tions.
Cosine similarities can be defined in these re-
presentations, and here, as other authors have 
done, we use a rule that if the cosine similarity 
63
does not exceed a threshold, the input sentence is 
labeled as ?neutral?, the absence of emotion. 
Otherwise, it is labeled with one emotion asso-
ciated with the closest emotional vector having 
the highest similarity value. We use a predeter-
mined threshold (t = 0.65) for the purpose of va-
lidating a strong emotional analogy between two 
vectors (Penumatsa, Ventura et al 2006).
If we define the similarity between a given in-
put text, I, and an emotional class,  ! , as 
sim(I,   ! ), the categorical classification result, 
CCR, is more formally represented as follows:
CCR(")
= #arg  max! $sim%", ! &'  if sim(", ! ) ( )
"neutral"                        if sim(", ! ) < )* 
One class with the maximum score is selected as 
the final emotion class.
Dimensionality reduction in VSM reduces the
computation time and reduces the noise in the 
data. This enables the unimportant data to dissi-
pate and underlying semantic text to become 
more patent. We will review three statistical di-
mensionality reduction methods (LSA, PLSA, 
and NMF) that are utilized in a category-based 
emotion model.
Latent Semantic Analysis (LSA) is the earliest 
approach successfully applied to various text 
manipulation areas (Landauer, Foltz et al 1998).
The main idea of LSA is to map terms or docu-
ments into a vector space of reduced dimensio-
nality that is the latent semantic space. The map-
ping of the given terms/document vectors to this 
space is based on singular vector decomposition 
(SVD). It is known that SVD is a reliable tech-
nique for matrix decomposition. It can decom-
pose a matrix as the product of three matrices.+ = ,-./  0 ,1-1.1/ = +1 (1)
where Ak is the closest matrix of rank k to the 
original matrix. The columns of Vk represent the 
coordinates for documents in the latent space.
Probabilistic Latent Semantic Anlaysis (PLSA)
(Hofmann 2001) has two characteristics distin-
guishing it from LSA. PLSA defines proper 
probability distributions and the reduced matrix 
does not contain negative values. Based on the 
combination of LSA and some probabilistic theo-
ries such as Bayes rules, the PLSA allows us to 
find the latent topics, the association of docu-
ments and topics, and the association of terms 
and topics. In the equation (2), z is a latent class 
variable (i.e. discrete emotion category), while w
and d denote the elements of term vectors and 
document vectors, respectively.
2(3,4) =  52(6)2(4|6)2(3|6)6 (2)
where P(w|z) and P(d|z) are topic-specific word 
distribution and document distribution, indivi-
dually. The decomposition of PLSA, unlike that 
of LSA, is performed by means of the likelihood 
function. In other words, P(z), P(w|z), and P(d|z)
are determined by the maximum likelihood esti-
mation (MLE) and this maximization is per-
formed through adopting the Expectation Max-
imization (EM) algorithm. For document similar-
ities, each row of the P(d|z) matrix is considered 
with the low-dimensional representation in the 
semantic topic space.
Non-negative Matrix Factorization (NMF) 
(Lee and Seung 1999) has been successfully ap-
plied to semantic analysis. Given a non-negative 
matrix A, NMF finds non-negative factors W and 
H that are reduced-dimensional matrices. The 
product WH can be regarded as a compressed 
form of the data in A.+ 0 78 =  578 (3)
W is a basis vector matrix and H is an encoded 
matrix of the basis vectors in the equation (3). 
NMF solves the following minimization problem 
(4) in order to obtain an approximation A by 
computing W and H in terms of minimizing the 
Frobenius norm of the error.9:;7,8 <+ =78<>2 , ?. ).  7,8 ( 0 (4)
where W, H  0 means that all elements of W and 
H are non-negative. This non-negative peculiari-
ty is desirable for handling text data that always 
require non-negativity constraints. The classifi-
cation of documents is performed based on the 
columns of matrix H that represent the docu-
ments. 
3.3 Three-dimensional estimation with fea-
tures derived from ANEW
Dimensional models have been studied by psy-
chologists often by providing a stimulus (e.g. a 
photo or a text), and then asking subjects to re-
port on the affective experience. ANEW (Brad-
ley and Lang 1999) is a set of normative emo-
tional ratings for a collection of English words
(N=1,035), where after reading the words, sub-
jects reported their emotions in a three dimen-
sional representation. This collection provides 
the rated values for valence, arousal, and domin-
ance for each word rated using the Self Assess-
ment Manikin (SAM). For each word w, the 
normative database provides coordinates 4@ in an 
affective space as:
64
4@ = (ABCD;ED,BFGH?BC,3G9:;B;ED)
= +I 7(4) (5)
The occurrences of these words in a text can 
be used, in a na?ve way, to weight the sentence in 
this emotional plane. This is a na?ve approach 
since words often change their meaning or emo-
tional value when they are used in different con-
texts.
As a counterpart to the categorical classifica-
tion above, this approach assumes that an input 
sentence pertains to an emotion based on the 
least distance between each other on the Va-
lence-Arousal-Dominance (VAD) space. The 
input sentence consists of a number of words and 
the VAD value of this sentence is computed by 
averaging the VAD values of the words:
?D;)D;EDJJJJJJJJJJJJ =  - 4@;:=1; (6)
where n is the total number of words in the input 
sentence. 
Since not many words are available in this 
normative database, a series of synonyms from 
WordNet-Affect are used in order to calculate 
the position of each emotion. These emotional 
synsets are converted to the 3-dimensional VAD 
space and averaged for the purpose of producing 
a single point for the target emotion as follows:
D9G):G;JJJJJJJJJJJ =  - 4@1:=11 (7)
where k denotes the total number of synonyms in 
an emotion. Anger, fear, joy, and sadness emo-
tions are mapped on the VAD space. Let Ac, Fc,
Jc, and Sc be the centroids of four emotions. Then 
the centroids, which are calculated by the equa-
tion (7), are as follows: Ac = (2.55, 6.60, 5.05), Fc
= (3.20, 5.92, 3.60), Jc = (7.40, 5.73, 6.20), and 
Sc = (3.15, 4.56, 4.00). Apart from the four emo-
tions, we manually define neutral to be (5, 5, 5). 
If the centroid of an input sentence is the most 
approximate to that of an emotion, the sentence 
is tagged as the emotion (with the nearest neigh-
bor algorithm). The centroid ?D;)D;EDJJJJJJJJJJJJ might be 
close to an D9G):G;JJJJJJJJJJJ on the VAD space, even if 
they do not share any terms in common. We de-
fine the distance threshold (empirically set to 4) 
to validate the appropriate proximity like the ca-
tegorical classification.
4 Emotion-Labeled Data
Three emotional datasets, with sentence-level 
emotion annotations, were employed for the 
evaluation described in the next section. The first 
dataset is ?Affective Text? from the SemEval 
2007 task (Strapparava and Mihalcea 2007). 1
We also use the ISEAR (International Survey 
on Emotion Antecedents and Reactions) dataset,
which consists of 7,666 sentences (Scherer and 
Wallbott 1994), with regard to our experiments.
This dataset consists of news headlines excerpted 
from newspapers and news web sites. Headlines 
are suitable for our experiments because head-
lines are typically intended to express emotions 
in order to draw the readers? attention. This data-
set has six emotion classes: anger, disgust, fear,
joy, sadness and surprise, and is composed of 
1,250 annotated headlines. The notable characte-
ristics are that SemEval dataset does not only 
allow one sentence to be tagged with multiple 
emotions, but the dataset alo contains a neutral
category in contrast to other datasets.
2
The annotated sentences of the third dataset
are culled from fairy tales (Alm 2009). Emotions 
are particularly significant elements in the lite-
rary genre of fairy tales. The label set with five 
emotion classes is as follows: angry-disgusted,
fearful, happy, sad and surprised. There are 176
stories by three authors: B. Potter, H.C. Ander-
sen, and Grimm?s. The dataset is composed of 
only sentences with affective high agreements,
which means that annotators highly agreed upon 
the sentences (four identical emotion labels).
For building the ISEAR, 1,096 participants who 
have different cultural backgrounds completed 
questionnaires about experiences and reactions 
for seven emotions including anger, disgust, fear,
joy, sadness, shame and guilt.
Emotion SemEval ISEAR Fairy tales Total
Anger 62 2,168 218 2,448
Fear 124 1,090 166 1,380
Joy 148 1,090 445 1,683
Sadness 145 1,082 264 1,491
Table 1: Number of sentences for each emotion
In our study, we have taken into account four 
emotion classes (Anger, Fear, Joy and Sadness)
which are in the intersection among three data-
sets (SemEval, ISEAR and Fairy tales). The 
number of sentences for each emotion and each 
1 The dataset is publicly available at 
http://www.cse.unt.edu/~rada/affecti
vetext.
2 Available at 
http://www.unige.ch/fapse/emotion/da
tabanks/isear.html
65
dataset used in our experiment is shown in Table 
1. In addition, sample sentences from the anno-
tated corpus appear in Table 2.
Dataset Sentences tagged with Sadness/Sad
SemEval Bangladesh ferry sink, 15 dead.
ISEAR When I left a man in whom I really 
believed.
Fairy 
tales
The flower could not, as on the pre-
vious evening, fold up its petals and 
sleep; it dropped sorrowfully.
Table 2: Sample sentences labeled with sadness/sad 
from the datasets
5 Experiments and Results
The goal of the affect classification is to predict a 
single emotional label given an input sentence. 
Four different approaches were implemented in 
Matlab. A categorical model based on a VSM 
with dimensionality reduction variants, (LSA, 
PLSA, and NMF), and a dimensional model, 
each with evaluated with two similarity measures 
(cosine angle and nearest neighbor). Stopwords 
were removed in all approaches. A Matlab tool-
kit (Zeimpekis and Gallopoulos 2005), was used 
to generate the term-by-sentence matrix from the 
text.
The evaluation in Table 3 shows Majority 
Class Baseline (MCB) as the baseline algorithm.
The MCB is the performance of a classifier that 
always predicts the majority class. In SemEval 
and Fairy tales the majority class is joy, while 
anger is the majority emotion in case of ISEAR.
The five approaches were evaluated on the data-
set of 479 news headlines (SemEval), 5,430 res-
ponses to questions (ISEAR), and 1,093 fairy 
tales? sentences. We define the following acro-
nyms to identify the approaches:
 CLSA: LSA-based categorical classification
 CPLSA: PLSA-based categorical classifica-
tion
 CNMF: NMF-based categorical classification
 DIM: Dimension-based estimation
The measure of accuracies used here were:
Cohen?s Kappa (Cohen 1960), average precision, 
recall, and F-measure. While the kappa scores 
are useful in obtaining an overview of the relia-
bility of the various classification approaches, 
they do not provide any insight on the accuracy 
at the category level for which precision, recall, 
and F-measure are necessary.
Data set SemEval ISEAR Fairy tales
Emotion Prec. Rec. F1 Prec. Rec. F1 Prec. Rec. F1
Anger MCB 0.000 0.000 - 0.399 1.000 0.571 0.000 0.000 -
CLSA 0.089 0.151 0.112 0.468 0.970 0.631 0.386 0.749 0.510
CPLSA 0.169 0.440 0.244 0.536 0.397 0.456 0.239 0.455 0.313
CNMF 0.294 0.263 0.278 0.410 0.987 0.579 0.773 0.560 0.650
DIM 0.161 0.192 0.175 0.708 0.179 0.286 0.604 0.290 0.392
Fear MCB 0.000 0.000 - 0.000 0.000 - 0.000 0.000 -
CLSA 0.434 0.622 0.511 0.633 0.038 0.071 0.710 0.583 0.640
CPLSA 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000
CNMF 0.525 0.750 0.618 0.689 0.029 0.056 0.704 0.784 0.741
DIM 0.404 0.404 0.404 0.531 0.263 0.351 0.444 0.179 0.255
Joy MCB 0.309 1.000 0.472 0.000 0.000 - 0.407 1.000 0.579
CLSA 0.455 0.359 0.402 0.333 0.061 0.103 0.847 0.637 0.727
CPLSA 0.250 0.258 0.254 0.307 0.381 0.340 0.555 0.358 0.436
CNMF 0.773 0.557 0.648 0.385 0.005 0.010 0.802 0.761 0.781
DIM 0.573 0.934 0.710 0.349 0.980 0.515 0.661 0.979 0.789
Sadness MCB 0.000 0.000 - 0.000 0.000 - 0.000 0.000 -
CLSA 0.472 0.262 0.337 0.500 0.059 0.106 0.704 0.589 0.642
CPLSA 0.337 0.431 0.378 0.198 0.491 0.282 0.333 0.414 0.370
CNMF 0.500 0.453 0.475 0.360 0.009 0.017 0.708 0.821 0.760
DIM 0.647 0.157 0.253 0.522 0.249 0.337 0.408 0.169 0.240
Table 3: Emotion identification results
66
5.1 Precision, Recall, and F-measure
Classification accuracy is usually measured in 
terms of precision, recall, and F-measure. Table 
3 shows these values obtained by five approach-
es for the automatic classification of four emo-
tions. The highest results for a given type of 
scoring and datasets are marked in bold for each 
individual class. We do not include the accuracy 
values in our results due to the imbalanced pro-
portions of categories (see Table 1). The accura-
cy metric does not provide adequate information, 
whereas precision, recall, and F-measure can ef-
fectively evaluate the classification performance 
with respect to imbalanced datasets (He and Gar-
cia 2009).
As can be seen from the table, the perfor-
mances of each approach hinge on each dataset 
and emotion category, respectively. In the case 
of the SemEval dataset, precision, recall and F-
measure for CNMF and DIM are comparable.
DIM approach gives the best result for joy,
which has a relatively large number of sentences. 
In ISEAR, DIM generally outperforms other ap-
proaches except for some cases, whereas CNMF 
has the best recall score after the baseline for the
anger category. Figure 1 indicates the results of 
3-dimensional and 2-dimensional attribute evalu-
ations for ISEAR. When it comes to fairy tales, 
CNMF generally performs better than the other 
techniques. Joy also has the largest number of 
data instances in fairy tales and the best recall 
ignoring the baseline and F-measure are obtained 
with the approach based on DIM for this affect 
category. CNMF gets the best emotion detection 
performance for anger, fear, and sadness in 
terms of the F-measure.
Figure 2 and Table 4 display results among 
different approaches obtained on the three differ-
ent datasets. We compute the classification per-
formance by macro-average, which gives equal 
weight to every category regardless of how many 
sentences are assigned to it.3
3 Macro-averaging scores are defined as:
This measurement 
prevents the results from being biased given the 
imbalanced data distribution. From this summa-
rized information, we can see that CPLSA per-
forms less effectively with several low perfor-
mance results across all datasets. CNMF is supe-
rior to other methods in SemEval and Fairy tales 
2m = 1K- L:K:=1 ,Mm =  1K- F:K:=1 ,>m = 1K- N:K:=1
where C is total number of categories, and pi, ri, and fi
stand for precision, recall, and F-measure, respective-
ly, for each category i.
datasets, while DIM surpasses the others in 
ISEAR. In particular, CPLSA outperforms 
CLSA and CNMF in ISEAR because their per-
formances are relatively poor. The result implies 
that statistical models which consider a proba-
bility distribution over the latent space do not 
always achieve sound performances. In addition,
we can infer that models (CNMF and DIM) with 
non-negative factors are appropriate for dealing 
with these text collections.
Another notable result is that the precision, re-
call, and F-measure are generally higher in fairy 
tales than in the other datasets. These sentences 
in the fairy tales tend to have more emotional 
terms and the length of sentences is longer. The 
nature of fairy tales makes unsupervised models 
yield better performance (see Table 2). In addi-
tion, affective high agreement sentence is anoth-
er plausible contributing reason for the encourag-
ing experimental results.
In summary, categorical NMF model and di-
mensional model show the better emotion identi-
fication performance as a whole.
5.2 Cohen?s Kappa
The kappa statistic measures the proportion of 
agreement between two raters with correction for 
chance. The kappa score is used as the metric to 
compare the performance of each approach. Fig-
ure 3 graphically depicts the mean kappa scores 
and its standard errors obtained from the emotion 
classification. Comparisons between four ap-
proaches are shown across all three datasets.
MCB is excluded in the comparison because the 
mean kappa score of MCB is 0.
Let MKCLSA, MKCPLSA, MKCNMF, and MKDIM be 
the mean kappa scores of four methods. The 
highest score (MKCNMF = 0.382) is achieved by 
the CNMF when the dataset is SemEval. In fairy 
tales, the CNMF method (MKCNMF = 0.652) also 
displays better result than the others (MKCLSA =
0.506, MKDIM = 0.304). On the contrary, the 
achieved results are significantly different in the 
case of the ISEAR dataset in comparison with 
the aforementioned datasets. The DIM (MKDIM =
0.210) clearly outperforms all methods. The kap-
pa score of the CPLSA approach (MKCPLSA =
0.099) is quantitatively and significantly higher 
than the CLSA (MKCLSA = 0.031) and CNMF 
(MKCNMF = 0.011). Kappa score for the NMF-
based methods is remarkably lower than the oth-
er three approaches. 
According to (Fleiss and Cohen 1973), a kap-
pa value higher than 0.4 means a fair to good 
level of agreement beyond chance alone and it is 
67
SemEval and Fairy tales datasets, while DIM 
surpasses the others in ISEAR dataset. Our 
PLSA conducted in all experiments is inferior to 
NMF, DIM as well as LSA. The result implies 
that statistical models which consider a proba-
bility distribution over the latent space do not 
always leads to sound performances. In addition,
we can infer that models (NMF and DIM) with 
non-negative factors are appropriate for dealing 
with text collections. Another interesting notice 
from overall results is that the precision, recall, 
and F-measure are higher in fairy tales than in 
two other datasets. The sentences in fairy tales 
have ampler emotional terms and the length of 
sentences is longer in comparison with those in 
other datasets. The nature of fairy tales makes 
unsupervised models yield better performance 
(see Table 2). In summary, categorical NMF 
model and dimensional model show the better 
emotion identification performance as a whole.
1.1 Cohen?s Kappa
The kappa score is used as the metric to evaluate 
the performance of each approach. Figure 4 
graphically depicts the mean kappa scores and its 
standard errors obtained from the emotion classi-
fication. Comparisons between four approaches
are shown and there are statistically significant 
differences in the kappa scores across all three 
datasets. MCB is excluded in the comparison 
because the mean kappa score of MCB is 0.
Let MKLSA, MKPLSA, MKNMF, and MKDIM be the 
mean kappa scores of four methods. The highest
score (MKNMF = 0.382) is achieved by the NMF
when the dataset is SemEval. In fairy tales, the 
NMF method (MKNMF = 0.652) also displays bet-
ter result than the others (MKLSA = 0.506, MKDIM
= 0.304). Note that the achieved results are
somewhat different in case of ISEAR dataset in 
comparison with the aforementioned experiment 
which used precision, recall, and F-measure. The 
DIM (MKDIM = 0.210) clearly outperforms all 
methods like section 5.1. On the contrary, the 
kappa score of the PLSA approach (MKPLSA =
0.099) is quantitatively and significantly higher 
than the LSA (MKLSA = 0.031) and NMF (MKNMF
= 0.011). Kappa score for the NMF-based me-
thods is remarkably lower than the other three
approaches. Nevertheless, we can observe that 
NMF-based categorical model and dimensional 
model got good grades on the whole.
1.2 Cohen?s Kappa
The most frequent words used in ISEAR dataset
for each emotion are shown in Table 4. NMF and 
Figure 1: Distribution of the ISEAR dataset in the 3-dimensional and 2-dimensional sentiment space. Th  
blue ?x? denotes the location of one sentence corresponding to valence, arousal, and d minance.
                        (a)                    (b)                   (c)
Figure 2: Comparisons of Precision, Recall, and F-measure: (a) SemEval; (b) ISEAR; (c) Fairy tales.
Data set SemEval ISEAR Fairy tales
Prec. Rec. F1 Prec. Rec. F1 Prec. Rec. F1
MCB 0.077 0.250 0.118 0.100 0.250 0.143 0.102 0.250 0.145
CLSA 0.363 0.348 0.340 0.484 0.282 0.228 0.662 0.640 0.630
CPLSA 0.189 0.282 0.219 0.260 0.317 0.270 0.282 0.307 0.280
CNMF 0.523 0.506 0.505 0.461 0.258 0.166 0.747 0.731 0.733
DIM 0.446 0.422 0.386 0.528 0.417 0.372 0.530 0.404 0.419
Table 4: Overall average results
(a) (b) (c)
Figure 3: Comparisons of Mean Kappa: (a) SemEval; (b) ISEAR; (c) Fairy tales.
68
an acceptable level of agreement. On the basis of 
this definition, the kappa score obtained by our 
best classifier (MKCNMF = 0.652) would be rea-
sonable. Most of the values are too low to say 
that two raters (human judges and computer ap-
proaches) agreed upon the affective states. How-
ever, we have another reason with respect to this 
metric in the experiment. We make use of the 
kappa score as an unbiased metric of the relia-
bility for comparing four methods. In other 
words, these measures are of importance in terms 
of the relative magnitude. Hence, the kappa re-
sults are meaningful and interpretable in spite of 
low values. We can observe that the NMF-based 
categorical model and the dimensional model 
both experienced higher performance.
5.3 Frequently occurring words
The most frequent words used in fairy tales for 
each emotion are listed in Table 5. We choose
this dataset since there are varying lexical items
and affective high agreement sentences, as men-
tioned in Section 5.1. Stemming is not used be-
cause it might hide important differences as be-
tween ?loving? and ?loved?. CNMF and DIM 
were selected for the comparison with the Gold 
Standard because they were the two methods
with the better performance than the others. Gold 
Standard is the annotated dataset by human raters 
for the evaluation of algorithm performance. The 
words most frequently used to describe anger 
across all methods include: cried, great, tears,
king, thought, and eyes. Those used to describe 
fear include: heart, cried, mother, thought, man,
and good. Joy contains happy, good, and cried
whereas sadness has only cried for three methods.
There is something unexpected for the word 
frequencies. We can observe that the association 
between frequently used words and emotion cat-
egories is unusual and even opposite. For in-
stance, a ?joy? is one of the most frequent words 
referred to for sadness in the Gold Standard. In 
CNMF and DIM, a ?good? is employed frequent-
ly with regard to fear. Moreover, some words
occur with the same frequency in more catego-
ries. For example, the word ?cried? is utilized to 
express anger, fear, and joy in the Gold Standard,
CNMF, and DIM. In order to find a possible ex-
planation in the complexity of language used in 
the emotional expression, some sentences ex-
tracted from fairy tales are listed below:
?The cook was frightened when he heard the or-
der, and said to Cat-skin, You must have let a 
hair fall into the soup; if it be so, you will have a 
good beating.? ? which expresses fear
?When therefore she came to the castle gate she 
saw him, and cried aloud for joy.? ? which is the 
expression for joy
?Gretel was not idle; she ran screaming to her 
master, and cried: You have invited a fine guest!?
? which is the expression for angry-disgusted
From these examples, we can observe that in 
these cases the affective meaning is not simply 
propagated form the lexicon, but is the effect of 
the linguistic structure at a higher level. 
6 Conclusion
We compared the performances of three tech-
niques, based on the categorical representation of 
emotions, and one based on the dimensional rep-
resentation. This paper has highlighted that the 
NMF-based categorical classification performs
Model Emotion Top 10 words
Gold Standard Anger king, thought, eyes, great, cried, looked, joy, mother, wife, tears
Fear great, cried, good, happy, thought, man, heart, poor, child, mother
Joy thought, mother, good, cried, man, day, wept, beautiful, back, happy
Sadness cried, fell, father, mother, back, joy, dead, danced, wife, tears
CNMF Anger great, cried, eyes, mother, poor, joy, king, heart, thought, tears
Fear cried, king, happy, good, man, heart, thought, father, boy, mother
Joy mother, thought, cried, king, day, great, home, joy, good, child
Sadness thought, cried, good, great, looked, mother, man, time, king, heart
DIM Anger eyes, fell, heart, tears, cried, good, stood, great, king, thought
Fear king, cried, heart, mother, good, thought, looked, man, child, time
Joy eyes, man, children, danced, cried, good, time, happy, great, wedding
Sadness cried, thought, great, king, good, happy, sat, home, joy, found
Table 5: Most frequent 10 words from fairy tales
69
the best among categorical approaches to classi-
fication. When comparing categorical against 
dimensional classification, the categorical NMF 
model and the dimensional model have better 
performances. Nevertheless, we cannot general-
ize inferences on which of these techniques is the 
best performer because results vary among data-
sets. As a future work, we aim at performing a
further investigation on this connection in order 
to identify more effective strategies applicable to 
a generic dataset. Furthermore, we aim at explor-
ing improvements in the methodology, employed 
in this work, and based on the combination of 
emotional modeling and empirical methods.
Acknowledgments
This research is partially sponsored by a Norman 
I. Price Scholarship from the University of Syd-
ney.
References
C. O. Alm (2009). Affect in Text and Speech, VDM 
Verlag Dr. M?ller.
S. Aman and S. Szpakowicz (2007). Identifying ex-
pressions of emotion in text. Text, Speech and Di-
alogue.
M. M. Bradley and P. J. Lang (1999). Affective
norms for English words (ANEW): Instruction 
manual and affective ratings. University of Flori-
da: The Center for Research in Psychophysiology.
J. Cohen (1960). A coefficient of agreement for no-
minal scales. Educational and psychological mea-
surement 20(1): 37-46.
S. D'Mello, A. Graesser, and R. W. Picard (2007). 
Toward an affect-sensitive AutoTutor. IEEE Intel-
ligent Systems 22(4): 53-61.
S. D?Mello, S. Craig, A. Witherspoon, B. Mcdaniel, 
and A. Graesser (2008). Automatic detection of 
learner?s affect from conversational cues. User 
Modeling and User-Adapted Interaction 18(1): 45-
80.
P. Ekman (1992). An argument for basic emotions. 
Cognition & Emotion 6(3): 169-200.
J. L. Fleiss and J. Cohen (1973). The equivalence of 
weighted kappa and the intraclass correlation. 
Educational and psychological measurement 33: 
613-619.
H. He and E. A. Garcia (2009). Learning from Imba-
lanced Data. IEEE Transactions on Knowledge 
and Data Engineering 21(9): 1263.
T. Hofmann (2001). Unsupervised learning by proba-
bilistic latent semantic analysis. Machine Learning 
42(1): 177-196.
B. Kort, R. Reilly, and R. W. Picard (2001). An affec-
tive model of interplay between emotions and 
learning: Reengineering educational pedagogy-
building a learning companion. IEEE International 
Conference on Advanced Learning Technologies, 
2001. Proceedings.
T. K. Landauer, P. W. Foltz, and D. Laham (1998). 
An introduction to latent semantic analysis. Dis-
course processes, Citeseer. 25: 259-284.
P. J. Lang (1980). Behavioral treatment and bio-
behavioral assessment: Computer applications. 
Technology in mental health care delivery sys-
tems: 119-137.
D. D. Lee and H. S. Seung (1999). Learning the parts 
of objects by non-negative matrix factorization. 
Nature 401(6755): 788-791.
P. Penumatsa, M. Ventura, A.C. Graesser, M. Lou-
werse, X. Hu, Z. Cai, and D.R. Franceschetti
(2006). The Right Threshold Value: What Is the 
Right Threshold of Cosine Measure When Using 
Latent Semantic Analysis for Evaluating Student 
Answers? International Journal on Artificial Intel-
ligence Tools, World Scientific Publishing.
J. A. Russell (2003). Core affect and the psychologi-
cal construction of emotion. Psychological review 
110(1): 145-172.
K. R. Scherer and H. G. Wallbott (1994). Evidence 
for universality and cultural variation of differen-
tial emotion response patterning. Journal of Perso-
nality and Social Psychology 66: 310-328.
C. Strapparava and R. Mihalcea (2007). Semeval-
2007 task 14: Affective text. Proceedings of the 
4th International Workshop on Semantic Evalua-
tions, Association for Computational Linguistics.
C. Strapparava and R. Mihalcea (2008). Learning to 
identify emotions in text. SAC '08: Proceedings of 
the 2008 ACM symposium on Applied computing, 
Fortaleza, Ceara, Brazil, ACM.
C. Strapparava and A. Valitutti (2004). WordNet-
Affect: an affective extension of WordNet. Pro-
ceedings of LREC.
R. B. Yates and B. R. Neto (1999). Modern informa-
tion retrieval. ACM P.
Zeimpekis D. and E. Gallopoulos (2005). TMG: A 
MATLAB toolbox for generating term-document 
matrices from text collections. Grouping multidi-
mensional data: Recent advances in clustering: 
187-210.
70
