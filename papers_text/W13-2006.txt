Proceedings of the BioNLP Shared Task 2013 Workshop, pages 45?49,
Sofia, Bulgaria, August 9 2013. c?2013 Association for Computational Linguistics
Biomedical Event Extraction
by Multi-class Classification of Pairs of Text Entities
Xiao Liu Antoine Bordes Yves Grandvalet
Universit? de Technologie de Compi?gne & CNRS
Heudiasyc UMR 7253, Rue Roger Couttolenc, CS 60319
60203 Compi?gne Cedex, FRANCE
firstname.lastname@hds.utc.fr
Abstract
This paper describes the HDS4NLP en-
try to the BioNLP 2013 shared task on
biomedical event extraction. This system
is based on a pairwise model that trans-
forms trigger classification in a simple
multi-class problem in place of the usual
multi-label problem. This model facili-
tates inference compared to global models
while relying on richer information com-
pared to usual pipeline approaches. The
HDS4NLP system ranked 6th on the Ge-
nia task (43.03% f-score), and after fix-
ing a bug discovered after the final submis-
sion, it outperforms the winner of this task
(with a f-score of 51.15%).
1 Introduction
Huge amounts of electronic biomedical docu-
ments, such as molecular biology reports or ge-
nomic papers are generated daily. Automatically
organizing their content in dedicated databases en-
ables advanced search and ease information re-
trieval for practitioners and researchers in biology,
medicine or other related fields. Nowadays, these
data sources are mostly in the form of unstruc-
tured free text, which is complex to incorporate
into databases. Hence, many research events are
organized around the issue of automatically ex-
tracting information from biomedical text. Efforts
dedicated to biomedical text are necessary because
standard Natural Language Processing tools can-
not be readily applied to extract biomedical events
since they involve highly domain-specific jargon
and dependencies (Kim et al, 2011).
This paper describes the HDS4NLP entry to one
of these challenges, the Genia task (GE) of the
BioNLP 2013 shared task. The HDS4NLP sys-
tem is based on a novel model designed to directly
extract events having a pairwise structure (trigger,
Figure 1: Part of a sentence and corresponding events for the
BioNLP 2013 GE task.
argument), in contrast to standard pipeline models
which first extract the trigger and then search for
the argument. Combining these two steps enables
to use more sophisticated event features while
largely avoiding error propagation. The model us-
age is also simple, in the sense that it does not rely
on any complex and costly inference process as
required by joint global systems based on Integer
Linear Programming.
The official HDS4NLP entry was only ranked
6th on the GE task (with 43.03% f-score). How-
ever, after fixing a bug discovered after the final
submission, the HDS4NLP system outperformed
the winner of the GE task, with a f-score 51.15%
to be compared to the 50.97% of EVEX.
2 BioNLP Genia Task
BioNLP Genia task aims at extracting event for-
mulas from text sentences, which are defined as
sequences of tokens (words, numbers, or sym-
bols). Events are constituted of two elements: an
event trigger and one or several arguments. The
event trigger is a sequence of tokens that indicates
an event is mentioned in the text. The arguments
of an event are participants, which can be pro-
teins, genes or other biomedical events. Figure 1
illustrates the GE task: given 3 proteins ?Tax?,
?CBP? and ?p300?, one must detect ?recruit? as
an event trigger and then extract two formulas:
( ?recruit?, Theme:?Tax?, Theme2:?CBP?) and
(?recruit?, Theme:?Tax?, Theme2:?p300?), both
with event type Binding.
In our work, we process tokens differently de-
pending on whether they are marked as proteins in
the annotation or not; the latter are termed candi-
date tokens. A key part of the task is to detect the
45
trigger tokens among the candidates. The BioNLP
2013 GE task considers 13 types of events, but we
only dealt with the 9 types already existing in the
2011 GE task, because there was not enough data
on the newly defined event types for proper train-
ing or model selection.
Table 1 lists these events and their properties.
The 9 event types may be merged into three main
groups: the first 5 have a single argument, a
Theme; the Binding event can accept up to two
arguments (2 Themes); the last 3 types also ac-
cept up to two arguments, a Theme and an optional
Cause. In the following, we refer to the first 6
types as non-regulation events and to the remain-
ing 3 as regulation ones.
Event type Principal arg Optional arg
Gene_expression Theme (P)
Transcription Theme (P)
Protein_catabolism Theme (P)
Phosphorylation Theme (P)
Localization Theme (P)
Binding Theme (P) Theme2 (P)
Regulation Theme (E/P) Cause (E/P)
Positive_regulation Theme (E/P) Cause (E/P)
Negative_regulation Theme (E/P) Cause (E/P)
Table 1: Main types of events with their arguments (P stands
for Protein, E for Event).
3 Previous Work
The preceding approaches falls into two main cat-
egories: pipeline incremental models and joint
global methods.
Pipeline approaches (S?tre et al, 2009; Co-
hen et al, 2009; Bj?rne et al, 2009) are the sim-
plest way to tackle the problem of event extrac-
tion. A sequence of classifiers are ran on the text to
successively (1) detect non-regulation event trig-
gers, (2) assign them arguments, (3) detect regula-
tion event triggers and (4) assign them arguments.
Such systems are relatively easy to set up but suf-
fer from error cascading. Besides, they detect trig-
gers using classifiers solely taking tokens as in-
put, or involve dependency parse information by
tree depth other than a concrete potential argument
(Bj?rne et al, 2009).
In the corpuses used in 2009 and 2011 for the
GE task, some tokens belong to several events of
different types; their classification thus requires to
solve a multi-label problem. We believe that de-
tecting triggers in isolation breaks the structured
problem down to excessively fine-grained sub-
tasks, with contextual information loss that leads
to ill-posed problems.
Global approaches (Riedel et al, 2009; Mc-
Closky et al, 2011) aim at solving the whole task
at once, so as to resolve the drawbacks of pipeline
models. In (McClosky et al, 2011), event an-
notations are converted into pseudo-syntactic rep-
resentations and the task is solved as a syntactic
extraction problem by traditional parsing meth-
ods. (Riedel et al, 2009; Riedel and McCallum,
2011a; Riedel et al, 2011; Riedel and McCallum,
2011b) encode the event annotations as latent bi-
nary variables indicating the type of each token
and the relation between each pair of them (pro-
tein or candidate) in a sentence. The state of these
variables is predicted by maximizing the global
likelihood of an Integer Linear Program.This joint
model achieves good performance (winner of the
2011 GE task), but might be overly complicated,
as it considers all possible combinations of tokens,
even unlikely ones, as potential events together.
4 Pairwise Model
Our new pairwise approach operates at the sen-
tence level. We denote CS = {ei}i the set of can-
didate tokens, AS = {aj}j the set of candidate
arguments in a given sentence S, and the set of
event types (augmented by None) is denoted Y .
The first step of a pipeline model assigns labels
to candidate tokens ei ? CS . Instead, our pair-
wise model addresses the problem of classifying
candidate-argument pairs (ei, aj) ? CS?AS . De-
noting fk the binary classifier predicting the event
type k ? Y , event extraction is performed by:
?(ei, aj) ? CS ?AS , y?ij = argmax
k?Y
fk(ei, aj) .
Variable y?ij encodes the event type of the pair
made of the candidate token ei and the argument
aj , an event being actually extracted when y?ij 6=
None. For the fk classifiers, we use Support Vec-
tor Machines (SVMs) (using implementation from
scikit-learn.org) in a one-vs-rest setting.
We used procedures from (Duan et al, 2003; Platt,
1999; Tax and Duin, 2002) to combine the outputs
of these binary classifiers in order to predict a sin-
gle class from Y for each pair (ei, aj).
This simple formulation is powerful because
classifying a pair (ei, aj) as not-None jointly de-
tects the event trigger ei and its argument aj . For
all event types with a single argument, predicting
y? variables directly solves the task. Working on
pairs (ei, aj) also allows to take into account in-
teractions, in particular through dedicated features
46
describing the connection between the trigger and
its argument (see Section 6). Finally, classifying
pairs (ei, aj) is conceptually simpler than classi-
fying ei: the task is a standard classification prob-
lem instead of a multi-label problem. Note that
entity ei may still be assigned to several categories
through the allocation of different labels to pairs
(ei, aj) and (ei, ak).
Though being rather minimalist, the pairwise
structure captures a great deal of trigger-argument
interactions, and the simplicity of the structure
leads to a straightforward inference procedure.
Compared to pipeline models, the main drawback
of the pairwise model is to multiply the number of
examples to classify by a card(AS) factor. How-
ever, SVMs can scale to large numbers of exam-
ples and card(AS) is usually low (less than 10).
5 Application to BioNLP Genia Task
For any given sentence, our system sequentially
solves a set of 4 pairwise relation extraction prob-
lems in the following order:
1. Trigger-Theme pair extraction (T-T),
2. Binding-Theme fusion (B-T),
3. Regulation-Theme pair extraction (R-T),
4. Regulation-Cause assignment (R-C).
Steps T-T and R-T are the main event extrac-
tion steps because they detect the triggers and one
argument. Since some events can accept multi-
ple arguments, we supplement T-T and R-T with
steps B-T and R-C, designed to potentially add ar-
guments to events. All steps are detailed below.
Steps T-T & R-T Both steps rely on our pair-
wise model to jointly extract event triggers, deter-
mine their types and corresponding themes. How-
ever, they detect different triggers with different
potential argument sets: for step T-T, AS con-
tains only proteins and Y = {Gene_expression,
Transcription, Protein_catabolism, Phosphoryla-
tion, Localization, Binding, None}. For step R-
T, AS contains proteins and all predicted trig-
gers, Y = {Regulation, Positive_regulation, Neg-
ative_regulation, None}.
Steps B-T & R-C These steps attempt to assign
optional arguments to Binding or regulation events
detected by T-T or R-T respectively. They proceed
similarly. Given an extracted event (ei, aj) and a
candidate argument set AS = {ak}, all combina-
tions {(ei, aj , ak)|k 6= j} are classified by a bi-
nary SVM. For B-T, AS contains all the proteins
Type Features
Surface features Stem
String after ?-?
String while pruning ?-? and/or ?/?
Prefix of token
Semantic features Lemma from WordNet
Part-of-speech (POS) tag
Token annotated as protein
Table 2: Word features.
of the sentence S that were extracted as argument
of a Binding event by T-T. For R-C, AS contains
all proteins and triggers detected by T-T. In both
cases, a post-processing step is used to select the
longest combination.
6 Features
We present here our features and preprocessing.
Candidate set For each sentence S, the set CS
is built using a trigger gazetteer: candidates are
recursively added by searching first the longest to-
kens sequences from the gazetteer. For candidates
with several tokens, a head token is selected using
an heuristic based on the dependency parse.
Candidate tokens Three types of features are
used, either related to the head token, a word win-
dow around it, or its parent and child nodes in the
dependency tree. Table 2 lists word features.
Proteins The protein name is a useless feature,
so the word features of the head token were re-
moved for proteins. Word features of the neigh-
boring tokens and of the parent node in the de-
pendency tree were still included. Proteins are
also described using features extracted from the
Uniprot knowledge base (uniprot.org).
Pairwise relations Our pairwise method is apt
to make use of features that code interactions be-
tween candidate triggers and arguments. These
patterns are defined from the path linking two to-
kens in the dependency parse tree of the sentence.
Special care was taken to perform tokenization
and sentence splitting because this has an impor-
tant impact on the quality of the dependency parse
trees. Data was split in sentences using both the
nltk toolkit (nltk.org) and the support anal-
ysis provided for the BioNLP 2013 GE task. To-
kenization was carried out using a slightly mod-
ified version of the tokenizer from the Stanford
event parser (McClosky et al, 2011). The de-
pendency parse trees were finally obtained using
phrase structure parser (McClosky et al, 2010)
47
combined with post-processing using the Stanford
corenlp package (De Marneffe et al, 2006).
Incorporating dependency information into the
pairwise model relies on the process encoding the
path into feature vectors. Many formatting meth-
ods have been proposed in previous works, such
as E-walks, that format the path into triplets (dep,
word, dep), V-walks that use triplets (word, dep,
word) or simply N-grams of words, following the
dependency parse: words are usually encoded via
stem and POS tags, and dep by the dependency
labels (Miwa et al, 2010). All these imperfect
representations lose a lot of information and can
even add noise, especially when the path is long.
Hence dependency parse features are processed
only for pairs for which the candidate-argument
path length is below a threshold whose value is a
hyper-parameter.
7 Experimental Results
The hyper-parameters of our system have been op-
timized on the BioNLP 2013 GE task development
set, after training on the corresponding training
set. Using these hyper-parameter values, the fi-
nal model submitted for test evaluation on the GE
task server has been trained on all documents from
training and development sets of BioNLP 2011
and 2013 GE tasks.
Table 3 lists the test results of our official sub-
mission. Our system achieved the best score for
SIMPLE ALL and second best for PROT-MOD
ALL, but it suffered from a rather poor perfor-
mance on REGULATION ALL, causing a low
overall score relegating the submission to the 6th
place in the competition.
Event Class recall prec. f-score
SIMPLE ALL 75.27 83.27 79.07
Binding 41.74 33.74 37.32
PROT-MOD ALL 70.68 75.84 73.17
REGULATION ALL 16.67 30.86 21.64
EVENT ALL 37.11 51.19 43.03
Table 3: Official test evaluation results.
After the test results were disclosed, we sus-
pected that our poor results on REGULATION
ALL were due to a bug, which was eventually dis-
covered in the post-processing step of R-C. We
re-trained our system after having fixed the bug
on the latest revision of the training set (our of-
ficial entry used revision 2 of the training set in-
stead of revision 3, which resulted in slightly dif-
ferent annotations for Binding events). This led
Event Class recall prec. f-score
Binding 43.24 34.37 38.30
REGULATION ALL 31.43 47.70 37.89
EVENT ALL 45.96 57.66 51.15
Table 4: Test evaluation results after bug fix.
to the results displayed in Table 4 (we only show
results that differ from Table 3). Our system ac-
tually achieves a EVENT ALL f-score of 51.15%,
instead of 43.03%: this rating is higher than the
best score of the BioNLP 2013 GE task (50.97%).
To compare to previous models, we also trained
our system on BioNLP2011 GE task training set
and evaluated it on development set. Our ap-
proach reaches a EVENT ALL f-score of 51.28%,
which is lower than that of this challenge?s winner,
the FAUST system (Riedel et al, 2011) (55.9%).
However, FAUST is a combination of several dif-
ferent models, compared to the UMass model
(Riedel and McCallum, 2011a), which is the main
constituent of FAUST, we achieve a higher EVT
score (74.93% vs 74.7%) but a lower overall score
(51.28% vs 54.8%). Our system is outperformed
on Binding and Regulation events; this indicates
the directions in which it should be improved.
8 Conclusion
This paper introduced a pairwise model designed
for biomedical event extraction, which, after bug
fix, outperforms the best performance of the
BioNLP 2013 GE task. This system decomposes
the overall task into the multi-class problem of
classifying (trigger, argument) pairs. Relying of
this pairwise structure for input examples allows
to use joint (trigger, argument) features, to avoid
costly global inference procedures over sentences
and to solve a simple multi-class problem instead
of a multi-label multi-class one.
Still, some issues remain. We currently cannot
extract regulation events whose arguments are an-
other regulation event. We are also subject to some
cascading error between steps T-T and R-T. In fu-
ture works, we intend to improve our system by
turning it into a dynamic online process that will
perform recursive event extraction.
Acknowledgments
This work was carried out in the framework of
the Labex MS2T (ANR-11-IDEX-0004-02), and
funded by the French National Agency for Re-
search (EVEREST-12-JS02-005-01).
48
References
Jari Bj?rne, Juho Heimonen, Filip Ginter, Antti Airola,
Tapio Pahikkala, and Tapio Salakoski. 2009. Ex-
tracting complex biological events with rich graph-
based feature sets. In Proceedings of the BioNLP
2009 Workshop Companion Volume for Shared Task,
pages 10?18, Boulder, Colorado, June. Association
for Computational Linguistics.
K. Bretonnel Cohen, Karin Verspoor, Helen John-
son, Chris Roeder, Philip Ogren, William Baumgart-
ner, Elizabeth White, and Lawrence Hunter. 2009.
High-precision biological event extraction with a
concept recognizer. In Proceedings of the BioNLP
2009 Workshop Companion Volume for Shared Task,
pages 50?58, Boulder, Colorado, June. Association
for Computational Linguistics.
Marie-Catherine De Marneffe, Bill MacCartney, and
Christopher D. Manning. 2006. Generating typed
dependency parses from phrase structure parses. In
Proceedings of LREC, volume 6, pages 449?454.
Kaibo Duan, S. Sathiya Keerthi, Wei Chu, Shirish Kr-
ishnaj Shevade, and Aun Neow Poo. 2003. Multi-
category classification by soft-max combination of
binary classifiers. In In 4th International Workshop
on Multiple Classifier Systems.
Jin-Dong Kim, Sampo Pyysalo, Tomoko Ohta, Robert
Bossy, Ngan Nguyen, and Jun?ichi Tsujii. 2011.
Overview of BioNLP shared task 2011. In Proceed-
ings of BioNLP Shared Task 2011 Workshop, pages
1?6, Portland, Oregon, USA, June. Association for
Computational Linguistics.
David McClosky, Eugene Charniak, and Mark John-
son. 2010. Automatic domain adaptation for pars-
ing. In Human Language Technologies: The 2010
Annual Conference of the North American Chap-
ter of the Association for Computational Linguistics,
HLT ?10, pages 28?36, Stroudsburg, PA, USA. As-
sociation for Computational Linguistics.
David McClosky, Mihai Surdeanu, and Christopher D.
Manning. 2011. Event extraction as dependency
parsing. In Proceedings of the 49th Annual Meet-
ing of the Association for Computational Linguis-
tics: Human Language Technologies - Volume 1,
HLT ?11, pages 1626?1635, Stroudsburg, PA, USA.
Association for Computational Linguistics.
Makoto Miwa, Rune S?tre, Jin-Dong Kim, and
Jun?ichi Tsujii. 2010. Event extraction with
complex event classification using rich features.
J. Bioinformatics and Computational Biology,
8(1):131?146.
John C. Platt. 1999. Probabilistic outputs for sup-
port vector machines and comparisons to regularized
likelihood methods. In Advances in Large Margin
Classifiers, pages 61?74. MIT Press.
Sebastian Riedel and Andrew McCallum. 2011a. Fast
and robust joint models for biomedical event extrac-
tion. In Proceedings of the 2011 Conference on Em-
pirical Methods in Natural Language Processing,
pages 1?12, Edinburgh, Scotland, UK., July. Asso-
ciation for Computational Linguistics.
Sebastian Riedel and Andrew McCallum. 2011b. Ro-
bust biomedical event extraction with dual decom-
position and minimal domain adaptation. In Pro-
ceedings of BioNLP Shared Task 2011 Workshop,
pages 46?50, Portland, Oregon, USA, June. Asso-
ciation for Computational Linguistics.
Sebastian Riedel, Hong-Woo Chun, Toshihisa Takagi,
and Jun?ichi Tsujii. 2009. A Markov logic approach
to bio-molecular event extraction. In Proceedings of
the BioNLP 2009 Workshop Companion Volume for
Shared Task, pages 41?49, Boulder, Colorado, June.
Association for Computational Linguistics.
Sebastian Riedel, David McClosky, Mihai Surdeanu,
Andrew McCallum, and Christopher D. Manning.
2011. Model combination for event extraction in
BioNLP 2011. In Proceedings of BioNLP Shared
Task 2011 Workshop, pages 51?55, Portland, Ore-
gon, USA, June. Association for Computational Lin-
guistics.
Rune S?tre, Makoto Miwa, Kazuhiro Yoshida, and
Jun?ichi Tsujii. 2009. From protein-protein interac-
tion to molecular event extraction. In Proceedings
of the BioNLP 2009 Workshop Companion Volume
for Shared Task, pages 103?106, Boulder, Colorado,
June. Association for Computational Linguistics.
D. M. J. Tax and R. P. W. Duin. 2002. Using two-class
classifiers for multiclass classification. In Proceed-
ings of the 16th International Conference on Pattern
Recognition, volume 2, pages 124?127 vol.2.
49
