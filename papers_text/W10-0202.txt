Proceedings of the NAACL HLT 2010 Workshop on Computational Approaches to Analysis and Generation of Emotion in Text, pages 10?16,
Los Angeles, California, June 2010. c?2010 Association for Computational Linguistics
Emotion Detection in Email Customer Care
Narendra Gupta, Mazin Gilbert, and Giuseppe Di Fabbrizio
AT&T Labs - Research, Inc.
Florham Park, NJ 07932 - USA
{ngupta,mazin,pino}@research.att.com
Abstract
Prompt and knowledgeable responses to cus-
tomers? emails are critical in maximizing cus-
tomer satisfaction. Such emails often con-
tain complaints about unfair treatment due to
negligence, incompetence, rigid protocols, un-
friendly systems, and unresponsive personnel.
In this paper, we refer to these emails as emo-
tional emails. They provide valuable feedback
to improve contact center processes and cus-
tomer care, as well as, to enhance customer re-
tention. This paper describes a method for ex-
tracting salient features and identifying emo-
tional emails in customer care. Salient fea-
tures reflect customer frustration, dissatisfac-
tion with the business, and threats to either
leave, take legal action and/or report to au-
thorities. Compared to a baseline system us-
ing word ngrams, our proposed approach with
salient features resulted in a 20% absolute F-
measure improvement.
1 Introduction
Emails are becoming the preferred communication
channel for customer service. For customers, it is a
way to avoid long hold times on call centers phone
calls and to keep a record of the information ex-
changes with the business. For businesses, it of-
fers an opportunity to best utilize customer service
representatives by evenly distributing the work load
over time, and for representatives, it allows time to
research the issue and respond to the customers in
a manner consistent with business policies. Busi-
nesses can further exploit the offline nature of this
channel by automatically routing the emails involv-
ing critical issues to specialized representatives. Be-
sides concerns related to products and services, busi-
nesses ensure that emails complaining about unfair
treatment due to negligence, incompetence, rigid
protocols and unfriendly systems, are always han-
dled with care. Such emails, referred to as emotional
emails, are critical to reduce the churn i.e., retain-
ing customers who otherwise would have taken their
business elsewhere, and, at the same time, they are a
valuable source of information for improving busi-
ness processes.
In recurring service oriented businesses, a large
number of customer emails may contain routine
complaints. While such complaints are important
and are addressed by customer service represen-
tatives, our purpose here is to identify emotional
emails where severity of the complaints and cus-
tomer dissatisfaction are relatively high. Emotional
emails may contain abusive and probably emotion-
ally charged language, but we are mainly interested
in identifying messages where, in addition to the
flames, the customer includes a concrete descrip-
tion of the problem experienced with the company
providing the service. In the context of customer
service, customers express their concerns in many
ways. Sometimes they convey a negative emotional
component articulated by phrases like disgusted
and you suck. In other cases, there is a minimum
emotional involvement by enumerating factual sen-
tences such as you overcharged, or take my
business elsewhere. In many cases, both
the emotional and factual components are actually
present. In this work, we have identified eight dif-
10
ferent ways that customers use to express their emo-
tions in emails. Throughout this paper, these ways
will be referred to as Salient Features. We cast the
identification of emotional email as a text classifi-
cation problem, and show that using salient features
we can significantly improve the identification ac-
curacy. Compared to a baseline system which uses
Boosting (Schapire, 1999) withnword n-grams fea-
tures, our proposed system using salient features re-
sulted in improvement in f-measure from 0.52 to
0.72.
In section 2, we provide a summary of previous
work and its relationship with our contribution. In
section 3, we describe our method for emotion de-
tection and extraction of salient features. A series of
experiments demonstrating improvement in classifi-
cation performance is presented in section 4. We
conclude the paper by highlighting the main contri-
bution of this work in section 5.
2 Previous Work
Extensive work has been done on emotion detec-
tion. In the context of human-computer dialogs, al-
though richer features including acoustic and intona-
tion are available, there is a general consensus (Lit-
man and Forbes-Riley, 2004b; Lee and Narayanan,
2005) about the use of lexical features to signifi-
cantly improve the accuracy of emotion detection.
Research has also been done in predicting ba-
sic emotions (also referred to as affects) within text
(Alm et al, 2005; Liu et al, 2003). To render speech
with prosodic contour conveying the emotional con-
tent of the text, one of 6 types of human emotions
(e.g., angry, disgusted, fearful, happy, sad, and sur-
prised) are identified for each sentence in the run-
ning text. Deducing such emotions from lexical con-
structs is a hard problem evidenced by little agree-
ment among humans. A Kappa value of 0.24-0.51
was shown in Alm et al (2005). Liu et al (2003)
have argued that the absence of affect laden surface
features i.e., key words, from the text does not imply
absence of emotions, therefore they have relied more
on common-sense knowledge. Instead of deducing
types emotions in each sentence, we are interested
in knowing if the entire email is emotional or not.
Additionally we are also interested in the intensity
and the cause of those emotions.
There is also a body of work in areas of creating
Semantic Orientation (SO) dictionaries (Hatzivas-
siloglou and McKeown, 1997; Turney and Littman,
2003; Esuli and Sebastiani, 2005) and their use in
identifying emotions laden sentences and polarity
(Yu and Hatzivassiloglou, 2003; Kim and Hovy,
2004; Hu and Liu, 2004) of those emotions. While
such dictionaries provide a useful starting point,
their use alone does not yield satisfactory results. In
Wilson et al (2005), classification of phrases con-
taining positive, negative or neutral emotions is dis-
cussed. For this problem they show high agreement
among human annotators (Kappa of 0.84). They
also show that labeling phrases as positive, negative
or neutral only on the basis of presence of key word
from such dictionaries yields a classification accu-
racy of 48%. An obvious reason for this poor per-
formance is that semantic orientations of words are
context dependent.
Works reported in Wilson et al (2005); Pang et al
(2002) and Dave et al (2003) have attempted to
mitigate this problem by using supervised meth-
ods. They report classification results using a num-
ber of different sets of features, including unigram
word features. Wilson et al (2005) reports an im-
provement (63% to 65.7% accuracy) in performance
by using a host of features extracted from syntac-
tic dependencies. Similarly, Gamon (2004) shows
that the use of deep semantic features along with
word unigrams improve performances. Pang et al
(2002) and Dave et al (2003) on the other hand
confirmed that word unigrams provide the best clas-
sification results. This is in line with our experi-
ence as well and could be due to sparseness of the
data. We also used supervised methods to predict
emotional emails. To train predictive models we
used word ngrams (uni-, bi- and tri-grams) and a
number of binary features indicating the presence of
words/phrases from specific dictionaries.
Spertus (1997) discusses a system called Smoky
which recognizes hostile messages and is quite sim-
ilar to our work. While Smoky is interested in iden-
tifying messages that contain flames, our research
on emotional emails looks deeper to discover the
reasons for such flames. Besides word unigrams,
Smoky uses rules to derive additional features for
classification. These features are intended to cap-
ture different manifestations of the flames. Simi-
11
larly, in our work we also use rules (in our case im-
plemented as table look-up) to derive additional fea-
tures of emotional emails.
3 Emotion detection in emails
We use supervised machine learning techniques to
detect emotional emails. In particular, our emotion
detector is a statistical classifier model trained using
hand labeled training examples. For each example,
a set of salient features is extracted. The major com-
ponents of our system are described below.
3.1 Classifier
For detecting emotional emails we used Boostex-
ter as text classification. Our choice of machine
learning algorithm was not strategic and we have no
reason to believe that SVMs or maximum entropy?
based classifiers will not perform equally well.
Boostexter, which is based on the boosting family of
algorithms, was first proposed by Schapire (1999). It
has been applied successfully to numerous text clas-
sification applications (Gupta et al, 2005) at AT&T.
Boosting builds a highly accurate classifier by com-
bining many ?weak? base classifiers, each one of
which may only be moderately accurate. Boost-
ing constructs the collection of base classifiers iter-
atively. On each iteration t, the boosting algorithm
supplies the base learner weighted training data and
the base learner generates a base classifier ht. Set
of nonnegative weights wt encode how important it
is that ht correctly classifies each email. Generally,
emails that were most often misclassified by the pre-
ceding base classifiers will be given the most weight
so as to force the base learner to focus on the ?hard-
est? examples. As described in Schapire and Singer
(1999), Boostexter uses confidence rated base clas-
sifiers h that for every example x (in our case it is the
customer emails) output a real number h(x) whose
sign (-1 or +1) is interpreted as a prediction(+1 indi-
cates emotional email), and whose magnitude |h(x)|
is a measure of ?confidence.? The output of the final
classifier f is f(x) =
?T
t=1 ht(x), i.e., the sum of
confidence of all classifiers ht. The real-valued pre-
dictions of the final classifier f can be mapped onto a
confidence value between 0 and 1 by a logistic func-
tion;
conf(x = emotional email) =
1
1 + e?f(x)
.
The learning procedure in boosting minimizes the
negative conditional log likelihood of the training
data under this model, namely:
?
i
ln(1 + e?yif(xi)).
Here i iterates over all training examples and yi is
the label of ith example.
3.2 Feature extraction
Emotional emails are a reaction to perceived exces-
sive loss of time and/or money by customers. Ex-
pressions of such reactions in emails are salient fea-
tures of emotional emails. For our data we have
identified the eight features listed below. While
many of these features are of general nature and can
be present in most customer service related emo-
tional emails, in this paper we make no claims about
their completeness.
1. Expression of negative emotions: Explic-
itly expressing customers affective states
by phrases like it upsets me, I am
frustrated;
2. Expression of negative opinions about
the company: by evaluative expres-
sions like dishonest dealings,
disrespectful. These could also be
insulting expressions like stink, suck,
idiots;
3. Threats to take their business elsewhere:
by expression like business elsewhere,
look for another provider. These
expressions are neither emotional or evaluative;
4. Threats to report to authorities: federal
agencies, consumer protection.
These are domain dependent names of agen-
cies. The mere presence of such names implies
customer threat;
5. Threats to take legal action: seek
retribution, lawsuit. These ex-
pressions may also not be emotional or
evaluative in nature;
6. Justification about why they should have been
treated better. A common way to do this is
12
to say things like long time customer,
loyal customer, etc. Semantic orienta-
tions of most phrases used to express this fea-
ture are positive;
7. Disassociate themselves from the company,
by using phrases like you people, your
service representative, etc. These
are analogous to rule class ?Noun Phrases used
as Appositions? in Spertus (1997).
8. State what was done wrong to them: grossly
overcharged, on hold for hours,
etc. These phrases may have negative or
neutral semantic orientations.
In addition to the word unigrams, salient features of
emotional emails are also used for training/testing
the emotional email classifier. While labeling the
training data, labelers look for salient features within
the email and also the severity of the loss perceived
by the customer. For example, email 1 in Fig. 1 is la-
beled as emotional because customer perception of
loss is severe to the point that the customer may can-
cel the service. On the other hand, email 2 is not
emotional because customer perceived loss is not se-
vere to the point of service cancellation. This cus-
tomer would be satisfied in this instant if he/she re-
ceives the requested information in a timely fashion.
To extract salient features from an email, eight
separate lists of phrases customers use to express
each of the salient features were manually created.
These lists were extracted from the training data
and can be considered as basic rules that identify
emotional emails. In the labeling guide for critical
emails labelers were instructed to look for salient
features in the email and keep a list of encountered
phrases. We further enriched these lists by: a) us-
ing general knowledge of English, we added vari-
ations to existing phrases and b) searching a large
body of email text (different from testing) for differ-
ent phrases in which key words from known phrases
participated. For example from the known phrase
lied to we used the word lied and found a
phrase blatantly lied. Using these lists we
extracted eight binary salient features for each email,
indicating presence/absence of phrases from the cor-
responding list in the email.
1. You are making this very difficult
for me. I was assured that
my <SERVICE> would remain at
<CURRENCY> per month. But you
raised it to <CURRENCY> per
month. If I had known you were
going to go back on your word,
I would have looked for another
Internet provider. Present
bill is <CURRENCY>, including
<CURRENCY> for <SERVICE>.
2. I cannot figure out my current
charges. I have called several
times to straighten out a problem
with my service for <PHONENO1>
and <PHONENO2>. I am tired of
being put on hold. I cannot get
the information from the automated
phone service.
Figure 1: Email samples: 1) emotional; 2) neutral
4 Experiments and evaluation
We performed several experiments to compare the
performance of our emotional email classifier with
that using a ngram based text classifier. For these
experiments we labeled 620 emails as training ex-
amples and 457 emails as test examples. Training
examples were labeled independently by two differ-
ent labelers1 with relatively high degree of agree-
ment among them. Kappa (Cohen, 1960) value of
0.814 was observed versus 0.5-0.7 reported for emo-
tion labeling tasks (Alm and Sproat, 2005; Litman
and Forbes-Riley, 2004a). Because of the relatively
high agreement among these labelers, with differ-
ent back ground, we did not feel the need to check
the agreement among more than 2 labelers. Table
1 shows that emotional emails are about 12-13% of
the total population.
Set Number of examples Critical Emails
Training 620 12%
Test 457 13%
Table 1: Distribution of emotional emails
1One of the labeler was one of the authors of this paper and
other had linguistic back ground.
13
Due to the limited size of the training data we
used cross validation (leave-one-out) technique on
the test set to evaluate outcomes of different exper-
iments. In this round robin approach, each example
from the test set is tested using a model trained on
all remaining 1076 (620 plus 456) examples. Test
results on all 457 test examples are averaged.
Throughout all of our experiments, we computed
the classification accuracy of detecting emotional
emails using precision, recall and F-measure. No-
tice for our test data a classifier with majority vote
has a classification accuracy of 87%, but since none
of the emotional emails are identified, recall and F-
measure are both zero. On the other hand, a clas-
sifier which generates many more false positives
for each true positive, will have a lower classifi-
cation accuracy but a higher (non-zero) F-measure
than the majority vote classifier. Fig. 2 shows pre-
cision/recall curves for different experiments. The
black circles represent the operating point corre-
sponding to the best F-measure for each curve. Ac-
tual values of these points are provided in Table 2.
As a baseline experiment we used word ngram
features to train a classifier model. The graph la-
beled as ?ngram features? in Fig. 2 shows the per-
formance of this classifier. The best F-measure in
this case is only 0.52. Obviously this low perfor-
mance can be attributed to the small training set and
the large feature space formed by word ngrams.
Recall Prec. F-Mes.
Ngram Features 0.45 0.61 0.52
Rule based:
Threshholding on
Salient Features counts
? 4 0.41 0.93 0.57
? 3 0.63 0.74 0.68
? 2 0.81 0.53 0.63
Salient Features 0.77 0.65 0.70
ngram &
Salient Features 0.65 0.81 0.72
Ngram &
Random Features 0.57 0.67 0.61
Table 2: Recall and precision corresponding to best F-
measure for different classifier models
Figure 2: Precision/Recall curves for different experi-
ments. Large black circles indicate the operating point
with best F-Measure
4.1 Salient features
The baseline system was compared with a similar
system using salient features. First, we used a sim-
ple classification rule that we formulated by look-
ing at the training data. According to this rule, if
an email contained three or more salient features it
was classified as an emotional email. We classified
the test data using this rule and obtained and an F-
measure of 0.68 (see row labeled as ? 3 in Table 2).
Since no confidence thresholding can be used with
the deterministic rule, its performance is indicated
by a single point marked by the gray circle in Fig. 2.
This result clearly demonstrates high utility of our
salient features. To verify that the salient features
threshold count of 3 used in our simple classification
rule is the best, we also evaluated the performance of
the rule for the salient features with threshold count
of 2 and 4 (row labeled as ? 2 and ? 4 in Table 2).
In our next set experiments, we trained a clas-
sifier model using salient features alone and with
word ngrams. Corresponding cross validation re-
sults on the test data are annotated in Table 2 and in
14
Fig. 2 as ?Salient Features? and ?N-grams & Salient
Features?, respectively. Incremental improvement in
best F-measure clearly shows: a) BoosTexter is able
to learn better rules than the simple rule of identify-
ing three or more salient features. b) Even though
salient features provide a significant improvement
in performance, there is still discriminative informa-
tion in ngram features. A direct consequence of the
second observation is that the detection accuracy can
be further improved by extending/refining the phrase
lists and/or by using more labeled data so that to
exploit the discriminative information in the word
ngram features.
Salient Features of emotional emails are the con-
sequence of our knowledge of how customers react
to their excessive loss. To empirically demonstrate
that eight different salient features used in identifi-
cation of emotional emails do provide complemen-
tary evidence, we randomly distributed the phrases
in eight lists. We then used them to extract eight
binary features in the same manner as before. Best
F-measure for this experiment is shown in the last
row of Table 2, and labeled as ?N-gram & Random
Features?. Degradation in performance of this ex-
periment clearly demonstrates that salient features
used by us provide complimentary and not redun-
dant information.
5 Conclusions
Customer emails complaining about unfair treat-
ment are often emotional and are critical for busi-
nesses. They provide valuable feedback for improv-
ing business processes and coaching agents. Fur-
thermore careful handling of such emails helps to
improve customer retention. In this paper, we pre-
sented a method for emotional email identification.
We introduced the notion of salient features for
emotional emails, and demonstrated high agreement
among two labelers in detecting emotional emails.
We also demonstrated that extracting salient fea-
tures from the email text and using them to train a
classifier model can significantly improve identifi-
cation accuracy. Compared to a baseline classifier
which uses only the word ngrams features, the addi-
tion of the salient features improved the F-measure
from 0.52 to 0.72. Our current research is focused
on improving the salient feature extraction process.
More specifically by leveraging publically available
Semantic orientation dictionaries, and by enriching
our dictionaries using phrases extracted from a large
corpus by matching syntactic patterns of some seed
phrases.
References
Alm, Cecilia and Richard Sproat. 2005. Emotional
sequencing and development in fairy tales. In
Proceedings of the First International Conference
on Affective Computing and Intelligent Interac-
tion.
Alm, Cecilia Ovesdotter, Dan Roth, and Richard
Sproat. 2005. Emotions from text: machine
learning for text-based emotion prediction. In
HLT ?05: Proceedings of the conference on Hu-
man Language Technology and Empirical Meth-
ods in Natural Language Processing. Association
for Computational Linguistics, Morristown, NJ,
USA, pages 579?586.
Cohen, J. 1960. A coefficient of agreement for nom-
inal scales. Educational and Psychological Mea-
surement 20(1):37?46.
Dave, Kushal, Steve Lawrence, and David M. Pen-
nock. 2003. Mining the peanut gallery: Opinion
extraction and semantic classification of product
reviews. In Proceedings of WWW. pages 519?
528.
Esuli, A. and F. Sebastiani. 2005. Determin-
ing the semantic orientation of terms through
gloss classificaion. In Proceedings of CIKM-05,
14th ACM International Conference on Informa-
tion and Knowledge Management. Bremen, DE.,
pages 617?624.
Gamon, M. 2004. Sentiment classification on cus-
tomer feedback data: Noisy data large feature
vectors and the role of linguistic analysis. In Pro-
ceedings of COLING 2004. Geneva, Switzerland,
pages 841?847.
Gupta, Narendra, Gokhan Tur, Dilek Hakkani-Tu?r,
Srinivas Banglore, Giuseppe Riccardi, and Mazin
Rahim. 2005. The AT&T Spoken Language
Understanding System. IEEE Transactions on
Speech and Audio Processing 14(1):213?222.
Hatzivassiloglou, Vasileios and Kathleen McKeown.
1997. Predicting the semantic orientation of ad-
15
jectives. In Proceedings of the Joint ACL/EACL
Conference. pages 174?181.
Hu, Minqing and Bing Liu. 2004. Mining and sum-
marizing customer reviews. In Proceedings of the
ACM SIGKDD Conference on Knowledge Dis-
covery and Data Mining (KDD). pages 168?177.
Kim, Soo-Min and Eduard Hovy. 2004. Determin-
ing the sentiment of opinions. In Proceedings of
the International Conference on Computational
Linguistics (COLING).
Lee, Chul Min and Shrikanth S. Narayanan. 2005.
Toward detecting emotions in spoken dialogs.
IEEE Transactions on Speech and Audio Process-
ing 13(2):293?303.
Litman, D. and K. Forbes-Riley. 2004a. Annotat-
ing student emotional states in spoken tutoring
dialogues. In Proceedings of the 5th SIGdial
Workshop on Discourse and Dialogue (SIGdial).
Boston, MA.
Litman, D. and K. Forbes-Riley. 2004b. Predicting
student emotions in computer-human tutoring di-
alogues. In Proceedings of the 42nd Annual Meet-
ing of the Association for Compuational Linguis-
tics (ACL). Barcelone, Spain.
Liu, Hugo, Henry Lieberman, and Ted Selker. 2003.
A model of textual affect sensing using real-world
knowledge. In IUI ?03: Proceedings of the 8th
international conference on Intelligent user inter-
faces. ACM Press, Miami, Florida, USA, pages
125?132.
Pang, Bo, Lillian Lee, and Shivakumar
Vaithyanathan. 2002. Thumbs up? Sentiment
classification using machine learning techniques.
In Proceedings of the 2002 Conference on Em-
pirical Methods in Natural Language Processing
(EMNLP). Philadelphia, Pennsylvania, pages
79?86.
Schapire, R.E. 1999. A brief introduction to boost-
ing. In Proceedings of IJCAI.
Schapire, R.E. and Y. Singer. 1999. Improved
boosting algorithms using confidence-rated pre-
dictions. Machine Learning 37(3):297?336.
Spertus, Ellen. 1997. Smokey: Automatic recogni-
tion of hostile messages. In In Proc. of Innova-
tive Applications of Artificial Intelligence. pages
1058?1065.
Turney, P. and M. Littman. 2003. Measuring praise
and criticism: Inference of semantic orientation
from association. ACM Transactions on Informa-
tion Systems 21(4):315?346.
Wilson, Theresa, Janyce Wiebe, and Paul Hoffmann.
2005. Recognizing contextual polarity in phrase-
level sentiment analysis. In HLT ?05: Proceed-
ings of the conference on Human Language Tech-
nology and Empirical Methods in Natural Lan-
guage Processing. Association for Computational
Linguistics, Morristown, NJ, USA, pages 347?
354.
Yu, Hong and Vasileios Hatzivassiloglou. 2003. To-
wards answering opinion questions: Separating
facts from opinions and identifying the polarity of
opinion sentences. In Proceedings of the Confer-
ence on Empirical Methods in Natural Language
Processing (EMNLP).
16
