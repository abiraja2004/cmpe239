Proceedings of NAACL-HLT 2013, pages 758?764,
Atlanta, Georgia, 9?14 June 2013. c?2013 Association for Computational Linguistics
PPDB: The Paraphrase Database
Juri Ganitkevitch1 Benjamin Van Durme1,2 Chris Callison-Burch2,3
1Center for Language and Speech Processing, Johns Hopkins University
2Human Language Technology Center of Excellence, Johns Hopkins University
3Computer and Information Science Department, University of Pennsylvania
Abstract
We present the 1.0 release of our para-
phrase database, PPDB. Its English portion,
PPDB:Eng, contains over 220 million para-
phrase pairs, consisting of 73 million phrasal
and 8 million lexical paraphrases, as well as
140 million paraphrase patterns, which cap-
ture many meaning-preserving syntactic trans-
formations. The paraphrases are extracted
from bilingual parallel corpora totaling over
100 million sentence pairs and over 2 billion
English words. We also release PPDB:Spa, a
collection of 196 million Spanish paraphrases.
Each paraphrase pair in PPDB contains a
set of associated scores, including paraphrase
probabilities derived from the bitext data and a
variety of monolingual distributional similar-
ity scores computed from the Google n-grams
and the Annotated Gigaword corpus. Our re-
lease includes pruning tools that allow users to
determine their own precision/recall tradeoff.
1 Introduction
Paraphrases, i.e. differing textual realizations of the
same meaning, have proven useful for a wide vari-
ety of natural language processing applications. Past
paraphrase collections include automatically derived
resources like DIRT (Lin and Pantel, 2001), the
MSR paraphrase corpus and phrase table (Dolan
et al, 2004; Quirk et al, 2004), among others.
Although several groups have independently ex-
tracted paraphrases using Bannard and Callison-
Burch (2005)?s bilingual pivoting technique (see
Zhou et al (2006), Riezler et al (2007), Snover et
al. (2010), among others), there has never been an
official release of this resource.
In this work, we release version 1.0 of the Para-
Phrase DataBase PPDB,1 a collection of ranked En-
glish and Spanish paraphrases derived by:
? Extracting lexical, phrasal, and syntactic para-
phrases from large bilingual parallel corpora
(with associated paraphrase probabilities).
? Computing distributional similarity scores for
each of the paraphrases using the Google n-
grams and the Annotated Gigaword corpus.
In addition to the paraphrase collection itself, we
provide tools to filter PPDB to only retain high pre-
cision paraphrases, scripts to limit the collection to
phrasal or lexical paraphrases (synonyms), and soft-
ware that enables users to extract paraphrases for
languages other than English.
2 Extracting Paraphrases from Bitexts
To extract paraphrases we follow Bannard and
Callison-Burch (2005)?s bilingual pivoting method.
The intuition is that two English strings e1 and e2
that translate to the same foreign string f can be as-
sumed to have the same meaning. We can thus pivot
over f and extract ?e1, e2? as a pair of paraphrases,
as illustrated in Figure 1. The method extracts a di-
verse set of paraphrases. For thrown into jail, it ex-
tracts arrested, detained, imprisoned, incarcerated,
jailed, locked up, taken into custody, and thrown
into prison, along with a set of incorrect/noisy para-
phrases that have different syntactic types or that are
due to misalignments.
For PPDB, we formulate our paraphrase collec-
tion as a weighted synchronous context-free gram-
mar (SCFG) (Aho and Ullman, 1972; Chiang, 2005)
1Freely available at http://paraphrase.org.
758
... f?nf Landwirte , weil
... 5 farmers were in Ireland ...
...
oder wurden , gefoltert
or have been , tortured
festgenommen 
thrown into jail
festgenommen
imprisoned
...
... ...
...
Figure 1: Phrasal paraphrases are extracted via bilingual
pivoting.
with syntactic nonterminal labels, similar to Cohn
and Lapata (2008) and Ganitkevitch et al (2011).
An SCFG rule has the form:
r
def= C ? ?f, e,?, ~??,
where the left-hand side of the rule,C, is a nontermi-
nal and the right-hand sides f and e are strings of ter-
minal and nonterminal symbols. There is a one-to-
one correspondence, ?, between the nonterminals
in f and e: each nonterminal symbol in f has to
also appear in e. Following Zhao et al (2008), each
rule r is annotated with a vector of feature functions
~? = {?1...?N} which are combined in a log-linear
model (with weights ~?) to compute the cost of ap-
plying r:
cost(r) = ?
N?
i=1
?i log?i. (1)
To create a syntactic paraphrase grammar we
first extract a foreign-to-English translation gram-
mar from a bilingual parallel corpus, using tech-
niques from syntactic machine translation (Koehn,
2010). Then, for each pair of translation rules where
the left-hand side C and foreign string f match:
r1
def= C ? ?f, e1,?1, ~?1?
r2
def= C ? ?f, e2,?2, ~?2?,
we pivot over f to create a paraphrase rule rp:
rp
def= C ? ?e1, e2,?p, ~?p?,
with a combined nonterminal correspondency func-
tion ?p. Note that the common source side f im-
plies that e1 and e2 share the same set of nonterminal
symbols.
The paraphrase rules obtained using this method
are capable of making well-formed generalizations
of meaning-preserving rewrites in English. For
instance, we extract the following example para-
phrase, capturing the English possessive rule:
NP ? the NP1 of NNS 2 | the NNS2 ?s NP1.
The paraphrase feature vector ~?p is computed
from the translation feature vectors ~?1 and ~?2 by
following the pivoting idea. For instance, we esti-
mate the conditional paraphrase probability p(e2|e1)
by marginalizing over all shared foreign-language
translations f :
p(e2|e1) ?
?
f
p(e2|f)p(f |e1). (2)
3 Scoring Paraphrases Using Monolingual
Distributional Similarity
The bilingual pivoting approach anchors para-
phrases that share an interpretation because of a
shared foreign phrase. Paraphrasing methods based
on monolingual text corpora, like DIRT (Lin and
Pantel, 2001), measure the similarity of phrases
based on distributional similarity. This results in a
range of different types of phrases, including para-
phrases, inference rules and antonyms. For instance,
for thrown into prison DIRT extracts good para-
phrases like arrested, detained, and jailed. How-
ever, it also extracts phrases that are temporarily
or causally related like began the trial of, cracked
down on, interrogated, prosecuted and ordered the
execution of, because they have similar distribu-
tional properties. Since bilingual pivoting rarely ex-
tracts these non-paraphrases, we can use monolin-
gual distributional similarity to re-rank paraphrases
extracted from bitexts (following Chan et al (2011))
or incorporate a set of distributional similarity scores
as features in our log-linear model.
Each similarity score relies on precomputed dis-
tributional signatures that describe the contexts that
a phrase occurs in. To describe a phrase e, we gather
counts for a set of contextual features for each oc-
currence of e in a corpus. Writing the context vector
for the i-th occurrence of e as ~se,i, we can aggre-
gate over all occurrences of e, resulting in a distri-
butional signature for e, ~se =
?
i ~se,i. Following the
intuition that phrases with similar meanings occur in
759
the long-term
achieve25
goals 23
plans 97
investment 10
confirmed64
revise43 the long-term
the long-term
the long-term
the long-term
the long-term
.
.
.
.
L-achieve = 25
L-confirmed
= 64
L-revise = 43
?
R-goals 
= 23
R-plans  = 97
R-investment 
= 10
?
the long-term
?
=~sig
?
(a) The n-gram corpus records the long-term as preceded
by revise (43 times), and followed by plans (97 times). We
add corresponding features to the phrase?s distributional
signature retaining the counts of the original n-grams.
long-term investment holding on to
det
amod
the
JJ NN VBG IN TO DT
NP
PP
VP
? ?
the long-term
?
=~sig
?
dep-det-R-investment
pos-L-TO 
pos-R-NN  
lex-R-investment 
lex-L-to 
dep-amod-R-investment
syn-gov-NP syn-miss-L-NN 
lex-L-on-to 
pos-L-IN-TO  
dep-det-R-NN dep-amod-R-NN
(b) Here, position-aware lexical and part-of-speech n-
gram features, labeled dependency links , and features
reflecting the phrase?s CCG-style label NP/NN are in-
cluded in the context vector.
Figure 2: Features extracted for the phrase the long term from the n-gram corpus (2a) and Annotated Gigaword (2b).
similar contexts, we can then quantify the goodness
of e? as a paraphrase of e by computing the cosine
similarity between their distributional signatures:
sim(e, e?) = ~se ? ~se?
|~se||~se? |
.
A wide variety of features have been used to de-
scribe the distributional context of a phrase. Rich,
linguistically informed feature-sets that rely on de-
pendency and constituency parses, part-of-speech
tags, or lemmatization have been proposed in work
such as by Church and Hanks (1991) and Lin and
Pantel (2001). For instance, a phrase is described by
the various syntactic relations such as: ?what verbs
have this phrase as the subject??, or ?what adjectives
modify this phrase??. Other work has used simpler
n-gram features, e.g. ?what words or bigrams have
we seen to the left of this phrase??. A substantial
body of work has focussed on using this type of
feature-set for a variety of purposes in NLP (Lapata
and Keller, 2005; Bhagat and Ravichandran, 2008;
Lin et al, 2010; Van Durme and Lall, 2010).
For PPDB, we compute n-gram-based context
signatures for the 200 million most frequent phrases
in the Google n-gram corpus (Brants and Franz,
2006; Lin et al, 2010), and richer linguistic signa-
tures for 175 million phrases in the Annotated Gi-
gaword corpus (Napoles et al, 2012). Our features
extend beyond those previously used in the work by
Ganitkevitch et al (2012). They are:
? n-gram based features for words seen to the left
and right of a phrase.
? Position-aware lexical, lemma-based, part-of-
speech, and named entity class unigram and bi-
gram features, drawn from a three-word win-
dow to the right and left of the phrase.
? Incoming and outgoing (wrt. the phrase) de-
pendency link features, labeled with the corre-
sponding lexical item, lemmata and POS.
? Syntactic features for any constituents govern-
ing the phrase, as well as for CCG-style slashed
constituent labels for the phrase.
Figure 2 illustrates the feature extraction for an ex-
ample phrase.
4 English Paraphrases ? PPDB:Eng
We combine several English-to-foreign bitext cor-
pora to extract PPDB:Eng: Europarl v7 (Koehn,
2005), consisting of bitexts for the 19 European lan-
guages, the 109 French-English corpus (Callison-
Burch et al, 2009), the Czech, German, Span-
ish and French portions of the News Commen-
tary data (Koehn and Schroeder, 2007), the United
Nations French- and Spanish-English parallel cor-
pora (Eisele and Chen, 2010), the JRC Acquis cor-
pus (Steinberger et al, 2006), Chinese and Arabic
760
Identity Paraphrases Total
Lexical 0.6M 7.6M 8.1M
Phrasal 4.9M 68.4M 73.2M
Syntactic 46.5M 93.6M 140.1M
All 52.0M 169.6M 221.4M
Table 1: A breakdown of PPDB:Eng size by paraphrase
type. We distinguish lexical (i.e. one-word) paraphrases,
phrasal paraphrases and syntactically labeled paraphrase
patterns.
newswire corpora used for the GALE machine trans-
lation campaign,2 parallel Urdu-English data from
the NIST translation task,3 the French portion of
the OpenSubtitles corpus (Tiedemann, 2009), and a
collection of Spanish-English translation memories
provided by TAUS.4
The resulting composite parallel corpus has more
than 106 million sentence pairs, over 2 billion En-
glish words, and spans 22 pivot languages. To ap-
ply the pivoting technique to this multilingual data,
we treat the various pivot languages as a joint Non-
English language. This simplifying assumption al-
lows us to share statistics across the different lan-
guages and apply Equation 2 unaltered.
Table 1 presents a breakdown of PPDB:Eng by
paraphrase type. We distinguish lexical (a single
word), phrasal (a continuous string of words), and
syntactic paraphrases (expressions that may con-
tain both words and nonterminals), and separate
out identity paraphrases. While we list lexical and
phrasal paraphrases separately, it is possible that a
single word paraphrases as a multi-word phrase and
vice versa ? so long they share the same syntactic
label.
5 Spanish Paraphrases ? PPDB:Spa
We also release a collection of Spanish paraphrases:
PPDB:Spa is extracted analogously to its English
counterpart and leverages the Spanish portions of the
bitext data available to us, totaling almost 355 mil-
lion Spanish words, in nearly 15 million sentence
pairs. The paraphrase pairs in PPDB:Spa are anno-
2http://projects.ldc.upenn.edu/gale/
data/Catalog.html
3LDC Catalog No. LDC2010T23
4http://www.translationautomation.com/
Identity Paraphrases Total
Lexical 1.0M 33.1M 34.1M
Phrasal 4.3M 73.2M 77.5M
Syntactic 29.4M 55.3M 84.7M
All 34.7M 161.6M 196.3M
Table 2: An overview of PPDB:Spa. Again, we parti-
tion the resource into lexical (i.e. one-word) paraphrases,
phrasal paraphrases and syntactically labeled paraphrase
patterns.
expect
NNS VBP
NP
VP
the data
NP VP
S
to show
JJ
economistsfew
......
S
...
RelArg0 Arg1
Figure 3: To inspect our coverage, we use the Penn
Treebank?s parses to map from Propbank annotations to
PPDB?s syntactic patterns. For the above annotation
predicate, we extract VBP ? expect, which is matched
by paraphrase rules like VBP ? expect | anticipate
and VBP ? expect | hypothesize. To search for
the entire relation, we replace the argument spans
with syntactic nonterminals. Here, we obtain S ?
NP expect S, for which PPDB has matching rules like
S ? NP expect S | NP would hope S, and S ?
NP expect S | NP trust S. This allows us to apply so-
phisticated paraphrases to the predicate while capturing
its arguments in a generalized fashion.
tated with distributional similarity scores based on
lexical features collected from the Spanish portion
of the multilingual release of the Google n-gram
corpus (Brants and Franz, 2009), and the Spanish
Gigaword corpus (Mendonca et al, 2009). Table 2
gives a breakdown of PPDB:Spa.
6 Analysis
To estimate the usefulness of PPDB as a resource
for tasks like semantic role labeling or parsing, we
analyze its coverage of Propbank predicates and
predicate-argument tuples (Kingsbury and Palmer,
2002). We use the Penn Treebank (Marcus et
al., 1993) to map Propbank annotations to patterns
which allow us to search PPDB:Eng for paraphrases
that match the annotated predicate. Figure 3 illus-
761
 1 3 5-30 -25 -20 -15 -10 -5  0Avg. Score Pruning Threshold 0 0.5 1-30 -25 -20 -15 -10 -5  0  0 50 100 150Coverage PP / Type
(a) PPDB:Eng coverage of Propbank predicates
(top), and average human judgment score (bottom)
for varying pruning thresholds.
 0 0.2 0.4 0.6 0.8 1-30 -25 -20 -15 -10 -5  0  0 20 40 60 80 100 120 140 160Coverage Paraphrases / TypePruning ThresholdRelation Tokens CoveredParaphrases / TypeRelation Types Covered
(b) PPDB:Eng?s coverage of Propbank predicates
with up to two arguments. Here we consider rules
that paraphrase the full predicate-argument expres-
sion.
Figure 4: An illustration of PPDB?s coverage of the manually annotated Propbank predicate phrases (4a) and binary
relations with argument non-terminals (4b). The curves indicate the coverage on tokens (solid) and types (dotted), as
well as the average number of paraphrases per covered type (dashed) at the given pruning level.
trates this mapping.
In order to quantify PPDB?s precision-recall
tradeoff in this context, we perform a sweep
over our collection, beginning with the full set of
paraphrase pairs and incrementally discarding the
lowest-scoring ones. We choose a simple estimate
for each paraphrase pair?s score by uniformly com-
bining its paraphrase probability features in Eq. 1.
The top graph in Figure 4a shows PPDB?s cover-
age of predicates (e.g. VBP ? expect) at the type
level (i.e. counting distinct predicates), as well as
the token level (i.e. counting predicate occurrences
in the corpus). We also keep track of average num-
ber of paraphrases per covered predicate type for
varying pruning levels. We find that PPDB has a
predicate type recall of up to 52% (accounting for
97.5% of tokens). Extending the experiment to full
predicate-argument relations with up to two argu-
ments (e.g. S ? NNS expect S), we obtain a 27%
type coverage rate that accounts for 40% of tokens
(Figure 4b). Both rates hold even as we prune the
database down to only contain high precision para-
phrases. Our pruning method here is based on a sim-
ple uniform combination of paraphrase probabilities
and similarity scores.
To gauge the quality of our paraphrases, the au-
thors judged 1900 randomly sampled predicate para-
phrases on a scale of 1 to 5, 5 being the best. The
bottom graph in Figure 4a plots the resulting human
score average against the sweep used in the cover-
age experiment. It is clear that even with a simple
weighing approach, the PPDB scores show a clear
correlation with human judgements. Therefore they
can be used to bias the collection towards greater re-
call or higher precision.
7 Conclusion and Future Work
We present the 1.0 release of PPDB:Eng and
PPDB:Spa, two large-scale collections of para-
phrases in English and Spanish. We illustrate the
resource?s utility with an analysis of its coverage of
Propbank predicates. Our results suggest that PPDB
will be useful in a variety of NLP applications.
Future releases of PPDB will focus on expand-
ing the paraphrase collection?s coverage with regard
to both data size and languages supported. Further-
more, we intend to improve paraphrase scoring by
incorporating additional sources of information, as
well as by better utilizing information present in the
data, like domain or topic. We will also address
points of refinement such as handling of phrase am-
biguity, and effects specific to individual pivot lan-
guages. Our aim is for PPDB to be a continuously
updated and improving resource.
Finally, we will explore extensions to PPDB to in-
clude aspects of related large-scale resources such as
lexical-semantic hierarchies (Snow et al, 2006), tex-
tual inference rules (Berant et al, 2011), relational
patterns (Nakashole et al, 2012), and (lexical) con-
ceptual networks (Navigli and Ponzetto, 2012).
762
Acknowledgements
We would like to thank Frank Ferraro for his Prop-
bank processing tools. This material is based
on research sponsored by the NSF under grant
IIS-1249516 and DARPA under agreement num-
ber FA8750-13-2-0017 (the DEFT program). The
U.S. Government is authorized to reproduce and dis-
tribute reprints for Governmental purposes. The
views and conclusions contained in this publication
are those of the authors and should not be interpreted
as representing official policies or endorsements of
DARPA or the U.S. Government.
References
Alfred V. Aho and Jeffrey D. Ullman. 1972. The Theory
of Parsing, Translation, and Compiling. Prentice Hall.
Colin Bannard and Chris Callison-Burch. 2005. Para-
phrasing with bilingual parallel corpora. In Proceed-
ings of ACL.
Jonathan Berant, Jacob Goldberger, and Ido Dagan.
2011. Global learning of typed entailment rules. In
Proceedings of ACL.
Rahul Bhagat and Deepak Ravichandran. 2008. Large
scale acquisition of paraphrases for learning surface
patterns. In Proceedings of ACL/HLT.
Thorsten Brants and Alex Franz. 2006. Web 1T 5-gram
version 1.
Thorsten Brants and Alex Franz. 2009. Web 1T 5-gram,
10 european languages version 1. Linguistic Data
Consortium, Philadelphia.
Chris Callison-Burch, Philipp Koehn, Christof Monz,
and Josh Schroeder. 2009. Findings of the 2009
Workshop on Statistical Machine Translation. In Pro-
ceedings of WMT, pages 1?28, Athens, Greece, March.
Tsz Ping Chan, Chris Callison-Burch, and Benjamin Van
Durme. 2011. Reranking bilingually extracted para-
phrases using monolingual distributional similarity. In
EMNLP Workshop on GEMS.
David Chiang. 2005. A hierarchical phrase-based model
for statistical machine translation. In Proceedings of
ACL.
Kenneth Church and Patrick Hanks. 1991. Word asso-
ciation norms, mutual information and lexicography.
Computational Linguistics, 6(1):22?29.
Trevor Cohn and Mirella Lapata. 2008. Sentence com-
pression beyond word deletion. In Proceedings of the
COLING.
Bill Dolan, Chris Quirk, and Chris Brockett. 2004. Un-
supervised construction of large paraphrase corpora:
Exploiting massively parallel news sources. In Pro-
ceedings of the COLING.
Andreas Eisele and Yu Chen. 2010. MultiUN: A multi-
lingual corpus from united nation documents. In Pro-
ceedings of LREC, Valletta, Malta.
Juri Ganitkevitch, Chris Callison-Burch, Courtney
Napoles, and Benjamin Van Durme. 2011. Learning
sentential paraphrases from bilingual parallel corpora
for text-to-text generation. In Proceedings of EMNLP.
Juri Ganitkevitch, Benjamin Van Durme, and Chris
Callison-Burch. 2012. Monolingual distributional
similarity for text-to-text generation. In Proceedings
of *SEM. Association for Computational Linguistics.
Paul Kingsbury and Martha Palmer. 2002. From tree-
bank to propbank. In Proceedings of LREC.
Philipp Koehn and Josh Schroeder. 2007. Experiments
in domain adaptation for statistical machine transla-
tion. In Proceedings of WMT, Prague, Czech Repub-
lic, June. Association for Computational Linguistics.
Philipp Koehn. 2005. Europarl: A parallel corpus for sta-
tistical machine translation. In MT summit, volume 5.
Philipp Koehn. 2010. Statistical Machine Translation.
Cambridge University Press.
Mirella Lapata and Frank Keller. 2005. Web-based mod-
els for natural language processing. ACM Transac-
tions on Speech and Language Processing, 2(1).
Dekang Lin and Patrick Pantel. 2001. Discovery of infer-
ence rules from text. Natural Language Engineering.
Dekang Lin, Kenneth Church, Heng Ji, Satoshi Sekine,
David Yarowsky, Shane Bergsma, Kailash Patil, Emily
Pitler, Rachel Lathbury, Vikram Rao, Kapil Dalwani,
and Sushant Narsale. 2010. New tools for web-scale
n-grams. In Proceedings of LREC.
Mitchell P. Marcus, Mary Ann Marcinkiewicz, and Beat-
rice Santorini. 1993. Building a large annotated cor-
pus of english: the Penn Treebank. Computational
Linguistics, 19(2).
Angelo Mendonca, David Andrew Graff, and Denise
DiPersio. 2009. Spanish Gigaword Second Edition.
Linguistic Data Consortium.
Ndapandula Nakashole, Gerhard Weikum, and Fabian
Suchanek. 2012. PATTY: a taxonomy of rela-
tional patterns with semantic types. In Proceedings
of EMNLP.
Courtney Napoles, Matt Gormley, and Benjamin Van
Durme. 2012. Annotated gigaword. In Proceedings
of AKBC-WEKEX 2012.
Roberto Navigli and Simone Paolo Ponzetto. 2012. Ba-
belNet: The automatic construction, evaluation and
application of a wide-coverage multilingual semantic
network. Artificial Intelligence, 193.
Chris Quirk, Chris Brockett, and William Dolan. 2004.
Monolingual machine translation for paraphrase gen-
eration. In Proceedings of EMNLP.
763
Stefan Riezler, Alexander Vasserman, Ioannis Tsochan-
taridis, Vibhu Mittal, and Yi Liu. 2007. Statistical
machine translation for query expansion in answer re-
trieval. In Proceedings of the 45th Annual Meeting of
the ACL.
Matthew Snover, Nitin Madnani, Bonnie Dorr, and
Richard Schwartz. 2010. Ter-plus: paraphrase, se-
mantic, and alignment enhancements to translation
edit rate. Machine Translation, 23(2-3):117?127.
Rion Snow, Daniel Jurafsky, and Andrew Y. Ng. 2006.
Semantic taxonomy induction from heterogenous evi-
dence. In Proceedings of the ACL/Coling.
Ralf Steinberger, Bruno Pouliquen, Anna Widiger,
Camelia Ignat, Tomaz Erjavec, Dan Tufis, and Da?niel
Varga. 2006. The JRC-Acquis: A multilingual
aligned parallel corpus with 20+ languages. In Pro-
ceedings of LREC, Genoa, Italy.
Jo?rg Tiedemann. 2009. News from OPUS: A collection
of multilingual parallel corpora with tools and inter-
faces. In Recent Advances in Natural Language Pro-
cessing, volume 5.
Benjamin Van Durme and Ashwin Lall. 2010. Online
generation of locality sensitive hash signatures. In
Proceedings of ACL, Short Papers.
Shiqi Zhao, Cheng Niu, Ming Zhou, Ting Liu, and Sheng
Li. 2008. Combining multiple resources to improve
SMT-based paraphrasing model. In Proceedings of
ACL/HLT.
Liang Zhou, Chin-Yew Lin, Dragos Stefan Munteanu,
and Eduard Hovy. 2006. Paraeval: Using paraphrases
to evaluate summaries automatically. In Proceedings
of HLT/NAACL.
764
