Language Production: the Source ofthe Dictionary 
David D. McDonald 
University of Massachusetts at Amherst 
April 1980 
Abstract 
Ultimately in any natural language production system the largest amount of 
human effort will go into the construction of the dictionary: the data base 
that associates objects and relations in the program's domain with the words 
and phrases that could be used to describe them. This paper describes a 
technique for basing the dictionary directly on the semantic abstraction 
network used for the domain knowledge itself, taking advantage of the 
inheritance and specialization machanisms of a network formalism such as 
r,L-ON~ The technique creates eonsidcrable economies of scale, and makes 
possible the automatic description of individual objects according to their 
position in the semantic net. Furthermore, because the process of deciding 
what properties to use in an object's description is now given over to a 
common procedure, we can write general-purpose rules to, for example, 
avoid redundancy or grammatically awkward constructionS. 
Regardless of its design, every system for natural !anguage 
production begins by selecting objects and relations from the speaker's 
internal model of the world, and proceeds by choosing an English phrase to 
describe ach selected item, combining them according to the properties of 
the phrases and the constraints of the language's grammar and rhetoric. TO 
do this, the system must have a data base of some sort, in which the objects 
it will talk about are somewhow associated with the appropriate word or 
phrase (or with procedures that will construct them). 1 will refer to such a 
data base as a dictionary. 
Evcry production system has a dictionary in one form or another, and 
its compilation is probably the single most tedious job that the human 
designer must perform. In the past. typically every object and relation has 
been given its own individual "lex" property with the literal phrase to be 
used; no attempt was made to share criteria or sub-phrases between 
properties; and there was a tacit a~umtion that the phrase would have the 
right form and content in any of the contexts that the object will be 
mentioned. (For a review of this literature, see r~a .) However, 
dictionaries built in this way become increasingly harder to maintain as 
programs become larger and their discourse more sophisticated. We would 
like instead some way to de the extention of the dictionary direcdy to the 
extention of the program's knowledge base; then, as the knowledge base 
expands the dictionary will expand with it with only a minimum of 
additional cffort. 
This paper describes a technique for adapting a semantic abstraction 
hierarchy of thc sort providcd by ~d~-ONE ~:1.\] to function directly as a 
dictionary for my production system MUMIII.I~ \ [ ,q '~ .  . Its goal is largely 
expositional in the sense that while the technique is fully spocificd and 
proto-types have been run, many implementation questions remain to be 
explored and it is thus premature to prescnt it as a polished system for 
others to use; instead, this paper is intended as a presentation of the 
issues--potcntial economicw---that he technique is addressing. In 
particular, given the intimate relationship between the choice of 
architecture in the network formalism used and the ability uf the dictionary 
to incorporate linguistically useful generalizations and utilities, this 
presentation may suggest additional criteria for networ k design, namely to 
make it easier to talk about he objects the network 
The basic idea of "piggybacking" the dictionary onto the speaker's 
regular semantic net can be illustrated very simply: Consider the KL.ONE 
network in figure one, a fragment taken from a conceptual taxonomy for 
augmented transition ets (given in \[klune\]). The dictionary will provide 
the means to describe individual concepts (filled ellipses) on the basis of 
their links to generic concepts lempty ellipses) and their functional roles 
(squar~s), as shown there for the individual concept "C205". The default 
English description of C205 (i.e. "the jump arc fi'om S /NP  to S/DCL") is 
created recursiveiy from dL.~riptions of the three network relations that 
C205 participates in: its "supercuneept" link to the concept "jump-are". and 
its two role-value relations: "source-stateIC205)=S/NP" and "next- 
state(C205)=S/t:~Ct.". Intuitively. we want to associate each of the 
network objects with an English phrase: the concept "art'" with the word 
"art"', the "source-state" role relation with the phrase "C205 comes from 
S/NF" (note the embedded references), and so on. The machinery that 
actually brings about this ~sociation is, of course, much more elaborate, 
involving three different recta-level networks describing the whole of the 
original, "domain" network, as well as an explicit representation f the 
English grammar (i.e. it Ls itsclf expressed in rd,-oN~). 
role links ~ ? ~ test 
~ act ion  value-.restriction links 
IL_ 
value links 
"The jump arc from S./NP to S/DCL" 
Figure One: the speaker's original network 
What does this rather expensive I computational machinery purchase? 
There are numrous benefits: The most obvious is the economy of scale 
within the dictionary that is gained by drawing directly on the economies 
\[. What is cxpensive to represcnt in an explicit, declarative structure need 
not be expensive wllen translated into pn~ccdurai forth. \] do not seriously 
expect anyone to implement suctl a dicti()nary by interpreting the Y-.I.-ON,~, 
structures themselves; given tmr present hardware such a tact would be 
hopelessly inel\]icient. Instead, a compilation pnx:css will in effective 
"compact" the explicit version of thc dictionary in~t~ an expeditious,, space.- 
expensive (i.e. heavily redundant} version that pc:rfbrms each inheritance 
only once and fl~eu runs as an efficient, self-contained procedure. 
57 
alr,,:.~dy prcsent in the network: a one-time liuguistic annotation of the 
nctwork's generic concepts aod relations can be passed own to describe 
arbitrary numbcrs of instantiating individuals by following general rules 
based on the geography of thc network. At thc same time. the dictionary 
"cmr~ " \['or a object in the nctwork may be ~pcciaiizcd and hand-tailored, if 
desired, in order to take advantage of special words or idiomadc phrases or 
it may inherit partial dct'auk reali~ation~ e.g. just \['or determiners or 
ad~erbia| modifiers, while specializing, its uther parts. More generally. 
because we ha~c now retried the procc~ of collecting the "raw material" of 
Lhe production process (i.e. scanning the nctw(,rk), we c:m imp(vse rules and 
constraints on it just ,xs thougi~ it were another part of the production 
planning process; we can develop a dictionary gnmm~ur entirely analogous 
to our gramm.'~r of l'nglish. This allows us to filter or mmsform the 
collection pnx:css under contextual cuntnd according to general nlles, and 
thereby, among edict things, automatically avoid rcdundancics ur violations 
o\[' grammatical constraints such as complex-NP. 
In order to adapt a semantic net for use a~ a dictionary we must 
dctermthe three points: (1) What type of linguistic annotation to use--just 
what is to be associated with the nodes ufa network? (2) How annotations 
from individual nodes are to be accumulatcd~what dictates the pattern in 
which the network is scanned? (3) How the accumulation process is made 
sensitive to context. 'lllese will be the ft~us of the rest oft he paper. 
l'hc three points of the desigu arc. of course, mutually dcpendcnt, 
and are \['urther dependent on the requirements of the dictionary's 
cmploye~, the planning and \[inguLstic realization componants or" the 
produc'3on system, in the interests of space I will not go into the details of 
these components in this paper, especially as this dictionary desigu appears 
to be ,~ful I%r more than lust my own particular production system. My 
assumptions are: (t) that the output ot the dictionary (the Input to my 
realization component) is a representation of  a natural language phrase as 
defined by the grammar and with both words and other objects from the 
domain network as its terminals (the embedded domain objects correspond 
to the variable parts of'the phrase, i.e. the arguments to the original network 
relation): and (2) that the planning process (the component that decides 
what to say) will specify that network objects be described either as a 
composition era set of other network relations that it has explicitly selected, 
or else will leave the de~:riptiun to a default given in the dictionary. 
Meta- level  annotat ion 
"\]'he basis of the dictionary is a meta-/evel network constructed so as to 
shadow the domain network used by the rest of the speaker's cognitive 
processes. "\['his "dictionary network" describes the domain network from 
the point of view of d1? accumulation procedure and the linguistic 
annotation. \[t is itself an abstraction hierarchy, and is also expressed in xL. 
ON"~ (though see the earlier \['ootuot?). Objects in the regular network are 
connected hy recta-links to their corresponding dictionary "entries". These 
entries are represcntaUons of English phra.?x.~ (either a single phrase or word 
or a cluster of alternative phrases with some decision-criteria to s?lcet 
among them at run dine). When we want to describe an object, we follow 
out its recta-link inzo the dictionary network and then realize the word or 
phrase that we find. 
Special izing Generic Phrases 
"\['he nu'y for an objcct may itself have a hicrarcifical structure that 
parallels point fi)r point the I~ierarehical sU'ucture of the object's deseription 
in the domain. Figure two slzows the section of the dicti:mary network that 
annotates the supen:oncept chain front "jump-an:" to "object"; comparable 
dictionary networks can be built \[.or hierarchies of roles or other hierarchical 
network structures. Noticc how the use of an inheritance m~hanisrn within 
the dictionary network (denoted by the vcrticat \[inks betwccn roles) allows 
us on the one hand to state the determiner decision (show, bern only as a 
cloud) once and for all at thc level of the domain conccpt "object", while at 
the same time we can vo:umulate or supplant lexk:al material as we move 
down to more specific levels in the domain nctwork. 
Rgure Two: the recta-level dictionary network 
After all the inhent*n~c is factored in. dt? entry for. e.g., the generic 
concept "lump-ate" will de~:.ribe a noun phrase (represented by an 
thdiviual ?oilcept in K.i..O~t;) ~,,hose head position, is filled lly the word 
"arc', classifier position by "jump", and whose determiner will be 
calculated (at run time) by die same roudne that calculated detemlinen \['or 
objects in general (e.g. it will react Io whedlcr 'Jt? reference is to a generic or 
an individual to how. many other objects have the same dcseription, to 
whether any spec~ contrustive effects are intended, etc. see \[q'~ !). 
Should the planner d,'x:ide to use this entry by itself, say to produce 
"C205 is\[ajump arc\]", this dccripdon from the dictionary nctwork would 
be eonvercd to a proper constituent structure and integrated with the rest 
of the utterance under production. However. the entry will often be used in 
conjunction with the entries for several other domain objects, in which 
it is first manipulated as a deseription--constraint s atement--in order to 
determine what 8ramroadcal consuuction(s) would realize the objects as a 
group. 
The notion of crea~ng a consolidated English phrase out of the 
phr~ t'or several different objects is central to the power of this 
dictionary. '\['he designer is only expected to explicitly designate words for 
the generic objects in the domain network; the entries for the individual 
objects that the geueric objecLs de,scribe :rod cvcn the entries for a 
hicntrehical chain such as in figure two should typically be constructablo by 
default by fullowing general-purpo,Je linguistic rules and combination 
heud=ies. 
58 
t "  
Large entries out of small ones 
Figure three shows a sketch of the combination process, Here we 
need a dictionary entry to describe the relationship between the specific 
jump-arc C205 and the state it leads to, S/DCL, i.e. we want something like 
the sentence "(6"205) goes to (S/DCL)". where the refercnces in angle 
brackets would be ultimately replaced by their own English phrases. When 
the connecdng role relation ("next-state") can bc rendered into English by a 
conventional pattern, wc can use an automatic combination technique as in 
the figure to construct a linguistic relationship for the domain onc by using 
a conventional dictionary entry for the concept-role-value relations as 
specialized by the specific entry for thc role "next-state". 
The figure shows diagramaiically thc relationship between the 
domain network relation, its recta-level description as an object in the 
network fomlalism (i.e. it is an instance of a concept linked to one of its 
roles linked in turn to the roic value), and finally the corresponding 
conventional linguistic construction. The actoal Zl,.O~t; reprcscntation of 
this relation is considerably more elaborate since the links themselves are 
reified, however this sketch shows the rclevant level of detail as regards 
what kinds of knowledge arc nccded in or'tier to assemble the entry 
R \[raducable-v~ goes to I 
JUMP-ARC 
 blV:CONCEPT__ROt _V*LUE) 
; ; \ 
CaAS'C-CLAUS J" 
Figure Three: Combining Entries by Network Relations 
procedurally. First the domain reladon is picked out and categorized: here 
this was done by a the conventional recta-level description of the relation in 
terms of the VJ,.ONE primitives it was built from, below we will see how a 
comparable categorization can be done on a purely linguistic basis. With 
the relation categorized, we can associated it with an entry in the dictionary 
network, in this ease an instance of a "basic-clause" (i.e. one without any 
adjuncts or rom-transfomaations). We now have determined a mapping 
from the entries for the components of the original domain relation to 
linguistic roles within a clause and have. in effect, created the relation's 
entry which we could then compile for efficiency. 
There is much more to be said about how the "embedded entries" 
can be controlled, how, for example, the planner can arrange to say either 
"C205 goes to S/DCL" or "There is a jump arc going to S/DCL" by 
dynamically specializing the description of the clause, however it would be 
taking us too far afield: the interested reader is referred to \[thesisl. The 
point to be made here is just that the writer of the dictionary has an option 
either to write specific dictionary entries for domain relations, or to leave 
them to general "macro entries" that will build them out of the entries for 
the objects involved as just sketched. Using the macro entries of course 
meau that less effort v, ill be needed over all, but using specific entries 
permits one to rake advantage of special idioms or variable phrases that are 
either not productive nough or not easy enough to pick out in a standard 
recta-level description of the domain network to be worth writing macro 
entries for. A simple example would be a special entry for when one plans 
to describe an arc in terms of both its source and its nexi states: in this case 
there is a nice compaction available by using die verb "connect" in a single 
clause (instead of one clause for each role). Since the ~I,-O~F. formalism has 
no transparent means of optionally bundling two roles into one, this 
compound rcladon has to be given its own dictionary entry by hand. 
Mak ing  co lnbinat ions l inguist ical ly  
Up to this point, we have been looking at associations between 
"organic" objects or relations in the domain network and their dictionary 
entries for production. It is often the case however, that the speech planner 
will want to talk about combinations of objects or complex relations that 
have been assembled just for the occasion of one conversation and have no 
natural counterpart within the regular domain network. In a case like this 
there wuuld not already be an entry in the dictionary for the new relation; 
however, in most eases we can still produce an integrated phrase by looking 
at how the components of the new relation can combine linguistically. 
These linguistic ombinations are not so much the provence of the 
dictionary as of my linguistic realization component. MuMnI,E. ~.IUSIBLE 
has the ability to perform what in the early days of transformational 
generative grammar were referred to as "gcneraliT.ed transformations": the 
combining of two or more phrases into a single phrase on the basis of their 
linguistic descriptions. We have an example of this in the original example 
of the default description ofC205 as "the jump arc fram S /N  P to S/DC L". 
This phrase was produced by having the default planner construct an 
expression indicating which network relations to combine (or more 
precisely, which phrases to combine, the phrases being taken from the 
entries of the relations), and then pass the expression to MI.MnLE which 
produces the "compound" phrase on the basis of the linguistic description 
of the argument phrases. The expression would look roughly like this: 1 
(descr ibe  C205 as (and \[np Ihejumparcl 
\[clau:~ C205 \[rcdueable-vp Comes from S/NP \] } 
\[clause C205 \[rcducable'~p goes lo S/OCL I \] 
MUMBLE's task is the production of  an object description front the raw 
material o f  a noun phrase and two clauses. To do this, it will have to match 
die three phrases against one of its known linguistic ombination patterns, 
just as the individual concept, role, and value were matched by a pattern 
from the Itt,.ONl.: representation formalism. In this case, it characterizes the 
trio as combinable through the adjunction of. the two clauses to the noun 
phrase as qualifiers. Additionally. the rhetorical label "rcdueable-vp" in the 
clauses indicates that their verbs can be omitted without losing significant 
1. A "phrase" in a dictionary entry does not cnnsist simply of  a string of  
words, They are actually schemata specifying the grammatical and 
rl~etorical relationships that the words and argument d(unain objects 
participate in according to their functional n~/cs. The bracketed CXl)rcssious 
shown in the cxprc.~ion are fur expository purposes only and are modeled 
on the usual representation ft~r iJhraso structure. I-mbedded objects uch as 
"C205" or "S/NP" will be replaced by their own English phrases 
incrementally asthe containing phrases i  realized, 
59 
intbrmation, triggering a stylistic transformation co shorten and simplify the 
phrase. At this point MUMIIU': h;LS a linguistic reprcsenmtion of  its decision 
which is turned ovcr to the normal realization pruccss For completion. 
Exauszivc details of  these operations may be found in \["1~ . 
Contextual Effects 
The mechanisms of the dictionary per se perform two ~ncdons: (l) 
the association of the "ground level" linguistic phrases with the objeets of 
the domain network, and (2) the proper paczeros for accumulating the 
linguistic dcscriptions of other parts of the domain network so as to describe 
complex generic relatioos or to describe individual concepts in terms of 
their specific rela0ons and thcir generic description (as widt C205). On  top 
of these two levels is graRcd a third lcvcl of contextually-triggered ffects; 
these effects are carried out by MUMI|IJ." {the component hat is maintaining 
the linguistic context that is the source of the uiggcrs). ~ting at the point 
where combinations are submitted to it as just described. 
Tu best illustrate the contextual cffec~ wc should mm, e to a slightly 
more complex example, o,c that is initiated by the speaker's planning 
process rathcr by than a defnuiL Suppose that the speaker is talking about. 
the A r.~ state "SI(")CL" and wants to say in effect that it is part of the 
domain relation "ncxt-s~ite(C205)=SIIX~L". The default way to express 
this reladon is as a Fact about the jump arc C"205: but what we ~r? doing 
now is to use it as Fact about S /DCL which will require the production of  a 
quite different ph~Lse. The planning process expresses this intention to 
MU.MIn.E with the ~\[Iowing expression: 
(say-about C205 that (next-state C205 S/DCL)) 
The operator "say-about" is responsible for detcnnining, on the basis 
of  the dictionary's description of the "neat-state" rcladon, what \[-~ngiish 
construction to use in order to express the ~peaker's intentcd focus. When 
the dictionary contains several possible renlizating phrases for a relation (For 
example "next-.,4a~C'~5) L~ the nezI slate after soun~J, au~C'z~)" Of 
%e.,.-s~u~C205) ~ the target o f  C2o.s"). then "say-about" will have to choo~ 
between the reafiz~tions on the basis either of  some stylistic criteria, For 
example whether one of the contained relations had been mentioned 
recently or ~me default (e.g. "sm~-~,~C'..0~"). Let us suppose for present 
purposes that the only phrase listed in dictionary for the next-state relation 
is the one from the first example, Le. 
Now. "say-about"s goal is a sentence that has S/DCL as its subje=. 
It can tell from the dictionary's annotauon and its English grammar that the 
phrase as it stands will not permit this since the verb "go to" does not 
passiviz?; however, the phrase is amenable to a kind of  deffiog 
transformation that would yield the text: "S/DCL L~ where C205 goe~ to'. 
"Say-about" arraogcs for this consu'uccion by building the structure below 
as its representation o f i~ decision, passing it on to .~R:),mu.: for realizatiou. 
Note ~at this structure :'- .,.,.,.,.,.,.,.,.,~sentialy a linguistic constituent structure of the 
.sual sort, describing the (annotated) surtace sU-ucture of dze intended text 
co the depth that "say-abouC' has planned it, 
60 
dllu~ 
\[sul~-ctl \[prmlte~ml 
\[rea~,~-~l \[wn.trac-I 
Figure Four:. the output of the "say-about" operator 
The ~nctional labels marking the constituent positions (i.e. 
"subject", "verb", ccc.) control the options for the realization of the 
domain-network objects they initially con=in. (The objects will be 
subscquendy replaced by the phrases that reafizc thcm. processing from leR 
to righc) Thus the first instance of  S/I)CI_ in the subject position, is 
realized without contextual effects as the name ".V/DCL": while the second 
instance, acting as the reladve pronoun fur the cleft, is realized as the 
interrogative pronoun "where": and the final instance, embedded within the 
"next-state" relation, is suprcsscd entirely even though the rest of the 
relation is expre.~cd normally. These cnutextoal variations are all entirely 
transparent o the dictionary mechanisms and demonstrate how we can 
increa~ the utility of  the phrases by carefully annotating them in the 
dictionary and using general purpose operations chat are ~ggered by the 
descriptions of the phrases alone, therefore not needing to know anything 
about their semant~ content. 
This example was of contextual effects that applied aRer the domain 
objects had been embedded in a linguistic structure, l.inguis~c ontext can 
have its effect eadier as well by monitoring the aecumuladon p~occ~ and 
appiyiog its effects at that level. Considering how the phrase for the jump 
are C2.05 would be fonned in this same example. Since the planner's 
original insmaction (i.e. "(say-abm,t_ )" did not mention C205 spccifcally, 
the description of that ubjec~ will be IeR to the default precis discussed 
earlier. In the original example, C205 was dc~ribed in issoladon, her= it L~ 
part of an ongoing dJscou~e context which muse be allowed ru influence the 
proton. 
The default description employed all three of  the domain-network 
relations that C205 is involved in. In this discourse context, however, one of  
those relations, "neat-smte(c2OS)=SIDCL". has already be given in the 
text: were we to include it in this realization of  C'205. the result would be 
garishly redundant and quite unnatural, i.e. "3/DCL ~ where the jump arc 
from S/NP Io S/DCL goes to". To rule out this realization, we can filterttm 
original set of three relations, eliminating the redundant relation bemuse we 
know that it is already mentioned in the CCXL Doing this en~ils (1) having 
some way to recognize when a relauon is already given in the text. and (2) a 
predictable point in the preec~ when the filtering can be done. rha  second 
is smaight fo~arcL the "describe-as" fimetion is the interface between the 
planner and the re',dization components; we simply add a cheek in t~t  
function to scan through the list of  relation-entries to bc combined and 
arrange for given relations to be filtered ouc. 
As fi)r the definition of "given". MUMBLE maintains a multi-purpose 
record of  the cunmnt discourse context which, like the dictionary, is a recta- 
level network describing the original speaker's network from yet this other 
point of view. Nlem-links connect relations in the speaker's network with 
the mics they currendy play in ~be ongoing discourse, as illustrated in figure 
five. l~te definition of "give n" in terms of properties defined by discou~e 
roles such as these in conjunction with hcuristics about how much of the 
earlier text i~ likcly to still be rcmcmbered. 
ureo.state 
. . . .  
Current  Discourse Conte~ ~s /ocL  ~,h~l , "  
current-clausJ he / 
ad(cu rront- relative-clause) subject(cu frent.sentence) 
Figure Four:  us ing the d iscourse-context  as a fi lter 
Once able to refer to a rich, linguistically annotated description of the 
context, the powers of the dictionary can be extended still further to 
incorporate contextually-triggered transformations to avoid stylistically 
awkward or ungrammatical linguistic combinations. This part of the 
dictionary design is still being elaborated, so l will say only what sort of 
effects are trying to be achieved. 
Consider what was done earlier by the "say-about' function: there 
the planner proposed to say Something about one object by saying a relation 
in which the object was involved, the text choosen for the relation being 
specially transformed to insure that its thematic subject was the object in 
question, in these situations, the planner decides to use the relatinos it does 
without any particular regard for their potential linguistic structure. This 
means that there is a certain potential for linguistic disaster. Suppose we 
wanted to use our earlier trio of relations about C205 as the basis of a 
question about S/DCI,; that is, suppose our planner is a program that is 
building up an augmented transition et in response to a description fed to 
it by its human user and that it has reached a point where it knows that 
there is a sub-network of the ATN that begins with the state S/DCI. but it 
does not yet know how that sub-network is reached. (This would be as if 
the network of figure one had the "unknown-state" in place of S/NP.) 
Such a planner would be motivated to ask its user: 
(what <state> is-.~Jeh-thnt next-state(C20S)=<state>) 
Realizing this question will mean coming up with a description of 
C205. that name being one made up by the planner ather than the user. It 
can of course be described in terms of its properties as already shown; 
however, if dais description were done without appreciating that it oecured 
in the middle of a question, it would be possible to produce the nonsense 
sentence: 
" where does the jump arc from lead to S/DCL?' 
Here the embedded reference to the "unknown-state" (part of the relation, 
"source-state(C205)=unknown-state") appearcd in the text as a rclative 
clause qualiF/ing the reference to "the jump arc". Buc because "unknown- 
state" was being questioncd the English grammar automatically suppressed 
iL This lead R) the nonsense result shown because, as linguists have noted, 
in English one cannot question a noun phrase out of a relative clause--that 
would be a violation of an "island constraint" C?. ~.. 
Tlle problem is, of course, that the critical relation ended up in a 
relative clause rather than in a different part of the sentence where is 
suppression would have been normal, It was not inevitable that the 
nonsense form was chosen; there are equally expressive ~ersions of the 
same content, e.g. "where does the jump arc to S/DCI. come from?', the 
problem is how is a planner who knows nothing about grammatical 
principles and does not maintain a linguistic description of the current 
context o know not to choose tile nonsense form when confronted with 
ostensibly synomous alternatives. The answer as \[ see it is that the selection 
should not be the planner's problem--that we can leave the job to the 
linguistic realization component which already maintains the necessary 
knowledge base. What we do is to make the violation of a grammatical 
constraint such ,as this one of the criteria for filtering out realizations when a 
dictionary entry provides several synonomous choices, \[n dais case, the 
choice was made by a general transformation already within the realization 
component and the alternative would be taken from a knowledge of 
linguistically equivalent ways to ajoin the relations. 
A grammatical dictionary filter like this one for island-constraintS 
could also be use for the maintaince of discourse focus or for stylistic 
heuristics uch as wheth(:r to omit a reducable verb. In general, any 
decision criteria that is common to all of the dictionary entries hould be 
amenable to being abstracted out into a mechanism such as this at which 
point they can act transparendy to the planner and thereby gain an 
important modularity of linguistic and conceptual/pragmatic cr teria. "\['he 
potential problems with this technique involve questions of how much 
information the planner can rcasenably be expected to supply the linguistic 
componenL The above filter would be impossible, for example, if the 
macro-entry where it is applied were not able to notice that the embedded 
description of C205 could mention the "unknown-state" before it 
committed itself to ),he overall structure of the question. The sort of 
indexing required to do this does not seem unreasonable to me as long as 
the indexes are passed up with the ground dictionary entries to the macro- 
entries. Exactly how to do this is one of the pending questions of 
implementation. 
61 
t ? ? 
The dictionaries of other production systems in the literature have 
typically been either trivial. ~,nconditionai object to word mappi.gs Cf3, 
C'~3 , orelse been encoded in uncxtcndable procedures CZ.3. A 
notable exception is the decision tree technique of\[goldman\] and as refined 
by researchers atthe Yale Artificial Intelligence Protect. The improvements 
of' the present echnique over decision trees (which it otherwise resembles) 
can be found (1) in the sophistication of its representation or" the target 
English phrases, whereby abstract descriptions of tile rhetorical and 
syntactic structure of the phrases may be manipulated by general rules that 
need not know anything about their pragmatic content: and (2) in its ability 
to compile decision criteria and candidate phrases dynamically for new 
objects or relations in terms of r.hc criteria and phrases from their generic 
descriptions. 
l'hc dictionary described in this paper is not critically dependent on 
the details of" the \[ingui'~tic reali~,.ation component or planning component i
is used in conjunction with. It is designed, however, to make maximum use 
or" whatever constraints ,nay be available f'n)m the linguistic context 
(broadly construed) or from parallel intentional goals. Consequcndy. 
componcnts that do not cmploy MI.'3,IBI.E'$ tc~hniquc of represcnting the 
planned and already spoken parts of. thc utterance explicitly along with its 
linguistic structure ,nay bc unable to use it optimally. 
References 
\[I\] Brachman (\]979) Rcseareh in Natural Language Understanding. 
Quarterly "\['echnicai Progress Rcport No. 7. \[k~It Beranek and 
Newman inc. 
\[2\] Davcy (1974) Discourse Production Ph.D. Dissertation. -Edinburgh 
University. 
\[3\] Goldman (1974) Compnter Generation of Natural I.anguage from a 
Deep Conceptual I'lase. memo AIM-247, Stanford Artificial 
Intelligence Laboratory. 
\[41 McDonald. D.I). (1980) \[.angu:tge Production as a Process of 
Decision-making Under Constraints. Ph.D. Di~cmttion. MIT, to 
appcar as a technical report from the MIT Artificial Intelligence Lab. 
\[5\] (in preparation) "1 .anguage Production in A.\]. - a review", 
manuscript being revised ,'or publication. 
\[6\] Ross (1%8) Constraints on Vari-lMes in Syntax. Ph.D. Dissertation, 
Mrr. 
\[7\] Swat,out (\]977) A Digitalis Therapy Advisor with F-xplanatlons Mastcr,J 
Dissertation, MIT. 
\[8\] Winograd 0.973) Understanding Natund language Academic Press. 
62 
