Degrees of Stativity: The Lexical Representation of 
Verb Aspect 
Judith L. Klavans and Martin Chodorow 
IBM T.J.Watson Research 
Yorktown Heights, NY 
and 
~Hunter College of the City University of New York 
Abstract 
L'acqnisition automatique de connaissance 
lexicale h partir de larges corpus s'est 
essentiellement oceup& des phfinom~nes 
de co-occurrence, aux dfipens des traits 
lexicaux inh~rents. Nous prfisentons ici 
une m&hodologie qui permet d'obtenir 
l'information sfimantique sur l'aspect du 
verbe en analysa~t automatiquement un
corpus et en appliquant des tests lin- 
guistiques h l'aide d'une stifle d'outils 
d'anrdyse structura\]e. Lorsque ces deux 
t~:hes sont accomplies, nous proposons 
une rfipresentation de l'aspect du verbe 
qni associe une valeur de mesure pour les 
difffirents types d'fiv~nements. Les mesures 
zefl~tent l'usage typique du verbe, et par 
consfiquent une mesure de rfisistance ou 
de non-r~sistance h la coercion dans le 
eontexte de la phrase. Les rfisultats que 
nous rapportons ici ont fitfi obtenus de 
deux mani~res: en extrayant l'information 
n&essrSre h partir du corpus &iquetfi de 
Francis and Ku~era (1982), et en fais~nt 
tourner un analyseur syntaxlque (MeCord 
1980, 1990) sur le corpus du Reader's Di- 
gest afin d'extraire une information plus 
pr&ise sur l'usage du verbe dans le texte. 
Notre travail iUustre deux aspects: 
1. Les ptopri6t6s lexicales inh6rentes 
peuvent fitre dfitermin&s en appli- 
qurmt aux textes une s&ie de tests 
llngnistiques bien &ablis. Cela donne 
l'analyse de corpus une dimension 
suppl~mentaire qui va au-delh des 
ph~nom~nes de coocurrence (eomme 
par example information mutuelle, 
substitutabilitfi). 
2. Une propri~t~ lexieale n'a pas be- 
soin d'etre discrete mats peut &re 
repr~sent~e en tant que valeur ~ in- 
terprdter comme une tendance ou 
probabilitY; de cette mani~re, \]e oh- 
.jet lexieal exprime la propri~t~ donn~e 
darts un contexte non-marqu& Les 
valeurs der/v~es du corpus sont vari- 
ables, e'est-h-dire des valeurs h degr~s. 
Des tests linguistiques ont &~ automa- 
tiquement appliques aux corpus analys~s 
de mani~re k d&erminer la valeur initiale 
de l'aspect pour la stativit~, et ce, pour un 
ensenble de verbes frequents, repr~sentant 
plus de 90% des occurrences de verbes dans 
un corpus d'un million de roots. 
ACTES DE COLING-92, NArTr~. 23-28 AOl~r 1992 1 1 2 6 PROC. OF COLING-92. NANTES, AUG. 23-28, 1992 
Degrees of Stativity: The Lexical Representation f Verb Aspect 
Judith L. Klavans and Martin Chodorow t 
IBM T.J.Watson Research 
Yorktown Heights, NY 
amd 
~Hunter College of the City University of New York 
Abst ract  
The automatic acquisition of lexiced knowledge 
from large corpora has dealt primarily with 
coocurrence phenomena, t the expense of inher- 
ent lexic~l features. We present here u method- 
ology for obtaining semantic information on verb 
aspect by parsing a corpus and automatically up- 
plying linguistic tests with a set of structural anal- 
ysis tools. Once applied, we propose a represen- 
tation for verb aspect hat associates a value with 
weights for event types. Weights reflect typical 
verb use, and thus represent a measure of the resis- 
tance or ease of coercion in sentential context. The 
results we report here have been obtained in two 
ways: by extracting relevant information from the 
tagged Brown corpus (Francis and Ka~era 1982), 
and by running ~ parser (McCord 1980, 1990) on 
the Reader's Digest corpus to extract more accu- 
rate information on verb usage in text. 
1 Overv iew 
Our work illustrates two points: 
1. Inherent lexical properties can be deterufined 
by applying a battery of established hnguistic 
tests to corpora~ This adds to the utility of 
corpus analysis a dimension beyond coocnr- 
fence phenomena (e.g. mutual information, 
substitutability). 
2. A \]exical property need not be discrete bat 
can be represented as a value to be inter- 
preted as a tendency or probability for the 
lexical item to exhibit the given property in 
an unmarked context. Corpus-derived values 
are variable, i.e. DEGREE ValU~ 
Linguistic tests have been automatically applied 
to parsed corpora to determine an initial aspectual 
value for stativity for u set of frequent verbs, cov- 
eting over 90% of verb occurrences in a one million 
word corpus. 
2 Event  types  
Aspect can be informally defined as a property 
which reflects the temporal organization of an 
event, such as duration (whether an event involves 
change over time), telicity (whether it has a defi- 
nite endpoint or is ongoing), iteratlvlty (whether 
or not it is repetitive) and so on (see Comrie 1976.) 
We assume three event types, following Vendler 
1967, refined by many others, and recently re- 
cast from the perspective of computational lexicon 
building by Pastejovsky 1991, and Pustejovsky 
and Boguraev (to appear) 1: 
S ta te (S) :  knon, resemble, b~, l ove  
Process(P) :  run,  walk, eviM 
Trans i t ion(T) :  g ive ,  open, bu i ld ,  dest roy  
A verb can enter into u construction which may 
change the overall phrasal or sentential event 
structure, as ttte result of event-coercion. Coer- 
cion can be defined as the process by which verbs 
in context appear to demonstrate some regular 
ambiguities, i.e. they appear to change categories. 
Pustejovsky argues that u verb is inherently (lex- 
fealty) specified as being of a certain event type 
(e-type). 
Schema: e- type(Verb)  - SIPIT 
e- type(reeenb le)  ~ S 
e- type( run)  ~ P 
e-type(give)  - T 
Figure One 
INolice that accomplishment verbs (e.g. ~palnt ? pie- 
ture"), and Itchleveme, t veltbw ("reach a goM") are both 
considered tr~neition verbi, 
AcrEs DE COLING-92. NANIJ?S. 23-28 AO~I 1992 1 1 2 7 PnOC. OF COLING-92, NAhrrgs, AUG. 23-28, 1992 
We call this the NON-DEGREE APPROACH, since 
there is no degree specified. Our claim is that, 
rather than the representation in Figure One, the 
event structure is a vector of values, e-type (Verb) 
= (S,P,T). We deal here only with the statics/non- 
statics distinction, since there are regular differ- 
ences between states versus activities and accom- 
plishments (Lakoff 1965). We propose a simplified 
representation e-type(Verb)=Vo(x) with a single 
value for stativity, Vs, the non-statics value being 
merely the complement, i.e. 1I, + V~s = 1. Our 
position can be summarized as: 
Schema: e-type(Verb) ~ Vs(Z) 
where 0 < Vs(X)< 1 and 
nhore VH + V~s = 1 . 
Figure T~o 
We call our position the DEGREE APPROACH 
since a numeric value or DEGREE iS specifted. We 
agree with the notion of assuming basic verb types, 
with coercions, rostra the position proposed by 
Dowry 1979 that there be different entries for dif- 
ferent usages. 
To allow the process interpretation i  sentences 
like: 
(i) The chi ld iv being a fool  today. 
(2) She i~ resembling her mothez 
more and more each day. 
the phrase "more (and more)" in (2), a temporal 
expression, acts to "coerce" or force a non-stative 
event (in this case a process). ~ In fact, the verb 
"be", often touted as fundamentally the most sta- 
tics verb in the language is frequently coerced into 
process and transition. 
3 Computational Lexicons 
The work reported here is part of an ongoing 
project in the bexical Systems Group at IBM Re- 
search to extract and represent lexical knowledge 
in CompLex, a computational lexicon which will 
be able to provide information to natural language 
processing systems. The seeds of this project are 
presented in Klavans 1988, where it is argued that 
the building of a computational lexicon requires 
~Our position might be viewed in terms of ~signing 
probabilities tothe arc tranmltions in ~ system luck as that 
proposed by Moths and Steedman 1988, in which coercions 
~re recursive but carefully constrained along several key pa- 
r~neters defining possible transitions within a finite-state 
trtmsition etwork. 
mapping of resources into a common central lexi- 
cat datu base, rather than being dictionary bound. 
The view is further expanded in Byrd 1989. Puste- 
jovsky and Boguraev (to appear) argue that a the~ 
ory of lexlcal semantics making use of a knowl- 
edge representation framework offers an expressive 
vocabulary for the representation f such lexical 
information. They outline a concrete framework 
consisting of four levels of lexlcal meaning: (1) Ar- 
gument Structure; (2) Event Structure; (3) Quails 
Structure; and (d) Lexical Inheritance Structure. 
Pustejovsky 1991 provides formal details of the 
event structure specification for verbs, with a for- 
real explanation of semantic type coercion. 
Specification of verb and phrasal aspect mat- 
ter to NLP systems in several ways. For example, 
when a stative verb is used in the present ense, 
it involves only one occasion of the event. In con- 
trust, a non-stative usage involves a frequentative, 
iterative, or repetitive interpretation. Thus: 
John knous the answers. ( s ing le)  
John runs. ( repet i t i ve )  
Sue builds houses. ( repet i t i ve )  
It is necessary to understand the interpretation f 
statlvity for several reasons. In language genera- 
tion, adverbial adjuncts which have a durational 
interpretation are, under most circumstances, dis- 
allowed: 
*John knew the answers for  three days. 
John ran for  three hours. 
Sue bu i l t  houses for  three decades. 
For text analysis, if a verb which is usually stative 
is used with a non-statlve adverb, such as "de- 
liberately", it can be inferred that the event is 
non-stative, and not the reverse. If the event is 
non-statics, then it can be inferred that it could 
be a repetitive or iterative vent. This can effect 
not only the semantic interpretation of the text it- 
self, but also translation and the choice of adverb. 
3 
3Many of these issues are discussed in the CL Special 
Issue on Tense and Aspect (June, 1988) in articles by Hin- 
niche, Moens and Steedman, Nakhimovsky, Passoneau, and 
Webber. For example, Passoneau demonstrates how, with- 
out an ~ccurate specification f the ~pectual tendencies 
of the verb coupled with the effect of temporal nd aspec- 
tual adjuncts, messages, which tend to be in the present 
tense, ttre not correctly understood nor generated in the 
PUNDIT system. For instance, "the pressure is low" must 
be interpreted at statlve, whereas "the pump operates" 
must be interpreted as a process. In machine translation, 
for example, the verb parecerse meaning 'to resemble one 
another' is even leHs statics in Spanish than in English. 
Thus, sentence (2) above should be translated into Spanish 
ACRES DE COLING-92, NAntES, 23-28 AO'dr 1992 1 1 2 8 PRec. OF COLING-92, NANTES. AUG. 23-28, 1992 
Aspect is complex. Stativity is not u simple 
feature such as an imate(+/ - ) .  To ob . . . . .  this, 
it suffices to look in any comprehensive grammar, 
for example, Quirk et al 1972, in wtfich lexieal 
verbs are divided into the classes "dynamic" and 
"stative", with the caveat hat "it would be more 
accurate to speak of 'dynamic' and "stative' uses 
of verbs" (p. 94-95). Dowty 1979 observes that the 
issue of interpretation and aspect involves " the 
thorny problems of polysemy and honrophony"(p. 
62). Since some verbs are "more statlve" than 
others, meaning that the most common unmarked 
use is as a marker of sentential or event stativity, 
the lexicon must embody this lexieal fact. Our 
proposal provides the capability in the lexicon of 
representing that variability, combined with auto- 
matic means of inducing variability values. 
4 Procedure  
Some standard tests for the stative/nou-statlve 
distinction are given in Dowty 1979, such 
as the progressive, imperative, cmnplement of 
force/persuade, intentionM adverbs, and pseudo- 
cleft, as in: 4 
Progress ive : non-s ta t ives  
* John is kneeing the anuuer. 
John in running. 
John in building s house. 
Complement of force/persuadu:  
* flail forced John to know the ansner. 
flail pursuadud Amy to run. 
John forced Bi l l  to bui ld a house, 
Adverbs, e-g- de l iberate ly ,  carufu l ly :  
* Gull do l iburatu ly  knou the anBeer. 
Evelyn ran care fu l ly .  
Sue care fu l ly  bu i l t  a house. 
Even though tests for stativity involve interactions 
between semantic and syntactic facets of a sen- 
tence, we have chosen three tests for stativlty, the 
most robust being the tendency for a verb to occur 
in the progressive. Unlike other tests, the progres- 
sive itself is a statement of duration and process. 
We hypothesized that degree of stativity, i.e. a 
value for stativity Vo, conld be inferred by deter- 
mining the ratio of total frequency of occurrence 
of a verb in a progressive usage, past or present, 
in the simple present, not the progre,mive, a~i*t EngllJh. 
eada d~a . l l a  se parsee I~s  a ?~ ~dre .  
For activity verbs, the progressive in EngliJh translates to 
the progressive in SpalfiJh. 
4 Activltes and accompllshmentl aresubject to other dim- 
tinguilhing tests which are not the wubject of this paper. 
over its frequency as a verb in the same corpus: 
F(Verb(X) 
whore 0 < V, < 1 
A value closer to 0 indicates that a verb prefers ta- 
tivlty. \]'his basic value can be modified by other 
tests, such the force/persuade test, and the delib- 
erately/carefully test. 
We are aware that this is an overMmplificatlon 
of the property of stativity. Ilowever, our goal is 
to search for the most robust and pragmatically 
possible tests to start with. Our technique has 
given results which concur with our intuitions, al- 
though there are limitations discussed below, s In 
order to do this, we needed u text tagged for part 
of speech. Otherwise, instances uch as "hear- 
ing aid", '% knowing look" would be taken as in- 
stances of progressive verbs. 
5 Resu l ts  
Tagged Ku~era and Francis Data 
The Brown corpus  provided a convenient s arting 
point, since words are tagged for part of speech. 
ltowever, a closer look at the tag set itself reveals 
a weakness which could bias our results. The 
tag VBG is used to tag "verb, present partici- 
ple, and gerund." Thus, there is no distinction 
in the label for the different usages of the "-ing" 
form, although some "-ing" forms are labelled NN 
for noun or JJ for adjective. Despite this prob- 
lem, we chose to use the Brown data, knowing 
that the numbers aright be distorted. We started 
with a list of the 100 most frequent words la- 
belled as verbs (i.e. the 100 most frequent verbs, 
which account for over 90verbs which have been 
discussed in the literature on stativity (such as 
"resemble", "matter", "intend"). Figure Three 
lists some results, ordered by degree of stativity. 
e - type( t ry )= Vs(.3326) 
u-type(work)= V0(.3064) 
e - typu(n i t )= V,(.2929) 
u-type(run)= V, (.2853) 
e - typu(p lay) -  Vs(.2552) 
aPustejovsky, personM communication, hem pointed out 
some problem cases where the progressive fMsely indicates 
that root is non-Jtative, such as lie/sit verbs (The book is 
lying on the shelf, The c~p is sitting on the cownteO, and 
mental attitude verbs (John il thinking that he should 90 
home now, Sdohn is knowing that he should go home note, 
Marll is suspecting that John will propose tonight. ) Such 
problemt van be rewolved by fine-tuning testJ. 
?We thank Slav~ Kate for pointin\[ us to this resource. 
ACTES DE COLING-92, NANTES, 23-28 AOt~V 1992 1 1 2 9 PROC. OF COLING-92, NANTES, AUO. 23-28, 1992 
e-type(move)= Vs(.2326) 
e - type(go)= 11,(.2304) 
e - type( fo l low)= V,(.1234) 
e - type(g ive)= V,(.0783) 
e-type(become)= V,(.0718) 
e - type(hoar )= V,(,0669) 
e- type(~ee l )= V,(.0637) 
e-type(uppettr)= V,(.0481) 
e-type(know)= 1/',(.0332) 
e - type(vent )= V,(.0253) 
e- type(need)= Vw(.0197) 
e - type(be)= V,(.0173) 
e- type(eeem)= V,(.Ol20) 
Figure Three 
As can be seen, the ranking roughly reflects in- 
tuitions about stativity, so, for example, seem is 
more stative than hear ,  which is in turn more st~ 
tire than run .  
Pars ing  w i th  Eng l i sh  S lo t  Grammar  
The second more refined method utilizes a parser 
to analyze text, and to record verb usages. For this 
purpose, we used the English Slot Grammar (Me- 
Cord 1980, 19901 a broad-coverage parser writ- 
ten in PKOLOG. 7 To obtain counts of verb us- 
ages from the representations produced by ESG, 
we used a tool for querying trees (QT), built by 
the second author, also in PROLOG. The cor- 
pus is the Reader's Digest (RD) corpus, consist- 
ing of just over one million words. We took the 
same llst of the 115 most frequent and most fre- 
quently discussed verbs that was used for ob- 
taining values from the Brown corpus. We ex- 
tracted all sentences under 30 words containing 
the inflectional variants of these verbs from the 
RD corpus. We then ran the parser on this sub- 
corpus, ran QT, and obtained values for the dif- 
ferent verb usages. Unlike the Brown data, dis- 
tinctions are made between the gerundive and 
participial usages. Figure Four gives results for 
some verbs, listed in the same order as in Figure 
Three, with n indicating the number of tokens: 
e - type( t ry )= V,(.2167) (n = 286) 
e - type(york)= V,(.1311) (n ffi 244) 
e-type(s i t )= Vs(.1506) (n = 146) 
e-type(run)= V,(.1565) (n = 230) 
e- type(p lay)= V,(.2315) (n = 95) 
e-type(move)= V,(.0798) (n = 2131 
TAn exception to the quality it imperatives, **here there 
were some errors in the parsing; they were removed from 
our cMculationt. 
e - type(go)= 1I,(.2901) (n = 107t) 
e - type( fo i le r )= 1I,(.0375) (n = t33) 
e - type(g ive)= V,(.0209) (n = 430) 
e-type(become)= V,(.0507) (n = 493) 
e - type(hear )= V,(.OO00) (n = 242) 
o - type( fee l )= V,(.0317) (n = 315) 
e-type(uppenm)= V,(.0272) (n = 147) 
e- type(knov)= V,(.OOO0) (n = 630) 
e- type(want)= V,(.0000) (n = 466) 
o-type(need) = V,(.O000) (n = 258) 
e-type(be)= V,(.0124) (n = 12482) 
e-type(seem)= V,(.0000) (n = 260) 
Figure Four 
Additional Syntactic Tests 
The progressive test is only one of several tests, 
and in and of itself is certainly inadequate. Sev- 
eral tests mast be run, and then event values must 
be computed for each linguistic test. Two param- 
eters are involved: the strength of each test as an 
indicator of e-type, and the sparsity of data. 
We have preliminary results on two tutditional 
tests: the force/persuade t st and the deliber- 
ately/carefully test. Synonyms and taxonyms 
were collected for each (ad)verb, data were ex- 
tracted frmn the corpus and parsed. For example, 
the following shows how a sentence with "force" 
was analyzed. However, more datais  needed, from 
a larger corpus, for the results to be significant. 
The same applies for the adverb test. 
D i f f i cu l t iue  forced him to abandon . . .  
verb( fo rce)  inf_ camp_verb (abandon) 
Figure Five - Verb "Force" 
Results of running and computing the weights of 
different tests on larger corpora will be reported 
in future publications. 
6 D iscuss ion  
As expected, the results from each corpus dif- 
fer considerably; we believe this is due primarily 
to surface tagging vs. full parsing. The results 
from the second method using ESG do not carry 
the noise from the ambiguous VBG tag from the 
Brown corpus. However, there are two important 
points to be made: (1) One million words is simply 
not enough. More data need to be (and will be) 
run to get a more complete and accurate count. 
These are to be viewed as preliminary data, us~ 
able but not complete. (2) The value V,(.0000) 
AcrEs DF.COLING-92, NANTES, 23-28 Aour 1992 l 1 3 0 PREC. OV COL1NG-92, NANTES, AUG. 23-28, 1992 
cannot be considered categorical. Verbs are gen- 
erally adaptable in context, s It is a known fact 
that value* either for words with low frequencies 
or words in low frequency constructions must be 
computed on very large corpora (Liberman 1989.) 
The current limitations of this approach must 
be clearly stated. First of all, this method con- 
rates the polysemons usages of certain verbs and, 
in English, of the verb-particle construction. It 
could be argued that with enough corpus data, 
this would become unimportant, but we believe 
this position not correct. What is required is a 
fuller analysis of adjuncts in order to know if n 
verb has been coerced. For example, it could 
be the case that a verb which is S in the an- 
marked case (i.e. in a neutral context) tends to 
appear as a T verb frequently, since that verb 
might not occur frequently in a null context at 
all. As another example, consider the case of a 
typical stative verb "know". With the object "an- 
swer", "know" becomes typically inchoative, e.g. 
"know the answer by tomorrow" meaning "be- 
come knowledgeable of the answer", or it could 
be used in the transition sense, e.g. "he will know 
the answer by tomorrow" meaning "he does not 
know now and will know then." Thus, it could 
be underlying semantic structure, and not sur- 
face syntactic behavior, that determines coercion 
possibilities. 9 In conclusion, The DEGREE AP- 
PROACH captures the fact that verbs have degrees 
of e-type, i.e. that some verbs are more pliable 
than others. Thus, rather than the non-degree 
values in Figure One, we argue for entries like: 
e -eype( reeeab lo )  = V,(.0740) 
e - typo(go)  = V#(.2304) 
e-type(seem)= V,(.012O) 
A corpus-breed method can be used to antomatl- 
cally derive values for e-type, i.e. under n certain 
cut-off, the verb is stative, but alternbh in con- 
text. More importantly, it gives a degree of likeli- 
hood that given any context, the verb will be used 
statively or non-statively. 
*This is a tact which any semanticist who is trying to 
argue a firm point can at*el* to. 
tAho, there appear to be some clashes on the resulting 
values and intuitions, thus leading to the suggeJtion that 
either our intuitions are not correct or that the method it 
unreliable. We have not, in fact, addressed the issue of 
underlyin~ semantic representation (e.g. in terms of prim. 
itivea) in this paper. It has been suggested that syntactic 
tests \[or aspect might be flawed, and that the only way 
to distinguish aspectual c asses it via the semantic onse- 
quences ot a restive vs. non0tative proposition. If correct, 
the approach of extracting values based on syntactic tests 
will fail by definition, regardless of whether the value, are 
assigned manually or automatically. 
7 References  
1. Byrd, Roy. 1989. "Discovering Relationships 
unsung Word Sense*", Dictionaries in the Elec- 
tronic Age: Proceedings of the Fifth Annual Con- 
Jerenec o\] the University of Waterloo Centre \]or 
the New Oxford English Dictionary 
2. Comrie, Bernard 1976. Aspect. Cambridge 
University Press: Cambridge, English. 
3. Dowry, David. 1979. Word Meaning and Mon. 
*ague Grammar. Dordrecht: tlolland. 
4. Francis, W. Nelson and Henry Ku6era. 1982. 
Frequency Analysis of Enlglish Usage: Lexicon 
and Grammar. t longhton Mifflin: Boston. 
5. Klavaas, Judith L. (1988) "Building a Corn- 
puts*loaM Lexicon using Machine Readable Dic- 
tionaries", Proceedings of the Third International 
Congress of the European Association for Lexicog- 
raphy. Budapest, Hungary. 
6. Lakoff, George. 1965. "On the Nature of 
Syntactic Irregularity", PhD Dissertation, Depart- 
meat of Linguistics. Indiana University: Bloom- 
ingtoa, Indiana. 
7. Liberman, Mark. 1989. "How Many Words Do 
People Know?" Invited Talk delivered at the 27th 
Annus.l Meeting of the Association for Compata~ 
*tonal Linguistics. Vancouver, B.C., Canada. 
8. McCord, M. C. 1980. "Slot Grammars" Com- 
putational Linguistlcs, Vol 6:31-43. 
9. MeCord, M. C. 1990. "SLOT GRAMMAR: 
A System for Simpler Construction of Practi- 
cal Natural Language Grammar*," in R. Sender 
(Ed.), International Symposium on Natural Lan- 
guage and Logic, Lecture Notes in Computer Sci- 
ence, Springer Verlag. 
10. Moensp Marc and Marc Steedman. 1988 
"Temporal Ontology and Temporal Reference" 
Computational Linguistics. Vol. 14:2:15-28. 
11. Pustejovsky, James. 1991. "The Syntax of 
Event Structure" Cognition Vol. 41:103:47-82. 
12. Pustejovsky, James and Bran Bognrnev. to 
appear. "Lexical Knowledge l~.epreaentation a d 
Natural Language Processing" IBM Journal of 
Research and Development. 
13. Quirk, Randolph, Sidney Greenbaum, Geof- 
frey Leech, Jan Svartvik. 1972. A Comprehen- 
sive Grammar of the English Language, Longman: 
London. 
14. Teany, Carol Lee. 1987. "Grnmmatlcalizing 
Aspect and Affectedness", PhD Dissertation, De~ 
par*men* of Linguistics. M.I.T., Cambridge: Mas- 
sachusetts. 
15. Vendler, Zeno. 1967. Linguistics iu Philoso. 
phy, Coruell University Press: Ithaca, New York. 
ACTES DE COLING-92, NAgrES, 23-28 ho~rr 1992 1 1 3 1 PROC. oF COLING.92, NANTES. AUG. 23-28, 1992 
