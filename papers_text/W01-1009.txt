Gathering Knowledge for a Question Answering System from
Heterogeneous Information Sources
Boris Katz and Jimmy Lin and Sue Felshin
MIT Articial Intelligence Laboratory
200 Technology Square
Cambridge, MA 02139
fboris, jimmylin, sfelshing@ai.mit.edu
Abstract
Although vast amounts of information
are available electronically today, no ef-
fective information access mechanism ex-
ists to provide humans with convenient
information access. A general, open-
domain question answering system is a
solution to this problem. We propose an
architecture for a collaborative question
answering system that contains four pri-
mary components: an annotations sys-
tem for storing knowledge, a ternary ex-
pression representation of language, a
transformational rule system for han-
dling some complexities of language, and
a collaborative mechanism by which or-
dinary users can contribute new knowl-
edge by teaching the system new infor-
mation. We have developed a initial pro-
totype, called Webnotator, with which to
test these ideas.
1 Introduction
A tremendous amount of heterogenous informa-
tion exists in electronic format (the most promi-
nent example being the World Wide Web), but the
potential of this large body of knowledge remains
unrealized due to the lack of an eective informa-
tion access method. Because natural language is
the most convenient and most intuitive method
of accessing this information, people should be
able to access information using a system capa-
ble of understanding and answering natural lan-
guage questions|in short, a system that com-
bines human-level understanding with the infal-
lible memory of a computer.
Natural language processing has had its suc-
cesses and failures over the past decades; while the
successes are signicant, computers will not soon
be able to fully process and understand language.
In addition to the traditional di?culties associ-
ated with syntactic analysis, there remains many
other problems to be solved, e.g., semantic inter-
pretation, ambiguity resolution, discourse model-
ing, inferencing, common sense, etc. Furthermore,
not all information on the Web is textual|some
is sound, pictures, video, etc. While natural lan-
guage processing is advanced enough to under-
stand typical interactive questions about knowl-
edge (interactive questions are typically fairly sim-
ple in structure), it cannot understand the knowl-
edge itself. For the time being, therefore, the
only way for computers to access their own knowl-
edge is for humans to tell the computers what the
knowledge means in a language that the comput-
ers can understand|but still in a language that
humans can produce. A good way to accomplish
this is with the use of natural language annota-
tions, sentences which are simple enough for a
computer to analyze, yet which are in natural hu-
man language. Once knowledge is so annotated,
and indexed in a knowledge repository, a question
answering system can retrieve it.
The Start (SynTactic Analysis using Re-
versible Transformations) Natural Language Sys-
tem (Katz, 1990; Katz, 1997) is an example of a
question answering system that uses natural lan-
guage annotations. Start is a natural language
question answering system that has been available
to users on the World Wide Web
1
since Decem-
ber, 1993. During this time, it has engaged in
millions of exchanges with hundreds of thousands
of people all over the world, supplying users with
knowledge regarding geography, weather, movies,
corporations, and many many other areas. De-
spite the success of Start in serving real users,
its domain of expertise is relatively small and ex-
panding its knowledge base is a time-consuming
task that requires trained individuals.
We believe that the popularity of the Web may
oer a solution to this knowledge acquisition prob-
lem by providing collaborative mechanisms on a
scale that has not existed before. We can poten-
tially leverage millions of users on the World Wide
1
http://www.ai.mit.edu/projects/infolab
Web to construct and annotate a knowledge base
for question answering. In fact, we had proposed
a distributed mechanism for gathering knowledge
from the World Wide Web in 1997 (Katz, 1997),
but only recently have we attempted to implement
this idea.
An advantage of natural language annotations
is that it paves a smooth path of transition as nat-
ural language processing technology improves. As
natural language analysis techniques advance, the
annotations may become more and more complex.
Eventually, a textual information segment could
be its own annotation; someday, through other
technologies such as speech and image recognition,
etc., annotations could even be automatically con-
structed for non-textual information.
A further advantage is that natural language
annotations can be processed via techniques that
only partially understand them|via IR engines,
or less-than-ideal natural language systems|yet
they retain their more complex content and can be
reanalyzed at a later date by more sophisticated
systems.
2 Overview
We propose a collaborative question answering ar-
chitecture composed of the four following compo-
nents:
1. Natural Language Annotation is a tech-
nique of describing the content of informa-
tion segments in machine parsable natural
language sentences and phrases.
2. Ternary Expressions are subject-relation-
object triples that are expressive enough
to represent natural language, and also
amenable to rapid, large-scale indexing.
3. Transformational Rules handle the prob-
lem of linguistic variation (the phenomenon
in which sentences with dierent surface
structures share the same semantic content)
by explicitly equating representational struc-
tures (derived from dierent surface forms)
that have approximately the same meaning.
4. Collaborative Knowledge Gathering is a
technique by which the World Wide Web may
be viewed not only as a knowledge resource,
but also a human resource. The knowledge
base of a question answering system could be
constructed by enlisting the help of millions
of ordinary users all over the Web.
3 Annotations
Natural language annotations are machine-
parsable sentences or phrases that describe the
content of various information segments. They de-
scribe the questions that a particular segment of
information is capable of answering. For example,
the following paragraph about polar bears:
Most polar bears live along the northern
coasts of Canada, Greenland, and Russia,
and on islands of the Arctic Ocean. . .
may be annotated with one or more of the follow-
ing:
Polar bears live in the Arctic.
Where do polar bears live?
habitat of polar bears
A question answering system would parse these
annotations and store the parsed structures with
pointers back to the original information segment
that they described. To answer a question, the
user query would be compared against the anno-
tations stored in the knowledge base. Because this
match occurs at the level of ternary expressions,
structural relations and transformation (to be dis-
cussed in Section 5) can equate queries and anno-
tations even if their surface forms were dierent.
Furthermore, linguistically sophisticated machin-
ery such as synonymy/hyponymy, ontologies, can
be brought to bear on the matching process. If a
match were found, the segment corresponding to
the annotation would be returned to the user as
the answer.
The annotation mechanism we have outlined
serves as a good basis for constructing a question
answering system because annotating information
segments with natural language is simple and intu-
itive. The only requirement is that annotations be
machine parsable, and thus the sophistication of
annotations depends on the parser itself. As natu-
ral language understanding technology improves,
we can use more and more sophisticated annota-
tions.
In addition, annotations can be written to de-
scribe any type of information, e.g., text, im-
ages, sound clips, videos, and even multimedia.
This allows integration of heterogenous informa-
tion sources into a single framework.
Due to the vast size of the World Wide Web,
trying to catalog all knowledge on the World Wide
Web is a daunting task. Instead, focusing on
meta-knowledge is a more promising approach to
building a knowledge base that spans more than a
tiny fraction of the Web. Consider that reference
librarians at large libraries obviously don't know
all the knowledge stored in the reference books,
but they are nevertheless helpful in nding infor-
mation, precisely because they have a lot of knowl-
edge about the knowledge. Natural language anno-
tations can assist in creating a smart \reference
librarian" for the World Wide Web.
4 Representing Natural Language
A good representational structure for natural lan-
guage is ternary expressions.
2
They may be in-
tuitively viewed as subject-relation-object triples,
and can express most types of syntactic relations
between various entities within a sentence. We be-
lieve that the expressiveness of ternary relations
is adequate for capturing the information need of
users and the meaning of annotations. For ex-
ample, \What is the population of Zimbabwe?"
would be represented as two ternary expressions:
[what is population]
[population of Zimbabwe]
Ternary expressions can capture many rela-
tionships between entities within a sentence.
Such a representational structure is better than
a keyword-based scheme which equates a doc-
ument's keyword statistics with its semantic
content. Consider the following sets of sen-
tences/phrases that have similar word content,
but (dramatically) dierent meanings:
3
(1) The bird ate the young snake.
(1
0
) The snake ate the young bird.
(2) The meaning of life
(2
0
) A meaningful life
(3) The bank of the river
(3
0
) The bank near the river
Ternary expressions abstract away the linear or-
der of words in a sentence into a structure that is
closer to meaning, and therefore a relations-based
information access system will produce much more
precise results.
We have conducted some initial information re-
trieval experiments comparing a keyword-based
approach with one that performs matching based
on relations
4
. Using Minipar (Lin, 1999), we
parsed the entire contents of the Worldbook En-
cyclopedia and extracted salient relations from
it (e.g., subject-verb-object, possessives, prepo-
sitional phrase, etc.) We found that precision
2
See (Katz, 1990; Katz, 1997) for details about
such representation in Start.
3
Examples taken from (Loper, 2000)
4
to be published
for relations-based retrieval was much higher than
for keyword-based retrieval. In one test, retrieval
based on relations returned the database's three
correct entries:
Question: What do frogs eat?
Answer:
(R1) Adult frogs eat mainly insects and
other small animals, including earthworms,
minnows, and spiders.
(R4) One group of South American frogs
feeds mainly on other frogs.
(R6) Frogs eat many other animals, includ-
ing spiders, ies, and worms.
compared to 33 results containing the keywords
frog and eat which were returned by the keyword-
based system|the additional results all answer a
dierent question (\What eats frogs?") or other-
wise coincidentally contain those two terms.
Question: What do frogs eat?
Answer:
. . .
(R7) Adult frogs eat mainly insects and
other small animals, including earthworms,
minnows, and spiders.
(R8) Bowns eat mainly other sh, frogs,
and craysh.
(R9) Most cobras eat many kinds of animals,
such as frogs, shes, birds, and various small
mammals.
(R10) One group of South American frogs
feeds mainly on other frogs.
(R11) Cranes eat a variety of foods, includ-
ing frogs, shes, birds, and various small
mammals.
(R12) Frogs eat many other animals, includ-
ing spiders, ies, and worms.
(R13) . . .
Another advantage of ternary expressions is
that it becomes easier to write explicit transfor-
mational rules that encode specic linguistic vari-
ations. These rules are capable of equating struc-
tures derived from dierent sentences with the
same meaning (to be discussed in detail later).
In addition to being adequately expressive for
our purposes, ternary expressions are also highly
amenable to rapid large-scale indexing and re-
trieval. This is an important quality because
a large question answering system could poten-
tially contain answers to millions of questions.
Thus, compactness of representation and e?-
ciency of retrieval become an important consid-
eration. Ternary expressions may be indexed and
retrieved e?ciently because they may be viewed
using a relational model of data and manipulated
using relational databases.
5 Handling Linguistic Variation
Linguistic variation is the phenomenon in which
the same meaning can be expressed in a variety
of dierent ways. Consider these questions, which
ask for exactly the same item of information:
(4) What is the capital of Taiwan?
(5) What's the capital city of Taiwan?
(6) What is Taiwan's capital?
Linguistic variations can occur at all levels of
language; the examples above demonstrate lexical,
morphological and syntactic variations. Linguistic
variations may sometimes be quite complicated,
as in the following example, which demonstrates
verb argument alternation.
5
(7) Whose declaration of guilt shocked the
country?
(8) Who shocked the country with his dec-
laration of guilt?
Transformational rules provide a mechanism to
explicitly equate alternate realizations of the same
meaning at the level of ternary expressions.
As an example, Figure 1 shows a sample trans-
formational rule for (7) and (8).
6
Thus, through
application of this rule, question (7) can be
equated with question (8).
[n
1
shock n
2
] [n
3
shock n
2
]
[shock with n
3
] $
[n
3
related-to n
1
] [n
3
related-to n
1
]
where n 2 Nouns where n 2 Nouns
Figure 1: Sample Transformational Rule
Transformational rules may be generalized by
associating arbitrary conditions with them; e.g.,
verb 2 shock, surprise, excite : : :
A general observation about English verbs is
that they divide into \classes," where verbs in
the same class undergo the same alternations.
For example, the verbs `shock', `surprise', `excite',
etc., participate in the alternation shown in Sen-
tence (7) and (8) not by coincidence, but because
5
Beth Levin (Levin, 1993) oers an excellent treat-
ment on English verb classes and verb argument al-
ternations.
6
This rule is bidirectional in the sense that each
side of the rule implies the other side. The rule is
actually used in only one direction, so that we canon-
icalize the representation.
they share certain semantic qualities. Although
the transformational rule required to handle this
alternation is very specic (in that it applies to a
very specic pattern of ternary expression struc-
ture), the rule can nevertheless be generalized over
all verbs in the same class by associating with the
rule conditions that must be met for the rule to
re, i.e., verb 2 emotional-reaction-verbs; see Fig-
ure 2.
[n
1
v
1
n
2
] [n
3
v
1
n
2
]
[v
1
with n
3
] $
[n
3
related-to n
1
] [n
3
related-to n
1
]
where n 2 Nouns and v 2 emotional-reaction-verbs
Figure 2: Sample Transformational Rule
Note that transformational rules can also en-
code semantic knowledge and even elements of
common sense. For example, a rule can be written
that equates a selling action with a buying action
(with verb arguments in dierent positions). Or
as another example, rules can even encode impli-
catures, e.g., A murdered B implies that B is dead.
Transformational rules can apply at the syntac-
tic, semantic, or even pragmatic levels, and oer
a convenient, powerful, and expressive framework
for handling linguistic variations.
In order for a question answering system to be
successful and have adequate linguistic coverage,
it must have a large number of these rules. A lexi-
con which classied verbs by argument alternation
patterns would be a good start, but this is another
resource lacking in the world today. Rules gener-
ally may be quite complex, and it would be di?-
cult to gather such knowledge from average Web
users with little linguistic background. Requesting
that users describe segments with multiple anno-
tations (each representing a dierent phrasing of
the description), might serve as a preliminary so-
lution to the linguistic variation problem. Another
possible solution will involve learning transforma-
tional rules from a corpus. The di?culty in cre-
ating transformational rules is a serious problem
and unless and until this problem is solved, an
NL-based QA system would have to be restricted
to a limited domain where a small number of ex-
perts could provide enough transformational rule
coverage, or would require a large commitment of
resources to attain su?cient coverage.
6 Collaboration on the Web
A critical component of a successful natural lan-
guage question answering system is the knowledge
base itself. Although the annotation mechanism
simplies the task of building a knowledge base,
the accumulation of knowledge is nevertheless a
time consuming and labor intensive task. How-
ever, due to the simplicity of natural language an-
notations (i.e., describing knowledge in everyday
English), ordinary users with no technical skills
may contribute to a knowledge base. Thus, by
providing a general framework in which people on
the World Wide Web can enter additional knowl-
edge, we can engage millions of potential users all
over the world to collaboratively construct a ques-
tion answering system. We can distribute the ef-
fort of building a knowledge base across many or-
dinary users by allowing them to teach the system
new knowledge.
The idea of using the Internet as a tool for
collaboration across geographically distributed re-
gions is not a new idea. The Open Source move-
ment rst demonstrated the eectiveness and sus-
tainability of programming computer systems in
a distributed manner. Made possible in part by
the World Wide Web, the Open Source move-
ment promotes software development by nurtur-
ing a community of individual contributors work-
ing on freely distributed source code. Under this
development model, software reliability and qual-
ity is ensured through independent peer review by
a large number of programmers. Successful Open
Source projects include Linux, a popular Unix-like
operating system; Apache, the most popular Web
server in the World; SendMail, an utility on vir-
tually every Unix machine; and dmoz, the Open
Directory Project, whose goal is to produce the
most comprehensive directory of the Web by rely-
ing on volunteer editors.
7
Another example of Web-based collaboration
is the Open Mind Initiative (Stork, 1999; Stork,
2000), which is a recent eort to organize ordi-
nary users on the World Wide Web (netizens) to
assist in developing intelligent software. Based on
the observation that many tasks such as speech
recognition and character recognition require vast
quantities of training data, the initiative attempts
to provide a collaborate framework for collecting
data from the World Wide Web. The three pri-
mary contributors within such a framework are
domain experts, who provide fundamental algo-
rithms, tool/infrastructure developers, who de-
velop the framework for capturing data, and non-
expert netizens, who supply the raw training data.
Open Mind Commonsense
8
is an attempt at
constructing a large common sense database by
7
http://www.dmoz.org
8
http://openmind.media.mit.edu
collecting assertions from users all over the Web.
9
Other projects have demonstrated the viabil-
ity of Web-enabled collaborative problem-solving
by harnessing the computational power of idle
processors connected to the Web.
10
The SETI
(Search for Extraterrestrial Intelligence) Institute
was founded after Nasa canceled its High Resolu-
tion Microwave Survey project. The institute or-
ganizes thousands of individuals who donate their
idle processor cycles to search small segments of
radio telescope logs for signs of extraterrestrial
intelligence.
11
Other similar projects that orga-
nize the usage of idle processor time on personal
computers include the Internet Mersenne Prime
Search,
12
and the RC5 Challenge.
13
Recent technical, social, and economic devel-
opments have made the abovementioned models
of collaboration possible. Furthermore, numerous
successful projects have already demonstrated the
eectiveness of these collaborative models. Thus,
it is time to capitalize on these emerging trends
to create the rst collaborative question answer-
ing system on the World Wide Web.
Even with the components such as those de-
scribed above, there still remains a major hurdle
in jumpstarting the construction of a collaborative
question answering system. We are faced with a
classic chicken-and-egg problem: in order to at-
tract users to contribute knowledge, the system
must serve a real information need (i.e., actually
provide users with answers). However, in order
to serve user information needs, the system needs
knowledge, which must be contributed by users.
In the initial stages of building a question an-
swering system, the knowledge base will be too
sparse to be useful. Furthermore, the system may
be very brittle, and might not retrieve the correct
information segment, even if it did exist within
the knowledge base (e.g., due to a missing trans-
formational rule).
It may be possible to address this dilemma with
an incremental approach. The system can rst
be restricted to a very limited domain (e.g., \an-
imals" or \geography"). Users' expectations will
be carefully managed so that they realize the sys-
tem is highly experimental and has a very lim-
ited range of knowledge. In eect, the users will
9
A non-collaborative approach to building a com-
mon sense knowledge base is taken by Lenat whose
Cyc project (Lenat, 1995) is an attempt to build a
common sense knowledge base through a small team
of dedicated and highly trained specialists.
10
http://www.distributed.org
11
http://setiathome.ssl.berkeley.edu
12
http://www.mersenne.org
13
http://www.distributed.org/rc5/
be populating a domain-specic knowledge base.
Over time, the system will be able to answer more
and more questions in that domain, and hence be-
gin to oer interesting answers to real users. After
this, a critical mass will form so that users are not
only teaching the system new knowledge, but also
receiving high quality answers to their questions.
At that point, a decision can be made to increase
the domain coverage of the system.
In order to initialize this process, we can boot-
strap o the curiosity and altruism of individual
users. As an example, the Openmind Common
Sense project has accumulated over 280 thousand
items of information by over six thousand users
based on a data collection model that does not
supply the user with any useful service. The
dream of building \smart" systems has always
been a fascination in our culture (e.g., HAL from
2001: A Space Odyssey); we believe that this will
serve to attract rst-time users.
7 Evolving the System
While the collaborative information gathering
task proceeds, we are then faced with the prob-
lem of maintaining the system and ensuring that
it will provide users with useful information. Two
immediate issues arise: quality control and lin-
guistic variation.
How can we insure the quality of the contributed
material? In general, any system that solicits in-
formation from the World Wide Web faces a prob-
lem of quality control and moderation. Although
most Web users are well-meaning, a small frac-
tion of Web users may have malicious intentions.
Therefore, some ltering mechanisms must be im-
plemented to exclude inappropriate content (e.g.,
pornography or commercial advertisement) from
being inserted into the knowledge base. More
troublesome is the possibility of well-meant but
incorrect information which is probably more com-
mon and denitely harder to detect.
How can we handle linguistic variation? There
are often dierent ways of asking the same ques-
tion; the annotation of a particular segment might
not match the user query, and hence the correct
answer may not be returned as a result. Transfor-
mational rules may be a solution to the problem,
but writing and compiling these rules remain a
di?cult problem.
We propose a variety of solutions for the main-
tenance of a collaborative question answering sys-
tem, depending on the level of human intervention
and supervision.
At one end of the spectrum, an unsupervised
approach to quality control can be implemented
through a distributed system of moderation with
dierent trust levels. The scheme essentially calls
for self-management of the knowledge repository
by the users themselves (i.e., the users with high
trust levels). Dierent trust levels will allow users
various levels of access to the knowledge base, e.g.,
the ability to modify or delete information seg-
ments and their associated annotations or to mod-
ify other users' trust levels. To initiate the process,
only a small group of core editors is required.
In such an unsupervised system, the problem of
linguistic variation could be addressed by prompt-
ing users to give multiple annotations, each de-
scribing the information content of a particular
segment in a dierent way. With a su?ciently
large user base, wide coverage might still be
achieved in the absence of broad-coverage trans-
formational rules.
At the other end of the spectrum, a large or-
ganization may commit signicant amounts of re-
sources to maintaining a supervised collaborative
knowledge base. For example, an organization
may be willing to commit resources to preserve
its organizational memory in the form of an \in-
telligent FAQ" supported by natural language an-
notations. Computers can be eectively utilized
to augment the memory of an organization (Allen,
1977), and have been successfully deployed in real-
world environments with relative success (Acker-
man, 1998).
If an organization were willing to commit signi-
cant resources to a collaborative knowledge reposi-
tory, then transformational rules can be written by
experts with linguistic background. Such experts
could constantly review the annotations entered
by ordinary users and formulate transformational
rules to capture generalizations.
Supervised use of natural language annotation
falls short of the grandiose goal of accessing the
entire World Wide Web, but is the practical and
useful way to apply NL annotation until the trans-
formational rule problem can be solved for unlim-
ited domains.
8 Initial Prototype
Webnotator is a prototype test-bed to evaluate
the practicality of NL-based annotation and re-
trieval through Web-based collaboration. It pro-
vides e?cient facilities for retrieving answers al-
ready stored within the knowledge base and a scal-
able framework for ordinary users to contribute
knowledge.
The system analyzes natural language annota-
tions to produce ternary expressions by postpro-
cessing the results of Minipar (Lin, 1993; Lin,
1994), a fast and robust functional dependency
parser that is freely available for non-commercial
purposes. The quality of the representational
structures depends ultimately on the quality of
whatever parser Webnotator is made to access. In
the current implementation, ternary expressions
are not embedded, elements of ternary expres-
sions are not indexed, and coreference is not de-
tected. Words are stemmed to their root form and
morphological information is discarded. The sys-
tem also implements a version of transformational
rules described above as a simple forward-chaining
rule-based system.
Using a relational database, Webnotator imple-
ments a knowledge base that stores ternary ex-
pressions derived from annotations and their asso-
ciated information segments. Ternary expressions
t neatly into a relational model of data, and thus
manipulation of the knowledge (including answer-
ing queries and inserting new knowledge) can be
formulated as SQL queries. This vastly simplies
development eorts while maintaining robustness
and performance.
Webnotator provides an interface through
which users may teach the system new knowl-
edge by supplying new information segments and
adding new annotations. Essentially, the user en-
ters, in a CGI form, an information segment and
annotations that describe the knowledge. Since
the segment of information can contain any valid
HTML, images, tables, and even multimedia con-
tent may be included. Alternatively, the user may
simply provide a URL to annotate, and Webnota-
tor will automatically create a link to the URL in
its knowledge base.
Currently, Webnotator is a prototype that has
been released to a small community of developers
and testers within the MIT Articial Intelligence
Laboratory. We plan on releasing the system to
the general public in the near future. By col-
lecting knowledge from the general public and by
varying the representations and transformations
applied by Webnotator, it should be possible to
discover which features are most important for
a natural-language-based annotation system and
whether the state of the art is indeed su?ciently
advanced to make such a system practical and ef-
fective.
9 Related Work
A variety of research has been conducted on bet-
ter information access methods on the World
Wide Web (e.g., the \Semantic Web" (Berners-
Lee, 1999)). However, most of these approaches
have concentrated on methods of annotating exist-
ing web pages with metadata such as XML/RDF
(Resource Description Framework) (Staab et al,
2000), extensions to HTML (Luke et al, 1997;
Hein et al, 1999; Staab et al, 2000), special-
ized descriptions (W. Dalitz and Lugger, 1997),
or even conceptual graphs (Martin and Eklund,
1999).
The common thread among previous work is the
embedding of metadata directly into Web docu-
ments, which are then gathered via crawling or
spidering. This approach only works if the target
community of the system is well-dened; adop-
tion of various metadata techniques are presently
limited, and thus it would be pointless to crawl
the entire web to search for metadata. A model
in which distributed metadata are gathered by a
spider will not work with a constantly changing
community that is ill-dened. In principle, there
is no reason why our natural language annotations
cannot be embedded into Web documents also; the
issue is strictly a practical concern.
Another common theme in previous work is
the organization of knowledge in accordance with
some pre-established ontology. This presents sev-
eral challenges for building a general system for
gathering knowledge. Ontologies are often ei-
ther too specic to be of general use (e.g., Ri-
boWeb's ontology for ribosome data (Altmann et
al., 1999)), or too weak to provide much structure
(e.g., Yahoo). Since the ontology is static and
must be agreed upon prior to any knowledge base
development, it may be too constricting and too
inconvenient for the expression of new or unantic-
ipated concepts. Although systems do allow for
arbitrary extension of the ontology (Hein et al,
1999; Staab et al, 2000), such extensions defeat
the purpose of a structure-imposing ontology. Our
proposed alternative to a ontological hierarchy is
to take advantage of the expressiveness of natu-
ral language, and use linguistic devices to relate
concepts. The combination of lexical resources
(e.g., synonyms and meronyms in WordNet) and
transformational rules provide a natural, extensi-
ble way to relate and structure dierent concepts.
A compelling argument for natural language an-
notations is their expressiveness and compactness.
Martin and Eklund (Martin and Eklund, 1999) ar-
gue against an XML-based system of metadata be-
cause XML was primarily intended to be machine
readable, not human readable. In their paper,
they started with an English phrase, and then pro-
ceeded to demonstrate the encoding of that sen-
tence in various formalisms. A constraint graph
encoding was simpler than a KIF (Knowledge In-
terchange Format) encoding, which was in turn
shorter than a RDF format. Of course, this begs
the question: why not just annotate the document
with the original English phrase? Current NLP
technology can handle a large variety of English
sentences and phrases, which may serve as the
annotations directly. Such is system is not only
simpler, more intuitive, but also more compact.
10 Conclusion
Recent social, technical, and economic develop-
ments have made possible a new paradigm of soft-
ware development and problem solving through
loosely-organized collaboration of individuals on
the World Wide Web. Many successful prece-
dents have already proven the viability of this ap-
proach. By leveraging this trend with existing an-
notation and natural language technology, we can
provide a exible framework for a question an-
swering system that grows and \evolves" as each
user contributes to the knowledge base, with only
minimal outside supervision. Testing will reveal
whether such a system can help users realize some
of the untapped potential of the World Wide Web
and other sources of digital information as a vast
repository of human knowledge.
References
Mark S. Ackerman. 1998. Augmenting organi-
zational memory: A eld study of answer gar-
den. ACM Transactions on Information Sys-
tems, 16(3):203{224, July.
Thomas Allen. 1977. Managing the Flow of Tech-
nology. MIT Press.
R. Altmann, M. Bada, X. Chai, M. W. Car-
illo, R. Chen, and N. Abernethy. 1999. Ri-
boWeb: An ontology-based system for collabo-
rative molecular biology. IEEE Intelligent Sys-
tems, 14(5):68{76.
T. Berners-Lee. 1999. Weaving the Web. Harper,
New York.
Je Hein, James Hendler, and Sean Luke. 1999.
SHOE: A knowledge representation language
for internet applications. Technical Report
CS-TR-4078, Institute of Advanced Computer
Studies, University of Maryland, College Park.
Boris Katz. 1990. Using English for indexing and
retrieving. In P.H. Winston and S.A. Shellard,
editors, Articial Intelligence at MIT: Expand-
ing Frontiers, volume 1. MIT Press.
Boris Katz. 1997. Annotating the World Wide
Web using natural language. In Proceedings of
the 5th RIAO Conference on Computer Assisted
Information Searching on the Internet (RIAO
'97).
Doug Lenat. 1995. CYC: A large-scale investment
in knowledge infrastructure. Communications
of the ACM, 38(11):33{38.
Beth Levin. 1993. English Verb Classes and Al-
ternations: A Preliminary Investigation. Uni-
versity of Chicago Press.
Dekang Lin. 1993. Principled-based parsing with-
out overgeneration. In Proceedings of the 31th
Annual Meeting of the Association for Compu-
tational Linguistics (ACL'93).
Dekang Lin. 1994. PRINCIPAR|An e?cient,
broad-coverage, principle-based parser. In Pro-
ceedings of the 15th International Conference on
Computational Linguistics (COLING '94).
Dekang Lin. 1999. Minipar|a minimalist parser.
In Maryland Linguistics Colloquium, University
of Maryland, College Park, March 12,.
Edward Loper. 2000. Applying semantic relation
extraction to information retrieval. Master's
thesis, Massachusetts Institute of Technology.
S. Luke, L. Spector, D. Rager, and J. Hendler.
1997. Ontology-based web agents. In Proceed-
ings of the First International Conference on
Autonomous Agents.
Philippe Martin and Peter Eklund. 1999. Em-
bedding knowledge in web documents. In Pro-
ceedings of the Eighth International World Wide
Web Conference.
S. Staab, J. Angele, S. Decker, M. Erd-
mann, A. Hotho, A. Maedche, H.-P. Schnurr,
R. Studer, and Y. Sure. 2000. Semantic com-
munity web portals. In Proceedings of the Ninth
International World Wide Web Conference.
David G. Stork. 1999. Character and document
research in the open mind initiative. In Pro-
ceedings of the Fifth International Conference
on Document Analysis and Recognition.
David G. Stork. 2000. Open data collection for
training intelligent software in the open mind
initiative. In Proceedings of the Engineering In-
telligent Systems Symposium (EIS '2000).
M. Grotschel W. Dalitz and J. Lugger. 1997.
Information services for mathematics and the
internet. In A. Sydow, editor, Proceedings of
the 15th IMACS World Congress on Scientic
Computation: Modelling and Applied Mathe-
matics. Wissenschaft und Technik Verlag.
