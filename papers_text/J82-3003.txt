Using Semantics in Non-Context-Free Parsing 
of Montague Grammar 1 
David Scott Warren 
Department of Computer Science 
SUNY at Stony Brook 
Long Island, NY 11794 
Joyce Friedman 
University of Michigan 
Ann Arbor, MI  
In natural language processing, the question of the appropriate interaction of syntax 
and semantics during sentence analysis has long been of interest. Montague grammar with 
its fully formalized syntax and semantics provides a complete, well-defined context in which 
these questions can be considered. This paper describes how semantics can be used during 
parsing to reduce the combinatorial explosion of syntactic ambiguity in Montague grammar. 
A parsing algorithm, called semantic equivalence parsing, is presented and examples of its 
operation are given. The algorithm is applicable to general non-context-free grammars 
that include a formal semantic component. The second portion of the paper places 
semantic equivalence parsing in the context of the very general definition of an interpreted 
language as a homomorphism between syntactic and semantic algebras (Montague 1970). 
Introduction 
The close interrelation between syntax and seman- 
tics in Montague grammar provides a good framework 
in which to consider the interaction of syntax and 
semantics in sentence analysis. Several different ap- 
proaches are possible in this framework and they can 
be developed rigorously for comparison. In this paper 
we develop an approach called semantic equivalence 
parsing that introduces logical translation into the on- 
going parsing process. We compare this with our ear- 
lier directed process implementation i which syntactic 
parsing is completed prior to translation to logical 
form. 
Part I of the paper gives an algorithm that parses a 
class of grammars that contains both essentially 
context-free rules and non-context- free rules as in 
Montague's 1973 PTQ. Underlying this algorithm is a 
1 A preliminary version of this paper was presented at the 
symposium on Modelling Human Parsing Strategies at the Universi- 
ty of Texas at Austin, March 24-26, 1981. The work of the first 
author was supported in part by NSF grant IST 80-10834. 
nondeterministic syntactic program expressed as an 
ATN. The algorithm introduces equivalence parsing, 
which is a general execution method for nondetermin- 
istic programs that is based on a recall table, a gener- 
alization of the well-formed substring table. Semantic 
equivalence, based on logical equivalence of formulas 
obtained as translations, is used. We discuss the con- 
sequences of incorporating semantic processing into 
the parser and give examples of both syntactic and 
semantic parsing. In Part II the semantic parsing al- 
gorithm is related to earlier tabular context-free recog- 
nition methods. Relating our algorithm to its prede- 
cessors gives a new way of viewing the technique. 
The algorithmic description is then replaced by a de- 
scription in terms of refined grammars. Finally we 
suggest how this notion might be generalized to the 
full class of Montague grammars. 
The particular version of Montague grammar used 
here is that of PTQ, with which the reader is assumed 
to be conversant. The syntactic component of PTQ is 
an essentially context- free grammar, augmented by 
some additional rules of a different form. The non- 
Copyright 1982 by the Association for Computational Linguistics. Permission to copy without fee all or part of this material is granted 
provided that the copies are not made for direct commercial advantage and the Journal reference and this copyright notice are included on 
the first page. To copy otherwise, or to republish, requires a fee and/or  specific permission. 
0362-613X/82/030123-16503.00 
American Journal of Computational Linguistics, Volume 8, Number 3-4, July-December 1982 123 
David Scott Warren and Joyce Friedman Using Semantics in Non-Context-Free Parsing 
context-free aspects arise in the treatment of quantifi- 
er scope and pronouns and their antecedents. Syntac- 
tically each antecedent is regarded as substituted into 
a place marked by a variable. This is not unlike the 
way fillers are inserted into gaps in Gazdar 's  1979 
treatment. However,  Montague's  use of variables 
allows complicated interactions between different 
variable-antecedent pairs. Each substitution rule sub- 
stitutes a term phrase (NP) for one or more occurrenc- 
es of a free variable in a phrase (which may be a sen- 
tence, common noun phrase, or intransitive verb 
phrase). The first occurrence of the variable is re- 
placed by the phrase; later occurrences are replaced by 
appropriate pronouns. The translation of the resulting 
phrase expresses the coreferential ity of the noun 
phrase and the pronouns. With substitution, but with- 
out pronouns, the only function of substitution is to 
determine quantifier scope. 
Directed Process  Approach 
One computational approach to processing a sen- 
tence is the directed process approach, which is a se- 
quential analysis that follows the three-part presenta- 
tion in PTQ. The three steps are as follows. A purely 
syntactic analysis of a sentence yields a set of parse 
trees, each an expression in the disambiguated lan- 
guage. Each parse tree is then translated by 
Montague's rules into a formula of intentional ogic to 
which logical reductions are immediately applied. The 
reduced formulas can then be interpreted in a model. 
The directed process approach is the one taken in the 
system described by Friedman, Moran, and Warren 
1978a,b. 
Semantic equivalence parsing is motivated by the 
observation that the directed process approach, in 
which all of the syntactic processing is completed be- 
fore any semantic processing begins, does not take 
maximal advantage of the coupling of syntax and se- 
mantics in Montague grammars. Compositionality and 
the fact that for each syntactic rule there is a transla- 
tion rule suggest that it would be possible to do a 
combined syntactic-semantic parse. In this approach, 
as soon as a subphrase is parsed, its logical formula is 
obtained and reduced to an extensionalized normal 
form. Two parses for the same phrase can then be 
regarded equivalent if they have the same formula. 
The approach to parsing suggested by Cooper 's  
1975 treatment of quantified noun phrases is like our 
semantic equivalence parsing in storing translations as 
one element of the tuple corresponding to a noun 
phrase. Cooper's  approach differs from the approach 
fol lowed here because he has an intermediate stage 
that might be called an "autonomous yntax tree".  
The frontier of the tree is the sentence; the scope of 
the quantifier of a noun phrase is not yet indicated. 
Cooper 's  approach has been fol lowed by the GPSG 
system (Gawron et al 1982) and by Rosenschein and 
Shieber 1982. Neither of those systems treats pro- 
nouns. In Montague's  approach, which we follow 
here, the trees produced by the parser are expressions 
in the disambiguated language, so scope is determined, 
pronoun antecedents are indicated, and each tree has a 
unique (unreduced) translation. The descriptions of 
the systems that use Cooper 's  approach seem to imply 
that they use a second pass over the syntax tree to 
determine the actual quantifier scopes in the final logi- 
cal forms. Were these systems to use a single pass to 
produce the final logical forms, the results described in 
this paper would be directly applicable. 
1. Equivalence Parsing 
Ambigui ty  
Ambiguity in Montague grammar is measured by 
the number of different meanings. In this view syn- 
tactic structure is of no interest in its own right, but 
only as a vehicle for mapping semantics. Syntactic 
ambiguity does not directly correspond to semantic 
ambiguity, and there may be many parses with the 
same semantic interpretation. Further, sentences with 
scope ambiguity, such as A man loves every woman, 
require more than one parse, because the syntactic 
derivation determines quantifier scope. 
In PTQ there is infinite syntactic ambiguity arising 
from three sources: alphabetic variants of variables, 
variable for variable substitutions, and vacuous varia- 
ble substitution. However,  these semantically unnec- 
essary constructs can be eliminated, so that the set of 
syntactic sources for any sentence is finite, and a par- 
ser that finds the full set is possible. (This corre- 
sponds to the "variable principle" enunciated by Jans- 
sen 1980 and used by Landsbergen 1980.) This ap- 
proach was the basis of our earlier PTQ parser 
(Friedman and Warren 1978). 
However,  even with these reductions the number of 
remaining parses for a sentence of reasonable com- 
plexity is still large compared to the number of non- 
equivalent translations. In the directed process ap- 
proach this is treated by first finding all the parses, 
next finding for each parse a reduced translation, and 
then finally obtaining the set of reduced translations. 
Each reduced translation may, but does not necessari- 
ly, represent a different sentence meaning. No mean- 
ings are lost. Further reductions of the set of transla- 
tions would be possible, but the undecidability of logi- 
cal equivalence precludes algorithmic reduction to a 
minimal set. 
The ATN Program 
In the underlying parser the grammar is expressed 
as an augmented transition network (ATN) (Woods 
1973). Both the syntactic and the semantic parsers 
use this same ATN. The main difficulty in construct- 
124 American Journal of Computational Linguistics, Volume 8, Number 3-4, July-December 1982 
David Scott Warren and Joyce Friedman Using Semantics in Non-Context-Free Parsing 
ing the ATN was, as usual, the non-context-free as- 
pects of the grammar, in particular the incorporation 
of a treatment of substitution rules and variables. The 
grammar given in PTQ generates infinitely many deriv- 
ations for each sentence. All but finitely many of 
these are unnecessary variations on variables and were 
eliminated in the construction of the ATN. The ATN 
represents only the reduced set of structures, and must 
therefore be more complex. 
Equivalence Test ing 
In order to say what we mean by semantic equiva- 
lence parsing, we use Harel 's 1979 notion of execution 
method for nondeterministic programs. An execution 
method is a deterministic procedure for finding the 
possible execution paths through a nondeterministic 
program given an input. For an ATN, these execution 
paths correspond to different parses. Viewing parsing 
in this way, the only difference between the usual 
syntactic parsing and semantic equivalence parsing is a 
difference in the execution method. As will be seen, 
semantic equivalence parsing uses semantic tests as 
part of the execution method. 
We call the execution method we use to process a 
general ATN equivalence parsing (Warren 1979). 
Equivalence parsing is based on a recall table. The 
recall table is a set of buckets used to organize and 
hold partial syntactic structures while larger ones are 
constructed. Equivalence parsing can be viewed as 
processing an input sentence and the ATN to define 
and fill in the buckets of the recall table. The use of 
the recall table reduces the amount of redundant proc- 
essing in parsing a sentence. Syntactic structures 
found along one execution path through the ATN need 
not be reconstructed but can be directly retrieved from 
the recall table and used on other paths. The recall 
table is a generalization of the familiar wel l - formed 
substring table (WFST) to arbitrary programs that 
contain procedure calls. Use of the WFST in ATN 
parsing is noted in Woods 1973 and Bates 1978. 
Bates observes that the WFST is complicated by the 
HOLDs and SENDRs in the ATN. These are the ATN 
actions that correspond to parameter passing in proce- 
dures and are required in the ATN for PTQ to correctly 
treat the substitution rules. 
In the Woods system the WFST is viewed as a pos- 
sible optimization, to be turned on when it improves 
parsing efficiency. In our system the recall table is an 
intrinsic part of the parsing algorithm. Because any 
ATN that naturally represents PTQ must contain left 
recursion, the usual depth-f irst (or breadth-f irst or 
best-f irst) ATN parsing algorithm would go into an 
infinite loop when trying to find all the parses of any 
sentence. The use of the recall table in equivalence 
parsing handles left-recursive ATNs without special 
consideration (Warren 1981). As a result there is no 
need to rewrite the grammar to eliminate left-recursive 
rules as is usually necessary. 
In a general nondeterministic program, a bucket in 
the recall table corresponds to a particular subroutine 
and a set of values for the calling parameters and re- 
turn parameters. For an ATN a bucket is indexed by a 
triple: (1) a grammatical category, that is, a subnet to 
which a PUSH is made, (2) the contents of the SENDR 
registers at the PUSH and the current string, and (3) 
the contents of the LIFTR registers at the POP and the 
then-current string. A bucket contains the members 
of an equivalence class of syntactic structures; precise- 
ly what they are depends on what type of equivalence 
is being used. 
What makes equivalence parsing applicable to non- 
context-free grammars is that its buckets are more 
general than the cells in the standard tabular context- 
free algorithms. In the C-K-Y algorithm (Kasami 
1965), for example, a cell is indexed only by the start- 
ing position and the length of the parsed segment, i.e., 
the current string at PUSH and POP. The cell contents 
are nonterminals. In our case all three are part of the 
bucket index, which also includes SENDR and LIFTR 
register values. The bucket contents are equivalence 
classes of structures. 
Sentence  Recogni t ion 
For sentence recognition all parses are equivalent. 
So it is enough to determine, for each bucket of the 
recall table, whether or not it is empty. A sentence is 
in the language if the bucket corresponding to the 
sentence category (with empty SENDR registers and 
full string, and empty LIFTR registers and null string) 
is nonempty. The particular forms of the syntactic 
structures in the bucket are irrelevant; the contents of 
the buckets are only a superfluous record of the spe- 
cific syntactic structures. The syntactic structure is 
never tested and so does not affect the flow of con- 
trol. Thus which buckets are nonempty depends only 
on what other buckets are nonempty and not on what 
those other buckets contain. For sentence recognition, 
when the execution method constructs a new member 
of a bucket that is already nonempty, it may or may 
not add the new substructure, but it does not need to 
use it to construct any larger syntactic structures. This 
is because the earlier member has already verified this 
bucket as nonempty. Therefore this fact is already 
known and is already being used to determine the 
nonemptiness of other buckets. To find all parses, 
however, equivalence parsing does use all members of 
each bucket to construct larger structures. 
It would be possible first to do recognition and 
determine all the nonempty buckets in the recall table, 
and then to go back and take all variants of one single 
parse that can be obtained by replacing any substruc- 
ture .by  another substructure from the same bucket. 
American Journal of Computational Linguistics, Volume 8, Number 3-4, July-December 1982 125 
David Scott Warren and Joyce Friedman Using Semantics in Non-Context-Free Parsing 
This is essentially how the context-free parsing algor- 
ithms constructed from the tabular recognition me- 
thods work. This is not how the equivalence parsing 
algorithm works. When it obtains a substructure, it
immediately tries to use it to construct larger struc- 
tures. 
The difference described above between sentence 
recognition and sentence parsing is a difference only 
in the execution methods used to execute the ATN and 
not in the ATN itself. This difference is in the test for 
equivalence of bucket contents. In sentence recogni- 
tion any two syntactic structures in a bucket are equiv- 
alent since we only care whether or not the substring 
can be parsed to the given category. At the other 
extreme, in finding all parses, two entries are equiva- 
lent only if they are the identical structure. For most 
reasonable ATNs, including our ATN for PTQ, this 
would not happen; distinct paths lead to distinct struc- 
tures. 
Semantic parsing is obtained by aga inmodi fy ing  
only the equivalence test used in the execution method 
to test bucket contents. For semantic parsing two 
entries are equivalent if their logical translations, after 
logical reduction and extensionalization, are identical 
to within change of bound variable. 
Small Grammar  
For our examples, we introduce in Figure 1 a small 
subnet of the ATN for PTQ. Arcs with fully capital- 
ized labels are PUSH arcs; those with lower case labels 
are CAT arcs. Structure-building operations are indi- 
cated in parentheses. This net implements just three 
rules of PTQ. Rule $4 forms a sentence by concaten- 
ating a term phrase and an intransitive verb phrase; 
S l l  conjoins two sentences, and S14,i substitutes a 
term phrase for the syntactic variable he i in a sen- 
tence. $4 and S l l  are context-free rules; S14,i is one 
of the substitution rules that make the grammar non- 
context-free and is basic to the handling of quantifiers, 
pronouns, and antecedents. The ATN handles the 
substitution by using a LIFTR to carry the variable- 
binding information. The LIFTR is not used for the 
context-free rules. 
ITE 
TS 
TS 
IV ($4 TERM IVP) 
POP SENT l 
(S11 SENTI (S14,i TERM SENT) 
SENT2) 
TE 
bte i l l POP hei 
IV 
biv POP IVP 
Figure 1. Subnet of the ATN for PTQ, 
126 American Journal of Computational Linguistics, Volume 8, Number 3-4, July-December 1982 
David Scott Warren and Joyce Friedman Using Semantics in Non-Context-Free Parsing 
Example 1: Bill walks 
The first example is the sentence Bill walks. This 
sentence has the obvious parse using only the context- 
free rule $4. It also has the parse using the substitu- 
tion rule. We will carry through the details of its 
parse to show how this substitution rule is treated in 
the parsing process. 
In the trace PUSHes and POPs in the syntactic anal- 
ysis of this sentence are shown. The entries are in 
chronological order. The PUSHes are numbered se- 
quentially for identification. The PUSH number uni- 
quely determines a) the category to which the PUSH is 
made, b) the remainder of the sentence being parsed 
at the time of the PUSH, and c) the contents of the 
SENDR registers at the time of the PUSH, called the 
PUSH environment. At each POP a bucket and an 
element in that bucket are returned. The bucket name 
at a POP is made up of the corresponding PUSH num- 
ber, the remaining input string, and the contents of the 
LIFTR registers, which are called the POP environ- 
ment. The element in the bucket is the tree that is 
returned. For brevity we use in the trace only the first 
letters of the words in the sentence; for example, Bill 
walks becomes Bw. 
Trace of Bill walks 
PUSH: Bucket: Contents: 
# CAT Str Env from Str Env Tree 
1 TS Bw null 
\[Parsing begins with a PUSH to the sentence category passing the entire string and an empty or null environment.\] 
2 TE Bw null 
\[In the sentence subnet we first PUSH to find a TE.\] 
2 w null Bill 
\[The TE subnet finds and POPs the term Bill to return from PUSH 2.\] 
3 IV w null 
3 e null walk 
1 e null ($4 Bill walk) 
\[Now since a tree is returned to the top level, covers the whole string, and the returned environment is null, the 
tree is printed. The parses are always the trees in bucket 1-e-null. The execution method now backs up; there 
are no more POPs from PUSH 3; there is another from PUSH 2.\] 
2 w (he0 B) he0 
\[Continuing forward with the new environment...\] 
4 IV w (he0 B) 
4 e null walk 
\[Note that this is not the same bucket as on the previous PUSH 3 because the PUSH environments differ.\] 
1 e (he0 B) ($4 he0 walk) 
\[The tree has been returned and covers the whole string. However, the returned environment is not null so the 
parse fails, and the execution method backs up to seek another eturn from PUSH 1.\] 
1 e null (S14,0 Bill ($4 he0 walk)) 
\[This is another element in bucket 1-e-null;  it is a successful parse so it is printed out. Execution continues but 
there are no more parses of the sentence.\] 
Discussion 
In this trace bucket t -e -nu l l  is the only bucket 
with more than one entry. The execution method was 
syntactic parsing, so each of the two entries was re- 
turned and printed out. For recognition, these two 
entries in the bucket would be considered the same 
and the second would not have been POPped. Instead 
of continuing the computation up in the subnet from 
which the PUSH was made, this path would be made to 
fail and the execution method would back up. For 
semantic equivalence parsing, the bucket contents 
throughout would not be the syntax trees, but would 
instead be their reduced extensionalized logical formu- 
las. (Each such logical formula represents the equiva- 
lence class of the syntactic structures that correspond 
to the formula.) For example, bucket 2-w-null would 
contain ~,Pp{Ab} and bucket 3-c-null would contain 
walk'. The first entry to bucket 1-E-null would be the 
formula for ($4 Bill walk), that is, walk . ' (b) .  The 
entry to bucket 1-e-null  on the last line of the trace 
American Journal of Computational Linguistics, Volume 8, Number 3-4, July-December 1982 127 
David Scott Warren and Joyce Friedman Using Semantics in Non-Context-Free Parsing 
would be the formula for (S14,0 Bill ($4 he0 walk)), 
which is also walk . ' (b) .  Therefore, this second entry 
would not be POPped. 
Buckets also serve to reduce the amount of repeat- 
ed computation. Suppose we have a second PUSH to 
the same category with the same string and environ- 
ment as an earlier PUSH. The buckets resulting from 
this new PUSH would come out to be the same as the 
buckets from the earlier PUSH. Therefore the buckets 
need not be recomputed; the results of the earlier 
buckets can be used directly. This is called a 
"FAKEPUSH" because we don't  actually do the PUSH 
to continue through the invoked subnet but simply do 
a "FAKEPOP" using the contents of the previously 
computed buckets. 
Consider, as an example of FAKEPOP, the partial 
trace of the syntactic parse of the sentence Bill walks 
and Mary runs (or Bw&Mr for short). The initial part 
of this trace, through step 4, is essentially the same as 
the trace above for the shorter sentence Bill walks. 
Trace of Bill walks and Mary runs 
PUSH: Bucket: 
# CAT Str Env from Str 
Contents: 
Env Tree 
1 TS Bw&Mr null 
2 TE Bw null 
3 IV w null 
2 w&Mr null Bill 
3 &Mr null walk 
1 &Mr null ($4 Bill walk) 
\[A tree has been returned to the top level, but it does not cover the whole sentence, so the path fails and the 
execution method backs up.\] 
2 w&Mr (he0 B) he0 
4 IV w&Mr (he0 B) 
4 &Mr null walk 
1 &Mr (he0 B ($4 he0 walk) 
\[Again a tree has been returned to the top level, but it does not span the whole string, nor is the returned 
environment null, so we fail.\] 
1 &Mr null (S14,0 Bill ($4 he0 walk)) 
\[Again we are the top level; again we do not span the whole string, so again we fail.\] 
5 TS Bw&Mr null 
\[This is the second arc from the TS node of Figure 1. The PUSH to TE (2 above) has completely failed. 
However, this PUSH, TS-Bw&Mr-null has been done before; it is PUSH 1. We already have two buckets from 
that PUSH: 1-&Mr-null containing two trees, and 1-&Mr-(he0 B) with one tree. There is no need to re-enter this 
subnet; the buckets and their contents tell us what would happen. Therefore we FAKEPOP one subtree and its 
bucket and follow that computation to the end; later we will return to FAKEPOP the next one.\] 
1(5) &Mr null ($4 Bill walk) 
6 TS Mr null 
7 TE Mr null 
7 r null Mary 
\[This computation continues and parses the second half of this sentence. Two parses are produced: 
(S11 ($4 Bill walk) ($4 Mary run)) and 
(S11 ($4 Bill walk) (S14,0 Mary ($4 he0 run))) 
After this, the execution method fails back to the FAKEPOP at PUSH 5, and another subtree from a bucket from 
PUSH 2 is FAKEPOPped.\] 
1(5) &Mr null (S14,0 Bill (he0 walk)) 
\[And the computation continues, eventually producing a total of ten parses for this sentence.\] 
(In the earlier example of Bill  walks, these 
FAKEPOPs are done, but their computations immedi- 
ately fail, because they are looking for a conjunction 
but are at the end of the sentence.) 
128 American Journal  of Computat ional  Linguistics, Volume 8, Number 3-4, Ju ly-December 1982 
David Scott Warren and Joyce Friedman Using Semantics in Non-Context-Free Parsing 
Results of Parsing 
The sentence Bill walks and Mary runs has ten 
syntactic structures with respect to the PTQ grammar. 
The rules $4, S l l ,  and S14,i can be used in various 
orders. Figure 2 shows the ten different structures in 
the order they are produced by the syntactic parser. 
The nodes in the trees of Figure 2 that are in italics 
are the syntactic structures used for the first time. 
The nodes in standard type are structures used previ- 
ously, and thus either are part of an execution path in 
common with an earlier parse, or are retrieved from a 
bucket in the recall table to be used again. Thus the 
number of italicized nodes measures in a crude way 
the amount of work required to find all the parses for 
this sentence. 
S l l  
I 
I I 
$4 $4 
I t 
i i i I 
Bill walk Mary run 
b. 
I 
Bill 
I 
$4 
I 
I 
walk 
S14,0 Mary 
I 
$11 
I 
I 
he0 
I 
$4 
i 
I 
run 
e ,  S l l  
1 
I 
$4 
L 
I I 
Bill walk 
I 
he0 
I 
S14,0 Mary 
I 
$4 
I 
I 
run  
I 
$4 
I I 
he0 walk 
$14,0 Bill 
I 
$11 
i 
i 
$4 
f 
I 
Mary 
I 
run 
e. S14,1 Mary 
I 
$14,0 Bill 
I 
$11 
I 
I 
$4 
I 
I I I 
he0 walk hel 
I I 
$4 $4 
I I 
I I wJlk run he0 
S14,0 Bill 
I 
S14,1 Mary 
I 
S l l  
I 
I 
$4 
I 
I 
hel 
I 
run 
Figure 2. Ten parses for Bill walks and Mary runs, 
American Journal of Computational Linguistics, Volume 8, Number 3-4, July-December 1982 129 
David Scott Warren and Joyce Friedman Using Semantics in Non-Context-Free Parsing 
g. 
I 
$4 
I 
I I 
he0 walk 
S14,0 Bill 
I 
$11 
I 
I 
S14,1 Mary 
I 
$4 
I 
I I 
hel run 
$11 
I 
I I 
$14,0 Bill $4 
i I $4 
I I Mary 
I I 
heO walk 
I 
run 
S14,1 Mary 
I 
$11 
I 
I I 
S14,0 Bill $4 
i I S4 
I I hel  
I I 
heO walk 
run 
$11 
I 
he0 
I I 
S14,0 Bill S14,1 Mary 
I I 
$4 $4 
I I 
I I I 
walk he 1 run 
Figure 2. continued 
Example of Semantic  Equivalence Parsing 
This sentence, Bill walks and Mary runs, is one for 
which semantic parsing is substantially faster. It is 
unambiguous; its only reduced extensionalized logical 
translation is "wa lk , ' (b )&run , ' (m)" .  In the directed 
process parser, all ten trees of Figure 2 are found. 
They will all have the same translation. In semantic 
parsing on'ly one is found. Here the method works to 
advantage because both parses of the initial string Bill 
walks result in the same environment for parsing Mary 
runs. These two parses go into the same bucket so 
only one needs to be used to construct larger struc- 
tfires. We trace the example. 
PUSH: Bucket: 
# CAT Str Env from Str 
= 
Contents: 
Env Formula ? 
1 TS Bw&Mr null 
2 TE Bw null 
3 IV 
\[Fail\] 
4 IV 
\[Fail\] 
2 
w null 
3 
1 
2 
w&Mr (he0 B) 
4 
1 
w&Mr null )tPp{Ab} y 
&Mr null walk' y 
&Mr null wa lk , ' (b )  y 
w&Mr (he0 B) hPP{x0} y 
&Mr null walk' y 
&Mr (he0 B) walk'(Vx0) y 
130 American Journal of Computational Linguistics, Volume 8, Number 3-4, July-December 1982 
David Scott Warren and Joyce Friedman Using Semantics in Non-Context-Free Parsing 
1 &Mr null wa lk , ' (b)  n 
\[This formula is the translation of the syntactic structure using S14,0 to substitute Bill into "he0 walks". This is 
the same bucket and the same translation as obtained at the return from 1 after PUSH 3 above, so we do not POP 
(indicated by the 'n'  in the final column), but instead fail back.\] 
5 TS Bw&Mr null 
\[FAKEPOP, since this is a repeat PUSH to this category with these parameters. There are two buckets: 1-&Mr- 
null, which in syntactic parsing had two trees but now has only one translation, and bucket 1-&Mr-(he0 B) with 
one translation. So we FAKEPOP 1-&Mr-null.\] 
1(5) &Mr null wa lk , ' (b)  y (FAKEPOP) 
6 TS Mr null 
7 TE Mr null 
7 r null y 
8 IV r null 
8 E null y 
6 e null y 
1 ~ null  y 
\[This is a successful parse. The top level prints out the translation and then the execution method fails back.\] 
9 IV r (he0 M) 
Mary 
run' 
run , ' (m)  
wa lk , ' (b )&run, ' (m)  
7 (he0 M) null ~PP{x0} y 
9 e null run' y 
6 E null run,'(Vx0) y 
1 E (he0 M) walk, ' (b)&run, '(Vx0) y 
\[Fail because we are at the top level and the environment is not null.\] 
1 ~ null wa lk , ' (b )&run, ' (m)  n 
\[Again we want to enter a translation into bucket 1-E-null. This translation duplicates the one already there. 
it is not returned and we fail back.\] 
6 E null run , ' (m)  n 
\[This again duplicates a bucket and its contents, so we fail back to the second FAKEPOP from PUSH 5. 
use the other bucket: 1-&Mr-(he0 B).\] 
1(5) &Mr (he0 B) walk,'(Vx0) y (FAKEPOP) 
(he0 B) 
(he0 B) 
(he0 B) 
10 TS Mr 
11 r null 
11 TE Mr 
12 IV r 
So 
Now we 
~P{xO} y 
run' y 
run , ' (m)  y 
walk, ' (Vx0)&run, '(m) y 
12 ? null 
10 e null 
1 E (he0 B) 
\[Fail at the top level since the environment is not null.\] 
1 e (he0 B) wa lk , ' (b )&run, ' (m)  
\[This duplicates a bucket and its contents, so we do not POP it but fail back.\] 
l l  r (hel M) ~PP{xl} 
13 e null 
10 e (hel M) 
1 e (he0 B) 
(hel M) 
13 IV r (he0 B) 
(hel M) 
run' 
run, ' (~xl )  
walk, '(~x0) &run,'(Vx 1 ) 
(hel M) walk , ' (b)&run, ' (Vxl )  
null wa lk , ' (b )&run, ' (m)  
Y 
\[Fail at top level because nvironment is not null.\] 
1 c 
\[Fail at top level because environment is not null.\] 
1 e 
\[Duplicate bucket and translation, so fail.\] 
American Journal of Computational Linguistics, Volume 8, Number 3-4, July-December 1982 131 
David Scott Warren and Joyce Friedman Using Semantics in Non-Context-Free Parsing 
1 c (he0 B) 
\[Duplicate bucket and translation, so fail.\] 
1 c null 
\[Duplicate, so fail.\] 
10 e null 
\[Duplicate, so fail.\] 
walk, ' (Vx0)&run, ' (m) n 
wa lk , ' (b )&run, ' (m)  n 
run , ' (m)  n 
This completes the trace of the semantic parse of the sentence. 
Results of Parsing 
Figure 3 displays in graphical form the syntactic 
structures built during the semantic parsing of Bill 
walks and Mary runs traced above. A horizontal line 
over a particular node in a tree indicates that the 
translation of the structure duplicated a translation 
already in its bucket, so no larger structures were built 
using it. Only parse a) is a full parse of the sentence 
and thus it is the only parse returned. All the others 
are aborted when they are found equivalent o earlier 
partial results. These points of abortion in the compu- 
tation are the points in the trace above at which a POP 
fails due to the duplication of a bucket and its con- 
tents. 
a. S l l  
I 
I I 
$4 $4 
I I 
1 I I I 
Bill walk Mary run 
b. S14,0 Mary 
S l l  
I 
I 1 
$4 $4 
I I 
I I I I 
Bill walk he0 run 
S14,0 Mary 
$4 
I 
I I 
he0 run 
d. $14,0 Bill 
$11 
I 
I I 
$4 $4 
I I 
I I I I 
he0 walk Mary run 
Figure 3. Semantic parses of Bill walks and Mary runs. 
132 American Journal of Computational Linguistics, Volume 8, Number 3-4, July-December 1982 
David Scott Warren and Joyce Friedman Using Semantics in Non-Context-Free Parsing 
I 
$4 
I 
I 
he0 
e .  S14,1 Mary 
I 
$14,0 Bill 
I 
$11 
I 
I 
$4 
I 
I I I 
walk he 1 run 
I 
he0 
$14,0 Bill 
I 
$14,1 Mary 
I 
S l l  
I 
I I 
$4 $4 
I I 
I I 
walk he 1 
I 
run 
g. S14,1 Mary 
I 
$4 
I 
I I 
he 1 run 
Figure 3. continued 
Note that construction of parse c) is halted when a 
translation is built that duplicates the translation of 
the right $4 subtree of parse a). This corresponds to 
the failure due to duplicate bucket contents in bucket 
6-E-null following PUSH 9 in the trace above. Simi- 
larly parse g) is aborted before the entire tree is built. 
This corresponds to the failure in the final line of the 
trace due to a duplicate translation in bucket 
10-E-null. Semantic parses that would correspond to 
syntactic parses h), i), and j) of Figure 2 are not con- 
sidered at all. This is because bucket 1-&Mr-null con- 
tains two syntactic structures, but only one translation. 
Thus in semantic equivalence parsing we only do one 
FAKEPOP for this bucket for PUSH 5. In syntactic 
parsing the other parses are generated by the 
FAKEPOP of the other structure in this bucket. 
Reducing the Env i ronment  
The potential advantage of semantic equivalence 
parsing derives from treating partial results as an equi- 
valence class in proceeding. A partial result consists 
of a structure, its extensionalized reduced translation, 
and a set of parameters of the parse to that point. 
These parameters are the environment for parsing the 
phrase. Consider the sentence John loves Mary and its 
parses: 
(1) ($4 John ($5 love Mary)) 
(2) ($4 John (S16,0 Mary ($5 love he0))) 
(3) (S14,0 John ($4 (he0 ($5 love Mary)))  
(4) (S14,0 John ($4 he0 (S16,1 Mary 
($5 love he l ) ) ) )  
(plus 3 more) 
On reaching the phrase love Mary in parse (3) the 
parameters are not the same as they were at that point 
in parse (1), because the pair (he0 John) is in the 
environment. Thus the parser is not able to consult 
the recall table and immediately return the already 
parsed substructure. Instead it must reparse love Mary 
in the new context. 
This environment problem arises because the ATN 
is designed to follow PTQ in treating pronouns by the 
non-context- f ree substitution rules. We have also 
considered, but have not to this point implemented, 
alternative ways of treating variables to make partial 
results equal. One way would be not to pass variable 
bindings down into lower nets at all. Thus the PUSH 
environment would always be null. Since these bind- 
ings are used to find the antecedent for a pronoun, the 
way antecedents are determined would have to be 
changed. An implementation might be as follows: On 
encountering a pronoun during parsing, replace it by a 
new he-variable. Then pass back up the tree informa- 
tion concerning both the variable number used and the 
pronoun's gender. At a higher point in the tree, where 
the substitution rule is to be applied, a determination 
can be made as to which of the substituted terms 
could be the antecedent for the pronoun. The variable 
number of the pronoun can then be changed to agree 
with the variable number of its antecedent term by a 
variable-for-variable substitution. Finally the substitu- 
tion rule can be used to substitute the term into the 
phrase for all occurrences of the variable. Note that 
this alternative process would construct trees that do 
have substitution rules to substitute variables for varia- 
American Journal of Computational Linguistics, Volume 8, Number 3-4, July-December 1982 133 
David Scott Warren and Joyce Friedman Using Semantics in Non-Context-Free Parsing 
bles, contrary to the variable principle mentioned 
above. We also note that with this modification a 
pronoun is not associated with its antecedent when it is 
first encountered. Instead the pronoun is saved and at 
some later point in the parse the association is made. 
This revised treatment is related computationally to 
that proposed in Cooper 1975. 
Evaluation of Semantic Equivalence Parsing 
The question of the interaction of syntax and se- 
mantics in parsing was introduced early in computa- 
tional linguistics. Winograd 1971 argued for the in- 
corporation of semantics as early as possible in the 
recognition process, in order to reduce the amount of 
syntactic processing that would be needed. Partial 
parses that had no interpretation did not need to be 
continued. The alternative position represented by 
Woods's early work (Woods and Kaplan 1971) was 
basically the inverse: less semantic processing would 
be needed if only completed parses were interpreted. 
This argument is based on the idea of eliminating un- 
interpretable parses as soon as possible. 
This advantage, if it is one, of integrated syntactic 
and semantic procedures does not occur here because 
the semantic aspect does not eliminate any logical 
analyses. The translation of a structure to a formula is 
always successful, so no partial parse is ever eliminat- 
ed for lack of a translation. What happens instead is 
that several partial parses are found to be equivalent 
because they have the same translation. In this case 
only a representative of the set of partial parses needs 
to be carried forward. 
A further expansion of equivalence parsing would 
be interpretation equivalence parsing. Sentence process- 
ing would take place in the context of a specified mod- 
el. Two structures would be regarded as equivalent if 
they had the same denotation in the model. More 
partial structures would be found equivalent under the 
equivalence relation than under the reduce- 
extensionalize relation, and fewer structures would 
need to be constructed. Further, with the interpreta- 
tion equivalence relation, we might be able to use an 
inconsistent denotation to eliminate an incorrect par- 
tial parse. For example, consider a sentence such as 
Sandy and Pat are running and she is talking to him. In 
this case, since the gender of Sandy and Pat cannot be 
determined syntactically, these words would have to 
be marked in the lexicon with both genders. This 
would result in multiple logical formulas for this sen- 
tence, one for each gender assumption. However,  
during interpretation equivalence parsing, the referents 
for Sandy and Pat would be found in the model and 
the meaning with the incorrect coreference could be 
rejected. 
Logical normal forms other than the reduced, ex- 
tensionalized form used above lead to other reasonable 
versions of equivalence parsing. For example, we 
could further process the reduced, extensionalized 
form to obtain a prenex normal form with the matrix 
in clausal form. We would use some standard conven- 
tions for naming variables, ordering sequences of the 
same quantifier in the prefix, and ordering the literals 
in the clauses of the matrix. This would allow the 
algorithm to eliminate, for example, multiple parses 
arising from various equivalent scopes and orderings of 
existential quantifiers. 
The semantic equivalence processor has been im- 
plemented in Franz Lisp. We have applied it to the 
PTQ grammar and tested it on various examples. For 
purposes of comparison the directed process version 
includes syntactic parse, translation to logical formula 
and reduction, and finally the reduction of the list of 
formulas to a set of formulas. The mixed strategy 
yields exactly this set of formulas, with one parse tree 
for each. Experiments with the combined parser and 
the directed parser show that they take approximately 
the same time for reasonably simple sentences. For 
more complicated sentences the mixed strategy usually 
results in less processing time and, in the best cases, 
results in about a 40 percent speed-up. The distin- 
guishing characteristic of a string for which the me- 
thod yields the greatest speed-up is that the environ- 
ment resulting from parsing an initial segment is the 
same for several distinct parses. 
The two parsing method we have described, the 
sequential process and the mixed process, were obvi- 
ously not developed with psychological modeling in 
mind. The directed process version of the system can 
be immediately rejected as a possible psychological 
model, since it involves obtaining and storing all the 
structures for a sentence before beginning to interpret 
any one of them. However, a reorganization of the 
programwould  make it possible to interpret each 
structure immediately after it is obtained. This would 
have the same cost in time as the first version, but 
would not require storing all the parses. 
Although semantic equivalence parsing was devel- 
oped in the specific context of the grammar of PTQ, it 
is more general in its applicability. The strict compos- 
itionality of syntax and semantics in PTQ is the main 
feature on which it depends. The general idea of equi- 
valence parsing can be applied whenever syntactic 
structure is used as an intermediate form and there is a 
syntax-directed translation to an output form on which 
an equivalence relation is defined. 
2. Input-Refined Grammars 
We now switch our point of view and examine 
equivalence parsing not in algorithmic terms but in 
formal grammatical terms. This will then lead into 
showing how equivalence parsing relates to Universal 
134 American Journal of Computational Linguistics, Volume 8, Number 3-4, July-December 1982 
David Scott Warren and Joyce Friedman Using Semantics in Non-Context-Free Parsing 
Grammar (UG) (Montague 1970). The basic concept 
to be used is an input-refined grammar. We begin by 
defining this concept for context- free grammars and 
using it to relate the tabular context-free recognition 
algorithms of Earley 1970, Cocke-Kasami-Younger  
(Kasami 1965), and Sheil 1976 to each other and 
eventually to our algorithm. 
Given a context-free grammar G and a string s over 
the terminal symbols of G, we define from G and s a 
new grammar Gs, called an input-refinement of G. 
This new grammar G s will bear a particular relation- 
ship to G: L(Gs) = {s}nL(G), i.e., L(Gs) is the single- 
ton set {s} if s is in L(G), and empty otherwise. Fur- 
thermore, there is a direct one-to-one relationship 
between the derivations of s in G and the derivations 
of s in G s. Thus the problem of recognizing s in G is 
reduced to the problem of determining emptiness for 
the grammar G s. Also, the problem of parsing s with 
respect to the grammar G reduces to the problem of 
exhaustive generation of the derivations of G s (there is 
at most one string). Each of the tabular context-free 
recognition algorithms can be viewed as implicitly 
defining this grammar G s and testing it for emptiness. 
Emptiness testing is essentially done by reducing the 
grammar, that is by eliminating useless symbols and 
productions. The table-constructing portion of a tabu- 
lar recognition algorithm, in effect, constructs and 
reduces the grammar Gs, thus determining whether or 
not it is empty. The tabular methods differ in the 
construction and reduction algorithm used. 
In each case, to turn a tabular recognition method 
into a parsing algorithm, the table must first be con- 
structed and then reprocessed to generate all the pars- 
es. This corresponds to reprocessing the grammar Gs t, 
the result of reducing the grammar Gs, and using it to 
exhaustively generate all derivations in G s. 
Rather than formally defining G s from a context- 
free grammar G and a string s in the general case, we 
illustrate the definition by example. The general defi- 
nition should be clear. 
Let G be the following context-free grammar: 
Terminals: {a,b} 
Nonterminals: {S} 
Start Symbol: S 
Productions: S-~S S a 
S-~b 
S~e 
(S produces the empty string) 
bba. Gbb a is defined from G and Let s be the string 
bba: 
Terminals: 
Nonterminals: 
{a,b} 
{al,a2,a3,b!,b2,b3, 
(t i for t a terminal of G 
and 1 <i<lcngth(s))  
S123,512,51,S23,52,S 3, 
(A x for each nonterminal A of G 
and each x a nonempty subse- 
quence of < 1,2,3 ..... length(s)>) 
S?,Sl,S2,S 3} 
(A i for each nonterminal A of G 
and i, 0<i<length(s) )  
Start Symbol: S123 
Productions: \[from G production: S-~S S a\] 
S123~S12S2a3 
S123~S~S2a3 
S123~S Sl2a 3 
S 12"~ SIS a 2 
S12--~ SuSla2 
S 1 ~ S?S?a t
S23--~ S~52a3 
$23 ~ S'S2a 3 
$2~$1Sla2 
$3~$2S2a3 
\[from G production: S-~b\] 
Sl~b 1 
S2~b 2 
$3--~ 3
\[from G production: S-~ e\] 
S?-~ ?
s ly ?  
$2~ ? 
$3~ ? 
\[for the terminals\] 
b l -~b 
b2- -b  
a3~a 
These productions for G s were constructed by begin- 
ning with a production of G, adding a subscript or a 
superscript o the nonterminal on the LHS to obtain a 
nonterminal of Gs, adding single subscripts to all ter- 
minals and sequence subscripts to some nonterminals 
on the RHS so that the concatenation of all subscripts 
on the RHS equals the subscript on the LHS. For the 
RHS nonterminals without subscripts, add the appro- 
priate subscript. Also, to handle the terminals, for 
each t i add the production T i~t  where t is the i th sym- 
bol in s. 
It is straightforward to show inductively that if a 
nonterminal symbol generates any string at all it gen- 
erates exactly the substring of s that its subscript de- 
termines. Symbols with superscripts generate the emp- 
ty string. Also a parse tree of G s can be converted to 
a parse tree of G by first deleting all terminals (each is 
dominated by the same symbol with a subscript) and 
then erasing all superscripts and subscripts on all sym- 
bols in the tree. Conversely, any parse tree for s in G 
can be converted to a parse tree of s in G s by adding 
appropriate subscripts and superscripts to all the sym- 
bols of the tree and then adding the terminal symbols 
at the leaves. 
American Journal of Computational Linguistics, Volume 8, Number 3-4, July-December 1982 135 
David Scott Warren and Joyce Friedman Using Semantics in Non-Context-Free Parsing 
It is clear that G s is not in general a reduced gram- 
mar. G s can be reduced to Gs ~ by eliminating unpro- 
ductive and unreachable symbols and the rules involv- 
ing them. Reducing the grammar will determine 
whether or not L(Gs) is empty. By the above discus- 
sion, this will determine whether s is in L(G), and thus 
an algorithm for constructing and reducing the refined 
grammar G s from G and s yields a recognition algor- 
ithm. Also, given the reduced grammar Gs I, it is 
straightforward, in light of the above discussion, to 
generate all parses of s in G: simply exhaustively gen- 
erate the parse trees of Gs ~ and delete subscripts and 
superscripts. 
The tabular context- free recognition methods of 
Cocke-Kasami-Younger,  Earley, and Sheil can all be 
understood as variations of this general approach. The 
C-K-Y recognition algorithm uses the standard bottom- 
up method to determine emptiness of G s. It starts 
with the terminals and determines which G s nontermi- 
nals are productive, eventually finding whether or not 
the start symbol is productive. The matrix it con- 
structs is essentially the set of productive nonterminals 
of G s. 
Sheil's well-formed substring table algorithm is the 
most obviously and directly related. His simplest al- 
gorithm constructs the refined grammar and reduces it 
top-down. It uses a top-down control mechanism to 
determine the productivity only of nonterminals that 
are reachable from the start symbol. The well-formed 
substring table again consists essentially of the reacha- 
ble, productive nonterminals of G s. 
Earley's recognition algorithm is more complicated 
because it simultaneously constructs and reduces the 
refined grammar. It can be viewed as manipulating 
sets of subscripted nonterminals and sets of prod- 
uctions of G s. The items on the item lists, however, 
correspond quite directly to reachable, productive 
nonterminals of G s. 
The concept of input-refined grammar provides a 
unified view of the tabular context-free recognition 
methods. Equivalence parsing as described in Part I 
above is also a tabular method, although it is not 
context-free. It applies to context-free grammars and 
also to some grammars such as PTQ that are not 
context-free. We next relate it to the very general 
class of grammars defined by Montague in UG. 
Universal Grammar and Equivalence Parsing 
In the following discussion of the problem of pars- 
ing in the general context of Montague's definitions of 
a language (which might more naturally be called a 
grammar) and an interpretation, we assume the reader 
is familiar with the definitions in UG (Montague 
1970). We begin with a formal definition of a refine- 
ment of a general disambiguated language. A particu- 
lar type of refinement, input-refinement, leads to an 
equivalence parsing algorithm. This generalizes the 
procedure for input-refining a grammar shown above 
for the special case of a context-free grammar. We 
then discuss the implications for equivalence parsing of 
using the formal interpretation of the language. Final- 
ly we show how the ATN for PTQ and semantic equi- 
valence parsing fit into this general framework. 
Recall that a disambiguated language f~ = <A, Fv, 
X 8, S, 80>v~r ,~a can be regarded as consisting of an 
algebra <A,F~,>~,eF, with proper expressions A and 
operations Fv, basic expressions X 8 for each category 
index d eA, a set of syntactic rules S, and a sentence 
category index 80EA. A language is a pair <~2,R> 
where ~2 is a disambiguated language and R is a binary 
relation with domain included in A. Given a disambig- 
uated language 
~2 = <A, F~, X#, S, 80>~EF, ~EA, 
a disambiguated language 
f~v = <A, F~,Xts,, S t , 80v>~,EF, 8'EA' 
is a refinement of 12 if there is a ref inement function 
d:AW-.A from the category indices of fl '  to those of f~ 
such that 
1) Xt~ _c Xd(8 , )  ' 
2) If <F~,<~lW,~2t ..... 8n1>,St> E S v, then 
<F~,<d(81' ) ,d(~2' )  ..... d (~n ' )>,  d (8 ' )> E S',  and 
3) d(80')  = 60 . 
(Note that the proper expressions A, the operat ion 
indexing set F, and the operations Fy of ~ and 12 ~ are 
the same.) 
The word refinement refers to the fact that the 
catgories of lZ are split into finer categories. Condi- 
tion 1 requires that the basic expressions of a refined 
category come from the basic expressions of the cate- 
gory it refines. Condit ion 2 requires that the new 
syntactic rules be consistent with the old ones. Note 
that Condition 2 is not a biconditional. 
If 12 t is a refinement of ~2 with ref inement function 
d, <C '8 ,>~, ,~,  is the family of syntactic categories of 
~2' and <C0>0E a is the family of syntactic categories 
of ~2, then C'~,-cCd(~, ). 
As a simple example of a refinement, consider an 
arbitrary disambiguated language ~2 t = <A, Fy, Xts,, 
d0w>yEr,8, Ea,. NOW let ~2 be the disambiguated lan- 
guage <A, Fy, Xa, S, a>yEi-, in which the set of cate- 
gory names is the singleton set {a}. X a = O~,EA, X~,. 
Let S be {<Fr, <a,a ..... a>,  a> : yeF  and the number 
of a's agrees with the arity of F}. Then f~ is a refine- 
ment of ~, with ref inement function d:At-~{a}, d(8 ~) 
= a for all d~?A ~. Note that the disambiguated lan- 
guage ~2 is completely determined by the algebra 
<A,Fy>yeF, and is the natural disambiguated language 
to associate with it. Thus in a formal sense, we can 
view a disambiguated language as a ref inement of its 
algebra. 
136 American Journal of Computational Linguistics, Volume 8, Number 3-4, Ju ly -December 1982 
David Scott Warren and Joyce Friedman Using Semantics in Non-Context-Free Parsing 
As a more intuitive example of refinement, consider 
an English-like language with categories term (TE) and 
intransitive verb phrase (IV) that both include singular 
and plural forms. The language generated would then 
allow subject-verb disagreement (assuming the ambig- 
uating relation R does not filter them out). By refin- 
ing category TE to TEsing and TEpl and category IV to 
IVsing and IVpl, and having syntactic rules that com- 
bine category TEsing with IVsing and TEpl with IVpl 
only, we obtain a refined language that has subject- 
verb agreement. A similar kind of refinement could 
eliminate such combinations as "colorless green 
ideas", if so desired. 
With this definition of refinement, we return to the 
problem of parsing a language L = <~, R>. The 
problem can now be restated: find an algorithm that, 
given a string ~, constructs a disambiguated language 
~2~ that is an input-refinement of fL That is, f~ is a 
refinement in which the sentence category Cts, is ex- 
actly the set of parses of ~ in L. Finding this algor- 
ithm is equivalent to solving the parsing problem. For 
given such an algorithm, the parsing problem reduces 
to the problem of generating all members of C'80,. 
In the case of a general anguage <~, R>, it may 
be the case that for ~ a string, the input-refined lan- 
guage f~ has finitely many categories. In this case the 
reduced grammar can be computed and a recursive 
parsing algorithm exists. If the reduced grammar has 
infinitely many categories, then the string has infinitely 
many parses and we are not, in general, interested in 
trying to parse such languages. It may happen, how- 
ever, that ~2~ has infinitely many categories, even 
though its reduction has only finitely many. In this 
case, we are not guaranteed a recursive parsing algor- 
ithm. However, if this reduced language can be effec- 
tively constructed, a recursive parsing algorithm still 
exists. 
The ATN for PTQ represents the disambiguated 
language for PTQ in the UG sense. The categories of 
this disambiguated language correspond to the set of 
possible triples: PTQ category name, contents of 
SENDR registers at a PUSH to that subnet, contents of 
the LIFTR registers at the corresponding POP. The 
input-refined categories include the remainder of the 
input string at the PUSH and POP. Thus the buckets 
in the recall table are exactly the input-refined cate- 
gories. The syntactic execution method is thus an 
exhaustive generation of all expressions in the sen- 
tence category of the input-refined disambiguated 
language. 
Semantic Equivalence Parsing in OG 
In UG, Montague inclues a theory of meaning by 
providing a definition of interpretation for a language. 
Let L = <<A,F,r,Xs,S,t~0>.rEF,SEA,R> be a language. 
An interpretation ,t' for L is a system <B,G~,,f>3,EF 
such that <B,Gv>v~ r is an algebra similar to 
<A,F./>3,eF; i.e., for each ~, E F, Fy and G./ have the 
same number of arguments, and f is a function from 
O,EAX 8 into B. Note that the algebra <B,G~,>.rE F 
need not be a free algebra (even though <A,Fy>v? r 
must be). B is the set of meanings of the interpreta- 
tion ,I,; Gv is the semantic rule corresponding to syn- 
tactic rule Fv; f assigns meanings to the basic expres- 
sions Xv. The meaning assignment for L determined 
by if' is the unique homomorphism g from <A,F.r>~,EF 
into <B,Gy>,/E F that is an extension of f. 
There are two ways to proceed in order to find all 
the meanings of a sentence ~ in a language L = <f~, 
R> with interpretation ~. The first method is to gen- 
erate all members of the sentence category Cts0 , of 
the input-refined language ~2~. As discussed above, 
this is done in the algebra <A,F./>~,cF of ~ ,  using the 
syntactic functions Fv to inductively construct mem- 
bers of A from the basic categories of f~ and members 
of A constructed earlier and then applying g. The 
second method is to use the fact that g is a homomor- 
phism from <A,F.~>~,EF into <B,G. />~ F. Because g 
is a homomorphism, we can carry out the construction 
of the image of the sentence category entirely in the 
algebra <B,G~,>~,eF of the interpretation q'. We may 
use the G functions to construct inductively members 
of B from the basic semantic categories, that is, the 
images under g (and f) of the basic syntactic categor- 
ies, and members of B already constructed. The ad- 
vantage of carrying out the construction in the algebra 
of ,t, is that this algebra may not be free, i.e., some 
element of B may have multiple construction se- 
quences. By carrying out the construction there, such 
instances can be noticed and used to advantage, thus 
eliminating some redundant search. There are addi- 
tional costs, however, associated with parsing in the 
interpretation algebra q'. Usually, the cost of evaluat- 
ing a G function in the semantic algebra is greater 
than the cost of the corresponding F function in the 
syntactic algebra. Also in semantic parsing, each 
member of B as it is constructed is compared to the 
other members of the same refined category that were 
previously constructed. 
In the PTQ parsing system discussed above, the 
interpretation algebra is the set of reduced transla- 
tions. The semantic functions are those obtained from 
the functions given in the T-rules in PTQ, and reducing 
and extensionalizing their results. The directed proc- 
ess version of the parser finds the meanings in this 
algebra by the first method, generating all parses in 
the syntactic algebra and then taking their images un- 
der the interpretation homomorphism. Semantic equi- 
valence parsing for PTQ uses the second method, car- 
rying out the construction of the meaning entirely 
within the semantic algebra. The savings in the exam- 
ple sentence Bil l  walks and Mary runs comes about 
American Journal of Computational Linguistics, Volume 8, Number 3-4, July-December 1982 137 
David Scott Warren and Joyce Friedman Using Semantics in Non-Context-Free Parsing 
because the algebra of reduced translations is not a 
free algebra, and the redundant search thus eliminated 
more than made up for the increase in the cost of 
translating and comparing formulas. 
Summary  
We have descr ibed a parsing algor i thm for the lan- 
guage of PTQ v iewed as consist ing of two parts, a 
nondetermin is t ic  program and an execut ion  method.  
We showed how, with only a change to an equiva lence 
relat ion used in the execut ion method,  the parser be- 
comes a recognizer.  We then discussed the addit ion of 
the semantic  component  of PTQ to the parser. With 
again only a change to the equivalence relat ion of the 
execut ion  method,  the semant ic  parser  is obta ined.  
The semantic equiva lence relat ion is equal i ty (to with- 
in change of bound var iable)  of reduced extensional -  
ized translations. Examples  were given to compare the 
two parsing methods.  
In the f ina lpor t ion  of the paper we descr ibed how 
the pars ing method  init ial ly presented in procedura l  
terms can be v iewed in formal  grammat ica l  terms. 
The not ion of input - re f inement  for context - f ree  gram- 
mars was in t roduced by example,  and the tabular  
context - f ree  recogni t ion algorithms were descr ibed in 
these terms. We then indicated how this not ion of  
re f inement  can be extended to the UG theory of lan- 
guage and suggested how our semantic  parser is essen- 
tially parsing in the algebra of an interpretat ion for the 
PTQ language. 
References 
Bates, Madeleine 1978 The theory and practise of augmented 
transition network grammars. In Bole, Ed., Natural Lanauge 
Communication with Computers. New York: 191-260. 
Cooper, R. 1975 Montague's semantic theory and transformation- 
al syntax. Ph.D. thesis. Amherst, MA: University of Massa- 
chusetts. 
Earley, Jay 1970 An efficient context-free parsing algorithm. 
Comm. ACM 13, 94-102. 
Friedman, J., Moran, D., and Warren, D.S. 1978a Evaluating 
English sentences in a logical model. Abstract 16, Information 
Abstracts, 7th International Conference on Computational 
Linguistics. Norway: University of Bergen (11 pp.). 
Friedman, J., Moran, D., and Warren, D.S. 1978b Evaluating 
English sentences in a logical model, presented to the 7th Inter- 
national Conference on Computation Linguistics, University of 
Bergen, Norway (August 14-18). Report N-15. Ann Arbor, 
MI: University of Michigan, Computer and Communication 
Sciences Department (mimeographed). 
Friedman, J. and Warren, D.S. 1978 A parsing method for Mon- 
tague grammars. Lingustics and Philosophy 2, 347-372. 
Gawron, J.M., et al 1982 The GPSG linguistic system. In Pro- 
ceedings 20th Annual Meeting of  the Association for Computational 
Linguistics, 74- 81. 
Gazdar, G. 1979 English as a context-free language University of 
Sussex (mimeograph). 
Harel, David 1979 On the total correctness of nondeterministic 
programs. IBM Research Report RC 7691. 
Hintikka, J., Moravcsik, J., and Suppes, P., Eds. 1973 Approaches 
to Natural Language. Dordrecht: D. Reidel. 
Janssen, T.W.V. 1978 Compositionality and the form of rules in 
Montague grammar. In Groenenijk, J. and Stokhof, M., Eds., 
Proceedings of the Second Amsterdam Colloquium on Montague 
Grammar and Related Topics. Amsterdam Papers in Formal 
Grammar, Volume II. University of Amsterdam, 211-234. 
Janssen, T.W.V. 1980 On problems concerning the quantification 
rules in Montague grammar. In Roher, G., Ed., Time, Tense, 
and Quantifiers. Tuebingen, Max Niemeyer Verlag. 
Kasami, T. 1965 An efficient recognition and syntax-analysis 
algorithm for context-free languages. Science Report AFCRL- 
65-758. Bedford, MA: Air Force Cambridge Research Labora- 
tory. 
Landsbergen, S.P.J. 1980 Adaptation of Montague grammar to 
the requirements of parsing. M.S. 11.646. Eindhoven, The 
Netherlands: Philips Research Laboratories. 
Montague, Richard 1970 Universal grammar (UG). Theoria 36, 
373-398. 
Montague, Richard 1973 The proper treatment of quantification 
in ordinary English. In Hintikka, Moravcsik, and Suppes 1973. 
Reprinted in Montague 1974, 247-270. 
Montague, Richard 1974 Formal Philosophy: Selected Papers of  
Richard Montague. Edited and with an introduction by Rich- 
mond Thomason. New Haven, CT: Yale University Press. 
Rosenschein, S.J. and Shieber, S.M. 1982 Translating English into 
logical form. In Proceedings 20th Annual Meeting of  the Associa- 
tion for Computational Linguistics, 1-8. 
Sheil, B.A. 1976 Observations on context-free parsing. Statistical 
Methods in Linguistics 71-109. 
Warren, David S. 1979 Syntax and semantics in parsing: an appli- 
cation to Montague grammar. Ph.D. thesis. Ann Arbor, MI: 
University of Michigan. 
Winograd, T.A. 1972 Understanding Natural Language. New York: 
Academic Press. 
Woods, W.A. and Kaplan, R.M. 1971 The Lunar Sciences Natural 
Language Information System. BBN Report No. 2265. Cam- 
bridge, MA Bolt Beranek and Newman. 
Woods, W.A. 1973 An experimental parsing system for transition 
network grammars. In Rustin, R., Ed., Natural Language 
Processing. New York: Algorithmics Press, Inc., 111-154. 
138 American Journal of Computational Linguistics, Volume 8, Number 3-4, July-December 1982 
