Proceedings of the 9th SIGdial Workshop on Discourse and Dialogue, pages 120?127,
Columbus, June 2008. c?2008 Association for Computational Linguistics
A Frame-Based Probabilistic Framework for Spoken Dialog Manage-
ment Using Dialog Examples 
 
 
Kyungduk Kim, Cheongjae Lee, Sangkeun Jung and Gary Geunbae Lee 
Department of Computer Science and Engineering 
Pohang University of Science & Technology (POSTECH) 
San 31, Hyoja-Dong, Pohang, 790-784, Republic of Korea 
{getta, lcj80, hugman, gblee}@postech.ac.kr 
 
 
 
 
 
 
Abstract 
This paper proposes a probabilistic framework 
for spoken dialog management using dialog 
examples. To overcome the complexity prob-
lems of the classic partially observable Mar-
kov decision processes (POMDPs) based 
dialog manager, we use a frame-based belief 
state representation that reduces the complexi-
ty of belief update. We also used dialog ex-
amples to maintain a reasonable number of 
system actions to reduce the complexity of the 
optimizing policy. We developed weather in-
formation and car navigation dialog system 
that employed a frame-based probabilistic 
framework. This framework enables people to 
develop a spoken dialog system using a prob-
abilistic approach without complexity prob-
lem of POMDP. 
1 Introduction 
A robust dialog manager is an essential part of 
spoken dialog systems, because many such sys-
tems have failed in practice due to errors in speech 
recognition. Speech recognition errors can be 
propagated to spoken language understanding 
(SLU), so the speech input must be considered er-
ror-prone from a standpoint of dialog management. 
Therefore robust dialog managers are necessary to 
develop practical spoken dialog systems. 
One approach to dialog management uses the 
partially observable Markov decision process 
(POMDP) as a statistical framework, because this 
approach can model the uncertainty inherent in 
human-machine dialog (Doshi and Roy, 2007). 
The dialog manager uses a probabilistic, rather 
than deterministic, approach to manage dialog. As 
more information becomes available, the dialog 
manager updates its belief states. A POMDP-based 
dialog manager can learn the optimized policy that 
maximizes expected rewards by reinforcement 
learning. 
But applying classic POMDP to a practical di-
alog system incurs a scalability problem. The com-
putational complexity of updating belief states and 
optimizing the policy increases rapidly with the 
size of the state space in a slot-filling dialog task. 
To solve this scalability problem, the method of 
compressing states or mapping the original state 
space to summarized space can be used (Williams 
and Young, 2006; Roy et al,2005), but these algo-
rithms tend to approximate the state space exces-
sively. The complexity problem of POMDP comes 
from updating beliefs that are out of the user?s in-
tention, and from calculating the reward of system 
actions that do not satisfy user?s objective. 
In this paper, we propose a new probabilistic 
framework for spoken dialog management using 
dialog examples. We adopted a frame-based belief 
state representation to reduce the complexity of 
belief update. Furthermore, we used an example-
based approach to generate only a reasonable 
number of system action hypotheses in a new 
framework. We developed a dialog system by us-
ing our new framework in weather information 
service and car navigation service. 
120
2 Overview 
We try to address two problems of applying 
POMDP to slot-filling dialog management. 1) 
Computational complexity of belief update: it is 
difficult to maintain and update all belief states at 
every turn of dialog since there are too many di-
alog states in slot-filling dialog tasks. 2) Computa-
tional complexity of policy optimizing: optimizing 
complexity depends on both the space size of di-
alog states, and the number of available machine 
actions. In slot-filling dialog tasks, a system action 
can have various slot values so that the system 
needs to choose an action among a large number of 
action hypotheses. 
In our new probabilistic framework (Figure 1), 
we try to solve these problems. Our approach uses 
1) the frame-based belief state representation to 
solve the computational complexity problem of 
belief update and 2) the dialog examples to gener-
ate action hypotheses to solve the computational 
complexity of policy optimizing by reducing the 
number of system action hypotheses. First, the sys-
tem groups belief states dynamically using frame-
based belief state representation according to us-
er?s utterance and its SLU result. Then the system 
uses an example-based approach to generate only 
system action hypotheses that are suitable for cur-
rent belief states. If there are too many hypotheses 
for calculating expected utility, the system prunes 
them away until only a reasonable number of hy-
potheses remains. The following describes the de-
tails of each system?s component and the dialog 
managing process. 
User?s Utterance
SLU Result
Frame-bas d Belief 
St te Re r sentation
Dialog 
Example DB
Calculating
Utilities
System action
User?s Intention,
Semantic Frame,
Dialog History
Pruning 
Hypotheses
Lexico-semantic 
Similarity
Generating
Hypotheses
 
Figure 1. Overview of the system operation. Bold ar-
rows indicate the control flow. Thin arrows indicate the 
data flow.  
3 Frame-based Belief State Representation 
We assumed that the machine?s internal represen-
tation of the dialog state sm consists of three com-
ponents: user?s goal su, user?s last action au and 
dialog history sd. This section briefly describes the 
basic introduction of POMDP framework and ex-
plains each component of machine?s internal state 
in the standpoint of our frame-based probabilistic 
framework. 
3.1 POMDP for spoken dialog management 
A POMDP is defined as a tuple that consists of six 
substates: (S, A, P, R, ?, O) where S is a set of 
state, A is a set of action, P is a transition proba-
bility P(s?|s,a), R is a reward function R(s,a,s?), ? 
is a set of observation and O is an observation 
model P(o|s,a). The current state is not determinis-
tic in a POMDP framework while it is determined 
as a specific state in a Markov decision process 
(MDP) framework. In a POMDP, the probability 
distribution over all states s?S, which is referred 
as a belief state b(s), is maintained instead of de-
terministic state. At each time instant t, the system 
chooses an action a?A, and this causes the system 
to move from current state s to next state s? with 
the transition probability P(s? |s,a). Then, the sys-
tem is granted a reward R(s,a) while the system 
receives an observation o with probability of 
P(o|s?,a). The system computes the belief state in 
the next time instance b?(s?) as a following: 
 
? ????? s sbassPasoPksb )(),|(),|()(  
 
where k is a normalizing factor. This process is 
referred as belief update. 
Optimizing a POMDP policy is a process of 
finding a mapping function from belief states to 
actions that maximizes the expected reward. The 
system should compute a value function over be-
lief spaces to find optimized actions. However, 
unlike as in a MDP, each value in a POMDP is a 
function of an entire probability distribution and 
belief spaces are very complex, so that a POMDP 
has a scale problem of computing the exact value 
function. 
A POMDP for spoken dialog system is well 
formulated in (Williams and Young, 2007). First, a 
state s can be factored to three substates: (su, au, sd) 
121
where su is a user goal state, au is a user action, and 
sd is a dialog history. A system action am and user 
action au can be cast as action a and observation o 
respectively. With some independence assumption 
between variables, the belief update equation can 
be rewritten as following: 
 
,),,(           
),,|(),|(           
),|()|
~
(         
),,()(
?
? ?
???
?????
?????
???????
u
u d
a
duu
s s
mdudmuu
muuuu
duu
sasb
asasPassP
asaPaaPk
sasbb
 
where 
ua~?  is an automatic speech recognizer (ASR) 
and SLU recognition result of user action. In our 
framework, belief update is done based on this eq-
uation. But applying this directly to a spoken di-
alog system can have a problem because the 
probabilities used in the equation are hard to esti-
mate from the corpus due to the data sparseness. 
Therefore, we adopted Young?s (2007) belief up-
date formula that is simplified from the original 
equation. 
3.2 User goal state 
In a slot-filling dialog system, the user?s goal can 
be represented as a fully-filled frame in which all 
slots of the frame contain values specified by the 
user?s intention. Therefore, if a dialog system has 
W slots and each slot can have a value among V 
candidates, then VW user goals can be represented 
as frames. This means that the number of user 
goals is related exponentially to the number of 
slots. This number of user goals is intractable in 
practical dialog systems. 
Therefore, a method is needed to reduce the size 
of the state space rather than maintaining all belief 
states. To do this, we developed a frame-based be-
lief state representation in which the system dy-
namically groups set of equivalent states to a high-
level frame state. Frame state, which is a similar 
concept to the partition in the hidden information 
state (HIS) approach (Young et al 2007) 
represents the indistinguishable classes of user?s 
goals. The biggest difference between frame-based 
representation and partition-based representation is 
that the former uses only user input to split the 
frame state, whereas the latter uses the user input 
and external ontology rules such as a prior proba-
bility for belief of split partition. Therefore, the 
frame-based representation has relatively high do-
main portability because it does not need that kind 
of external domain dependent information. 
In the frame-based belief state representation, a 
partially-filled frame state represents the current 
user?s goal state for which the unfilled slot can be 
filled in the future, while a fully-filled frame state 
represents  co plete user?s goal state. Figure 2 
describes an example of the ubsumption relation-
ship between partially filled frames and fully filled 
frames.  
 
Figure 2. Subsumption relationship between partially 
filled frame and fully filled frame. The left frame is par-
tially filled and three frames in the right side are fully 
filled. 
 
At the start of a dialog, all states belong to the 
root frame state f0. As the dialog progresses, this 
root frame state is split into smaller frame states 
whenever the value of a slot is filled by the user?s 
input (Figure 3). First, if the user?s input [A=a] 
fills the slot of the root frame state f0, then it splits 
into two frame states: f1, which includes all user 
goal states with the slot A having ?a? as a value; 
and {f0-f1}, which is the relative complement of f1. 
Next, if the user?s input [B=b] is entered to the 
system, each frame f1 and {f0-f1} is split into small-
er frame states. The system updates not all belief 
states but only the beliefs of the frame states, so 
that the computational complexity remains rela-
tively small.  
If each user?s goal has uniform distribution, the 
belief of frame state b(f) can be calculated as fol-
lows:  
# of user goals contained in frame ( ) # of all user goals
fb f ?
 
This can be computed as follows:  
 
122
t
0
t
1
t
2
.
.
.
Root
Frame State
f
0
0( ) 1b f ?
{f
0
 - f
1
}
0 1
49
({ })
50
b f f? ?
f
1
(A = a)
1
1
( )b f
 f
3
(A = a)
(B = b)
3 2
1
( )
50
b f ?
{f
1 
? f
3
}
(A = a)
1 3 2
49
({ })
50
b f f? ?
 f
2
(B = b)
2 2
49
( )
50
b f ?
{{f
0
 - f
1
} - f
2
}
2
0 1 2 2
49
({{ } })
50
b f f f? ? ?
A = a
A != a
f
1 { f0 - f1}
f
0
A = a
B = b
A = a
B != b
A != a
B = b
A != a
B != b
f
3
{f
1 
? f
3
}
 f
2
{{f
0
 - f
1
} - f
2
}
User Input
A = a
User Input
B = b
User Input
C = c
Frame Splitting State Space
 
Figure 3. Splitting frame states and their beliefs with three user?s inputs. f0, f1, f2, ? denote frame states and b(f) 
means the belief of frame state f. A, B, C are the slot labels and a, b, c are the respective values of these slots. 
 
 
where Sfilled means the set of slots that are filled by 
the user?s input in frame state f, and SnotFilled means 
the set of empty slots. Vs denotes the set of availa-
ble values for slot s, and Vs? stands for the set of 
values for slot s that were specified by the user in 
other frame states. 
3.3 User action 
The SLU result of current user's utterance is used 
for the user action. The result frame of SLU con-
sists of a speech act, a main goal, and several 
named-entity component slots for each user's utter-
ance. The speech act stands for the surface-level 
speech act per single utterance and the main goal 
slot is assigned from one of the predefined classes 
which classify the main application actions in a 
specific domain such as ?search the weather 
(SEARCH_WEATHER)? or ?search the tempera-
ture (SEARCH_TEMPERATURE)? in the weather 
information service domain. The tasks for filling 
the named-entity component slots, such as, name 
of the city, name of the state, are viewed as a se-
quence labeling task. The Figure 4 shows some 
examples of predefined classes for SLU semantic 
frame in weather information service dialog system 
Our SLU module was developed based on the 
concept spotting approach, which aims to extract 
only the essential information for predefined mean-
ing representation slots, and was implemented by 
applying a conditional random field model (Lee et 
al., 2007).  
 
 
Figure 4 Example predefined classes for semantic frame 
of SLU in weather information service dialog system. 
 
3.4 Dialog history 
Similar to the traditional frame-based dialog 
management approach, a frame can represent the 
history of the dialog. The difference between the 
traditional frame-based dialog manager and our 
framework is that traditional frame-based dialog 
123
manager maintains only one frame while our 
framework can maintain multiple dialog hypothes-
es. Moreover, each hypothesis in our framework 
can have a probability as in the belief state of the 
classic POMDP.  
4 Example-based System Action Genera-
tion 
4.1 Example-based system action hypothesis 
generation 
It is impossible to consider all of the system ac-
tions as hypotheses because the number of possible 
actions is so large. We used an example-based ap-
proach to generate a reasonable number of system 
action hypotheses as hinted in (Lee et al, 2006). In 
this approach, the system retrieves the best dialog 
example from dialog example database (DEDB) 
which is semantically indexed from a dialog cor-
pus. To query a semantically close example for the 
current situation, the system uses the user?s inten-
tion (speech act and main goal), semantic frame 
(component slots) and discourse history as search 
key constraints (Lee et al, 2006). These search 
keys can be collected with SLU output (e.g., user 
intention and semantic frame) and discourse histo-
ry in a dialog manager. Figure 5 describes an ex-
ample of search key for DEDB on a weather 
information service system.  
 
User?s utterance  What will the temperature be tomorrow?  
                     Weather_Type  Time_Date  
Search key 
constraints  
Speech Act = wh_question  
Main Goal = search_temperature  
WEATHER_TYPE = 1 (filled) 
TIME_DATE = 1 (filled) 
LOC_CITY = 0 (unfilled) 
LOC_STATE = 0 (unfilled) 
Lexico-semantic  
Input 
What will the [WEATHER_TYPE] be 
[TIME_DATE]? 
Figure 5. Example search key constraints for dialog 
example database.  
 
For each frame state f1, ?, fn, the system gene-
rates one or more system action hypotheses by 
querying the DEDB respectively. Queried actions 
may inconsistent with the current frame state be-
cause the situation of indexed dialog examples 
may different from current dialog situation. There-
fore, the system maps the contents of dialog exam-
ple to information of current frame state. Slot 
values of frame state and information from content 
database (e.g., weather information database) are 
used for making the action consistent. If the system 
retrieves more than a threshold number of system 
action hypotheses using the search key constrains, 
then the system should prune away dialog exam-
ples to maintain only a reasonable number of hypo-
theses. We used lexico-semantic similarity 
between the user utterance and the retrieved exam-
ples to limit the number of hypotheses. To measure 
the lexico-semantic similarity, we first replace the 
slot values in the user utterance by its slot names to 
generate lexico-semantic input, and calculate the 
normalized edit distance between that input and 
retrieved examples (Figure 5). In the normalized 
edit distance, we defined following cost function 
C(i,j) to give a weight to the term which is re-
placed by its slot name. 
 
1, 2,
1, 2, 1, 2, _
1, 2, 1, 2, _
0  if                                       
( , ) 1  if  and ,  
1.5  if  and ,
i j
i j i j slot name
i j i j slot name
w w
C i j w w w w S
w w w w S
? ?
?? ? ??
? ? ??
 
 
where w1,i is ith word of user?s utterance, w2,j is jth 
word of dialog example?s utterance, and Sslot_name is 
the set of slot names. According to the lexico-
semantic similarity, the system appends the top Nh-
ranked hypotheses to the final action hypotheses 
(where Nh is the rank threshold). 
Many existing systems used heuristics or rule-
based approaches to reduce the number of system 
action hypotheses (Young et al, 2007). But these 
methods are not flexible enough to handle all di-
alog flows because a system developer should de-
sign new heuristics or rules whenever the system 
needs to support a new kind of dialog flow. The 
example-based approach, on the contrary, can in-
stantly refine the control of dialog flows by adding 
new dialog examples. This is a great advantage 
when a system developer wants to change or refine 
a dialog control flow. 
4.2 Calculating Expected Utilities 
We adopted the principle of maximum expected 
utility to determine the optimized system actions 
among the hypotheses (Paek and Horvitz, 2004). 
124
* argmax ( | )
argmax ( | ) ( , )
argmax ( ) ( , )
m
a
a h
h
a EU a
P H h u a h
b h u a h
?
?
?
? ?
?
?
?
?
 
 
where ? denotes all information about the envi-
ronment, u(a,h) means the utility of taking an ac-
tion when the internal state of the machine is h, 
which consists of three substates, (f, au, sd) : f is a 
frame state, au is a user?s last action, and sd is a 
dialog history. The utility function u(a,h) can be 
specific to each application. We defined a 
handcrafted utility function to calculate the ex-
pected utility. 
5 Experiments 
We performed two evaluations. 1) Real user evalu-
ation: we measured the user satisfaction with vari-
ous factors by human. 2) Simulated user 
evaluation: we implemented user simulator to 
measure the system performance with a large 
number of dialogs. We built dialog corpora in two 
domains: weather information service and car na-
vigation.  
5.1 Real user evaluation 
We built a dialog corpus in weather information 
service to measure the performance of the dialog 
system using our approach by real user evaluation. 
This corpus consists of 99 dialogs with 503 user 
utterances (turns). User?s utterances were anno-
tated with the semantic frame including speech 
acts, main goal and component slots for training 
the SLU module and indexing the DEDB. 
To evaluate the preliminary performance, four 
test volunteers among computer science people 
evaluated our dialog system with five different 
weather information-seeking tasks. The volunteers 
typed their utterances with a keyboard rather than 
using a real ASR because it is hard to control the 
WER. We employed a simulated ASR error chan-
nel by generating random errors to evaluate the 
performance of dialog management under various 
levels of WER. We will explain the details of our 
ASR channel simulator in Section 5.2. The WER is 
controlled by this ASR channel simulator while the 
volunteers were interacting with computer. To 
measure the user perception of task completion 
rate (TCR), the volunteers evaluated the system?s 
response in each dialog to measure the success turn 
rate (STR) and decided whether the entire dialog 
was successful or not. We evaluated the perfor-
mance of our dialog system based on criteria out-
lined in (Litman and Pan, 2004) by measuring user 
satisfaction, which is defined with a linear combi-
nation of three measures: TCR, Mean Recognition 
Accuracy (MRA), and STR. 
 
User Satisfaction = ?TCR +?STR + ?MRA 
 
In our evaluation, we set ?, ? and ? to 1/3, so 
that the maximum value of the user satisfaction is 
one.  
 
 
Figure 6 Dialog system performance with various word 
error rates in weather information seeking tasks. Dotted 
line is TCR; dashed line is STR; solid line is user satis-
faction. 
 
TCR, STR and user satisfaction decreased with 
WER. User satisfaction has relatively high value 
when the WER is smaller than 20% (Figure 6). If 
the WER is equal or over 20%, user satisfaction 
has small value because the TCR decreases rapidly 
in this range. 
Generally, TCR has a higher value than STR, 
because although a dialog turn may fail, users still 
have a chance to use other expressions which can 
be well recognized by the system. As a result of 
this, even when some dialog turns fail, the task can 
be completed successfully. 
TCR decreases rapidly when WER ?20%. 
When WER is high, the probability of losing the 
125
information in a user utterance is also large. Espe-
cially, if words contain important meaning, i.e., 
values of component slots in SLU, it is difficult for 
the system to generate a proper response. 
STR is 0.83 when WER is zero, i.e., although all 
user inputs are correctly recognized, the system 
sometimes didn?t generate proper outputs. This 
failure can be caused by SLU errors or malfunction 
of the dialog manager. SLU errors can be propa-
gated to the dialog manager, and this leads the sys-
tem to generate a wrong response because SLU 
results are inputs of dialog manger. 
If the WER is 20%, user satisfaction is relatively 
small because TCR decreases rapidly in this range. 
This means that our approach is useful in a system 
devoted to providing weather information, and is 
relatively robust to speech errors if the WER is less 
than 20%. 
5.2 Simulated user evaluation 
We built another dialog corpus in car navigation 
service to measure the performance of the dialog 
system by simulated user evaluation. This corpus 
consists of 123 dialogs with 510 user utterances 
(turns). The SLU result frame of this corpus has 7 
types of speech acts, 8 types of main goals, and 5 
different component slots. 
The user simulator and ASR channel simulator has 
been used for evaluating the proposed dialog man-
agement framework. The user simulator has two 
components: an Intention Simulator and a Surface 
Simulator. The Intention Simulator generates the 
next user intention given current discourse context, 
and the Surface Simulator generates user sentence 
to express the generated intention.  
ASR channel simulator simulates the speech 
recognition errors including substitution, deletion, 
and insertions errors. It uses the phoneme confu-
sion matrix to estimate the probability distribution 
for error simulation. ASR channel simulator dis-
torts the generated user utterance from Surface Si-
mulator. By simulating user intentions, surface 
form of user sentence and ASR channel, we can 
test the robustness of the proposed dialog system in 
both speech recognition and speech understanding 
errors. 
We defined a final state of dialog to automati-
cally measure TCR of a simulated dialog. If a di-
alog flow reaches the final state, the evaluator 
regards that the dialog was successfully completed. 
TCRs and average dialog lengths were measured 
under various WER conditions that were generated 
by ASR channel simulator. Until the SLU result is 
an actual input of the dialog manager, we also 
measured the SLU accuracy. If a SLU result is 
same as a user?s intention of the Intention Simula-
tor, then the evaluator considers that the result is 
correct. Unlike in the real user evaluation, the di-
alog system could be evaluated with relatively 
large amount of simulated dialogs in the simulated 
user evaluation. 5000 simulated dialogs were gen-
erated for each WER condition. 
 
 
Figure 7 TCR, SLU accuracy, and average dialog length 
of the dialog system under various WER conditions. 
 
We found that the SLU accuracy and TCR li-
nearly decreased with the WER. Similar in the 
human evaluation, TCR is about 0.9 when WER is 
zero, and it becomes below 0.7 when WER is 
higher than 20%. Average dialog length, on con-
trary, increased with WER, and it has similar val-
ues when WER is less than 10% although it 
increased relatively rapidly when WER is higher 
than 15%. 
 
6 Conclusions 
This paper proposed a new probabilistic method to 
manage the human-machine dialog by using the 
frame-state belief state representation and the ex-
ample-based system action hypothesis generation. 
The frame-based state representation reduces the 
computational complexity of belief update by 
grouping the indistinguishable user goal states. 
And the system generates the system action hypo-
126
theses with the example-based approach in order to 
refine the dialog flows easily. In addition, this ap-
proach employed the POMDP formalism to main-
tain belief distribution over dialog states so that the 
system can be robust to speech recognition errors 
by considering the uncertainty of user?s input. 
A prototype system using our approach has been 
implemented and evaluated by real and simulated 
user. According to the preliminary evaluation, our 
framework can be a useful approach to manage a 
spoken dialog system. 
We plan to progress the research on adopting a 
formalized online search to determine the optimal 
system action (Ross and Chaib-draa, 2007). With 
the online searching, system doesn?t need to be-
have the useless computation because this ap-
proach searches only possible path. We expect that 
this property of the online searching show the syn-
ergetic effect on dialog management if it combines 
with example-based approach. 
Similar to example-based approach, the case-
based reasoning approach (Eliasson, 2006) can be 
helpful for our future research. Some properties 
such as using previous cases to process current 
case can be shared with our approach. We think 
that some other properties including the concept of 
online learning can be useful for making our ap-
proach concrete 
Acknowledgments 
This research was supported by the MKE (Min-
istry of Knowledge Economy), Korea, under the 
ITRC (Information Technology Research Center) 
support program supervised by the IITA (Institute 
for Information Technology Advancement) (IITA-
2008-C1090-0801-0045) 
References  
Changki Lee, Jihyun Eun, Minwoo Jeong, and Gary 
Geunbae Lee, Y. Hwang, M. Jang, ?A multi-strategic 
concept-spotting approach for robust understanding 
of spoken Korean,? ETRI Journal, vol. 29, No.2, pp. 
179-188, 2007. 
 
Cheongjae Lee, Sangkeun Jung, Jihyun Eun, Minwoo 
Jeong and Gary Geunbae Lee, ?A situation-based di-
alogue management using dialogue examples,? in 
Proceedings of International conference on Acoustics, 
Speech, and Signal Processing, Toulouse, 2006. 
 
Diane J. Litman and Shimei Pan, ?Empirically evaluat-
ing an adaptable spoken dialogue system,? in Pro-
ceedings of the 8th International Conference on 
Spoken Language Processing, pp. 2145-2148, 2004. 
 
Finale Doshi and Nicholas Roy, ?Efficient Model 
Learning for Dialog Management,? in Proceeding of 
the ACM/IEEE international conference on Human-
robot interaction, Washington DC, 2007. 
 
Jason D. Williams and Steve Young, "Scaling POMDPs 
for dialog management with composite summary 
point-based value iteration (CSPBVI)," in Proceed-
ings of AAAI Workshop on Statistical and Empirical 
Approaches for Spoken Dialogue Systems, Boston, 
2006. 
 
Jason D. Williams and Steve Young, " Partially Observ-
able Markov Decision Processes for Spoken Dialog 
Systems." Computer Speech and Language 21(2): 
231-422, 2007 
 
Karolina Eliasson, ?The Use of Case-Based Reasoning 
in a Human-Robot Dialog System?, Licentiate of 
Engineering Thesis of Link?ping Institute of Tech-
nology at Link?ping University, 2006 
 
Nicholas Roy, Geoffrey Gordon, and Sebastian Thrun, 
?Finding approximate pomdp solutions through be-
lief compression,? Journal of Artificial Intelligence 
Research, vol. 23, pp.1?40, 2005. 
 
Spt?phane Ross, Brahim Chaib-draa, ?AEMS: An Any-
time Online Search Algorithm for Approximate Poli-
cy Refinement in Large POMDPs?, in Proceedings 
of the 20th International Joint Conference on Artifi-
cial Intelligence, 2007 
 
Steve Young, Jost Schatzmann, Karl Weilhammer and 
Hui Ye, "The hidden information state approach to 
dialog management," in Proceedings of International 
Conference on Acoustics, Speech, and Signal 
Processing, Honolulu, 2007. 
 
Tim Paek and Eric Horvitz, ?Optimizing automated call 
routing by integrating spoken dialog models with 
queuing models,? in Proceedings of HLT-NAACL, pp. 
41-48, Boston, 2004. 
 
 
127
