Dependency Tree Based Sentence Compression
Katja Filippova and Michael Strube
EML Research gGmbH
Schlo?-Wolfsbrunnenweg 33
69118 Heidelberg, Germany
http://www.eml-research.de/nlp
Abstract
We present a novel unsupervised method for
sentence compression which relies on a de-
pendency tree representation and shortens sen-
tences by removing subtrees. An automatic
evaluation shows that our method obtains re-
sult comparable or superior to the state of the
art. We demonstrate that the choice of the
parser affects the performance of the system.
We also apply the method to German and re-
port the results of an evaluation with humans.
1 Introduction
Within the field of text-to-text generation, the sen-
tence compression task can be defined as follows:
given a sentence S, consisting of words w1w2...wn,
what is a subset of the words of S, such that it
is grammatical and preserves essential information
from S? There are many applications which would
benefit from a robust compression system, such as
subtitle generation, compression for mobile devices
with a limited screen size, or news digests. Given
that to date most text and speech summarization
systems are extractive, sentence compression tech-
niques are a common way to deal with redundancy
in their output.
In recent years, a number of approaches to sen-
tence compression have been developed (Jing, 2001;
Knight & Marcu, 2002; Gagnon & Da Sylva, 2005;
Turner & Charniak, 2005; Clarke & Lapata, 2008,
inter alia). Many explicitly rely on a language
model, usually a trigram model, to produce gram-
matical output (Knight & Marcu, 2002; Hori & Fu-
rui, 2004; Turner & Charniak, 2005; Galley & McK-
eown, 2007). Testing the grammaticality of the out-
put with a language model is justified when work-
ing with a language with rigid word order like En-
glish, and all but one approach mentioned have
been applied to English data. However, compress-
ing sentences in languages with less rigid word or-
der needs a deeper analysis to test grammaticality.
And even for languages with rigid word order the
trigram model ignores the structure of the sentence
and therefore may significantly distort the meaning
of the source sentence. Approaches going beyond
the word level either require a comprehensive lexi-
con (Jing, 2001), or manually devised rules (Gagnon
& Da Sylva, 2005; Clarke & Lapata, 2008) to de-
termine prunable constituents. A lexicon is not al-
ways available, whereas the hand-crafted rules may
not cover all cases and are too general to be univer-
sally applicable (e.g. PPs can be pruned).
In this paper we present a novel unsupervised ap-
proach to sentence compression which is motivated
by the belief that the grammaticality of the output
can be better ensured by compressing trees. In par-
ticular, given a dependency tree, we want to prune
subtrees which are neither obligatory syntactic argu-
ments, nor contribute important information to the
content of the sentence. A tree pruning approach
does not generate new dependencies and is unlikely
to produce a compression with a totally different
meaning. Our approach is unsupervised and adapt-
able to other languages, the main requirement be-
ing that there are a dependency parser and a corpus
available for the languages. We test our approach
on English and German data sets and obtain results
comparable or superior to the state of the art.
25
2 Related Work
Many existing compression systems use a noisy-
channel approach and rely on a language model
to test the grammaticality of the output (Knight &
Marcu, 2002; Turner & Charniak, 2005; Galley &
McKeown, 2007). Other ways to ensure gram-
maticality and to decide whether a constituent is
obligatory or may be pruned are to utilize a sub-
categorization lexicon (Jing, 2001), or to define a
set of generally prunable constituents. Gagnon &
Da Sylva (2005) prune dependency trees by remov-
ing prepositional complements of the verb, subordi-
nate clauses and noun appositions. Apparently, this
does not guarantee grammaticality in all cases. It
may also eliminate important information from the
tree.
Most approaches are supervised and require train-
ing data to learn which words or constituents can
be dropped from a sentence (Riezler et al, 2003;
McDonald, 2006). However, it is difficult to obtain
training data. Still, there are few unsupervised meth-
ods. For example, Hori & Furui (2004) introduce
a scoring function which relies on such informa-
tion sources as word significance score and language
model. A compression of a given length which
maximizes the scoring function is then found with
dynamic programming. Clarke & Lapata (2008)
present another unsupervised approach. They for-
mulate the task as an optimization problem and solve
it with integer linear programming. Two scores con-
tribute to their objective function ? a trigram lan-
guage model score and a word significance score.
Additionally, the grammaticality of the output is en-
sured by a handful of linguistic constraints, stating
e.g. which arguments should be preserved.
In this paper we suggest an alternative to the pop-
ular language model basis for compression systems
? a method which compresses dependency trees and
not strings of words. We will argue that our formu-
lation has the following advantages: firstly, the ap-
proach is unsupervised, the only requirement being
that there is a sufficiently large corpus and a depen-
dency parser available. Secondly, it requires neither
a subcategorization lexicon nor hand-crafted rules to
decide which arguments are obligatory. Thirdly, it
finds a globally optimal compression by taking syn-
tax and word importance into account.
3 Dependency Based Compression
Our method compresses sentences in that it removes
dependency edges from the dependency tree of a
sentence. The aim is to preserve dependencies
which are either required for the output to be gram-
matical or have an important word as the dependent.
The algorithm proceeds in three steps: tree transfor-
mation (Section 3.1), tree compression (Section 3.2)
and tree linearization (Section 3.3).
3.1 Tree Transformation
Before a dependency tree is compressed, i.e. be-
fore some of the dependencies are removed, the tree
is modified. We will demonstrate the effect of the
transformations with the sentence below:
(1) He said that he lived in Paris and Berlin
The first transformation (ROOT) inserts an explicit
rootnode (Fig. 1(a)). The result of the second trans-
formation (VERB) is that every inflected verb in the
tree gets an edge originating from the rootnode (Fig.
1(b)). All edges outgoing from the rootnode bear the
s label. Apart from that we remove auxiliary edges
and memorize such grammatical properties as voice,
tense or negation for verbs.
The purpose of the remaining transformations is
to make relations between open-class words more
explicit. We want to decide on pruning an edge
judging from two considerations: (i) how important
for the head this argument is; (ii) how informative
the dependent word is. As an example, consider a
source sentence given in (2). Here, we want to de-
cide whether one prepositional phrase (or both) can
be pruned without making the resulting sentence un-
grammatical.
(2) After some time, he moved to London.
It would not be very helpful to check whether an ar-
gument attached with the label pp is obligatory for
the verb move. Looking at a particular preposition
(after vs. to) would be more enlightening. This
motivates the PREP transformation which removes
prepositional nodes and places them as labels on the
edge from their head to the respective noun (Fig.
1(c)). We also decompose a chain of conjoined ele-
ments (CONJ) and attach each of them to the head of
the first element in the chain with the label the first
26
Paris
Berlinand
he
live
say
he
in
root
s
(a) The source tree after ROOT.
Paris
Berlinand
he
live
say
he
in
root
s s
(b) After VERB
Paris
Berlinand
he
live
say
he
root
s
s
in
(c) After PREP
live
say
he
root
Paris Berlinhe
s
s
in
in
(d) After CONJ
Figure 1: The dependency structure of He said that he lived in Paris and Berlin after the transformations
element attaches to its head with (Fig. 1(d)). This
way we can retain any of the conjoined elements
in the compression and do not have to preserve the
whole sequence of them if we are interested in only
one. This last transformation is not applied to verbs.
3.2 Tree Compression
We formulate the compression task as an optimiza-
tion problem which we solve using integer linear
programming1. Given a transformed dependency
tree (a graph if new edges have been added), we de-
cide which dependency edges to remove. For each
directed dependency edge from head h to word w we
thus introduce a binary variable xlh,w where l stands
for the edge?s label:
xlh,w =
{
1 if the dependency is preserved
0 otherwise
(1)
The goal is to find a subtree which gets the highest
score of the objective function (2) to which both the
1In our implementation we use lp solve (http://
sourceforge.net/projects/lpsolve).
probability of dependencies (P (l|h)) and the impor-
tance of dependent words (I(w)) contribute:
f(X) =
?
x
xlh,w ? P (l|h) ? I(w) (2)
Intuitively, the conditional probabilities prevent us
from removing obligatory dependencies from the
tree. For example, P (subj|work) is higher than
P (with|work), and therefore the subject will be
preserved whereas the prepositional label and thus
the whole PP can be pruned. This way we do
not have to create an additional constraint for every
obligatory argument (e.g. subject or direct object).
Neither do we require a subcategorization lexicon to
look up which arguments are obligatory for a cer-
tain verb. Verb arguments are preserved because the
dependency edges, with which they are attached to
the head, get high scores. Table 1 presents the prob-
abilities of a number of labels given that the head
is study. Table 2 presents the probabilities for their
German counterparts.
Note that if we would not apply the PREP trans-
formation we would not be able to distinguish be-
27
subj dobj in at after with to
0.16 0.13 0.05 0.04 0.01 0.01 0.01
Table 1: Probabilities of subj, d(irect)obj, in, at, after,
with, to given the verb study
subj obja in an nach mit zu
0.88 0.74 0.44 0.42 0.09 0.02 0.01
Table 2: Probabilities of subj, obja(ccusative), in, at, af-
ter, with, to given the verb studieren
tween different prepositions and could only calcu-
late P (pp|studieren) which would not be very in-
formative. The probabilities for English are lower
than those for German because we calculate the con-
ditional probabilities given word lemma. In English,
the part of speech information cannot be induced
from the lemma and thus the set of possible labels
of a node is on average larger than in German.
There are many ways in which word importance,
I(w) can be defined. Here, we use the formula intro-
duced by Clarke & Lapata (2008) which is a modifi-
cation of the significance score of Hori et al (2003):
I(wi) =
l
N ? fi log
FA
Fi
(3)
wi is the topic word (either noun or verb), fi is the
frequency of wi in the document, Fi is the frequency
of wi in the corpus, and FA is the sum of frequencies
of all topic words in the corpus. l is the number of
clause nodes above w and N is the maximum level
of embedding of the sentence w belongs to.
The objective function is subject to constraints of
two kinds. The constraints of the first kind are stuc-
tural and ensure that the preserved dependencies re-
sult in a tree. (4) ensures that each word has one
head at most. (5) ensures connectivity in the tree.
(6) restricts the size of the resulting tree to ? words.
?w ? W,
?
h,l
xlh,w ? 1 (4)
?w ? W,
?
h,l
xlh,w ?
1
|W |
?
u,l
xlw,u ? 0 (5)
?
x
xlh,w ? ? (6)
? is a function of the length of the source sentence
in open-class words. The function is not linear since
the degree of compression increases with the length
of the sentence. The compression rate of human-
generated sentences is about 70% (Clarke & Lapata,
2008)2. To approximate this value, we set the pro-
portion of deleted words to be 20% for short sen-
tences (5-9 non-stop words), this value increases up
to 50% for long sentences (30+ words).
The constraints of the second type ensure the syn-
tactic validity of the output tree and explicitly state
which edges should be preserved. These constraints
can be general as well as conditional. The former
ensure that an edge is preserved if its source node
is retained in the output. Conditional syntactic con-
straints state that an edge has to be preserved if (and
only if) a certain other edge is preserved. We have
only one syntactic constraint which states that a sub-
ordinate conjunction (sc) should be preserved if and
only if the clause it belongs to functions as a sub-
ordinate clause (sub) in the output. If it is taken as
the main clause, the conjunction should be dropped.
In terms of edges, this can be formulated as follows
(7):
?xscw,u, xsubh,w ? xscw,u = 0 (7)
Due to the constraint (4), the compressed subtree
is always rooted in the node added as a result of the
first transformation. A compression of a sentence to
an embedded clause is not possible unless one pre-
serves the structure above the embedded clause. Of-
ten, however, main clauses are less important than an
embedded clause. For example, given the sentence
He said they have to be held in Beirut it is the em-
bedded clause which is informative and to which the
source sentence should be compressed. The purpose
of the VERB modification is to amend exactly this
problem. Having an edge from the rootnode to ev-
ery inflected verb allows us to compress the source
sentence to any clause.
3.3 Tree Linearization
A very simple but reasonable linearization technique
is to present the words of a compressed sentence in
the order they are found in the source sentence. This
method has been applied before and this is how we
2Higher rates correspond to longer compressions.
28
linearize the trees obtained for the English data. Un-
fortunately, this method cannot be directly applied to
German because of the constraints on word order in
this language. One of the rules of German grammar
states that in the main clause the inflected part of the
verb occupies the second position, the first position
being occupied by exactly one constituent. There-
fore, if the sentence initial position in a source sen-
tence is occupied by a constituent which got pruned
off as a result of compression, the verb becomes
the first element of the sentence which results in an
undesirable output. There are linearization meth-
ods developed for German which find an optimal
word order for a sentence (Ringger et al, 2004;
Filippova & Strube, 2007). We use our recent
method to linearize compressed trees.
4 Corpora and Annotation
We apply our method to sentences from two corpora
in English and German. These are presented below.
English Compression Corpus: The English data
we use is a document-based compression cor-
pus from the British National Corpus and
American News Text Corpus which consists of
82 news stories3. We parsed the corpus with
RASP (Briscoe et al, 2006) and with the Stan-
ford PCFG parser (Klein & Manning, 2003).
The output of the former is a set of dependency
relations whereas the latter provides an option
for converting the output into dependency for-
mat (de Marneffe et al, 2006) which we use.
Tu?Ba-D/Z: The German corpus we use is a col-
lection of 1,000 newspaper articles (Telljohann
et al, 2003)4. Sentence boundaries, morphol-
ogy, dependency structure and anaphoric rela-
tions are manually annotated in this corpus.
RASP has been used by Clarke & Lapata (2008)
whose state of the art results we compare with ours.
We use not only RASP but also the Stanford parser
for several reasons. Apart from being accurate, the
latter has an elaborated set of dependency relations
3The corpus is available from http://homepages.
inf.ed.ac.uk/s0460084/data.
4The corpus is available from http://www.sfs.
uni-tuebingen.de/en_tuebadz.shtml.
(48 vs. 15 of RASP) which is not overly large (com-
pared with the 106 grammatical relations of the Link
Parser). This is important for our system which
relies on syntactic information when making prun-
ing decisions. A comparison between the Stanford
parser and two dependency parsers, MiniPar and
Link Parser, showed a decent performance of the for-
mer (de Marneffe et al, 2006). It is also of interest to
see to what extent the choice of the parser influences
the results.
Apart from the corpora listed above, we use the
Tipster corpus to calculate conditional probabilities
of syntactic labels given head lemmas as well as
word significance scores. The significance score
is calculated from the total number of 128 mil-
lion nouns and verbs. Conditional probabilities are
calculated from a much smaller portion of Tipster
(about 6 million tokens). The latter number is com-
parable to the size of the data set we use to com-
pute the probabilities for German. There, we use
a corpus of about 4,000 articles from the German
Wikipedia to calculate conditional probabilities and
significance scores. The corpus is parsed with the
highly accurate CDG parser (Foth & Menzel, 2006)
and has the same dependency format as Tu?Ba-D/Z
(Versley, 2005).
Although all corpora are annotated with depen-
dency relations, there are considerable differences
between the annotation of the English and German
data sets. The phrase to dependency structure con-
version done by the Stanford parser makes the se-
mantic head of the constituent its syntactic head. For
example, in the sentence He is right it is the adjec-
tive right which is the root of the tree. Unlike that,
sentences from the German corpora always have a
verb as the root. To unify the formats, we write a set
of rules to make the verb the root of the tree in all
cases.
5 Evaluation
We evaluate the results automatically as well as with
human subjects. To assess the performance of the
method on the English data, we calculate the F-
measure on grammatical relations. Following Rie-
zler et al (2003), we calculate average precision and
recall as the amount of grammatical relations shared
between the output of our system and the gold stan-
29
dard variant divided over the total number of rela-
tions in the output and in the human-generated com-
pression respectively. According to Clarke & Lapata
(2006), this measure reliably correlates with human
judgements. The results of our evaluation as well as
the state of the art results reported by Clarke & Lap-
ata (2008) (LM+SIG+CONSTR), whose system uses
language model scoring (LM), word significance
score (SIG), and linguistic constraints (CONSTR),
are presented in Table 3. The F-measure reported
by Clarke & Lapata (2008) is calculated with RASP
which their system builds upon. For our system we
present the results obtained on the data parsed with
RASP as well as with the Stanford parser (SP). In
both cases the F-measure is found with RASP in or-
der to allow for a fair comparison between the three
systems. We recalculate the compression rate for the
gold standard ignoring punctuation. On the whole
corpus the compression rate turns out to be slightly
higher than that reported by Clarke & Lapata (2008)
(70.3%).
F-measure compr.rate
LM+SIG+CONSTR 40.5 72.0%
DEP-BASED (RASP) 40.7 49.6%
DEP-BASED (SP) 49.3 69.3%
GOLD - 72.1%
Table 3: Average results on the English corpus
As there are no human-generated compressions
for German data, we evaluate the performance of the
method in terms of grammaticality and importance
by means of an experiment with native speakers. In
the experiment, humans are presented with a source
sentence and its compression which they are asked
to evaluate on two five-point scales. Higher grades
are given to better sentences. Importance represents
the amount of relevant information from the source
sentence retained in the compression. Since our
method does not generate punctuation, the judges
are asked to ignore errors due to missing commas.
Five participants took part in the experiment and
each rated the total of 25 sentences originating from
a randomly chosen newspaper article. Their ratings
as well as the ratings reported by Clarke & Lapata
(2008) on English corpus are presented in Table 4.
grammar importance
LM+SIG+CONSTR 3.76 3.53
DEP-BASED (DE) 3.62 3.21
Table 4: Average results for the German data
6 Discussion
The results on the English data are comparable with
or superior to the state of the art. These were ob-
tained with a single linguistic constraint (7) and
without any elaborated resources which makes our
system adaptable to other languages. This suggests
that tree compression is a better basis for sentence
compression systems than language model-oriented
word deletion.
In order to explain why the choice of parser sig-
nificantly influences the performance of the method,
we calculate the precision P defined as the number
of dependencies shared by a human-generated com-
pression (depc) and the source sentence (deps) di-
vided over the total number of dependencies found
in the compression:
P = |depc ? deps||depc|
(8)
The intuition is that if a parser does not reach high
precision on gold standard sentences, i.e. if it does
not assign similar dependency structures to a source
sentence and its compression, then it is hopeless
to expect it to produce good compression with our
dependency-based method. However, the precision
does not have to be as high as 100% because of,
e.g., changes within a chain of conjoined elements
or appositions. The precision of the two parsers cal-
culated over the compression corpus is presented in
Table 5.
RASP Stanford parser
precision 79.6% 84.3%
Table 5: Precision of the parsers
The precision of the Stanford parser is about 5%
higher than that of RASP. In our opinion, this partly
explains why the use of the Stanford parser increases
the F-measure by 9 points. Another possible reason
for this improvement is that the Stanford parser iden-
tifies three times more dependency relations than
30
RASP and thus allows for finer distinctions between
the arguments of different types.
Another point concerns the compression rates.
The compressions generated with RASP are consid-
erably shorter than those generated with the Stanford
parser. This is mainly due to the fact that the struc-
ture output by RASP is not necessarily a tree or a
connected graph. In such cases only the first subtree
of the sentence is taken as input and compressed.
The results on the German set are not conclu-
sive since the number of human judges is relatively
small. Still, these preliminary results are compara-
ble to those reported for English and thus give us
some evidence that the method can be adapted to
languages other than English. Interestingly, the im-
portance score depends on the grammaticality of the
sentence. A grammatical sentence can convey unim-
portant information but it was never the case that an
ungrammatical sentence got a high rating on the im-
portance scale. Some of the human judges told us
that they had difficulties assigning the importance
score to ungrammatical sentences.
7 Conclusions
We presented a new compression method which
compresses dependency trees and does not rely on a
language model to test grammaticality. The method
is unsupervised and can be easily adapted to lan-
guages other than English. It does not require a
subcategorization lexicon or elaborated hand-crafted
rules to decide which arguments can be pruned and
finds a globally optimal compression taking syn-
tax and word importance into account. We demon-
strated that the performance of the system depends
on the parser and suggested a way to estimate how
well a parser is suited for the compression task. The
results indicate that the dependency-based approach
is an alternative to the language model-based one
which is worth pursuing.
Acknowledgements: This work has been funded
by the Klaus Tschira Foundation, Heidelberg, Ger-
many. The first author has been supported by a KTF
grant (09.009.2004). We would like to thank Yan-
nick Versley who helped us convert Tu?Ba-D/Z in the
CDG format and Elke Teich and the three anony-
mous reviewers for their useful comments.
References
Briscoe, Edward, John Carroll & Rebecca Watson
(2006). The second release of the RASP sys-
tem. In Proceedings of the COLING-ACL In-
teractive Presentation Session, Sydney, Australia,
2006, pp. 77?80.
Clarke, James & Mirella Lapata (2006). Models for
sentence compression: A comparison across do-
mains, training requirements and evaluation mea-
sures. In Proceedings of the 21st International
Conference on Computational Linguistics and
44th Annual Meeting of the Association for Com-
putational Linguistics, Sydney, Australia, 17?21
July 2006, pp. 377?385.
Clarke, James & Mirella Lapata (2008). Global in-
ference for sentence compression: An integer lin-
ear programming approach. Journal of Artificial
Intelligence Research, 31:399?429.
de Marneffe, Marie-Catherine, Bill MacCartney &
Christopher D. Manning (2006). Generating
typed dependency parses from phrase structure
parses. In Proceedings of the 5th International
Conference on Language Resources and Evalua-
tion, Genoa, Italy, 22?28 May 2006, pp. 449?454.
Filippova, Katja & Michael Strube (2007). Generat-
ing constituent order in German clauses. In Pro-
ceedings of the 45th Annual Meeting of the As-
sociation for Computational Linguistics, Prague,
Czech Republic, 23?30 June 2007, pp. 320?327.
Foth, Kilian & Wolfgang Menzel (2006). Hybrid
parsing: Using probabilistic models as predictors
for a symbolic parser. In Proceedings of the 21st
International Conference on Computational Lin-
guistics and 44th Annual Meeting of the Associa-
tion for Computational Linguistics, Sydney, Aus-
tralia, 17?21 July 2006, pp. 321?327.
Gagnon, Michel & Lyne Da Sylva (2005). Text
summarization by sentence extraction and syn-
tactic pruning. In Proceedings of Computational
Linguistics in the North East, Gatineau, Que?bec,
Canada, 26 August 2005.
Galley, Michel & Kathleen R. McKeown (2007).
Lexicalized Markov grammars for sentence com-
31
pression. In Proceedings of Human Language
Technologies 2007: The Conference of the North
American Chapter of the Association for Compu-
tational Linguistics, Rochester, N.Y., 22?27 April
2007, pp. 180?187.
Hori, Chiori & Sadaoki Furui (2004). Speech sum-
marization: An approach through word extraction
and a method for evaluation. IEEE Transactions
on Information and Systems, E87-D(1):15?25.
Hori, Chiori, Sadaoki Furui, Rob Malkin, Hua Yu
& Alex Waibel (2003). A statistical approach to
automatic speech summarization. EURASIP Jour-
nal on Applied Signal Processing, 2:128?139.
Jing, Hongyan (2001). Cut-and-Paste Text Summa-
rization, (Ph.D. thesis). Computer Science De-
partment, Columbia University, New York, N.Y.
Klein, Dan & Christopher D. Manning (2003). Ac-
curate unlexicalized parsing. In Proceedings of
the 41st Annual Meeting of the Association for
Computational Linguistics, Sapporo, Japan, 7?12
July 2003, pp. 423?430.
Knight, Kevin & Daniel Marcu (2002). Summariza-
tion beyond sentence extraction: A probabilistic
approach to sentence compression. Artificial In-
telligence, 139(1):91?107.
McDonald, Ryan (2006). Discriminative sentence
compression with soft syntactic evidence. In
Proceedings of the 11th Conference of the Eu-
ropean Chapter of the Association for Computa-
tional Linguistics, Trento, Italy, 3?7 April 2006,
pp. 297?304.
Riezler, Stefan, Tracy H. King, Richard Crouch &
Annie Zaenen (2003). Statistical sentence con-
densation using ambiguity packing and stochastic
disambiguation methods for Lexical-Functional
Grammar. In Proceedings of the Human Lan-
guage Technology Conference of the North Amer-
ican Chapter of the Association for Computa-
tional Linguistics, Edmonton, Alberta, Canada,
27 May ?1 June 2003, pp. 118?125.
Ringger, Eric, Michael Gamon, Robert C. Moore,
David Rojas, Martine Smets & Simon Corston-
Oliver (2004). Linguistically informed statisti-
cal models of constituent structure for ordering
in sentence realization. In Proceedings of the
20th International Conference on Computational
Linguistics, Geneva, Switzerland, 23?27 August
2004, pp. 673?679.
Telljohann, Heike, Erhard W. Hinrichs & Sandra
Ku?bler (2003). Stylebook for the Tu?bingen tree-
bank of written German (Tu?Ba-D/Z). Technical
Report: Seminar fu?r Sprachwissenschaft, Univer-
sita?t Tu?bingen, Tu?bingen, Germany.
Turner, Jenine & Eugene Charniak (2005). Su-
pervised and unsupervised learning for sentence
compression. In Proceedings of the 43rd An-
nual Meeting of the Association for Computa-
tional Linguistics, Ann Arbor, Mich., 25?30 June
2005, pp. 290?297.
Versley, Yannick (2005). Parser evaluation across
text types. In Proceedings of the 4th Workshop
on Treebanks and Linguistic Theories, Barcelona,
Spain, 9-10 December 2005.
32
