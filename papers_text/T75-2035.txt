! 
! 
Formal Reasoning 
~nd 
Language Understanding Systems 
Raymond Reiter 
Department of Computer Science 
University of Brit ish Columbia 
I .  Introduction 
Computat ional  studies in l inguistics 
have led to a variety of proposals~ for 
semantic representat ions of natural 
language. To a first approximation these 
all have a number of features in common. 
First, there is some formal language onto 
which, with the aid of a grammar, surface 
forms are mapped. Secondly, there is a 
formal language (usually, but not 
necessari ly, the same as the first) for the 
representat ion of world knowledge and which 
is used to perform inferences necessary for 
integrat ing the surface form into the 
knowledge structure, and/or for answering 
questions. Finally, there is, or should be 
\[5,18\] a specif icat ion of the semantics of 
these formal languages. 
There seem to be three dominant 
proposals for semantic representations: 
(I) Procedural semantics \[16,17\] where 
the underlying representat ion consists of 
procedures in some executable language. 
(2) Network structures \[11,13,14\] which 
represent knowledge by appropriate graphical 
data structures. 
(3) Logical representat ion \[3,7,12\] which 
express world knowledge by formulae in some 
formal calculus. 
These dist inct ions are not nearly as 
clear as one might like. Both logical and 
network representat ions often appeal to 
procedural components, networks appear to be 
representable as logical formlae via fairly 
direct mappings \[15\], while logical formulae 
have straight- forward procedural 
representat ions \[6\]. 
In this paper I shall discuss 
mechanisms for formal reasoning within 
logical representations. I shall make the 
(gross) assumption that surface forms have 
aleady been mapped onto some form of 
predicate calculus representation. In 
particular, I make no claims about the role 
or nature of the inferences required in 
mapping from surface structures to a logical 
deep structure. Neither do I take any 
posit ion on the primit ives of this deep 
structure. They may derive from a case 
oriented grammar, conceptual dependency 
theory etc. Ultimately, of course, the 
extent to which the choice of these 
primit ives faci l i tates inference will be a 
factor affecting this choice. I take it as 
self evident that no semantic representat ion 
can expl icit ly contain all of the 
information required by a language 
understanding system so there is a need for 
inferr ing new knowledge from that expl ic it ly 
represented. In this connection it is worth 
observing that, contrary to some prevai l ing 
opinions, formal reasoning does not preclude 
fuzzy or imprecise reasoning. There are no 
175 
a priori reasons why notions like 
"probably", "possibly", etc. cannot be 
formalized within a logical calculus and new 
imprecise knowledge deduced from old by 
means of prefectly definite and precise 
rules of inference. 
In the remainder of this paper I 
discuss two paradigms for formal reasoning 
with which I have worked - resolution and 
natural deduction - and argue in favour of 
the latter approach. I also indicate how 
other semantic representat ions - procedures 
and networks - might fit into this paradigm. 
Finally, I discuss some problems deriving 
from computat ional  l inguist ics which have 
not been seriously considered by researchers 
in formal inference but which I think might 
fruit ful ly be explored within a logical 
framework. 
2. Paradigms for Formal Reasoning 
A. Resolut ion \[10\] 
The resolut ion principle is based on 
five key concepts, two of which (the 
el iminat ion of quanif iers through the 
in t roduct ion  of Skolem functions, 
unif ication) are of part icular relevance to 
problems in the representat ion of l inguistic 
deep structures. 
I) The el imination of quantif iers 
One miht choose to assign to the 
statement "Every animal has a nose" a 
logical representat ion of the form 
(x ) (3y) \ [ANIMAL(x)~HAS-AS-PART(x ,y )  
NOSE(y)\] (I) 
As is well known, the sequence of 
quanti f iers at the head of this formula is 
cr it ical to its interpretat ion - 
interchanging them assigns a total ly 
different meanng to the formula. Hence each 
quanti f ier is assigned a scope which, 
roughly speaking, is the maximal part of the 
formula governed by that quantif ier. 
Unfortunately, the representat ion of 
quanti f iers and their scope leads to some 
complexity in processing this information. 
(Anyone who has faced this problem in 
semanic net representat ions is well aware of 
the dif f icult ies.)  An elegant solution is to 
replace each existent ia l ly  quanti f ied 
variable (y in (I)) by a new Skolem function 
(which in (I) we can call "nose") whose 
arguments are all of the universal ly 
quanti f ied variables (x in (I)) in whose 
scope the existential  variable lies. (Thus 
y is replaced by nose(x) in (I)). Next, all 
of the quanti f iers are deleted. The 
result ing formula is logical ly equivalent to 
the original. The quant i f ier- f ree formula 
of (I) is 
ANIMAL(x)~HAS-AS-PART(x ,nose(x ) )  
NOSE(nose(x)) (2) 
The reduction of formulae to 
quanif ier- free form also admits a primit ive 
form of inference by pattern matching 
(unif ication). 
(ii) Unif icat ion 
In effect the uni f icat ion algor i thm 
answers questions like "Is formula A an 
instance (special case) of formula B?" or 
"Is there a special case common to both A 
and B?" Unif ication is simply consistent 
pattern matching i.e. if a variable in one 
posit ion matches an expression, it must 
match the identical expression in some other 
position. Thus ANIMAL(x) unif ies with 
ANIMAL(fr i tz)  under the substitut ion 
fritzlx. HAS-AS-PART(fr i tz ,nose(fr i tz) )  
unif ies with HAS-AS-PART(x,nose(x))  again 
with fritzlx. P(x,f(x),y) unif ies with 
P(z,f(a),b) under the subst itut ion 
alz,alx,bly,  but fails to unify with 
P(b,f(a),b).  
(iii) Canonical form for formulae 
The resolut ion paradigm requires that a 
quant i f ier - f ree formula be converted to 
clausal form, i.e. a conjunct of disjuncts 
called clauses. The conversion algor ithm is 
quite straightforward involving Boolean 
transformatons of the form A~B~AV B, 
AB~AW B, AW BC~(A~ B) (AV C) etc. The 
formula (2) has two clauses in its canonical 
form: 
AN'IMAL(x) ~ HAS-AS-PART(x, nose(x)) 
~ x ~  V NOSE(nose(x)) (3) 
(iv) The resolut ion rule of inference 
There is but one rule of inference in 
resolut ion theory: If L IV~and L2~are  two 
clauses such that (a) LI and L2 are 
complementary literals. (A l iteral is a 
predicate symbol together with its 
arguments, or the negation of same. Two 
l iterals are complementary if they have the 
same predicate symbol, and one is unnegated 
while the other is negated.) 
(b) The argument list of LI is unif iab~ with 
that of L2 under a subst itut ion , then one 
can infer the new clause (gV~)~. For 
example, if we know tha cats are animals, or 
in clausal form 
~'~(y) V ANIMAL(y) 
then by unifying ANIMAL(y) on its 
complementary l iteral ANIMAL(x) in (3), we 
can infer 
~T(F )  V HAS-AS-PART(y,nose(F))  
CAT(y) NOSE(nose(y)) (4) 
i.e. cats have noses. If in addit ion it is 
known that CAT(fr itz),  then by unifying this 
on CAT(y) in (4), we can deduce the two 
clauses 
HAS-AS-PART(fr i tz ,nose(fr i tz) )  (5.1) 
NOSE(nose(fr i tz))  (5.2) 
(v) Completeness 
Resolut ion is a refutation loJ~ic i.e. 
if T is some statement to be proved, the 
clausal form of its negation is added to the 
clauses represent ing the knowledge base, and 
an attempt is made to derive a contradict ion 
by means of the single resolut ion inference 
rule. For exmple, to prove that Fritz has a 
nose i.e. 
(~z)\[NOSE(x) A HAS-AS-PART(fr i tz ,z) \ ]  
first negate, y ie ld ing__  
(z)\[N--6-~E(z) ~ HAS-AS-PART(fr i tz ,z) \ ] ,  
then remove the universal  quanti f ier which 
i~ds  the clause 
NOSE(z )v  HAS-AS-PART(fr i tz ,z) .  Resolving 
with (5.1) yields NOSE(nose(fr i tz))  which 
contradicts (5.2). 
176 
Resolution is also complete. This 
means that if T is indeed logical ly valid (T 
is true under all possible interpretat ions 
in which the knowledge base is true) then 
there is a refutation proof of T with 
resolut ion as the sole rule of inference. 
There are two observat ions one can make 
here. The first is that resolut in is very 
much a competence model for formal 
inference. By no stretch of the imagination 
can it be construed as a performance model, 
in part because of its canonical 
representat in for formulae, in part because 
of its "unnatural" rule of inference. 
Secondly, by virtue of its completeness 
resolut ion is provably adequate as a 
competence model, in contrast with 
l inguist ic competence models for which the 
adequacy of any proposed theory is largely 
an empir ical  question. 
It is the combinat ion of 
representat ional  security deriving from 
completeness and theoret ical  elegance 
deriving from the simpl ic ity of the 
underly ing logic that has led to so much 
intensive research into resolution. In 
particular, attempts to deal with the gross 
inef f ic iency of the theory have been largely 
syntactic, des igned to constrain the 
possible inferences that can be made, but 
without sacr i f ic ing the completeness 
security blanket. Very l ittle research has 
been devoted to the representat ion and use 
of domain knowledge, primarily, I think, 
because the ways in which humans use such 
knowledge have no correspondents within the 
resolut ion paradigm. 
B. Natural  Deduct ion Systems\[ l ,8,9\]  
These can best be character ized as 
attempts to define a performance model for 
logical reasoning, in contrast to resolut ion 
as a competence model. In particular, any 
such model must make use of all of the 
domain specif ic "non- logical"  knowledge 
avai lable to a human, and make use of it in 
corresponding ways. Among the features of 
such systems are the following: 
(i) Formulae are quanti f ier- free,  but remain 
in their "natural" form. Thus, (I) is 
represented in the form (2), not as (3). 
(ii) There are many (not just one) rules of 
inference~ each corresponding to some 
observable inference mechanism used in human 
reasoning. Some examples: (grossly 
simplif ied. In part icular the role of 
uni f icat ion is suppressed.) 
(a) General ized modus ponens. If 
AAB~C~D is a known fact, and if A,B and C 
are all known facts, then D may be deduced 
as a new known fact. If one of A,B or C is 
not known, no deduction is made. 
(b) Back-chaining. If the current subgoal 
is to prove D, and if W~D is known, then a 
possible next subgoal is to prove W. 
(c) Case analysis. If AV  B is known, 
generate two cases, one a context in which A 
is assumed true, the other a context in 
which B is true, and proceed with the proof 
for each context. 
(d) Spl i t t ing conjunct ive subgoals. If 
I 
I 
I 
I 
! 
I 
! 
I 
I 
! 
! 
i 
a 
l 
l 
I 
i 
I 
I 
1 
I 
I 
I 
I 
! 
l 
I 
I 
.I 
I 
I 
i 
i 
i 
I 
I 
I 
I 
the current subgoal is to prove AAB,  first 
prove A, then prove B. 
(e) Impl icative subgoals. If the current 
subgoal is to prove A~B,  update the current 
context with A, and prove B. 
Quite a number of addit ional  inference 
rules are possible. I have given a few 
examples only to indicate the flavour of the 
approach, and its naturalness. Some 
observations. First, the logic yields 
direct proofs, each of which must be 
provable assuming that its ancestor 'is 
Drovable. This property turns out to be 
crit ical for the appl icat ion of domain 
specif ic knowledge for reducing search. 
(See (iii) below.) I know of no resolution 
logic with this property. Thirdly, the 
search for a proof proceeds by decomposing a 
problem into simpler problems as in rules 
(c), (d) and (e). Finally, there is an 
explicit  representat ion of local contexts 
which prevents irrelevant formulae in 
adjacent contexts from pol lut ing the local 
search. By way of contrast, resolut ion 
systems operate in a single global context. 
(iii) Central to the natural deduction 
approach is it emphasis on the 
representat ion and appropriate use by the 
logic of domain specif ic knowledge. 
Examples of such knowledge are models, 
counterexamples, special cases etc. The 
fact that, as noted in (ii), each subgoal W 
must be provable provides the logic with a 
handle on how to use such knowledge. For if 
W or some special case of W is false in a 
model, or if there is a known counterexample 
to W, then there is no point in trying to 
prove it. If W is true in some model, or if 
it is possible to derive consequences of W 
which are known to be true, then there is 
addit ional  evidence to warrant trying to 
prove it. 
In some approaches \[9\] formulae in the 
knowledge base may have associated with them 
domain specif ic knowledge indicating how 
best to use that formula in the search for a 
proof. For example, in view of the enormous 
number of possible animals, there would be 
associated with CAT(y)~ANIMAL(y)  the 
advice: If you are trying to prove that 
something is an animal and you don't 
current ly know it to be a cat, don't try to 
prove it is a cat. The representat ion of 
this kind of knowledge clearly derives from 
the exhortat ions of the procedural ist  \[6\]. 
(iv) Natural  deduction systems are 
incomplete. This seems to be a necessary 
consequence of their emphasis on generat ing 
subgoals each of which must be provable. 
There are serious questions as to whether 
this is a sat isfactory state of affairs. A 
facile argument has it that humans are 
necessar i ly  incomplete (because of natural 
time and space bounds) so there is no need 
for computat ional  logic to concern itself 
with this issue. However, for a logic to 
qual i fy as a performance model, it must be 
incomplete in precisely the ways that we 
are. The fact is that we overcome some of 
the l imitat ions to time and space bounds by 
appeal ing to a variety of "non-logical" 
processes. Typical of these processes is 
177 
the inspired guess which one encounters in 
mathematics whenever an induction hypothesis 
is proposed, or some obscure expressin is 
somehow pulled out of a hat to make a proof 
go through. One thing is certain. Neither 
the induction hypothesis, nor the expression 
was discovered by any process of pattern 
directed (via unif icat ion) search using the 
rules of inference of a logic, despite the 
fact that completeness guarantees the 
ult imate success of such a search. The 
di f f iculty with formulat ing an appropriate 
notion of completeness for a performance 
model is precisely in character iz ing these 
non- logical  processes and how they function 
in "completing" the under ly ing logical ly 
incomplete rules of inference. One of the 
virtues of natural deduction systems is that 
this dist inct ion between logical and 
non- logical  processes is made, and that it 
is possible in some fairly general 
s ituations for the logic to recognize when 
to invoke appropriate external routines \[9\]. 
3. The Two Cultures - Future Prospects 
It is safe to say that there has been 
little communicat ion between researchers in 
computat ional  l inguist ics and formal 
inference. The Just i f icat ion seems to be 
that the former are concerned with 
performing shallow inference on large 
knowledge bases, whereas the latter focus on 
deep inference over relat ively small 
domains. I believe this dist inct ion is a 
superf ic ia l  one, and that each discipl ine 
has much to gain from the problems and 
proposed solutions of the other. As an 
example of how a logical paradigm can be 
relevant to current ideas in computat ional  
l inguistics, consider the relat ionship 
between semantic nets and logical 
representat ions.  
Almost all of the quest ion-answer ing 
systems that I know of use semantic nets for 
their inferencing component despite the fact 
that 
(a) their semantics is by no means 
clear \[18\] 
(b) there are serious di f f icult ies in 
represent ing and processing quanti f iers and 
their scopes 
(c) no methods have been proposed for 
computing on a net which yield inferencing 
capabi l i t ies even remotely approximat ing 
those of a natural deduction system - 
capabi l i t ies which we know humans possess. 
These are all non-problems for an 
appropr iate logical system. Nevertheless, 
there are def inite virtues to semantic nets 
as knowledge representat ions,  especial ly  
their use in forming associat ions among 
concepts and their explicit  representaion of 
superset links. It seems to me that there 
would be definite advantages to interfacing 
a natural deductive system with a semantic 
net, each component doing what it does best. 
In its simplest real ization, imagine a net 
all of whose nodes denote nominal concepts 
and all of whose links denote "subset" or 
"superset". Within the logic, each variable 
and function symbol occurr ing in a formula 
is assigned a type which is the domain over 
which the varible is meant to range or the 
range of the function Symbol. Each such 
type has a corresponding node in the net. 
For example, (2) would be represented as 
HAS-AS-PART(x{ANIMAL},nose{NOSE}(x{ANIMAL} 
)) (6) 
The general fact that cats are animals 
has no representat ion in the logical 
component, but is represented in the net by 
appropr iately linked CAT and ANIMAL nodes. 
Now the question "Does Fritz have a nose?" 
translates to an attempt to prove 
HAS-AS-PART(fr i tz{CAT}, y{NOSE}). If we 
could unify this with (6) the question would 
be answered. However, a term (in this case 
x) cannot unify with another term (fritz) 
unless their types are compatible. To 
determine compat ib i l i ty the  unif ier calls on 
the semantic net processor to check whether 
a path of superset links connects node CAT 
to node ANIMAL. In this case there is such 
a path, so the unif icaton succeeds. 
Notice how each component benefits from 
the presence of the other. The logic 
benefits by processing fewer, and 
considerably more compact formulae than 
would otherwise be necessary. (Compare (6) 
with (2)). In particular, compact i f icat ion 
el iminates many logical connectives, which 
has the effect of reducing the number of 
appl icat ions of rules of inference in 
deriving a result. This is so because these 
rules are "connective driven". Since search 
is largely a matter of the nondeterminist ic  
appl icat ion of rules of inference, the 
search space is reduced. Notice also that 
the unif ier is now responsible for some 
inference beyond that of simple pattern 
matching. From a search strategic point of 
view there are sound reasons for encouraging 
this transfer of logical power from the 
rules of inference to the unifier. Thus, 
the unif ier should also be responsible for 
dealing general ly with transit ive and 
ref lexive relat ions by appeal ing to 
computat ions on appropriate data structures 
which represent these relations. The 
general point of view here is that as much 
of the inferencing as possible should be 
effected computat ional ly  rather than 
logically, leaving the logic to deal with 
"diff icult" problems. Given this view, a 
semantic net is just one of a whole class of 
possible data structures which faci l i tate 
computat ion as a substitute for certain 
kinds of deduction. Assuming that it is 
possible to isolate "what nets do best" the 
designer of a net is free to tune its 
representat ion and procedures with respect 
to a few well defined tasks without concern 
for its general inferencing abi l i t ies (or 
lack thereof). 
Finally, it must be admitted that there 
are a host of problems deriving from 
l inguistic considerat ions which have not 
even been considered by researchers in 
formal inference. Many of these problems, 
in part icular most of the "fuzzy" kinds of 
reasoning described in \[2\], probably cannot 
be nicely incorporated in any paradigm for 
formal inference. Nevertheless, there 
remain many interest ing questions worth 
178 
exploring within a logical framework. 
(i) Other quantif iers. Logic has been 
content to deal with just two quanti f iers - 
"there exists" and "for all". Natural 
language invokes a whole spectrum of 
quanti f iers - "most of", "many of", "seven 
of", "a few of", etc. There is no 
dif f iculty in augmenting the syntax of a 
logical formal ism with new quanti f iers 
corresponding to these. The di f f iculty is 
in defining their semantics, and in 
specify ing appropriate new rules of 
inference. It is possible, for example, to 
define "most-of" in some set theoretic 
formal ism which effect ively says "more than 
80%", but I find this approach unsatisfying. 
A dif ferenct approach, borrowing on the 
successful  treatment of "there exists" in 
logic, might define "most-of" as a Skolem 
function with certain propert ies pecul iar to 
our understanding of the meaning of "most 
of". Thus, one property of the "Skolem 
function" most-of  is that it unif ies with 
any term of the same type as the argument to 
most-of; the unif ier returns the atom 
"probably". Thus, "Most dogs bark" becomes 
something like BARK(most-of(x{DOG})) ,  and 
"Does Fido bark?" translates to 
BARK(f ido{DOG}).  Unif icat ion succeeds and 
we conclude something like 
PROBABLY(BARK(f ido{DOG})) .  Clearly there 
are plenty of problems here not least what 
we mean by "probably", but the example gives 
the f lavour of a possible logical approach, 
as well as an indicat ion how certain kinds 
of "fuzzy" reasoning might be modeled in an 
extended logic. 
(ii) Dif ferent levels of memory - contexts 
for wanting, needing etc. Consider 
represent ing "x wants P" in some logical 
formalism, where P is an arbitrary 
proposit ion. In speci fy ing the propert ies 
of "WANT" we shall need (among other things) 
some kind of schema of the form 
WANTS(x,P) A Q 
WANTS(x, anything derivable from P and 
Q) (7) 
where Q is an arbitrary proposit ion. This 
is unl ike anything that researchers in 
formal inference have had to deal with. One 
possible approach, deriving from the context 
mechanism in natural deduct ion systems, is 
to maintain a variety of contexts, one 
contain ing formulae assumed universal ly  true 
(the knowledge base), and for each 
individual  x who wants something a context 
of all the formulae represent ing what x 
wants. Notice that within a want-context 
there is no commitment to the truth value of 
a formula - x may want a unicorn. The role 
of the schema (7) is assumed by the logic 
which knows which intercontextual  inferences 
are legal. 
(iii) Computat ion vs. deduction. This is a 
general problem involving the trade-off  
between the general i ty of deduct ion with its 
attendant ineff iciency, and the use of 
highly tuned procedural  special ists.  My 
part icular  bias is that one cannot entirely 
do away with deduction, but that the logic 
saould recognize if and when a deduction is 
best done procedural ly, call the right 
special ist,  and know what to do with the 
I 
I 
I 
I 
I 
I 
I 
I 
i 
! 
results returned. This point of view is 
reflected in my earlier suggestion that one 
possible role for a semantic net is as a 
specialist for checking compatibility of 
types. Similarly, work in procedural 
semantics (e.g.\[17\]) can be viewed as 
complementary to deduction, not as an 
antithetical paradigm. 
Ideally, what we want is "search-free" 
inference i.e. an appropriate collection of 
procedural specialists together with some 
supervisory system which knows which 
specialist to call, and when. If the 
specialists are "factored out" there is no 
logic left. The possibility of realizing 
this ideal seems to me remote, if only 
because mathematics is a human activity 
which does require formal inference and 
hence search. Consequently, it is important 
to better understand this trade-off between 
computation and deduction (or the particular 
and the general) and we can hope that in the 
future researchers in formal reasoning will 
clarify some of the issues. In this 
connection it is worth remarking that the 
distinction between computation and 
deduction is by no means clear \[4\]. 
REFERENCES 
\[I\] Bledsoe, W.W., Boyer, R.S. and 
Henneman, W.H., Computer proofs of limit 
theorems, Artificial Intelligence, 3 
(1972), pp. 27-60. 
\[2\] Carbonell, J.R. and Collins, A.M., 
Natural semantics in artificial 
intelligence, Proc. Third IJCAI, 
Stanford University, Stanford, CA 
(1973), pp.344-351. 
\[3\] Coles, L.S., An on-line 
question-answering system with natural 
language and pictorial input, Proc. ACM 
23rd Natl. Conf. (1968), pp.157-167. 
\[4\] Hayes, P.J., Computation and deduction, 
Proc. Symposium on the Mathematical 
Basis of Computation, Czech. Academy of 
Sciences (1973). 
\[5\] Hayes, P.J., Some problems and  
non-problems in representation theory, 
Proc. AISB Summer Conf., University of 
Sussex,Brighton, U.K. (1974), pp.63-79. 
\[6\] Hewitt, C., Description and theoretical 
analysis (using schemata) of PLANNER: A 
language for proving theorems and 
manipulating models in a robot, AI 
TR-258 (1972), AI Lab., M.I.T. 
\[7\] McCarthy, J. and Hayes, P., Some 
philosophical problems from the 
standpoint of artificial intelligence, 
Machine Intelligence ~, Meltzer and 
Michie (eds), pp.463-502 (American 
Elsevier, NYC 1969). 
\[8\] Reiter, R., A semantically guided 
deductive system for automatic 
theorem-proving, Proc. Third IJCAI, 
Stanford University, Stanford CA (1973), 
pp.41-46. 
\[9\] Reiter, R., A paradigm for formal 
reasoning, Dept. of Computer Science, 
Univ. of British Columbia 
(forthcoming). 
\[10\] Robinson, J.A., A machine oriented 
logic based on the resolution principle, 
J_=. ACM, 12 (1965), pp.23-41. 
179 
\[11\] Rumelhart, D.E. and Norman, D.A., 
Active semantic networks as a model of 
human memory, Proc. Third IJCAI, 
Stanford University, Stanford CA (1973), 
pp.450-457. 
\[12\] Sandewall, E.J., Representing natural 
language information in predicate 
calculus, Machine Intelligence 6, 
Meltzer and Michie (eds), pp. 255-277. 
\[13\] Schank, R.C., Identification of 
conceptualizations underlying natural 
language, Computer Models of Thought and 
Language, Schank and Colby (eds), 
pp.187-247, (W.H. Freeman and Company, 
San Francisco CA, 1973). 
\[14\] Simmons, R.F., Semantic networks: their 
computation and use for understanding 
English sentences, Computer Models of 
Thought and Language, Schank and Colby 
(eds), pp.63-113. 
\[15\] Simmons, R.F. and Bruce, B.C., Some 
relations between predicate calculus and 
semantic net representations of 
discourse, Proc. Second IJCAI, The 
British Computer Society, London (1971), 
pp.524-530. 
\[16\] Winograd, T., Understanding Natural 
Language, Cognitive Psychology, 3, 
(1972). 
\[17\] Woods, W.A., Procedural semantics for a 
question-answering machine, AFIPS Conf. 
Proc., FJCC, 33 (Part I), (1968), 
pp.457-471. 
\[18\] Woods, W.A., What's in a link: 
Foundations for semantic networks, 
ReDresentation and Understanding, Bobrow 
and Collins (eds), Academic Press 
(forthcoming). 
