Proceedings of the EACL 2012 Workshop on Computational Linguistics and Writing, pages 9?18,
Avignon, France, April 23, 2012. c?2012 Association for Computational Linguistics
From Drafting Guideline to Error Detection:
Automating Style Checking for Legislative Texts
Stefan H?fler
University of Zurich, Institute
of Computational Linguistics
Binzm?hlestrasse 14
8050 Z?rich, Switzerland
hoefler@cl.uzh.ch
Kyoko Sugisaki
University of Zurich, Institute
of Computational Linguistics
Binzm?hlestrasse 14
8050 Z?rich, Switzerland
sugisaki@cl.uzh.ch
Abstract
This paper reports on the development of
methods for the automated detection of vi-
olations of style guidelines for legislative
texts, and their implementation in a pro-
totypical tool. To this aim, the approach
of error modelling employed in automated
style checkers for technical writing is en-
hanced to meet the requirements of legisla-
tive editing. The paper identifies and dis-
cusses the two main sets of challenges that
have to be tackled in this process: (i) the
provision of domain-specific NLP methods
for legislative drafts, and (ii) the concretisa-
tion of guidelines for legislative drafting so
that they can be assessed by machine. The
project focuses on German-language legisla-
tive drafting in Switzerland.
1 Introduction
This paper reports on work in progress that is
aimed at providing domain-specific automated
style checking to support German-language legisla-
tive editing in the Swiss federal administration. In
the federal administration of the Swiss Confedera-
tion, drafts of new acts and ordinances go through
several editorial cycles. In a majority of cases, they
are originally written by civil servants in one of
the federal offices concerned, and then reviewed
and edited both by legal experts (at the Federal
Office of Justice) and language experts (at the Fed-
eral Chancellery). While the former ensure that
the drafts meet al relevant legal requirements, the
latter are concerned with the formal and linguistic
quality of the texts. To help this task, the author-
ities have drawn up style guidelines specifically
geared towards Swiss legislative texts (Bundeskan-
zlei, 2003; Bundesamt f?r Justiz, 2007).
Style guidelines for laws (and other types of
legal texts) may serve three main purposes: (i) im-
proving the understandability of the texts (Lerch,
2004; Wydick, 2005; Mindlin, 2005; Butt and
Castle, 2006; Eichhoff-Cyrus and Antos, 2008),
(ii) enforcing their consistency with related texts,
and (iii) facilitating their translatability into other
languages. These aims are shared with writing
guidelines developed for controlled languages in
the domain of technical documentation (Lehrndor-
fer, 1996; Reuther, 2003; Muegge, 2007).
The problem is that the manual assessment of
draft laws for their compliance with all relevant
style guidelines is time-consuming and easily in-
consistent due to the number of authors and editors
involved in the drafting process. The aim of the
work presented in this paper is to facilitate this
process by providing methods for a consistent au-
tomatic identification of some specific guideline
violations.
The remainder of the paper is organised as fol-
lows. We first delineate the aim and scope of the
project presented in the paper (section 2) and the
approach we are pursuing (section 3). In the main
part of the paper, we then identify and discuss
the two main challenges that have to be tackled:
the technical challenge of providing NLP methods
for legislative drafts (section 4) and the linguis-
tic challenge of concretising the existing drafting
guidelines for legislative texts (section 5).
2 Aim and Scope
The aim of the project to be presented in this paper
is to develop methods of automated style checking
specifically geared towards legislative editing, and
to implement these methods in a prototypical tool
(cf. sections 3 and 4). We work towards automat-
9
XML
<...><...><...><...><...><...><...>
DetectionRules
Pre-processing
ErrorDetection
LegislativeDraft
Enriched Draft
Error Report
PredefinedHelptexts
ID 203
Help Text
 ID  span
 80  [...]
135  [...]
203  [...]
OutputGeneration
2)
1)
3)
HighlightedDraft
1)
2)
3)
Documentation/Help Text
+
Error ID
Token IDs
Figure 1: Architecture of the style checking system.
ically detecting violations of existing guidelines,
and where these guidelines are very abstract, we
concretise them so that they become detectable by
machine (cf. section 5). However, it is explicitly
not the goal of our project to propose novel style
rules.
We have adopted a broad conception of ?style
checking? that is roughly equivalent to how the
term, and its variant ?controlled language check-
ing,? have been used in the context of technical
writing (Geldbach, 2009). It comprises the assess-
ment of various aspects of text composition con-
trolled by specific writing guidelines (typographi-
cal conventions, lexical preferences, syntax-related
recommendations, constraints on discourse and
document structure), but it does not include the
evaluation of spelling and grammar.
While our project focuses on style checking for
German-language Swiss federal laws (the federal
constitution, acts of parliament, ordinances, fed-
eral decrees, cantonal constitutions), we believe
that the challenges arising from the task are in-
dependent of the chosen language and legislative
system but pertain to the domain in general.
3 Approach
The most important innovative contribution of our
project is the enhancement of the method of er-
ror modelling to meet the requirements of legisla-
tive editing. Error modelling means that texts are
searched for specific features that indicate a style
guideline violation: the forms of specific ?errors?
are thus anticipated and modelled.
The method of error modelling has mainly been
developed for automated style checking in the do-
main of technical writing. Companies often con-
trol the language used in their technical documen-
tation in order to improve the understandability,
readability and translatability of these texts. Con-
trolled language checkers are tools that evaluate
input texts for compliance with such style guide-
lines set up by a company.1
State-of-the-art controlled language checkers
work along the following lines. In a pre-processing
step, they first perform an automatic analysis of the
input text (tokenisation, text segmentation, mor-
phological analysis, part-of-speech tagging, pars-
ing) and enrich it with the respective structural
and linguistic information. They then apply a
number of pre-defined rules that model potential
?errors? (i.e. violations of individual style guide-
lines) and aim at detecting them in the analysed
text. Most checkers give their users the option to
choose which rules the input text is to be checked
for. Once a violation of the company?s style guide-
lines has been detected, the respective passage is
highlighted and an appropriate help text is made
available to the user (e.g. as a comment in the orig-
inal document or in an extra document generated
by the system). The system we are working on is
constructed along the same lines; its architecture
is outlined in Fig. 1.
Transferring the described method to the do-
main of legislative editing has posed challenges
to both pre-processing and error modelling. The
peculiarities of legal language and legislative texts
have necessitated a range of adaptations in the NLP
procedures devised, and the guidelines for legisla-
tive drafting have required highly domain-specific
1Examples of well-developed commercial tools that offer
such style checking for technical texts are acrolinx IQ by
Acrolinx and CLAT by IAI.
10
error modelling, which needed to be backed up
by substantial linguistic research. We will detail
these two sets of challenges in the following two
sections.
4 Pre-Processing
4.1 Tokenisation
The legislative drafters and editors we are target-
ing exclusively work with MS Word documents.
Drafters compose the texts in Word, and legisla-
tive editors use the commenting function of Word
to add their suggestions and corrections to the
texts they receive. We make use of the XML
representation (WordML) underlying these doc-
uments. In a first step, we tokenise the text con-
tained therein and assign each token an ID directly
in the WordML structure. We then extract the
text material (including the token IDs and some
formatting information that proves useful in the
processing steps to follow) for further processing.
The token IDs are used again at the end of the
style checking process when discovered styleguide
violations are highlighted by inserting a Word com-
ment at the respective position in the WordML rep-
resentation of the original document. The output
of our style checker is thus equivalent to how leg-
islative editors make their annotations to the drafts
? a fact that proves essential with regard to the tool
being accepted by its target users.
4.2 Text Segmentation
After tokenisation, the input text is then segmented
into its structural units. Legislative texts exhibit a
sophisticated domain-specific structure. Our text
segmentation tool detects the boundaries of chap-
ters, sections, articles, paragraphs, sentences and
enumeration elements, and marks them by adding
corresponding XML tags to the text.
There are three reasons why text segmentation
is crucial to our endeavour:
1. Proper text segmentation ensures that only
relevant token spans are passed on to further
processing routines (e.g. sentences contained
in articles must to be passed on to the parser,
whereas article numbers or section headings
must not).
2. Most structural units are themselves the ob-
ject of style rules (e.g. ?sections should not
contain more than twelve articles, articles
should not contain more than three para-
graphs and paragraphs should not contain
more than one sentence?). The successful
detection of violations of such rules depends
on the correct delimitation of the respective
structural units in the text.
3. Certain structural units constitute the context
for other style rules (e.g. ?the sentence right
before the first element of an enumeration has
to end in a colon?; ?the antecedent of a pro-
noun must be within the same article?). Here
too, correct text segmentation constitutes the
prerequisite for an automated assessment of
the respective style rules.
We have devised a line-based pattern-matching al-
gorithm with look-around to detect the boundaries
of the structural units of legislative drafts (H?fler
and Piotrowski, 2011). The algorithm also exploits
formatting information extracted together with the
text from the Word documents. However, not all
formatting information has proven equally reliable:
as the Word documents in which the drafts are com-
posed do only make use of style environments to
a very limited extent, formatting errors are rela-
tively frequent. Font properties such as italics or
bold face, or the use of list environments are fre-
quently erroneous and can thus not be exploited for
the purpose of delimiting text segments; headers
and newline information, on the other hand, have
proven relatively reliable.
Figure 2 illustrates the annotation that our tool
yields for the excerpt shown in the following ex-
ample:
(1) Art. 14 Amtsenthebung 2
Die Wahlbeh?rde kann eine Richterin oder
einen Richter vor Ablauf der Amtsdauer des
Amtes entheben, wenn diese oder dieser:
a. vors?tzlich oder grobfahrl?ssig
Amtspflichten schwer verletzt hat; oder
b. die F?higkeit, das Amt auszu?ben, auf
Dauer verloren hat.
Art. 14 Removal from office
The electoral authorities may remove a judge
from office before he or she has completed
his or her term where he or she:
2Patentgerichtsgesetz (Patent Court Act), SR 173.41; for
the convenience of readers, examples are also rendered in the
(non-authoritative) English version published at
http://www.admin.ch/ch/e/rs/rs.html.
11
<article>
<article_head>
<article_type>Art.</article_type>
<article_nr>14</article_nr>
<article_header>Amtsenthebung</article_header>
</article_head>
<article_body>
<paragraph>
<sentence>
Die Wahlbeh?rde kann eine Richterin oder einen Richter vor Ablauf der Amtsdauer
des Amtes entheben, wenn diese oder dieser:
<enumeration>
<enumeration_element>
<element_nr type="letter">a.</element_nr>
<element_text>
vors?tzlich oder grobfahrl?ssig Amtspflichten schwer verletzt hat;
oder
</element_text>
</enumeration_element>
<enumeration_element>
<element_nr type="letter">b.</element_nr>
<element_text>
die F?higkeit, das Amt auszu?ben, auf Dauer verloren hat.
</element_text>
</enumeration_element>
</enumeration>
</sentence>
</paragraph>
</article_body>
</article>
Figure 2: Illustration of the text segmentation provided by the tool. Excerpt: Article 14 of the Patent Court Act.
(Token delimiters and any other tags not related to text segmentation have been omitted in the example.)
a. wilfully or through gross negligence
commits serious breaches of his or her
official duties; or
b. has permanently lost the ability to
perform his or her official duties.
As our methods must be robust in the face of input
texts that are potentially erroneous, the text seg-
mentation provided by our tool does not amount to
a complete document parsing; our text segmenta-
tion routine rather performs a document chunking
by trying to detect as many structural units as pos-
sible.
Another challenge that arises from the fact that
the input texts may be erroneous is that features
whose absence we later need to mark as an error
cannot be exploited for the purpose of detecting
the boundaries of the respective contextual unit. A
colon, for instance, cannot be used as an indicator
for the beginning of an enumeration since we must
later be able to search for enumerations that are not
preceded by a sentence ending in a colon as this
constitutes a violation of the respective style rule.
Had the colon been used as an indicator for the de-
tection of enumeration boundaries, only enumera-
tions preceded by a colon would have been marked
as such in the first place. The development of ad-
equate pre-processing methods constantly faces
such dilemmas. It is thus necessary to always an-
ticipate the specific guideline violations that one
later wants to detect on the basis of the information
added by any individual pre-processing routine.
Special challenges also arise with regard to the
task of sentence boundary detection. Legislative
texts contain special syntactic structures that off-
the-shelf tools cannot process and that therefore
need special treatment. Example (1) showed a sen-
tence that runs throughout a whole enumeration;
colon and semicolons do not mark sentence bound-
aries in this case. To complicate matters even
further, parenthetical sentences may be inserted
behind individual enumeration items, as shown in
example (2).
(2) Art. 59 Abschirmung 3
1 Der Raum oder Bereich, in dem station?re
Anlagen oder radioaktive Strahlenquellen
betrieben oder gelagert werden, ist so zu
3Strahlenschutzverordnung (Radiological Protection Or-
dinance), SR 814.50; emphasis added.
12
konzipieren oder abzuschirmen, dass unter
Ber?cksichtigung der Betriebsfrequenz:
a. an Orten, die zwar innerhalb des
Betriebsareals, aber ausserhalb von
kontrollierten Zonen liegen und an
denen sich nichtberuflich
strahlenexponierte Personen aufhalten
k?nnen, die Ortsdosis 0,02 mSv pro
Woche nicht ?bersteigt. Dieser Wert
kann an Orten, wo sich Personen
nicht dauernd aufhalten, bis zum
F?nffachen ?berschritten werden;
b. an Orten ausserhalb des Betriebsareals
die Immissionsgrenzwerte nach
Artikel 102 nicht ?berschritten werden.
2 [...]
Art. 59 Shielding
1 The room or area in which stationary
radiation generators or radioactive sources
are operated or stored shall be designed and
shielded in such a way that, taking into
account the frequency of use:
a. in places situated within the premises
but outside controlled areas, where
non-occupationally exposed persons
may be present, the local dose does not
exceed 0.02 mSv per week. In places
where people are not continuously
present, this value may be exceeded
by up to a factor of five;
b. in places outside the premises, the
off-site limits specified in Article102
are not exceeded.
2 [...]
In this example, a parenthetical sentence (marked
in bold face) has been inserted at the end of the
first enumeration item. A full stop has been put
where the main sentence is interrupted, whereas
the inserted sentence is ended with a semicolon
to indicate that after it, the main sentence is con-
tinued. The recognition of sentential insertions as
the one shown in (2) is important for two reasons:
(i) sentential parentheses are themselves the object
of style rules (in general, they are to be avoided)
and should thus be marked by a style checker, and
(ii) a successful parsing of the texts depends on a
proper recognition of the sentence boundaries. As
off-the-shelf tools cannot cope with such domain-
specific structures, we have had to devise highly
specialised algorithms for sentence boundary de-
tection in our texts.
4.3 Linguistic Analysis
Following text segmentation, we perform a lin-
guistic analysis of the input text which consists of
three components: part-of-speech tagging, lemma-
tisation and chunking/parsing. The information
added by these pre-processing steps is later used
in the detection of violations of style rules that
pertain to the use of specific terms (e.g. ?the modal
sollen ?should? is to be avoided?), syntactic con-
structions (e.g. ?complex participial constructions
preceding a noun should be avoided?) or combina-
tions thereof (e.g. ?obligations where the subject
is an authority must be put as assertions and not
contain a modal verb?).
For the tasks of part-of-speech tagging and lem-
matisation, we employ TreeTagger (Schmid, 1994).
We have adapted TreeTagger to the peculiarities
of Swiss legislative language. Domain-specific
token types are pre-tagged in a special routine to
avoid erroneous part-of-speech analyses. An ex-
ample of a type of tokens that needs pre-tagging
are domain-specific cardinal numbers: i.e. cardi-
nal numbers augmented with letters (Article 2a)
or with Latin ordinals (Paragraph 4bis) as well as
ranges of such cardinal numbers (Articles 3c?6).
Furthermore, TreeTagger?s recognition of sentence
boundaries is overwritten by the output of our text
segmentation routine. We have also augmented
TreeTagger?s domain-general list of abbreviations
with a list of domain-specific abbreviations and
acronyms provided by the Swiss Federal Chan-
cellery. The lemmatisation provided by TreeTag-
ger usually does not recognise complex compound
nouns (e.g. G?terverkehrsverlagerung ?freight traf-
fic transfer?); such compound nouns are frequent
in legislative texts (Nussbaumer, 2009). To solve
the problem, we combine the output of TreeTag-
ger?s part-of-speech tagging with the lemma infor-
mation delivered by the morphology analysis tool
GERTWOL (Haapalainen and Majorin, 1995).
Some detection tasks (e.g. the detection of legal
definitions discussed in section 4.4 below) addi-
tionally require chunking or even parsing. For
chunking, we also employ TreeTagger; for pars-
ing, we have begun to adapt ParZu to legislative
language, a robust state-of-art dependency parser
13
(Sennrich et al, 2009). Like most off-the-shelf
parsers, ParZu was trained on a corpus of newspa-
per articles. As a consequence, it struggles with
analysing constructions that are rare in that do-
main but frequent in legislative texts, such as com-
plex coordinations of prepositional phrases and
PP-attachment chains (Venturi, 2008), parenthe-
ses (as illustrated in example 2 above) or subject
clauses (as shown in example 3 below).
(3) Art. 17 Rechtfertigender Notstand 4
Wer eine mit Strafe bedrohte Tat begeht,
um ein eigenes oder das Rechtsgut einer
anderen Person aus einer unmittelbaren,
nicht anders abwendbaren Gefahr zu
retten, handelt rechtm?ssig, wenn er
dadurch h?herwertige Interessen wahrt.
Art. 17 Legitimate act in a situation of
necessity
Whoever carries out an act that carries a
criminal penalty in order to save a legal
interest of his own or of another from
immediate and not otherwise avertable
danger, acts lawfully if by doing so he
safeguards interests of higher value.
As the adaptation of ParZu to legislative texts is
still in its early stages, we cannot yet provide an
assessment of how useful the output of the parser,
once properly modified, will be to our task.
4.4 Context Recognition
The annotations that the pre-processing routines
discussed so far add to the text serve as the basis
for the automatic recognition of domain-specific
contexts. Style rules for legislative drafting often
only apply to special contexts within a law. An
example is the rule pertaining to the use of the
modal sollen (?should?). The drafting guidelines
forbid the use of this modal except in statements
of purpose. Statements of purpose thus consti-
tute a special context inside which the detection
of an instance of sollen is not to trigger an error
message. Other examples of contexts in which
special style rules apply are transitional provisions
(?bergangsbestimmungen), repeals and amend-
ments of current legislation (Aufhebungen und ?n-
derungen bisherigen Rechts), definitions of the
4Strafgesetzbuch (Criminal Code), SR 311.0; emphasis
added.
subject of a law (Gegenstandsbestimmungen), def-
initions of the scope of a law (Geltungsbereichsbe-
stimmungen), definitions of terms (Begriffsbestim-
mungen), as well as preambles (Pr?ambeln) and
commencement clauses (Ingresse).
A number of these contexts can be identified
automatically by assessing an article?s position
in the text and certain keywords contained in its
header. A statements of purpose, for instance, is
usually the first article of a law, and its header usu-
ally contains the words Zweck (?purpose?) or Ziel
(?aim?). Similar rules can be applied to recognise
transitional provisions, repeals and amendments of
current legislation, and definitions of the subject
and the scope of a law.
Other contexts have to be detected at the senten-
tial level. Definitions of terms, for instance, do not
only occur as separate articles at the beginning of a
law; they can also appear in the form of individual
sentences throughout the text. As there is a whole
range of style rules pertaining to legal definitions
(e.g. ?a term must only be defined if it occurs at
least three times in the text?; ?a term must only be
defined once within the same text?; ?a term must
not be defined by itself?), the detection of this par-
ticular context (and its components: the term and
the actual definition) is crucial to a style checker
for legislative texts.5
To identify legal definitions in the text, we have
begun to adopt strategies developed in the con-
text of legal information retrieval: Walter and
Pinkal (2009) and de Maat and Winkels (2010),
for instance, show that definitions in German court
decisions and in Dutch laws respectively can be
detected by searching for combinations of key
words and sentence patterns typically used in these
domain-specific contexts. In H?fler et al (2011)
we have argued that this approach is also feasible
with regard to Swiss legislative texts: our pilot
study has shown that a substantial number of legal
definitions can be detected even without resort-
ing to syntactic analyses, merely by searching for
typical string patterns such as ?X im Sinne dieser
Verordnung ist/sind Y? (?X in the sense of this ordi-
nance is/are Y?). We are currently working towards
refining and extending the detection of legal defini-
tions by including additional syntactic information
yielded by the processes of chunking and parsing
into the search patterns.
5Further rules for the use of legal definitions in Swiss law
texts are provided by Bratschi (2009).
14
Once the legal definitions occurring in a draft
have been marked, the aforementioned style rules
can be checked automatically (e.g. by searching
the text for terms that are defined in a definition
but occur less than three times in the remainder
of the text; by checking if there are any two legal
definitions that define the same term; by assessing
if there are definitions where the defined term also
occurs in the actual definition).
After having outlined some of the main chal-
lenges that the peculiarities of legal language and
legislative texts pose to the various pre-processing
tasks, we now turn to the process of error mod-
elling, i.e. the effort of transferring the guidelines
for legislative drafting into concrete error detection
mechanisms operating on the pre-processed texts.
5 Error Modelling
5.1 Sources
The first step towards error modelling consists in
collecting the set of style rules that shall be ap-
plied to the input texts. The main source that we
use for this purpose are the compilations of draft-
ing guidelines published by the Swiss Federal Ad-
ministration (Bundeskanzlei, 2003; Bundesamt f?r
Justiz, 2007). However, especially when it comes
to linguistic issues, these two documents do not
claim to provide an exhaustive set of writing rules.
Much more so than the writing rules that are put
in place in the domain of technical documenta-
tion, the rules used in legislative drafting are based
on historically grown conventions, and there may
well be conventions beyond what is explicitly writ-
ten down in the Federal Administration?s official
drafting guidelines.
Consequently, we have also been collect-
ing rule material from three additional sources.
A first complementary source are the various
drafting guidelines issued by cantonal govern-
ments (Regierungsrat des Kantons Z?rich, 2005;
Regierungsrat des Kantons Bern, 2000) and, to a
lesser extent, the drafting guidelines of the other
German-speaking countries (Bundesministerium
f?r Justiz, 2008; Bundeskanzleramt, 1990; Rechts-
dienst der Regierung, 1990) and the European
Union (Europ?ische Kommission, 2003). A sec-
ond source are academic papers dealing with spe-
cific issues of legislative drafting, such as Eisen-
berg (2007), Bratschi (2009).
Finally, legislative editors themselves constitute
an invaluable source of expert knowledge. In or-
der to learn of their unwritten codes of practice,
we have established a regular exchange with the
Central Language Services of the Swiss Federal
Chancellery. Including the editors in the process
is likely to prove essential for the acceptability of
the methods that we develop.
5.2 Concretisation and Formalisation
The next error modelling step consists in concretis-
ing and formalising the collected rules so that spe-
cific algorithms can be developed to search for
violations of the rules in the pre-processed texts.
Depending on the level of abstraction of a rule,
this task is relatively straight-forward or it requires
more extensive preliminary research:
Concrete Rules A number of rules for legisla-
tive drafting define concrete constraints and can
thus be directly translated into detection rules. Ex-
amples of such concrete rules are rules that pro-
hibit the use of specific abbreviations (e.g. bzw.
?respectively?; z.B. ?e.g.?; d.h. ?i.e.?) and of certain
terms and phrases (e.g. grunds?tzlich ?in princi-
ple?; in der Regel ?as a general rule?). In such
cases, error detection simply consists in searching
for the respective items in the input text.
Some rules first need to be spelled out but can
then also be formalised more or less directly: the
rule stating that units of measurement must always
be written out rather than abbreviated, for instance,
requires that a list of such abbreviations of mea-
suring units (e.g. m for meter, kg for kilogram, %
for percent) is compiled whose entries can then be
searched for in the text.
The formalisation of some other rules is some-
what more complicated but can still be derived
more or less directly. The error detection strate-
gies for these rules include accessing tags that
were added during pre-processing or evaluating
the environment of a potential error. For exam-
ple, the rule stating that sentences introducing an
enumeration must end in a colon can be checked
by searching the text for <enumeration> tags that
are not preceded by a colon; violations of the rule
stating that an article must not contain more than
three paragraphs can be detected by counting for
each <article_body> environment, the number of
<paragraph> elements it contains.
15
Abstract Rules However, guidelines for legisla-
tive drafting frequently contain rules that define
relatively abstract constraints. In order to be able
to detect violations of such constraints, a linguistic
concretisation of the rules is required.
An example is the oft-cited rule that a sentence
should only convey one statement or proposition
(Bundesamt f?r Justiz, 2007, p. 358). The er-
ror modelling for this rule is not straightforward:
it is neither clear what counts as a statement in
the context of a legislative text, nor is it obvious
what forms sentences violating this rule exhibit.
Linguistic indicators for the presence of a multi-
propositional sentence first need to be determined
in in-depth analyses of legislative language. In
H?fler (2011), we name a number of such indica-
tors: among other things, sentence coordination,
relative clauses introduced by the adverb wobei
(?whereby?), and certain prepositions (e.g. vorbe-
h?ltlich ?subject to? or mit Ausnahme von ?with the
exception of?) can be signs that a sentence contains
more than one statement.
Even drafting rules that look fairly specific at
first glance may turn out to be in need of further lin-
guistic concretisation. An example is the rule that
states that in an enumeration, words that are shared
between all enumeration elements should be brack-
eted out into the introductory sentence of the enu-
meration. If, for instance, each element of an
enumeration starts with the preposition f?r (?for?),
then that preposition belongs in the introductory
sentence. The rule seems straight enough, but in
reality, the situation is somewhat more compli-
cated. Example (4) shows a case where a word
that occurs at the beginning of all elements of an
enumeration (the definite article die ?the?) cannot
be bracketed out into the introductory sentence:
(4) Art. 140 Obligatorisches Referendum 6
[...]
2 Dem Volk werden zur Abstimmung
unterbreitet:
a. die Volksinitiativen auf Totalrevision
der Bundesverfassung;
b. die Volksinitiativen auf Teilrevision der
Bundesverfassung in der Form der
allgemeinen Anregung, die von der
Bundesversammlung abgelehnt worden
sind;
6Bundesverfassung (Federal Constitution), SR 101; em-
phasis added.
c. die Frage, ob eine Totalrevision der
Bundesverfassung durchzuf?hren ist,
bei Uneinigkeit der beiden R?te.
Art. 140 Mandatory referendum
[...]
2 The following shall be submitted to a vote
of the People:
a. the popular initiatives for a complete
revision of the Federal Constitution;
b. the popular initiatives for a partial
revision of the Federal Constitution in
the form of a general proposal that have
been rejected by the Federal Assembly;
c. the question of whether a complete
revision of the Federal Constitution
should be carried out, in the event that
there is disagreement between the two
Councils.
Even if one ignores the fact that the definite article
in letters a and b is in fact not the same as the
one in letter c (the former being plural, the latter
singular), it is quite apparent that articles cannot
be extracted from the elements of an enumeration
without the nouns they specify. Even the seem-
ingly simple rule in question is thus in need of a
more linguistically informed concretisation before
it can be effectively checked by machine.
The examples illustrate that style guidelines for
legislative writing are often kept at a level of ab-
straction that necessitates concretisations if one
is to detect violations of the respective rules au-
tomatically. Besides the development of domain-
specific pre-processing algorithms, the extensive
and highly specialised linguistic research required
for such concretisations constitutes the main task
being tackled in this project.
Conflicting Rules A further challenge to error
modelling arises from the fact that a large propor-
tion of drafting guidelines for legislative texts do
not constitute absolute constraints but rather have
the status of general writing principles and rules
of thumb. This fact has to be reflected in the feed-
back messages that the system gives to its users:
what the tool detects are often not ?errors? in the
proper sense of the word but merely passages that
the author or editor may want to reconsider.
The fact that many style rules only define soft
constraints also means that there may be conflict-
ing rules. Consider, for instance, sentence (5):
16
(5) Art. 36 Ersatzfreiheitsstrafe 7
[...]
5 Soweit der Verurteilte die Geldstrafe trotz
verl?ngerter Zahlungsfrist oder
herabgesetztem Tagessatz nicht bezahlt oder
die gemeinn?tzige Arbeit trotz Mahnung
nicht leistet, wird die Ersatzfreiheitsstrafe
vollzogen.
Art. 36 Alternative custodial sentence
[...]
5 As far as the offender fails to pay the
monetary penalty despite being granted an
extended deadline for payment or a reduced
daily penalty unit or fails to perform the
community service despite being warned of
the consequences, the alternative custodial
sentence is executed.
On the one hand, this sentence must be consid-
ered a violation of the style rule that states that
the main verb of a sentence (here execute) should
be introduced as early as possible (Regierungsrat
des Kantons Z?rich, 2005, p. 73). On the other
hand, if the sentence was re-arranged in compli-
ance with this rule ? by switching the order of the
main clause and the subsidiary clause ? it would
violate the rule stating that information is to be pre-
sented in temporal and causal order (Bundesamt
f?r Justiz, 2007, p. 354). This latter rule entails
that the condition precedes its consequence.
To be able to deal with such conflicting con-
straints, error detection strategies have to be as-
signed weights. However, one and the same rule
may have different weights under different cir-
cumstances. In conditional sentences like the one
shown above, the causality principle obviously
weighs more than the rule that the main verb must
be introduced early in the sentence. Such context-
dependent rankings for individual style rules have
to be inferred and corroborated by tailor-made
corpus-linguistic studies.
5.3 Testing and Evaluation
The number of drafts available to us is very lim-
ited ? too limited to be used to test and refine the
error models we develop. However, due to the
complexity of the drafting process (multiple au-
thors and editors, political intervention), laws that
7Strafgesetzbuch (Criminal Code), SR 311.0
have already come into force still exhibit viola-
tions of specific style rules. We therefore resort
to such already published laws to test and refine
the error models we develop. To this aim, we have
built a large corpus of legislative texts automati-
cally annotated by the pre-processing routines we
have described earlier in the paper (H?fler and
Piotrowski, 2011). The corpus contains the entire
current federal legislation of Switzerland, i.e. the
federal constitution, all cantonal constitutions, all
federal acts and ordinances, federal decrees and
treaties between the Confederation and individual
cantons and municipalities. It allows us to try out
and evaluate novel error detection strategies by
assessing the number and types of true and false
positives returned.
6 Conclusion
In this paper, we have discussed the development
of methods for the automated detection of viola-
tions of domain-specific style guidelines for leg-
islative texts, and their implementation in a proto-
typical tool. We have illustrated how the approach
of error modelling employed in automated style
checkers for technical writing can be enhanced to
meet the requirements of legislative editing. Two
main sets of challenges are tackled in this process.
First, domain-specific NLP methods for legisla-
tive drafts have to be provided. Without extensive
adaptations, off-the-shelf NLP tools that have been
trained on corpora of newspaper articles are not
adequately equipped to deal with the peculiarities
of legal language and legislative texts. Second,
the error modelling for a large number of draft-
ing guidelines requires a concretisation step before
automated error detection strategies can be put in
place. The substantial linguistic research that such
concretisations require constitutes a core task to be
carried out in the development of a style checker
for legislative texts.
Acknowledgments
The project is funded under SNSF grant 134701.
The authors wish to thank the Central Language
Services of the Swiss Federal Chancellery for their
continued advice and support.
References
Rebekka Bratschi. 2009. ?Frau im Sinne dieser Bade-
ordnung ist auch der Bademeister.? Legaldefinitio-
17
nen aus redaktioneller Sicht. LeGes, 20(2):191?213.
Bundesamt f?r Justiz, editor. 2007. Gesetzgebungs-
leitfaden: Leitfaden f?r die Ausarbeitung von Er-
lassen des Bundes. Bern, 3. edition.
Bundeskanzlei, editor. 2003. Gesetzestechnische
Richtlinien. Bern.
Bundeskanzleramt, editor. 1990. Handbuch der Recht-
setzungstechnik, Teil 1: Legistische Leitlinien. Wien.
Bundesministerium f?r Justiz, editor. 2008. Handbuch
der Rechtsf?rmlichkeit, Empfehlungen zur Gestal-
tung von Gesetzen und Rechtsverordnungen. Bunde-
sanzeiger Verlag, K?ln.
Peter Butt and Richard Castle. 2006. Modern Legal
Drafting. Cambridge University Press, Cambridge,
UK, 2nd edition.
Emile de Maat and Radboud Winkels. 2010. Auto-
mated classification of norms in sources of law. In
Semantic Processing of Legal Texts. Springer, Berlin.
Karin M. Eichhoff-Cyrus and Gerd Antos, editors.
2008. Verst?ndlichkeit als B?rgerrecht? Die Rechts-
und Verwaltungssprache in der ?ffentlichen Diskus-
sion. Duden, Mannheim, Germany.
Peter Eisenberg. 2007. Die Grammatik der Gesetzes-
sprache: Was ist eine Verbesserung? In Andreas
L?tscher and Markus Nussbaumer, editors, Denken
wie ein Philosoph und schreiben wie ein Bauer,
pages 105?122. Schulthess, Z?rich.
Europ?ische Kommission, editor. 2003. Gemein-
samer Leitfaden des Europ?ischen Parlaments, des
Rates und der Kommission f?r Personen, die in den
Gemeinschaftsorganen an der Abfassung von Rechts-
texten mitwirken. Amt f?r Ver?ffentlichungen der
Europ?ischen Gemeinschaften, Luxemburg.
Stephanie Geldbach. 2009. Neue Werkzeuge zur Au-
torenunterst?tzung. MD?, 4:10?19.
Mariikka Haapalainen and Ari Majorin. 1995. GER-
TWOL und morphologische Desambiguierung f?r
das Deutsche. In Proceedings of the 10th Nordic
Conference of Computational Linguistics. University
of Helsinki, Department of General Linguistics.
Stefan H?fler and Michael Piotrowski. 2011. Build-
ing corpora for the philological study of Swiss legal
texts. Journal for Language Technology and Com-
putational Linguistics (JLCL), 26(2):77?90.
Stefan H?fler, Alexandra B?nzli, and Kyoko Sugisaki.
2011. Detecting legal definitions for automated
style checking in draft laws. Technical Report CL-
2011.01, University of Zurich, Institute of Computa-
tional Linguistics, Z?rich.
Stefan H?fler. 2011. ?Ein Satz ? eine Aussage.? Multi-
propositionale Rechtss?tze an der Sprache erkennen.
LeGes, 22(2):259?279.
Anne Lehrndorfer. 1996. Kontrolliertes Deutsch: Lin-
guistische und sprachpsychologische Leitlinien f?r
eine (maschinell) kontrollierte Sprache in der Tech-
nischen Dokumentation. G?nter Narr, T?bingen.
Kent D. Lerch, editor. 2004. Recht verstehen.
Verst?ndlichkeit, Missverst?ndlichkeit und Unver-
st?ndlichkeit von Recht. de Gruyter, Berlin.
Maria Mindlin. 2005. Is plain language better? A com-
parative readability study of plain language court
forms. Scribes Journal of Legal Writing, 10.
Uwe Muegge. 2007. Controlled language: The next
big thing in translation? ClientSide News Magazine,
7(7):21?24.
Markus Nussbaumer. 2009. Rhetorisch-stilistische
Eigenschaften der Sprache des Rechtswesens. In
Ulla Fix, Andreas Gardt, and Joachim Knape, ed-
itors, Rhetorik und Stilistik/Rhetoric and Stylis-
tics, Handbooks of Linguistics and Communica-
tion Science, pages 2132?2150. de Gruyter, New
York/Berlin.
Rechtsdienst der Regierung, editor. 1990. Richtli-
nien der Regierung des F?rstentums Liechtenstein
?ber die Grunds?tze der Rechtsetzung (Legistische
Richtlinien). Vaduz.
Regierungsrat des Kantons Bern, editor. 2000. Recht-
setzungsrichtlinien des Kantons Bern. Bern.
Regierungsrat des Kantons Z?rich, editor. 2005.
Richtlinien der Rechtsetzung. Z?rich.
Ursula Reuther. 2003. Two in one ? can it work? Read-
ability and translatability by means of controlled
language. In Proceedings of EAMT-CLAW 2003.
Helmut Schmid. 1994. Probabilistic part-of-speech
tagging using decision trees. In Proceedings of the
International Conference on New Methods in Lan-
guage Processing, pages 44?49.
Rico Sennrich, Gerold Schneider, Martin Volk, and
Martin Warin. 2009. A new hybrid dependency
parser for German. In Proceedings of the GSCL
Conference 2009, pages 115?124, T?bingen.
Giulia Venturi. 2008. Parsing legal texts: A contrastive
study with a view to knowledge managment applica-
tions. In Proceedings of the LREC 2008 Workshop
on Semantic Processing of Legal Texts, pages 1?10,
Marakesh.
Stephan Walter and Manfred Pinkal. 2009. Defini-
tions in court decisions: Automatic extraction and
ontology acquisition. In Joost Breuker, Pompeu
Casanovas, Michel Klein, and Enrico Francesconi,
editors, Law, Ontologies and the Semantic Web. IOS
Press, Amsterdam.
Richard C. Wydick. 2005. Plain English for Lawyers.
Carolina Academic Press, 5th edition.
18
