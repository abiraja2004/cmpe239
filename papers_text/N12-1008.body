2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 70?79,
Montre?al, Canada, June 3-8, 2012. c?2012 Association for Computational Linguistics
Multi Event Extraction Guided by Global Constraints
Roi Reichart Regina Barzilay
Computer Science and Artificial Intelligence Laboratory
Massachusetts Institute of Technology
{roiri, regina}@csail.mit.edu
Abstract
This paper addresses the extraction of event
records from documents that describe multi-
ple events. Specifically, we aim to identify
the fields of information contained in a docu-
ment and aggregate together those fields that
describe the same event. To exploit the in-
herent connections between field extraction
and event identification, we propose to model
them jointly. Our model is novel in that it
integrates information from separate sequen-
tial models, using global potentials that en-
courage the extracted event records to have
desired properties. While the model con-
tains high-order potentials, efficient approxi-
mate inference can be performed with dual-
decomposition. We experiment with two data
sets that consist of newspaper articles de-
scribing multiple terrorism events, and show
that our model substantially outperforms tra-
ditional pipeline models.
1 Introduction
Today, most efforts in information extraction have
focused on the field extraction task, commonly for-
mulated as a sequence tagging problem. When a
document describes a single event, the list of ex-
tracted fields provides a useful abstraction of the in-
put document. In practice, however, a typical news-
paper document describes multiple events, and a flat
list of field values may not contain the sufficient
structure required for many NLP applications. Our
goal is therefore to extract event templates which ag-
gregate field values for individual events.
Consider, for instance, the New York Times arti-
cle excerpt in Figure 1 that describes three related
terrorist events. As this example illustrates, in order
to populate the corresponding event templates, the
model needs to identify segments that describe indi-
vidual events. Such segmentation is challenging, as
event boundaries are not explicitly demarcated in the
text. Moreover, descriptions of different events are
often intermingled, as in the above example, further
complicating boundary recovery.
In this paper, we consider a model that jointly
performs event segmentation and field extraction.
This model capitalizes on the inherent connection
between the two tasks in order to reduce the ambi-
guity of template-based extraction. For example, the
distribution of field values in the text provides strong
clues about event segmentation, such as the presence
of multiple new fields strongly signaling a segment
boundary. Likewise, knowledge of the boundaries
enables the model to rule out mutually inconsistent
predictions, such as extracting two distinct locations
for the same event.
We formulate our approach as a joint model that
marks each word with field and event labels si-
multaneously. At the sentence level, segmentation
and field extraction taggers are implemented using
separate sequence models operating over local fea-
tures. At the document level, the model encourages
global consistency via potentials that link the ex-
tracted event records and their fields. Some of these
potentials are limited to fields of an individual event
such as the ?single city per event? constraint. Others
encode discourse-level properties of the whole doc-
ument and thus involve records of multiple events,
70
A powerful car bomb exploded today in Baghdad inside the holiest Shiite shrine . As many as 95 people were killed
in the event, according to sources in Washington. The blast came only two days after another car bomb exploded in a crowded
street in Mosul in the northern part of Iraq, killing 13 pedestrians, in an attack carried out by Al Qaeda. Together with the
previous attack by Al Qaeda, the shooting in Najaf three weeks ago that killed 15 American soldiers, violence seemed
to spike to its highest level. The bombing today, happened around 9am, when the roads are crowded with people. ...
Organization Tactic Target Weapon Fatalities City Country
Event 1 ? bombing Shiite shrine car bomb 95 people Baghdad ?
Event 2 Al Qaeda bombing ? car bomb 13 pedestrians Mosul Iraq
Event 3 Al Qaeda shooting ?- ? 15 American Soldiers Najaf ?
Figure 1: A New York times article describing three terrorist events and a table demonstrating the corresponding event records.
such as the tendency in newspaper reporting to fea-
ture the main event at the beginning and repeatedly
throughout the document.
While these high-order potentials encode impor-
tant linguistic properties of valid assignments, they
greatly complicate learning and inference. There-
fore, our method estimates the parameters of the lo-
cal sequence models and the global potentials sep-
arately. Then, at inference time, it finds variable
assignments that are most consistent with both the
local models and the global potentials. Inference
is implemented via dual-decomposition, an efficient
algorithm shown to be effective for complex joint
inference problems.
We evaluate our approach for event extraction on
two data sets, one is a new collection of long news-
paper articles and the other is a subset of the MUC-
4 documents. Both data sets consist of articles that
describe multiple terrorist events (40.3 and 12.4 sen-
tences and 4.4 and 3.1 events per article for each data
set on average). We demonstrate the benefits of the
joint model for event extraction; it outperforms a tra-
ditional pipeline model by a significant margin. For
instance, it yields an absolute gain of 8.5% for our
new corpus when measured using document-level F-
score. Our results show the effectiveness of global
constraints in the context of template extraction and
motivate their exploration in other IE tasks.
2 Previous Work
Event-Template Extraction Event template extrac-
tion has been previously explored in the MUC-4
scenario template task. Work on this task has fo-
cused on pipeline models which decouple the task
into the sub-tasks of field extraction and event-based
text segmentation. For example, rule-based meth-
ods (Rau et al., 1992; Chinchor et al., 1993) identify
generalizations both for single field fillers and for re-
lations between fields and use them to fill event tem-
plates. Likewise, classifier-based algorithms (Chieu
et al., 2003; Xiao et al., 2004; Maslennikov and
Chua, 2007; Patwardhan and Riloff, 2009) gener-
ally train individual classifiers for each type of field
and aggregate candidate fillers based on a senten-
tial event classifier. Finally, unsupervised techniques
(Chambers and Jurafsky, 2011) have combined clus-
tering, semantic roles, and syntactic relations in or-
der to both construct and fill event templates.
In our work, we also address the sub-tasks of
field extraction and event segmentation individu-
ally; however, we link them through soft global con-
straints and encourage consistency through joint in-
ference. To facilitate the joint inference, we use a
linear-chain CRF for each sub-task.
Global Constraints Previous work demonstrated
the benefits of applying declarative constraints in in-
formation extraction (Finkel et al., 2005; Roth and
tau Yih, 2004; Chang et al., 2007; Druck and Mc-
Callum, 2010). Constraints have been explored both
at sentence and document level. For example, Finkel
et al. (2005) employ document-level constraints to
encourage global consistency of named entity as-
signments. Likewise, Chang et al. (2007) use con-
straints at multiple levels, such as sentence-level
constraints to specify field boundaries and global
constraints to ensure relation-level consistency. In
our work we focus on document-level constraints.
We utilize both discourse and record-coherence con-
straints to encourage consistency between local se-
quence models.
There has also been unsupervised work that
demonstrates the benefit of domain-specific con-
straints (Chen et al., 2011). In our work we show
that domain-specific constraints based on the com-
mon structure of newspaper articles are also useful
to guide a supervised model.
71
3 Model
Problem Formulation Given a document, our goal
is to extract field values and aggregate them into
event records. The training data consists of event an-
notations where each word in the document is tagged
with a field and with an event id. If a word is not a
filler for a field, it is annotated with a default NULL
field value. At test time, the number of events is not
given and has to be inferred from the data.
Model Structure Our model is built around the
connection between local extraction decisions and
global constraints on event structure. Based on
local cues, the model can identify candidate field
fillers. However, connecting them to events requires
a broader document context. To effectively capture
this context, the model needs to group together por-
tions of the document that describe the same event.
Global constraints are instrumental in this process,
as they drive the aggregation of contiguous segments
computed by a local segmentation model. In ad-
dition, global constraints coordinate local decisions
and thereby enable us to express important discourse
dependencies between various assignments.
To implement these ideas in a computational
framework, we define an undirected graphical model
with a vertex set V = X ? Y ? Z . X is a set of ob-
served nodes; xi represents the ithe word in a docu-
ment. Y and Z are sets of unobserved nodes corre-
sponding to the field and event assignments respec-
tively of the ith word. The number of input words in
a document is denoted by n.
We define three types of potentials:
? Field-labeling Potentials associate words in a
document with field labels based on their local
sentential context.
? Event-labeling Potentials associate words in a
document with event boundaries based on the
local surroundings of a candidate boundary.
? Global Consistency Potentials link the ex-
tracted event records and their fields to encour-
age global consistency. These potentials are de-
fined over the entire set of variables related to a
document.
The resulting maximum aposteriori problem is:
MAP (?) =
?
f?F
?f (rf )
where ?f are the potential functions and {rf |f ?
{1, . . . , n}, f ? F} is the set of their variables.
3.1 Modeling Local Dependencies
Field Labeling The first step of the model is tagging
the words in the input document with fields. Fol-
lowing traditional approaches, we employ a linear-
chain CRF (Lafferty et al., 2001) that operates
over standard lexical, POS-based and syntactic fea-
tures (Finkel et al., 2005; Finkel and Manning, 2009;
Bellare and McCallum, 2009; Yao et al., 2010).
Event Segmentation At the local level, event analy-
sis involves identification of event boundaries which
we model as linear segmentation. To this end, we
employ a binary CRF that predicts whether a given
word starts a description of a new event or continues
the description of the current event, based on lex-
ical and POS-based features. In addition, we add
features obtained from the output of the field extrac-
tion CRF. These features capture the intuition that
boundary sentences often contain multiple fields.
The potential functions of these components are
given by the likelihoods of the corresponding CRFs.
3.2 Modeling Global Dependencies
The main function of the global constraints is to
link extracted fields to the corresponding events.
In addition, the model can use global constraints
to resolve potentially inconsistent decisions of the
local models by encouraging them to agree with
global, document-level properties. We consider two
types of global consistency potentials: discourse po-
tentials that involve interactions between multiple
records, and record coherence potentials that cap-
ture patterns at the level of individual records.
The general form of a global potential p is:
?f (xf?p, yf?p, zf?p) =
{
?p if potential-property holds
0 otherwise
Where f ? p is the index set of variables over
which the potential is defined. Table 1 gives a formal
description of all the potentials. Below we describe
the linguistic intuition behind these potentials.
Discourse Potentials To populate event records
with extracted information, the model needs to
72
Discourse
MAIN EVENT Two consecutive sentences without fields indicate a transition
to the main event:
(?Si, Si+1 s.t. (?k ? Si, yk = NULL) ? (?k ? Si+1, yk = NULL)) ?
(?l ? i s.t. (?u, u ? i, u < l, 1fME(Su)=1), ?p ? Sl, zp = CENTRAL)
SEGMENT BOUNDARY Event changes should take place in multi-field sentences:
?i, j ? I, ((i = j + 1) ? (zi! = zj)) ?
(?i1 . . . it ? I s.t. 1[fs?SB(i,i1,...it)=1] ? 1[ff?SB(i1,...it)=1])
EVENT REDUNDANCY Events should not significantly overlap:
?i, j ? {1, . . . , |Z|}, ?k, l ? I s.t.
((yk = yl) ? (yk! = NULL) ? (zk = i) ? (zl = j) ? (xk! = xl))
Record Coherence
FIELD SPARSITY Some fields take a single unique value per record:
?K,L ? I, C ? ?, ((YK = C) ? (YL = C) ? (ZK = ZL)) ? (XK = XL)
RECORD DENSITY Words associated with a field should fill the field if it is otherwise empty:
?i ? ?, C ? ?, (?k ? I s.t. (1[Cind(xk)=1]) ? (zk = i)) ? (?l ? I s.t. (yl = C) ? (zl = i))
Table 1: Logical formulations of the properties encouraged by the global potentials. Si is the set of indexes corre-
sponding the the ith sentence. fME(Su) = 1 iff there is no event change in sentence Su. fs?SB(i1, . . . , it) = 1 iff the
corresponding words appear in the same sentence. ff?SB(i1, . . . , it) = 1 iff the corresponding words have different,
non-NULL, field values. Cind(xk) = 1 iff xk is assigned to C in a training event record. CENTRAL is the central
event of the document, defined to be its first event. I = {1, . . . , n}, ? = {1, . . . |Y |}, ? = {1, . . . , |Z|}.
group together sentences that describe the same
event. The local boundary model can only predict
contiguous blocks of event descriptions, but it can-
not link together blocks that appear in different parts
of the document. Our approach towards this task
is informed by regularity in the discourse organiza-
tion of news articles. A typical news story is de-
voted to a single event, mixed with short descrip-
tions of other events. Therefore, we prefer event as-
signments where long segments with no field values
? e.g., background descriptions ? are associated with
the main event. This intuition is formalized in the
Main Event Potential shown in Table 1.
The second discourse constraint concerns detec-
tion of event boundaries. We prefer assignments in
which the boundary sentence contains a large num-
ber of fields. This preference is expressed in the Seg-
ment Boundary Potential shown in Table 1.
The final discourse constraint favors assignments
that reduce redundancy in generated records. It is
unlikely that a document describes several events
with significant factual overlap. This constraint
is implemented in the Event Redundancy Potential
shown in Table 1.
Record Coherence Potentials These potentials
capture properties of valid field assignments in the
context of a given event record. The first potential
in this group ? Field Sparsity Potential ? is ap-
plied to fields, such as City, that tend to take a single
unique value per event record.1 This potential dis-
courages assignments that link this field with multi-
ple values within the same event. Similar constraints
have been effectively used in information extraction
in the past (Finkel et al., 2005). In our work, we ap-
ply this constraint at the event level, rather than at
the document level, thereby enabling multiple vari-
able values for multi-event documents.
The second record coherence potential ? Record
Density Potential ? aims to reduce empty fields in
the event record. This potential turns on when a lo-
cal extractor fails to identify a filler for a field when
processing a given event segment. If this segment
contains words that are labeled as potential fillers in
the context of other events in the training data, we
prefer assignments that associate them with the field
that otherwise would have been empty. This poten-
tial is inspired by the one sense per discourse con-
straint (Gale et al., 1992) that associates all the oc-
currences of the word in a document with the same
semantic meaning.
1The potential is defined for the following fields: Terrorist
Organization, Weapon, City, and Country.
73
4 Inference
Dual Decomposition The global potentials encode
important document level information that links to-
gether the extracted event records and their fields.
Introducing these potentials, however, greatly com-
plicates inference. Consider the MAP equation of
Section 3. If the intersection between each pair of
subsets, fi, fj ? F , had been empty, we could have
found the MAP assignment by solving each poten-
tial separately. However, since many subset pairs do
overlap, we must enforce agreement among the as-
signments which results in an NP-hard problem.
In order to avoid this computational bottleneck we
turn to dual-decomposition (Rush et al., 2010; Koo
et al., 2010), an inference technique that enables ef-
ficient computation of a tight upper bound on the
MAP objective, while preserving the original depen-
dencies of the model. Dual decomposition has been
recently applied to a joint model for biomedical en-
tity and event extraction by Riedel and McCallum
(2011). In their work, however, events are defined in
the sentence level. Here we show how this technique
can be applied to a model which involves document-
level potentials.
We first re-write the MAP equation, such that it
contains a local potential for each of the unobserved
variables, as required by the inference algorithm:
MAP (?) = max
y,z
?
j?J
?j(rj) +
?
f?F
?f (rf )
where we denote the set of indexes of all unob-
served variables with J and refer to each of them
with rj . We then define the dual problem:
min
?
L(?), L(?) =
?
j?J
max
rj
[?j(rj) +
?
f :j?f
?fj(rj)]+
?
f?F
max
rf
[?f (rf )?
?
j?f
?fj(rj)]
where for every f ? F and j ? f , ?fj is a vector of
Lagrange multipliers with an entry for each possi-
ble assignment of rj . We add the notation ?f for the
matrix of Lagrange multipliers for all the variables
in f , and for an assignment M of the variables in f
we define ?f (M) to be the corresponding vector of
Lagrange multipliers. The multipliers can be viewed
as messages transferred between the potentials to en-
courage agreement between their assignments.
The dual objective, L(?), forms an upper bound
on the MAP objective. Our inference algorithm
Set g0fj ? 0 for all j ? J, f ? F
for k = 1 to K do
for j ? J do
rlkj = argmax
rj
[?j(rj) +
?
f :j?f
?fj(rj)]
end? TRUE
for f ? F do
rpkf = argmaxrf
[?f (rf )?
?
j?f
?fj(rj)]
for j ? f do
if rlkj 6= rpkfj then
gkfj(rlkj ) + = 1
gkfj(rpkfj) ? = 1
end? FALSE
?k+1fj = ?
k
fj ? ?k ? gkfj
if end then
return Rk
?k ? 1/k
return (RK )
(a)
rlkj : Sort [?j(rj) +
?
f :j?f
?fj(rj)]. Return the minimizing rj .
rpkf :
MMAkf ?: Minimum-Message assignment
PRAkf ?: Property-Respecting assignment
if (?p ? sum(?f (PRA)) > (?1) ? sum(?f (MMA)) then
rpkf = PRAkf
else
rpkf = MMAkf
(b)
Figure 2: The inference algorithm. (a): The dual-
decomposition algorithm. (b): Algorithms for the
argmax operations of the dual-decomposition algorithm.
therefore searches for its minimum, i.e. the tightest
upper bound of the original MAP objective. L(?) is
convex and non-differentiable and can therefore be
minimized by the subgradient descent algorithm in
Figure 2 (a).
Individual Potentials Maximization The inference
algorithm requires efficient solvers for its argmax
problems. For the field labeling and event segmen-
tation potentials, the messages are encoded into the
feature space of the CRF, and exact maximization is
achieved through standard CRF decoding. For the
local potentials, (rlkj ), the maximizing assignments
are computed by sorting the messages for each un-
observed variable (Figure 2 (b)).
The global potentials are more challenging. Ide-
ally, we could find the optimal assignment, rp?f , that
agrees with the assignments of the other potentials
( rp?f = argmin
?
j?f ?fj(rpj)) and at the same
time respects the property encouraged by its own po-
74
tential (?p(rp?f ) > 0). In practice, however, there
may be no such assignment, in which case the as-
signment conflict needs to be resolved.
We first compute the minimum-message assign-
ment (MMA), the assignment that minimizes the
message sum. If this assignment respects the poten-
tial property then it is the optimal assignment. Oth-
erwise, we compute the property-respecting assign-
ment (PRA), the assignment with the (approximate)
lowest message sum under the condition that the po-
tential property holds. From these two assignments
we select the one with the higher score.
Finding the MMA is simple, as it is the minimum-
message assignment of each unobserved variable
separately. However, finding the global optimal
PRA is computationally demanding, as it requires
searching over a very large assignment space. We
therefore trade accuracy for efficiency and restrict
each potential to modify the MMA assignment for
only one type of variables: Y (fields) or Z (events).
The discourse potentials and the FIELD SPARSITY
potential are restricted to changes of the event vari-
ables, while the RECORD DENSITY potential is re-
stricted to changes of the field variables.
For the MAIN EVENT potential, consecutive sen-
tences with no fields trigger a return to the main
event. For the SEGMENT BOUNDARY potential,
event changes that take place in sentences with a
small number of fields are removed. For our work,
this threshold is set to three. For the EVENT RE-
DUNDANCY potential, redundant events are inte-
grated with the largest event in which they are con-
tained. For the RECORD DENSITY potential, words
seen in both training records and event text are used
to fill empty fields. For each empty field in each
event, words labeled with event are scanned for can-
didate fillers, and those with the minimal impact on
the message sum are assigned to that field.
Finally, for the FIELD SPARSITY potential, if a
field contains more than one word or phrase per
event, the event assignments of these words or
phrases are recomputed. This computation is imple-
mented as a minimum matching problem in a bipar-
tite graph. One side of the graph consists of a vertex
for every word or phrase assigned to the addressed
field, and the other side consists of one vertex for
each event in the document. If the number of phrases
assigned to the field is larger than the number of
events in the document, some of the event vertices
will be assigned to new events. The edge weights
are the sum of message changes corresponding to
relabeling the word or phrase with the new event.
We solve this problem efficiently (O(n3)) using the
Kuhn-Munkres algorithm (Kuhn, 1955).
5 Experiments
Data This work focuses on multi-event extraction.
While some of the articles in the MUC test corpus
do have multiple events, the majority contain only
one (77.5%) or two (12%). We therefore created two
corpora for our experiments. The first is a new cor-
pus of 70 articles from New York Times (NYT) LDC
corpus, each describing one or more terrorist events
from various parts of the world. The second, also of
70 articles, consists of a subset of the MUC articles
that describe more than one event. We stripped this
corpus from the MUC annotation and annotated it
according to our scheme.
Annotations were provided by two annotators
with graduate school educations. Every word was
tagged with a field and an event id. The 8 fields
we use are: Terrorist Organization, Target, Tactic,
Weapon, Fatalities, Injuries, Country and City.
We compared the agreement between annotators
on 10 articles by computing the percentage of words
for which the annotators gave the same labeling.
The inter-annotator agreement was 90.9% (kappa =
0.9) when fields and events are evaluated together
(i.e., the annotators are considered to agree only
when they assign the same field and event id to the
word), 97.8% (kappa = 0.97) for events only, and
92% (kappa = 0.91) for fields only.
The two corpora differ from each other with re-
spect to several important properties. The New-York
Times articles are longer (40.3 compared to 12.4
sentences per article) and describe a larger number
of events (4.4 compared to 3.1 events per article on
average). In addition, while our hypothesis about
the predominance of the main (first) event cover-
age holds for both corpora, it better characterizes the
New-York Times corpus, as is demonstrated by the
following two statistics.
First, in the NYT corpus the average number of
sentences containing field fillers for the main event
is 14.7, while for any other event the average number
75
is 3.2. In the MUC corpus the corresponding num-
bers are 5.3 and 2.0. Second, in the NYT corpus
the number of times an article goes back to a pre-
viously described event is 182 (average of 2.6 times
per article), of which 154 (84.6%) are transitions to
the main event. In the MUC corpus the number of
times an article goes back to a previously described
event is only 38 (average of 0.54 times per article),
but, similarly to the NYT, in as much as 32 (84.2%)
of these cases the transitions are to the main event.
Experimental Setup For both corpora, we used 30
articles for training (1218 sentences in NYT, 423 in
MUC), 7 articles for development (358 sentences in
NYT, 79 in MUC) and 33 articles for test (1244 sen-
tences in NYT, 367 in MUC). The sentences were
POS tagged with the MXPOST tagger (Ratnaparkhi,
1996) and parsed with the Charniak parser (Char-
niak and Johnson, 2005).
We trained our model with a two steps procedure.
First, the local CRFs were separately trained on the
training articles. Then, we trained the parameters of
the global potentials using the structured perceptron
algorithm (Collins, 2002) on the development data.
We perform joint inference over the local CRFs
as well as the global potentials with dual decompo-
sition. This algorithm is guaranteed to give the MAP
assignment if it converges to a solution in which all
the potentials agree on the label assignment for the
variables in their scope. To deal with disagreements,
we ran the algorithm for 200 iterations past the point
of fluctuations around the dual minimum. The final
label assignment is determined by a majority vote
between the potentials in the 10 iterations with the
highest total inter potential agreement (Sontag et al.,
2010).
Baselines We compare our algorithm to two base-
line models. The first baseline is related to previous
techniques that decompose the task into field extrac-
tion and event segmentation sub-tasks (Jean-Louis
et al., 2011; Patwardhan and Riloff, 2007; Patward-
han and Riloff, 2009). For this PIPELINE baseline,
we run the CRF models described in Section 3.1,
first the field CRF and then the event CRF. The field-
based features of the event CRF are extracted from
the output of the field CRF.
Our model incorporates global dependencies into
a document level model. An alternative approach is
to encode this information as local features that re-
flect global dependencies (Liang et al., 2008). We
therefore constructed a second baseline, the bidirec-
tional pipeline model (BI-PIPELINE), that considers
global features which encode similar properties to
those encouraged by our global potentials. We im-
plement this by incorporating event-based features
into the feature set of the field labeling CRF, while
kipping the event segmentation CRF fixed. 2 As in
the pipeline model, each CRF is trained separately
on the training data. The BI-PIPELINE model, how-
ever, emulates our joint inference procedure by it-
eratively running a field labeling and an event seg-
mentation CRFs. The number of iterations for this
model was estimated on development data.
Evaluation Measures We follow the MUC-4
scoring guidelines (Chinchor, 1992). To compare
between a learned and a gold standard event, we
compute the word-level F-score between each of
their fields and average the results. If a field is empty
in both event records, it is not counted in the mutual
event score, while if it is empty in only one of the
event records, its F-score is 0.
Ideally, the measure should be able to capture
paraphrases. For example, if the Tactic field in
a gold event record contains the words ?bombing?
and ?blast?, the measure is expected to give a per-
fect score to a learned record that contains one of
these words. Therefore, as in the MUC-4 guidelines,
we count pre-specified synonyms and morphologi-
cal derivations of the same word only once.
For every document, we then map the learned
events to the gold events in a greedy 1-1 manner
using the Kuhn-Munkres algorithm (Kuhn, 1955).
Once we have an event mapping, we can report
an average recall, precision and F-score across the
test set for all fields, events and documents (where
the document F-score is the average F-score of its
events). We use the sign test to measure the statis-
tical significance for our results. Since the number
of events described in a document is not given to the
models as input, we also report the average ratio be-
tween the number of induced and gold events.
2Example additional features are: (1) whether a word with
the same most frequent field (MFF) as the encoded word previ-
ously appeared in its event; (2) whether a new event is started
in the sentence of the encoded word; and (3) whether the event
of the encoded word contains at least one word annotated with
the MFF of the encoded word.
76
NYT Documents Events Fields Event Number
R P F R P F R P F Ratio
Joint Model 38.7 42.4 38.5 36.2 40.8 36.4 43.6 49.1 43.8 0.95
Bi-pipeline Model 33.3 30.8 30.2 31.9 30.1 29.4 38.8 36.6 35.7 1.14
Pipeline Model 28.3 27.0 26.2 27.1 26.8 25.5 35.4 34.8 33.2 1.5
MUC Documents Events Fields Event Number
R P F R P F R P F Ratio
Joint Model 49.8 43.2 43.5 48.7 43.0 42.7 53.6 45.9 46.2 0.88
Bi-pipeline Model 38.1 38.6 36.3 34.3 33.9 32.2 41.5 40.5 38.6 0.92
Pipeline Model 30.8 32.8 29.7 29.9 32.0 28.9 37.9 40.1 36.6 0.89
Table 2: Performance of the joint model and the pipeline models on the event record extraction task. Top table is for
the New-York Times data. Bottom table is for the MUC data. All results are statistically significant with p < 0.05.
NYT TO TAR TAC WEAP INJ FAT CO CITY
Joint Model 21.9 23.4 49.0 39.6 40.8 49.1 43.1 46.6
Bi-pipeline Model 8.4 19.7 47.5 20.9 25.9 18.3 38.8 38.1
Pipeline Model 7.1 18.1 41.9 36.9 19.1 16.5 38.0 46.1
MUC TO TAR TAC WEAP INJ FAT CO CITY
Joint Model 49.0 25.2 63.6 62.0 43.3 21.1 19.7 38.3
Bi-pipeline Model 28.0 24.7 38.2 55.8 42.7 25.6 37.5 37.2
Pipeline Model 34.9 23.4 50.3 56.5 10.4 12.4 30.0 32.0
Table 3: Comparison between the joint model and the pipeline models for the different fields. When the joint model is
superior results are statistically significance with p < 0.05.
(a)
NYT Fields Events
R P F GF LF
Joint model 47.3 51.3 49.2 54.8 61.3
Bi-Pipeline 31.0 43.8 36.3 48.8 56.2
Pipeline Model 39.2 55.4 45.9 51.3 52.9
(b)
MUC Fields Events
R P F GF LF
Joint model 47.3 51.3 49.2 62.8 70.0
Bi-Pipeline 49.5 36.1 41.8 62.2 62.0
Pipeline Model 31.0 43.8 36.3 65.5 70.3
Table 4: Performance of the joint and the pipeline models on the labeling tasks of assigning words to fields (left) and
to events (right). Field values are computed for words tagged with the non-NULL field. Events values are computed
for words that are assigned to a non-NULL field by the gold standard (GF) or by the model (LF). When the joint model
is superior, results for fields are statistically significant with p < 0.01 and for events with p < 0.05.
6 Results
Event-Records Results for event record extraction,
the main task addressed in this paper, are presented
in Table 2. For all measures, the model outperforms
the pipeline baselines, with an F-score difference of
up to 13.8%.
The rightmost column of the table demonstrates
the tendency of our model to under-segment. For
both corpora our model extracts a smaller number
of events than the gold standard on average (5% for
NYT, 12% for MUC). The pipeline baselines extract
more events than our model on average. For NYT
they over-segment (14% for bi-pipeline, 53% for the
pipeline) while for MUC they under-segment (8%
and 11% respectively). These differences are ex-
pected as the baselines cannot combine different text
segments that describe the same event.
Table 3 presents per-field F-score performance.
The joint model outperforms the pipeline baselines
for 7 out of the 8 fields in the NYT experiments, and
for 6 out of 8 fields in the MUC experiments.
Model Components Table 6 presents the perfor-
mance of variants of the joint model created by ex-
cluding each potential type. The results demonstrate
the significance of both discourse and record co-
herence potentials for the performance of the full
model.
Sub-tasks Performance A model for our task
77
(a)
Gold Fields Gold Events
NYT Doc. Events Fields Ratio Doc. Events Fields
Joint
Model
69.1 62.5 64.4 1.05 45.7 46.5 50.0
Bi-
Pipeline
? ? ? ? 41.7 40.8 46.1
Pipeline 47.9 43.9 51.3 1.56 40.8 40.4 43.9
(b)
Gold Fields Gold Events
MUC Doc. Events Fields Ratio Doc. Events Fields
Joint
model
78.5 75.0 74.5 0.76 50.8 47.9 51.4
Bi-
Pipeline
? ? ? ?- 37.0 34.3 39.9
Pipeline 76.1 71.1 72.0 0.78 32.6 31.2 36.0
Table 5: Performance of the joint model and the pipeline models when the gold standard for one of the labeling tasks
is given at test time. Results are statistically significant with p < 0.05.
NYT
Excluded Component Documents Events Fields Event
Rat.
Record Coherence 32.1 31.0 37.7 1.04
Discourse 26.7 26.3 34.3 1.5
MUC
Record Coherence 37.4 33.6 39.6 0.88
Discourse 37.7 36.6 42.7 0.89
Table 6: The effect of the record coherence potentials and
of the discourse potentials on the performance of the joint
model. Results are presented for F-scores, each line is for
the full model when potentials of one type are excluded.
should determine both when a word is a good field
filler and to which event the field belongs. Since
our main evaluation collapses the effect of these de-
cisions together, we performed two additional sets
of experiments to analyze the model?s accuracy on
each sub-task separately.
Figure 4 presents the performance of the different
models on the labeling tasks of assigning words to
fields and to events. The number of words associated
with a field differs between the gold standard and
the models? output. For fields, we therefore report
word level recall, precision and F-score between the
set of words assigned a non-NULL field by a model
and the corresponding gold standard set. For events,
we compute the fraction of words assigned the cor-
rect event among the words assigned to a non-NULL
field in either the gold standard or the output of the
model.
Figure 5 presents the document F-score when the
gold-standard fields (left) or events (right) of the test
set are known at test time. Note that when the gold
standard fields are known, the BI-PIPELINE model
is not applicable anymore since it is designed to
improve field assignment using event-informed fea-
tures. The results demonstrate that encoding field
information to the models is more valuable than en-
coding information about events. This provides us
with an important direction for future improvement
of our model.
Accuracy and Efficiency When we ran our algo-
rithm on the joint task of the NYT data-set it con-
verged after 89 iterations. For the MUC joint task
and the ablation analysis experiments we ran the al-
gorithm for 200 iterations past the point of fluctua-
tions around the dual minimum.
On a 2GHz CPU, 2GB RAM machine, it took
our dual-decomposition algorithm 15 minutes and
10 seconds to complete its run on the entire NYT test
set. For the MUC joint task experiment, in the 10
iterations considered for the majority vote, there is
full agreement between the potentials for 97.77% of
the unobserved variables. That is, the voting scheme
affects the assignment of only 2.23% of the unob-
served variables.
7 Conclusions
In this paper we presented a joint model for identify-
ing fields of information and aggregating them into
event records. We experimented with two data sets
of newspaper articles containing multiple event de-
scriptions. Our results demonstrate the importance
and effectiveness of global constraints for event
record extraction.
Acknowledgements
The authors gratefully acknowledge the support of
the DARPA Machine Reading Program under AFRL
prime contract no. FA8750-09-C0172. Any opin-
ions, findings and conclusions expressed in the ma-
terial are those of the author(s) and do not neces-
sarily reflect the views of DARPA, AFRL or the US
government. Thanks also to the members of the MIT
NLP group and to Amir Globerson for their sugges-
tions and comments.
78
References
