English-Chinese Machine Trans la t ion  System IMT/EC 
Chert Zhsoxlong and Gee Qingshi 
Ins t i tu te  o f  Computing Technology 
Chinese Academy of  Science 
Bel J lng, PRC. 
Abstract  
IM'I/EC is an English-Chinese machine translation 
system ~,hich integrates some outstanding features of 
the case grammar end semantic grammar ln to  a uniform 
frame, LISeS var ious kuowledgo In the disamblguation, 
and t r ies  to modify the ob ject  language by i t se l f .  In 
th i s  poF,er,we f i r s t  introduce IMT/EC's design motive- 
t ior l  and overa l l  a rch i tec ture ,  then describe the 
deslgn phi losophy o f  i t s  t rans la t ion  mechanisms and 
thelr procesging algorithms. 
J,The design nlotivation 
\]'he design of the IMT/EC system are motivated to 
develop new approaches to the Engllsh-Chinese machine 
translation, such as, to provide the system with 
powerful analysis meohanisnls end MT knowledge base 
menagonlerit system , as well as some exceptional pro- 
cessing and learning meohanlsms, that is, to make the 
system ba intelligent. In addition, it also tries to 
inregret9 as many advantages of conventional machine 
translation systems into a single system as possible, 
such as, to provide the system with powerful mechon-. 
Isms for the processing of various ambiguities and 
contextu,~l relations. The design of the IMT's trans- 
lation mechanisms are based on the following consl- 
derQti on ~;, 
(1) S t -ana lys i s  
In the development o f  machine t rans la t ion  system, 
in order to disambiguato the source language, we 
have to {molyze the input deeply to get the in terna l  
meonlng representation of the source language. 
However, the deeper we aaalyze the input, the more we 
lose the clues about how to express the translation, 
also, th(it it results in extremely poor or no trans- 
lations ef sentences for which complete analyses can 
not be (h~rlved\[Slocum 85\]. To find a suitable analys- 
is depth so as to get both clues about how to express 
the trorl~;lation of the input and to disombiguate the 
input conlpletely Is almost impossible. In the IMT/EC, 
we try t(, design a simple grammar analysis mechanism 
-- SC-gr'(~mmar auulysls mechanism to inherit both the 
outstanding features of case grammar analysis and se- 
mantic grammar analysis so as to produce a high qua- 
lity translation, 
(2) Multl- language translations oriented 
In present technical conditions, it is impossible 
to design a general internal meaning representation 
for all natural languages. Thus, the knowledge based 
multl- language oriented machine translation system is 
difficult to be marketed in the near future. A feasl- 
ble way ~or designing multl--longuage oriented machine 
translatJorl systems might be to separate the proces- 
sing mechanisms from the language specific rules |as 
King et oI. ~5\], thet ie, t O apply the same process- 
ing meotlonlsm with different language spec i f i c  rules 
for d~ffErent natural language pair translations. In 
the 1NI'/EC, we develop a general ru le  representat ion 
form for  the representat ion  of  var ious knowledges 
used in the t rans lo t lon .  Knowledges fo r  d i f fe rent  
language pa l r  t rans la t ions  are stored in the d i f fe r -  
ant packages o f  the knowledge base IMT-KB. The know- 
ledge base are organized In mult i -package end multi- 
l eve l  way so as to  s tore  ru les  fo r  the t rans la t ion  o f  
d i f fe rent  language pa i rs  and d i f fe rent  phases o f  the 
processing. Thus, the system can be eas i ly  extended 
for' mult i - language t ra r l s la t lon  purposes. 
(3) Divers i ty  processing 
As the dlsemblguation rules are rather words spe- 
cific, ?% is diff icult to manage them in the same 
way. To deal wlth this problem, we store these rules 
in their respected word entries end classify them es 
several  categor ies  in the IMT/EC, Each category cor -  
responds tO 0 general subroutine epplleatlon mechan- 
ism, which apply the word specific rules and subrout- 
ines in the processing of translation. The subrout- 
ines are stored in a natura l  language spec i f i c  sub- 
rout ine  package. Some word spec i f i c  subroutines are 
d i rec t ly  stored in the respected word entry.  
(~) Powerful exceptional processing 
Since the natura l  language phenomena ore so abund- 
ant that  any ex is ted machine t rans la t ion  system can 
not process all the phenomena, it is essential to 
provide an exceptional processing mechanism in the 
system to deal wlth except iona l  phenomena. As IMT/EC 
incorporates some learn ing mechanisms, thus, i t  i s  
more powerful  in deal ing with the exceptions than 
others.  
(5) Automatic mod i f i ca t ion  of  the t rans la t ion  
General ly speaking, machine t rans la t ion  system can 
only produce r ig id  t rans la t lons ,  i t  i s  a desire that  
MT systems be able to modify the output by i t se l f  so 
as to produce more f luent  t rans la t ions .  IMT/EC t r ies  
to apply same common sense knowledge and l ingu is t i c  
knowledge o f  ob ject  language to disamblguate the 
input end modify the t rans la t ions ,  thus, to improve 
the t rans la t lon  qua l i ty .  
In the fo l low ing  paragraph, we focus on the t rans -  
la t ion  procedure of  the system end the algor i thms 
re la ted  to i t  ignor ing the knowledge base organiza-  
t ion  and management mechanisms. 
2. The overa l l  a rch i tec ture  o f  the system 
The architecture of the IMT/EC system is as 
follow, 
\] knowledge  base management 
Engllsh Input System IMT-KB 
\[ 
~ f Knowledge~ 
Morphological  Analysis l . I I ~ Appl icatzon J 
& Dictionary Ret r lv ing~ / p ._ I_T_T. .~1~ 
t 
I ~;n: l ; ; " ; ' s  ' L \~/  ___  B?se.~_ 7 
\[ - - ~ ~  /~ / Augmentat ion -~ _ 
/ Dlsambigu~on r / I\k & Modifiootio~ f * ~  
| & Transfer  L / I \~  
' . . . .  ',, I 
I - Acquisitioo ) 
I the Tren?lot lonJ  / 
t 
/ 
/ 
Fig. The arch i tec ture  of  the IMT/EC 
117 
As the rule bose and dlctlonarv in a machine 
trenslat lon system is so vast that it ls impossible 
for human beings to find the confllotion end implica- 
tion among the rules. To modify a rule in the knowle- 
dge base often results In many side effects on other 
ru les .  Thus, i t  Is  necessary to prov ide  a se l f  re -  
o rgan izat ion  and re f inement  mechanisms in the knowle- 
dge bose. 
In the IMT/EC, we design a spec ia l  knowledge base 
management system IMT-KB to  manage ell the knowledge 
used In var lous  processing phases o f  the t rans la -  
t ion .  In add i t ion ,  IMT/EC a lso provides o knowledge 
bose augmentation and knowledge acqu is i t ion  env i ron -  
ment fo r  the system to  augment system performance by 
i t se l f  and fo r  the users to  improve the knowledge 
base. 
The col1 re la t ions  connected by dotted l lnes  in 
the f igure  above ore executed only when the user sets 
the learn ing  mechanisms in  working s ta tus .  These 
mechanisms can acqu i re  new knowledge in  the dynamic 
interactive, static interactive,or disconnected ways. 
They ore primarily used to resolve the exaeDtlenel 
phenomena in the translation. 
Dynamic Interactive Learning (DIL): Whenever the 
system encounters c sentence out of its processing 
range, it produces various possible translations for 
each segment of the sentence and interacts with human 
beings when necessary to select on appropriate trans- 
lation of the segment and combine them to get 
o correct translation of the sentence. At the some 
time, it also creates'some new rules to reflect the 
selections. That is, it learns some new knowledge. 
Static Interactive Learning (SIL): Whenever the 
system encounters a sentence out o f  i t s  processing 
range,it records down the sentence and its appearance 
context in e f i l e .  After the text has been translated, 
i t  begins to analyze the sentence in detai l  to get 
various possible translations for each segment of the 
sentence and in teracts  w i th  human beings when necess- 
ary to get appropr ia te  t rans la t ions  o f  the segments 
and combines them to get a cor rec t  t rans la t ion  o f  the 
sentence. At the same time, it also creates some new 
rules to reflect the selections, thus, to learn new 
knowledge. 
Disconnected Learning (DL): Whenever the system 
encounters o sentence out of i t s  processing range, i t  
analyzes the sentence in detail to get al the possi- 
ble translations, and then evaluates these transla- 
tions according to the preference rules stored i n . the  
IMT-KB to select on appropriate translation and 
modify the re la ted  ru les  used in the ana lys i s  to  
re f lec t  the se lec t ions .  I t  sk ips over sentences which 
the t rans la t ion  con not be determined by the pre fe -  
rence rules Instead of interacting with human beings. 
5. The translation procedure 
IMT/EO's tronslatlon procedure is divided into 
several phases, i.e.,morphology onalysls and diction- 
cry retrlvlng, SC-grammor anolysls,dlsamblguotlon and 
t rans fer ,  modification of  the t rons la t lon  etc. 
The communlcotions between t rons lo t lon  mechanisms 
and the knowledge bose ore performed by the knowledge 
base management system IMT-KB, these operat ions  
includes getting a se~ of related rules and returning 
some In fo rmat ion  fo r  the mod i f i ca t ion  as we l l  aS 
augmentotlon o f  the MT knowledge bose. 
5.1. Morphology ana lys i s  and d ic t ionary  re t r iv ing  
In the IMT/EC, words in  most common uses con be 
re t r ived  by e i ther  the i r  base forms or the i r  sur face 
forms, wh l le  most o f  the other  words can only  be re -  
t r ieved  by their base forms. The tasks of the morpho- 
logy analysis ore to process the prefix, suffix, and 
compound words. Since these processlngs ore complete- 
iv natural language spec i f i c ,  in order for  the proce- 
ssing mechanisms to  be language independent, we deve- 
lop a language independent morphology analysis me- 
chanism to opply the language specific morphology 
rules In the morphology analysis, 
The morphology analysis rule form is 
<surface pattern> -> <condit ions> I <resu l t> 
118 
Here, 
<surface pattern> is the surface form of the word 
to  be analyzed, 
<conditions> is the oppllcotlon condltlons of. the 
rule, 
<result> Is the definltlon of the word base form 
analyzed. 
For example, 
(1)  ( "  s) -> (verb - )  I (de f ( " ) ,  SV) 
(2)  ( "  s ) -> (noun *)  I ( c le f ( * ) ,  PN) 
(3 ) ( -1  - "2) -> (word -1 ) (word  "2)1 
( (de f (morpho log  v w1), 
def(morphologv "2) ) ,  CaM) 
Here, *, -1 and *2 are variables Indlcating that 
it con be bounded to any sub-character string of the 
word to  be analyzed, def(X) is the definition of  X in 
the IMT-KB, SV, PN, cam are surface ' features o f  the 
word. 
Rule ( I )  Ind lcotes  that  when the las t  character  o f  
the surface form o f  a word i s  ' s '  and the remained 
character  s t r ing  * in the word i s  o verb, then i t s  
sur face feature  i s  the s lngu lor  verb form (SV) o f  the 
verb *. Thus, I t  re turns  the value o f  
(de f ( * ) ,  SV) 
as resu l t .  
Rule (2)  ind icates  that  when the los t  character  o f  
the sur face form of  a word i s  ' s '  and the remained 
character string * in the word is o noun, then its 
surface feature  i s  the p lu ra l  noun form (PN) o f  the 
noun *. Thus, i t  re turns  the value o f  
(de f ( * ) ,  PN) 
as resu l t .  
Rule (5)  ind icates  that  when the character  s t r ing  
of o word comprises a character '-', the left pert ~1 
and the right part w2 of '-' ore both words, then it 
l so  compound word of ~I and w2.Thus, it applies mor- 
phology rules to analyze the word ~1 and *2, and re- 
turns the value of 
( ( f (morpho logy  -1 ) , f (morpho logy  w2)),COM) 
as resu l t ,  
Suppose that ,  
SX indicates that X is o variable, 
#X returns  the character  l l s t  o f  X, 
&X returns the lost character of X, 
>X returns the f i r s t  part of rule X or the 
f i r s t  element of  a l i s t ,  
<X re turns  the remained por t  o f  X which 
(>X" <X o X), 
f(X,V) returns the first different item palr of 
X ond Y, 
lookup(X) looks up the dictionary and returns the 
deflnltlon of the word X, 
search(X) returns the morphology rules which leclu-. 
des character X, 
check(X) tests whether two elements of the item 
pair X is uniflable or nag, 
nul l (x)  tests whether llst X IS empty, 
apply(g,x) returns the result of g(X), 
t(X) tests whether result X needs further 
onolysls and performs recurs lve  analysis 
when necessary. 
The a lgor i thm for  morphology ana lys i s  and d ict ion- -  
erv re t r iev lnq  i s  as fo l low.  
INITIALIZE 
$X <- #word; 
SP <- search(& SX); 
$P <- $PU search(> $X); 
$ resu l t  <- ( ); 
fo r  $ ru le  m SP do 
{MATCH 
SPAT <= > Srule; 
$COND <- >"< $ru le ;  
$RES <- <=< $ru le ;  
Loop 
$patr  <-- f(SPAT, SX); 
i f  (nu l l ($po l r ) )  goto TEST; 
i f  (not (check($pa i r ) ) )  break; 
SPAT <- $PAT~ Spel t ;  
i PA IR  .I. <-. iPAIR l.U ($po l r} ;  
gate  Loop ; 
rEST 
fo r  $CONDI e$COND, do 
($PROP <- lookup(>e < ($CONDL)); 
if (not (app ly (> $CONDI, SPROP)) brook;  
} 
|:~ESUI.T 
iPROP <-- lookup (> ($RES~'$PA);R L ) ) ;  
iresult <-- i resu l t  U {($RES~ iPA:\[R L, 
iPR(IP ) } ; 
) 
if (pull($res~it)) re turn  word 
e l se  re tur r l  t ($ resu \ ] . t ) ;  
El~ll), 
3.2. St--Grammar Anulys:Ls 
The St -grammar eno lys i s  mechanism o f  IMT/EC 
U|)plle~ th( SC--rolos stored ill the iMT-KB to dlsumbl- 
gLlate the ~.trueturol embigultles of the input senten-- 
cos end predm;es the  s t ruc tura l  descr ip t ion  fo r  them. 
"ihe grammar |lOS some outs tend ing  features  o f  the case 
grommet ond semunt ic  gr'ommor. The ru le  form l s  cs 
fo l low,  
<S-STRUCTURE> ~> <S-ENVIRONMENT>I 
< R=SI'RUCTURE >, 
<I~- ENVIRONMENi> 
<TRANSFER>. 
Itore, 
<S-.SIIRUCrUI~E> mid <S-ENVIRONMENT> are  ru le  cond i -  
t ions  which de f ines  the  cur rent  s t r t l c tL I r ( \ ] l  form end 
contextua l  foat t l res  o f  the  input ,  <R-.STRUCTURE> und 
<R-ENVIRONNiENT> ore  resu l t  s t rueturu l  form ~nd 
cor l textue l  features  o f  the  input ,  <TRANSFER> ere the  
t rens formot lo~Is  re la ted  to  the  ru le .  
lho  s t ruc tura l  forms , <S-SI'RUCTURE> end 
<R-STRUCTURE> ore  represented  os s t r ings  o f  syntogmos 
arid words . \ ]he  contextue l  envlronments,<S-ENVIRON~ENT> 
and <R-ENViRONMENT> ore  represented  os vectors ,  o f  
which each e lement  cor responds  to  on in ter -sentent ta l  
re le t ion  or  e spec la \ ]  eeoc, the i r  va lues  ere  used to  
reso lve  the  e l l ips i . s ,dnephore ,  tense  and espocts  e tc .  
i t  i s  the pr inc ipa l  contextua l  p rocess ing  mochenisms 
in the  IMI/EC. 
Since the  contextua l  vector  i s  used on ly  os a 
supplo*~lent to the pure semantic grammar ona\]vsls, 
espeele\].\].y in the processing of contextual relations, 
it is riot necessary to analyze the Irlput to the 
extent  the| .  one con get  e l l  the  semant ic  re la t ions  o f  
the input. Thus, the vector processing formalism is 
completely acceptable. 
Two example rules ore as follow, 
NP VP -> A I S, change(B1 ,?) ,  INP IVP. 
in  NP -> A1 I PP, chonge(B2 ,X) ,  ze l  INP nue i .  
St -grammar one lys i s  mechanisms rece ive  the  resu l t s  
o f  morphology ana lys i s  or  p rev ious  SO- reduct ion ,  send 
the messages to  the  IMT-K8 to  get  re le ted  ru les ,  end 
app ly  these  ru les  to  , reduce.  the  input  unt i l  o non- 
terminal symbol S is reduced, thus, to produce the 
structural descr ip t ion  o1' the input. 
The SO-grommet ana lys i s  a lgor i thm o f  the system 
is:. 
(I) \]in the entries of' the \[MT-KB dictionary, we 
stored not only the word meanings and their disembi-- 
guotlon conditions, but oleo SO-phrase end sementlc 
rules specJflo to the entry word. When onulyzlng e 
sentence,  the  system f i r s t  re t r ieves  the  SC-phrose 
ru les  spec i f i c  te  the  words appeared irl the  sentence,  
end ~pp l im{ these  ru les  to  f ind  a l i s t  o f  poss ib le  
phrases o f  the  sentence f rom the  context  o f  the  words 
in  the  senl;eneo. 
The phr~se l i s t  re turned  i s  os fo l low,  
X, ( i ,  , J, ) 
X~(?~,J:) 
x~( i . , j~) .  
Here, XI, X~., ...,Xm ore phrase syutogma Identif$ers, 
i } ,  ~) . . . . .  J.~ arid J~, Jz . . . . .  J~ ere  end ing  pos i -  
t rons  o f  the  phrases in  the  input  sentence.  
(2 )  F ind a l i s t  o f  expectat ion  pathos f rom the  
phrase \[List as follow,. 
"'~') X~;(J,~l k,! X~l(m,4t m) X, ( i , J , )  
vl~), ?~/( l , Jm i X~)(Jm?l,k ) ~ U"~+I,n#) 
P(w ~ ) P(w~+ L) . , ,  p (w~z.  # 
(Here,  P(w) i s  the  word w i t se l f  or  i t s  p roper ty ,  t 
i s  the  cur rent  ona lys l s  pos i t ion  which in i t ia l  ve luo  
i s  ~ , I  i s  the  expects | lee  length  de f ined  by the  user )  
end order  them by means o f  the  phrase ending post-- 
t lons  n=,n~ . . . . .  n~ f rom le rger  to  smel le r .  These 
pothes are  used as heur i s t i cs  in  the ano\] .ys is  e f  the 
sentence.  We t ry  one new patt i  o t  one beckt reck ing .  
(3 )  Send the  ano\].yzed component 
M = V , ( . . . )  V~( . . . )  . . .  V~( . . . )  
cndI i ihe cur rent  expectet ion  path to  theIIMT---KB to 
re t r leve  the 'SC- ru Ies 'wh ich  heed pc | te rns  conta in  
sub-s t r ing  o f  
{~ , ( . . . )  . . .  v~( . . . )  x~( . . : )  . . .  xz ( . . . )  ~1 Path = or  
( .  ) v~( ) P (w~ ) . . .  P (w~.~)  
and organ ize  these  ru les  in  a l i s t  accord ing  to the i r  
p re ferences  f rom higher" Lo lower .  Then, i t  tokes one 
ru le  f rom the  ru le  l l s t  a t  one buck f i reck lng  and go to  
(~)  to  app l  V the  ru le  to  reduce the  input .  
I f  no ru le  in  the  l l s t  con be success fu l l y  app l ied  
to reduce the  input ,  the  system gets  the  next  expec-  
ta t ion  path f rom (2)end repeet  (3 ) .  I f  a l l  the  expec-  
ta t ion  pethes have been t r ied  end no success fu l  ru le  
has been app l ied ,  i t  re turns  1;o the las t  ana lys i s  
pos i t ion  to  re -ana lyze  the  input .  I f  the  cur rent  erla-- 
l ys i s  pos i t ion  I s  the  beg inn ing  o f  the sentence,  the 
system co i l s  the  except ion  process ing  , lechenism to  
deal  w i th  th i s  un- -ana lyzab le  sentence.  
(l~) Match the  ru le  head pat tern  w i th  the  cur rent  
form o f  the  input  sentence.  I f  there  i s  a sub-pat tern  
o f  the  cur rent  sentence pet tern  that  can match the  
ru le  heed, then go to  (5 )  e l se  get  the  next  ru le  f rom 
(3)  end t r ies  to  re-.match them. 
(5 )  F i r s t ,  odd some newly formed phrases in to  the  
phrase l i s t  in order For the backtracking of the one 
lys l s ,  then co l l  the  cese ene lys?s  mechanism to  check 
the  eur reet  ana lys i s  resu l t s  und the  cur rent  form o f  
t i le  sentence 'to F i l l  i n  the  rose  freme A, B in  the  
ru le  end the  context  vector .  The case ane lys i s  a lgo -  
r i thm i s  descr ibed  In  the  fo l low ing  paragraph.  
(6 )  Check A end the  context  vector  to  see whether  
the i r  va lues  are  un l f leb le .  I f  they  are  un i f ieb le ,  
then go to  (71, e l se  get  the  next  ru le  f rom (3)  and 
re turns  to  (4 ) .  
(7 )  S tore  the  backt rack ing  in fo rmet ion  in to  the  
temporary  s tock ,  subst i tu te  the  reduc ing  par t  o f  the  
cur rent  sentence fo rm wi th  the  reduced form, change 
the  cur rent  ana lys i s  pos i t ion  to  the  las t  word oF the  
newly reduced syntagma,cnd change the  re la ted  e lement  
va lues  o? the  context  vector  aecord ing  to  the  e lement  
va lues  o f  B. 
I f  the  cur rent  pos i t ion  i s  not  the  end o f  o sen-  
tence,  then go to  (2 ) ,  
I f  the  cur rent  position is the  end o f  a sentence 
end the  cur rent  form o f  the  sentence i s  net  S, ~hon 
go to  (2 ) ,  
I f  the  cur rent  pos i t ion  i s  the  end o f  e sentence 
end the  cur rent  fo rm o f  the  sentence i s  S, then go 
to  (8), 
(8 )Ca l l  the  semant ic  p rocess ing  mechanism to  check 
the  resu l t  o f  the  nns lys l s  to  see whether  ~t v io la tes  
the  Eng l i sh  co l locet lon  ru les .  I f  the  resu l t  v io le tes  
the co l locat ion  ru les ,  the  system recovers  to  the  
s ta tus  be fore  the  las t  reduct ion  and gets  'the r lext 
ru le  f rom (5)  to  r 'e -ono iyze  the  input .  Otherwise , there  
wlll be two cases, 
a, If the user  only needs the most adequate 
? trensletlon, the system proceeds to analyze the next 
sentence.  
b. I f  the  user  needs e l l  poss ib le  t rcns la t ions ,  
the  system records  down ~he cur rent  resu l t  end rose -  
vers  to  the  s te tus  be fore  the  Zest  reduct ion  end gets  
119 
the next rule from (5) to re-analyze the input in 
order to get other onolysls results. 
AS we have ment ioned before ,  the  case ana lys i s  in  
the  SC-ana lys l s  i s  on ly  a complement to  the  semant ic  
ana lys i s .  I t  i s  ma in ly  used to  des1 w i th  the  context  
re la t ion  and a?pect ,  tense ,  modal e tc .  Thus, the  
system on ly  needs to  ana lyze  those  cases which can be 
used in  those  purposes.  I t  l s  much s impler  than the  
case ana lys i s  in  the  case grammar ana lys i s .  
The case ana lys i s  in  the  SC-ena lys l s  l s  performed 
by the  fo l low ing  a lgor i thm,  
(1)  Get the  case express ions  de f ined  in  the  
el'emerita o f "  vector  A and B. The form o f  the  e lement 
express ions  o f  A and g l s  
s~\ [ i \ ] :E  
Here, S~\ [ I \ ]  ind icates  the  e lement case Cdent l f le r (S#)  
o f  the  case frame A or  g i s  corresponded to  the  case 
ident i f ie r  s i l l  o f  the  system case frame, l .e . , sys tem 
context  vector .  E i s  the  express ion  used to  get  the  
va lue  o f  the  respected  case.  
(2)  Ret r ieve  the  def in i t ion  o f  the  case ident i f i -  
ers from the  system case frame and organ ize  these 
case ident i f ie r  in to  a 1 le t  accord ing  to  the i r  pre fe -  
rences from h igher  to  lower .  The form i s ,  
(S\[i l \] .subject:EI,S\[12\].obJect:E2 ..... S\[lm\].Em .... ) 
(5) Evaluate the value of the elements in the case 
identifier llst, and flll them Into the respected 
pos i t ion  in  the  case frame A end B. There are many 
cases in  the  evo luat lon .  
a. E ls a constant, returns E, 
b. E ls empty, evaluate the case value according 
the  def in i t ion  o f  the  case ident i f ie r ,  
c. I f  the case identif ier l sa  syntagma idetlfl- 
er, then finds the vclue of the identifier 
from the analyzed input according to the 
heur i s t i cs  p rov ided  by the  express ion  E, 
d. If the ease identifier is o sementlc identi- 
fier, then ca l l  the  semant ic  mechdnlsm to  get  
the  va lue  which can be f i l l ed  in to  the  case 
ident i f ie r  from the  input  accord ing  to  the  
heur i s t i cs  p rov ided  by the  express ion  E, 
e. For o ther  case ident i f ie rs ,ca l l  the l r  respec-  
ted Subroutines to get the value of the case. 
These subroutines are defined by the rule 
des igner .  
The case analysis in the SC-analysis con solve the 
elllpsls, anaphora, and other contextual problems. 
5.5. Semantic dlsambiguatlon and transformation 
The SO-rules define not only the relations for the 
syntagma reduction, but also contextual vector value 
changes w i th  respect  to  the  reduct ion  o f  o sentence,  
and the  ru les  re la ted  t rans format ions .  
The t rans format ion  operat ion  de f ined  in  the  SC~rule 
i s  in  the  fo l lew lng  forms,  
IX IX . . .  IX 
Here, IX , IX . . . .  , IX are t rans la t ions  o f  the  
syntagmas X , X , . . . ,  X in  the  ru le  head. The i r  
pos i t ions  ind icate  the  pos i t ions  o f  the  t rans la t ions  
of the syntogmas. There will also be some indicators 
In the string which are used to indicate positions of 
the translations for inserting tense, voice, modal 
modiflers.These indlcotors are used as the heuristics 
of the semantic processing. 
The transformetlon in the IMT/EC ls relatively 
slmple. It travels over the whole anolysls tree from 
top to down, left to right, transfer every node when 
the node is ?raveled.J'he result of the transformation 
is the Chinese utterance of the sentence. 
Rules with same head patterns may have different 
case frames A and B, in  th i s  case, they  may correspond 
to  d i f fe rent  t rans format ion  operat ions .  These ru les  
ore de f ined  as two d i f fe rent  ru les  by the  ru le  des lg -  
ne'r. Whfle in  the  IMT-KB, the  system s tores  them as 
one ru le  w l th  many cand idate  r ight  pat terns .  Whenever 
the  head pat tern  i s  success fu l ly  matched, the  system 
sequent ia l l y  checks these  cand idates  unt i l  one of 
them is  sa t i s f ied  and records  down the  cur rent  suc-  
cess fu l  position so that backtracking mechanism can 
120 
get the other candidates when necessary. 
The tasks of the semantic processing in the IMT/EC 
ore to  check the  resu l ts  o f  the  ana lys i s  to  see whe- 
ther  they satisfy the syntax or semantic collocation 
ru les  de f ined  in  the  IMT-KB, to  produce the  su i tab le  
mod i f ie rs  fo r  express ing  the  tense ,  vo lce ,  aspects  
and so on In  the  Chinese.  In  some cases , l t  a l so  app ly  
the  we l l  formed wor ld  knowledge def lned  in  the  IMT-KB 
to  e l iminate  some 11 lega l  express ions  and extend the  
meanings o f  some ambigu i ty  words. 
Slnce the  SC-ana lys l s  i s  based on the  semant ic  
grammar analysis, most of the syntax and semantic 
ambigu i t ies  are so lved  in  the  reduct ion  operat ions .  
Even though the  case ana lys l s  in  SC-ana lys l s  l s  aimed 
main ly  to  reso lve  the  contextua l  problems, they  can 
a l so  so lve  some ambigu i t ies  among o sentence.  That i s ,  
the  semant ic  p rocess ing  in  the  IMT/EC l s  o r lented  to  
spec l f l c  ambigu i t ies  and ln ter -sentent la l  case va lue  
eva luat ions .  Though the  process tngs  are d i f fe rent  in  
d i f ferent phases of the trons1otlon, they can be 
categorized as, 
(1) determining the value of o specific semantic 
ident i f ie r ,  such as tlme adverbial, place edverblal, 
anophoro etc. 
When o specific semantic ident i f ie r  is concerned, 
the semontlc, processlng mechanisms f i r s t  finds the 
key word which con match the semantic ident i f ie r  from 
the sentence,such as word wlth tlme,plaoe properties, 
then get the phrase which comprises the key word in 
the sentence, and return the phrase as the value of 
the ident i f ie r .  
Only simple anaphoro phenomena re considered in 
the IMT/EC. They are processed in two di f ferent ways. 
One is to compare the synonyms to flnd the. anaphorn 
words, the other Is to f lnd the suitable anaphoro 
content through the position relations, such ca ,  in 
some specific context the word 'which' can refer to 
the noun phrases immedlotel y before i t .  
(2) checking the collocation of syntogmas. 
There ore three  poss ib le  categor ies  o f  co l locat ion  
In  the analysls results, 
<1> X W -> (W => CI) 
<2> W Y -> (W => C2)  
<5> X W Y -> (w => C 3) 
Here, X, Y may be strings of words or syntagmos, W 
Is a specific word. The above expressions means that, 
<1> W appears a f ter  string X and functions as 
speech CI,  
<2> W appears be fore  s t r ing  Y and funct ions  as 
speech C~, 
<5> W appears between s t r lng  X and Y and func -  
t ions  as speech C~. 
The re la ted  word def in i t ion  in  the IMT-KB d ic t ion -  
ary  is as fo l low,  
W := C, (E, => MI) 
(E~ :> M~) 
c: (E~ => M~) 
Cm (E~ => M~) 
Here, C is the speech category, E is the context 
structure of word W, M Is the meaning of word W. 
The semantic processing mechanism retrieves the 
collocatlon rules specific to words of the sentence 
from the  IMT-KB, and app l ies  these  ru les  to  check the  
analysis result to see whether there is any Violation 
between the analysis result and collocation rules. If 
there ls ,  returns fe l l .  
(5) cheoklng the distant contextual relatlons. 
There are also three possible categories of 
distant contextual relations appeared in o sentence, 
X . . .  W \[m\] -> (W => C~) 
W . . .  Y \[n\] -> (W => C~) 
X . . .  W . . .  Y \[m,n\] -> (W => C~) 
Here, X, V, W, C have the same meanings as in the 
(2). n, m are optional, they defines the relat ive 
position between the word W and XIY. When n, m = 0, 
they ore the cases described in (2), When n, m is not 
def ined ,  they  ind icates  any pos i t ion  before /a f te r  the  
word ~V. These d is tant  contextua l  re la t ion  ru les  are 
de f ined  la  the  It~-I'--Kg In  the  same way as in  (2 ) .  
I f  m and/or  u are  present ,  the  semant ic  process ing  
mochenisdl f inds  m/rl word be fore /a f te r  t i le  word W in 
the  sentence,  and t r ies  to  reduce that  word and i t s  
ad jacent  words inca  X or' Y. I f  they  can be reduced, 
end t i le  word W funct ioas  as the  same category  as 
de f ined  in  the  ru le ,  tr len Successes, e18o e l iminates  
tlm analysis, 
if . iaud n are not ~efined, then try to find the 
word before /a f te r  t i le  word W which con be reduced 
in to  X or  Y together  w i th  i t s  ad jacent  words. I f  there  
ere no such e lement  in  t i le  sentence,  then re turns  
f ( l i l .  
( l l ) c re ,3 t ing  Chinese mod i f ie rs  to  express the  tense.  
vo ice ,  modal arid so on Grid inser t  these  mod i f ie rs  in 
ti le t r (3 J is lot icn accord ing  to  t i le  pos i t ion  mark 
Ip'pearoci iu  the ru le .  
the  9recess ing  procedure i s  as fo l low,  
a. GeL ClIO niorks o f  the  tense,  vo ice ,  modal e tc .  
b. Coll. trio' cor respe l ld /ng  sabraut ines  de f ined  by the  
ru le  des igner  to  del.orlidtle on appropr ia te  modi f i - -  
or  1-'or t i le mclrk. This  i s  bclsod main ly  on t i le  soa- 
tex i ; l lu l  s t ruc ture  o f  the  ana lys i s  resu l t .  
C. Ins(~rt tri() modifier in trlo position of tile truns- 
lati~)n marked by the  niarker.  
For" exa l l l J i l o , i f  a very  i s  in  the  ' - leg '  form and t i le re  
&s I:e t ime odvorb io l  in  the  i~lput,  the  tease o f  tho 
contoxt  are a l l  p rogress ive ,  then ignores  trle t ime 
rHark. IF  the  pred icate  ore  'be going to ' ,  then t rans -  
la tes  i t  as 'dashuang'  ignor ing  tr lo t ime mark. 
The wor ld  knowledge ru les  are de f ined  in  the  same 
form as ihe  semant ic  ru les .  "lhe app l i ca t ion  o f  these 
ru les  (Jr( to  tes t  tile context  to f ind  the semantic  
f'o(~ttlres Of the  s l tL Io t Ion  end coIdpQre these to  the  
wor ld  mo(iel de f in i t ion  dei"i~lc, d if~ the  wor ld  knowledge 
ru le  to  \[{el;ormiue the  s i t< lo t ion  of" the  u t terance ,  and 
thO~l detormido the cor rech  t rans la t ion  or  exterlct the  
mounlllgS Of re la ted  words. 
Every semunt lc  p rocess ing  nleChOnlsm mentiorled 
.b<)ve co,~responds to u spec i f i c  p rocess ing  subrout.-  
ir le. rtie;~.~ sabroat ines  are ca l led  i l l  the  grammar one- 
l ys l s  Ulid t rans format ion  process ing  to  per form the  
re la ted  \[~{911tantic p rocess ing .  (1)  I s  p r imar i ly  asod in  
the  case qna lys l s ,  (2 )  and (~) are pr ' Imar l ly  used in  
check ing cbe ana lys i s  resu l t  and d isembiguat ions  in  
the  ana lv : ; I s  and t rons for t l l aL ion , (4 )  is pr imar i ly  used 
i l l  the  t r ,msformot lon .  
The gr~muner and word t rnns format lon  q lgor$thm is ,  
(1 )  CHrrent=node <-- root  o f  t i le  ena lys l s  t ree ,  
(2))Z'? the  curront-InOdO i s  o loa f  node, go (4 ) ,  
(~) The current - -node i s  not  a lea f  node, the 
process in! j  are as fo l low,  
a. i I '  ~ll the  elemerlts in  the  t rans format ion  
e~:pression o f  the  node c~re constant ,  go (5 ) ,  
b. Ji ~ t i l l  the  var iab les  le  trio t rans format ion  
express ion  o f  the  node are  subst i tu ted  by 
c(~nstants,  thee call semant ic  p rocess ing  me- 
chanism to  c reate  su i tab le  mod i f ie rs .  Go (5 ) .  
a. i f '  there  are  scale unsubst i tu ted  var iab les  in  
the  express ion  o f  the  node. se t  these  var la - .  
b ias  r~s cur rent -node  er)e by one, aed uses the  
resu l ts  re turned  by each subnode to  rep lace  
the  var i ( lb les .  
(l~) Whet! the  cur rent=node Js a lea f  node , that  i s ,  
i t  i s  n spec~f lc  word or  arl ldlol~, then re t r ieves  
i t s  de f in t t ; lon  l=l"Onl the  IM'I'-,KB, ce l l  the  semant ic  
i}re(:osslu\[ I  ,lecheli I Sill to  determine on appropriate 
moaning far i t  according to the tree structure. 
(5) I| '  Lhe eurrent-aode is root node,then returns 
trio curron{;  fornl  o f  the transfermatiou exprese ion  es 
the  t rans la t ion  o f  the  sentence.  Otherwise ,  re turns  
t i le  expr 'ess ion to  the  parent  uode , reeovers  the parent  
nod~ rJs cur reet  node. Go (2 ) .  
~ . t ,  The mod i f i ca t ion  of: the  t rans la t ion  
The ob jec t ive  of" the  automat ic  mod i f i ca t ion  o f  the  
t r 'aus lGt lo~i  iS tO i l i lprove the  roadab i l i ty  o f  the  
t rans l{~L: lor l ,but  t i l t s  socr l f l ces  par t  o f  the  accuracy .  
I t  i s  more su i tab le  fo r  the  non-sc te l l t i f l c  l i te ra ture  
tdans la t lon .  
The main tasks  compr ises:  
a. Change the  order  o f  the  phrases and words o f  
the  t rans la t ion ,  
b. Subst i tu te  some words which co l locot ion  i s  not  
commonly used in  the  Chinese ut terahce  fo r  the  syno-  
i 
nymous words, 
c. lnsert some conjunctive words when necessary, 
d. E11m~.nate some redundant wards. 
The algorithm for these processing is, 
( I )  According to the Chinese oollocotion rules 
defined in the IMT-KB, changes the words and phrases 
order of the tranelatlon which are not in accord with 
the co l locat?on  convent ions  in  Chinese,  such as, 
Budon . . . .  E rch ia  . . . .  
(2 )  Accord ing to  the  co -occur rence  ru les  o f  the  
Chinese words de f ined  in  the  IMT-KB, check the  uses 
o f  the  Chinese words in  the  t rans la t ion .  I f  they  are 
not  in  accord wi th  the co-occurrence ru les ,  then rep- 
laces these  words w i th  the  Chinese synonymous words 
unt i l  they  ape accord to  the  ru les .  I f  there  i s  no 
su i tab le  synonyms.then t r ies  to  extend the  meaning o f  
some words. The meaning extend ing  ru les  are de f ined  in  
the  word ent r ies .  I t s  form i s  as fo l low,  
<word> : -  <cond i t ion  1> <extens ion  I> 
<cond i t ion  2> <extens ion  2> 
<cond i t ion  n> <extens ion  n> 
Here, <word> ind icates  the  word appeared in  the  
sentence,  
<cond i t ion> def ines  the  extend ing  cond i t ions ,  
<extens ion> i s  the  u t terances  extended.  
i?  the  word can not  be rep laced  or  extended,  t i len 
jus t  re turns  the  source t rans la t ion .  
(5)  Check the  t rans la t ion  to  f ind  the  redundant 
words and e l iminates  them. The form o f  do le t io r l  ru le  
i s ,  
X V X Z -> p (X) ,  p (V) i X V Z 
such as, 'NP de NP de -> NP NP de ' .  
Since the  mod i f i ca t ion  has no abso lu te  standard 
and requ i res  a la rge  amount o f  wor ld  knowledge, i t  i s  
ra ther  d l f f l cu l t  to  so lve  th i s  problem in  one day. In 
the  ZMT/EC, we on ly  deal  w i th  the  most s imple eases. 
More complex s i tuat ions  can be so lved w i th  the  app l i -  
ca t ion  and improvement o f  the  system. Thus , the  system 
is  designed to  be eas i ly  extended w i th  the  app l i ca -  
t ion .  
if the  user  needs h igh qua l i ty  t rans la t ion ,  he may 
cal l  the post editing subroutine to modify the trans- 
lat ion by human beings or with the aid of human 
beings.  At t i le  same t ime,we can a l so  set  the  learn ing  
mechanisms in  work ing  s ta tus  to  trace the  mod i f i ca -  
t ion  procedure oF human beings and produce some use- 
fu l  ru les  For the  system. 
I~. Summary 
In  conc lus ion ,  we hove ln t roduce~ ~ t rans la t ion  
process ing  procedure  9 f  the  Eng l i sh -Ch inese  machine 
t rans la t ion  system IMT/EC, and descr ibe  i t s  p r inc ipa l  
process ing  a lgor i thms.  
Aknowledgement: We would l i ke  to  thank Hang Xiong, 
Zharlg Yu j ie ,  Ye Y imln ,  Tong J iox ion ,  Zong L ly i ,  
Zhong Z i fe ,  Chen Z1zong, Chen Zizeng and Fu Wei For 
the i r  cooperat ion  in  th  e imp lementat ion  o f  IMT/EC, 
5. Reference  
\[1 \] Axe lb iewer ,  Chr i s t ian  Fenneyro l ,  Johannes R l tzke ,  
ErWirl i tegent r l t t (1985) ,  ASCOF-A modular mul t i leve l  
system for  French-German t rans la t ion ,  OL, Vo i .11 ,  No. 
2-5,  p'157-'154, 1985. 
\ [2 \ ]  Bernard Vauquois and Chr i s t ian  ~\ ]o i te t ,Automated 
121 
transletion at Grenoble university, CL, Voi.11, No.I, 
p28-36, 1985. 
\[5\] galena Henlsz-Dostert et e l . ,  Machine Transla- 
t ion,  Mouton publishers, Hague, Paris,New York, 1979. 
\[4\] Harry tennant, Natural Language processing, Pe- 
t roce l l i  books, New York, 1981. 
\[5\] Hiroshl Uchida, Fuj ltru machine translation 
system: ATLAS, FGCS, Vol.2, No.2, p95-1~0,1986. 
\[6\] Jaime G. Carbonell and Masaru Tomita, New 
approaches to Machine Translation, TR-CMU-CS-85-143, 
Carnegie-Mellon University, 1985. 
\[7\] Jonathan Slocum, A survey of machine transla- 
tion: i t s  hlstory,current status and future perspect- 
ives, CL, Vol. 11,No. 1, p1-17, 1985. 
\[8\] Kazunori Muraki, VENUS: Two-phrase machine 
t rans lat ion system, FGCS, Vol.2, p121-124, 1986. 
\[9\] Martin Kay, The MIND system, Natural Language 
processing, edited by Rustin, Algorithmics press, New 
York, 1975, p155-189. 
\[10\] Makota Nagao, Current Status and future trends 
in machine t rans la t ion ,  FGCS, Vol. 2, No. 2, p77-82, 
1986. 
\[11\] M.Nogao, J .Tsu j i l  and J.Nakamura, Science and 
Technology agency's machine t rans lat ion proJect,FGCS, 
Vol.2, No.2, p125-14~, 1986. 
\[12\] Murlel Vasconcellos and MarJorie Leon, SPANAM 
and ENGSPAN: machine t rans lat ion  at the PAN American 
health organization, CL,Vol.11,No.2-5, p122-156,1985. 
\[15\] Paul L.Garvin(ed.),  Natural Language and the 
Computer, McGraw-Hill book, New York, London, 1979. 
\[14\] Perelra F. and Warren D., Definite clause 
grammar for  language onalvsls, A r t l f~c lo l  Inte l l lgen-  
ce, Vol.15,p251-278,198~. 
\[15\] Pierre Isabelle and Laurent Bourbeau, TAUM- 
AVIATION:Its technlcal features and some experimental 
results,  CL, Vol.11, No. 1, p18-27, 1985. 
\[16\] Richard E. CulZingford, Word-meaning selection 
in multiproces~language understanding, IEEE Trans. 
on Pattern analysis and m~chlne inte l l igence,  Vol, 
PAMI-.6, No.4., July 1984,p493-509. 
\[17\] R.F.Simmons, Technologies for  machine trans- 
lat ion,  FGCS, Vol.2, No.2, p85-94, 1986. 
\[18\] Rod Johnson, Maghi Kinq, end Louis des Tombe, 
EUROTRA: A mult i l ingual  system under development, CL, 
V01.11, No.2-3, p155-169,1985. 
\[19\] Roger Sehank, The condeptuel analysis of 
natural language, Natural Language processing, edited 
by Randall Rustln, Algorithmics Press, New York,1975, 
p291-511. 
\[20\] Rozena Hennisz-Dostert, R.Ross Macdonald and 
Michael Zarechnak, Machine translotion, Mouton Publi- 
sher, Hugue, Paris, New York, 1979. ~. 
\[21\] S.Amano, The Toshiba machine t rans lat ion sys- 
tem, FGCS, Vol.2, No.2, p121-124~11986. 
\[22\] Terry Wlnograd, Language as a Cognltlve(Vol 1) 
process, Addison-Wesley Publishing Company, 
California,London, 1985. 
\[25\] Vtnf ie ld  S.Bennett and Jonathan 61ocum, The 
LRC machine t rans lat ion  system, CL, Vo1.11, No.2-5, 
p1?1-121, 1985. 
\[24\] Y. Wilks, The stanford machine translation 
project,  Natural Language Processing, edited by 
Randall Rustin, Algorithmics Press, New York, 1973, 
p245-291. 
\[25\] Yoshlhiko Nlt ta,  Problems of machine t rans la-  
t ion systems-effect of cultural  differences on sent- 
ence structure,  FGCS, Vol.2, No.2, p117-120, 1986. 
122 
