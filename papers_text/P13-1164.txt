Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 1669?1679,
Sofia, Bulgaria, August 4-9 2013. c?2013 Association for Computational Linguistics
Lightly Supervised Learning of Procedural Dialog Systems
Svitlana Volkova
CLSP
Johns Hopkins University
Baltimore, MD
svitlana@jhu.edu
Pallavi Choudhury, Chris Quirk, Bill Dolan
NLP Group
Microsoft Research
Redmond, WA
pallavic,chrisq,
billdol@microsoft.com
Luke Zettlemoyer
Computer Science and Engineering
University of Washington
Seattle, WA
lsz@cs.washington.edu
Abstract
Procedural dialog systems can help users
achieve a wide range of goals. However,
such systems are challenging to build,
currently requiring manual engineering of
substantial domain-specific task knowl-
edge and dialog management strategies. In
this paper, we demonstrate that it is pos-
sible to learn procedural dialog systems
given only light supervision, of the type
that can be provided by non-experts. We
consider domains where the required task
knowledge exists in textual form (e.g., in-
structional web pages) and where system
builders have access to statements of user
intent (e.g., search query logs or dialog
interactions). To learn from such tex-
tual resources, we describe a novel ap-
proach that first automatically extracts task
knowledge from instructions, then learns a
dialog manager over this task knowledge
to provide assistance. Evaluation in a Mi-
crosoft Office domain shows that the indi-
vidual components are highly accurate and
can be integrated into a dialog system that
provides effective help to users.
1 Introduction
Procedural dialog systems aim to assist users
with a wide range of goals. For example, they
can guide visitors through a museum (Traum et
al., 2012; Aggarwal et al, 2012), teach students
physics (Steinhauser et al, 2011; Dzikovska et
al., 2011), or enable interaction with a health care
U: ?I want to add page numbers and a title?
S: ?Top or Bottom of the page??
U: ?Top?
S: ?Please select page design from the tem-
plates? (*System shows drop down menu*)
U: *User selects from menu*
S: ?Enter header or footer content?
U: ?C.V.?
S: ?Task completed.?
Figure 1: An example dialog interaction between
a system (S) and user (U) that can be automatically
achieved by learning from instructional web page
and query click logs.
system (Morbini et al, 2012; Rizzo et al, 2011).
However, such systems are challenging to build,
currently requiring expensive, expert engineering
of significant domain-specific task knowledge and
dialog management strategies.
In this paper, we present a new approach for
learning procedural dialog systems from task-
oriented textual resources in combination with
light, non-expert supervision. Specifically, we as-
sume access to task knowledge in textual form
(e.g., instructional web pages) and examples of
user intent statements (e.g., search query logs or
dialog interactions). Such instructional resources
are available in many domains, ranging from
recipes that describe how to cook meals to soft-
ware help web pages that describe how to achieve
goals by interacting with a user interface.1
1ehow.com,wikianswers.com
1669
There are two key challenges: we must (1)
learn to convert the textual knowledge into a us-
able form and (2) learn a dialog manager that pro-
vides robust assistance given such knowledge. For
example, Figure 1 shows the type of task assis-
tance that we are targeting in the Microsoft Office
setting, where the system should learn from web
pages and search query logs. Our central contribu-
tion is to show that such systems can be built with-
out the help of knowledge engineers or domain ex-
perts. We present new approaches for both of our
core problems. First, we introduce a method for
learning to map instructions to tree representations
of the procedures they describe. Nodes in the tree
represent points of interaction with the questions
the system can ask the user, while edges represent
user responses. Next, we present an approach that
uses example user intent statements to simulate di-
alog interactions, and learns how to best map user
utterances to nodes in these induced dialog trees.
When combined, these approaches produce a com-
plete dialog system that can engage in conversa-
tions by automatically moving between the nodes
of a large collection of induced dialog trees.
Experiments in the Windows Office help do-
main demonstrate that it is possible to build an
effective end-to-end dialog system. We evaluate
the dialog tree construction and dialog manage-
ment components in isolation, demonstrating high
accuracy (in the 80-90% range). We also conduct
a small-scale user study which demonstrates that
users can interact productively with the system,
successfully completing over 80% of their tasks.
Even when the system does fail, it often does so in
a graceful way, for example by asking redundant
questions but still reaching the goal within a few
additional turns.
2 Overview of Approach
Our task-oriented dialog system understands user
utterances by mapping them to nodes in dialog
trees generated from instructional text. Figure 2
shows an example of a set of instructions and the
corresponding dialog tree. This section describes
the problems that we must solve to enable such in-
teractions, and outlines our approach for each.
Knowledge Acquisition We extract task knowl-
edge from instructional text (e.g., Figure 2, left)
that describes (1) actions to be performed, such
as clicking a button, and (2) places where input
is needed from the user, for example to enter the
contents of the footer or header they are trying to
create. We aim to convert this text into a form that
will enable a dialog system to automatically assist
with the described task. To this end, we construct
dialog trees (e.g., Figure 2, right) with nodes to
represent entire documents (labeled as topics t),
nodes to represent user goals or intents (g), and
system action nodes (a) that enable execution of
specific commands. Finally, each node has an as-
sociated system action as, which can prompt user
input (e.g., with the question ?Top or bottom of
the page??) and one or more user actions au that
represent possible responses. All nodes connect
to form a tree structure that follows the workflow
described in the document. Section 3 presents a
scalable approach for inducing dialog trees.
Dialog Management To understand user intent
and provide task assistance, we need a dialog man-
agement approach that specifies what the system
should do and say. We adopt a simple approach
that at all times maintains an index into a node in
a dialog tree. Each system utterance is then simply
the action as for that node. However, the key chal-
lenge comes in interpreting user utterances. After
each user statement, we must automatically up-
date our node index. At any point, the user can
state a general goal (e.g., ?I want to add page num-
bers?), refine their goal (e.g., ?in a footer?), or both
(e.g.,?I want to add page numbers in the footer?).
Users can also change their goals in the process of
completing the tasks.
We develop a simple classification approach
that is robust to these different types of user behav-
ior. Specifically, we learn classifiers that, given the
dialog interaction history, predict how to pick the
next tree node from the space of all nodes in the di-
alog trees that define the task knowledge. We iso-
late two specific cases, classifying initial user ut-
terances (Section 4) and classifying all subsequent
utterances (Section 5). This approach allows us to
isolate the difference in language for the two cases,
and bias the second case to prefer tree nodes near
the current one. The resulting approach allows for
significant flexibility in traversing the dialog trees.
Data and Evaluation We collected a large set of
such naturally-occurring web search queries that
resulted in a user click on a URL in the Microsoft
Office help domain.2 We found that queries longer
that 4-5 words often resembled natural language
utterances that could be used for dialog interac-
2http://office.microsoft.com
1670
Figure 2: An example instructional text paired with a section of the corresponding dialog tree.
tions, for example how do you add borders, how
can I add a footer, how to insert continuous page
numbers, and where is the header and footer.
We also collected instructional texts from the
web pages that describe how to solve 76 of the
most pressing user goals, as indicated by query
click log statistics. On average 1,000 user queries
were associated with each goal. To some extent
clickthroughs can be treated as a proxy for user
frustration; popular search targets probably repre-
sent user pain points.
3 Building Dialog Trees from
Instructions
Our first problem is to convert sets of instructions
for user goals to dialog trees, as shown in Figure
2. These goals are broadly grouped into topics
(instructional pages). In addition, we manually
associate each node in a dialog tree with a train-
ing set of 10 queries. For the 76 goals (246 in-
structions) in our data, this annotation effort took
a single annotator a total of 41 hours. Scaling this
approach to the entire Office help domain would
require a focused annotation effort. Crucially,
though, this annotation work can be carried out by
non-specialists, and could even be crowdsourced
(Bernstein et al, 2010).
Problem Definition As input, we are given in-
structional text (p1 . . . pn), comprised of topics
(t1 . . . tn) describing:
(1) high-level user intents (e.g., t1 ? ?add and for-
mat page numbers?)
(2) goals (g1, . . . , gk) that represent more spe-
cific user intents (e.g., g1 ? ?add header or
footer content to a preformatted page number
design?, g2 ? ?place the page number in the
side margin of the page?).
Given instructional text p1 . . . pn and queries
q1 . . . qm per topic ti, our goals are as follows:
Figure 3: Relationships between user queries and
OHP with goals, instructions and dialog trees.
- for every instructional page pi extract a topic
ti and a set of goals g1 . . . gk;
- for every goal gj for a topic ti, extract a set of
instructions i1 . . . il;
- from topics, goals and instructions, construct
dialog trees f1 . . . fn (one dialog tree per
topic). Classify instructions to user interac-
tion types thereby identifying system action
nodes a1s . . . als. Transitions between these
nodes are the user actions a1u . . . alu.
Figure 2 (left) presents an example of a topic
extracted from the help page, and a set of goals
and instructions annotated with user action types.
In the next few sections of the paper, we out-
line an overall system component design demon-
strating how queries and topics are mapped to the
dialog trees in Figure 3. The figure shows many-
to-one relations between queries and topics, one-
to-many relations between topics and goals, goals
and instructions, and one-to-one relations between
topics and dialog trees.
User Action Classification We aim to classify
instructional text (i1 . . . il) for every goal gj in the
decision tree into four categories: binary, selec-
tion, input or none.
Given a single instruction i with category au,
we use a log-linear model to represent the distri-
1671
bution over the space of possible user actions. Un-
der this representation, the user action distribution
is defined as:
p(au|i, ?) =
e???(au,i)?
a?u e
???(au,i) , (1)
where ?(au, i) ? Rn is an n-dimensional fea-
ture representation and ~? is a parameter vector we
aim to learn. Features are indicator functions of
properties of the instructions and a particular class.
For smoothing we use a zero mean, unit variance
Gaussian prior (0, 1) that penalizes ~? for drifting
too far from the mean, along with the following
optimization function:
log p(Au, ?|I) = log p(Au|I, ?)? log p(?) =
=
?
au,i?(Au,I)
p(au|i, ?)?
?
i
(? ? ?i)2
2?2i
+ k
(2)
We use L-BFGS (Nocedal and Wright, 2000) as
an optimizer.
Experimental Setup As described in Section 2,
our dataset consists of 76 goals grouped into 30
topics (average 2-3 goals per topic) for a total of
246 instructions (average 3 instructions per goal).
We manually label all instructions with user ac-
tion au categories. The distribution over cate-
gories is binary=14, input=23, selection=80 and
none=129. The data is skewed towards the cat-
egories none and selection. Many instruction do
not require any user input and can be done auto-
matically, e.g., ?On the Insert tab, in the Header
and Footer group, click Page Number?. The ex-
ample instructions with corresponding user action
labels are shown in Figure 2 (left) . Finally, we di-
vide the 246 instructions into 2 sets: 80% training
and 20% test, 199 and 47 instructions respectively.
Results We apply the user action type classifi-
cation model described in the Eq.1 and Eq.2 to
classify instructions from the test set into 4 cate-
gories. In Table 1 we report classification results
for 2 baselines: a majority class and heuristic-
based approach, and 2 models with different fea-
ture types: ngrams and ngrams + stems. For a
heuristic baseline, we use simple lexical clues to
classify instructions (e.g., X or Y for binary, select
Y for selection and type X, insert Y for input). Ta-
ble 1 summarizes the results of mapping instruc-
tional text to user actions.
Features # Features Accuracy
Baseline 1: Majority ? 0.53
Baseline 2: Heuristic ? 0.64
Ngrams 10,556 0.89
Ngrams + Stems 12,196 0.89
Table 1: Instruction classification results.
Building the Dialog Trees Based on the classi-
fied user action types, we identify system actions
a1s . . . als which correspond to 3 types of user ac-
tions a1s . . . als (excluding none type) for every goal
in a topic ti. This involved associating all words
from an instruction il with a system action als. Fi-
nally, for every topic we automatically construct a
dialog tree as shown in Figure 2 (right). The dia-
log tree includes a topic t1 with goals g1 . . . g4, and
actions (user actions au and system actions as).
Definition 1. A dialog tree encodes a user-system
dialog flow about a topic ti represented as a di-
rected unweighted graph fi = (V,E) where top-
ics, goals and actions are nodes of correspond-
ing types {t1 . . . tn}, {g1 . . . gk}, {a1 . . . al} ? V .
There is a hierarchical dependency between topic,
goal and action nodes. User interactions are
represented by edges ti ? {g1 . . . gk}, a1u =
(gj , a1) . . . alu = (ak?1, ak) ? E.
For example, in the dialog tree in Figure 2 there
is a relation t1 ? g4 between the topic t1 ?add
and format page numbers? and the goal g4 ?in-
clude page of page X of Y with the page number?.
Moreover, in the dialog tree, the topic level node
has one index i ? [1..n], where n is the number
of topics. Every goal node includes information
about its parent (topic) node and has double index
i.j, where j ? [1..k]. Finally, action nodes include
information about their parent (goal) and grand-
parent (topic) nodes and have triple index i.j.z,
where z ? [1..l].
4 Understanding Initial Queries
This section presents a model for classifying ini-
tial user queries to nodes in a dialog tree, which
allows for a variety of different types of queries.
They can be under-specified, including informa-
tion about a topic only (e.g., ?add or delete page
numbers?); partially specified, including informa-
tion about a goal (e.g., ?insert page number?); or
over-specified, including information about an ac-
tion ( e.g., ?page numbering at bottom page?.)
1672
Figure 4: Mapping initial user queries to the nodes
on different depth in a dialog tree.
Problem Definition Given an initial query, the
dialog system initializes to a state s0, searches for
the deepest relevant node given a query, and maps
the query to a node on a topic ti, goal gj or action
ak level in the dialog tree fi, as shown in Figure 4.
More formally, as input, we are given automati-
cally constructed dialog trees f1 . . . fn for instruc-
tional text (help pages) annotated with topic, goal
and action nodes and associated with system ac-
tions as shown in Figure 2 (right). From the query
logs, we associate queries with each node type:
topic qt, goal qg and action qa. This is shown in
Figure 2 and 4. We join these dialog trees repre-
senting different topics into a dialog network by
introducing a global root. Within the network,
we aim to find (1) an initial dialog state s0 that
maximizes the probability of state given a query
p(s0|q, ?); and (2) the deepest relevant node v ? V
on topic ti, goal gj or action ak depth in the tree.
Initial Dialog State Model We aim to predict
the best node in a dialog tree ti, gj , al ? V based
on a user query q. A query-to-node mapping is en-
coded as an initial dialog state s0 represented by a
binary vector over all nodes in the dialog network:
s0 = [t1, g1.1, g1.2, g1.2.1 . . . , tn, gn.1, gn.1.1].
We employ a log-linear model and try to maxi-
mize initial dialog state distribution over the space
of all nodes in a dialog network:
p(s0|q, ?) =
e
?
i ?i?i(s0,q)
?
s?0 e
?
i ?i?i(s?0,q)
, (3)
Optimization follows Eq. 2.
We experimented with a variety of features.
Lexical features included query ngrams (up to 3-
grams) associated with every node in a dialog tree
with removed stopwords and stemming query un-
igrams. We also used network structural features:
Accuracy
Features Topic Goal Action
Random 0.10 0.04 0.04
TFIDF 1Best 0.81 0.21 0.45
Lexical (L) 0.92 0.66 0.63
L + 10TFIDF 0.94 0.66 0.64
L + 10TFIDF + PO 0.94 0.65 0.65
L + 10TFIDF + QO 0.95 0.72 0.69
All above + QHistO 0.96 0.73 0.71
Table 2: Initial dialog state classification results
where L stands for lexical features, 10TFIDF - 10
best tf-idf scores, PO - prompt overlap, QO - query
overlap, and QHistO - query history overlap.
tf-idf scores, query ngram overlap with the topic
and goal descriptions, as well as system action
prompts, and query ngram overlap with a history
including queries from parent nodes.
Experimental Setup For each dialog tree,
nodes corresponding to single instructions were
hand-annotated with a small set of user queries,
as described in Section 3. Approximately 60% of
all action nodes have no associated queries3 For
the 76 goals, the resulting dataset consists of 972
node-query pairs, 80% training and 20% test.
Results The initial dialog state classification
model of finding a single node given an initial
query is described in Eq. 3.
We chose two simple baselines: (1) randomly
select a node in a dialog network and (2) use a tf-
idf 1-best model.4 Stemming, stopword removal
and including top 10 tf-idf results as features led
to a 19% increase in accuracy on an action node
level over baseline (2). Adding the following fea-
tures led to an overall 26% improvement: query
overlap with a system prompt (PO), query overlap
with other node queries (QO), and query overlap
with its parent queries (QHistO) .
We present more detailed results for topic, goal
and action nodes in Table 2. For nodes deeper in
the network, the task of mapping a user query to an
action becomes more challenging. Note, however,
that the action node accuracy numbers actually un-
3There are multiple possible reasons for this: the soft-
ware user interface may already make it clear how to accom-
plish this intent, the user may not understand that the software
makes this fine-grained option available to them, or their ex-
perience with search engines may lead them to state their in-
tent in a more coarse-grained way.
4We use cosine similarity to rank all nodes in a dialog
network and select the node with the highest rank.
1673
derstate the utility of the resulting dialog system.
The reason is that even incorrect node assignments
can lead to useful system performance. As long
as a misclassification results being assigned to a
too-high node within the correct dialog tree, the
user will experience a graceful failure: they may
be forced to answer some redundant questions, but
they will still be able to accomplish the task.
5 Understanding Query Refinements
We also developed a classifier model for mapping
followup queries to the nodes in a dialog network,
while maintaining a dialog state that summarizes
the history of the current interaction.
Problem Definition Similar to the problem def-
inition in Section 4, we are given a network of di-
alog trees f1 . . . fn and a query q?, but in addition
we are given the previous dialog state s, which
contains the previous user utterance q and the last
system action as. We aim to find a new dialog
state s? that pairs a node from the dialog tree with
updated history information, thereby undergoing a
dialog state update.
We learn a linear classifier that models
p(s?|q?, q, as, ?), the dialog state update distribu-
tion, where we constrain the new state s? to contain
the new utterance q? we are interpreting. This dis-
tribution models 3 transition types: append, over-
ride and reset.
Definition 2. An append action defines a dialog
state update when transitioning from a node to its
children at any depth in the same dialog tree e.g.,
ti ? gi.j (from a topic to a goal node), gi.j ?
ai.j.z (from a goal to an action node) etc.
Definition 3. An override action defines a dialog
state update when transitioning from a goal to its
sibling node. It could also be from an action node5
to another in its parent sibling node in the same di-
alog tree e.g., gi.j?1 ? gi.j (from one goal to an-
other goal in the same topic tree), ai.j.z ? ai.?j.z
(from an action node to another action node in a
different goal in the same dialog tree) etc.
Definition 4. A reset action defines a dialog state
update when transitioning from a node in a current
dialog tree to any other node at any depth in a
dialog tree other than the current dialog tree e.g.,
ti ? t?i, (from one topic node to another topic
5A transition from ai.j.z must be to a different goal or an
action node in a different goal but in the same dialog tree.
(a) Updates from topic node ti
(b) Updates from goal node gj
(c) Updates from action node al
Figure 5: Information state updates: append, reset
and override updates based on Definition 2, 3 and
4, respectively, from topic, goal and action nodes.
node) ti ? g?i.j (from a topic node to a goal node
in a different topic subtree), etc.
The append action should be selected when the
user?s intent is to clarify a previous query (e.g.,
?insert page numbers? ? ?page numbers in the
footer?). An override action is appropriate when
the user?s intent is to change a goal within the
same topic (e.g., ?insert page number? ?change
page number?). Finally, a reset action should be
used when the user?s intent is to restart the dialog
(e.g., ?insert page x of y? ? ?set default font?).
We present more examples for append, override
and reset dialog state update actions in Table 3.
1674
Previous Utterance, q User Utterance, q? Transition Update Action, a
inserting page numbers qt1 add a background ti ? t?i 2, reset-T, reset
how to number pages qt2 insert numbers on pages in margin ti ? si.j 1.4, append-G, append
page numbers qt3 set a page number in a footer ti ? ai.j.z 1.2.1, append-A, append
page number a document qt4 insert a comment ti ? g?i.j 21.1, reset-G, reset
page number qt5 add a comment ?redo? ti ? a?i.j.z 21.2.1, reset-A, reset
page x of y qg1 add a border gi.j ? t?i 6, reset-T, resetformat page x of x qg2 enter text and page numbers gi.j ? gi.?j 1.1, override-G, overrideenter page x of y qg3 page x of y in footer gi.j ? ai.j.z 1.3.1, append-A, appendinserting page x of y qg4 setting a default font gi.j ? g?i.j 6.1, reset-G, resetshowing page x of x qg5 set default font and style gi.j ? a?i.j.z 6.4.1, reset-A, resetpage numbers bottom qa1 make a degree symbol ai.j.z ? t?i 13, reset-T, reset
numbering at bottom page qa2 insert page numbers ai.j.z ? gi.?j 1.1, override-G, override
insert footer page numbers qa3 page number design ai.j.z?1 ? ai.j.z 1.2.2, append-A, append
headers page number qa4 comments in document ai.j.z ? g?i.j 21.1, reset-G, reset
page number in a footer qa5 changing initials in a comment ai.j.z ? a?i.j.z 21.2.1, reset-A, reset
Table 3: Example q and q? queries for append, override and reset dialog state updates.
Figure 5 illustrates examples of append, over-
ride and reset dialog state updates. All transitions
presented in Figure 5 are aligned with the example
q and q? queries in Table 3.
Dialog State Update Model We use a log-linear
model to maximize a dialog state distribution over
the space of all nodes in a dialog network:
p(s?|q?, q, as?) =
e
?
i ?i?i(s?,q?,as,q)
?
s?? e
?
i ?i?i(s??,q?,as,q)
, (4)
Optimization is done as described in Section 3.
Experimental Setup Ideally, dialog systems
should be evaluated relative to large volumes of
real user interaction data. Our query log data,
however, does not include dialog turns, and so we
turn to simulated user behavior to test our system.
Our approach, inspired by recent work (Schatz-
mann et al, 2006; Scheffler and Young, 2002;
Georgila et al, 2005), involves simulating dialog
turns as follows. To define a state s we sam-
ple a query q from a set of queries per node v
and get a corresponding system action as for this
node; to define a state s?, we sample a new query
q? from another node v? ? V, v 6= v? which
is sampled using a prior probability biased to-
wards append: p(append)=0.7, p(override)=0.2,
p(reset)=0.1. This prior distribution defines a dia-
log strategy where the user primarily continues the
current goal and rarely resets.
We simulate 1100 previous state and new query
pairs for training and 440 pairs for testing. The
features were lexical, including word ngrams,
stems with no stopwords; we also tested network
structure, such as:
- old q and new q? query overlap (QO);
- q? overlap with a system prompt as (PO);
- q? ngram overlap with all queries from the old
state s (SQO);
- q? ngram overlap with all queries from the
new state s? (S?QO);
- q? ngram overlap with all queries from the
new state parents (S?ParQO).
Results Table 4 reports results for dialog state
updates for topic, goal and action nodes. We also
report performance for two types of dialog updates
such as: append (App.) and override (Over.).
We found that the combination of lexical and
query overlap with the previous and new state
queries yielded the best accuracies: 0.95, 0.84 and
0.83 for topic, goal and action node level, respec-
tively. As in Section 4, the accuracy on the topic
level node was highest. Perhaps surprisingly, the
reset action was perfectly predicted (accuracy is
100% for all feature combinations, not included
in figure). The accuracies for append and override
actions are also high (append 95%, override 90%).
Features Topic Goal Action App. Over.
L 0.92 0.76 0.78 0.90 0.89
L+Q 0.93 0.80 0.80 0.92 0.83
L+P 0.93 0.80 0.79 0.91 0.85
L+Q+P 0.94 0.80 0.80 0.93 0.85
L+SQ 0.94 0.82 0.81 0.93 0.85
L+S?Q 0.93 0.80 0.80 0.91 0.90
L+S?+ParQ 0.94 0.80 0.80 0.91 0.86
L+Q+S?Q 0.94 0.81 0.81 0.91 0.88
L+SQ+S?Q 0.95 0.84 0.83 0.94 0.88
Table 4: Dialog state updates classification ac-
curacies where L stands for lexical features, Q -
query overlap, P - prompt overlap, SQ - previous
state query overlap, S?Q - new state query overlap,
S?ParQ - new state parent query overlap.
1675
6 The Complete Dialog System
Following the overall setup described in Section 2,
we integrate the learned models into a complete
dialog system. To evaluate the quality of the in-
teractions with this system, we performed a small
scale user study, as described here.
Experimental Setup We randomly chose 8
goals, across topics, from the 76 used to train our
models. For each goal, six users were shown a Mi-
crosoft Word document before and after the goal
was executed. Users were allowed to interact with
the system in an unconstrained manner providing a
total of 48 interactions. If at any point they thought
the system response was irrelevant to their intent,
they could either rephrase or start over.
User Study We objectively measured task com-
pletion and the quality of individual system utter-
ances. We also asked the users to rate the system
(on a scale of 1-5, with 5 being best) on various
measures, including whether the system asked rel-
evant questions. Table 5 summarizes the results.
In general, users were able to complete the tasks
and were reasonably satisfied.
Discussion Figure 6 shows four example di-
alogs. User utterances ranged from single key-
words to rich, sentence-like goal descriptions. For
the shorter inputs, the system was generally able
to identify a small cohort of high-probability in-
tents. For longer inputs, especially with explicitly
specified parameter settings, the system was usu-
ally able to elicit whatever additional information
was required to complete the task. The majority of
errors fell into two categories when the system:
I. missed key information in the input and
asked redundant questions ? Figure 6 (C);
II. failed to correctly identify the intent, and
asked an irrelevant question ? Figure 6 (D).
Table 5 shows the frequency of each error type.
Objective Measures Observed Rates
User achieved task 83%
System asked irrelevant questions 19%
System asked redundant questions 18%
User Satisfaction Score Std.Dev.
Overall satisfaction 3.42 0.49
Questions were relevant 4.17 0.41
Ambiguity was managed 4.00 0.89
Table 5: User study results.
U: ?I want a page number and title at the bot-
tom of the page?
S: ?Choose a page number design from the
gallery of designs?
U: *User selects design*
S: ?To insert header or footer content before the
page number, type the content, and then press
TAB to position the content?
U: ?Professional Resume?
S: ?Task Completed?
(A)
U: ?Alphabetize bullets?
S: ?Do you want to sort a list alphabetically?
U: ?Sort a list?
S: ?Select the text in a bulleted or numbered
list?
U: *User selection*
S: ?Ascending or Descending??
U: ?Ascending?
S: ?Task Completed?
(B)
U: ?I want the background color to be yellow?
S: ?Choose a color for the document?
U: ?Yellow ?
S: ?Task completed?
(C)
U: ?I want to change the font face and size?
S: ?Choose the default font?
U: ?No, reduce the size of the text?
S: *System Restarts*
(D)
Figure 6: Four example dialogs from the user
study, including cases that (A and B) complete
successfully, (C) have a redundant question, and
(D) fail to recognize the user intent.
7 Related work
To the best of our knowledge, this paper presents
the first effort to induce full procedural dialog sys-
tems from instructional text and query click logs.
Grounded Language Learning There has been
significant interest in grounded language learn-
ing. Perhaps the most closely related work
learns to understand instructions and automati-
1676
cally complete the tasks they describe (Branavan
et al, 2009; Vogel and Jurafsky, 2010; Kush-
man et al, 2009; Branavan et al, 2010; Artzi and
Zettlemoyer, 2013). However, these approaches
did not model user interaction. There are also
many related approaches for other grounded lan-
guage problems, including understanding game
strategy guides (Branavan et al, 2011), model-
ing users goals in a Windows domain (Horvitz
et al, 1998), learning from conversational inter-
action (Artzi and Zettlemoyer, 2011), learning
to sportscast (Chen and Mooney, 2011), learning
from event streams (Liang et al, 2009), and learn-
ing paraphrases from crowdsourced captions of
video snippets (Chen and Dolan, 2011).
Dialog Generation from Text Similarly to Pi-
wek?s work (2007; 2010; 2011), we study extract-
ing dialog knowledge from documents (mono-
logues or instructions). However, Piwek?s ap-
proach generates static dialogs, for example to
generate animations of virtual characters having a
conversation. There is no model of dialog man-
agement or user interaction, and the approach does
not use any machine learning. In contrast, to the
best of our knowledge, we are the first to demon-
strate it is possible to learn complete, interactive
dialog systems using instructional texts (and non-
expert annotation).
Learning from Web Query Logs Web query
logs have been extensively studied. For example,
they are widely used to represent user intents in
spoken language dialogs (Tu?r et al, 2011; Celiky-
ilmaz et al, 2011; Celikyilmaz and Hakkani-Tur,
2012). Web query logs are also used in many other
NLP tasks, including entity linking (Pantel et al,
2012) and training product and job intent classi-
fiers (Li et al, 2008).
Dialog Modeling and User Simulation Many
existing dialog systems learn dialog strategies
from user interactions (Young, 2010; Rieser and
Lemon, 2008). Moreover, dialog data is often lim-
ited and, therefore, user simulation is commonly
used (Scheffler and Young, 2002; Schatzmann et
al., 2006; Georgila et al, 2005).
Our overall approach is also related to many
other dialog management approaches, including
those that construct dialog graphs from dialog data
via clustering (Lee et al, 2009), learn information
state updates using discriminative classification
models (Hakkani-Tur et al, 2012; Mairesse et al,
2009), optimize dialog strategy using reinforce-
ment learning (RL) (Scheffler and Young, 2002;
Rieser and Lemon, 2008), or combine RL with
information state update rules (Heeman, 2007).
However, our approach is unique in the use of in-
ducing task and domain knowledge with light su-
pervision to assist the user with many goals.
8 Conclusions and Future Work
This paper presented a novel approach for au-
tomatically constructing procedural dialog sys-
tems with light supervision, given only textual re-
sources such as instructional text and search query
click logs. Evaluations demonstrated highly accu-
rate performance, on automatic benchmarks and
through a user study.
Although we showed it is possible to build com-
plete systems, more work will be required to scale
the approach to new domains, scale the complex-
ity of the dialog manager, and explore the range of
possible textual knowledge sources that could be
incorporated. We are particularly interested in sce-
narios that would enable end users to author new
goals by writing procedural instructions in natural
language.
Acknowledgments
The authors would like to thank Jason Williams
and the anonymous reviewers for their helpful
comments and suggestions.
References
Priti Aggarwal, Ron Artstein, Jillian Gerten, An-
thanasios Katsamanis, Shrikanth Narayanan, Angela
Nazarian, and David R. Traum. 2012. The twins
corpus of museum visitor questions. In Proceedings
of LREC.
Yoav Artzi and Luke Zettlemoyer. 2011. Learning
to recover meaning from unannotated conversational
interactions. In NIPS Workshop In Learning Seman-
tics.
Yoav Artzi and Luke Zettlemoyer. 2013. Weakly su-
pervised learning of semantic parsers for mapping
instructions to actions. Transactions of the Associa-
tion for Computational Linguistics, 1(1):49?62.
Michael S. Bernstein, Greg Little, Robert C. Miller,
Bjo?rn Hartmann, Mark S. Ackerman, David R.
Karger, David Crowell, and Katrina Panovich.
2010. Soylent: a word processor with a crowd in-
side. In Proceedings of ACM Symposium on User
Interface Software and Technology.
1677
S. R. K. Branavan, Harr Chen, Luke S. Zettlemoyer,
and Regina Barzilay. 2009. Reinforcement learning
for mapping instructions to actions. In Proceedings
of ACL.
S. R. K. Branavan, Luke S. Zettlemoyer, and Regina
Barzilay. 2010. Reading between the lines: learn-
ing to map high-level instructions to commands. In
Proceedings of ACL.
S. R. K. Branavan, David Silver, and Regina Barzi-
lay. 2011. Learning to win by reading manuals in
a monte-carlo framework. In Proceedings of ACL.
Asli Celikyilmaz and Dilek Hakkani-Tur. 2012. A
joint model for discovery of aspects in utterances.
In Proceedings of ACL.
Asli Celikyilmaz, Dilek Hakkani-Tu?r, and Gokhan Tu?r.
2011. Mining search query logs for spoken language
understanding. In Proceedings of ICML.
David L. Chen and William B. Dolan. 2011. Collect-
ing highly parallel data for paraphrase evaluation. In
Proceedings of ACL.
David L. Chen and Raymond J. Mooney. 2011. Learn-
ing to interpret natural language navigation instruc-
tions from observations. In Proceedings of AAAI.
Myroslava Dzikovska, Amy Isard, Peter Bell, Jo-
hanna D. Moore, Natalie B. Steinhauser, Gwen-
dolyn E. Campbell, Leanne S. Taylor, Simon Caine,
and Charlie Scott. 2011. Adaptive intelligent tuto-
rial dialogue in the beetle ii system. In Proceedings
of AIED.
Kallirroi Georgila, James Henderson, and Oliver
Lemon. 2005. Learning user simulations for infor-
mation state update dialogue systems. In Proceed-
ings of Eurospeech.
Dilek Hakkani-Tur, Gokhan Tur, Larry Heck, Ashley
Fidler, and Asli Celikyilmaz. 2012. A discrimi-
native classification-based approach to information
state updates for a multi-domain dialog system. In
Proceedings of Interspeech.
Peter Heeman. 2007. Combining Reinforcement
Learning with Information-State Update Rules. In
Proceedings of ACL.
Eric Horvitz, Jack Breese, David Heckerman, David
Hovel, and Koos Rommelse. 1998. The Lumiere
project: Bayesian user modeling for inferring the
goals and needs of software users. In Proceedings
of Uncertainty in Artificial Intelligence.
Nate Kushman, Micah Brodsky, S. R. K. Branavan,
Dina Katabi, Regina Barzilay, and Martin Rinard.
2009. WikiDo. In ACM HotNets.
Cheongjae Lee, Sangkeun Jung, Kyungduk Kim, and
Gary Geunbae Lee. 2009. Automatic agenda graph
construction from human-human dialogs using clus-
tering method. In Proceedings of NAACL.
Xiao Li, Ye-Yi Wang, and Alex Acero. 2008. Learn-
ing query intent from regularized click graphs. In
Proceedings of SIGIR.
Percy Liang, Michael I. Jordan, and Dan Klein. 2009.
Learning semantic correspondences with less super-
vision. In Proceedings of ACL-IJCNLP.
F. Mairesse, M. Gasic, F. Jurcicek, S. Keizer, B. Thom-
son, K. Yu, and S. Young. 2009. Spoken lan-
guage understanding from unaligned data using dis-
criminative classification models. In Proceedings of
Acoustics, Speech and Signal Processing.
Fabrizio Morbini, Eric Forbell, David DeVault, Kenji
Sagae, David R. Traum, and Albert A. Rizzo. 2012.
A mixed-initiative conversational dialogue system
for healthcare. In Proceedings of SIGDIAL.
Jorge Nocedal and Stephen J. Wright. 2000. Numeri-
cal Optimization. Springer.
Patric Pantel, Thomas Lin, and Michael Gamon. 2012.
Mining entity types from query logs via user intent.
In Proceedings of ACL.
Paul Piwek and Svetlana Stoyanchev. 2010. Generat-
ing expository dialogue from monologue: Motiva-
tion, corpus and preliminary rules. In Proceedings
of NAACL.
Paul Piwek and Svetlana Stoyanchev. 2011. Data-
oriented monologue-to-dialogue generation. In Pro-
ceedings of ACL, pages 242?247.
Paul Piwek, Hugo Hernault, Helmut Prendinger, and
Mitsuru Ishizuka. 2007. T2d: Generating dialogues
between virtual agents automatically from text. In
Proceedings of Intelligent Virtual Agents.
Verena Rieser and Oliver Lemon. 2008. Learning ef-
fective multimodal dialogue strategies from wizard-
of-oz data: Bootstrapping and evaluation. In Pro-
ceedings of ACL.
A. Rizzo, Kenji Sagae, E. Forbell, J. Kim, B. Lange,
J. Buckwalter, J. Williams, T. Parsons, P. Kenny,
David R. Traum, J. Difede, and B. Rothbaum. 2011.
Simcoach: An intelligent virtual human system for
providing healthcare information and support. In
Proceedings of ITSEC.
Jost Schatzmann, Karl Weilhammer, Matt Stuttle, and
Steve Young. 2006. A survey of statistical user sim-
ulation techniques for reinforcement-learning of dia-
logue management strategies. Knowledge Engineer-
ing Review, 21(2).
Konrad Scheffler and Steve Young. 2002. Automatic
learning of dialogue strategy using dialogue simula-
tion and reinforcement learning. In Proceedings of
Human Language Technology Research.
Natalie B. Steinhauser, Gwendolyn E. Campbell,
Leanne S. Taylor, Simon Caine, Charlie Scott, My-
roslava Dzikovska, and Johanna D. Moore. 2011.
1678
Talk like an electrician: Student dialogue mimick-
ing behavior in an intelligent tutoring system. In
Proceedings of AIED.
David R. Traum, Priti Aggarwal, Ron Artstein, Susan
Foutz, Jillian Gerten, Athanasios Katsamanis, Anton
Leuski, Dan Noren, and William R. Swartout. 2012.
Ada and grace: Direct interaction with museum vis-
itors. In Proceedings of Intelligent Virtual Agents.
Go?khan Tu?r, Dilek Z. Hakkani-Tu?r, Dustin Hillard, and
Asli C?elikyilmaz. 2011. Towards unsupervised spo-
ken language understanding: Exploiting query click
logs for slot filling. In Proceedings of Interspeech.
Adam Vogel and Dan Jurafsky. 2010. Learning to fol-
low navigational directions. In Proceedings of ACL.
Steve Young. 2010. Cognitive user interfaces. In IEEE
Signal Processing Magazine.
1679
