An Improved Heuristic for Ellipsis Processing* 
Ralph M. Welschedel 
Department of Computer & Information Sciences 
University of Delaware 
Newark, Delaware 19711 
and Norman K. Sondheimer 
Software Research 
Sperry Univac MS 2G3 
Blue Bell, Pennsylvania 19424 
I. In t roduct ion  
Robust  response to e l l ips is  ( f ragmen- 
tary sentences)  is essent ia l  to acceptab le  
natura l  language inter faces.  For in- 
stance, an exper iment  with the REL Engl i sh  
query system showed 10% e l l ip t ica l  input 
(Thompson, 1980). 
In Quirk, et al (1972), three types 
of contextua l  e l l ips is  have been identi -  
fied: 
I. repet i t ion,  if the ut terance  is a 
f ragment  of the prev ious sentence.  
2. rep lacement ,  if the input rep laces  a 
s t ructure  in the previous sentence.  
3. expansion,  if the input adds a new 
type of st ructure to those used in the 
prev ious  sentence.  
Ins tances  of the three types appear  in 
the fo l lowing  example.  
Were you angry? 
a) I was.  
b) Fur ious.  
c) Probably.  
d) For a time. 
e) Very. 
f) I did not want to be. 
g) Yes terday  I was. 
( repet i ion  with 
change in person) 
( rep lacement)  
(expansion)  
(expansion)  
(expansion)  
(expansion)  
(expans ion  & 
repet i t ion)  
In add i t ion  to appear ing  as answers fol- 
lowing quest ions,  any of the three types 
can appear  in quest ions  fo l lowing state- 
ments, s tatements  fo l lowing statements ,  or 
in the ut terances  of a s ingle speaker.  
This paper presents  a method of au- 
tomat ica l ly  in terpret ing  e l l ips is  based on 
d ia logue context.  Our method expands on 
p~evious work by a l lowing for expans ion 
e l l ips is  and by a l lowing for all combina-  
t ions of s tatement fo l lowing quest ion,  
quest ion  fo l lowing statement,  quest ion  
fo l lowing quest ion,  etc. 
*This material is based upon work partially sup- 
ported by the National Science Foundation under 
Grant No. IST-8009673. 
2. Re lated Work 
Severa l  natura l  language systems 
(e.g., Bobrow et al, 1977; Hendr ix  et 
al., 1978; Kwasny  and Sondheimer ,  1979) 
inc lude heur i s t i cs  for rep lacement  and 
repet i t ion  el l ips is ,  but not expans ion  
el l ips is .  One genera l  s t rategy has been 
to subst i tu te  f ragments  into the ana lys is  
of the previous input, e.g., subst i tu t ing  
parse trees of the e l l ip t i ca l  input into 
the parse trees of the prev ious input in 
L IFER (Hendrix,  et al, 1978). This only 
appl ies  to inputs of the same type, e.g., 
repeated quest ions.  
A l len (1979) deals with some examples  
of expans ion  e l l ips is ,  by f i t t ing a parsed 
e l l ip t i ca l  input into a model of the 
speaker ' s  plan. This is s imi lar  to other 
methods that interpret  f ragments  by plac- 
ing them into prepared f ie lds in frames or 
case slots (Schank et al, 1980; Hayes and 
Mouradian,  1980; Waltz, 1978). This ap- 
proach seems most app l i cab le  to l imited-  
domain systems. 
3. The Heur i s t i c  
There are three aspects to our solu- 
tien: a mechan ism for repet i t ion  and 
rep lacement  e l l ips is ,  an extens ion  for 
inputs of d i f ferent  types, such as frag- 
mentary  answers  to quest ions,  and an ex- 
tens ion for expans ion  el l ips is .  
3.1 Repet i t ion  and Rep lacement  
As noted above, repet i t ion  and re- 
p lacement  e l l ips is  can be viewed as sub- 
s t i tu t ion  in the previous form. We have 
implemented this not ion in an augmented  
t rans i t ion  network  (ATN) grammar inter-  
preter  with the assumpt ion  that the "pre- 
vious form" is the complete  ATN path that 
parsed the previous input and that the 
lexical  items consumed along that path are 
assoc iated  with the arcs that consumed 
them. In e l l ips is  mode, the ATN inter-  
preter  executes the path using the e l l ipt -  
ical input in the fo l lowing way: 
85 
I. Words from the e l l ip t ica l  input, 
i.e., the cur ren~ input, may be con- 
sumed along the path at any point. 
2. Any arc requ i r ing  a word not found 
in the current  input may be 
t raversed us ing the lexical  item 
assoc ia ted  with the arc from the 
prev ious input. 
3. However,  once the path consumes the  
f irst word from the e l l ip t i ca l  
input, all words from the e l l ip t i ca l  
input must be consumed before an arc 
can use a word from the prev ious 
input.  
4. T ravers ing  a PUSH arc may be accom ~ 
p l ished ei ther  by fo l low ing  the sub- 
path of the previous input or by 
f ind ing any const i tuent  ef the re- 
qui red type in the current  input. 
The ent ire ATN can be used in these 
cases. 
Suppose that the path for "Were you 
angry?" is given by Table I. Square 
brackets  are used to ind icate subpaths 
resu l t ing  from PUSHes.  "..." ind icates  
tests and act ions  wh ich  are i r re levant  te 
the current  d iscuss ion.  
01d Lexical  
State Arc Item 
S (CAT COPULA ... (TO Sx)) "w--~'r~e" 
Sx (PUSH NP . . .  (TO Sy))  
\[NP (CAT PRO . . .  (TO NPa)) "you" 
NPa (POP ...) \] 
Sy (CAT ADJ ... (TO Sz)) "angry" 
Sz (POP . . . )  
Table I 
An ATN Path for "Were you Angry?"  
An e l l ip t i ca l  input of "Was he?" fol- 
lowing "Were you angry?" could be under-  
steed by t ravers ing  all of the arcs as in 
Table I. Fo l low ing  point I above, "was" 
and "he" would be subst i tuted for "were" 
and "you". Fo l low ing  point 3, in t ravers-  
ing the arc (CAT ADJ ... (TO Sz)) the lex- 
ical item "angry" from the previous input 
would be used. Item 4 is i l lus t rated by 
an e l l ip t i ca l  input of "Was the old man?"; 
this is unders tood  by t ravers ing the arcs 
at the S level of Table I, but using the 
appropr ia te  path in the NP network to 
parse the old man 
3.2 T rans format ions  of the Prev ious Form 
Whi le the approach i l lus t ra ted  in 
Sect ion  3.1 is usefu l  in a data base query 
env i ronment  where ~\ ] l ip t ica l  input typi- 
cal ly is a mod l f i ca t ion  of the prev ious 
query, it does not account for e l l ip t ica l  
s tatements  fo l lowing quest ions,  e l l ip t i ca l  
quest ions  fo l lowing statements ,  etc. Our 
approach to the prob lem is to write a set 
ef t rans format ions  which map the parse 
path of a quest ion  (e.g., Table I) into an 
expected parse path for a dec la ra t ive  
response,  and the parse ~path for a de- 
c larat ive  into a path for an expected 
quest ion,  etc. 
The le f t -hand side of a t rans forma-  
tion is a pat tern  which is matched against  
the ATN path of the previous ut terance.  
Pat tern  e lements  inc lude l i tera ls  refer-  
r ing te arcs, var iab les  which match a sin- 
gle arc or embedded path, var iab les  which 
match zero or mere arcs, and sets ef al- 
ternat ives .  It is s t ra ight fo rward  to con- 
struct  a d i sc r iminat ion  net cor respond ing  
to all le f t -hand sides for e f f i c ient ly  
f ind ing what pat terns  match the ATN path 
of the previous sentence.  The r ight -hand 
side ef a t rans format ion  is a pat tern  
which const ructs  an expected path. The 
form of the pat tern  en the r ight -hand side 
is a l ist of re ferences  to states,  arcs, 
and lexical  entr ies.  Such re ferences  can 
be made through items matched on the 
le f t -hand side or by expl ic i t  const ruct ion  
ef l i tera l  path e lements .  
Our technique is to rest r ic t  the map- 
ping such that any expected parse path is 
generated by app ly ing  only one t rans forma-  
tion and app ly ing it only once. A spec ia l  
feature of our t rans format iona l  system is 
the automat ic  a l lowance  for d ia logue 
diexis. An expected parse path for the 
answer to "Were you angry?" is g iven in 
Table 2. Note in Table 2, "you" has be- 
come "I" and "were" has become "was" 
Old Lex ica l  
State Arc Item 
(PUSH NP ... (TO Sa)) 
(CAT PRO ... (TO NPa)) 
(PoP ...) 
(CAT COPULA . . .  (TO Sy))  
(CAT ADJ ... (TO Sz)) 
(POP . . . )  
S 
\[NP "I" 
NPa \] 
Sa "was " 
Sy "angry" 
Sz 
Table 2 
Dec larat ive  for the expected answer 
for "Were you angry?".  
Us ing this path, the e l l ips is  in terpreter  
de'scribed in Sect ion 3.1 would unders tand 
the e l l ipses in "a)" and "b)" below, in 
the same way as "a')" and "b'i" 
a) I was. 
a') I was angry. 
b) ~y spouse was. 
b') My spouse was angry. 
86 
3.3 Expans ions  
A large class of expans ions  are sim- 
ple adjuncts ,  such as examples c, d, e, 
and g in sect ion  I. We have handled this 
by bu i ld ing  our e l l ips is  in terpreter  to 
a l low depar t ing  from the base path at 
des ignated  states to consume an ad junct  
from the input str ing. We mark states in 
the grammar where ad juncts  can occur. For 
each such state, we l ist a set of l inear  
( though poss ib ly  cycl ic)  paths, cal led 
"expans ion  paths".  Our in terpreter  as 
imp lemented  al lows depar tures  from the 
base path at any state so marked in the 
grammar;  it fo l lows expans ion  paths by 
consuming words from the input str ing, and 
must return to a state on the base form. 
Each of the examples  in c, d, e, and g of 
sect ion  I can be handled by expans ion  
paths only one arc long. They are given 
in Table 3. 
In i t ia l  
State 
Sy 
Expans ion  Path 
(PUSH ADVERB ... (TO S)) 
P robab ly  (I was angry).  
(PUSH PF  . . .  (To s)) 
For a time (I was angry).  
(PUS~ ~P 
(* this inc ludes a teat 
that the NP is one 
of time or place) 
? .. (TO S)) 
Yes terday  (I was angry).  
(PUSH INTENSIF IER-ADVERB 
. . .  (TO Sy) )  
(I was) very (angry).  
Table 3 
Example  Expans ion  Paths 
Since this is an extens ion  to the e l l ips is  
in terpreter ,  combinat ions  of repet i t ion,  
rep lacement ,  and expans ion  can all be han- 
dled by the one mechanism.  For instance,  
in response to "Were you angry?",  "Yester-  
day you were (angry)" would be treated 
us ing the expans ion  and rep lacement  
mechan isms.  
~. Spec ia l  Cases and L imi ta t ions  
The ideal model  of contextua l  el- 
l ipsis would cor rect ly  predict  what are 
appropr ia te  e l l ip t i ca l  forms in context,  
what their  in terpreta t ion  is, and what 
forms are not mean ingfu l  in context .  We 
bel ieve this requires  s t ructura l  restr ic -  
tions, semant ic  constra ints ,  and a model 
of the goals of the speaker.  Our heur is-  
tic does not meet these cr i ter ia  in a 
number of cases. 
Only two c lasses of s t ruc tura l  con- 
s t ra ints  are captured.  One re lates the 
e l l ips is  to the prev ious  form as a combi-  
nat ion  of repet i t ion ,  rep lacement ,  and 
expans ion.  The o~her const ra in t  is that 
the input must be consumed as a cont iguous  
str ing. This const ra in t  is v io lated,  for 
instance,  in "I was (angry) yes terday"  as 
a response to "Were you angry?"  
Never the less ,  the const ra in t  is computa-  
t iona l ly  useful ,  s ince a l low ing  arb i t ra ry  
gaps in consuming  the e l l ip t i ca l  input 
produces  a very large space of cor rect  
in terpreta t ions .  A lud icrous  example is 
the fo l lowing quest ion  and e l l ip t i ca l  
response:  
Has the boss given our mutual  fr iend a 
raise? 
A fat raise. 
A l low ing  arb i t ra ry  gaps between the sub- 
str ings of the e l l ips is  a l lows an in- 
te rpreta t ion  such as "A (boss has given 
our) fat ( fr iend a) raise."  
Whi le it may be poss ib le  to v iew all 
contextua l  e l l ips is  as combinat ions  of the 
operat ions  repet i t ion,  rep lacement ,  and 
expans ion  appl ied  to something,  our model  
makes the strong assumpt ion  that these 
operat ions  may be viewed as app ly ing  to an 
ATN path rather s t ra ight fo rward ly  re lated 
to the prev ious  ut terance.  Not all expan- 
s ions can be viewed that way, as example f 
in Sect ion  I i l lus t rates .  Also, answers  
of "No" require specia l  process ing;  that 
response in answer  to "Were you angry" 
should not be in terpreted  as "No, I was 
angry."  One should be able to account  for 
such examples  wi th in  the heur i s t i c  
descr ibed  in this paper, perhaps by a l low-  
ing the t rans format ion  system descr ibed in 
sect ion  3.2 to be complete ly  genera l  rath- 
er than st rongly  res t r i c ted  to one and 
only one t rans format ion  app l i cat ion .  Row- 
ever, we propose hand l ing  such cases by 
spec ia l  purpose rules we are deve lop ing .  
These rules for the spec ia l  cases, plus 
the mechan ism descr ibed in sect ion 3 to- 
gether  wil l  be formal ly  equ iva lent  in 
p red ic t ive  power to a grammar  for e l l ip t i -  
cal forms. 
Though the heur i s t i c  is independent  
of the ind iv idua l  grammar,  des ignat ing  
expans ion  paths and t rans format ions  obvi- 
ously is not. The grammar  may make this 
an easy oz" d i f f i cu l t  task. For instance 
in the grammar we are using, a subnetwork  
that co l lects  all tense, aspect,  and mo- 
dal i ty  e lements  would s impl i fy  some of the 
t rans format ions  and expans ion  paths. 
~atura l ly ,  semant ics  must play an 
important  part in e l l ips is  process ing.  
Cons ider  the ut terance pair below: 
87 
Did the bess have a martini  at lunch? 
Some wine. 
Though syntact ical ly  this could be inter- 
preted either as "Some wine (did have a 
martini  at lunch)", "(The boss did have) 
some wine (at lunch)", or "(The boss did 
have a martini  at) some wine". Semantics 
should prefer the second reading. We are 
testing our heurist ic using the RUS gram- 
mar (Bebrow, 1978) which has frequent 
calls from the grammar requesting that the 
semantic component decide whether to build 
a semantic interpretat ion for the partial  
parse found or to veto that partial parse. 
This should aid performance. 
~. Summary and Conclusion 
There are three aspects te our 
solution: a mechanism for repetit ion and 
replacement ell ipsis, an extension for 
inputs of different types, such as frag- 
mentary answers to questions, and an ex- 
tension for expansion ell ipsis. 
Our heurist ic deals with the three 
types of expansion ell ipsis as follows: 
Repet i t ion el l ipsis is processed by re- 
peating specific parts of a transformed 
previous path using the same phrases as in 
the transformed form ("I was angry"). 
Replacement ell ipsis is processed by sub- 
st ituting the el l ipt ical  input for contig- 
uous const ituents on a transformed previ- 
ous path. Expansion ell ipsis may be pro- 
cessed by taking special ly marked paths 
that detour from a given state in that 
path. Combinat ions of the three types of 
el l ipsis are represented by combinat ions 
of the three var iat ions in a transformed 
previous path. 
There are two contr ibut ions of the 
work. First, our method allows for expan- 
sion ell ipsis. Second, it accounts for 
combinat ions of previous sentence form and 
ell ided form, e.g., statement fol lowing 
question, question fol lowing statement, 
question fol lowing question. Furthermore, 
the method works without any constraints 
on the ATN grammar. The heurist ics carry 
over to formalisms similar to the ATN, 
such as context-free grammars and augment- 
ed phrase structure grammars. 
Our study of ell ipsis is part of a 
much broader framework we are developing 
for processing syntact ical ly  and/or 
semantical ly i l l - formed input; see 
Weischedel and Sondheimer (1981). 
References 
Allen, James F., "A Plan-Based Approach to 
Speech Act Recognit ion,"  Ph.D. Thesis, 
Dept. of 'Computer Science, Univers i ty  of 
Toronto, Toronto, Canada, 1979. 
Bobrew, D., R. Kaplan, M. Kay, D. Norman, 
H. Thompson and T. Winograd, "GUS, A 
Frame-dr iven Dialog System", Art i f ic ia l  
Intel l igence, 8, (1977), 155-173. 
Bobrow, R., "The RUS System", in Research 
in Natural  Language Understandin$,  by B. 
Webber and R. Bobrow, BBN Report No. 3878, 
Belt Beranek and Newman, Inc., Cambridge, 
MA, 1978. 
Hayes, P. and G. Mouradian, "Flexible 
Parsing", in Proc. of the 18th Annual 
Meet in~ of the Assoc. for Cemp. Ling., 
Phi ladelphia,  June, 1980, 97-103. 
Hendrix, G., E. Sacerdoti,  D. Sagalowicz 
and J. Slocum, "Developing a Natural 
Language Interface to Complex Data", ACM 
Trans. on Database S~s., 3, 2, (1978--~, 
105-147. 
Kwasny, S. and N. Sondheimer, "Ungrammati-  
cality and Extragrammat ica l i ty  in Natural  
Language Understanding Systems", in Proc. 
ef the 17th Annual Meeting of the Assoc. 
for Comp. Lin~., San Diego, August, 1979, 
19-23. 
Quirk, R., S. Greenbaum, G. Leech and J. 
Svartvik, A Grammar of Centempory English, 
Seminar Press, New York, 1972. 
Schank, R., M. Lebowitz and L. Birnbaum, 
"An Integrated Understander",  American 
Journal of Comp. Ling., 6, I, (1980), 
13-30. 
Thompson, B. H., "Linguist ic Analysis of' 
Natural  Language Communicat ion with Com- 
puters", p~'oceedings o f  the Eighth 
International  Conference on Computat ionai  
Linguist ics, Tokyo, October, 1980, 
190-201. 
Waltz, D., "An English Language Quest ion 
Answering System for a Large Relat ional  
Database", Csmm. ACM, 21, 7, (1978), 
526-559. 
Weischedel,  Ralph M. and Norman K. Son- 
dheimer, "A Framework for Processing Ill- 
Formed Input", Technical  Report, Dept. of 
Computer & Informatiou Sciences, Universi -  
ty of Delaware, Ne~ark, DE, 1981. 
Acknowledgement 
~luch credit is due to Amir Razi for 
his programming assistance. 
88 
