Elaborating a Knowledge Base for Deep Lexical Semantics
Niloofar Montazeri and Jerry R. Hobbs
Information Sciences Institute
University of Southern California
Marina del Rey, California
Abstract
We describe the methodology for constructing axioms defining event-related words, anchored
in core theories of change of state and causality. We first derive from WordNet senses a smaller
set of abstract, general ?supersenses?. We encode axioms for these, and we test them on textual
entailment pairs. We look at two specific examples in detail to illustrate both the power of the
method and the holes in the knowledge base that it exposes. Then we address the problem of holes
more systematically, asking, for example, what kinds of ?pairwise interactions? are possible for core
theory predicates like change and cause.1
1 Introduction
From the sentence
Russia is blocking oil from entering Ukraine.
we would like to be able to conclude
Oil can not be delivered to Ukraine.
But doing this requires fairly complex inference, because the words ?block?, ?enter?, ?can?, ?not? and
?deliver? carve up the world in different ways. Our approach is to define words such as these by means
of axioms that link with underlying core theories2 explicating such very basic concepts as change of
state and causality. Given the logical form of sentences like these two, we apply these axioms to express
the meaning of the sentences in more fundamental predicates, and do a certain amount of defeasible
reasoning in the core theories to determine that the second follows from the first.
More generally, we are engaged in an enterprise we call ?deep lexical semantics? (Hobbs, 2008), in
which we develop various core theories of fundamental commonsense phenomena and define English
word senses by means of axioms using predicates explicated in these theories. Among the core theories
are cognition, microsociology, and the structure of events. The last of these is the focus of this paper. We
use textual entailment pairs like the above to test out subsets of related axioms. This process enforces a
1This research was supported in part by the Defense Advanced Research Projects Agency (DARPA) Machine Reading
Program under Air Force Research Laboratory (AFRL) prime contract no. FA8750-09-C-0172, and in part by the Office of
Naval Research under contract no. N00014-09-1-1029.. Any opinions, findings, and conclusion or recommendations expressed
in this material are those of the author(s) and do not necessarily reflect the view of the DARPA, AFRL, ONR, or the US
government.
2http://www.isi.edu/ hobbs/csk.html.
195
uniformity in the way axioms are constructed, and also exposes missing inferences in the core theories.
The latter is a major issue in this paper.
In Section 2 we describe three aspects of the framework we are working in?the logical form we
use, abductive interpretation and defeasibility, and the core theories of change of state and causality. In
Section 3 we describe the methodology we use for constructing axioms, deriving from WordNet senses
a smaller set of abstract, general ?supersenses?, encoding axioms for these, and testing them on textual
entailment pairs. In Section 4 we look at two specific examples to illustrate both the power of the method
and the holes in the knowledge base that it exposes. In Section 5 we address the problem of holes more
systematically, specifically asking, for example, what kinds of ?pairwise interactions? are possible for
core theory predicates like change and cause.
2 Framework
We use a logical notation in which states and events (eventualities) are reified. Specifically, if the ex-
pression (p x) says that p is true of x, then (p? e x) says that e is the eventuality of p being true
of x. Eventuality e may exist in the real world (Rexist), in which case (p x) holds, or it may only
exist in some modal context, in which case that is expressed simply as another property of the possible
individual e. (In this paper we use a subset of Common Logic3 for the syntax of our notation.)
The logical form of a sentence is a flat conjunction of existentially quantified postive literals, with
about one literal per morpheme. (For example, logical words like ?not? and ?or? are treated as expressing
predications about possible eventualities.) We have developed software4 to translate Penn TreeBank-style
trees (as well as other syntactic formalisms) into this notation. The underlying core theories are expressed
as axioms in this notation (Hobbs, 1985).
The interpretation of a text is taken to be the lowest-cost abductive proof of the logical form of
the text, given the knowledge base. That is, to interpret a text we prove the logical form, allowing for
assumptions at cost, and pick the lowest-cost proof. Factors involved in computing costs include, besides
the number of assumptions, the salience of axioms, the plausibility of axioms expressing defeasible
knowledge, and consiliance or the degree to which the pervasive implicit redundancy of natural language
texts is exploited. We have demonstrated that many interpretation problems are solved as a by-product
of finding the lowest-cost proof. This method has been implemented in an abductive theorem-prover
called Mini-Tacitus5 that has been used in a number of applications (Hobbs et al, 1993; Mulkar et al,
2007), and is used in the textual entailment problems described here. We are also working toward a
probabilistic semantics for the cost of proofs (Blythe et al, 2011). Abductive interpretation accounts for
script-like understanding of text?a script predicate provides the most economical interpretation (Hobbs
et al, 1993)?but also enables interpretation of novel texts.
Most commonsense knowledge is defeasible, i.e., it can be defeated. This is represented in our
framework by having a unique ?et cetera? proposition in the antecedent of Horn clauses that cannot be
proved but can be assumed at a cost corresponding to the likeliehood that the conclusion is true. For
example, the axiom
(forall (x) (if (and (bird x)(etc-i x))(fly x)))
would say that if x is a bird and other unspecified conditions hold, (etc-i), then x flies. No other
axioms enable proving (etc-i x), but it can be assumed, and hence participate in the lowest cost
3http://common-logic.org/.
4http://www.rutumulkar.com/download/NL-Pipeline/NL-Pipeline.php.
5http://rutumulkar.com/download/TACITUS/tacitus.php.
196
proof. The index i is unique to this axiom. In this paper rather than invent new indices for each axiom, we
will use the abbreviation (etc) to indicate the defeasibility of the rule. (This approach to defeasibility
is similar to circumscription (McCarthy, 1980).)
We have articulated a number of core theories6. The two most relevant to this paper are the theory
of change of state and the theory of causality. The predication (change? e e1 e2) says that e is
a change of state whose initial state is e1 and whose final state is e2. The chief properties of change
are that there is some entity whose state is undergoing change, that change is defeasibly transitive,
that e1 and e2 cannot be the same unless there has been an intermediate state that is different, and that
change is consistent with the before relation from our core theory of time. Since many lexical items
focus only on the initial or the final state of a change, we introduce for convenience the predications
(changeFrom? e e1) and (changeTo? e e2), defined in terms of change.
The chief distinction in our core theory of causality is between the notions of causalComplex and
cause. A causal complex includes all the states and events that have to happen or hold in order for the
effect to happen. A cause is that contextually relevant element of the causal complex that is somehow
central to the effect, whether because it is an action the agent performs, because it is not normally true,
or for some other reason. Most of our knowledge about causality is expressed in terms of the predicate
cause, rather than in terms of causal complexes, because we rarely if ever know the complete causal
complex. Typically planning, explanation, and the interpretation of texts (though not diagnosis) involves
reasoning about cause. Among the principal properties of cause are that it is defeasibly transitive,
that events defeasibly have causes, and that cause is consistent with before.
We also have a core theory of time, and the times of states and events can be represented as temporal
properties of the reified eventualities. The theory of time has an essential function in axioms for words
explicitly referencing time, such as ?schedule? and ?delay?. But for most of the words we are explicating
in this effort, we base our approach to the dynamic aspects of the world on the cognitively more basic
theory of change of state. For example, the word ?enter? is axiomatized as a change of state from being
outside to being inside, and the fact that being outside comes before being inside follows from the axiom
relating the predicates change and before.
We find that reifying states and events as eventualities and treating them as first-class individuals is
preferable to employing the event calculus (Gruninger and Menzel, 2010; Mueller, 2006) which makes a
sharp distinction between the two, because language makes no distinction in where they can appear and
we can give them a uniform treatment.
3 Methodology
Our methodology consists of three steps.
1. Analyzing the structure of a word?s WordNet senses.
2. Writing axioms for the most general senses
3. Testing the axioms on textual entailment pairs.
Our focus in this paper is on words involving the concepts of change of state and causality, or event
words, such as ?block?, ?delay?, ?deliver?, ?destroy?, ?enter?, ?escape?, ?give?, ?hit?, ?manage?, and
?provide?. For each word, we analyze the structure of its WordNet senses. Typically, there will be pairs
that differ only in, for example, constraints on their arguments or in that one is inchoative and the other
6http://www.isi.edu/ hobbs/csk.html.
197
causative. This analysis generally leads to a radial structure indicating how one sense leads by incre-
ments, logically and perhaps chronologically, to another word sense (Lakoff, 1987). The analysis also
leads us to posit ?supersenses? that cover two or more WordNet senses. (Frequently, these supersenses
correspond to senses in FrameNet (Baker et al, 2003) or VerbNet (Kipper et al, 2006), which tend to be
coarser grained; sometimes the desired senses are in WordNet itself.)
For example, for the verb ?enter?, three WordNet senses involve a change into a state:
V2: become a participant
V4: play a part in
V9: set out on an enterprise
Call this supersense S1. Two other senses add a causal role to this:
V5: make a record of
V8: put or introduce into something
Two more senses specialize supersense S1 by restricting the target state to be in a physical location:
V1: come or go into
V6: come on stage
One other sense specializes S1 by restricting the target state to be membership in a group.
V3: register formally as a participant or member
Knowing this radial structure of the senses helps enforce uniformity in the construction of the axioms. If
the senses are close, their axioms should be almost the same.
We are currently only constructing axioms for the most general or abstract senses or supersenses.
In this way, although we are missing some of the implications of the more specialized senses, we are
capturing the most basic topological structure in the meanings of the words. Moreover, the specialized
senses usually tap into some specialized domain that needs to be axiomatized before the axioms for these
senses can be written.
In constructing the axioms in the event domain, we are very much informed by the long tradition of
work on lexical decomposition in linguistics (e.g., Gruber, 1965; Jackendoff, 1972). Our work differs
from this in that our decompositions are done as logical inferences and not as tree transformations as in
the earliest linguistic work, they are not obligatory but only inferences that may or may not be part of the
lowest-cost abductive proof, and the ?primitives? into which we decompose the words are explicated in
theories that enable reasoning about the concepts.
Figure 1 shows the radial structure of the senses for the word ?enter?, together with the axioms that
characterize each sense. A link between two word senses means an incremental change in the axiom for
one gives the axiom for the other. For example, the axiom for enter-S2 says that if x1 enters x2 in
x3, then x1 causes a change to the eventuality i1 in which x2 is in x3; and the expanded axiom for
enter-S1.1 states that if x1 enters x2, then there is a change to a state e1 in which x1 is in x2. So
enter-S2 and enter-S1.1 are closely related and thus linked together.
Abstraction is a special incremental change where one sense S1.1 specializes another sense S1 ei-
ther by adding more predicates to or specializing some of the predicates in S1?s axiom. We represent
abstractions via arrows pointing from the subsenses to the supersenses. In Figure 1, enter-S1.1 and
enter-S1.2 both specialize enter-S1. The predicate enter-S1.1 adds an extra predicate de-
scribing e1 as an in eventuality and enter-S1.2 specializes e1 to membership in x2, where x2 is a
group.
198
Figure 1: Senses of and axioms for the verb ?enter?
The supersenses capture the basic topology of the senses they subsume. The extra information that
the subsenses convey are typically the types and properties of the arguments, such as being a place or a
process, or qualities of the causing event, such as being sudden or forceful.
For each set of inferentially related words we construct textual entailment pairs, where the hypothesis
(H) intuitively follows from text (T), and use these for testing and evaluation. The person writing the
axioms does not know what the pairs are, and the person constructing the pairs does not know what the
axioms look like.
The ideal test then is whether given a knowledge base K consisting of all the axioms, H cannot be
proven from K alone, but H can be proven from the union of K and the best intepretation of T. This is
often too stringent a condition, since H may contain irrelevant material that doesn?t follow from T, so an
alternative is to determine whether the lowest cost abductive proof of H given K plus T is substantially
lower than the lowest cost abductive proof of H given K alone, where ?substantially lower? is defined by
a threshold that can be trained (Ovchinnikova et al, 2011).
4 Two Examples
Here we work through two examples to illustrate how textual entailment problems are handled in our
framework. In these examples, given a text T and a hypothesis H, we ask if H can be proven from T,
perhaps with a small number of low-cost assumptions.
Because the examples we deal with involve a great deal of embedding, we need to use the primed
predicates, keeping the eventuality arguments explicit.
We also assume in these examples that lexical disambiguation has been done correctly. With more
context, lexical disambiguation should fall out of the best interpretation, but it is unreasonable to ex-
pect that in these short examples. In practice we run the examples both with disambiguated and with
nondisambiguated predicates.
In these examples we do not show the costs, although they are used by our system.
The first example is the pair
T: Russia is blocking oil from entering Ukraine.
H: Oil cannot be delivered to Ukraine.
199
The relevant part of the logical form of the text is
(and (block-V3? b1 x1 e1)(enter-S2? e1 o1 u1))
That is, there is a blocking event b1 in which Russia x1 blocks eventuality e1 from occurring, and e1 is
the eventuality of oil o1 entering Ukraine u1. The -V3 on block indicates that it is the third WordNet
sense of the verb ?block? and the -S2 suffix on enter indicates that it is the second supersense of
?enter?.
The relevant part of the logical form of the hypothesis is
(and (not? n2 c2) (can-S1? c2 x2 d2) (deliver-S2? d2 x2 o2 u2))
That is, n2 is the eventuality that c2 is not the case, where c2 is some x2?s being able to do d2, where
d2 is x2?s delivering oil o2 to Ukraine u2. Note that we don?t know yet that the oil and Ukraine in the
two sentences are coreferential.
The axiom relating the third verb sense of ?block? to the underlying core theories is
AX4: (forall (c1 x1 e1)
(if (block-V3? c1 x1 e1)
(exist (n1 p1)
(and (cause? c1 x1 n1)(not? n1 p1)(possible? p1 e1)))))
This rule says that for x1 to block some eventuality e1 is for x1 to cause e1 not to be possible. (In this
example, for expositional simplicity, we have allowed the eventuality c1 of blocking be the same as the
eventuality of causing, where properly they should be closely related but not identical.)
The other axioms needed in this example are
AX1: (forall (c1 e1)
(if (and (possible? c1 e1)(etc))
(exist (x1)(can-S1? c1 x1 e1))))
AX2: (forall (d1 x1 c1 r1 x2 x3)
(if (and (cause? d1 x1 c1)(changeTo? c1 r1)(rel? r1 x2 x3)
(deliver-S2? d1 x1 x2 x3))))
AX3: (forall (c1 x1 x2)
(if (enter-S2? c1 x1 x2)
(exist (i1)(and changeTo? c1 i1)(in? i1 x1 x2))))
AX1 says that defeasibly, if an eventuality e1 is possible, then someone can do it. AX2 says that if x1
causes a change to a situation r1 in which x2 in in some relation to x3, then in a very general sense
(S2), x1 has delivered x2 to x3. AX3 says that if c1 is the eventuality of x1 entering x2, then c1 is
the change into a state i1 in which x1 is in x2.
Starting with the logical form of H as the initial interpretation and applying axioms AX1 and AX2,
we get interpretation H1:
H1: (and (not? n2 c2) (possible? c2 d2) (cause? d2 x2 c1)
(changeTo? c1 r1)(rel? r1 o2 u2))
At this point we are stuck in our effort to back-chain to T. An axiom is missing, namely, one that says
that ?in? is a relation between two entities.
AX5: (forall (r x1 x2) (if (in? r1 x1 x2)(rel? r1 x1 x2)))
Using AX5, we can back-chain from H1 and derive interpretation H2:
H2: (and (not? n2 c2)(possible? c2 d2)(cause? d2 x2 c1)
(changeTo? c1 r1)(in? r1 o2 u2))
We can then further back-chain with AX3 to interpretation H3:
200
H3: (and (not? n2 c2)(possible? c2 d2)(cause? d2 x2 c1)
(enter-S2? c1 o2 u2))
Again, we need a missing axiom, AX6, to get closer to the logical form of T:
AX6: (forall (p e1)
(if (and (possible? p,e1)(etc))
(exist (c x1) (and (possible? p c)(cause? c x1 e1)))))
That is, if something is possible, it is possible for something to cause it. Using this axiom, we can derive
H4: (and (not? n2 c2)(possible? c2 c1)(enter-S2? c1 o2 u2))
The final missing axiom, AX7, says that if x1 causes eventuality c2 not to occur, then c2 doesn?t occur.
AX7: (forall (n x1 n1 c2)
(if (and (cause? n x1 n1)(not? n1 c2))( not? n c2)))
Using this we derive interpretation H5.
H5: (and (cause? n2 x3 n)(not? n c2)(possible? c2 c1)(enter-S2? c1 o2 u2))
We can now apply the rule for ?block?, identifying b1 and n2, x1 and x3, e1 and c1, o1 and o2, and
u1 and u2, yielding H6 and establishing the entailment relation between H and T.
H6: (and (block-V3? n2 x3 c1)(enter-S2? c1 o2 u2))
Our second example is the text-hypothesis pair
T: The plane managed to escape the attack.
H: The plane was not captured.
The relevant parts of the logical forms of T and H are as follows:
T: (and (manage-V1? m1 p1 e1)(escape-S1? e1 p1 a1))
H: (and (not? n2 c2)(capture-S1? c2 x2 p2))
The axioms relating these words to the core theories are as follows:
AX1: (forall (cp c x2 n chf a y1 x3 y0 x2)
(if (and (changeTo? cp c)(cause? c x2 n)(not? n chf)
(changeFrom? chf a)(at? a y1 x3)(arg? y0 x2))
(capture? cp y0 y1)))
AX2: (forall (es x0 x1)
(if (escape? es x0 x1)
(exist (ch a)
(and (cause? es x0 ch)(changeFrom? ch a)(at? a x0 x1)))))
AX3: (forall (m y0 e1)
(if (manage? m y0 e1) (Rexist (m e1))))
201
The first says that a change to a situation in which x2 is causing y1 not to change location is a capturing
by some y0 of y1. The second says that escaping implies causing a change from being at a location.
The third says that if you manage to do e1, then e1 occurs.
Using these axioms, we would like to establish the entailment relation from T to H. However, in
order for this reasoning to go through, we need several more axioms?saying that if an eventuality does
not hold, there has been no change to that eventuality, and nothing has caused it to occur; that double
negation cancels out; and that if something is caused, it occurs.
It may seem at first blush that any new text-hypothesis pair will reveal new axioms that must be
encoded, and that therefore it is hopeless ever to achieve completeness in the theories. But a closer
examination reveals that the missing axioms all involve relations among the most fundamental predicates,
like cause, change, not, and possible. These are axioms that should be a part of the core theories
of change and causality. They are not a random collection of facts, any one of which may turn out to
be necessary for any given example. Rather we can investigate the possibilities systematically. That
investigation is what we describe in the following section.
5 Relations among Fundamental Predicates
For completeness in the core theories, we need to look at pairs of fundamental predicates and ask what re-
lations hold between them, what their composition yields, and for each such axiom whether it is defeasi-
ble or indefeasible. The predicates we consider are possible, Rexist, not, cause, changeFrom,
and changeTo.
The first type of axiom formulates the relationship between two predicates. For example, the rule
relating cause and Rexist is
(forall (x e) (if (cause x e)(Rexist e)))
That is, if something is caused, then it actually occurs. Other rules of this type are as follows:
(forall (x e) (if (Rexist e)(possible e)))
(forall (e) (if (and (Rexist e)(etc))(exist (x)(cause x e))))
(forall (e2)
(if (changeTo e2)
(exist (e1)(and (changeFrom e1)(not? e1 e2)))))
(forall (e1)
(if (changeFrom e1)
(exist (e2)(and (changeTo e2)(not? e2 e1)))))
(forall (e) (if (changeTo e)(Rexist e)))
(forall (e) (if (changeFrom e)(not e)))
(forall (e) (if (and (Rexist e)(etc))(changeTo e)))
That is, if something occurs, it is possible and, defeasibly, something causes it. If there is a change to
some state obtaining, then there is a change from its not obtaining, and vice versa. If there is a change
to something, then it obtains, and if there is a change from something, then it no longer obtains. If some
state obtains, then defeasibly there was a change from something else to that state obtaining.
The second type of axiom involves the composition of predicates, and gives us rules of the form
202
(forall (e1 e2 x) (if (and (p? e1 e2)(q? e2 x)) (r? e1 x)))
That is, when p is applied to q, what relation r do we get?
Figure 2 shows the axioms encoding these compositions. The rows correspond to the (p? e1
e2)?s and the columns correspond to the (q? e2 x)?s, and the cell contains the consequents (r? e1
x). If the rule is defeasible, the cell indicates that by adding (etc) to the antecedent. The consequents
in italics are derivable from other rules.
Figure 2: Axioms expressing compositions of fundamental predicates
For example, in the possible-possible cell, the rule says that if it is possible that something
is possible, then it is possible. To take a more complex example, the changeFrom-cause cell says
that if there is a change from some entity causing (or maintaining) a state, then defeasibly there will be a
change from that state. So if a glass is released, it will fall.
We have also looked at axioms whose pattern is the converse of those in Figure 2. For example, if
something does not hold, then it was not caused. Many of the axioms used in the examples are of this
sort.
6 Conclusion
If we are ever to have sophisticated natural language understanding, our systems will have to be able to
draw inferences like the ones illustrated here, and therefore they will need axioms of this complexity or
something equivalent. Because of their complexity, we cannot expect to be able to acquire the axioms
automatically by statistical methods. But that does not mean the situation is bleak. We have shown in
this paper that there is a systematic methodology for developing axioms characterizing the meanings of
words in a way that enforces uniformity and for elaborating the core theories these axioms are anchored
in. Doing this for several thousand of the most common words in English would produce a huge gain in
the inferential power of our systems, as illustrated by the textual entailment examples in this paper, and
would be an enterprise no greater in scope than the manual construction of other widely used resources
such as WordNet and FrameNet.
203
References
[1] Baker, C., Fillmore, C., Cronin, B.: The Structure of the Framenet Database, International Journal of Lexi-
cography, Volume 16.3: (2003) 281-296.
[2] J. Blythe, J. Hobbs, P. Domingos, R. Kate, and R. Mooney, 2011. ?Implementing Weighted Abduction in
Markov Logic?, Proceedings of the 9th International Conference on Computational Semantics, Oxford,
United Kingdom.
[3] Gruber, Jeffrey C., 1965. Studies in Lexical Relations, unpublished Ph.D. dissertation, Massachusetts Institute
of Technology, Cambridge, Massachusetts.
[4] Gruninger, Michael, and Christopher Menzel, 2010. ?The Process Specification Language (PSL) Theory and
Applications?, AI Magazine, Vol 24, No 3.
[5] Hobbs, Jerry R. 1985. ?Ontological Promiscuity.? Proceedings, 23rd Annual Meeting of the Association for
Computational Linguistics, pp. 61-69. Chicago, Illinois, July 1985.
[6] Hobbs, Jerry R., 2008. ?Deep Lexical Semantics?, Proceedings, 9th International Conference on Intelligent
Text Processing and Computational Linguistics (CICLing-2008), Haifa, Israel, February 2008.
[7] Hobbs, Jerry R., Mark Stickel, Douglas Appelt, and Paul Martin, 1993. ?Interpretation as Abduction?, Arti-
ficial Intelligence, Vol. 63, Nos. 1-2, pp. 69-142.
[8] Jackendoff, Ray S. 1972. Semantic interpretation in generative grammar. Cambridge, MA: The MIT Press.
[9] Kipper, Karin, Anna Korhonen, Neville Ryant, and Martha Palmer (2006) Extensive Classifications of En-
glish verbs. Proceedings, 12th EURALEX International Congress. Turin, Italy. September, 2006.
[10] Lakoff, George, 1987. Women, Fire, and Dangerous Things: What Categories Reveal About the Mind, Uni-
versity of Chicago Press, Chicago.
[11] McCarthy, John, 1980. ?Circumscription: A Form of Nonmonotonic Reasoning?, Artificial Intelligence, 13:
27-39.
[12] Mueller, Erik T., 2006. Commonsense Reasoning, Morgan Kaufmann Publishers, Inc., San Mateo, California.
[13] R. Mulkar, J.R. Hobbs, and E. Hovy, 2007. ?Learning from Reading Syntactically Complex Biology Texts?,
Proceedings of the AAAI Spring Symposium Commonsense?07. Stanford University, CA, 2007.
[14] E. Ovchinnikova, N. Montazeri, T. Alexandrov, J. Hobbs, M. McCord, and R. Mulkar-Mehta, 2011. ?Abduc-
tive Reasoning with a Large Knowledge Base for Discourse Processing?, Proceedings of the 9th International
Conference on Computational Semantics, Oxford, United Kingdom.
204
