WHY HUMAN TRANSLATORS STILL SLEEP IN PEACE? ~FOUR ENGINEERING AND LINGUISTIC GAPS IN NI.P~ 
Paola Velardi 
I s t i tu to  d' Informatica, via Brecce Bianche, Ancona, I ta ly 
ABSTRACT 
Because they wilt keep their job quite for a few. 
l h i s  paper has been inspired by a recent ed i to r ia l  
on the Financial  Times, that gives a discouraging 
overview of commercial natura l  Language processing 
systems (~the computer that  can sustain a natural  
language conversat ion . . ,  is un l i ke ly  to ex is t  for  
several decades') .  Computational L inguists are 
not so much concerned with app l icat ions  but 
computer sc ient i s ts  have the u l t imate  ob ject ive  to 
bu i ld  systems that  can ' increase the 
acceptab i l i ty  of computers in everyday 
s i tuat ions . '  Eventual ly ,  l i ngu is ts  as well  would 
pro f i t  by a s ign i f i cant  break-through in natural  
L~ulguage processing. 
This paper is a b r ie f  d i sser ta t ion  on four 
erlgineering and l ingu is t i c  issues we bel ieve 
c r i t i ca l  for  a more s t r i k ing  success of NLP: 
extensive acqu is i t ion  of the semantic lexicon,  
formal performance eva luat ion  methods to evaluate 
systems, development of shel l  systems for  rapid 
prototyping and customizat ion,  and f ina l ly  a more 
linguistically motivated approach to word 
categor i za t ion .  
THE ENTANGLED FOREST 
In the last decade, formal methods to express 
syntact ic  and semantic knowledge (whether in an 
integrated fashion or not) ,  p ro l i fe ra ted  to form 
an entangled fo res t .  New comers seem to prefer  
invent ing a brand-new method, or at least a 
brand-new name, rather  than t ry ing  to make sense 
of the dozens of . . . . . . . .  * -un i f i ca t ion -G 
* -~. ' i~ ,  etc.  Semantic languages are 
re la t ive ly  fewer, but even fewer are the corr~only 
agr'eed pr inc ip ia  about the type and qua l i ty  of 
language phenomena to be expressed. 
Different are also the perspectives under which 
linguists and computer scientists proceed in their 
work: 
Linguists  and psychologists are concerned with the 
nature of human communication, and use the 
computer as a tool  to model very spec i f i c ,  and 
yet meaningful aspects of language. To them, any 
phenomenon is worth to bee Looked at ,  no matter 
how frequent, because the focus in on humans, not 
on computes. 
Computer sc ient i s ts  are interested in bu i ld ing  
computer programs that can u l t imate ly  be useful in 
some relevant f ie ld  of social l i f e ,  as machine 
t rans la t ion ,  informat ion re t r ieva l ,  tu tor ing ,  etc. 
In order for a NLP system to be successful,  i t  
must cover the major i ty  of language phenomena that  
are prominent to a given app l i ca t ion .  Coverage 
here is a primary demand, because the focus is on 
the use of computers, not on the modeling of mind. 
I believe that failing to state clearly these 
differences has been a source of misunderstanding 
and scarce cooperation. Recently Jacobs pointed 
out (Jacobs 1989) that Linguists measure the power 
of a parser against pathological cases, and this 
very fact 'has been damaging to natural language 
processing as a field'. Linguists may as well 
comgtain that the proliferation of NLP papers 
listing in detail the computational features of 
'THE SYSTEM X' and claiming some 5% better 
performances, has been damaging to computational 
linguistics as a field. 
The author of th is  paper does not consider her 
past (and current)  work untouched by these 
c r i t i c i sms ,  but wishes that some more exp l i c i t  and 
general re - th ink ing  be shared by the computational 
l ingu is t i cs  + natural  language processing 
community. This paper was inspired by a recent 
ed i to r ia l  on the Financial  Times (Cookson 1989) 
that presents an overview of commercial and 
research systems based on NLP technology. The 
panorama of commercial systems is quite 
discouraging: the editorial is spread with such 
sentences as 'not yet robust enough' 'their 
grammatical coverage is modest' 'no computer has 
the background knowledge to resolve enough., 
383 
l i ngu is t i c  ambiguit ies '  and concludes: 'the 
computer that can sustain a natural f ree- f lowing 
conversation on a subject of your choice is 
un l ike ly  to ex is t  for several decades.' On the 
other' side, the author h igh l ights  several times 
the importance of th is  d i sc ip l ine  and i t s  possible 
appl icat ions.  He also quotes the UK bank's 
innovation manager David Barrow who says 'Natural 
language processing w i l l  be a key technology in 
increasing the acceptab i l i ty  of computers in 
everyday s i tuat ion ' .  
Yet, natural  language processing began to appear 
as a d i sc ip l ine  since 1950. Progress has been 
cer ta in ly  made, but i t  is not a s t r i k ing  one, with 
respect to other d i sc ip l ines  equal ly mature. Why 
is that? The reader of th is  paper should be aware 
by now he run across one of those 
where-are-we-now-and-where-are-we-going kind of 
papers; but we hope he will keep following us in a 
brief walk through the rough pathway of NLP. But 
please remember.., some (not all) viewpoints 
expressed hereafter would seem narrow-minded if 
applied to corM3utational linguistics, but are 
perfectly reasonable if the perspective is robust 
NLP. 
In n~view,  the major obstacle to a wider adoption 
of NLP systems is ident i f ied  by four engineering 
and l ingu is t i c  'gaps' .  Engineering gaps are: 
1. Lack of format evaluation methods (Section 1); 
2. Lack of tools  and engineering techniques for 
rapid prototyping and test ing of NLP modules 
(Section 4).  
L inguis t ic  gaps are: 
1. Poor encoding of the semantic lexicon (Section 
2); 
2. Poorly motivated models of word categor izat ion 
(Section 3). 
This paper has two s t r i c t ly  related guidel ine 
ideas, that I would l i ke  to state at the 
beginning: 
1. Breadth is more important than depth:  In 
evaluating the pros and cons of l ingu is t i c  and 
coa~uter methods for  NLP we should always keep 
in mind the i r  breadth. Methods that cannot be 
appl ied extensively and systematical ly  are 
simply uninterest ing.  I t  is per fect ly  
reasonable, and in fact very useful (despite 
what Hans Karlgren thinks about) to work on 
sub-languages, provided that the experiments 
we set to process such domains are 
reproducible on any other sub-domain. It is 
perfectly reasonable to define very 
fine-grained knowledge representation and 
manipulation frameworks to express deep 
2. 
language phenomena, provided we can 
demonstrate that such knowledge can be encoded 
on an extensive basis. As long as the field of 
linguistic knowledge representation will 
neglect the related issues of knowledge 
identification and acquisition, we cannot hope 
in a breakthrough of NLP. 
Domain-dependency is not so bad. One of the 
early errors in AI was the attempt of devising 
general purpose methods for general purpose 
problems. Expert systems have been successful 
but they lie on the other extreme. Current At 
research is seeking for a better compromise 
between generality and knowledge power. 
Linguistic knowledge is very vast and a full 
codification is unrealistic for the time 
being. I believe that a central issue is to 
accept the unavoidable reality of 
domain-dependent linguistic knowledge, and 
seek for generalizable methods to acquire one 
such knowledge. As discussed in section 3, I 
also believe that useful linguistic insights 
can be gathered by the study of language 
sub-domains. 
I. THE 'TRULY VIABLE' APPROACH 
Let us maintain our forest-and-path methaphor. Why 
is it so difficult to get oriented? The cunning 
reader of technical papers might have noticed a 
very frequent concluding remark: 'we demonstrated 
that XYZ is a viable approach to sentence 
(discourse, anaphora) analysis (generat ion) ' .  
But what is ' v iab le '?  Other d i sc ip l ines  developed 
models and experiments to evaluate a system: one 
could never claim XYZ viable without a good d ia l  
of tables, f igures and graphs. Why is i t  so 
d i f f i cu l t  in the f ie ld  of NLP? 
Very few papers have been published on the 
evaluation of NLP systems. Some well documented 
report on large NLP projects provides such 
performance figures as accuracy, 
in_telligibility and ua~\[~t, however these 
figures are not uniformly defined and measured. 
One good example is the Japanese Project (Nagao 
1988). The evaluation is performed by humans, 
applying some scoring to the system output (e.g. 
translation quality). 
Other papers provide a l i s t  of language phenomena 
dealt  with by the i r  systems, or an excerpt of 
sentence types the system is able to process. 
These results give at best some feel ing about the 
real power of a system, but by no means can be 
taken as a formal performance measure. 
3 8,4 2 
Two papers address the problem of performance 
ewJluation in a systemetic way: (Guido 1896) and 
(Reed 1988). The approaches are rather d i f fe rent :  
Guido and Mauri attempt an appl icat ion  of standard 
performance evaluat ion methods to the NLP 
discipline, introducing a formal expression for 
the =_performance measure of a NLP system. This 
i s  an hard task, as i t  comes out of the last 
section of the paper, where the formula is appl ied 
to a simple system. Nevertheless, we bel ieve th is  
work being seminal: formal methods are the most 
su i tab le  for  an uniform evaluat ion of NLP systems. 
In (Read 1988) a 'sourcebook approach' is pursued. 
The authors propose a f ine-gra ined cataloguing of 
language phenomena, to be used as a reference for 
the evaluat ion of NLP systems. This method in our 
view is not in contrast with, but rather 
complementary to, a formal evaluation. However, 
the final results of this research are not readily 
available as yet. A second remark is that in 
measuring the competence of a system, linguistic 
issues should be weighed by the 'importance' they 
here in a given application. It is unrealistic to 
pretend that a system can address every possible 
phenoalenon, but it must be able to address those 
phenomena that are prominent to the application 
domain. 
One interesting question is: How do we evaluate 
the l inguist ic  closure of a sub-language? Here is 
a l i s t  of measures, that have the interesting (to 
me) feature of being acquirable with the use of 
computers: 
1. 
2. 
3. 
ident i f i ca t ion  of the sub-language by a p lot  
of d i f fe rent  rootoform types per corpus size; 
Ident i f i ca t ion  of contexts, by and analysis of 
word co-occurrences, and ident i f i ca t ion  of 
semantic re la t ions ,  by an analysis of 
functional  words; 
Measures of complexity, to predict  the 
co~N~Jtational t rac tab i l i ty  of a corpus. Some 
of these measures are l i s ted  in (Kittredge 
1987), e.g. presence of copula, conjunctions, 
quant i f ie rs ,  long nominal compounds, etc. 
Others are suggested in the very interest ing 
studies on readab i l i ty ,  or ig inated by (Flesh 
1946). To our knowledge these methods have 
never been appl ied to the study of l ingu is t i c  
closure in NLP, even though they reached a 
remarkable prec is ion at measuring the ef fect  
of sentence structures and choice of words on 
language corr~)rehension by humans (and 
consequently by computers). 
2. THE WORLD IN A BOX 
Language resides in the lexicon: word knowledge is 
world knowledge. One of the major l im i ta t ion  of 
current NLP systems is a poor encoding of \ [exicat 
semantic knowledge: the world f i t s  a small box. 
The problem with lexica is twofold:  F i r s t ,  there 
is no shared agreement about the type and qua l i ty  
of phenomena to be described in a lexicon. \[n 
(Evens 1988) three major c~npeting approaches to 
meaning representation in lexica are l i s ted :  
re la t iona l  semantics, s t ructura l  semantics arid 
con~oonential/feature analysis.  In (Leech 1981) 7 
types of meaning are dist inguished.  
Relational semantics, but for  the type and number 
of conceptual re lat ions (or cases) to be used, 
shows some uni formity  among i ts  supporters for 
what concerns the structure of the lexicon and the 
way this  information is used to perform semantic 
analysis. The other approaches h igh l ight  much 
deeper phenomena than the semantic re la t ions  
between the words in a sentence, lout i t  is a hard 
task to induce from the l i te ra ture  any f i rm 
pr inc ip le  or shared agreement on the type of 
information to be represented. 
In (Velardi forthcoming) i t  is o t te r ) ted  a mere 
detai led cataloguing of meaning types as found in 
NLP l i te ra ture .  I t  is shown that a l l  types of 
semantic knowledge are in pr inc ip le  useful for the 
purpose of language understanding appl icat ions,  
but cannot be acquired on an extensive basis 
because the primary source of such knowledge are 
l inguists  ar~f psycholonguistic experiments. 
Again, re lat iona l  semantics is somehow more 
in tu i t i ve  than other methods and i t  is easier to 
acquire, because i t  can be induced using the 
evidence provided by texts rather than deduced by 
pre-defined conceptual p r imi t ives .  But even then, 
acquiring n~re than a few hundred word de f in i t ions  
became a proh ib i t i ve  task because of consistency, 
completeness, and boredom problems. 
Some work on com$)uter aided acqu is i t ion  of \[exica 
recently started (Catzolar i  1988) (Velardi 
1989a,b) (Zernik 1989a) (Jacobs 1988) (8inot 
1987); during IJCA! 1989, a workshop was held on 
this  topic (Zernik 1989b). Al l .  the above works 
use corpora or on- l ine d ic t ionar ies  as e source of 
semantic learning, but the methodologies employed 
to manipulate this  texts are very d i f fe rent  and 
s t i l l  inadequate to the task. Personally, we 
bel ieve corpora a mere adequate source of 
information than d ic t ionar ies .  
, on- l ine d ic t ionar ies  are not eas i ly  ava i lab le  
to the sc ient i f i c  community; 
. d ic t ionar ies  mostly include taxonomic 
3 385 
information, that is hardly extracted because 
of circularity and consistency probtems, and 
because there is no clear method to extract 
and describe multiple senses in absence of 
examples; 
the information is not uniform with in  a given 
d ic t ionary ,  and may be very d i f fe rent  from 
d ic t ionary  to d ic t ionary  depending upon the i r  
purpose (e.g.  etymological d ic t ionar ies ,  s ty le  
d ic t ionar ies ,  e tc . ) .  
most of a l l ,  the information in d ic t ionar ies  
is very general,  whereas in NLP often are 
required domain-specific categories and 
definitions. 
Corpora provide r ich examples of word uses, 
including idioms and metonymies. I t  is possible to 
ident i fy  d i f fe rent  senses of a word by a context 
analysis (Vetardi 1989a) (Jacobs 1988). In 
addition, if the corpus used for lexicat 
acquisition is the application domain, one can 
derive a catalogue of relevant language issues. 
In any case, both research on corpora and 
d ic t ionar ies  is very promising, and hopeful ly w i l l  
provide in the near future more insight and 
experimontat support to meaning theories.  
3. THE "IS A" DILEMMA 
The core of any meaning representation method is a 
conceptual hierarchy, the \[S_A hierarchy. People 
that have experience on this, know how much 
time-consuming, and unrewarding, is the task of 
arranging words in a plausible hierarchy. The more 
concepts you put in, the more entangled becomes 
the hierarchy, and nobody is never fully 
sat i s f ied .  In (Niremburg 1987) a system is 
presented to assist  humans in entering and 
maintaining the consistency of a type hierarchy. 
But th is  does not a l lev ia te  the inherent 
complexity of grouping concepts in classes. 
One could maintain that type hierarchies in NLP 
systems should not mimic human conceptual 
p r imi t ives ,  but rather they are a computer method 
to express semantic knowledge in a compact form 
and simulate som~ very par t ia l  reasoning act iv i ty .  
Even under th is  conservative perspective, i t  is 
quite natural  for  the human hierarchy bui lder  to 
try to make sense of his own taxonomic activity 
(and get confused) rather than stay with what the 
specific application requires. Why not introducing 
such categories as MENTAL ACT and 
SOCIAL_PHENOMENON even though the texts to be 
processed only deals with files and disks? 
Several ins t i tu t ions  devoted large e f fo r ts  
towards the definition of IS A hierarchies for 
NLP. Some of these hierarchies are claimed 
'general-purpose':  to me, th is  claim is a minus, 
rather than a plus. 
NLP systems have been often presented as a model 
of human activities. Now, our taxonomic activity 
is precisely one good example of activity that 
works very differently than in computers. In 
computers, hierarchies are used to assert that, 
if X has the feature Y, and Z is-a X, then Z has 
the feature Y. Things are in the same category iff 
they have certain properties in common. This is 
an 9bjectivist view of categorization that has 
been proved in several studies inadequate to model 
human behavior. Objectivism has been argued 
against in experimental studies by psychologists, 
anthropologists, and linguists. In his beautiful 
book (Lakoff 1987) Lakoff lists several phenomena 
relevant to the activity of categorization, like: 
family resemblance, centrality, generat iy i t~ 
chaining, conceptual and funct!onal  
embodiment etc. Only the f i r s t  of these phenomena 
has to do with the c lass ica l  theory of property 
inheritance. But Lakoff shows that the elements of 
a category can be re lated without sharing any 
common property.  The t i t le  of his book 'woman, 
f i re  and dangerous things'  is an examples of 
apparently unrelated members of a s ing le  category 
in an aborigenal language of Aust ra l ia .  The 
categor izat ion pr inc ip le  that re lates these 
elements is called by Lakoff the 
domain-of-experience princip!e. Woman and fire 
are associated in myth. Fighting and fighting 
implements are in the same domain of experience 
with fire, and hence are in the same class. 
Birds also are in the same class, because they are 
believed to be the spirits of dead human-females. 
Other elements are 'catted' in a class by a 
chaining princip!e. Element x calls element y that 
calls z etc. 
I t  is outside the scope of th is  paper to 
summarize, or even l i s t ,  the f indings of lakof f  
and other researchers on human taxonomic ac t iv i ty .  
However the l i te ra ture  provides evidence and 
matter of thoughts concerning the inadequacy of 
property inheritance as a method to s t ructure  
l ingu is t i c  knowledge in NLP systems. 
But even if we stay with property inheritance? we 
should at \[east abandon the idea of seeking for 
general purpose taxonomies. Again, corpora are a 
useful basis to study categor izat ion in 
sub-worlds. Categories in d ic t ionar ies  are  the 
result of a conceptualization effort by a 
linguist. Corpora instead are a 'naive' example of 
a culturally homogeneous group of people, that 
draw much unconsciously on their knowledge on the 
use, and meaning, of words. Corpora are more 
interesting than dictionaries to study 
categorization, just like tribes are more 
4 386 
in terest ing  than ' c iv i l i zed '  
t~nthropetogists. 
cultures to 
4? GET ACCUSTOMED TO CUSTOMIZATION 
The main obstacle to a wider adoption of NLP 
systems in such ac t iv i t ies  as informat ion 
re t r ieva l  and automatic t rans la t ion  are 
re l iab i l i ty  and customizat ion.  These two issues 
are c lear ly  re la ted:  NLP make errors  not because 
the programs have bugs, but because their 
knowledge base is very limited. To cope with poor 
knowledge encoding, ad-hoc techniques are widely 
adopted, even though the use of ad-hoc techniques 
i=!; not advertised in papers, for obvious reasons. 
Ad-hoc techniques are the main cause of tong 
customization time, when switching from one 
a~l i ca t ion  domain to a s l ight ly  d i f fe rent  one. 
Customization and re l iab i l i ty  are in turn re lated 
with what we said so far :  
. we can ' t  pred ic t  the time spent for  
customizat ion,  as i t  happens in database 
systems, because methods for knowledge 
acquisition and knowledge structuring do not 
exist or are far from being assessed; 
. we can't evaluate reliability, because there 
are not formal evaluation methods for NLP 
systems. 
Ag~in, we came to the same problems. But i f  we 
mu~;t fo rce fu l ly  abandon the idea of genera\[ 
purpose language processors, at \[east we should 
equip ourselves with shel l  systems and 
human-computer inter faces  that  can assist  hu~lans 
in the creat ion ,  tes t ing  and maintenance of a l l  
data=entry ac t iv i t ies  in, st ied by NLP systems. 
Thi:~ paper shewed that in semantics there are not 
as yet assessed theor ies .  In syntax, we have too 
many, but not sys temat ica l ly  tested. Shel ls and 
interfaces are useful at: 
1. performing a wider experimentation of 
different theories; 
2. i~k ing the data -ent ry  ac t iv i ty  by hLcnans mere 
constrained or at least supervised; 
3. render the customizat ion ac t iv i ty  to some 
extent forecastab\[e;  
4. ensure consistency with the linguistic 
principia embraced by the system designers. 
In the f ie ld  of Expert Systems, shel ls  began to 
appe~r when the expert system technology was welt 
asse~;sed. May be she l ls  and inter faces have been 
disregarded so far  by the computational l ingu is t i c  
co~Jnity because they are felt i,~ature, given 
the =~;~ate of art, or just because we are so much 
af fec t ionate  toward the idea of encoding the 
world . . . .  However, several ac t iv i t ies  concerned 
with NLP systems can be co,~uterized or 
co.~ter-assisted. We already mentioned the work 
by Niremburg et at. to assist the creation of s 
concept ontology. A special extension of this 
system is under experimentation to guide the 
acqu is i t ion  of a re la t iona l  lexicon (Nirenhburg 
1989). Other systems have been presented for  
prototyping and test ing of syntact ic  parsers 
(Briscoe 1987) (Bougarev 1988) (Marotta 1990). 
5. ! DON'T HAVE THE READY RECIPE 
I know you knew it! Where-are-we-now papers never 
offer a panacea. This is a position paper: it did 
not present solutions, rather it pinpointed to 
problems and, where available, to current 
promising research (rather i,~1odestty, some is of 
our one). The following is a summary list of what 
the author considers her own guidelines for future 
work: 
, Performance eva luat ion:  never say a method is 
' v iab le '  i f  you can ' t  prove i t  fo rmal ly .  
Lexical semantics: don ' t  t ry  to seek for  the 
' rea l  meaning' of things.  Use evidence 
provided by on=l ine corpora as a source, and 
test-bed, of lex ica l  acqu is i t ion  methods. 
. ~ :  property inher i tance is 
inadequate. Is i t  poss ib le to i ,~ le ,~nt  on a 
computer some of the observed human mechanisms 
of categor izat ion? 
Customization: genera\[ purpese systems are 
unrea l i s t i c .  Bui ld she l ls  arKt in ter face  
systems to a l low for  a faster  and 
wel l=assisted customization ac t iv i ty .  
ACKNOWLEDGEMENTS 
This work has been supported by the European 
Co~ni ty  under grant PRO-ART 1989 
REFERENCES 
(g inot  1988) Binot J . \ [ . ,  Jensen K. J ) ict ionarz 
Entr ies as a source of know\[ed e f~q_e f2?._syntactic and 
other disambiguatioqs PrQc. o f2nd  Conf on Appl ied 
Natural Language Processing Austin,  February 1988 
387 
5 
(Boguraev 1988) Boguraev B., Carrot J., Briscoe 
E., Grover C. Software support for practical 
gra~nar development in COLING 88 Budapest 1988 
(Briscoe 1987) Briscoe E., Grover C., Boguraev B., 
Carroll J. A formalism and environment for the 
development of a large grammar of English in IJCAI 
198____77 Mitano, 1987 
(Calzotari 1988) N. Calzolari The Dictionarz and 
the thesaurus can be combined in Relational Models 
of the Lexicon Cambridge University Press, 1988 
(Cookson 1989) C. Cookson Wh c ters need to 
learn ~ in Financial Times September 20, 
1989 
(Evens 1988) M. Evens Introduction in Relational 
Models of the lexicon M. Evens ed. Cambridge 
University Press 1988 
(Flesh 1946) R. Flesh The Art of Plain Talk in 
~ Z  and Brothers 1946 
(Guida 1986) Guida G., Mauri G. Evaluation of 
Natural Language Processing Systems: Issue_.=s and 
Approaches in Proceedings of the IEEE vot.74, n.7 
July 1986 
(Jacobs 1988) P. Jacobs, U. Zernik Learning 
Phrases from Texts: A Case Study in AAAI 88 St. 
Paul, 1988 
(Jacobs 1989) P. Jacobs Making sense of texicat 
acquisition in Proc. of 1st. I JCAI Lexicat 
Acquisition Workshop Detroit 1989 
(Lakoff 1987) G. Lakoff Woman, Fire 
Things: what  categories reveal 
University of Chicago press, 1987 
and Dangerous 
about mind 
(Leech 1981) G. Leech Semantics Penguin books 1981 
(Marotta 1990) Marotta, Pazienza, Pettinelli, 
Vetardi On Parsing ....... F o rm-pars in~ 
submitted, 1990 
(Nagao 1988) M.Nagao, Tsujii J., Nakamura J . ,  Th.___ee 
J_rapanese Gover~ent Project for Machine 
Translation in Machin_eTranslation Systems ed. 
by J.Slocum, Cambridge University Press, 1988 
(Niremburg 1987) S. Nirenburg , V. Raskin The 
subworld concept lexicon a~d.. the Lexicon 
management S=ystem in C~_A~utational 
Li_~uistics n. 13, 1987 
(Niremburg 1989) Niremburg S., Raskin V., 
McCardetl R. Ontology based lexical 
ac_.c_quisition in Proc. 1st. \ [ JCA!  Lexical 
Acquisition gq~Detro i t ,  1987 
(Read 1988) Read No, Quilici A., Reeves J., Dyer 
M., Baker E. Evatuatin~ n a t ~ q e ~ \ [  
a sourcebook apprqach in COLING 88 Budapest 1988 
(Vetardi 1989a) 
ac_E_quisition of 
Vancouver, 1989 
Vetardi, Pazienza ~ter  aided 
lexical cooccurrences in ACL 89 
(Vetardi 1989b) Vetardi, Pazienza, Magrini 
Acquisition of semantic patterns from a natural 
corq.qEl~gs of texts in ACM-SIGART special issue on 
knowledge acquisition n. 107 , 1989 
(Velardi forthcoming) P. Vetardi Ac_c_q~Jirin~ 
Semantic Lexicon for Natural Lanu?1u.ag.e 
Processin~ in U. Zernik ed., Karl Erlbaum assoc., 
forthcoming 
(Zernik 1989) U. Zernik Lexicon Acquisition: 
Learning from Corpus by Capitalizing on Lexical 
Categories in IJCAI 1989 Detroit 1989 
(Zernik 1989b) U.Zernik ed. First Int. Lexical 
Acquisition Workshop Proceeding Detroit 1989 
388 6 
