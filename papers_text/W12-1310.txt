JEP-TALN-RECITAL 2012, Atelier TALAf 2012: Traitement Automatique des Langues Africaines, pages 107?117,
Grenoble, 4 au 8 juin 2012. c?2012 ATALA & AFCP
Extraction de lexiques bilingues ? partir de Wikip?dia 
Rahma Sellami1  Fatiha Sadat2 Lamia Hadrich Belguith1 
(1) ANLP Research Group ? Laboratoire MIRACL 
Facult? des Sciences Economiques et de Gestion de Sfax 
B.P. 1088, 3018 - Sfax ? TUNISIE 
(2) Universit? du Qu?bec ? Montr?al, 201 av. President Kennedy, 
Montr?al, QC, H3X 2Y3, Canada 
Rahma.Sellami@fsegs.rnu.tn, sadat.fatiha@uqam.ca, 
l.belguith@fsegs.rnu.tn 
RESUME ____________________________________________________________________________________________________________   
Avec l'int?r?t accru de la traduction automatique, le besoin de ressources multilingues 
comme les corpus comparables et les lexiques bilingues s?est impos?. Ces ressources sont 
peu disponibles, surtout pour les paires de langues qui ne font pas intervenir l'anglais. 
Cet article pr?sente notre approche sur l'extraction de lexiques bilingues pour les paires 
de langues arabe-fran?ais et yoruba-fran?ais ? partir de l?encyclop?die en ligne 
Wikip?dia. Nous exploitons la taille gigantesque et la couverture de plusieurs domaines 
des articles pour extraire deux lexiques, qui pourront ?tre exploit?s pour d'autres 
applications en traitement automatique du langage naturel. 
ABSTRACT _________________________________________________________________________________________________________  
Bilingual lexicon extraction from Wikipedia 
With the increased interest of the machine translation, needs of multilingual resources 
such as comparable corpora and bilingual lexicon has increased. These resources are not 
available mainly for pair of languages that do not involve English. 
This paper aims to describe our approach on the extraction of bilingual lexicons for 
Arabic-French and Yoruba-French pairs of languages from the online encyclopedia, 
Wikipedia. We exploit the large scale of Wikipedia article to extract two bilingual 
lexicons that will be very useful for natural language applications.  
MOTS-CLES : Lexique bilingue, corpus comparable, Wikip?dia, arabe-fran?ais, yoruba-
fran?ais. 
KEYWORDS : Bilingual lexicon, comparable corpora, Wikipedia, Arabic-French, Yoruba-
French. 
 
107
1 Introduction 
Les ressources linguistiques multilingues sont g?n?ralement construites ? partir de corpus 
parall?les. Cependant, l'absence de ces corpus a incit? les chercheurs ? exploiter d'autres 
ressources multilingues, telles que les corpus comparables : ensembles de textes dans 
diff?rentes langues, qui ne sont pas des traductions les uns des autres (Adafre et de Rijke, 
2006), mais qui contiennent des textes partageant des caract?res communs, tel que le 
domaine, la date de publication, etc. Car moins contrains, ils sont donc plus faciles ? 
construire que les corpus parall?les.  
Les lexiques bilingues constituent une partie cruciale dans plusieurs applications telles 
que la traduction automatique (Och et Ney, 2003) et la recherche d?information 
multilingue  (Grefenstette, 1998). 
Dans cet article, nous cherchons ? exploiter l?aspect multilingue ainsi que la taille 
gigantesque de l?encyclop?die en ligne, Wikip?dia, comme un grand corpus comparable 
pour l'extraction de deux lexiques bilingues (arabe-fran?ais et yoruba-fran?ais). (Morin, 
2007) a montr? que non seulement la taille du corpus comparable mais aussi sa qualit? 
est importante pour l?extraction d?un dictionnaire bilingue. Nous proposons d'utiliser une 
m?thode simple mais efficace, il s?agit d?exploiter les liens inter-langues entre les articles 
Wikip?dia afin d'extraire des termes (simples ou compos?s) arabes et yoruba et leurs 
traductions en fran?ais, puis, utiliser une approche statistique pour aligner les mots des 
termes compos?s.  
Les lexiques extraits seront utilis?s pour l?extraction d?un corpus parall?le ? partir de 
wikip?dia. 
Le contenu de cet article se r?sume comme suit. La section 2 pr?sente un bref aper?u des 
travaux ant?rieurs sur l'extraction de lexiques bilingues. La section 3 d?crit certaines 
caract?ristiques de Wikip?dia que nous avons exploit?es pour l?extraction de nos lexiques 
bilingues. La section 4 pr?sente bri?vement les langues arabe et yoruba. Nous 
pr?sentons, dans la section 5, notre travail de construction des lexiques bilingues ? partir 
de Wikip?dia. Nous ?valuons nos lexiques, dans la section 6. La section 7 conclu cet 
article et donne des pointeurs et extensions pour le futur. 
2 Etat de l?art 
Dans un premier temps, les chercheurs construisent les lexiques bilingues ? partir des 
corpus parall?les. Mais, en raison de l'absence de ces ressources, l?exploitation des corpus 
108
comparables a attir? l?attention de plusieurs chercheurs. (Morin et Daille, 2004) 
pr?sentent une m?thode pour l'extraction de terminologie bilingue ? partir d?un corpus 
comparable du domaine technique. Ils extraient les termes compos?s dans chaque langue 
puis ils alignent ces termes au niveau mot en utilisant une m?thode statistique exploitant 
le contexte des termes. (Otero, 2007) a cr?e un lexique bilingue (anglais-espagnol), en se 
basant sur des informations syntaxiques et lexicales extraites ? partir d?un petit corpus 
parall?le. (Sadat et al, 2003) ont pr?sent? une m?thode hybride qui se base sur des 
informations statistiques (deux mod?les de traduction bidirectionnels) combin?es ? des 
informations linguistiques pour construire une terminologie anglais-japonais. (Morin et 
Prochasson, 2011) ont pr?sent? une m?thode pour l'extraction d?un lexique bilingue 
sp?cialis? ? partir d?un corpus comparable, agr?ment? d?un corpus parall?le. Ils extraient 
des phrases parall?les ? partir du corpus comparable, puis, ils alignent ces phrases au 
niveau mots pour en extraire un lexique bilingue. (Hazem et al, 2011) proposent une 
extension de l?approche par similarit? inter-langue abord?e dans les travaux pr?c?dents. 
Ils pr?sentent un mod?le inspir? des m?tamoteurs de recherche d?information. 
Dans ce qui suit, nous d?crivons les travaux ant?rieurs qui ont exploit? Wikip?dia comme 
corpus comparable pour la construction d?un lexique bilingue.  
(Adafre et de Rijke, 2006) a cr?? un lexique bilingue (anglais-n?erlandais) ? partir de 
Wikipedia dans le but de l?utiliser pour la construction d'un corpus parall?le ? partir des 
articles de Wikip?dia.  Le lexique extrait est compos? uniquement de titres des articles 
Wikip?dia reli?s par des liens inter-langues. Les auteurs ont montr? l?efficacit? de 
l?utilisation de ce lexique pour la construction d?un corpus parall?le. (Bouma et al, 2006) 
ont construit un lexique bilingue pour la cr?ation d'un syst?me de question r?ponse 
multilingue (fran?ais-n?erlandais). En outre, (Decklerck et al, 2006) ont extrait un 
lexique bilingue ? partir des liens inter-langues de Wikip?dia. Ce lexique a ?t? utilis? 
pour la traduction des labels d?une ontologie. Ces travaux sont caract?ris?s par le fait 
qu?ils exploitent uniquement les liens inter-langues de Wikip?dia. Par contre, (Erdmann 
et al, 2008) analysent non seulement les liens inter-langues de wikip?dia, mais 
exploitent aussi les redirections et les liens inter-wiki pour la construction d?un 
dictionnaire anglais-japonais. Les auteurs ont montr? l?apport de l?utilisation de 
Wikip?dia par rapport aux corpus parall?les pour l?extraction d?un dictionnaire bilingue. 
Cet apport apparait surtout au niveau de la large couverture des termes. (Sadat et 
Terrasa, 2010) proposent une approche pour l?extraction de terminologie bilingue ? 
partir de Wikip?dia. Cette approche consiste ? extraire d?abord des paires de termes et 
109
traductions ? partir des diff?rents types d?informations, des liens et des textes de 
Wikip?dia, puis, ? utiliser des informations linguistiques afin de r?ordonner les termes et 
leurs traductions pertinentes et ainsi ?liminer les termes cibles inutiles.  
3 Bref aper?u sur les langues arabe et yoruba  
3.1 La langue arabe 
L?arabe (???????) est une langue originaire de la p?ninsule Arabique. Elle est parl?e en Asie 
et en Afrique du Nord. L?Arabe est issue du groupe m?ridional des langues s?mitiques. 
Elle s??crit de droite ? gauche tout en utilisant des lettres qui prennent des formes 
diff?rentes suivant qu?elles soient isol?es, au d?but, au milieu ou ? la fin du mot.1  
La langue arabe est morphologiquement riche ce qui pose le probl?me de l?ambigu?t? au 
niveau de son traitement automatique, un mot en arabe peut encapsuler la signification 
de toute une phrase (? ? ??? ?? ? ??/est ce que vous souvenez de nous ?). 
3.2 La langue yoruba 
Le yoruba (yor?b?) est une langue tonale appartenant ? la famille des langues nig?ro-
congolaises. Le yorouba, langue maternelle d?environ 20% de la population nig?riane, est 
?galement parl? au B?nin et au Togo. Au Nig?ria, il est parl? dans la plus grande partie 
des ?tats d?Oyo, Ogun, Ondo, Osun, Kwara et Lagos, et ? l?ouest de l??tat de Kogi.  
La langue se subdivise en de nombreux dialectes. Il existe n?anmoins aussi une langue 
standard2. 
Le yoruba s'?crit au moyen de plusieurs alphabet fond?es sur l?alphabet latin muni 
d?accents pour noter les tons (dont la charge fonctionnelle est tr?s importante), et de 
points souscrits pour noter les voyelles ouvertes. 
La voyelle est le centre de la syllabe. Le ton appara?t comme une caract?ristique 
inh?rente ? la voyelle ou ? la syllabe. Il y a autant de syllabes que de tons. Le 
symbolisme se pr?sente comme suit : ton haut: (/), ton bas: (\), ton moyen: (-). 
Ces tons d?terminent le sens du mot, une forme peut avoir plusieurs sens (ex. Igba/deux 
cent, Igba/calebasse, ?gba/temps, etc)3.  
                                                          
1 http://fr.wikipedia.org/wiki/Arabe [consult? le 26/04/2012]. 
2 http://fr.wikipedia.org/wiki/Yoruba_(langue) [consult? le 18/04/2012]. 
3 http://www.africananaphora.rutgers.edu/downloads/casefiles/YorubaGS.pdf [consult? le 
24/04/2012]. 
110
La morphologie de la langue yoruba est riche, faisant, par exemple, un large emploi 
du redoublement (ex. Eso/fruit, so/donner de fruits, j?/ d?goutter , ?jo/pluie). 
4 Caract?ristiques de Wikip?dia 
Lors de l'extraction de terminologies bilingues ? partir de corpus parall?les ou 
comparables, il est difficile d'atteindre une pr?cision et une couverture suffisantes, en 
particulier pour les mots moins fr?quents tels que les terminologies sp?cifiques ? un 
domaine (Erdmann, 2008). Pour notre travail de construction de lexiques bilingues, nous 
proposons d?exploiter Wikip?dia, une ressource multilingue dont la taille est gigantesque 
et qui est en d?veloppement continu. 
Dans ce qui suit, nous d?crivons certaines caract?ristiques de Wikip?dia, ces 
caract?ristiques font de Wikip?dia une ressource pr?cieuse pour l'extraction de ressources 
bilingues. 
Actuellement, Wikip?dia contient 21 368 483 articles dont 1 221 995 articles fran?ais, 
170771 articles en langue arabe et 29 884 articles en langue yoruba4. Ces articles 
couvrent plusieurs domaines. Nous exploitons l?aspect multilingue et gigantesque de 
cette ressource afin d?extraire des lexiques bilingues de large couverture. 
La structure de Wikip?dia est tr?s dense en liens ; ces liens relient soit des articles d?une 
seule langue soit des articles r?dig?s en langues diff?rentes.  
Les liens Wikip?dia peuvent ?tre class?s en :  
- Lien inter-langue : un lien inter-langue relie deux articles en langues diff?rentes. Un 
article a au maximum un seul lien inter-langue pour chaque langue, ce lien a comme 
syntaxe [[code de la langue cible : titre de l?article en langue cible]] avec ? code de la 
langue cible ? identifie la langue de l?article cible  et ? titre de l?article en langue cible ? 
identifie son titre (ex. [[yo:J?p?t?r?]]). Puisque les titres des articles Wikip?dia sont 
uniques,  la syntaxe des liens inter-langue est suffisante pour identifier les articles en 
langues cibles.  
- Redirection : une redirection  renvoie automatiquement le visiteur sur une autre 
page. La syntaxe Wikip?dia d'une redirection est : #REDIRECTION[[page de 
destination]]. Les pages de redirection sont notamment utilis?es pour des abr?viations 
(ex. SNCF redirige vers Soci?t? Nationale des Chemins de Fer), des synonymes (ex. e-
                                                          
4 http://meta.wikimedia.org/wiki/List_of_Wikipedias [consult? le 01/03/2012]. 
111
mail, courriel, m?l et messagerie ?lectronique redirigent vers courrier ?lectronique), des 
noms alternatifs (ex. Karol Wojty?a redirige vers Jean-Paul II), etc. 
- Lien inter-wiki : c'est un lien vers une autre page de la m?me instance de Wikip?dia. 
Le texte du lien peut correspondre au titre de l'article qui constitue la cible du lien (la 
syntaxe en sera alors : [[titre de l'article]]), ou diff?rer du titre de l'article-cible (avec 
la syntaxe suivante : [[titre de l'article|texte du lien]]). 
5 Extraction des lexiques bilingues ? partir de Wikip?dia 
5.1 Extraction des termes 
Nous avons extrait deux lexiques bilingues en exploitant la syntaxe des liens inter-
langues de Wikip?dia. En effet, les liens inter-langues relient deux articles en langues 
diff?rentes dont les titres sont en traduction mutuelle. En outre, ces liens sont cr??s 
par les auteurs des articles, nous supposons que les auteurs ont correctement positionn? 
ces liens. Aussi, un article en langue source est li? ? un seul article en langue cible, donc, 
nous n?avons pas ? g?rer d??ventuels probl?mes d?ambigu?t? au niveau de l?extraction des 
paires de titres.  
Nous avons t?l?charg? la base de donn?es Wikip?dia arabe (janvier 2012)5 et yoruba 
(mars 2012)6 sous format XML et nous avons extrait 104 104 liens inter-langue arabe et 
15 345 liens inter-langue yoruba vers les articles fran?ais. Chaque lien correspond ? une 
paire de titres arabe-fran?ais et yoruba-fran?ais. Certains titres sont compos?s de termes 
simples et d?autres sont compos?s de termes compos?s de plusieurs mots. 
5.2 Alignement des mots 
Dans le but d?avoir un lexique compos? uniquement des termes simples, nous avons 
proc?der ? une ?tape d?alignement des mots. 
Cette ?tape pr?sente plusieurs difficult?s dont : Premi?rement, les alignements ne sont 
pas n?cessairement contigus : deux mots cons?cutifs dans la phrase source peuvent ?tre 
align?s avec deux mots arbitrairement distants de la phrase cible. On appelle ce 
ph?nom?ne distorsion. Deuxi?mement, un mot en langue source peut ?tre align? ? 
plusieurs mots en langue cible ; ce qui est d?fini en tant que fertilit?. 
                                                          
5 http://download.wikipedia.com/arwiki/20120114/ [consult? le 01/03/2012]. 
6 http://dumps.wikimedia.org/yowiki/20120316/ [consult? le 15/03/2012]. 
112
Nous avons proc?d? ? une ?tape d?alignement des mots des paires de titres en nous 
basant sur une approche statistique, nous avons utilis? les mod?les IBM [1-5] (Brown et 
al., 1993) combin?s avec les mod?les de Markov cach?s HMM (Vogel et al,1996) vu que 
ces mod?les standard se sont av?r?s efficaces dans les travaux d'alignement de mots. 
Les mod?les IBM sont des mod?les ? base de mots, c?est-?-dire que l?unit? de traduction 
qui appara?t dans les lois de probabilit? est le mot.  
Les cinq mod?les IBM permettent d?estimer les probabilit?s P(fr |ar) et P(fr |yo) de fa?on 
it?rative, tel que fr est un mot fran?ais, ar est un mot arabe et yo est un mot yoruba. 
Chaque mod?le s?appuie sur les param?tres estim?s par le mod?le le pr?c?dant et prend 
en compte de nouvelles caract?ristiques telles que la distorsion, la fertilit?, etc.  
Le mod?le de Markov cach? (nomm? usuellement HMM) (Vogel et al, 1996) est une 
am?lioration du mod?le IBM2. Il mod?lise explicitement la distance entre l?alignement 
du mot courant et l?alignement du mot pr?c?dent. 
Nous avons utilis? l?outil open source Giza++ (Och et Ney, 2003) qui impl?mente ces 
mod?les pour l?alignement des mots et nous avons extrait les  traductions candidates  ? 
partir d?une table de traductions cr??e par Giza++. Chaque ligne de cette table contient 
un mot en langue arabe (ar) (respectivement yoruba (yo)), une traduction  candidate (fr) 
et un score qui calcule la probabilit? de traduction P(fr|ar) (resp. yoruba P(fr|yo)). 
Apr?s l??tape d?alignement, nous avons extrait 65 049 mots arabes et 155 348 paires de 
traductions candidates en fran?ais. En ce qui concerne le lexique yoruba-fran?ais, nous 
avons extrait 11 235 mots yoruba et 20 089 paires de traductions candidates en fran?ais. 
Afin d?am?liorer la qualit? de nos lexiques, nous avons proc?d? ? une ?tape de filtrage 
qui ?limine les traductions candidates ayant un score inf?rieur ? un seuil.  
 
 
 
 
FIGURE 1 ? Extrait de la table de traduction ar-fr 
 
 
 
 
 
FIGURE 2 ? Extrait de la table de traduction yo-fr 
R?m?           Rome               0.7500 
R?m?           romaine           0.33333 
al?d?nid?     naturelles         1.00000 
?w?j?          Soci?t?             0.66666 
?w?j?          Communaut?    0.20000 
Mathim?t?k? Math?matiques 0.50000 
Copper         Cuivre              1.000 
?? ? ?      Flou               1.0000000 
?? ? ?      Diffusion        0.1666667 
????? ?      ?quipes           0.1250000 
????? ?      f?minin           0.0067568 
????? ?      masculin         0.6690141 
??? ??? ?   N?gociations   1.0000000 
??? ??????  Amazones        1.0000000 
 
113
6 Evaluation 
Puisque notre int?r?t est centr? sur les liens inter-langues de Wikip?dia, les lexiques 
extraits ne contiennent pas des verbes.  
Nous avons ?valu?, manuellement, la qualit? de notre lexique bilingue en calculant la 
mesure de pr?cision et en se r?f?rant ? un expert.  
????????? =
nombre de traductions extraites correctes 
nombre de traductions extraites
 
Nous avons calcul? la pr?cision en se basant sur les traductions candidates de 50 mots 
arabes et yoruba et nous avons fait varier le seuil de 0 ? 1 pour en identifier la valeur 
optimale en fonction de la pr?cision. 
La figure 3 pr?sente les valeurs de pr?cision des deux lexiques en variant le seuil.  
Remarquons qu?en augmentant le seuil, la pr?cision est am?lior?e. Sa valeur passe de 
0.46 (avec un seuil ?gale 0) ? 0.74 (quand le seuil ?gale ? 1) pour le lexique yoruba-
fran?ais et de 0.22 ? 0.75 pour le lexique arabe-fran?ais. 
La figure 4 montre que la couverture du lexique fran?ais-yoruba et presque stable, elle 
varie entre 14045 (quand le seuil ?gale ? 0) et 11184 (quand le seuil ?gale ? 1). Ces 
valeurs sont tr?s inf?rieures par rapport ? celles du lexique arabe-fran?ais, ceci est d? 
principalement au faible nombre des articles Wikip?dia yoruba.  
La figure 3 montre que les meilleures valeurs de pr?cision sont atteintes ? partir d?un 
seuil ?gal ? 0.6 pour le lexique arabe-fran?ais. Mais, remarquons dans la figure 4, qu?? 
partir de ce seuil, la couverture du lexique est affaiblie. Ceci est expliqu? par le fait que 
plusieurs fausses traductions ont ?t? ?limin?es ? partir de ce seuil. 
Les erreurs du lexique yoruba-fran?ais sont dues principalement au fait que certains 
titres wikip?dia sont introduits en anglais (ex. density/densit?) et aux erreurs 
d?alignements (ex. Tanaka/Giichi).  
Les erreurs de traduction du lexique arabe-fran?ais sont dues principalement au fait que 
certains titres arabes sont introduits en langue autre que l?arabe (ex. cv/cv), en majorit? 
en langue anglaise. Certaines traductions candidates sont des translit?rations et pas des 
traductions (ex. ???????/Intifada). Aussi, nous avons d?tect? des erreurs d?alignement (ex.  
?? ?? ?/diagnostique). D?autres erreurs sont dues au fait que les paires de titres des 
articles ne sont pas des traductions pr?cises mais il s?agit juste de la m?me notion  (ex. 
???/No?l). 
114
 
FIGURE 3 ?Variation de la pr?cision des lexiques yo-fr et ar-fr selon le seuil 
  
FIGURE 4 ? Variation de la couverture des lexiques yo-fr et ar-fr selon le seuil 
7 Conclusion 
L?exploitation de Wikip?dia pour la construction de ressources linguistiques multilingues 
fait l?objet de plusieurs travaux de recherches, comme la construction des corpus 
parall?les, des lexiques multilingues et des ontologies multilingues. 
Dans cet article, nous avons d?crit notre travail pr?liminaire d?extraction de lexiques 
(arabe-fran?ais et yoruba-fran?ais) ? partir de Wikip?dia. En effet, notre but majeur est 
d?exploiter Wikip?dia en tant que corpus comparable pour la traduction automatique 
statistique.  
La m?thode que nous proposons est efficace malgr? sa simplicit?. Il s?agit d?extraire les 
titres arabes, yorubas et fran?ais des articles de Wikip?dia, en se basant sur les liens 
inter-langues puis d?aligner les mots de ces titres en se basant sur une approche 
statistique. Nous avons atteint des valeurs de pr?cision et de couverture encourageantes 
qui d?passent respectivement 0.7 et 60 000 paires de traductions pour le lexique arabe-
fran?ais et 0.7 et 14 000 paires de traductions pour le lexique yoruba-fran?ais. 
0
0,1
0,2
0,3
0,4
0,5
0,6
0,7
0,8
pr?cision ar-fr pr?cision yo-fr
0
10000
20000
30000
40000
50000
60000
70000
couverture du lexique yo-fr couverture du lexique ar-fr
no
m
br
e 
de
 p
ai
re
s 
de
 tr
ad
uc
tio
ns
115
Comme travaux futurs, nous envisageons d??largir la couverture de nos lexiques en 
exploitant d?autres liens Wikip?dia comme les redirections et les liens inter-wiki. Nous 
envisageons aussi d?utiliser ces lexiques pour l?extraction des corpus parall?les (arabe- 
fran?ais et yoruba-fran?ais) ? partir de Wikip?dia. Ces corpus seront utilis?s au niveau de 
l?apprentissage des syst?mes de traduction automatique statistique arabe-fran?ais et 
yoruba-fran?ais.  
Re?fe?rences 
ADAFRE, S. F. ET DE RIJKE, M. (2006). Finding Similar Sentences across Multiple Languages 
in Wikipedia. In Proceedings of the EACL Workshop on NEW TEXT Wikis and blogs and 
other dynamic text sources, pages 62?69. 
BOUMA, G., FAHMI, I., MUR, J., G. VAN NOORD, VAN DER, L., ET TIEDEMANN, J. (2006). Using 
Syntactic Knowledge for QA. In Working Notes for the Cross Language Evaluation Forum 
Workshop. 
BROWN PETER, F., PIETRA, V. J., PIETRA, S. A., ET MERCER, R. L. (1993). The Mathematics of 
Statistical Machine Translation: Parameter Estimation. IBM T.J. Watson Research Center, 
pages 264-311. 
DECLERCK, T., PEREZ, A. G., VELA, O., , Z., ET MANZANO-MACHO, D. (2006). Multilingual 
Lexical Semantic Resources for Ontology Translation. In Proceedings of International 
Conference on Language Ressources and Evaluation (LREC), pages 1492 ? 1495. 
ERDMANN, M., NAKAYAMA, K., HARA, T. ET NISHIO, S. (2008). A bilingual dictionary 
extracted from the wikipedia link structure. In Proceedings of International Conference on 
Database Systems for Advanced Applications (DASFAA) Demonstration Track, pages 380-
392. 
ERDMANN, M. (2008). Extraction of Bilingual Terminology from the Link Structure of 
Wikipedia. MSc. Thesis, Graduate School of Information Science and Engineering, Osaka 
University. 
GREFENSTETTE, G. (1998). The Problem of Cross-language Information Retrieval. Cross-
language Information Retrieval. Kluwer Academic Publishers. 
HAZEM, A., MORIN, E. ET SEBASTIAN P. S. (2011). Bilingual Lexicon Extraction from 
Comparable Corpora as Metasearch. In Proceedings of the 4th Workshop on Building and 
116
Using Comparable Corpora, pages 35?43, 49th Annual Meeting of the Association for 
Computational Linguistics, Portland, Oregon.  
MORIN, E. (2007). Synergie des approches et des ressources d?ploy?es pur le traitement 
de l??crit. Ph.D. thesis, Habilitation ? Diriger les Recherches, Universit? de Nantes. 
MORIN, E. ET DAILLE, B. (2004). Extraction de terminologies bilingues ? partir de corpus 
comparables d?un domaine sp?cialis?. Traitement Automatique des Langues (TAL), pages 
103?122. 
MORIN, E. ET PROCHASSON E. (2011). Bilingual Lexicon Extraction from Comparable 
Corpora Enhanced with Parallel Corpora. In Proceedings of the 4th Workshop on Building 
and Using Comparable Corpora, pages 27?34. 
OCH, F.J. ET NEY, H. (2003). A systematic comparison of various statistical alignment 
models. Computational Linguistics, pages 19?51, March. 
OTERO, PABLO G. (2007). Learning bilingual lexicons from comparable english and 
spanish corpora. In Proceedings of Machine Translation Summit XI, pages 191?198. 
SADAT, F., YOSHIKAWA, M. ET UEMURA, S. 2003. Bilingual terminology acquisition from 
comparable corpora and phrasal translation to cross-language information retrieval. In 
Proceedings of the 41st Annual Meeting on Association for Computational Linguistics-Volume, 
pages 141?144. Association for Computational Linguistics. 
SADAT, F. ET TERRASSA, A. (2010). Exploitation de Wikip?dia pour l?Enrichissement et la 
Construction des Ressources Linguistiques. TALN 2010, Montr?al. 
VOGEL, S., NEY H. ET C. TILLMANN (1996). HMM-based word alignment in statistical 
translation. In Preceding of the Conference on Computational Linguistics, pages 836?841, 
Morristown, NJ, USA. 
117

