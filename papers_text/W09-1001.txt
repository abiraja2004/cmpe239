Proceedings of the EACL 2009 Workshop on Computational Linguistic Aspects of Grammatical Inference, pages 1?4,
Athens, Greece, 30 March 2009. c?2009 Association for Computational Linguistics
Grammatical Inference and Computational Linguistics
Menno van Zaanen
Tilburg Centre for Creative Computing
Tilburg University
Tilburg, The Netherlands
mvzaanen@uvt.nl
Colin de la Higuera
University of Saint- ?Etienne
France
cdlh@univ-st-etienne.fr
1 Grammatical inference and its links to
natural language processing
When dealing with language, (machine) learning
can take many different faces, of which the most
important are those concerned with learning lan-
guages and grammars from data. Questions in
this context have been at the intersection of the
fields of inductive inference and computational
linguistics for the past fifty years. To go back
to the pioneering work, Chomsky (1955; 1957)
and Solomonoff (1960; 1964) were interested, for
very different reasons, in systems or programs that
could deduce a language when presented informa-
tion about it.
Gold (1967; 1978) proposed a little later a uni-
fying paradigm called identification in the limit,
and the term of grammatical inference seems to
have appeared in Horning?s PhD thesis (1969).
Out of the scope of linguistics, researchers and
engineers dealing with pattern recognition, under
the impulsion of Fu (1974; 1975), invented algo-
rithms and studied subclasses of languages and
grammars from the point of view of what could
or could not be learned.
Researchers in machine learning tackled related
problems (the most famous being that of infer-
ring a deterministic finite automaton, given ex-
amples and counter-examples of strings). An-
gluin (1978; 1980; 1981; 1982; 1987) introduced
the important setting of active learning, or learn-
ing for queries, whereas Pitt and his colleagues
(1988; 1989; 1993) gave several complexity in-
spired results with which the hardness of the dif-
ferent learning problems was exposed.
Researchers working in more applied areas,
such as computational biology, also deal with
strings. A number of researchers from that
field worked on learning grammars or automata
from string data (Brazma and Cerans, 1994;
Brazma, 1997; Brazma et al, 1998). Simi-
larly, stemming from computational linguistics,
one can point out the work relating language learn-
ing with more complex grammatical formalisms
(Kanazawa, 1998), the more statistical approaches
based on building language models (Goodman,
2001), or the different systems introduced to au-
tomatically build grammars from sentences (van
Zaanen, 2000; Adriaans and Vervoort, 2002). Sur-
veys of related work in specific fields can also
be found (Natarajan, 1991; Kearns and Vazirani,
1994; Sakakibara, 1997; Adriaans and van Zaa-
nen, 2004; de la Higuera, 2005; Wolf, 2006).
2 Meeting points between grammatical
inference and natural language
processing
Grammatical inference scientists belong to a num-
ber of larger communities: machine learning (with
special emphasis on inductive inference), com-
putational linguistics, pattern recognition (within
the structural and syntactic sub-group). There is
a specific conference called ICGI (International
Colloquium on Grammatical Inference) devoted
to the subject. These conferences have been held
at Alicante (Carrasco and Oncina, 1994), Mont-
pellier (Miclet and de la Higuera, 1996), Ames
(Honavar and Slutski, 1998), Lisbon (de Oliveira,
2000), Amsterdam (Adriaans et al, 2002), Athens
(Paliouras and Sakakibara, 2004), Tokyo (Sakak-
ibara et al, 2006) and Saint-Malo (Clark et al,
2008). In the proceedings of this event it is pos-
sible to find a number of technical papers. Within
this context, there has been a growing trend to-
wards problems of language learning in the field
of computational linguistics.
The formal objects in common between the
two communities are the different types of au-
tomata and grammars. Therefore, another meet-
ing point between these communities has been the
different workshops, conferences and journals that
focus on grammars and automata, for instance,
1
FSMNLP,GRAMMARS, CIAA, . . .
3 Goal for the workshop
There has been growing interest over the last few
years in learning grammars from natural language
text (and structured or semi-structured text). The
family of techniques enabling such learning is usu-
ally called ?grammatical inference? or ?grammar
induction?.
The field of grammatical inference is often sub-
divided into formal grammatical inference, where
researchers aim to proof efficient learnability of
classes of grammars, and empirical grammatical
inference, where the aim is to learn structure from
data. In this case the existence of an underlying
grammar is just regarded as a hypothesis and what
is sought is to better describe the language through
some automatically learned rules.
Both formal and empirical grammatical infer-
ence have been linked with (computational) lin-
guistics. Formal learnability of grammars has
been used in discussions on how people learn lan-
guage. Some people mention proofs of (non-
)learnability of certain classes of grammars as ar-
guments in the empiricist/nativist discussion. On
the more practical side, empirical systems that
learn grammars have been applied to natural lan-
guage. Instead of proving whether classes of
grammars can be learnt, the aim here is to pro-
vide practical learning systems that automatically
introduce structure in language. Example fields
where initial research has been done are syntac-
tic parsing, morphological analysis of words, and
bilingual modelling (or machine translation).
This workshop organized at EACL 2009 aimed
to explore the state-of-the-art in these topics. In
particular, we aimed at bringing formal and empir-
ical grammatical inference researchers closer to-
gether with researchers in the field of computa-
tional linguistics.
The topics put forward were to cover research
on all aspects of grammatical inference in rela-
tion to natural language (such as, syntax, seman-
tics, morphology, phonology, phonetics), includ-
ing, but not limited to
? Automatic grammar engineering, including,
for example,
? parser construction,
? parameter estimation,
? smoothing, . . .
? Unsupervised parsing
? Language modelling
? Transducers, for instance, for
? morphology,
? text to speech,
? automatic translation,
? transliteration,
? spelling correction, . . .
? Learning syntax with semantics,
? Unsupervised or semi-supervised learning of
linguistic knowledge,
? Learning (classes of) grammars (e.g. sub-
classes of the Chomsky Hierarchy) from lin-
guistic inputs,
? Comparing learning results in different
frameworks (e.g. membership vs. correction
queries),
? Learning linguistic structures (e.g. phonolog-
ical features, lexicon) from the acoustic sig-
nal,
? Grammars and finite state machines in ma-
chine translation,
? Learning setting of Chomskyan parameters,
? Cognitive aspects of grammar acquisition,
covering, among others,
? developmental trajectories as studied by
psycholinguists working with children,
? characteristics of child-directed speech
as they are manifested in corpora such
as CHILDES, . . .
? (Unsupervised) Computational language ac-
quisition (experimental or observational),
4 The papers
The workshop was glad to have as invited speaker
Damir ?Cavar, who presented a talk titled: On boot-
strapping of linguistic features for bootstrapping
grammars.
The papers submitted to the workshop and re-
viewed by at least three reviewers each, covered a
very wide range of problems and techniques. Ar-
ranging them into patterns was not a simple task!
There were three papers focussing on transduc-
ers:
2
? Jeroen Geertzen shows in his paper Dialogue
Act Prediction Using Stochastic Context-Free
Grammar Induction, how grammar induction
can be used in dialogue act prediction.
? In their paper (Experiments Using OSTIA for
a Language Production Task), Dana Angluin
and Leonor Becerra-Bonache build on previ-
ous work to see the transducer learning algo-
rithm OSTIA as capable of translating syn-
tax to semantics.
? In their paper titled GREAT: a finite-state
machine translation toolkit implementing a
Grammatical Inference Approach for Trans-
ducer Inference (GIATI), Jorge Gonza?lez and
Francisco Casacuberta build on a long his-
tory of GOATI learning and try to eliminate
some of the limitations of previous work.
The learning concerns finite-state transducers
from parallel corpora.
Context-free grammars of different types were
used for very different tasks:
? Alexander Clark, Remi Eyraud and Amaury
Habrard (A note on contextual binary fea-
ture grammars) propose a formal study of
a new formalism called ?CBFG?, describe
the relationship of CBFG to other standard
formalisms and its appropriateness for mod-
elling natural language.
? In their work titled Language models for con-
textual error detection and correction, Her-
man Stehouwer and Menno van Zaanen look
at spelling problems as a word prediction
problem. The prediction needs a language
model which is learnt.
? A formal study of French treebanks is made
by Marie-He?le`ne Candito, Benoit Crabbe? and
Djame? Seddah in their work: On statistical
parsing of French with supervised and semi-
supervised strategies.
? Franco M. Luque and Gabriel Infante-Lopez
study the learnability of NTS grammars with
reference to the Penn treebank in their paper
titled Upper Bounds for Unsupervised Pars-
ing with Unambiguous Non-Terminally Sep-
arated Grammars.
One paper concentrated on morphology :
? In A comparison of several learners for
Boolean partitions: implications for morpho-
logical paradigm, Katya Pertsova compares a
rote learner to three morphological paradigm
learners.
References
P. Adriaans and M. van Zaanen. 2004. Computational
grammar induction for linguists. Grammars, 7:57?
68.
P. Adriaans and M. Vervoort. 2002. The EMILE
4.1 grammar induction toolbox. In Adriaans et al
(Adriaans et al, 2002), pages 293?295.
P. Adriaans, H. Fernau, and M. van Zaannen, editors.
2002. Grammatical Inference: Algorithms and Ap-
plications, Proceedings of ICGI ?02, volume 2484
of LNAI, Berlin, Heidelberg. Springer-Verlag.
D. Angluin. 1978. On the complexity of minimum
inference of regular sets. Information and Control,
39:337?350.
D. Angluin. 1980. Inductive inference of formal lan-
guages from positive data. Information and Control,
45:117?135.
D. Angluin. 1981. A note on the number of queries
needed to identify regular languages. Information
and Control, 51:76?87.
D. Angluin. 1982. Inference of reversible languages.
Journal of the Association for Computing Machin-
ery, 29(3):741?765.
D. Angluin. 1987. Queries and concept learning. Ma-
chine Learning Journal, 2:319?342.
A. Brazma and K. Cerans. 1994. Efficient learning
of regular expressions from good examples. In AII
?94: Proceedings of the 4th International Workshop
on Analogical and Inductive Inference, pages 76?90.
Springer-Verlag.
A. Brazma, I. Jonassen, J. Vilo, and E. Ukkonen. 1998.
Pattern discovery in biosequences. In Honavar and
Slutski (Honavar and Slutski, 1998), pages 257?270.
A. Brazma, 1997. Computational learning theory and
natural learning systems, volume 4, chapter Effi-
cient learning of regular expressions from approxi-
mate examples, pages 351?366. MIT Press.
R. C. Carrasco and J. Oncina, editors. 1994. Gram-
matical Inference and Applications, Proceedings of
ICGI ?94, number 862 in LNAI, Berlin, Heidelberg.
Springer-Verlag.
N. Chomsky. 1955. The logical structure of linguis-
tic theory. Ph.D. thesis, Massachusetts Institute of
Technology.
3
N. Chomsky. 1957. Syntactic structure. Mouton.
A. Clark, F. Coste, and L. Miclet, editors. 2008.
Grammatical Inference: Algorithms and Applica-
tions, Proceedings of ICGI ?08, volume 5278 of
LNCS. Springer-Verlag.
C. de la Higuera. 2005. A bibliographical study
of grammatical inference. Pattern Recognition,
38:1332?1348.
A. L. de Oliveira, editor. 2000. Grammatical Infer-
ence: Algorithms and Applications, Proceedings of
ICGI ?00, volume 1891 of LNAI, Berlin, Heidelberg.
Springer-Verlag.
K. S. Fu and T. L. Booth. 1975. Grammatical infer-
ence: Introduction and survey. Part I and II. IEEE
Transactions on Syst. Man. and Cybern., 5:59?72
and 409?423.
K. S. Fu. 1974. Syntactic Methods in Pattern Recogni-
tion. Academic Press, New-York.
E. M. Gold. 1967. Language identification in the limit.
Information and Control, 10(5):447?474.
E. M. Gold. 1978. Complexity of automaton identi-
fication from given data. Information and Control,
37:302?320.
J. Goodman. 2001. A bit of progress in language mod-
eling. Technical report, Microsoft Research.
V. Honavar and G. Slutski, editors. 1998. Gram-
matical Inference, Proceedings of ICGI ?98, number
1433 in LNAI, Berlin, Heidelberg. Springer-Verlag.
J. J. Horning. 1969. A study of Grammatical Inference.
Ph.D. thesis, Stanford University.
M. Kanazawa. 1998. Learnable Classes of Categorial
Grammars. CSLI Publications, Stanford, Ca.
M. J. Kearns and U. Vazirani. 1994. An Introduction
to Computational Learning Theory. MIT press.
L. Miclet and C. de la Higuera, editors. 1996. Pro-
ceedings of ICGI ?96, number 1147 in LNAI, Berlin,
Heidelberg. Springer-Verlag.
B. L. Natarajan. 1991. Machine Learning: a Theoret-
ical Approach. Morgan Kauffman Pub., San Mateo,
CA.
G. Paliouras and Y. Sakakibara, editors. 2004. Gram-
matical Inference: Algorithms and Applications,
Proceedings of ICGI ?04, volume 3264 of LNAI,
Berlin, Heidelberg. Springer-Verlag.
L. Pitt and M. Warmuth. 1988. Reductions among
prediction problems: on the difficulty of predicting
automata. In 3rd Conference on Structure in Com-
plexity Theory, pages 60?69.
L. Pitt and M. Warmuth. 1993. The minimum consis-
tent DFA problem cannot be approximated within
any polynomial. Journal of the Association for
Computing Machinery, 40(1):95?142.
L. Pitt. 1989. Inductive inference, DFA?s, and com-
putational complexity. In Analogical and Induc-
tive Inference, number 397 in LNAI, pages 18?44.
Springer-Verlag, Berlin, Heidelberg.
Y. Sakakibara, S. Kobayashi, K. Sato, T. Nishino, and
E. Tomita, editors. 2006. Grammatical Infer-
ence: Algorithms and Applications, Proceedings of
ICGI ?06, volume 4201 of LNAI, Berlin, Heidelberg.
Springer-Verlag.
Y. Sakakibara. 1997. Recent advances of grammatical
inference. Theoretical Computer Science, 185:15?
45.
R. Solomonoff. 1960. A preliminary report on a gen-
eral theory of inductive inference. Technical Report
ZTB-138, Zator Company, Cambridge, Mass.
R. Solomonoff. 1964. A formal theory of inductive
inference. Information and Control, 7(1):1?22 and
224?254.
M. van Zaanen. 2000. ABL: Alignment-based learn-
ing. In Proceedings of COLING 2000, pages 961?
967. Morgan Kaufmann.
G. Wolf. 2006. Unifying computing and cognition.
Cognition research.
4
