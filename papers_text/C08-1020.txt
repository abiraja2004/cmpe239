Proceedings of the 22nd International Conference on Computational Linguistics (Coling 2008), pages 153?160
Manchester, August 2008
Hybrid processing for grammar and style checking
Berthold Crysmann?, Nuria Bertomeu?, Peter Adolphs?, Dan Flickinger?, Tina Klu?wer??
? Universita?t Bonn, Poppeldorfer Allee 47, D-53115 Bonn, {bcr,tkl}@ifk.uni-bonn.de
? Zentrum fu?r Allgemeine Sprachwissenschaft, Berlin, nuria.bertomeu@dfki.de
? DFKI GmbH, Berlin, {peter.adolphs,kluewer}@dfki.de
? CSLI, Stanford University, danf@csli.stanford.edu
Abstract
This paper presents an implemented hy-
brid approach to grammar and style
checking, combining an industrial pattern-
based grammar and style checker with bi-
directional, large-scale HPSG grammars
for German and English. Under this ap-
proach, deep processing is applied selec-
tively based on the error hypotheses of a
shallow system. We have conducted a com-
parative evaluation of the two components,
supporting an integration scenario where
the shallow system is best used for error de-
tection, whereas the HPSG grammars add
error correction for both grammar and con-
trolled language style errors.
1 Introduction
With the enormous amount of multilingual techni-
cal documentation produced by companies nowa-
days grammar and controlled language checking
(henceforth: style checking) is becoming an appli-
cation highly in demand. It is not only a helpful
tool for authors, but also facilitates the translation
of documents into foreign languages. Through the
use of controlled language by the authors, docu-
ments can be automatically translated more suc-
cessfully than with the use of free language. Style
checking should make authors aware of the con-
structions which should not be used, as well as
aiding in reformulating them. This can save a lot
of translation costs for companies producing large
amounts of mulitilingual documentation. Another
application of grammar and style checking is the
development of tutorial systems for learning a for-
eign language, as well as any kind of authoring sys-
tem for non-native speakers.
Previous approaches to grammar and style
checking can be divided into those based on fi-
nite state methods and those based on linguisti-
cally motivated grammars. To the former group be-
long e.g. the systems FLAG (Bredenkamp et al,
2000a; Bredenkamp et al, 2000b) and MultiLint
c
? 2008. Licensed under the Creative Commons
Attribution-Noncommercial-Share Alike 3.0 Unported li-
cense (http://creativecommons.org/licenses/by-nc-sa/3.0/).
Some rights reserved.
(Haller, 1996; Schmidt-Wigger, 1998). The basic
approach taken by such systems is the description
of error patterns through finite state automata. The
automata access the textual input enriched with
annotations from shallow linguistic analysis com-
ponents, such as part-of-speech tagging, morphol-
ogy and chunking. In FLAG, for instance, the an-
notation delivered by the shallow components is
integrated into a complex feature structure. Rules
are defined as finite state automata over feature
structures. The great advantages of such systems
are their robustness and efficient processing, which
make them highly suitable for real-life grammar
and style checking applications. However, since
shallow modules usually cannot provide a full syn-
tactic analysis, the coverage of these systems is
limited to error types not requiring a broader (non-
local) syntactic context for their detection. There-
fore their precision in the recognition of non-local
errors is not satisfactory.
Another short-coming of most shallow ap-
proaches to grammar checking is that they typi-
cally do not provide error correction: owing to the
absence of an integrated target grammar, genera-
tion of repairs cannot take the syntactic context
into account: as a result, some of the repairs sug-
gested by shallow systems are not globally well-
formed.
Grammar-based error checking constitutes the
other main strand in language checking technol-
ogy. These systems are typically equipped with a
model of target well-formedness. The main prob-
lem, when applied to the task of error checking
is that the sentences that are the focus of a gram-
mar checker are ideally outside the scope of the
grammar. To address this problem, grammar-based
checkers typically employ robustness techniques
(Ravin, 1988; Jensen et al, 1993; Douglas, 1995;
Menzel, 1998; Heinecke et al, 1998). The addi-
tion of robustness features, while inevitable for a
grammar-based approach, has the disadvantage of
considerably slowing down runtime performance.
Another issue with purely grammar-based check-
ing is related to the scarce distribution of actual
errors: thus, most effort is spent on the processing
of perfectly impeccable utterances. Finally, since
coverage of real-world grammars is never perfect,
these system also have difficulty to distinguish be-
153
tween extragrammatical and truly ungrammatical
sentences. Conversely, since grammars often over-
generate, a successful parse does not guarantee
wellformedness either.
One of the two major robustness techniques
used in the context of grammar-based language
checking are constraint relaxation (see e.g. (Dou-
glas, 1995; Menzel, 1998; Heinecke et al, 1998)),
which is typically realised by means of modifica-
tions to the parser (e.g. relaxation levels, robust uni-
fication). An alternative approach is error anticipa-
tion where errors are explicitly modelled by means
of grammar rules, so-called MAL-rules (McCoy et
al., 1996). This approach has already been inves-
tigated with an HPSG grammar, the ERG (Copes-
take and Flickinger, 2000), in the scenario of a tu-
torial system for language learning by (Bender et
al., 2004). We will follow this approach in the part
of our hybrid system based on deep processing.
Finite state methods and linguistically motivated
grammars are not only compatible, but also com-
plementary. Shallow methods are robust and effi-
cient, while deep processing based on grammars
provides high precision and detail. With the fo-
cussed application of deep analysis in finite state
based grammar and style checking systems, both
coverage and precision can be improved, while
the performance remains acceptable for real-world
applications. The combination of shallow and
deep components, hybrid processing, has already
been investigated in several modular architectures,
such as GATE (Gaizauskas et al, 1996), White-
board (Crysmann et al, 2002) and Heart-of-Gold
(Callmeier et al, 2004). Moreover, the improve-
ment in efficiency and robustness in deep process-
ing together with methods for its efficient applica-
tion makes the employment of deep processing in
real-world applications quite feasible. Hybrid pro-
cessing has been used for applications such as in-
formation extraction and question answering. But
to the best of our knowledge, the application of hy-
brid processing to grammar and style checking has
not been previously investigated.
In this paper, we present an implemented proto-
type of a hybrid grammar and style checking sys-
tem for German and English, called Checkpoint.
As the baseline shallow system we have taken
an industrial strength grammar and controlled lan-
guage style checker, which is based on the FLAG
technology. The deep processing platform used in
the project is the PET parser (Callmeier, 2000)
operating on wide-coverage English and German
HPSG grammars, the English Resource Grammar
(ERG) (Copestake and Flickinger, 2000) and the
German Grammar (GG) (Mu?ller and Kasper, 2000;
Crysmann, 2005; Crysmann, 2007), respectively.
The ERG and the GG have been developed for over
15 years and have already been used as deep pro-
cessing engines in the Heart-of-Gold hybrid pro-
cessing platform. We have developed an approach
for the selective application of deep processing
based on the error hypotheses of the shallow sys-
tem. Error detection in the deep system follows a
MAL-rule approach. In order to compare the ben-
efits of the selective application of deep process-
ing with its nonselective application, we have de-
veloped two scenarios: one parallel and one inte-
grated. While the parallel (nonselective) scenario
enables improvement in both recall and precision,
the integrated (selective) scenario only enables im-
provement in precision. However, the performance
of the integrated approach is much better. We have
also investigated several possibilities of integrating
deep processing in the selective scenario. Since the
HPSG grammars are suitable both for parsing and
generation, the system can successfully provide
both error corrections and paraphrases of stylistic
errors. For the purpose of investigation, evaluation
and statistical parse ranking, we have collected and
annotated several corpora of texts from technical
manuals. Finally, the approach has been evaluated
regarding error detection and performance.
2 The approach
Checkpoint has two main goals: (a) improving the
precision and recall of existing pattern-based gram-
mar and style checking systems for error types
whose detection requires considering more than
the strictly local syntactic context; and (b) gener-
ating error corrections for both grammar and style
errors. Accordingly, we have chosen to focus on
certain error types based on the difficulties of the
pattern-based system.
2.1 Anticipation of grammar errors
Grammar errors are detected by means of error
anticipation rules, or MAL-rules. MAL-rules ex-
actly model errors, so that erroneous sentences can
be parsed by the grammar. For this purpose we
enlarged two HPSG grammars for German, the
GG, and English, the ERG, with MAL-rules for
error types that were problematic for the pattern-
based shallow system. For German the following
phenomena have been handled: subject verb agree-
ment (subject verb agreement), NP internal agree-
ment (NP internal agreement), confusion of the
complementiser ?dass? with the homophonous pro-
noun or determiner ?das? (dass das), as well as
editing errors, such as local and non local repeti-
tion of words (repetitions). Here follow some ex-
amples (taken from the FLAG error corpus (Becker
et al, 2000), and die tageszeitung ?taz?, a German
newspaper):
(1) Auch in AOL gibt es Newsgroups, die
dieses Thema diskutiert [=diskutieren]. (FLAG)
Also in AOL are there newgroups, which (Pl)
this topic discuss (Sg).
?There are also newsgroups in AOL which dis-
cuss this topic.?
154
(2) Ich habe dem ganze [=ganzen] Geschehen
von meinem Sofa aus zugesehen. (FLAG)
I have the whole (wrong adj. form) events
from my couch out watched.
?I have watched the whole events from my
couch.?
(3) Vor allem im Su?den . . . fu?hrten [=haben] die
Liberalen der MR einen heftigen Wahlkampf
gegen die PS gefu?hrt. (taz, June 2007)
Above all in the south . . . led (past tense) the
liberals of the MR a hard election campaign
against the PS led (past participle).
?Particularly in the south, the liberals of the
MR led a hard election campaign against the
PS.?
For English, MAL-rules for errors concerning
subject verb agreement and missing determiners
were implemented.
2.2 Detection of stylistic errors
Stylistic errors are grammatical constructions that
are dispreferred in a particular register or type
of document. Sometimes certain constructions are
not desirable because machine translation systems
have problems dealing with them or because they
prevent easy understanding. In such cases a con-
trolled language approach is taken, where the prob-
lematic constructions are paraphrased into equiv-
alent less problematic constructions. Since these
constructions are grammatical they can be parsed
and, thus, detected. A generation of a paraphrase
is possible based on the semantic representation
obtained through parsing. For German the follow-
ing phenomena were handled: passive, future and
implicit conditional sentences, as in the following
example:
(4) Wartet man zulange, kriegt man keine Karten.
Waits one too long, gets one no tickets.
?If one waits too long one gets no tickets.?
Correct: Wenn man zulange wartet, kriegt
man keine Karten.
For English we focussed on the following phenom-
ena: passive (avoid passive), future (avoid future),
modal verbs (avoid modal verbs), subjunctive
(avoid subjunctive), stand-alone deictic pro-
nouns (use this that these those with noun) and
clause order in conditional sentences (condi-
tion must precede action).
2.3 Integrated vs. parallel scenarios
We have developed two integration scenarios: an
integrated one and a parallel one. In the parallel
scenario the pattern-based shallow system and the
deep processing parser run independently of each
other, that is, all sentences are parsed independent
of whether the shallow system has found an error
in them. In the integrated scenario the deep parser
is only called for those sentences where the shal-
low system has detected some error of the type
of those which Checkpoint is able to process (enu-
merated in subsection 2.1). The parallel scenario
allows improvement in the recall of the shallow
system, since Checkpoint can find errors that the
shallow system has not found. In the integrated
scenario, on the contrary, only the precision of the
shallow system can be improved, since Checkpoint
departs from the hypotheses of the shallow system.
The integrated scenario, however, promises to per-
form better in time than the parallel scenario, since
only a fraction of the whole text has to be scanned
for errors. Moreover, the performance of the inte-
grated system can also be improved with the se-
lective activation of the MAL-rules that model the
specific errors found by the shallow system. This
greatly reduces the enormous search space of the
parsing algorithms and the processing time result-
ing from the simultaneous processing of several
MAL-rules.
The integration of the shallow system and the
deep parser has been achieved through an exten-
sion of the PET parser that allows it to receive any
kind of input information and integrate this into
the chart. This preprocessing information can be,
for example, part-of-speech tagging, morphology
and lemmatisation, and already guides the parsing
process. It allows, for instance, recognition of un-
known words or identification of the correct lexi-
cal entry in cases where there is ambiguity. An in-
put format in terms of feature structures, the ?Fea-
ture Structure Chart? (FSC) format, has been devel-
oped for this purpose (Adolphs et al, 2008). The
shallow system, thus, produces a feature structure
chart, based on the information delivered by the
various shallow modules, and this information is
given as input to the PET deep parser, which reads
it and integrates it into the chart.
Error hypotheses from the shallow system are
passed to the deep parser by means of specific fea-
tures in the input feature structure (MAL-features)
of every input token in the FSC, permitting selec-
tive activation of MAL-rules. To this end, the origi-
nal FSC generated by the shallow system, which
contains information on the part-of-speech, the
lemma and morphological features such as num-
ber, gender and case, will be extended with MAL-
features. These MAL-features correspond to the
class of some MAL-rule in the grammar and have
boolean values. Signs in the grammar are speci-
fied for these MAL-features. MAL-rules are de-
fined such that they can only take as their daughters
edges with a positive value for the corresponding
MAL-feature. All information in the FSC input to-
kens is passed to the tokens in the chart through
a feature called TOKEN in lexical items. Thus, er-
ror hypotheses are passed from the input tokens to
the lexical items in the chart by stating that the val-
ues of the MAL-features in the lexical items are
155
equal to the values of the MAL-features in the cor-
responding input tokens in the FSC.
The values of the MAL-features are obtained
by checking the error report delivered by the shal-
low system. For certain errors detected by the shal-
low system there is a mapping to MAL-features.
The value of a MAL-feature will be set to ?+? if
the shallow system has found the corresponding
error. The rest of the MAL-features can be set to
?bool? if we want to allow other MAL-rules to
fire (which can improve recall, but increases am-
biguity and, consequently, has a negative effect on
performance). The values of the rest of the MAL-
features can also be set to ?-?, if we want to prevent
other MAL-rules from firing (which allows im-
provement only in precision, but limits ambiguity
and, consequently, results in better performance).
There is also the possibility of activating the rel-
evant MAL-features only for those tokens which
are, according to the shallow system, within the er-
ror span, instead of activating the MAL-features
for all tokens in the erroneous sentence.
2.4 Generation of corrections and
paraphrases
One of the advantages of using deep processing
in grammar and style checking is the possibility
of generating corrections and paraphrases which
obey the constraints imposed by the syntactic con-
text. Since the HPSG grammars that we are using
are suitable both for parsing and generation, this
is straightforward. Robust parsing delivers as out-
put a semantic representation in the Minimal Re-
cursion Semantics formalism (MRS) (Copestake
et al, 2006) of the sentence which can be used for
generation with the LKB (Carroll et al, 1999).
The MAL-rules directly assign well-formed se-
mantic representations from which a correct sur-
face string can be generated. In the case of stylis-
tic errors, transfer rules are used to generate the
desired paraphrase, using MRS-to-MRS mapping
rules modelled on the semantic transfer-based ma-
chine translation approach of (L?nning et al,
2004).
We identified two areas where generation of re-
pairs will actually provide a considerable added
value to a grammar checking system: first, for non-
native speakers, simple highlighting of the error
location is often insufficient, since the user may
not be familiar with the rules of the language. Sec-
ond, some areas, in particular stylistic ones may
involve considerable rearrangement of the entire
sentence. In these cases, generation of repairs and
paraphrases can reduce editing cost and also min-
imise the issue of editing errors associated with
non-local phenomena.
The generator and HPSG grammars we use are
able to provide a range of realisations for a given
semantic input. As a result, realisation ranking is
of utmost importance. In order to select repairs
which are both smooth and maximally faithful to
the input, modulo the error site, of course, we com-
bined two methods: a discriminative PCFG-model
trained on a generation treebank, enhanced by an
n-gram language model, cf. (Velldal and Oepen,
2005), and an alignment approach that chooses the
most conservative edit from a set of input realisa-
tions. As our similarity measure, we employed a
variant of BLEU score (NEVA), suggested in (Fors-
bom, 2003). The probabilistic ranking models we
trained achieve an exact match accuracy of 73%
for both English (Velldal and Oepen, 2005) and
German (as evaluated on the subset of TiGer the
error corpus was based on).
3 Error corpora
In order to learn more about the frequencies of the
different error types, to induce statistical models
that allow us to obtain the best parse in the do-
main of technical manuals and to evaluate our im-
plemented approach to grammar and style check-
ing, we collected and manually annotated corpora
from the domain of technical documentation.
Since errors in pre-edited text tend to be very
scarcely distributed, manual annotation is quite
costly. As a result, instance of certain well-known
error types cannot be tested in a greater variety of
linguistic environments. To overcome this problem,
we semi-automatically derived an additional error
corpus from a treebank of German.
English For purposes of evaluation in a real
world scenario, we constructed a corpus for En-
glish, consisting of 12241 sentences (169459
words) from technical manuals. The corpus was
semi-automatically annotated with several types of
grammar and style errors. For this purpose annota-
tion guidelines were developed, which contained
the description of the errors together with exam-
ples of each and their possible corrections. The an-
notation took place in two phases. First, we wanted
to find out about the precision of the shallow sys-
tem, so we ran the shallow system over the data.
This resulted in an annotation for each error found
consisting of the erroneous sentence, the error span
and the type of error. The annotators, who were na-
tive speakers, then decided whether the errors had
been correctly detected. In the second phase, we
aimed to create a gold standard, so as to be able to
evaluate both the shallow system and Checkpoint
regarding recall and precision. For this purpose, we
extracted the errors that had been annotated as cor-
rectly detected in the previous phase and the an-
notators only had to find the non-detected errors
in the rest of the corpus. For the latter, they also
marked the span and identified the error type.
Subsets of these two datasets were treebanked
with the corresponding HPSG grammars. We em-
ployed the treebanking methodology developed for
Redwoods (Oepen et al, 2002), which involved
156
first parsing a corpus and recording for each item
the alternative analyses (the parse forest) assigned
by the grammar, then manually identifying the cor-
rect analysis (if available) within that parse forest.
This approach provides both a gold standard syn-
tactic/semantic analysis for each parsed item, and
positive and negative training data for building an
accurate statistical model for automatic parse selec-
tion.
German For German, we pursued a complemen-
tary approach towards corpus construction. Here
the focus lay on creating a test and evaluation cor-
pus that provided instances of common error types
in a variety of linguistic contexts. Since manual
error annotation is highly costly, owing to scarce
error distributions in pre-edited text, we chose to
automatically derive an error corpus from an ex-
isting treebank resource. As for the error types, we
focussed on those errors which are arguably perfor-
mance errors, as e.g. missing final consonants in in-
flectional endings, the confusion of homophonous
complementiser and relative pronoun, or else, edit-
ing errors, such as local and non-local duplicates.
We introduced instances of errors in a sub-
corpus of the German TiGer treebank (Brants
et al, 2002), nicknamed TiG-ERR, consisting of
77275 words (5652 sentences) from newspaper
texts. All the sentences in this subcorpus were
parsable, so that an evaluation of Checkpoint in
the ideal situation of 100% coverage could be car-
ried out. The artificially introduced errors were
of the following types: subject verb agreement,
NP internal agreement, dass/das, and repetitions,
all of them already illustrated with examples in sec-
tion 2.1.
Additionally, we annotated a corpus of technical
documents for these error types to estimate the dis-
tribution of these error types in pre-edited text.
4 Error models
In order to construct a statistical parse-ranking
model which could determine the intended use of
a MAL-rule in the analysis of a sentence where the
grammar produced analyses both with and without
MAL-rules, the English treebank was constructed
using the version of the ERG which included the
MAL-rules. 4000 sentences from the English cor-
pus were presented to the parser, of which 86.8%
could be parsed with the ERG, and of these, the an-
notators found an intended analysis for 2500 sen-
tences, including some which correctly used MAL-
rules. From these annotations, a customised parse
selection model was computed and then used in
parsing all of the corpus, this time recording only
the one analysis determined to be most likely ac-
cording to this model. We also compared accu-
racy of error detection based on this new model
with the accuracy of a pre-existing parse-selection
model trained on tourism data for LOGON, and
confirmed that the new model indeed improved
over the old one.
For German, we have not created a specific sta-
tistical model yet, but, instead, we have used an ex-
isting parse selection model (Crysmann, 2008) and
combined it with some heuristics which enable us
to select the best error hypothesis. The heuristics
check for each parsed sentence whether there is an
analysis containing no MAL-rule. If there is one
and this is not ranked as the best parse, it is moved
to the first position in the parse list. As a result, we
can eliminate a high percentage of false alarms.
5 Evaluation results
We have evaluated the English and the German ver-
sions of Checkpoint against the corpora described
in section 3.
German For German we have taken as a test
corpus standard the TiG-ERR subcorpus contain-
ing the automatically introduced errors, and have
parsed all its sentences. The following table shows
the frequencies of the different types of handled er-
rors in the corpus of technical manuals, the FLAG
error corpus (Becker et al, 2000), and in the TiG-
ERR corpus. The electronic version of the FLAG
corpus consists of 14,492 sentences, containing
1,547 grammar or style errors.
ERROR TYPE MANUALS FLAG TiG-ERR
NP internal agr 119 180 2258
subject verb agr 17 63 748
dass/das 1 152 75
repetitions 19 n/a 2571
Table 1: Frequencies of the error types for German
The following charts show the values for recall
and precision for the shallow system and Check-
point. As you can see, Checkpoint improves the
recall for the error types subject verb agreement
and NP internal agreement, whereas the precision
remains more or less the same. For the error type
dass/das Checkpoint improves both recall and pre-
cision. For the error type repetitions, which is only
partially handled by the spell checker in the shal-
low system, Checkpoint reaches considerable re-
call and precision values.
Deep processing on average improves the recall
of the shallow system by 21% and the precision
remains equal at 0.83. According to the error fre-
quencies in the corpus of technical manuals, deep
processing would improve the recall of the shallow
system by only 1.7%, since the error types sub-
ject verb agreement, NP internal agreement and
dass/das only make up 6.57% of the total amount
of annotated errors. However, as we found out later,
the corpora of technical manuals consist of texts
that have already undergone correction, so the er-
rors are very sparse.
157
Figure 1: Checkpoint values for recall and preci-
sion for German
Figure 2: Values for recall and precision for the
shallow system for German
Through the MAL-rules the coverage of the GG
on the TiG-ERR corpus increased to 85% - 95%,
whereas without the MAL-rules the coverage was
10%. This 10% coverage included overgeneration
by the grammar, as well as sentences that, after the
automatic insertion of errors, still remained gram-
matical, although they didn?t express the intended
meaning any more.
The performance of the parallel and integrated
scenarios was compared. The ambiguity of the
MAL-rules, that is, the possibility of applying sev-
eral MAL-rules to a unique error, considerably de-
teriorates the performance when processing sen-
tences containing several errors. In a subcorpus
containing NP internal agreement errors, the aver-
age processing time per sentence increases from
8.3 seconds with the selective activation of MAL-
rules to 31.4 seconds with the activation of all
MAL-rules. Particularly the MAL-rules modeling
the error subject verb agreement are a source of
ambiguity. If these MAL-rules are only selectively
activated the average processing time per sentence
decreases to 14.9 seconds.
Finally, we have evaluated the performance of
the German grammar in the task of error correction,
using non-local duplicates and adjectival agree-
ment errors as a test bed. For these error types,
the German HPSG grammar generated repairs for
85.4% of the detected non-local duplicates and
90% of the detected agreement errors.
English For English we have only implemented
and evaluated the parallel scenario. The focus for
English evaluation was the recognition of those
stylistic errors whose correction requires a re-
structuring of the sentence, and the generation of
the corresponding paraphrases. The recognition of
such error types is not based on MAL-rules, but
on certain already existing rules in the grammar.
The approach was evaluated taking the manually
annotated English corpus of technical manuals as
a gold standard. The following table shows the fre-
quencies of the error types handled by Checkpoint.
ERROR TYPE OCCURRENCES
avoid future 404
avoid modal verbs 657
avoid passive 213
Table 2: Frequencies of the error types for English
The PET parser with the ERG reached 86.1%
coverage on the full corpus. The following charts
show the values for recall and precision for Check-
point and the shallow system.
Figure 3: Checkpoint values for recall and preci-
sion for English
Figure 4: Values for recall and precision for the
shallow system for English
As one can see, for the stylistic errors
avoid future and avoid modal verbs, Checkpoint
reaches values which, although relatively high, are
lower than the shallow system. In most cases a
paraphrase for these errors can be constructed,
so the improvement Checkpoint provides here is
the generation of corrections. For the error type
avoid passive the precision is not so high, which
is due in part to mistakes in the manual annotation.
The passive sentences found by Checkpoint are
actually passive sentences. However, these were
158
not annotated as passives, because the annotators
were told to annotate only those stylistic errors
for which a paraphrase was possible. The same
happens for stylistic errors like avoid subjunctive,
use this that these those with noun and condi-
tion must precede action. In principle, Check-
point is very good at finding these types of errors,
but we cannot yet present a reliable evaluation here,
since only those errors were annotated for which
a paraphrase was possible. This approach is rea-
sonable, since no error alarm should be produced
when there is no other possibility of expressing the
same. However, since we have not yet developed
a method which allows us to automatically distin-
guish those cases for which a paraphrase is possi-
ble from those for which none is, we would need
to annotate all occurrences of a phenomenon in the
corpus, and introduce a further annotation tag for
the paraphrase potential of the sentence.
Nevertheless, even if the grammar-based re-
search prototype cannot beat the industrial pattern-
based system in terms of f-measures, we still be-
lieve that the results are highly valuable in the con-
text of our integrated hybrid scenario: Since the
full reversibility of the ERG has already been estab-
lished independently by (Velldal and Oepen, 2005),
the combined system is able to generate error cor-
rection for a great proportion of the errors detected
by the shallow component. This includes 80% and
above for avoid future and avoid modal verbs.
6 Summary and conclusions
In this paper we have presented an implemented
approach to grammar and style checking based on
hybrid processing. The hybrid system has two com-
ponents: a shallow grammar and style checking
system based on the FLAG technology, and the
PET deep parser operating on linguistically moti-
vated grammars for German and English. The Ger-
man version of the hybrid system improves the re-
call and in certain cases the precision of the shal-
low system and generates error corrections. For
English, the hybrid system in most cases success-
fully generates paraphrases of sentences contain-
ing stylistic errors. Although we only have ex-
plored some of the possibilities of integrating deep
and shallow processing for the grammar and style
checking application, these results speak for the
feasibility of using hybrid processing in this task.
We have developed an integrated strategy which
forwards the output of the shallow system, includ-
ing both the output from several pre-processing
linguistic modules and the error hypotheses, as in-
put to the deep parser. This procedure not only im-
proves the robustness of the deep parser with the
recognition of unknown words and reduces ambi-
guity by instantiating only those lexical items con-
sistent with the hypotheses of the POS tagger or
the morphology; but it also allows the selective
application of grammar rules, which considerably
reduces the search space for parsing and, conse-
quently, improves performance. Based on the error
hypotheses of the shallow system, the selective ap-
plication of grammar rules is achieved by positing
features in the Feature Structure Chart whose par-
ticular values are a pre-condition for MAL-rules
to apply. The improvement in performance sug-
gests that this strategy can be extensible to parsing
in general based on pre-processing components.
Given the output of a chunker, for example, certain
syntactic configurations can already be excluded.
Having features whose values allow one to switch
off certain rules not compatible with these con-
figurations would considerably reduce the search
space.
On the other hand, we have run the two mod-
ules independently from each other to find out
how the recall of the shallow system can be im-
proved by deep processing. The fact that for sev-
eral error types, such as subject verb agreement
and NP internal agreement, recall can be consider-
ably improved suggests that, in order not to parse
all sentences, the shallow system should send an
error hypothesis to the deep system when finding
particular syntactic configurations which may indi-
cate the occurrence of such errors. In this way, such
error hypotheses, although not reliably detectable
by the shallow system alone, could be confirmed
or discarded with a focussed application of deep
processing, which would not be as resource con-
suming as parsing every sentence.
One of the results of the experiment has been
an on-line demonstration system. The running sys-
tem shows that the different modules can be eas-
ily combined with each other. Our hybrid approach,
however, is generic and portable. Although imple-
mented for our specific baseline system, it can in
principle be used with other shallow systems.
Acknowledgements
The research reported in this paper has been car-
ried out as part of the DFKI project Checkpoint,
running from February until November 2007. The
project was funded by the ProFIT program of the
Federal State of Berlin and the EFRE program of
the European Union.
References
Adolphs P., S. Oepen, U. Callmeier, B. Crysmann, and
B. Kiefer. 2008. Some Fine Points of Hybrid Natural
Language Parsing. Proceedings LREC-2008, Mar-
rakech, Morocco.
Becker M., A. Bredenkamp, B. Crysmann, and J. Klein.
2003. Annotation of error types for a German news-
group corpus. In A. Abeille?, editor, Treebanks.
Building and Using Parsed Corpora, number 20 in
Text, Speech And Language Technology. Kluwer,
Dordrecht.
159
Bender, E. M., D. Flickinger, S. Oepen, A. Walsh,
and T. Baldwin. 2004. Arboretum: Using a preci-
sion grammar for grammar checking in call. In In-
STIL/ICALL symposium 2004. NLP and speech tech-
nologies in advanced language learning systems.
Venice, Italy.
Brants, T., S. Dipper, S. Hansen, W. Lezius, and G.
Smith. 2002. The TIGER Treebank. In Proceedings
of the Workshop on Treebanks and Linguistic Theo-
ries. Sozopol.
Bredenkamp, A., B. Crysmann and M. Petrea. 2000.
Looking for errors: A declarative formalism for
resource-adaptive language checking. In Proceed-
ings LREC-2000. Athens, Greece.
Bredenkamp, A., B. Crysmann and M. Petrea. 2000.
Building multilingual controlled language perfor-
mance checkers. In Proceedings of the CLAW 2000.
Seattle, WA.
Callmeier, U., A. Eisele, U. Scha?fer, and M. Siegel.
2004. The Deepthought core architecture frame-
work. In Proceedings of LREC-2004, 1205?1208,
Lisbon, Portugal.
Callmeier, Ulrich. 2000. PET ? a platform for ex-
perimentation with efficient HPSG processing tech-
niques. Natural Language Engineering 6(1):99?
108.
Carroll, John and Ann Copestake and Dan Flickinger
and Victor Poznanski. 1999. An efficient chart gen-
erator for semi-lexicalist grammars. Proceedings of
ENLG, pp. 86?95.
Copestake, A., and D. Flickinger. 2000. An open-
source grammar development environment and
broad-coverage english grammar using HPSG. In
Proceedings LREC-2000. Athens, Greece.
Copestake, A., D. Flickinger, C. Pollard, and I. Sag.
2006. Minimal recursion semantics: an introduction.
Research on Language and Computation 3(4):281?
332.
Crysmann, B., A. Frank, B. Kiefer, S. Mu?ller, G. Neu-
mann, J. Piskorski, U. Scha?fer, M. Siegel, H. Uszko-
reit, F. Xu, M. Becker, and H.-U. Krieger. An inte-
grated architecture for shallow and deep processing.
In Proceedings of ACL 2002, University of Pennsyl-
vania, Philadelphia, 2002.
Crysmann B. 2005. Relative clause extraposition in
German: An efficient and portable implementation.
Research on Language and Computation, 3(1):61?
82.
Crysmann B. 2007 Local ambiguity packing and dis-
continuity in German. In T. Baldwin, M. Dras,
J. Hockenmaier, T. H. King, and G. van Noord, ed-
itors, Proceedings of the ACL 2007 Workshop on
Deep Linguistic Processing, pages 144?151, Prague,
Czech Republic.
Crysmann B. 2008. Parse Selection with a German
HPSG Grammar. In S. Ku?bler and G. Penn, editors,
Proceedings of the ACL 2008 Workshop on Parsing
German (PaGe), pages 9?15, Columbus, Ohio, USA.
Douglas, S. 1995. Robust PATR for error detec-
tion and correction. In A. Schoeter and C. Vogel
(Eds.)Nonclassical feature systems, Vol. 10, pp. 139-
156. Centre for Cognitive Science, University of Ed-
inburgh.
Forsbom, E. 2003. Training a Super Model Look-
Alike. Proceedings of the MT Summit IX Workshop
?Towards Systemizing MT Evaluation?, pp. 29-36.
Gaizauskas, R., H. Cunningham, Y. Wilks, P. Rodgers
and K. Humphreys. 1996. GATE: An environment
to support research and development in natural lan-
guage engineering. In Proceedings of the 8th IEEE
international conference on tools with artificial in-
telligence. Toulouse, France.
Jensen, K., G. E., Heidorn and S. D. Richardson (Eds.).
1993. Natural language processing: The PLNLP ap-
proach. Boston - Dordrecht - London.
Haller, J. 1996. MULTILINT: A technical documenta-
tion system with multilingual intelligence. In Trans-
lating and the computer 18. London.
Heinecke, J., J. Kunze, W. Menzel, and I. Schroeder.
1998. Eliminative parsing with graded constraints.
In Proceedings ACL/Coling 1998, Vol. I, pp. 526-
530. Universite de Montreal, Montreal, Quebec,
Canada.
L?nning J. T. , S. Oepen, D. Beermann, L. Hellan, J.
Carroll, H. Dyvik, D. Flickinger, J. B. Johannessen,
P. Meurer, T. Nordga?rd, V. Rose?n and E. Velldal.
2004. LOGON. A Norwegian MT effort. In Pro-
ceedings of the Workshop in Recent Advances in
Scandinavian Machine Translation. Uppsala, Swe-
den.
McCoy, K. F., C. A. Pennington, and L. Z. Suri. 1996.
English error correction: A syntactic user model
based on principled ?mal-rule? scoring. In Proceed-
ings of UM-96, the Fifth International Conference on
User Modeling, pp. 59-66. Kona, Hawaii.
Menzel, W. 1998. Constraint satisfaction for robust
parsing of natural language. In Theoretical and Ex-
perimental Artificial Intelligence, 10 (1), 77-89.
Mu?ller, S., and W. Kasper. 2000. HPSG analysis of
German. In W. Walster (Ed.), Verbmobil: Foun-
dations of Speech-to-Speech Translation, 238?253
Springer, Berlin.
Oepen, S., K. Toutanova, S. Shieber, C. Manning, D.
Flickinger and T Brants. 2002. The LinGO Red-
woods Treebank. Motivation and Preliminary Appli-
cations. In Proceedings of COLING 2002. Taipei,
Taiwan.
Ravin, Y. 1998. Grammar errors and style weaknesses
in a text-critiquing system. In IEEE Transactions on
Communication, 31 (3)
Schmidt-Wigger, A. 1998. Grammar and style check-
ing for German. In Proceedings of CLAW 98. Pitts-
burgh, PA.
Velldal, E. and S. Oepen. 2005. Maximum entropy
models for realization ranking. In Proceedings of
the 10th MT-Summit (X), Phuket, Thailand.
160
