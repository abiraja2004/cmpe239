Proceedings of the GEMS 2011 Workshop on Geometrical Models of Natural Language Semantics, EMNLP 2011, pages 52?61,
Edinburgh, Scotland, UK, July 31, 2011. c?2011 Association for Computational Linguistics
Assessing Interpretable, Attribute-related Meaning Representations for
Adjective-Noun Phrases in a Similarity Prediction Task
Matthias Hartung and Anette Frank
Computational Linguistics Department
Heidelberg University
{hartung,frank}@cl.uni-heidelberg.de
Abstract
We present a distributional vector space model
that incorporates Latent Dirichlet Allocation
in order to capture the semantic relation hold-
ing between adjectives and nouns along inter-
pretable dimensions of meaning: The meaning
of adjective-noun phrases is characterized in
terms of ontological attributes that are promi-
nent in their compositional semantics. The
model is evaluated in a similarity prediction
task based on paired adjective-noun phrases
from the Mitchell and Lapata (2010) bench-
mark data. Comparing our model against a
high-dimensional latent word space, we ob-
serve qualitative differences that shed light
on different aspects of similarity conveyed
by both models and suggest integrating their
complementary strengths.
1 Introduction
This paper offers a comparative evaluation of two
types of accounts to the compositional meaning of
adjective-noun phrases. This comparison is embed-
ded in a similarity judgement task that determines
the semantic similarity of pairs of adjective-noun
phrases. All models we consider establish the sim-
ilarity of adjective-noun pairs by measuring simi-
larity between vectors representing the meaning of
the individual adjective-noun phrases. However, the
models we investigate differ in the type of interpreta-
tion they assign to adjectives, nouns and the phrases
composed from them.
One type of approach is represented by the clas-
sical vector space model (VSM) of Mitchell and La-
pata (2010; henceforth: M&L). It represents the se-
mantics of adjective-noun phrases in latent seman-
tic space, based on dimensions defined by bags of
context words. This classical model will be com-
pared against a compositional analysis of adjective-
noun phrases that represents adjectives and nouns
along interpretable dimensions of meaning, i.e. dis-
crete ontological attributes such as SIZE, COLOR,
SPEED, WEIGHT. Here, lexical vectors for adjec-
tives and nouns define possible attribute meanings as
component values; vector composition is intended
to elicit those attributes that are prominent in the
meaning of the whole phrase. For instance, a com-
posed vector representation of the phrase hot pep-
per is expected to yield high component values on
the dimensions TASTE and SMELL, rather than TEM-
PERATURE. The underlying relations between ad-
jectives and nouns, respectively, and the attributes
they denote is captured by way of latent semantic in-
formation obtained from Latent Dirichlet Allocation
(LDA; Blei et al (2003)). Thus, we treat attributes
as an abstract meaning layer that generalizes over
latent topics inferred by LDA and utilize this inter-
pretable layer as the dimensions of our VSM.
This approach has been shown to be effective
in an attribute selection task (Hartung and Frank,
2011), where the goal is to predict the most promi-
nent attribute(s) ?hidden? in the compositional se-
mantics of adjective-noun phrases. In this paper,
our main interest is to assess the potential of mod-
eling adjective semantics in terms of discrete, inter-
pretable attribute meanings in a similarity judgement
task, as opposed to a representation in latent seman-
tic space that is usually applied to tasks of this kind.
52
For this purpose, we rely on the evaluation data
set of M&L which serves as a shared benchmark in
the GEMS 2011 workshop. Their similarity judge-
ment task, being tailored to measuring latent simi-
larity, represents a true challenge for an analysis fo-
cused on discrete ontological attributes.
Our results show that the latent semantic model
of M&L cannot be beaten by an interpreted anal-
ysis based on LDA topic models. However, we
show substantial performance improvements of the
interpreted analysis in specific settings with adapted
training and test sets that enable focused compar-
ison. An interesting outcome of our investiga-
tions is that ? using an interpreted LDA analysis of
adjective-noun phrases ? we uncover divergences in
the notions of similarity underlying the judgement
task that go virtually unnoticed in a latent semantic
VSM, while they need to be clearly distinguished in
models focused on interpretable representations.
The paper is structured as follows: After a brief
summarization of related work, Section 3 introduces
Controled LDA, a weakly supervised extension to
standard LDA, and explains how it can be utilized to
inject interpretable meaning dimensions into VSMs.
In Section 4, we describe the parameters and exper-
imental settings for comparing our model to M&L?s
word-based latent VSM in a similarity prediction
task. Section 5 presents the results of this experi-
ment, followed by a thorough qualitative analysis of
the specific strengths and weaknesses of both mod-
els in Section 6. Section 7 concludes.
2 Related Work
Recent work in distributional semantics has engen-
dered different perspectives on how to character-
ize the semantics of adjectives and adjective-noun
phrases.
Almuhareb (2006) aims at capturing the seman-
tics of adjectives in terms of attributes they denote
using lexico-syntactic patterns. His approach suf-
fers from severe sparsity problems and does not ac-
count for the compositional nature of adjective-noun
phrases, as it disregards the meaning contributed by
the noun. It is therefore unable to perform disam-
biguation of adjectives in the context of a noun.
Baroni and Zamparelli (2010) and Guevara
(2010) focus on how best to represent composition-
ality in adjective-noun phrases considering differ-
ent types of composition operators. These works
adhere to a fully latent representation of mean-
ing, whereas Hartung and Frank (2010) assign sym-
bolic attribute meanings to adjectives, nouns and
composed phrases by incorporating attributes as di-
mensions in a compositional VSM. By holding the
attribute meaning of adjectives and nouns in dis-
tinct vector representations and combining them
through vector composition, their approach im-
proves on both weaknesses of Almuhareb?s work.
However, their account is still closely tied to Al-
muhareb?s pattern-based approach in that counts of
co-occurrence patterns linking adjectives and nouns
to attributes are used to populate the vector represen-
tations. These, however, are inherently sparse. The
resulting model therefore still suffers from sparsity
of co-occurrence data.
Finally, Latent Dirichlet Allocation, originally de-
signed for tasks such as text classification and doc-
ument modeling (Blei et al, 2003), found its way
into lexical semantics. Ritter et al (2010) and
?O Se?aghdha (2010), e.g., model selectional restric-
tions of verb arguments by inducing topic distribu-
tions that characterize mixtures of topics observed in
verb argument positions. Mitchell and Lapata (2009,
2010) were the first to use LDA-inferred topics as
dimensions in VSMs.
Hartung and Frank (2011) adopt a similar ap-
proach, by embedding LDA into a VSM for
adjective-noun meaning composition, with LDA
topics providing latent variables for attribute mean-
ings. That is, contrary to M&L, LDA is used to
convey information about interpretable semantic at-
tributes rather than latent topics. In fact, Hartung
and Frank (2011) are able to show that ?injecting?
topic distributions inferred from LDA into a VSM
alleviates sparsity problems that persisted with the
pattern-based VSM of Hartung and Frank (2010).
Baroni et al (2010) highlight two strengths of
VSMs that incorporate interpretable dimensions of
meaning: cognitive plausibility and effectiveness in
concept categorization tasks. In their model, con-
cepts are characterized in terms of salient proper-
ties and relations (e.g., children have parents, grass
is green). However, their approach concentrates on
nouns. Open questions are (i) whether it can be ex-
tended to further word classes, and (ii) whether the
53
interpreted meaning layers are interoperable across
word classes, to cope with compositionality. The
present paper extends their work by offering a test
case for an interpretable, compositional VSM, ap-
plied to adjective-noun composition with attributes
as a shared meaning layer. Moreover, to our knowl-
edge, we are the first to expose such a model to a
pairwise similarity judgement task.
3 Attribute Modeling based on LDA
3.1 Controled LDA
This section introduces Controled LDA (C-LDA), a
weakly supervised variant of LDA. We use C-LDA
to model attribute information that pertains to ad-
jectives and nouns individually. This information is
?injected? into a vector-space framework as a ba-
sis for computing the attributes that are prominent
in compositional adjective-noun phrases.
In its original statement, LDA is a fully unsu-
pervised process that estimates topic distributions
over documents ?d and word-topic distributions ?t
with topics represented as hidden variables. Esti-
mating these parameters on a document collection
yields topic proportions P (t|d) and topic distribu-
tions P (w|t) that can be used to compute a smooth
distribution P (w|d) as in (1), where t denotes a la-
tent topic, w a word and d a document in the corpus.
P (w|d) =
?
t
P (w|t)P (t|d) (1)
While the generative story underlying both mod-
els is identical, C-LDA extends standard LDA by
?implicitly? taking supervised category information
into account. This allows for linking latent topics to
interpretable semantic attributes. The idea is to col-
lect pseudo-documents in a controlled way such that
each document conveys semantic information about
one specific attribute. The pseudo-documents are
selected along syntactic dependency paths linking
the respective attribute noun to meaningful context
words (adjectives and nouns). A corpus consisting
of the two sentences in (2), e.g., yields a pseudo-
document for the attribute noun SPEED containing
car and fast.
(2) What is the speed of this car? The machine
runs at a very fast speed.
Note that, though we are ultimately interested
in triples between attributes, adjectives and nouns
that are conveyed by the compositional semantics
of adjective-noun phrases, C-LDA is only exposed
to binary tuples between attributes and adjectives or
nouns, respectively. This is in line with the findings
of Hartung and Frank (2010), who obtained sub-
stantial performance improvements by splitting the
triples into separate binary relations.
3.2 Embedding C-LDA into a VSM
The main difference of C-LDA compared to stan-
dard LDA is that the estimated topic proportions
P (t|d) of the former will be highly attribute-
specific, and similarly so for the topic distributions
P (w|t). We experiment with two variants of VSMs
that differ in the way they integrate attribute infor-
mation inferred from C-LDA, denoted as C-LDA-A
and C-LDA-T.
In C-LDA-A, the dimensions of the space are in-
terpretable attributes. The vector components re-
lating a target word w to an attribute a are set to
P (w|a). This probability is obtained from C-LDA
by constructing the pseudo-documents as distribu-
tional fingerprints of the respective attribute, as de-
scribed in Section 3.1 above:
P (w|a) ? P (w|d) =
?
t
P (w|t)P (t|d) (3)
C-LDA-T capitalizes on latent topics as dimen-
sions; the vector components are set to the topic pro-
portions P (w|t) as directly obtained from C-LDA.1
4 Parameters and Experimental Settings
Data. Our experiments are based on the adjective-
noun section of M&L?s 2010 evaluation data set2. It
consists of 108 pairs of adjective-noun phrases that
were rated for similarity by human judges.
1The ?topics as dimensions? approach has also been used
by Mitchell and Lapata (2010) for dimensionality reduction. In
their word space model, however, this setting leads to a decrease
in performance on adjective-noun phrases. Therefore, we do
not compare ourselves to this instantiation of their model in this
paper.
2Available from: http://homepages.inf.ed.ac.
uk/s0453356/share
54
Models. We contrast the two LDA-based models
(i, ii) C-LDA-A and C-LDA-T with two standard
VSMs: (iii) a re-implementation of the latent VSM
of M&L and (iv) a dependency-based VSM (De-
pVSM) which relies on dependency paths that con-
nect the target elements and attribute nouns in local
contexts. The paths are identical to the ones used
for constructing pseudo-documents in (i) and (ii).
Thus, DepVSM relies on the same information as
C-LDA-A and C-LDA-T, without capitalizing on the
smoothing power provided by LDA.
In the C-LDA models, we experiment with several
topic number settings. Depending on the number of
attributes |A| contained in the training material (see
below), we train one model instance for each topic
number in the range from 0.5 ? |A| to 2 ? |A|. For our
LDA implementations, we use MALLET (McCal-
lum, 2002). We run 1000 iterations of Gibbs sam-
pling with hyperparameters set to the default values.
Training data. For C-LDA-A, C-LDA-T and De-
pVSM we apply two different training scenarios:
In the first setting, we collect pseudo-documents
instantiating 262 attribute nouns that are linked to
adjectives by an attribute relation in WordNet
(Fellbaum, 1998). The topic distributions induced
from this data cover the broadest space of attribute
meanings we could produce from WordNet3. In a
second setting, we assume the presence of an ?or-
acle? that confines the training data to a subset of
33 attribute nouns that are linked to those adjectives
that actually occur in the M&L test set, to allow for
a focused evaluation. In both C-LDA variants, all
adjectives and nouns occurring at least five times in
the pseudo-documents become target elements in the
VSM. The pseudo-documents are collected along
dependency paths extracted from section 2 of the
pukWaC corpus (Baroni et al, 2009). The same set-
tings are used for training the DepVSM model.
As the M&L model is not intended to reflect at-
tribute meaning, the training data for this model re-
mains constant. Like M&L, we set the target el-
ements of this model to all types contained in the
complete evaluation data set (including nouns, ad-
3Note that in Hartung and Frank (2011) only a subset of
these attributes, mainly those characterized as properties in
WordNet, could be successfully modeled, at overall moderate
performance levels.
jectives and verbs) and select the 2000 context words
that co-occur most frequently with these targets in
pukWaC 2 as the dimensions of the space.
Filters on test set. Given the different types of
?semantic gist? of the models described above, we
expect that the LDA models perform best on those
test pairs that involve attributes known to the model.
To test this expectation, we compile a restricted test
set containing 43 pairs (adj1 n1, adj2 n2) where
both adj1 and adj2 bear an attribute meaning accord-
ing to WordNet.
Composition operators. In our experiments, we
use a subset of the operators proposed by Mitchell
and Lapata (2010) to obtain a compositional repre-
sentation of adjective-noun phrases from individual
vectors: vector multiplication (?; best operator in
M&L?s experiments on adjective-noun phrases) and
vector addition (+). Besides, in order to assess the
contribution of individual vectors in the composi-
tion process, we experiment with two ?composition
surrogates? by taking the individual adjective (ADJ-
only) or noun vector (N-only) as the result of the
composition process.
Evaluating the models. The models described
above are evaluated against the human similarity
judgements data provided by Mitchell and Lapata
(2010) as follows: We compute the cosine similar-
ity between the composed vectors representing the
adjective-noun phrases in each test pair. Next, we
measure the correlation between the model scores
and the human judgements in terms of Spearman?s
?, where each human rating is treated as an indi-
vidual data point. The correlation coefficient finally
reported is the average over all instances4 of one
model. For completeness, we also report the corre-
lation score of the best model instance and the stan-
dard deviation over all model instances.
5 Discussion of Results
Results on complete test set. Table 1 displays the
results achieved by the VSMs based on C-LDA and
4In fact, only those model instances resulting in a significant
correlation with the human judgements (p < 0.05) are taken
into account. This way, we eliminate both inefficient and overly
optimistic model instances.
55
+ ? ADJ-only N-only
avg best ? avg best ? avg best ? avg best ?
26
2
at
tr
s C-LDA-A 0.19 0.25 0.05 0.15 0.20 0.04 0.17 0.23 0.04 0.11 0.23 0.06
C-LDA-T 0.19 0.24 0.02 0.28 0.31 0.02 0.20 0.24 0.02 0.18 0.24 0.03
M&L 0.21 0.34 0.19 0.27
DepVSM -0.09 -0.09 -0.14 -0.08
33
at
tr
s C-LDA-A 0.23 0.27 0.02 0.21 0.24 0.01 0.27 0.29 0.01 0.17 0.22 0.02
C-LDA-T 0.21 0.28 0.03 0.14 0.23 0.04 0.22 0.27 0.03 0.10 0.21 0.06
M&L 0.21 0.34 0.19 0.27
DepVSM 0.21 0.20 0.27 0.19
Table 1: Correlation coefficients (Spearman?s ?) for different training sets, complete test set
+ ? ADJ-only N-only
avg best ? avg best ? avg best ? avg best ?
26
2
at
tr
s
(fi
lte
re
d) C-LDA-A 0.22 0.31 0.07 0.12 0.30 0.11 0.18 0.30 0.08 0.17 0.28 0.07C-LDA-T 0.25 0.30 0.03 0.26 0.35 0.04 0.24 0.29 0.04 0.19 0.23 0.04
M&L 0.38 0.40 0.24 0.43
DepVSM 0.08 -0.09 0.06 -0.07
33
at
tr
s
(fi
lte
re
d) C-LDA-A 0.29 0.32 0.02 0.31 0.36 0.02 0.34 0.38 0.02 0.09 0.18 0.04
C-LDA-T 0.26 0.36 0.05 0.14 0.30 0.09 0.28 0.38 0.07 0.03 0.18 0.08
M&L 0.38 0.40 0.24 0.43
DepVSM 0.34 0.32 0.35 0.19
Table 2: Correlation coefficients (Spearman?s ?) for different training sets and filtered test sets
the M&L word space model on the full adjective-
noun test set. The table is split into an upper and a
lower part containing the different results obtained
from training on 262 and 33 attributes, respectively.
Each multicolumn shows the performance achieved
by one of the different composition operators pre-
sented in Section 4, as well as results obtained from
predicting similarity on the basis of raw adjective
(ADJ-only) and noun (N-only) vectors.
First and foremost, we observe best overall per-
formance for the M&L model when combined with
multiplicative vector composition (? = 0.34), even
though the best results for this setting reported in
M&L (2010) (? = 0.46) cannot be reproduced.
Nevertheless, the C-LDA models show a consid-
erable performance improvement when the training
material is constrained to appropriate attributes by
an oracle (cf. Sect. 4). Another interesting obser-
vation is that the individual adjective and noun vec-
tors produced by M&L and the C-LDA models, re-
spectively, show diametrically opposed performance
(cf. 3rd and 4th multicolumn in Table 1).
More in detail, C-LDA-A achieves relative im-
provements across all composition operators when
comparing the 33-ATTR to the 262-ATTR setting.
Contrasting C-LDA-A and C-LDA-T, the latter is
clearly more effective on the larger training set, es-
pecially in combination with the ? operator (? =
0.28). This might be due to the intersective character
of multiplication, which requires densely populated
components in both the adjective and the noun vec-
tor. This requirement meets best with the C-LDA-T
model as long as the number of topics provided is
large. The + operator, on the other hand, combines
better with C-LDA-A. In the 33-ATTR setting, this
combination even outperforms vector addition un-
der the M&L model. Generally, C-LDA-A performs
better on the smaller training set, where it leaves C-
LDA-T behind in every configuration. This high-
lights that an interpretable, attribute-related meaning
layer generalizing over latent topics can be effective
if a small, discriminative set of attributes is available
for training. Otherwise, C-LDA-T seems to be more
powerful for the present similarity judgement task.
Analyzing the performance of the composition
surrogates ADJ-only and N-only in the restricted 33-
ATTR setting reveals an interesting twist in the qual-
ity of adjective vs. noun vectors: While M&L gen-
56
erally yields better results on noun vectors alone (as
compared to adjective vectors), C-LDA-A clearly
outperforms M&L in predicting similarity based on
adjective meanings in isolation. In this configura-
tion, M&L is also outperformed by the (very strong)
dependency baseline which is, in turn, only slightly
beaten by C-LDA-A in its best configuration. In
fact, it is the ADJ-only surrogate under the C-LDA-
A model in its best setting (? = 0.29) that comes
closest to the overall best-performing M&L model.
This indicates that modeling attributes in the latent
semantics of adjectives can be informative for the
present similarity prediction task. The poor quality
of the noun vectors, however, limits the overall per-
formance of the C-LDA models considerably.
Results on filtered test set. As can be seen from
Table 2, our expectation that C-LDA-A and C-
LDA-T should benefit from limiting the test set to
instances related to attribute meanings is largely
met. We observe overall improvement of correla-
tion scores; also the characteristics of the individual
models observed in Table 1 remain unchanged.
However, M&L benefits from filtering as well,
and in some configurations, e.g. under vector addi-
tion, the relative improvement is even bigger for the
latent word space models. This shows that M&L
and our C-LDA models are not fully complemen-
tary, i.e. some aspects of attribute similarity are also
covered by latent models.
Neverthelesss, the adjective/noun twist observed
for individual vector performance is corroborated:
C-LDA-A?s adjective vectors outperform those of
M&L by ten points (33 attributes, filtered setting;
compared to six points on the complete test set),
whereas the performance of the noun vectors drops
even further. Again, the DepVSM baseline performs
very strong on the adjective vectors in isolation,
which clearly underlines that our dependency-based
context selection procedure is effective. On the other
hand, the individual noun vectors produced by M&L
even yield the best overall result on the filtered test
data, thus outperforming both composition methods.
Differences in adjective and noun vectors. In or-
der to highlight qualitative differences of the indi-
vidual adjective and noun vectors across the various
models, we analyzed their informativeness in terms
of entropy. The intuition is as follows: The lower the
262 attrs 33 attrs
avg ? avg ?
C-LDA-A (JJ) 1.20 0.48 0.83 0.27
C-LDA-A (NN) 1.66 0.72 1.23 0.46
C-LDA-T (JJ) 0.92 0.04 0.50 0.04
C-LDA-T (NN) 1.10 0.06 0.60 0.02
M&L (JJ) 2.74 0.91 2.74 0.91
M&L (NN) 2.96 0.33 2.96 0.33
DepVSM (JJ) 0.48 0.61 0.65 0.32
DepVSM (NN) 0.38 0.67 0.96 0.21
Table 3: Average entropy of individual adjective and
noun vectors across different models
entropy exhibited by a vector, the more pronounced
are its most prominent components. On the contrary,
high entropy indicates a rather broad, less accen-
tuated distribution of the probability mass over the
vector components (cf. Hartung and Frank (2010)).
The results of this analysis are displayed in Ta-
ble 3. With regard to the C-LDA models, we observe
lower entropy in adjective vectors compared to noun
vectors across both training settings, which corre-
sponds to their relative performance in the similar-
ity prediction task. This indicates that C-LDA cap-
tures the relation between adjectives and attributes
in a very pronounced way, and that this information
proves valuable for similarity prediction.
The DepVSM model shows inconsistent results
with regard to the different training sets. While the
pattern observed for the C-LDA models is confirmed
on the limited training set, training on the full set of
262 attributes results in more accentuated noun vec-
tors. Given the huge standard deviations, however,
we suppose that these figures are not very reliable.5
The correspondence between lower entropy and
better performance we could observe for C-LDA-
A and C-LDA-T is, however, not confirmed by the
M&L word space model, as their adjective vectors
exhibit lower entropy on average6, while they per-
sistently underperform relative to the noun vectors
5In fact, unlike the C-LDA models and M&L, DepVSM
faces severe sparsity problems on the large training set, as be-
comes evident from the average total frequency mass per vector:
Noun vectors accumulate 704 cooccurrence counts over 262 di-
mensions on average, while adjective vectors are populated with
1555 counts on average (652 vs. 1052 counts over 33 dimen-
sions on the small training set).
6The entropy values of M&L are not directly comparable to
those of the C-LDA models and DepVSM; M&L entropies are
generally higher due to the higher dimensionality of the model.
57
(cf. Tables 1 and 2). Note, however, that the en-
tropy values of individual adjective vectors disperse
widely around the mean (?=0.91). This suggests
that a considerable proportion of M&L?s adjective
vectors is rather evenly distributed.
Analyzing the individual performance of noun
vectors in terms of entropy is less conclusive. While
the noun vectors consistently exhibit relatively high
entropy, their varying performance across the dif-
ferent models cannot be explained. We hypothesize
that the characteristics of the different models might
be more decisive instead: Apparently, attributes as
an abstract meaning layer are appropriate for mod-
eling the contribution of adjectives to phrase simi-
larity, whereas the contribution of nouns seems to
be captured more effectively by M&L-like distribu-
tions along bags of context words.
6 Error Analysis
In order to gain deeper insight into the strengths
and weaknesses of C-LDA-A and M&L, we
extracted the ten most similar/dissimilar pairs
(+Sim/?SimC-LDA-A/M&L; cf. Table 4) according
to system predictions, as well as the ten pairs
on which system and human raters show high-
est/lowest agreement in terms of similarity scores
(+Agr/?AgrC-LDA-A/M&L; cf. Table 5), for the best-
performing model instance of C-LDA-A and M&L
in the unfiltered 33-ATTR setting, respectively.
All pairs in +SimC-LDA-A and +SimM&L exhibit
matching attributes. +SimC-LDA-A contains two pairs
involving contrastive attribute values (vs. four in
+SimM&L): long period ? short time, hot weather
? cold air. Obviously, C-LDA-A is not prepared to
recognize this type of dissimilarity, as it does not
model the semantics and orientation of attribute val-
ues, and so assigns overly optimistic similarity rates.
While this deficiency is explained for C-LDA, it is
unexpected for M&L, where in +SimM&L we find
pairs such as old person ? elderly lady with similar-
ity ratings that are almost identical to antonymous
pairs discussed above, such as high price ? low cost.
We further observe a striking difference regarding
overall similarity ratings in both systems: We find
high scores of 0.88 on average within +SimC-LDA-A,
as opposed to 0.52 in +SimM&L. The difference
is less marked regarding ?Sim. Similarly, we
find overall low average similarity rates (0.2) in
+AgrM&L, whereas +AgrC-LDA-A achieves somewhat
higher rates (0.27). While all examples point to-
wards dissimilarity, C-LDA-A shows more discrim-
inative power, as exemplified by hot weather ? el-
derly lady (lowest rating) vs. central authority ? lo-
cal office (highest rating). This suggests that, over-
all, C-LDA-A disposes of a more discriminative se-
mantic representation to judge similarity ? which of
course can also go astray.
The disagreement set ?AgrC-LDA-A contains the
antonymous adjectives with high similarity ratings
from +SimC-LDA-A, of course. We also note a high
proportion (5/10) of pairs involving adjectives with
vague and highly ambiguous attribute meanings,
such as good, new, certain, general. These are dif-
ficult to capture, especially in combination with ab-
stract noun concepts such as information, effect or
circumstance.
An interesting type of similarity is represented by
early evening ? previous day. In this case, we ob-
serve a contrast in the semantics of the nouns in-
volved, while the pair exhibits strong similarity on
the attribute level, which is reflected in the system?s
similarity score. This type of similarity is reminis-
cent of relational analogies investigated in Turney
(2008). A related example is rural community ? fed-
eral assembly. Unlike the human judges, C-LDA
predicts high similarity for both pairs.
The examples given in ?AgrM&L, by contrast,
clearly point to a lack in capturing adjective seman-
tics, with misjudgements such as effective way ? effi-
cient use, large number ? vast amount or large quan-
tity ? great majority.
Turning to ?AgrC-LDA-A again, we find 9/10 items
exhibit values greater than 0.67 (average: 0.78).
This means the model yields a high number of
false positives in rating similarity (with explanations
and some reservations just discussed). All items in
?AgrM&L, by contrast, have values below 0.36 (av-
erage: 0.16). That is, we again observe that this
model assigns lower similarity scores. This is con-
firmed by a comparative analysis of average sim-
ilarity scores on the entire test set: C-LDA-A;+
yields an average similarity of 0.48 (?=0.05) over
all instances, while M&L;? yields 0.16 on average
(?=0.16). The human ratings (after normalization
to the scale from 0 to 1) amount to 0.39 (?=0.26).
58
SIMILARITY
C-LDA-A; + M&L; ?
+Sim
long period ? short time 0.95 important part ? significant role 0.66
hot weather ? cold air 0.95 certain circumstance ? particular case 0.60
different kind ? various form 0.91 right hand ? left arm 0.56
better job ? good place 0.89 long period ? short time 0.55
different part ? various form 0.88 old person ? elderly lady 0.54
social event ? special circumstance 0.88 high price ? low cost 0.54
better job ? good effect 0.88 black hair ? dark eye 0.48
similar result ? good effect 0.85 general principle ? basic rule 0.44
social activity ? political action 0.82 special circumstance ? particular case 0.43
early evening ? previous day 0.80 hot weather ? cold air 0.43
?Sim
early stage ? long period 0.11 old person ? right hand 0.03
northern region ? early age 0.11 new information ? further evidence 0.03
earlier work ? early evening 0.11 early stage ? dark eye 0.01
elderly woman ? black hair 0.10 practical difficulty ? cold air 0.01
practical difficulty ? cold air 0.08 left arm ? elderly woman 0.01
small house ? old person 0.07 hot weather ? elderly lady 0.00
left arm ? elderly woman 0.06 national government ? cold air 0.00
hot weather ? further evidence 0.06 black hair ? right hand 0.00
dark eye ? left arm 0.05 hot weather ? further evidence 0.00
national government ? cold air 0.03 better job ? economic problem 0.00
Table 4: Similarity scores predicted by optimal C-LDA-A and M&L model instances; 33-ATTR setting
AGREEMENT
C-LDA-A; + M&L; ?
+Agr
major issue ? american country 0.29 similar result ? good effect 0.29
efficient use ? little room 0.29 small house ? important part 0.14
economic condition ? american country 0.29 national government ? new information 0.12
public building ? central authority 0.29 major issue ? social event 0.26
northern region ? industrial area 0.28 new body ? significant role 0.11
new life ? economic development 0.42 social event ? special circumstance 0.25
new body ? significant role 0.13 economic development ? rural community 0.32
hot weather ? elderly lady 0.13 new technology ? public building 0.18
social event ? low cost 0.13 high price ? short time 0.10
central authority ? local office 0.44 new body ? whole system 0.24
?Agr
early evening ? previous day 0.80 effective way ? efficient use 0.29
rural community ? federal assembly 0.67 federal assembly ? national government 0.24
new information ? general level 0.68 vast amount ? high price 0.10
similar result ? good effect 0.85 different kind ? various form 0.24
better job ? good effect 0.88 vast amount ? large quantity 0.36
social event ? special circumstance 0.88 large number ? vast amount 0.31
better job ? good place 0.89 older man ? elderly woman 0.00
certain circumstance ? particular case 0.22 earlier work ? early stage 0.00
hot weather ? cold air 0.95 large number ? great majority 0.09
long period ? short time 0.95 large quantity ? great majority 0.04
Table 5: Test pairs showing high and low agreement between systems and human raters, together with system similarity
scores as obtained from optimal model instances; 33-ATTR setting
59
While these means are not fully comparable as they
are the result of different composition operations,
the standard deviations suggest that M&L?s similar-
ity predictions are dispersed over a larger range of
the scale, while the C-LDA scores show only small
variation. This missing spread might be one of the
reasons for C-LDA?s lower performance.
In summary, we note one obvious shortcoming in
the C-LDA-A model, in that it does not capture dis-
similarity due to distinct contrastive meanings of at-
tribute values in cases of similarity on the noun and
attribute levels. With its focus on attribute seman-
tics, however, C-LDA-A is able to capture similar-
ity due to relational analogies, as in early evening
? previous day (0.8), whereas the latent model of
M&L is clearly noun-oriented, and thus predicts a
low similarity of 0.2 for this pair.
We conclude that the proposed attribute analysis
of adjective-noun pairs implements an inherently re-
lational form of similarity. Noun semantics is cap-
tured only indirectly, through the range of attributes
found relevant for the noun. The current model also
fully neglects the meaning of scalar attribute values.
Whether a more comprehensive analysis of inter-
preted adjective-noun meanings is able to succeed
in a paired similarity prediction task is an open issue
to be explored in future work.
7 Conclusion
In this paper, we presented a distributional VSM
that incorporates latent semantic information char-
acterizing ontological attributes in the meaning of
adjective-noun phrases, as obtained from C-LDA, a
weakly supervised variant of LDA. Originally de-
signed for an attribute selection task (Hartung and
Frank, 2011), this model faces a true challenge when
evaluated in a pairwise similarity judgement task
against a high-dimensional word space model, such
as M&L?s VSM. In fact, our model is unable to com-
pete with M&L even in its best configurations.
Thorough analysis reveals, however, that the qual-
ity of individual adjective and noun vectors is dia-
metric across the two models: C-LDA, capitalizing
on interpretable ontological dimensions, produces
effective adjective vectors, whereas its noun repre-
sentations lag behind. The inverse situation is ob-
served for the word-based latent VSM of M&L.
One qualification is in order, though: In its cur-
rent state, the C-LDA model relies on an ?oracle?
that pre-selects the attributes involved in the test set
for the model to be trained on. Although one could
argue that tailoring the context words to the target
words has a similar effect in our re-implementation
of M&L, interferences of this kind are not desirable
in principle. Future work will need to explore in
more detail possible attribute ranges with regard to
their usefulness for different tasks and data sets.
Our comparative investigaton of the specific
strengths and weaknesses of the models indicates
that they focus on different aspects of similarity:
M&L, possibly due to its higher and more discrim-
inative dimensionality, tends to produce more ef-
ficient noun vectors. Overall, this model accords
better with human similarity judgements across di-
verse aspects of similarity than the more focused
attribute-oriented LDA models. The C-LDA mod-
els focus on a specific, interpretable meaning di-
mension shared by adjectives and nouns, with a ten-
dency for stronger modeling capacity for adjectives.
They are currently not prepared to capture dissimi-
larity in cases of contrastive attribute values, while
on the positive side, they effectively cope with re-
lational analogies, both with similar and dissimilar
noun meanings.
Our findings suggest that adding more discrimina-
tive power to the noun representations and scalar in-
formation about attribute values to the adjective vec-
tors might be beneficial. Further research is needed
to investigate how to combine interpretable seman-
tic representations tailored to specific relations, as
captured by C-LDA, with M&L-like bag-of-words
representations in a single distributional model.
Applying interpreted models to the present simi-
larity rating task will still remain a challenge, as it
involves mapping diverse mixtures of aspects and
grades of similarity to human judgements. How-
ever, if the performance of an integrated model can
compete with a purely latent semantic analysis, this
offers a clear advantage for more general tasks that
require linking phrase meaning to symbolic knowl-
edge bases such as (multilingual) ontologies, or for
application scenarios that involve discrete seman-
tic labels, such as text classification based on topic
modeling (Blei et al, 2003) or fine-grained named
entity classification (Ekbal et al, 2010).
60
References
Abdulrahman Almuhareb. 2006. Attributes in Lexical
Acquisition. Ph.D. Dissertation, Department of Com-
puter Science, University of Essex.
Marco Baroni and Roberto Zamparelli. 2010. Nouns
are vectors, adjectives are matrices: Representing
adjective-noun constructions in semantic space. In
Proceedings of the 2010 Conference on Empiri-
cal Methods in Natural Language Processing, East
Stroudsburg, PA, pages 1183?1193.
Marco Baroni, Silvia Bernardini, Adriano Ferraresi, and
Eros Zanchetta. 2009. The WaCky Wide Web: A Col-
lection of Very Large Linguistically Processed Web-
crawled Corpora. Journal of Language Resources and
Evaluation, 43(3):209?226.
Marco Baroni, Brian Murphy, Eduard Barbu, and Mas-
simo Poesio. 2010. Strudel. A Corpus-based Seman-
tic Model based on Properties and Types. Cognitive
Science, 34:222?254.
David M. Blei, Andrew Ng, and Michael Jordan. 2003.
Latent Dirichlet Allocation. JMLR, 3:993?1022.
Asif Ekbal, Eva Sourjikova, Anette Frank, and Simone
Ponzetto. 2010. Assessing the Challenge of Fine-
grained Named Entity Recognition and Classification.
In Proceedings of the ACL 2010 Named Entity Work-
shop (NEWS), Uppsala, Sweden.
Christiane Fellbaum, editor. 1998. WordNet: An Elec-
tronic Lexical Database. MIT Press, Cambridge,
Mass.
Emiliano Guevara. 2010. A regression model of
adjective-noun compositionality in distributional se-
mantics. In Proceedings of the 2010 Workshop on
GEometrical Models of Natural Language Semantics,
Stroudsburg, PA. Association for Computational Lin-
guistics.
Matthias Hartung and Anette Frank. 2010. A Structured
Vector Space Model for Hidden Attribute Meaning in
Adjective-Noun Phrases. In Proceedings of the 23rd
International Conference on Computational Linguis-
tics (COLING), Beijing, China, August.
Matthias Hartung and Anette Frank. 2011. Exploring
Supervised LDA Models for Assigning Attributes to
Adjective-Noun Phrases. In Proceedings of the 2011
Conference on Empirical Methods in Natural Lan-
guage Processing, Edinburgh, UK.
Andrew Kachites McCallum. 2002. MAL-
LET: A machine learning for language toolkit.
http://mallet.cs.umass.edu.
Jeff Mitchell and Mirella Lapata. 2008. Vector-based
Models of Semantic Composition. In Proceedings of
ACL-08: HLT, pages 236?244, Columbus, Ohio, June.
Jeff Mitchell and Mirella Lapata. 2009. Language Mod-
els Based on Semantic Composition. In Proceedings
of the 2009 Conference on Empirical Methods in Nat-
ural Language Processing, Singapore, August 2009,
pages 430?439, Singapore, August.
Jeff Mitchell and Mirella Lapata. 2010. Composition
in Distributional Models of Semantics. Cognitive Sci-
ence, 34:1388?1429.
Diarmuid ?O Se?aghdha. 2010. Latent variable models
of selectional preference. In Proceedings of the 48th
Annual Meeting of the Association for Computational
Linguistics, pages 435?444, Uppsala, Sweden, July.
Association for Computational Linguistics.
Alan Ritter, Mausam, and Oren Etzioni. 2010. A latent
dirichlet alocation method for selectional preferences.
In Proceedings of the 48th Annual Meeting of the Asso-
ciation for Computational Linguistics, pages 424?434,
Uppsala, Sweden, July. Association for Computational
Linguistics.
Peter D. Turney. 2008. A uniform approach to analogies,
synonyms, antonyms, and associations. In Proceed-
ings of the 22nd International Conference on Com-
putational Linguistics (Coling 2008), pages 905?912,
Manchester, UK.
61
