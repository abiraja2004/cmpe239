Proceedings of the Fourth Workshop on Statistical Machine Translation , pages 173?181,
Athens, Greece, 30 March ? 31 March 2009. c?2009 Association for Computational Linguistics
Improving Arabic-Chinese Statistical Machine Translation  
using English as Pivot Language 
 
 
Nizar Habash Jun Hu 
Center for Computational Learning Systems Computer Science Department 
Columbia University Columbia University 
New York, NY 10115, USA New York, NY 10115, USA 
habash@ccls.columbia.edu jh2740@columbia.edu 
 
  
Abstract 
We present a comparison of two approaches for 
Arabic-Chinese machine translation using Eng-
lish as a pivot language: sentence pivoting and 
phrase-table pivoting. Our results show that 
using English as a pivot in either approach out-
performs direct translation from Arabic to Chi-
nese.  Our best result is the phrase-pivot system 
which scores higher than direct translation by 
1.1 BLEU points. An error analysis of our best 
system shows that we successfully handle many 
complex Arabic-Chinese syntactic variations. 
1 Introduction 
Arabic and Chinese are two languages with a 
very large global presence; however, there has 
not been, to our knowledge, any work on MT 
for this pair.  Given the cost involved in creat-
ing parallel corpora for Arabic and Chinese and 
given that there are lots of available resources 
(in particular parallel corpora) for Arabic and 
English and for Chinese and English, we are 
interested in exploring the role English might 
serve as a pivot (or bridge) language.  In this 
paper we explore different ways of pivoting 
through English to translate Arabic to Chinese. 
Our work is similar to previous research on 
pivot languages except in that our three lan-
guages (source, pivot and target) are very dif-
ferent and from completely unrelated families.  
We focus our experiments on a trilingual paral-
lel corpus to keep all conditions experimentally 
clean. Our results show that using English as a 
pivot language for translating Arabic to Chinese 
actually outperforms direct translation. We be-
lieve this may be a result of English being a sort 
of middle ground between Arabic and Chinese 
in terms of different linguistic features and, in 
particular, word order. 
 
Section  2 describes previous work. Section 3 
discusses relevant linguistic issues of Arabic, 
Chinese and English. Section  4 describes our 
system and different pivoting techniques. And 
Section  5 presents our experimental results. 
2 Previous Work 
There has been a lot of work on translation 
from Chinese to English (Wang et al, 2007; 
Crego and Mari?o, 2007; Carpuat and Wu, 
2007; among others) and from Arabic to Eng-
lish (Sadat and Habash, 2006, Al-Onaizan and 
Papineni, 2006; among others).  There is also a 
fair amount of work on translation into Chinese 
from Japanese, Korean and English (Isahara et 
al., 2007; Kim et al, 2002; Ye et al, 2007; 
among others).  In 2008, the National Institute 
of Standards and Technology (NIST) MT 
Evaluation competition introduced English-
Chinese as a new evaluation track.1 
 
Much work has been done on exploiting multi-
lingual corpora for MT or related tasks such as 
lexical induction or word alignment.  Schafer 
and Yarowsky (2002) induced translation lexi-
cons for languages without common parallel 
corpora using a bridge language that is related 
to the target languages.  Simard (1999) de-
scribed a sentence aligner that makes simulta-
neous decisions in a trilingual parallel text. 
Kumar et al (2007) improved Arabic-English 
MT by using available parallel data in other 
languages. Callison-Burch et al(2006) ex-
ploited the existence of multiple parallel cor-
pora to learn paraphrases for Phrase-based MT. 
Filali and Bilmes (2005) improved word align-
ment by leveraging multilingual parallel trans-
lations. 
 
Most related to our work on pivoting are the 
following: Utiyama and Isahara (2007) studied 
                                                           
1 http://www.nist.gov/speech/tests/mt/2008/doc/ 
173
sentence and phrase pivoting strategies using 
three European languages (Spanish, French and 
German). Their results showed that pivoting 
does not work as well as direct translation.  Wu 
and Wang (2007) focused on phrase pivoting. 
They proposed an interpolated scheme that em-
ploys two phrase tables: one extracted from a 
small amount of direct parallel data; and the 
other extracted from large amounts of indirect 
data with a third pivoting language. They com-
pared results for different European language as 
well as Chinese-Japanese translation using Eng-
lish as a pivoting language. Their results show 
that simple pivoting does not improve over di-
rect MT; however, extending the direct MT sys-
tem with phrases learned through pivoting 
helps. Babych et al (2007) compared two 
methods for translating into English from 
Ukrainian: direct Ukrainian-English MT versus 
translation via a cognate language, Russian. 
Their comparison showed that it is possible to 
achieve better translation quality via pivoting. 
 
In this paper we use a standard phrase-based 
MT approach (Koehn, 2004) that is in the same 
spirit of most statistical MT nowadays.  We be-
lieve that we are the first to explore the Arabic-
Chinese language pair in MT. We differ from 
previous pivoting research in showing that piv-
oting can outperform direct translation even 
when the source, target and pivot languages are 
all linguistically unrelated. 
 
3 Linguistic Issues  
In this section we discuss different linguistic 
phenomena in which Arabic, English and Chi-
nese are divergent. We consider orthography, 
morphology and syntax. We also present a new 
metric for quantifying linguistic differences.  
3.1 Orthography 
Arabic is written from right-to-left using an al-
phabet of 36 letters and eight optional diacriti-
cal marks. Arabic is written in a cursive mostly 
word-internal connected form, but words are 
separated by white spaces.  The absence of Ara-
bic diacritics adds a lot of ambiguity.    
 
Chinese uses a complex orthography that in-
cludes around 10,000 characters in common 
use.  Characters convey semantic rather than 
phonological information. Chinese is written 
from left-to-right or top-down.  Chinese words 
can be made out of one, two or more charac-
ters. However, words are written without sepa-
rating spaces.  Word segmentation is a major 
challenge for processing Chinese (Wu, 1998).   
 
English uses the Roman alphabet and its words 
are written with separating white spaces. Eng-
lish orthography is much closer to Arabic than 
it is to Chinese. 
3.2 Morphology 
Arabic is a morphologically rich language with 
a large set of morphological features such per-
son, number, gender, voice, aspect, mood, case, 
and state. Arabic features are realized using 
both concatenative (affixes and stems) and 
templatic (root and patterns) morphology with 
a variety of morphological, phonological and 
orthographic adjustments. In addition, Arabic 
has a set of very common clitics that are writ-
ten attached to the word, e.g., the conjunction 
?+  w+ ?and?, the preposition ?+  b+2  ?with/in?, 
the definite article ?? +  Al+ ?the? and a range of 
pronominal clitics that can attach to nouns (as 
possessives) or verbs and prepositions (as ob-
jects).   
 
In stark contrast to Arabic, Chinese is an isolat-
ing language with no morphology to talk of. 
However, what Chinese lacks in morphology it 
replaces with a complex system of nominal 
quantifiers and verbal aspects.  For example, in 
Figure 1 (at the end of this paper),  Chinese 
marks the definiteness and humanness of the 
word?? Xue Sheng ?student? using  the two 
characters ?? Zhe Wei  ?this person?, while 
the indefiniteness and book-ness of the word?
Shu ?book? are indicated through the characters
?? Yi Ben ?one book-type?.  
 
English has a simple limited morphology pri-
marily indicating number and tense. English 
stands in the middle between Arabic and Chi-
nese in terms of morphological complexity.  
3.3 Syntax 
Arabic is morpho-syntactically complex with 
many differences from Chinese and English. 
We describe here three prominent syntactic 
issues in which Arabic, Chinese and English 
vary widely: subject-verb order, verb-
                                                           
2  Arabic transliteration is in the Habash-Soudi-Buckwalter 
scheme (Habash et al 2007). 
174
prepositional phrase order and nominal modifi-
cation. 
 
First, Arabic verb subjects may be: (a.) pro-
dropped (verb conjugated), (b.)  pre-verbal, or 
(c.)  post-verbal. The morphology of the Arabic 
verb varies in the three cases. By contrast Eng-
lish and Chinese are both generally subject-verb 
languages. When translating from Arabic, the 
challenge is to determine whether there is an 
explicit subject and, if there is, whether it is pre- 
or post-verbal.  Since Arabic objects also follow 
the verb, a sequence of Verb NounPhrase may 
be a verb subject or a pro-drop-verb object. In 
the example in Figure 1, the subject (student) 
appears after the sentence initial verb in Arabic, 
but at the beginning of the sentence in Chinese 
and English. 
 
Secondly, as for the word order of prepositional 
phrases (PP), Arabic and English are similar in 
that PPs generally appear at the end of the sen-
tence (after all the verbal arguments) and to a 
lesser extent at its beginning.  In Chinese, how-
ever, some PPs (in particular locatives and tem-
porals) must appear between subject and verb.  
Other PPs may appear at end of sentence.  In the 
example in Figure 1, the location of the reading, 
?in the classroom? appears at the end of the 
Arabic and English sentences; however, it is 
between subject and verb in Chinese. 
 
Finally, we distinguish three types of nominal 
modification: adjectival (as in ?red book?),  pos-
sessive (as in ?John?s book?) and relative (as in 
?the book [which] John gave me?).  All of these 
modification types are handled in a similar 
manner in Chinese: using the particle? De to 
connect modifier with modified.  Modifiers al-
ways precede the modified. For example, in 
Figure 1, ?a book about China? appears as ?? 
?? ?? Guan Yu Zhong Guo De Shu ?about 
China De book?.    Similarly, ?the student?s 
book? would be translated as ?? ? ? Xue 
Sheng De Shu ?student DE book?. Like Chinese, 
English adjectival modifiers precede what they 
modify. However, relative modifiers follow.  
Possessive modifiers in English can appear be-
fore or after: ?the student?s book? or ?the book 
of the student?.  Unlike English and Chinese, 
Arabic adjectival modifiers typically follow 
their nouns (with a small exception of some su-
perlative adjectives).  However, similar to Eng-
lish but not Chinese, Arabic relative modifiers 
follow what they modify.  As for possessive 
modifiers, Arabic has a special construction 
called Idafa, in which modifiers immediately 
follow what they modify without connecting 
particles. For example, ?the student?s book? can 
only be translated in Arabic as NOPQO? ?PR? ktAb 
AlTAlb ?book the-student?.3 
 
These different phenomena are summarized in 
Table 1.  It is interesting to point out that Eng-
lish phenomena are a middle ground for Arabic 
and Chinese: in some cases English is closer to 
Arabic and in others to Chinese.  
 
 Arabic English Chinese 
Orthography reduced 
alphabet 
alphabet Characters 
Morphology Rich Poor Very Poor 
Subject-Verb V Subj 
Subj V 
Vsubj 
Subj V Subj ? V 
Verb-PP V?PP V?PP PP V 
V PP 
Adjectival 
Modifier 
N Adj Adj N Adj DE N 
Possessive 
Modifier 
N Poss N of Poss 
Poss ?s N 
Poss DE N 
Relative 
Modifier 
N Rel N Rel Rel DE N 
Table 1: Comparing different linguistic phenomena 
in Arabic, English and Chinese 
3.4 Quantifying Linguistic Differences 
The previous section described specific types 
of linguistic phenomena without distinguishing 
them in terms of frequency or effect distance. 
For example, Arabic nominals (nouns, adjec-
tives and adverbs) are seven times as frequent 
as verbs; and nominal modification phenomena 
are more likely local than long distance com-
pared to verb-subject order.  A proper quantifi-
cation of these different phenomena requires 
trilingual parallel treebanks, which are not 
available. As such, we propose a simple metric 
to quantify linguistic differences by measuring 
the translation complexity of different language 
pairs. The metric is Average Relative Align-
ment Length (ARAL): 
 
ARAL = 1| L |
pa
Salab ?L
? ? pbSb  
 
                                                           
3  Arabic dialects allow an additional construction. We 
focus here on Modern Standard Arabic. 
175
We define L as the set of all alignment links 
linking words in a parallel corpus of languages 
A and B. For each alignment link, lab, linking 
words a and b, we define pa and pb as the posi-
tion of words a and b in their respective sen-
tences. We also define Sa and Sb as the lengths 
of the sentences in which a and b appear, re-
spectively. ARAL is the mean of the absolute 
difference in relative word position (pi/Si) of the 
words of every alignment link. The larger 
ARAL is, the more reordering and inser-
tions/deletions we expect, and the more com-
plexity and difference. ARAL is a harsh metric 
since it ignores syntactic structure facts that ex-
plain how clusters of words move together.   
 
A-C A-E E-C 
0.1679 0.0846 0.1531 
Table 2: Average Relative Alignment Length for  
pairs of Arabic (A), English (E) and Chinese (C) 
 
Table 2 presents the ARAL scores for each lan-
guage pair. These scores are computed over the 
grow-diag-final symmetrized alignment we use 
in our system (Koehn, 2004). ARALAC is the 
highest and ARALAE is the lowest. The average 
length of sentences is generally close among 
these languages (given the segmentation we 
use): Arabic is ~32 words, English is ~31 and 
Chinese is ~29.  Arabic and English are much 
closer to each other than either to Chinese. This 
may be the result of Arabic tokenization and 
Chinese segmentation technologies which have 
been developed for translation into English. We 
address this issue in section  4.1. The ARAL 
scores agree with our assessment that English is 
closer to Arabic and to Chinese than Arabic is 
to Chinese.  As a result, we believe it may serve 
as a good pivot language for translating Arabic 
to Chinese.    
 
4 System Description 
In this section, we describe the different sys-
tems we compare. 
4.1 Data 
Our data collection is the United Nations (UN) 
multilingual corpus, provided by the LDC 4 
(catalog no. LDC2004E12).  The UN corpus has 
in principle parallel sentences for Arabic, Eng-
lish and Chinese. However, the Arabic-English 
                                                           
4 http://www.ldc.upenn.edu 
(A-E) data and Chinese-English (C-E) data sets 
were not in synch. The A-E data set has 3.2M 
lines while the C-E data set has 5.0M lines. We 
used the document ID provided in the data to 
match sentences from A-E against those in C-E 
to generate a three-way parallel corpus with 
2.6M lines.  
 
We tokenized the Arabic data in the Arabic 
Treebank scheme (Sadat and Habash, 2006). 
Chinese was segmented into words using a 
segmenter developed by Howard Johnson for 
the Portage Chinese-English MT system.5 So a 
sentence consists of multiple words with spaces 
between them and each word is comprised of 
one or more characters. English was simply 
processed to split punctuation and ??s?. The 
same preprocessing was used in all systems 
compared. 
 
We are aware of two potentially biased aspects 
of our experimental setting.  First, the Arabic 
and Chinese portions of our data collection, the 
UN corpus, are known to be generated from 
English originals. And secondly, the preproc-
essing techniques we used on Arabic and Chi-
nese were developed for translation from these 
languages into English. These two aspects 
make English potentially more central to our 
experiments than if the data collection and pre-
processing were done on Arabic and Chinese 
independent of English. Of course, it must be 
noted that the data bias is not unique to our 
work but rather a challenge for any bilingual 
corpus, in which translation is done from one 
language to another. Additionally, we can ar-
gue that the English bias in data and preproc-
essing does not only affect the Arabic-English 
and English-Chinese pipelines, but it also 
makes the Arabic and Chinese data potentially 
closer.  Finally, given the expense involved in 
creating direct Arabic-Chinese parallel text and 
given the large amounts of Arabic-English and 
English-Chinese data, we think our results 
(with English bias) are still valid and interest-
ing. That said, we leave the question of Arabic-
Chinese optimization to future work.  
4.2 Direct A-C MT System 
In our baseline direct A-C system, we used the 
Arabic and Chinese portions of our parallel 
corpus to train a direct phrase-based MT sys-
tem. We use GIZA++ (Och and Ney, 2003) for 
                                                           
5 http://iit-iti.nrc-cnrc.gc.ca/projects-projets/portage_e.html 
176
word alignment, and the Pharaoh system suite 
to build the phrase table and decode (Koehn, 
2004). The Chinese language model (LM) used 
200M words from the UN corpus segmented in 
a manner consistent with our training.  The tri-
gram LM was built using the SRILM toolkit 
(Stolcke, 2002).   
4.3 Sentence Pivoting MT System 
The sentence pivoting system (A-s-C) used 
English as an interface between two separate 
pharse-based MT systems: an Arabic-English 
direct system and an English-Chinese direct 
system. When translating Arabic to Chinese, the 
English top-1 output of the Arabic-English sys-
tem was passed as input to the English-Chinese 
system. The English LM used to train the Ara-
bic-English system is built from the counterpart 
of the Chinese data used to build the Chinese 
LM in our parallel corpus. We use 210M Eng-
lish words in total.  
4.4 Phrase Pivoting MT System  
The phrase pivoting system (A-p-C) extracts a 
new Arabic to Chinese phrase table using the 
Arabic-English phrase table and the English-
Chinese phrase table. We consider a Chinese 
phrase a translation of an Arabic phrase only if 
some English phrase can bridge the two. We use 
the following formulae to compute the lexical 
and phrase probabilities in the new phrase table 
in a similar manner to Utiyama and Isahara 
(2007). Here, ?  is the lexical probability and 
wp is the phrase probability.  
  
'( | ) ( | ) ( | )
e
a c a e e c? ? ?=?  
'( | ) ( | ) ( | )
e
c a c e e a? ? ?=?  
'( | ) ( | ) ( | )w w w
e
p a c p a e p e c=?  
'( | ) ( | ) ( | )w w w
e
p c a p c e p e a=?  
 
The left hand side of the formulae represents the 
four required probabilities in a Pharaoh Arabic-
Chinese phrase table. 
 
5 Evaluation 
For each of the direct system, the sentence-
pivoting system and the phrase-pivoting system, 
we conduct four sets of experiments with dif-
ferent data sizes. Table 3 illustrates the training 
data size for each experiment. The training data 
is collected from the beginning of the same 
parallel corpus, so the larger training sets in-
clude the smaller ones. 
 
 Lines Words (Arabic) 
S 32500 1 Million 
M 65000 2 Million 
L 130000 4 Million 
XL 260000 8 Million 
Table 3: Training Data Size 
 
We use two other data sets (1K lines each) for 
tuning and testing. Each sentence in these sets 
has only one reference. Tuning and testing data 
sets are the same across all experiments and 
systems.  In all our experiments, we decode 
using Pharaoh (Koehn, 2004) with a distortion 
limit of 4 and a maximum phrase length of 7. 
Tuning is done for each experimental condition 
using Och?s Minimum Error Training (Och, 
2003). 
 
Note that for each set of experiments with the 
same data size, we draw Chinese, Arabic and 
English from the same chunk of three way par-
allel corpus. For example, in S size experi-
ments, the two phrase tables used to build a 
new table in the phrase-pivoting approach are 
extracted respectively from the A-E and E-C 
systems built in the sentence-pivoting approach 
with size S corpora. 
 
5.1 Direct System Results 
Table 4 shows the results of the direct transla-
tion system A-C. It also includes the result for 
A-E and E-C direct translation. As expected, as 
we double the size of the data, the BLEU score 
(Papineni et al, 2002) increases.  However, the 
rate of increase is not always consistent. In par-
ticular, the M and L conditions vary highly in 
A-E compared to A-C. This is odd especially 
given that we are comparing the same set of 
data from the three parallel corpora.  We specu-
late that this may have to do with an oddity in 
that portion of the data set that may have a dif-
ferent quality than the rest. We see the effect of 
this drop in A-E in the next section.  BLEU is 
measured on English case-insensitively. BLEU 
is measured on Chinese using segmented words 
not characters. 
177
 
 
 A-C A-E E-C 
S 11.17 21.89 19.29 
M 13.43 
(+20.2%) 
23.86 
(+9.0%) 
20.85 
(+8.1%) 
L 14.62 
(+8.9%) 
24.86 
(+4.2%) 
22.42 
(+7.5%) 
XL 16.17 
(+10.6%) 
27.96 
(+12.5%) 
24.11 
(+7.5%) 
Table 4: BLEU-4 scores comparing performance of 
direct translation of Arabic-Chinese (A-C), Arabic-
English (A-E) and English-Chinese (E-C) for four 
training data sizes. The percentage increases are 
against the immediately lower data size. 
5.2 Pivoting System Results 
In Table 5, we present the results of the sen-
tence pivoting system (A-s-C) and the phrase 
pivoting system (A-p-C).  Under all conditions, 
A-s-C and A-p-C outperform A-C. A-p-C gen-
erally outperforms A-s-C except in the M data 
condition. The effect in the S conditions is big-
ger than the XL condition.  In our best result 
(XL), we increase the BLEU score by over 1.12 
points. Furthermore, the relative BLEU score 
increase from the L condition for A-p-C is 
15.5% as opposed to A-C?s 10.6%. The A-s-C 
relative increase from L to XL is 12.8%. This 
suggests that we are making better use of the 
available resources. The differences between A-
s-C and A-C and between A-p-C and A-C are 
statistically significant at the 95% confidence 
level (Zhang et al, 2004).   The differences be-
tween the two pivoting systems are not statisti-
cally significant. Examples from our best 
performing system are shown in Figure 2. 
 
 A-C A-s-C A-p-C 
S 11.17 12.24 9.6% 13.12 17.5% 
M 13.43 14.10 5.0% 13.75 2.4% 
L 14.62 14.96 2.3% 14.97 2.4% 
XL 16.17 16.88 4.4% 17.29 6.9% 
Table 5: Word-based BLEU-4 scores. A-C is direct 
translation. A-s-C is indirect translation through sen-
tence pivoting and A-p-C is indirect translation 
through phrase pivoting. The percentages indicate 
relative improvement over A-C. 
 
Our results are consistent with (Utiyama and 
Isahara, 2007) in that phrase-pivoting generally 
does better than sentence pivoting. However, 
we disagree with them in that, for us, direct 
translation is not the best system to use. We be-
lieve that this effect is caused by the combina-
tion of the very different languages we use. 
English is truly bridging between Arabic and 
Chinese in many linguistic dimensions.  We 
think it?s English?s middle-ground-ness that 
makes these results possible. 
 
 A-C A-s-C A-p-C 
S 53.75 54.38 1.2% 54.64 1.7% 
M 56.65 57.00 0.6% 55.88 -1.4% 
L 58.37 57.69 -1.2% 58.79 0.7% 
BLEU
-1 
XL 59.90 60.34 0.7% 60.28 0.6% 
S 21.32 21.80 2.3% 22.88 7.3% 
M 23.84 24.22 1.6% 23.76 -0.3% 
L 24.98 25.14 0.6% 25.87 3.6% 
BLEU
-4 
XL 25.95 27.11 4.5% 27.70 6.7% 
S 9.82 10.02 2.0% 11.42 16.3% 
M 11.56 11.84 2.4% 11.64 0.7% 
L 12.23 12.52 2.4% 13.09 7.0% 
BLEU
-7 
XL 12.69 13.52 6.5% 14.57 14.8% 
Table 6: Character-based BLEU scores for n-grams 
of maximum size 1, 4, and 7.  The percentages are 
relative to the direct system. 
 
In Table 6, we present additional scores using 
BLEU-1, BLEU-4 and BLEU-7 measured at 
the character level as opposed to the harsher 
measure at word level. Ignoring the odd behav-
ior in M and L conditions, the sentence-pivot 
and phrase-pivot approaches improve over the 
direct translation baseline in terms of fluency 
(BLEU-7) and accuracy (BLEU-1). Under the 
small data condition, the phrase-pivot approach 
increases the BLEU-4 score three times the 
increase of the sentence-pivot approach. That 
ratio reduces to 1.5 times in the XL condition. 
The relative improvements of the pivoting sys-
tems over the direct system are small at BLEU-
1 and much bigger at higher BLEU scores.  
This suggests that differences between the piv-
oting systems and the direct system are not in 
terms of lexical coverage but rather in terms of 
better reordering. 
 
The lengths of the outputs of all the systems 
(direct and pivoting) are larger than the refer-
ence length which means no brevity penalty 
was applied in BLEU calculation. Also, no 
BLEU-gaming was done by OOV deletion: all 
OOV words were left in the output. 
5.3 Error Analysis 
We conducted an error analysis of our best per-
forming system (Phrase Pivot XL) to under-
stand what issues need to be addressed in the 
178
future. We took a sample of 50 sentences re-
stricted in length to be between 15 and 35 Chi-
nese words. A Chinese native speaker compared 
our output to the reference translation and 
judged its quality in terms of two categories: 
syntax and lexical choice.   
 
In terms of syntax, our judge identified all the 
occurrences of (a) subjects and verbs, (b) prepo-
sitional phrases and verbs and (c) modified 
nouns.  Each case was judged as acceptable or 
wrong.  Placing a verb before its subject, a pre-
verbal prepositional phrase after its verb, or a 
modifier after the noun it modifies are all con-
sidered wrong.  We correctly produce subject-
verb order 73% of the time; and we produce 
nominal modification order correctly 64% of 
the time.  Our biggest weakness in terms of syn-
tax is prepositional phrase order.  It is worth 
noting that the two phenomena we do better on 
are addressed in translation from Arabic to Eng-
lish, unlike prepositional phrase order which is 
where Chinese is different from both Arabic and 
English. 
 
In terms of lexical choice our judge considered 
the translation quality of three classes of words: 
Nominals (nouns, pronouns, adjectives and ad-
verbs), Verbs, and other particles (prepositions, 
conjunctions and quantifiers).  An incorrectly 
translated or deleted word is considered wrong.  
We perform on nominals and particles at about 
the same level of 90%. Verbs are our biggest 
challenge with accuracy below 80%.  The ratio 
of deleted words among all wrong words is 
rather high at about 30% (for nominals and for 
verbs). The detailed results of the error analysis 
are shown in Table 7. 
 
Finally, there are 27 instances of Arabic Out-of-
Vocabulary (OOV) words (1.93% of all words) 
that are not handled. Ten (37%) of these are 
proper nouns. The rest belong to mostly nouns 
and adjectives. Orthogonally, 19 (70%) of all 
OOV words belong to the genre of science re-
ports, which is quite different from the data we 
train on. The OOVs include complex terms like 
_`aPb?cde?fg`bO? AlsybrwflwksAsyn ?ciproflox-
acin? and hi??kl ?PnPn? rjAjAt mdAry? ?[chemi-
cal] orbital shakers?. Other less frequent OOV 
cases involve bad tokenization and less com-
mon morphological constructions. 
 
 Total Acceptable Wrong 
Subj-Verb 48 35(73%) 13 (27%) 
Verb-PP 46 17 (37%) 29 (63%) 
Syntax 
Noun-Mod 97 62 (64%) 35 (36%) 
Nominal 408 368 (90%) 40 (10%) 
Verb 124 98 (79%) 26 (21%) 
Lexical 
Choice 
Particle 116 106 (91%) 10 (9%) 
Table 7: Results of human error analysis on a 
sample from the A-p-C system (XL) 
6 Conclusion and Future Work  
We presented a comparison of two approaches 
for Arabic-Chinese MT using English as a piv-
ot language against direct MT. Our results 
show that using English as a pivot in either ap-
proach outperforms direct translation from 
Arabic to Chinese. We believe that this is a 
result of English being a sort of middle ground 
between Arabic and Chinese in terms of differ-
ent linguistic features (in particular word or-
der). Our best result is the phrase-pivot system 
which scores higher than direct translation by 
1.1 BLEU points. An error analysis of our sys-
tem shows that we successfully handle many 
complex Arabic-Chinese syntactic variations 
although there is a large space for improvement 
still.   
 
In the future, we plan on exploring tighter cou-
pling of Arabic and Chinese through compar-
ing different methods of preprocessing Arabic 
for Arabic-Chinese MT, in a similar manner to 
Sadat and Habash (2006).  We also plan to 
study how well these results carry on to differ-
ent corpora (bilingual Arabic-English and Eng-
lish-Chinese) as opposed to the trilingual 
corpus used in this paper.  We also plan to in-
vestigate whether our findings in Arabic-
English-Chinese can be used for other different 
language triples.  
Acknowledgements 
We would like to thank Roland Kuhn, George 
Foster and Howard Johnson of the National 
Research Council Canada for helpful advice 
and discussions and for providing us with the 
Chinese preprocessing tools. 
 
179
 
Figure 1: An example highlighting Arabic-English-Chinese syntactic differences 
 
 
Figure 2: Examples of Arabic-Chinese MT output. English references and English  
glosses for Arabic and Chinese are provided to ease readability.  
 
Arabic k`op kq rO?? ?PuvO?? ?kox? ??PbudO hzfol h{`gO? ?{| ?Pe ? ?O? rd? ?P?p? .  
and-building upon this , therefore  this environment susceptible to-corruption and-lack qualifica-
tion to extent big . 
Eng-Ref Consequently , this environment lends itself to significant degrees of corruption and inefficiency . 
Chn-Ref ??,????????????????? 
Therefore, this kind environment caused have high-degree corruption and efficiency low. 
Chn-Out ??,??????????? ???????? ? 
Therefore , this kind environment inside DE corruption and lack efficiency on big degree top. 
 
Arabic  ?c?? ?e hpcdQ?O? ?Plcdo?O? ?f? ?O 90???? NdQO? ??bi ? ?f?? Plci . 
and-if did-not arrive information requested in period 90 day other , lapse application . 
Eng-Ref If the requested information is not received within a further 90 days ,  the application will lapse. 
Chn-Ref ???? 90?????? ?????,?????? 
If again pass 90 day yet not received requested DE information , then application loose validity. 
Chn-Out ??????? ????? 90??????????  
If not receive requested DE information 90 day within provide more DE request. 
  
Arabic ... h`lcv?O? ???n?? _`p ???c?O? ?e ??P?RO? ??Plcdo?O?? ?Pg? f`b`? . 
? facilitation exchanging the-information and-the-sharing in the-resources between the-agencies 
the-governmental . 
Eng-Ref ? to facilitate the sharing of information and resources between government agencies . 
Chn-Ref ???????????????????? ? 
?for all government agencies among exchanging information and resource offer convenience. 
Chn-Out ???????????????????? 
...purpose in facilitate information exchanging and sharing resource governments among agency . 
  
Arabic  ?PbuO? ??P?Rq? _l rx??? k?O? rO? ?`d?RdO hOPoe? hgaP?l f`p?k? ??k?Ra? ?e f??? ? ??Plcv?dO ??g?i?. 
and-should to-government that look in introducing measures appropriate and-effective to-reduce 
to extent least from possibilities the-corruption 
Eng-Ref Governments should consider introducing appropriate and effective measures to minimize the 
potential for corruption. 
Chn-Ref ????????????????,?? ??? ?????????? ? 
all countries governments should consider adopt appropriate DE effective methods , to-biggest-
extent DE reduce producing corruption DE possibility. 
Chn-Out ? ???????????????,????????????? ? 
all countries governments should consider build appropriate DE effective methods , to-biggest-
extent DE reduce corruption DE possibility. 
 
?f?i1NOPQO2 ?k?R??O3 ?PpPR5 ?_4 ?_`?O6 ??e 7??O8  ?. 
yqr?1 AlTAlb2 Almjthd3 ktAbA4 ?n5 AlSyn6 fy7 AlSf8 . 
read1 the-student2 the-diligent3 a-book4 about5 china6 in7 the-classroom8 . 
  
? 1? 2?? 3              ? 4  ?? 5        ? 6?? 7            ? 8     ? 9  ? 10      ?? 11      ?? 12          ? 13? 14? 
this1 quant2 diligent3 de4  student5     in6    classroom7 read8 one9 quant10 about11     china12           de13    book14 
Zhe1 Wei2 Qin Fen3        De4   Xue Sheng5 Zai6  Jiao Shi7       Du8     Yi9    Ben10      Guan Yu11 Zhong Guo12 De13   Shu14 
  
The diligent student is reading a book about China in the classroom. 
 
180
References  
Yaser Al-Onaizan and Kishore Papineni. 2006 Dis-
tortion models for statistical machine transla-
tion. In Proceedings of Coling-ACL?06. 
Sydney, Australia. 
Bogdan Babych, Anthony Hartley, and Serge 
Sharoff. 2007. Translating from under-
resourced languages: comparing direct transfer 
against pivot translation. In Proceedings of MT 
Summit XI, Copenhagen, Denmark.  
Tim Buckwalter. 2002. Buckwalter Arabic morpho-
logical analyzer version 1.0.  
Chris Callison-Burch, Philipp Koehn, and Miles 
Osborne. 2006. Improved statistical machine 
translation using paraphrases. In Proceedings 
of HLT-NAACL?06. New York, NY, USA. 
Marine Carpuat and Dekai Wu. 2007. Context-
dependent phrasal translation lexicons for sta-
tistical machine translation. In Proceedings of 
MT Summit XI, Copenhagen, Denmark.  
Josep M. Crego and Jos? B. Mari?o. 2007. Syntax-
enhanced n-gram-based SMT. In Proceedings 
of MT Summit XI, Copenhagen, Denmark.  
Karim Filali and Jeff Bilmes. Leveraging Multiple 
Languages to Improve Statistical MT Word 
Alignments. In Proceedings of ASRU?05, Can-
cun, Mexico. 
Nizar Habash. 2007. Syntactic preprocessing for 
statistical machine translation. In Proceedings 
of MT Summit XI, Copenhagen, Denmark. 
Nizar Habash, Abdelhadi Soudi, and Tim Buckwal-
ter. 2007. On Arabic Transliteration. In A. van 
den Bosch and A. Soudi, editors, Arabic Com-
putational Morphology: Knowledge-based and 
Empirical Methods. Springer.  
Hitoshi Isahara, Sadao Kurohashi, Jun?ichi Tsujii, 
Kiyotaka Uchimoto, Hiroshi Nakagawa, Hiro-
yuki Kaji, and Shun?ichi Kikuchi. 2007. De-
velopment of a Japanese-Chinese machine 
translation system.  In Proceedings of MT 
Summit XI, Copenhagen, Denmark. 
Philipp Koehn. 2004. Pharaoh: a Beam Search De-
coder for Phrase-based Statistical Machine 
Translation Models. In Proceedings of 
AMTA?04, Washington, DC, USA. 
Shankar Kumar, Franz Och, and Wolfgang Ma-
cherey. 2007. Improving word alignment with 
bridge languages. In Proceedings of EMNLP-
CoNLL?07, Prague, Czech Republic.   
Young-Suk Lee. 2004. Morphological Analysis for 
Statistical Machine Translation. In Proceedings 
of HLT-NAACL?04, Boston, MA, USA.  
Franz Josef Och and Hermann Ney. 2003. A Sys-
tematic Comparison of Various Statistical 
Alignment Models. Computational Linguistics, 
29 (1):19?52.  
Franz Josef Och. 2003. Minimum Error Rate Train-
ing for Statistical Machine Translation. In Pro-
ceedings of ACL?03, Sapporo, Japan. 
Fatiha Sadat and Nizar Habash. 2006. Combination 
of Arabic preprocessing schemes for statistical 
machine translation. In Proceedings of Coling-
ACL?06. Sydney, Australia. 
Kishore Papineni, Salim Roukos, Todd Ward, and 
Wei-Jing Zhu. 2002. BLEU: a Method for 
Automatic Evaluation of Machine Translation. 
In Proceedings of ACL?02, Philadelphia, PA, 
USA.  
Charles Schafer & David Yarowsky. 2002. Induc-
ing translation lexicons via diverse similarity 
measures and bridge languages. In Proceedings 
of CoNLL?02, Taipei, Taiwan. 
Micheal. Simard. 1999. Text translation alignment: 
Three languages are better than two. In Pro-
ceedings of EMNLP-VLC?99, College Park, 
MD, USA. 
Michel Simard, Nicola Ueffing, Pierre Isabelle, and 
Roland Kuhn. 2007. Rule-based translation 
with statistical phrase-based post-editing. In 
Proceedings of the workshop on Statistical 
Machine Translation, ACL?07, Prague, Czech 
Republic.   
Andreas Stolcke. 2002. SRILM - an Extensible 
Language Modeling Toolkit. In Proceedings of 
ICSLP?02, Denver, CO, USA. 
Masao Utiyama and Hitoshi Isahara. 2007. A com-
parison of pivot methods for phrase-based sta-
tistical machine translation. In Proceedings of 
NAACL-HLT?07, Rochester, NY, USA. 
Chao Wang, Michael Collins, and Philipp Koehn. 
2007. Chinese syntactic reordering for statisti-
cal machine translation.  In Proceedings of 
EMNLP-CoNLL?07, Prague, Czech Republic.   
Dekai Wu. 1998. A Position Statement on Chinese 
Segmentation.  Presented at the Chinese Lan-
guage Processing Workshop. http://www. 
cs.ust.hk/~dekai/papers/segmentation.html. 
Hua Wu and Haifeng Wang. 2007. Pivot language 
aproach for phrase-based statistical machine 
translation. In Proceedings of ACL?07, Prague, 
Czech Republic.   
Yang Ye, Karl-Michael Schneider, and Steven 
Abney. 2007. Aspect marker generation in 
English-to-Chinese machine translation. In 
Proceedings of MT Summit XI, Copenhagen, 
Denmark. 
Ying Zhang, Stephan Vogel and Alex Waibel, In-
terpreting Bleu/NIST scores: How much im-
provement do we need to have a better system?, 
In Proceedings of LREC?04, Lisbon, Portugal.  
 
 
181
