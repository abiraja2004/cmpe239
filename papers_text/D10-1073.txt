Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 745?755,
MIT, Massachusetts, USA, 9-11 October 2010. c?2010 Association for Computational Linguistics
Word Sense Induction & Disambiguation Using
Hierarchical Random Graphs
Ioannis P. Klapaftis
Department of Computer Science
University of York
United Kingdom
giannis@cs.york.ac.uk
Suresh Manandhar
Department of Computer Science
University of York
United Kingdom
suresh@cs.york.ac.uk
Abstract
Graph-based methods have gained attention in
many areas of Natural Language Processing
(NLP) including Word Sense Disambiguation
(WSD), text summarization, keyword extrac-
tion and others. Most of the work in these ar-
eas formulate their problem in a graph-based
setting and apply unsupervised graph cluster-
ing to obtain a set of clusters. Recent studies
suggest that graphs often exhibit a hierarchi-
cal structure that goes beyond simple flat clus-
tering. This paper presents an unsupervised
method for inferring the hierarchical group-
ing of the senses of a polysemous word. The
inferred hierarchical structures are applied to
the problem of word sense disambiguation,
where we show that our method performs sig-
nificantly better than traditional graph-based
methods and agglomerative clustering yield-
ing improvements over state-of-the-art WSD
systems based on sense induction.
1 Introduction
A number of NLP problems can be cast into a graph-
based framework, in which entities are represented
as vertices in a graph and relations between them are
depicted by weighted or unweighted edges. For in-
stance, in unsupervised WSD a number of methods
(Widdows and Dorow, 2002; Ve?ronis, 2004; Agirre
et al, 2006) have constructed word co-occurrence
graphs for a target polysemous word and applied
graph-clustering to obtain the clusters (senses) of
that word.
Similarly in text summarization, Mihalcea (2004)
developed a method, in which sentences are rep-
resented as vertices in a graph and edges between
them are drawn according to their common tokens
or words of a given POS category, e.g. nouns.
Graph-based ranking algorithms, such as PageRank
(Brin and Page, 1998), were then applied in order
to determine the significance of sentences. In the
same vein, graph-based methods have been applied
to other problems such as determining semantic sim-
ilarity of text (Ramage et al, 2009).
Recent studies (Clauset et al, 2006; Clauset et
al., 2008) suggest that graphs exhibit a hierarchi-
cal structure (e.g. a binary tree), in which vertices
are divided into groups that are further subdivided
into groups of groups, and so on, until we reach the
leaves. This hierarchical structure provides addi-
tional information as opposed to flat clustering by
explicitly including organisation at all scales of a
graph (Clauset et al, 2008). In this paper, we present
an unsupervised method for inferring the hierarchi-
cal structure (binary tree) of a graph, in which ver-
tices are the contexts of a polysemous word and
edges represent the similarity between contexts. The
method that we use to infer that hierarchical struc-
ture is the Hierarchical Random Graphs (HRGs) al-
gorithm due to Clauset et al (2008).
The binary tree produced by our method groups
the contexts of a polysemous word at different
heights of the tree. Thus, it induces the senses of
that word at different levels of sense granularity. To
evaluate our method, we apply it to the problem of
noun sense disambiguation showing that inferring
the hierarchical structure using HRGs provides ad-
ditional information from the observed graph lead-
ing to improved WSD performance compared to: (1)
745
Figure 1: Stages of the proposed method.
simple flat clustering, and (2) traditional agglomera-
tive clustering. Finally, we compare our results with
state-of-the-art sense induction systems and show
that our method yields improvements. Figure 1
shows the different stages of the proposed method
that we describe in the following sections.
2 Related work
Typically, graph-based methods, when applied to
unsupervised sense disambiguation represent each
word wi co-occurring with the target word tw as a
vertex. Two vertices are connected via an edge if
they co-occur in one or more contexts of tw. Once
the co-occurrence graph of tw has been constructed,
different graph clustering algorithms are applied to
induce the senses. Each cluster (induced sense) con-
sists of a set of words that are semantically related to
the particular sense. Figure 2 shows an example of
a graph for the target word paper that appears with
two different senses scholarly article and newspa-
per.
Ve?ronis (2004) has shown that co-occurrence
graphs are small-world networks that contain highly
dense subgraphs representing the different clusters
(senses) of the target word (Ve?ronis, 2004). To iden-
tify these dense regions Ve?ronis?s algorithm itera-
tively finds their hubs, where a hub is a vertex with a
very high degree. The degree of a vertex is defined to
be the number of edges incident to that vertex. The
identified hub is then deleted along with its direct
neighbours from the graph producing a new cluster.
For example, in Figure 2 the highest degree ver-
tex, news, is the first hub, which would be deleted
along with its direct neighbours. The deleted re-
gion corresponds to the newspaper sense of the tar-
get word paper. Ve?ronis (2004) further processed
the identified clusters (senses), in order to assign the
rest of graph vertices to the identified clusters by
utilising the minimum spanning tree of the original
graph.
In Agirre et al (2006), the algorithm of Ve?ronis
(2004) is analysed and assessed on the SensEval-3
dataset (Snyder and Palmer, 2004), after optimis-
ing its parameters on the SensEval-2 dataset (Ed-
monds and Dorow, 2001). The results show that the
WSD F-Score outperforms the Most Frequent Sense
(MFS) baseline by approximately 10%, while induc-
ing a large number of clusters (with averages of 60
to 70).
Another graph-based method is presented in
(Dorow and Widdows, 2003). They extract only
noun neighbours that appear in conjunctions or dis-
junctions with the target word. Additionally, they
extract second-order co-occurrences. Nouns are rep-
resented as vertices, while edges between vertices
are drawn, if their associated nouns co-occur in con-
junctions or disjunctions more than a given num-
ber of times. This co-occurrence frequency is also
used to weight the edges. The resulting graph is
then pruned by removing the target word and ver-
tices with a low degree. Finally, the MCL algorithm
(Dongen, 2000) is used to cluster the graph and pro-
duce a set of clusters (senses) each one consisting of
a set of contextually related words.
Chinese Whispers (CW) (Biemann, 2006) is a
parameter-free1 graph clustering method that has
been applied in sense induction to cluster the co-
occurrence graph of a target word (Biemann, 2006),
as well as a graph of collocations related to the tar-
get word (Klapaftis and Manandhar, 2008). The
evaluation of the collocational-graph method in the
SemEval-2007 sense induction task (Agirre and
Soroa, 2007) showed promising results.
All the described methods for sense induction ap-
1One needs to specify only the number of iterations. The
number of clusters is generated automatically.
746
Figure 2: Graph of words for the target word paper.
Numbers inside vertices correspond to their degree.
Figure 3: Running example of graph creation
ply flat graph clustering methods to derive the clus-
ters (senses) of a target word. As a result, they ne-
glect the fact that their constructed graphs often ex-
hibit a hierarchical structure that is useful in several
tasks including word sense disambiguation.
3 Building a graph of contexts
This section describes the process of creating a
graph of contexts for a polysemous target word. Fig-
ure 3 provides a running example of the different
stages of our method. In the example, the target
word paper appears with the scholarly article sense
in the contexts A, B, and with the newspaper sense
in the contexts C and D.
3.1 Corpus preprocessing
Let bc denote the base corpus consisting of the con-
texts containing the target word tw. In our work,
a context is defined as a paragraph2 containing the
target word.
The aim of this stage is to capture nouns contex-
tually related to tw. Initially, the target word is re-
moved from bc and part-of-speech tagging is applied
to each context. Following the work in (Ve?ronis,
2004; Agirre et al, 2006) only nouns are kept and
lemmatised. In the next step, the distribution of each
noun in the base corpus is compared to the distri-
bution of the same noun in a reference corpus3 us-
ing the log-likelihood ratio (G2) (Dunning, 1993).
Nouns with a G2 below a pre-specified threshold
(parameter p1) are removed from each paragraph of
the base corpus. The upper left part of Figure 3
shows the words kept as a result of this stage.
3.2 Graph creation
Graph vertices: To create the graph of vertices, we
represent each context ci as a vertex in a graph G.
Graph edges: Edges between the vertices of the
graph are drawn based on their similarity, defined
in Equation 1, where simcl(ci, cj) is the colloca-
tional weight of contexts ci, cj and simwd(ci, cj)
is their bag-of-words weight. If the edge weight
W (ci, cj) is above a prespecified threshold (param-
eter p3), then an edge is drawn between the corre-
sponding vertices in the graph.
W (ci, cj) =
1
2
(simcl(ci, cj) + simwd(ci, cj)) (1)
Collocational weight: The limited polysemy of col-
locations can be exploited to compute the similarity
between contexts ci and cj . In our setting, a colloca-
tion is a juxtaposition of two nouns within the same
context. Thus, given a context ci, each of its nouns
is combined with any other noun yielding a total of
(N
2
)
collocations for a context with N nouns. Each
collocation, clij is weighted using the log-likelihood
ratio (G2) (Dunning, 1993) and is filtered out if the
G2 is below a prespecified threshold (parameter p2).
At the end of this process, each context ci of tw is
associated with a vector of collocations (vi). The
upper right part of Figure 3 shows the collocations
associated with each context of our example.
2Our definition of context is equivalent to an instance of the
target word in the SemEval-2007 sense induction task dataset
(Agirre and Soroa, 2007).
3The British National Corpus, 2001, Distributed by Oxford
University Computing Services.
747
Given two contexts ci and cj , we calculate their
collocational weight using the Jaccard coefficient
on the collocational vectors, i.e. simcl(ci, cj) =
|vi?vj |
|vi?vj |
. The selection of Jaccard is based on the work
of Weeds et al (2004), who analyzed the variation
in a word?s distributionally nearest neighbours with
respect to a variety of similarity measures. Their
analysis showed that there are three classes of mea-
sures, i.e. those selecting distributionally more gen-
eral neighbours (e.g. cosine), those selecting distri-
butionally less general neighbours (e.g. AMCRM-
Precision (Weeds et al, 2004)) and those without a
bias towards the distributional generality of a neigh-
bour (e.g. Jaccard). In our setting, we are interested
in calculating the similarity between two contexts
without any bias. We selected Jaccard, since the rest
of that class?s measures are based on pointwise mu-
tual information that assigns high weights to infre-
quent events.
Bag-of-words weight: Estimating context similar-
ity using collocations may provide reliable estimates
regarding the existence of an edge in the graph, how-
ever, it also suffers from data sparsity. For this rea-
son, we also employ a bag-of-words model. Specif-
ically, each context ci is associated with a vector gi
that contains the nouns kept as result of the corpus
preprocessing stage. The upper left part of Figure
3 shows the words associated with each context of
our example. Given two contexts ci and cj , we cal-
culate their bag-of-words weight using the Jaccard
coefficient on the word vectors, i.e. simwd(ci, cj) =
|gi?gj |
|gi?gj |
.
The collocational weight and bag-of-words
weight are averaged to derive the edge weight be-
tween two contexts as defined in Equation 1. The
resulting graph of our running example is shown on
the bottom of Figure 3. This graph is the input to the
hierarchical random graphs method (Clauset et al,
2008) described in the next section.
4 Hierarchical Random Graphs for sense
induction
In this section, we describe the process of inferring
the hierarchical structure of the graph of contexts
using hierarchical random graphs (Clauset et al,
2008).
Figure 4: Two dendrograms for the graph in Figure 3.
4.1 The Hierarchical Random Graph model
A dendrogram is a binary tree with n leaves and
n ? 1 parents. Figure 4 shows an example of two
dendrograms with 4 leaves and 3 parents. Given a
set of n contexts that we need to arrange hierarchi-
cally, let us denote by G = (V,E) the graph of con-
texts, where V = {v0, v1 . . . vn} is the set of ver-
tices, E = {e0, e1 . . . em} is the set of edges and
ek = {vi, vj}.
Given an undirected graph G, each of its n ver-
tices is a leaf in a dendrogram, while the internal
nodes of that dendrogram indicate the hierarchical
relationships among the leaves. We denote this or-
ganisation byD = {D1, D2, . . . Dn?1}, where each
Dk is an internal node. Every pair of nodes (vi, vj)
is associated with a unique Dk, which is their low-
est common ancestor in the tree. In this manner D
partitions the edges that exist in G.
The primary assumption in the hierarchical ran-
dom graph model is that edges in G exist indepen-
dently, but with a probability that is not identically
distributed. In particular, the probability that an edge
{vi, vj} exists in G is given by a parameter ?k asso-
ciated with Dk, the lowest common ancestor of vi
and vj in D. In this manner, the topological struc-
ture D and the vector of probabilities ~? define the
HRG given by H(D, ~?) (Clauset et al, 2008).
748
4.2 HRG parameterisation
Assuming a uniform prior over all HRGs, the target
is to identify the parameters of D and ~?, so that the
chosen HRG is statistically similar to G. Let Dk be
an internal node of dendrogram D and f(Dk) be the
number of edges between the vertices of the subtrees
of the subtree rooted at Dk that actually exist in G.
For example, in Figure 4(A), f(D2) = 1, because
there is one edge in G connecting vertices B and C.
Let l(Dk) be the number of leaves in the left subtree
of Dk, and r(Dk) be the number of leaves in the
right subtree. For example in Figure 4(A), l(D2) =
2 and r(D2) = 2. The likelihood of the hierarchical
random graph (D, ~?) is defined in Equation 2, where
A(Dk) = l(Dk)r(Dk)? f(Dk).
L(D, ~?) =
?
Dk?D
?f(Dk)k (1? ?k)
A(Dk) (2)
The probabilities ?k that maximise the likelihood
of a dendrogram D can be easily estimated using
the method of MLE i.e ?k =
f(Dk)
l(Dk)r(Dk)
. Substi-
tuting this into Equation 2 yields Equation 3. For
numerical reasons, it is more convenient to work
with the logarithm of the likelihood which is defined
in Equation 4, where h(?k) = ??k log ?k ? (1 ?
?k) log (1? ?k).
L(D) =
?
Dk?D
[?
?k
k (1? ?k)
1??k ]l(Dk)r(Dk) (3)
logL(D) = ?
?
Dk?D
h(?k)l(Dk)r(Dk) (4)
As can be observed, each term ?l(Dk)r(Dk)h(?k)
is maximised when ?k approaches 0 or 1. This
means that high-likelihood dendrograms partition
vertices into subtrees, such that the connections
among their vertices in the observed graph are either
very rare or very common (Clauset et al, 2008). For
example, consider the two dendrograms in Figures
4(A) and 4(B). We observe that 4(A) is more likely
than 4(B), since it provides a better division of the
network leaves. Particularly, the likelihood of 4(A)
is L(D1) = (11 ? (1? 1)1) ? (11 ? (1? 1)1) ? (0.251 ?
(1 ? 0.25)3) = 0.105, while the likelihood of 4(B)
is L(D2) = (00 ? (1? 0)1) ? (11 ? (1? 1)1) ? (0.52 ?
(1? 0.5)2) = 0.062.
4.2.1 MCMC sampling
Finding the values of ?k using the MLE method
is straightforward. However, this is not the case
for maximising the likelihood function over the
space of all possible dendrograms. Given a graph
with n vertices, i.e. n leaves in each dendrogram,
the total number of different dendrograms is super-
exponential ((2n? 3)!! ?
?
2(2n)n?1e?n) (Clauset
et al, 2006).
To deal with this problem, we use a Markov
Chain Monte Carlo (MCMC) method that samples
dendrograms from the space of dendrogram mod-
els with probability proportional to their likelihood.
Each time MCMC samples a dendrogram with a
new highest likelihood, that dendrogram is stored.
Hence, our goal is to choose the highest likelihood
dendrogram once MCMC has converged.
Following the work in (Clauset et al, 2008),
we pick a set of transitions between dendrograms,
where a transition is a re-arrangement of the sub-
trees of a dendrogram. In particular, given a current
dendrogram Dcurr, each internal node Dk of Dcurr
is associated with three subtrees of Dcurr. For in-
stance, in Figure 5A, the subtrees st1 and st2 are
derived from the two children of Dk and the third
st3 from its sibling. Given a current dendrogram,
Dcurr, the algorithm proceeds as follows:
1. Choose an internal node, Dk ? Dcurr uni-
formly.
2. Generate two possible new configurations of
the subtrees of Dk (See Figure 5).
3. Choose one of the configurations uniformly to
generate a new dendrogram, Dnext.
4. Accept or reject Dnext according to
Metropolis-Hastings (MH) rule.
5. If transition is accepted, then Dcurr = Dnext.
6. GOTO 1.
According to MH rule (Newman and Barkema,
1999), a transition is accepted if logL(Dnext) ?
logL(Dcurr); otherwise the transition is accepted
with probability L(Dnext)L(Dcurr) . These transitions define
an ergodic Markov chain, hence its stationary distri-
bution can be reached (Clauset et al, 2008).
749
Figure 5: (A) current configuration for internal node Dk and its associated subtrees (B) first alternative configuration,
(C) second alternative configuration. Note that swapping st1, st2 in (A) results in an equivalent tree. Hence, this
configuration is excluded.
In our experiments, we noticed that the algorithm
converged relatively quickly. The same behaviour
(roughly O(n2) steps) was also noticed in Clauset et
al. (2008), when considering graphs with thousands
of vertices.
5 HRGs for sense disambiguation
5.1 Sense mapping
The output of HRG learning is a dendrogramD with
n leaves (contexts) and n?1 internal nodes. To per-
form sense disambiguation, we mapped the internal
nodes to gold standard senses using a sense-tagged
corpus. Such a sense-tagged corpus is needed when
induced word senses need to be mapped to a gold
standard sense inventory.
Instead of using a hard mapping from the den-
drogram internal nodes to the Gold Standard (GS)
senses, we use a soft probabilistic mapping and cal-
culateP (sk|Di), i.e the probability of sense sk given
node Di. Let F (Di) be the set of training contexts
grouped by internal node Di. Let F ?(sk) be the set
of training contexts that are tagged with sense sk.
Then the conditional probability, P (sk|Di), is de-
fined in Equation 5.
P (sk|Di) =
|F (Di) ? F ?(sk)|
|F (Di)|
(5)
Table 1 provides a sense-tagged corpus for the
running example of Figure 3. Using this corpus
and the tree in Figure 4(A), P (s1|D2) = 23 and
P (s2|D2) = 13 . In Figure 4(A) the rest of the calcu-
lated conditional probabilities are given.
5.2 Sense tagging
For evaluation we compared the proposed method
against the current state-of-the-art sense induction
GS sense Context ID Context words
s1 A journal, scholar, observation
science, paper
s1 B scholar, scholar, author,
publication, paper
s2 D times, guardian,
journalist, paper
Table 1: Sense-tagged corpus for the example in Figure 3
systems in the WSD task. We followed the setting
of SemEval-2007 sense induction task (Agirre and
Soroa, 2007). In this setting, the base corpus (bc)
(Section 3.1) for a target word consists both of the
training and testing corpus. As a result, a testing
context cj of tw is a leaf in the generated dendro-
gram. The process of disambiguating cj is straight-
forward exploiting the structural information pro-
vided by HRGs.
w(sk, cj) =
?
Di?H(cj)
P (sk|Di) ? ?i (6)
w(s?, cj) = argmax sk(w(sk, cj)) (7)
Let H(cj) denote the set of parents for context cj .
Then, the weight assigned to sense sk is the sum of
weighted scores provided by each identified parent.
This is shown in Equation 6, where ?i is the proba-
bility associated with each internal nodeDi from the
hierarchical random graph (see Figure 4(A)). This
probability reflects the discriminating ability of in-
ternal nodes.
Finally, the highest weight determines the win-
ning sense for context cj (Equation 7). In our ex-
ample (Figure 4(A)), w(s1, C) = (0 ?1+ 23 ?0.25) =
0.16 andw(s2, C) = (1?1+ 13 ?0.25) = 1.08. Hence,
s2 is the winning sense.
750
Parameter Range
G2 word threshold (p1) 15,25,35,45
G2 collocation threshold (p2) 10,15,20
Edge similarity threshold (p3) 0.05,0.09,0.13
Table 2: Parameter values used in the evaluation.
6 Evaluation
6.1 Evaluation setting & baselines
We evaluate our method on the nouns of the
SemEval-2007 word sense induction task (Agirre
and Soroa, 2007) under the second evaluation setting
of that task, i.e. supervised evaluation. Specifically,
we use the standard WSD measures of precision and
recall in order to produce their harmonic mean (F-
Score). The official scoring software of that task has
been used in our evaluation. Note that the unsuper-
vised measures of that task are not directly applica-
ble to our induced hierarchies, since they focus on
assessing flat clustering methods.
The first aim of our evaluation is to test whether
inferring the hierarchical structure of the constructed
graphs improves WSD performance. For that reason
our first baseline, Chinese Whispers Unweighted
version (CWU), takes as input the same unweighted
graph of contexts as HRGs in order to produce a
flat clustering. The set of produced clusters is then
mapped to GS senses using the training dataset and
performance is then measured on the testing dataset.
We followed the same sense mapping method as in
the SemEval-2007 sense induction task (Agirre and
Soroa, 2007).
Our second baseline, Chinese Whispers Weighted
version (CWW), is similar to the previous one, with
the difference that the edges of the input graph
are weighted using Equation 1. For clustering the
graphs of CWU and CWW we employ, Chinese
Whispers4 (Biemann, 2006).
The second aim of our evaluation is to assess
whether the hierarchical structure inferred by HRGs
is more informative than the hierarchical struc-
ture inferred by traditional Hierarchical Clustering
(HAC). Hence, our third baseline, takes as input a
similarity matrix of the graph vertices and performs
bottom-up clustering with average-linkage, which
has already been used in WSI in (Pantel and Lin,
4The number of iterations for CW was set to 200.
2003) and was shown to have superior or similar per-
formance to single-linkage and complete-linkage in
the related problem of learning a taxonomy of senses
(Klapaftis and Manandhar, 2010).
To calculate the similarity matrix of vertices we
follow a process similar to the one used in Sec-
tion 4.2 for calculating the probability of an inter-
nal node. The similarity between two vertices is
calculated according to the degree of connected-
ness among their direct neighbours. Specifically,
we would like to assign high similarity to pairs of
vertices, whose neighbours are close to forming a
clique.
Given two vertices (contexts) ci and cj , let
N(ci, cj) be the set of their neighbours andK(ci, cj)
be the set of edges between the vertices inN(ci, cj).
The maximum number of edges that could exist be-
tween vertices in N(ci, cj) is
(|N(ci,cj)|
2
)
. Thus, the
similarity of ci, cj is set equal to the number of
edges that actually exist in that neighbourhood di-
vided by the total number of edges that could exist
( |K(ci,cj)|
(|N(ci,cj)|2 )
).
The disambiguation process using the HAC tree
is identical to the one presented in Section 5.2 with
the only difference that the internal probability, ?i,
in Equation 6 does not exist for HAC. Hence, we re-
placed it with the factor 1|H(Di)| , whereH(Di) is the
set of children of internal node Di. This factor pro-
vides lower weights for nodes high in the tree, since
their discriminating ability will possibly be lower.
6.2 Results & discussion
Table 2 shows the parameter values used in the eval-
uation. Figure 6(A) shows the performance of the
proposed method against the baselines for p3 = 0.05
and different p1 and p2 values. Figure 6(B) il-
lustrates the results of the same experiment using
p3 = 0.09. In both figures, we observe that HRGs
outperform the CWU baseline under all parameter
combinations. In particular, all of the 12 perfor-
mance differences for p3 = 0.09 are statistically
significant using McNemar?s test at 95% confidence
level, while for p3 = 0.05 only 2 out of the 12 per-
formance differences were not judged as significant
from the test.
The picture is the same for p3 = 0.13, where
CWU performs significantly worse than for p3 =
751
Figure 6: Performance analysis of HRGs, CWU, CWW & HAC for different parameter combinations (Table 2). (A)
All combinations of p1, p2 and p3 = 0.05. (B) All combinations of p1, p2 and p3 = 0.09.
0.05 and p3 = 0.09. Specifically, the largest perfor-
mance difference between HRGs and CWU is 9.4%
at p1 = 25, p2 = 10 and p3 = 0.13. Setting the ver-
tex similarity threshold (p3) equal to 0.13 leads to
more sparse and disconnected graphs, which causes
Chinese Whispers to produce a large number of clus-
ters. This leads to sparsity problems and unreliable
mapping of clusters to GS senses due to the lack of
adequate training data. In contrast, HRGs suffer less
at this high threshold, although their performance
when p3<0.13 is better.
This picture does not change for the weighted ver-
sion of Chinese Whispers (CWW) which performs
worse than CWU. This is because CWW produces
a smaller number of clusters than CWU that con-
flate the target word senses. It seems that using
weighted edges creates a bias towards the MFS, in
effect missing rare senses of a target word. This
means that a number of words in the bag-of-words
context vectors and collocations in the collocational
context vectors (Section 3.2) are associated to more
than one sense of the target word and most strongly
associated to the MFS. As a result, increasing the p1
threshold to 25 and 35 leads to a higher performance
for CWW, since many of these words and colloca-
tions are filtered out.
Overall, the comparison of HRGs against the
CWU and CWW baselines has shown that inferring
the hierarchical structure of observed graphs leads
to improved WSD performance as opposed to using
flat clustering. This is because HRGs are able to in-
fer both the hierarchical structure of the graph and
include the probabilities, ?k, associated with each
internal node. These probabilities reflect the dis-
criminating ability of each node, offering informa-
tion missed by flat clustering.
In Figures 6(A) and 6(B) we observe that HRGs
perform significantly better than HAC. In particular,
all of their performance differences are statistically
significant for these parameter values. The largest
performance difference is 6.0% at p1 = 45, p2 = 10
and p3 = 0.05. However, this picture is not the same
when considering a higher context similarity thresh-
old (p3 = 0.13) as Figure 7 shows. In particular,
HRGs and HAC perform similarly for p3 = 0.13,
while the majority of performance differences are
not statistically significant.
The similar behaviour of HRGs and HAC at this
threshold is caused both by the worse performance
of HRGs and the improved performance of HAC as
opposed to lower p3 values. As it has been men-
tioned, setting p3 = 0.13 leads to sparse and dis-
connected graphs. Additionally, the likelihood func-
tion (Equation 3) is maximised when the probabil-
ity, ?k, of an internal node, Dk, approaches 0 or 1.
This creates a bias towards dendrograms, in which a
large number of internal nodes have zero probabil-
ity. These dendrograms might be a good-fit to the
observed graph, but not to the GS.
In contrast, HAC is less affected, because it never
considers creating an internal node, when the max-
imum similarity among any pair of two candidate
752
Figure 7: Performance of HRGs and HAC for different
parameter combinations (Table 2). All combinations of
p1, p2 and p3 ? 0.13.
subtrees is zero. Additionally, our experiments show
that HAC is unable to deal with noise when con-
sidering sparse graphs (p3<0.13). For that reason,
the F-Score of HAC increases as the edge similarity
threshold decreases.
To further investigate this issue and test whether
HAC is able to achieve a higher F-Score than HRGs
in higher p3 values, we executed two more experi-
ments for HAC and HRGs increasing p3 to 0.17 and
0.21 respectively. In the first case we observed that
the performance of HAC remained relatively stable
compared to p3 = 0.13, while in the second case the
performance of HAC decreased as Figure 7 shows.
In both cases, HAC performed significantly better
than HRGs.
Overall, the comparison of HRGs against HAC
has shown that HRGs perform significantly better
than HAC when considering connected or less sparse
graphs (p3<0.13). This is due to the fact that HAC
creates dendrograms, in which connections within
the clusters are dense, while connections between
the clusters are sparse, i.e. it only considers assorta-
tive structures. In contrast, HRGs also consider dis-
assortative dendrograms, i.e. dendrograms in which
vertices are less likely to be connected on small
scales than on large ones, as well as mixtures of
assortative and disassortative (Clauset et al, 2008).
This is achieved by allowing the probability ?k of
a node k to vary arbitrarily throughout the dendro-
gram.
HAC performs similarly or better than HRGs for
largely disconnected and sparse graphs, because
HRGs become biased towards disassortative trees
which are not a good fit to the GS (Figure 7). De-
spite that, our evaluation has also shown that the best
performance of HAC (F-Score = 86.0% at p1 = 15,
p2 = 10, p3 = 0.13) is significantly lower than
the best performance of HRGs (F-Score = 87.6% at
p1 = 35, p2 = 10, p3 = 0.09).
6.3 Comparison to state-of-the-art methods
Table 3 compares the best performing parameter
combination of our method against state-of-the-art
methods. Table 3 also includes the best performance
of our baselines, i.e HAC, CWU and CWW.
Brody & Lapata (2009) presented a sense induc-
tion method that is related to Latent Dirichlet Al-
location (Blei et al, 2003). In their work, they
model the target word instances as samples from a
multinomial distribution over senses which are suc-
cessively characterized as distributions over words
(Brody and Lapata, 2009). A significant advantage
of their method is the inclusion of more than one
layer in the LDA setting, where each layer corre-
sponds to a different feature type e.g. dependency
relations, bigrams, etc. The inclusion of different
feature types as separate models in the sense in-
duction process can easily be modeled in our set-
ting, by inferring a different hierarchy of target word
instances according to each feature type, and then
combining all of them to a consensus tree. In this
work, we have focused on extracting a single hierar-
chy combining word co-occurrence and bigram fea-
tures.
Niu et al (2007) developed a vector-based
method that performs sense induction by group-
ing the contexts of a target word using three types
of features, i.e. POS tags of neighbouring words,
word co-occurrences and local collocations. The se-
quential information bottleneck algorithm (Slonim
et al, 2002) is applied for clustering. HRGs perform
slightly better than the methods of Brody & Lap-
ata (2009) and Niu et al (2007), although the dif-
ferences are not significant (McNemar?s test at 95%
confidence level).
Klapaftis & Manandhar (2008) developed a
graph-based sense induction method, in which ver-
tices correspond to collocations related to the tar-
get word and edges between vertices are drawn ac-
753
System Performance (%)
HRGs 87.6
(Brody and Lapata, 2009) 87.3
(Niu et al, 2007) 86.8
(Klapaftis and Manandhar, 2008) 86.4
HAC 86.0
CWU 85.1
CWW 84.7
(Pedersen, 2007) 84.5
MFS 80.9
Table 3: HRGs against recent methods & baselines.
cording to the co-occurrence frequency of the cor-
responding collocations. The constructed graph is
smoothed to identify more edges between vertices
and then clustered using Chinese Whispers (Bie-
mann, 2006). This method is related to the basic
inputs of our presented method. Despite that, it is
a flat clustering method that ignores the hierarchical
structure exhibited by observed graphs. The previ-
ous section has shown that inferring the hierarchical
structure of graphs leads to superior WSD perfor-
mance.
Pedersen (2007) presented SenseClusters, a
vector-based method that clusters second order co-
occurrence vectors using k-means, where k is auto-
matically determined using the Adapted Gap Statis-
tic (Pedersen and Kulkarni, 2006). As can be ob-
served, HRGs perform significantly better than the
methods of Pedersen (2007) and Klapaftis & Man-
andhar (2008) (McNemar?s test at 95% confidence
level).
Finally, Table 3 shows that the best performing
parameter combination of HRGs achieves a signifi-
cantly higher F-Score than the best performing pa-
rameter combination of HAC, CWU and CWW. Fur-
thermore, HRGs outperform the most frequent sense
baseline by 6.7%.
7 Conclusion & future work
We presented an unsupervised method for inferring
the hierarchical grouping of the senses of a polyse-
mous word. Our method creates a graph, in which
vertices correspond to contexts of a polysemous tar-
get word and edges between them are drawn ac-
cording to their similarity. The hierarchical random
graphs algorithm (Clauset et al, 2008) was applied
to the constructed graph in order to infer its hierar-
chical structure, i.e. binary tree.
The learned tree provides an induction of the
senses of a given word at different levels of sense
granularity and was applied to the problem of WSD.
The WSD process mapped the tree?s internal nodes
to GS senses using a sense tagged corpus, and then
tagged new instances by exploiting the structural in-
formation provided by the tree.
Our experimental results have shown that our
graphs exhibit hierarchical organisation that can
be captured by HRGs, in effect providing im-
proved WSD performance compared to flat cluster-
ing. Additionally, our comparison against hierarchi-
cal agglomerative clustering with average-linkage
has shown that HRGs perform significantly better
than HAC when the graphs do not suffer from spar-
sity (disconnected graphs). The comparison with
state-of-the-art sense induction systems has shown
that our method yields improvements.
Our future work focuses on using different feature
types, e.g. dependency relations, second-order co-
occurrences, named entities and others to construct
our undirected graphs and then applying HRGs, in
order to measure the impact of each feature type
on the induced hierarchical structures within a WSD
setting. Moreover, following the work in (Clauset et
al., 2008), we are also working on using MCMC in
order to sample more than one dendrogram at equi-
librium, and then combine them to a consensus tree.
This consensus tree might be able to express a larger
amount of topological features of the initial undi-
rected graph.
Finally in terms of evaluation, our future work
also focuses on evaluating HRGs using a fine-
grained sense inventory, extending the evaluation on
the SemEval-2010 WSI task dataset (Manandhar et
al., 2010) as well as applying HRGs to other related
tasks such as taxonomy learning.
Acknowledgements
This work is supported by the European Com-
mission via the EU FP7 INDECT project, Grant
No.218086, Research area: SEC-2007-1.2-01 Intel-
ligent Urban Environment Observation System. The
authors would like to thank the anonymous review-
ers for their useful comments.
754
References
Eneko Agirre and Aitor. Soroa. 2007. Semeval-2007
Task 02: Evaluating Word Sense Induction and Dis-
crimination Systems. In Proceedings of SemEval-
2007, pages 7?12, Prague, Czech Republic.
Eneko Agirre, David Mart??nez, Oier Lo?pez de Lacalle,
and Aitor Soroa. 2006. Two Graph-based Algorithms
for State-of-the-art WSD. In Proceedings of EMNLP-
2006, pages 585?593, Sydney, Australia.
Chris Biemann. 2006. Chinese Whispers - An Efficient
Graph Clustering Algorithm and its Application to
Natural Language Processing Problems. In Proceed-
ings of TextGraphs, pages 73?80, New York, USA.
David M. Blei, Andrew Y. Ng, and Michael I. Jordan.
2003. Latent Dirichlet Allocation. J. Mach. Learn.
Res., 3:993?1022.
Sergey Brin and Lawrence Page. 1998. The Anatomy
of a Large-Scale Hypertextual Web Search Engine.
Comput. Netw. ISDN Syst., 30(1-7):107?117.
Samuel Brody and Mirella Lapata. 2009. Bayesian Word
Sense Induction. In Proceedings of EACL-2009, pages
103?111, Athens, Greece. ACL.
Aaron Clauset, Cristopher Moore, and Mark E. J. New-
man. 2006. Structural Inference of Hierarchies in Net-
works. In Proceedings of the ICML-2006 Workshop
on Social Network Analysis, pages 1?13, Pittsburgh,
USA.
Aaron Clauset, Cristopher Moore, and Mark E. J. New-
man. 2008. Hierarchical Structure and the Prediction
of Missing Links in Networks. Nature, 453(7191):98?
101.
Stijn Dongen. 2000. Performance Criteria for Graph
Clustering and Markov Cluster Experiments. Tech-
nical report, CWI (Centre for Mathematics and Com-
puter Science), Amsterdam, The Netherlands.
Beate Dorow and Dominic Widdows. 2003. Discovering
Corpus-specific Word Senses. In Proceedings of the
EACL-2003, pages 79?82, Budapest, Hungary.
Ted Dunning. 1993. Accurate Methods for the Statistics
of Surprise and Coincidence. Computational Linguis-
tics, 19(1):61?74.
Phil Edmonds and Beate Dorow. 2001. Senseval-2:
Overview. In Proceedings of SensEval-2, pages 1?5,
Toulouse, France.
Ioannis P. Klapaftis and Suresh Manandhar. 2008. Word
Sense Induction Using Graphs of Collocations. In
Proceedings of ECAI-2008, pages 298?302, Patras,
Greece.
Ioannis P. Klapaftis and Suresh Manandhar. 2010. Tax-
onomy Learning Using Word Sense Induction. In Pro-
ceedings of NAACL-HLT-2010, pages 82?90, Los An-
geles, California, June. ACL.
Suresh Manandhar, Ioannis P. Klapaftis, Dmitriy Dli-
gach, and Sameer S. Pradhan. 2010. Semeval-2010
Task 14: Word Sense Induction & Disambiguation. In
Proceedings of SemEval-2, Uppsala, Sweden. ACL.
Rada Mihalcea. 2004. Graph-based Ranking Algorithms
for Sentence Extraction, Applied to Text Summariza-
tion. In Proceedings of the ACL 2004 on Interactive
poster and demonstration sessions, page 20, Morris-
town, NJ, USA.
Mark Newman and Gerard Barkema. 1999. Monte Carlo
Methods in Statistical Physics. Oxford: Clarendon
Press, New York, USA.
Zheng-Yu Niu, Dong-Hong Ji, and Chew-Lim Tan. 2007.
I2R: Three Systems for Word Sense Discrimination,
Chinese Word Sense Disambiguation, and English
Word Sense Disambiguation. In Proceedings of
SemEval-2007, pages 177?182, Prague, Czech Repub-
lic.
Patrick Pantel and Dekang Lin. 2003. Automatically
Discovering Word Senses. In Proceedings of NAACL-
HLT-2003, pages 21?22, Morristown, NJ, USA.
Ted Pedersen and Anagha Kulkarni. 2006. Automatic
Cluster Stopping With Criterion Functions and the gap
Statistic. In Proceedings of the 2006 Conference of the
North American Chapter of the ACL on Human Lan-
guage Technology, pages 276?279, Morristown, NJ,
USA.
Ted Pedersen. 2007. UMND2 : Senseclusters Applied to
the Sense Induction Task of Senseval-4. In Proceed-
ings of SemEval-2007, pages 394?397, Prague, Czech
Republic.
Daniel Ramage, Anna N. Rafferty, and Christopher D.
Manning. 2009. Random Walks for Text Semantic
Similarity. In Proceedings of TextGraphs-4, Suntec,
Singapore, August.
Noam Slonim, Nir Friedman, and Naftali Tishby. 2002.
Unsupervised Document Classification Using Sequen-
tial Information Maximization. In SIGIR 2002, pages
129?136, New York, NY, USA. ACM.
Benjamin Snyder and Martha Palmer. 2004. The En-
glish All-words Task. In Rada Mihalcea and Phil Ed-
monds, editors, In Proceedings of Senseval-3, pages
41?43, Barcelona, Spain.
Jean Ve?ronis. 2004. Hyperlex: Lexical Cartography for
Information Retrieval. Computer Speech & Language,
18(3):223?252.
Julie Weeds, David Weir, and Diana McCarthy. 2004.
Characterising Measures of Lexical Distributional
Similarity. In Proceedings of COLING-2004, pages
10?15, Morristown, NJ, USA.
Dominic Widdows and Beate Dorow. 2002. A Graph
Model for Unsupervised Lexical Acquisition. In Pro-
ceedings of Coling-2002, pages 1?7, Morristown, NJ,
USA.
755
