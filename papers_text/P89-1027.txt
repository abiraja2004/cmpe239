TREATMENT OF  LONG DISTANCE DEPENDENCIES  IN  LFG AND TAG:  
FUNCTIONAL UNCERTAINTY  IN  LFG IS A COROLLARY IN  TAG"  
Aravind K. Joshi 
Dept. of Computer & Information Science 
University of Pennsylvania 
Philadelphia, PA 19104 
joshi@linc.cis.upenn.edu 
K. Vijay-Shanker 
Dept. of Computer & Information Science 
University of Delaware 
Newark, DE 19716 
vijay@udel.edu 
ABSTRACT 
In this paper the functional uncertainty machin- 
ery in LFG is compared with the treatment of long 
distance dependencies in TAG.  It is shown that 
the functional uncertainty machinery is redundant 
in TAG,  i.e., what functional uncertainty accom- 
plishes for LFG follows f~om the TAG formalism 
itself and some aspects of the linguistic theory in- 
stantiated in TAG.  It is also shown that the anal- 
yses provided by the functional uncertainty ma- 
chinery can be obtained without requiring power 
beyond mildly context-sensitive grammars. Some 
linguistic and computational aspects of these re- 
sults have been briefly discussed also. 
1 INTRODUCTION 
The so-called long distance dependencies are char- 
acterized in Lexical Functional Grammars (LFG) 
by the use of the formal device of functional un- 
certainty, as defined by Kaplan and Zaenan \[3\] 
and Kaplan and Maxwell \[2\]. In this paper, we 
relate this characterization to that provided by 
Tree ~,djoining Grammars (TAG), showing a di- 
rect correspondence b tween the functional uncer- 
tainty equations in LFG analyses and the elemen- 
tary trees in TAGs that give analyses for "long dis- 
tance" dependencies. We show that the functional 
uncertainty machinery is redundant in TAG, i.e., 
what functional uncertainty accomplishes for LFG 
follows from the TAG formalism itself and some 
fundamental spects of the linguistic theory in- 
stantiated in TAG. We thus show that these anal- 
yses can be obtained without requiring power be- 
yond mildly context-sensitive grammars. We also 
*This  work was partial ly supported (for the first au- 
thor) by the DRRPA grant N00014-85-K0018, A l tO grant 
DAA29-84-9-0027, and  NSF grant IRI84-10413-A02. The 
first author  also benefited from some discussion with Mark 
Johnson and Ron Kaplan at the Titisee Workshop on Uni- 
fication Grammars ,  March, 1988. 
briefly discuss the linguistic and computational 
significance of these results. 
Long distance phenomena are associated with 
the so-called movement. The following examples, 
1. Mary Henry telephoned. 
2. Mary Bill said that Henry telephoned. 
3. Mary John claimed that Bill said that Henry 
telephoned. 
illustrate the long distance dependencies due to 
topicalization, where the verb telephoned and its 
object Mary can be arbitrarily apart. It is diffi- 
cult to state generalizations about these phenom- 
ena if one relies entirely on the surface structure 
(as defined in CFG based frameworks) ince these 
phenomena c nnot be localized at this level. Ka- 
plan and Zaenan \[3\] note that, in LFG, rather than 
stating the generalizations on the c-structure, they 
must be stated on f-structures, ince long distance 
dependencies are predicate argument dependen- 
cies, and such functional dependencies are rep- 
resented in the f-structures. Thus, as stated in 
\[2, 3\], in the sentences (1), (2), and (3) above, 
the dependencies are captured by the equations 
(in the LFG notation 1) by 1" TOPIC =T OBJ, 
T TOPIC =T COMP OBJ, and 1" TOPIC =T 
COMP COMP OBJ, respectively, which state 
that. the topic Mary is also the object of tele. 
phoned. In general, since any number of additional 
complement predicates may be introduced, these 
equations will have the general form 
"f TOPIC =T COMP COMP ... OBJ 
Kaplan and Zaenen \[3\] introduced the formal 
device of functional unc'ertainty, in which this gen- 
eral case is stated by the equation 
1 Because of lack of space, we will not  define the LFG 
notation. We assume that  the reader is familiar with it. 
220 
T TOP IC  -T COMP?OBJ  
The functional uncertainty device restricts the 
labels (such as COMP ?) to be drawn from the 
class of regular expressions. The definition of f- 
structures is extended to allow such equations \[2, 
3\]. Informally, this definition states that if f is a 
f-structure and a is a regular set, then ( fa)  = v 
holds if the value of f for the attribute s is a f- 
structure f l  such that (flY) -- v holds, where sy 
is a string in a, or f = v and e E a. 
The functional uncertainty approach may be 
characterized as a localization of the long dis- 
tance dependencies; a localization at the level of f- 
structures rather than at the level of c-structures. 
This illustrates the fact that if we use CFG-like 
rules to produce the surface structures, it is hard 
to state some generalizations directly; on the other 
hand, f-structures or elementary trees in TAGs 
(since they localize the predicate argument depen- 
dencies) are appropriate domains in which to state 
these generalizations. We show that there is a di- 
rect link between the regular expressions used in 
LFG and the elementary trees of TAG. 
I . I  OUTL INE  OF THE PAPER 
In Section 2, we will define briefly the TAG for- 
malism, describing some of the key points of the 
linguistic theory underlying it. We will also de- 
scribe briefly Feature Structure Based Tree Ad- 
joining Grammars (FTAG), and show how some 
elementary trees (auxiliary trees) behave as func: 
tions over feature structures. We will then show 
how regular sets over labels (such as COMP ?) can 
also be denoted by functions over feature struc- 
tures. In Section 3, we will consider the example of 
topicalization as it appears in Section 1 and show 
that the same statements are made by the two 
formalisms when we represent both the elemen- 
tary trees of FTAG and functional uncertainties 
in LFG as functions over feature structures. We 
also point out some differences in the two analy- 
ses which arise due to the differences in the for- 
malisms. In Section 4, we point out how these 
similar statements are stated differently in the two 
formalisms. The equations that capture the lin- 
guistic generalizations are still associated with in- 
dividual rules (for the c-structure) of the grammar 
in LFG. Thus, in order to state generalizations 
for a phenomenon that is not localized in the c- 
structure, extra machinery such as functional un- 
certainty is needed. We show that what this extra 
machinery achieves for CFG based systems follows 
as a corollary of the TAG framework. This results 
from the fact that the elementary trees in a TAG 
provide an extended omain of locality, and factor 
out recursion and dependencies. A computational 
consequence of this result is that we can obtain 
these analyses without going outside the power 
of TAG and thus staying within the class of con- 
strained grammatical formalisms characterized as 
mildly context.sensitive (Joshi \[1\]). Another con- 
sequence of the differences in the representations 
(and localization) in the two formalisms is as fol- 
lows. In a TAG, once an elementary tree is picked, 
there is no uncertainty about the functionality in 
long distance dependencies. Because LFG relies 
on a CFG framework, interactions between uncer- 
tainty equations can arise; the lack of such interac- 
tions in TAG can lead to simpler processing of long 
distance dependencies. Finally, we make some re- 
marks as to the linguistic significance of restrict- 
ing the use of regular sets in the functional uncer- 
tainty machinery by showing that the linguistic 
theory instantiated in TAG can predict that the 
path depicting the "movement" in long distance 
dependencies can be characterized by regular sets. 
2 INTRODUCTION TO TAG 
Tree Adjoining Grammars (TAGs) are tree rewrit- 
ing systems that are specified by a finite set of 
elementary trees. An operation called adjoining ~ 
is used to compose trees. The key property of 
the linguistic theory of TAGs is that TAGs allow 
factoring of recursion from the domain of depen- 
dencies, which are defined by the set of elemen- 
tary trees. Thus, the elementary trees in a TAG 
correspond to minimal inguistic structures that 
localize the dependencies such as agreement, sub- 
categorization, and filler-gap. There are two kinds 
of elementary trees: the initial trees and auxiliary 
trees. The initial trees (Figure 1) roughly corre- 
spond to "simple sentences". Thus, the root of an 
initial tree is labeled by S or ~. The frontier is all 
terminals. 
The auxiliary trees (Figure 1) correspond 
roughly to minimal recursive constructions. Thus, 
if the root of an auxiliary tree is labeled by a non- 
terminal symbol, X,  then there is a node (called 
the foot node) in the frontier which is labeled by 
X. The rest of the nodes in the frontier are labeled 
by terminal symbols. 
2We do not consider lexicalized TAGs (defined by Sch- 
abes, Abeille, and Joshi \[7\]) which allow both adjoining 
and sub6titution. The ~uhs  of this paper apply directly 
to  them. Besides, they are formally equivalent to TAGs. 
221 
~ U  
p: WP 
' A 
I I 
P, V 
Ag~m~ A~am~tm 
2. The relation of T/to its descendants, i.e., the 
view from below. This feature structure is 
called b,. 
troo? 
S X brooc 
"-...~. . . . . . .  v J 
A a m . ~ p  mat  ? 
Figure 1: Elementary Trees in a TAG 
We will now define the operation of adjoining. 
Consider the adjoining of/~ at the node marked 
with * in a. The subtree of a under the node 
marked with * is excised, and/3 is inserted in its 
place. Finally, the excised subtree is inserted be- 
low the foot node of w, as shown in Figure 1. 
A more detailed description of TAGs and their 
linguistic relevance may be found in (Kroch and 
ao hi \[51). 
2.1 FEATURE STRUCTURE BASED 
TREE ADJO IN ING GRAMMARS 
(FTAG) 
In unification grammars, a feature structure is as- 
sociated with a node in a derivation tree in order 
to describe that node and its relation to features 
of other nodes in the derivation tree. In a FTAG, 
with each internal node, T/, we associate two fea- 
ture structures (for details, see \[9\]). These two 
feature structures capture the following relations 
(Figure 2) 
1. The relation ofT/to its supertree, i.e., the view 
of the node from the top. The feature struc- 
ture that describes this relationship is called 
~.  
Figure 2: Feature Structures and Adjoining 
Note that both the t ,  and b, feature structures 
hold for the node 7. On the other hand, with each 
leaf node (either a terminal node or a foot node), 
7, we associate only one feature structure (let us 
call it t,3). 
Let us now consider the case when adjoining 
takes place as shown in the Figure 2. The notation 
we use is to write alongside ach node, the t and b 
statements, with the t statement written above the 
b statement. Let us say that troo~,broot and tloot= 
bLoo~ are the t and b statements of the root and 
foot nodes of the auxiliary tree used for adjoining 
at the node 7. Based on what t and b stand for, it 
is obvious that on adjoining the statements , and 
troot hold for the node corresponding to the root 
of the auxiliary tree. Similarly, the statements b, 
and b/oo~ hold for the node corresponding to the 
foot of the auxiliary tree. Thus, on adjoining, we 
unify t ,  with troot, and b, with b/oot. In fact, 
this adjoining-is permissible only if t.oo~ and t.  
are compatible and so are b/oot and b~. If we do 
not adjoin at the node, 7, then we unify t ,  with 
b,. More details of the definition of FTAG may be 
found in \[8, 9\]. 
We now give an example of an initial tree and an 
auxiliary tree in Figure 3. We have shown only the 
necessary top and bottom feature structures for 
the relevant nodes. Also in each feature structure 
3The linguistic relevance of this restriction has been dis- 
cussed elsewhere (Kroch and Joshi \[5\]). The general frame- 
work does not  necessar i ly  requ i re  it .  
222 
shown, we have only included those feature-value 
pairs that are relevant. For the auxiliary tree, we 
have labeled the root node S. We could have la- 
beled it S with COMP and S as daughter nodes. 
These details are not relevant o the main point 
of the paper. We note that, just as in a TAG, the 
elementary trees which are the domains of depen- 
dencies are available as a single unit during each 
step of the derivation. For example, in al  the topic 
and the object of the verb belong to the same tree 
(since this dependency has been factored into al )  
and are coindexed to specify the movemeat due to 
topicalization. In such cases, the dependencies be- 
tween these nodes can be stated directly, avoiding 
the percolation of features during the derivation 
process as in string rewriting systems. Thus, these 
dependencies can be checked locally, and thus this 
checking need not be linked to the derivation pro- 
cess in an unbounded manner. 
t -  . . .  t -  . , .  
o,: ? b .~ ' :~\ ]  P,: s " \ [d~: l~!  
I I . -m 
I I 
Figure 3: Example of Feature Structures Associ- 
ated with Elementary Trees 
to adjoining, since this feature structure is not 
known, we will treat it as a variable that gets in- 
stantiated on adjoining. This treatment can be 
formalized by treating the auxiliary trees as func- 
tions over feature structures (by A-abstracting the 
variable corresponding to the feature structure for 
the tree that will appear below the foot node). 
Adjoining corresponds to applying this function to 
the feature structure corresponding to the subtree 
below the node where adjoining takes place. 
Treating adjoining as function application, 
where we consider auxiliary trees as functions, the 
representation f/3 is a function, say fz, of the 
form (see Figure 2) 
~f.($roo, A ...(broot A f ) )  
If we now consider the tree 7 and the node T?, to 
allow the adjoining of/3 at the node ~, we must 
represent 7 by 
(...~. A f~(b.) A...) 
Note that if we do not adjoin at ~7, since t, and 
/3, have to be unified, we must represent 7 by the 
formula 
( . . .~Ab~A. . . )  
which can be obtained by representing 7 by 
2.2 A CALCULUS TO REPRESENT 
FTAG 
In \[8, 9\], we have described a calculus, extending 
the logic developed by Rounds and Kasper \[4, 6\], 
to encode the trees in a FTAG. We will very briefly 
describe this representation here. 
To understand the representation f adjoining, 
consider the trees given in Figure 2, and in partic- 
ular, the node rl. The feature structures associated 
with the node where adjoining takes place should 
reflect he feature structure after adjoining and as 
well as without adjoining. Further, the feature 
structure (corresponding to the tree structure be- 
low it) to be associated with the foot node is not 
known prior to adjoining, but becomes pecified 
upon adjoining. Thus, the bottom feature struc- 
ture associated with the foot node, which "is b foot 
before adjoining, is instantiated on adjoining by 
unifying it with a feature structure for the tree 
that will finally appear below this node. Prior 
( . . .t~ A X(b~) A . . . )  
where I is the identity function. Similarly, we 
must allow adjoining by any auxiliary tree adjoin- 
able at 7/(admissibility of adjoining is determined 
by the success or failure of unification). Thus, if 
/31,... ,/3, form the set of auxiliary trees, to allow 
for the possibility of adjoining by any auxiliary 
tree, as well as the possibility of no adjoining at a 
node, we must have a function, F, given by 
F = Af.( f~x(f)  V . . .  V f :~( f )  V f)  
and then we represent 7 by 
(. . . t ,  A F(b,)  A .. .). 
In this way, we can represent the elementary trees 
(and hence the grammar) in an extended version 
of K-K logic (the extension consists of adding A- 
abstraction and application). 
223 
3 LFG AND TAG ANALYSES 
FOR LONG DISTANCE DE- 
PENDENCIES  
We will now relate the analyses of long distance de- 
pendencies in LFG and TAG. For this purpose, we 
will focus our attention only on the dependencies 
due to topicalization, as illustrated by sentences 
1, 2, and 3 in Section 1. 
To facilitate our discussion, we will consider eg- 
ular sets over labels (as used by the functional 
uncertainty machinery) as functions over feature 
structures (as we did for auxiliary trees in FTAG). 
In order to describe the representation of regu- 
lar sets, we will treat all labels (attributes) as 
functions over feature structures. Thus, the label 
COMP,  for example, is a function which given a 
value feature structure (say v) returns a feature 
structure denoted by COMP : v. Therefore, we 
can denote it by Av.COMP : v. In order to de- 
scribe the representation f arbitrary regular sets 
we have to consider only their associated regular 
expressions. For example, COMP ? can be repre- 
sented by the function C* which is the fixed-point 4 
of 
F = Av. (F (COMP : v) V v) s 
Thus, the equation 
T TOPIC  =T COMP*OBJ  
is satisfied by a feature structure that satisfies 
TOPIC  : v A C*  (OBJ  : v). This feature 
structure will have a general form described by 
TOPIC  : v A COMP : COMP : . . .  OB J  : v. 
Consider the FTAG fragment (as shown in Fig- 
ure 3) which can be used to generate the sentences 
1, 2, and 3 in Section 1. The initial tree al  will 
be represented by cat : "~ A F ( top ic  : v A F (pred  : 
te lephonedAobj  : v)). Ignoring some irrelevant de- 
tails (such as the possibility of adjoining at nodes 
other than the S node), we cnn represent ax as 
a l  = topic : v A F (ob j  : v) 
Turning our attention to /~h let us consider the 
bottom feature structure of the root of/~1. Since 
its COMP ~ the feature structure associated with 
the foot node (notice that no adjoining is allowed 
at the foot node and hence it has only one feature 
structure), and since adjoining can take place at 
the root node, we have the representation of 81 as 
t in  \[8\], we have established that the fixed-point exists. 
aWe use the fact that R" = R 'RU {e}. 
aLf(comp : f ^ s~bj : ( . . . )  ^ . . . )  
where F is the function described in Section 2.2. 
From the point of view of the path from the root 
to the complement, he NP and VP  nodes are 
irrelevant, so are any adjoinings on these nodes. 
So once again, if we discard the irrelevant infor- 
mation (from the point of view of comparing this 
analyses with the one in LFG), we can simplify 
the representation f 81 as 
Af .F (comp : f )  
As explained in Section 2.2, since j31 is the only 
auxiliary tree of interest, F would be defined as 
F = a / .Z l ( / )v / .  Using the definition of/~1 above, 
and making some reductions we have 
F = Af.F(comp : f )  V f 
This is exactly the same analysis as in LFG using 
the functional uncertainty machinery. Note that 
the fixed-point of F i sC , .  Now consider al.  Ob- 
viously any structure derived from it can now be 
represented as 
topic  : v A C * (obj : v) 
This is the same analysis as given by LFG. 
In a TAG, the dependent i ems are part of the 
same elementary tree. Features of these nodes can 
be related locally within this elementary tree (as 
in a , ) .  This relation is unaffected by any adjoin- 
ings on nodes of the elementary tree. Although 
the paths from the root to these dependent i ems 
are elaborated by the adjoinings, no external de- 
vice (such as the functional uncertainty machin- 
ery) needs to be used to restrict he possible paths 
between the dependent nodes. For instance, in 
the example we have considered, the fact that 
TOPIC  = COMP : COMP. . .  : OB J  follows 
from the TAG framework itself. The regular path 
restrictions made in functional uncertainty state- 
ments such as in TOPIC  = COMP*OBJ  is re- 
dundant within the TAG framework. 
4 COMPARISON OF THE TWO 
FORMALISMS 
We have compared LFG and TAG analyses of 
long distance dependencies, and have shown that 
what functional uncertainty does for LFG comes 
out as a corollary in TAG, without going beyond 
the power of mildly context sensitive grammars. 
224 
Both approaches aim to localize long distance de- 
pendencies; the difference between TAG and LFG 
arises due to the domain of locality that the for- 
malisms provide (i.e., the domain over which state- 
ments of dependencies can be stated within the 
formalisms). 
In the LFG framework, CFG-like productions 
are used to build the c-structure. Equations are 
associated with these productions in order to build 
the f-structure. Since the long distance depen- 
dencies are localized at the functional level, addi- 
tional machinery (functional uncertainty) is pro- 
vided to capture this localization. In a TAG, the 
elementary trees, though used to build the "phrase 
structure" tree, also form the domain for localizing 
the functional dependencies. As a result, the long 
distance dependencies can be localized in the el- 
ementary trees. Therefore, such elementary trees 
tell us exactly where the filler "moves" (even in 
the case of such unbounded ependencies) and the 
functional uncertainty machinery is not necessary 
in the TAG framework. However, the functional 
uncertainty machinery makes explicit the predic- 
tions about the path between the "moved" argu- 
ment (filler) and the predicate (which is close to 
the gap). In a TAG, this prediction is not explicit. 
Hence, as we have shown in the case of topicaliza- 
tion, the nature of elementary trees determines the 
derivation sequences allowed and we can confirm 
(as we have done in Section 3) that this predic- 
tion is the same as that made by the functional 
uncertainty machinery. 
4.1 INTERACTIONS AMONG UNCER-  
TA INTY  EQUATIONS 
The functional uncertainty machinery is a means 
by which infinite disjunctions can be specified in 
a finite manner. The reason that infinite number 
of disjunctions appear, is due to the fact that they 
correspond to infinite number of possible deriva- 
tions. In a CFG based formalism, the checking of 
dependency cannot be separated from the deriva- 
tion process. On  the other hand, as shown in \[9\], 
since this separation is possible in TAG,  only fi- 
nite disjunctions are needed. In each elementary 
tree, there is no uncertainty about the kind of de- 
pendency between a filler and the position of the 
corresponding gap. Different dependencies corre- 
spond to different elementary trees. In this sense 
there is disjunction, but it is still only finite. Hav- 
ing picked one tree, there is no uncertainty about 
the grammatical function of the filler, no matter 
how many COMPs come in between due to adjoin- 
ing. This fact may have important consequences 
from the point of view of relative fficiency of pro- 
cessing of long distance dependencies in LFG and 
TAG. Consider, for example, the problem of in- 
teractions between two or more uncertainty equa- 
tions in LFG as stated in \[2\]. Certain strings in 
COMP ? cannot be solutions for 
( f  TOP IC)  = (.f COMP"  GF) 
when this equation is conjoined (i.e., when it in- 
teracts) with ( f  COMP SUBJ  NUM)  = S ING 
and ( f  TOP IC  NUM)  = PL. In this case, the 
shorter string COMP SUBJ  cannot be used for 
COMP"  GF because of the interaction, although 
the strings COMP i SUB J, i >_ 2 can satisfy the 
above set of equations. In general, in LFG, extra 
work has to be done to account for interactions. 
On the other hand, in TAG, as we noted above, 
since there is no uncertainty about the grammat- 
ical function of the filler, such interactions do not 
arise at all. 
4.2 REGULAR SETS IN FUNCTIONAL 
UNCERTAINTY  
From the definition of TAGs, it can be shown that 
the paths are always context-free s ts \[11\]. If there 
are linguistic phenomena where the uncertainty 
machinery with regular sets is not enough, then 
the question arises whether TAG can provide an 
adequate analysis, given that paths are context- 
free sets in TAGs. On the other hand, if regular 
sets are enough, we would like to explore whether 
the regularity requirement has a linguistic signif- 
icance by itself. As far as we are aware, Kaplan 
and Zaenen \[3\] do not claim that the regularity 
requirement follows from the linguistic considera- 
tions. Rather, they have illustrated the adequacy 
of regular sets for the linguistic phenomena they 
have described. However, it appears that an ap- 
propriate linguistic theory instantiated in the TAG 
framework will justify the use of regular sets for 
the long distance phenomena considered here. 
To illustrate our claim, let us consider the el- 
ementary trees that are used in the TAG anal- 
ysis of long distance dependencies. The elemen- 
tary trees, Sl and/31 (given in Figure 3), are good 
representative examples of such trees. In the ini- 
tial tree, ?zt, the topic node is coindexed with the 
empty NP node that plays the grammatical role 
of object. At the functional evel, this NP node 
is the object of the S node of oq (which is cap- 
tured in the bottom feature structure associated 
with the S node). Hence, our representation of
225 
at (i.e., looking at it from the top) is given by 
topic : v A F(obj : v), capturing the "movement" 
due to topicalization. Thus, the path in the func- 
tional structure between the topic and the object 
is entirely determined by the function F, which 
in turn depends on the auxiliary trees that can 
be adjoined at the S node. These auxiliary trees, 
such as/~I, are those that introduce complemen- 
tizer predicates. Auxiliary trees, in general, in- 
troduce modifiers or complementizer predicates as 
in/~1. (For our present discussion we can ignore 
the modifier type auxiliary trees). Auxiliary trees 
upon adjoining do not disturb the predicate ar- 
gument structure of the tree to which they are 
adjoined. If we consider trees such as/~I, the com- 
plement is given by the tree that appears below 
the foot node. A principle of a linguistic theory 
instantiated in TAG (see \[5\]), similar to the pro- 
jec~ion principle, predicts that the complement of 
the root (looking at it from below) is the feature 
structure associated with the foot node and (more 
importantly) this relation cannot be disrupted by 
any adjoinings. Thus, if we are given the feature 
structure, f ,  for the foot node (known only af- 
ter adjoining), the bottom feature structure of the 
root can be specified as comp : jr, and that of the 
top feature structure of the root is F(comp : f ) ,  
where F, as in a,, is used to account for adjoinings 
at the root. 
To summarize, in a l ,  the functional dependency 
between the topic and object nodes is entirely de- 
termined by the root and foot nodes of auxiliary 
trees that can be adjoined at the S node (the ef- 
fect of using the function F). By examining such 
auxiliary trees, we have characterized the latter 
path as Af.F(comp : f ) .  In grammatical terms, 
the path depicted by F can be specified by right- 
linear productions 
F -* F comp : / I 
Since right-linear grammars generate only regular 
sets, and TAGs predict he use of such right-linear 
rules for the description of the paths, as just shown 
above, we can thus state that TAGs give a justi- 
fication for the use of regular expressions in the 
functional uncertainty machinery. 
4.3 GENERATIVE  CAPACITY  AND 
LONG DISTANCE DEPENDENCY 
We will now show that what functional uncer- 
tainty accomplishes for LFG can be achieved 
within the FTAG framework without requiring 
power beyond that of TAGs. FTAG,  as described 
in this paper, is unlimited in its generative ca- 
pacity. By placing no restrictions on the feature 
structures associated with the nodes of elemen- 
tary trees, it is possible to generate any recursively 
enumerable language. In \[9\], we have defined a 
restricted version of FTAG, called RFTAG, that 
can generate only TALs (the languages generated 
by TAGs). In RFTAG, we insist that the fea- 
ture structures that are associated with nodes are 
bounded in size, a requirement similar to the finite 
closure membership restriction in GPSG. This re- 
stricted system will not allow us to give the analy- 
sis for the long distance dependencies due to top- 
icalization (as given in the earlier sections), since 
we use the COMP attribute whose value cannot be 
bounded in size. However, it is possible to extend 
RFTAG in a certain way such that such analysis 
can be given. This extension of RFTAG still does 
not go beyond TAG and thus is within the class of 
mildly context-sensitive grammar formalisms de- 
fined by Joshi \[1\]. This extension of RFTAG is 
discussed in \[10\]. 
To give an informal idea of this extension and 
a justification for the above argument, let us con- 
sider the auxiliary tree,/~1 in Figure 3. Although 
we coindex the value of the comp feature in the 
feature structure of the root node of/~1 with the 
feature structure associated with the foot node, we 
should note that this coindexing does not affect 
the context-freeness of derivation. Stated differ- 
ently, the adjoining sequence at the root is inde- 
pendent of other nodes in the tree in spite of the 
coindexing. This is due to the fact that as the fea- 
ture structure of the foot of/~1 gets instantiated 
on adjoining, this value is simply substituted (and 
not unified) for the value of the comp feature of 
the root node. Thus, the comp feature is being 
used just as any other feature that can be used 
to give tree addresses (except hat comp indicates 
dominance at the functional level rather than at 
the tree structure level). In \[10\], we have formal- 
ized this notion by introducing raph adjoining 
grammars which generate xactly the same lan- 
guages as TAGs. In a graph adjoining grammar, 
/~x is represented as shown in Figure 4. Notice 
that in this representation the comp feature is like 
the features 1 and 2 (which indicate the left and 
right daughters of a node) and therefore not used 
explicitly. 
5 CONCLUSION 
We have shown that for the treatment of long dis- 
tance dependencies in TAG, the functional un- 
226 
NP VP l 
t 
camp 
Figure 4: An Elementary DAG 
certainty machinery in LFG is redundant. We 
have also shown that the analyses provided by 
the functional uncertainty machinery can be ob- 
tained without going beyond the power of mildly 
context-sensitive grammars. We have briefly dis- 
cussed some linguistic and computational spects 
of these results. 
We believe that our results described in this pa- 
per can be extended to other formalisms, such as 
Combinatory Categorial Grammars (CCG), which 
also provide an e~ended omain of locality. It is 
of particular interest o carry out this investiga- 
tion in the context of CCG because of their weak 
equivalence to TAG (Weir and Joshi \[12\]). This 
exploration will help us view this equivalence from 
the structural point of view. 
REFERENCES 
\[1\] A. K. Joshi. How much context-sensitivity 
is necessary for characterizing structural de- 
scriptions - -  Tree Adjoining Grammars. In D. 
Dowty, L. Karttunen, and A. Zwicky, editors, 
Natural Language Processing q Theoretical, 
Computational nd Psychological Perspective, 
Cambridge University Press, New York, NY, 
1985. Originally presented in 1983. 
\[2\] R. M. Kaplan and J. T. Maxwell. An al- 
gorithm for functional uncertainity. In 12 th 
International Conference on Comput. Ling., 
1988. 
\[3\] R. M. Kaplan and A. Zaenen. Long distance 
dependencies,constituent structure, and func- 
tional uncertainity. In M. Baltin and A. 
Kroch, editors, Alternative Conceptions of 
Phrase Structure, Chicago University Press, 
Chicago. IL, 1988. 
\[4\] 
\[5\] 
\[6\] 
\[7\] 
\[8\] 
\[9\] 
\[lO\] 
\[11\] 
\[12\] 
R. Kasper and W. C. Rounds. A logical se- 
mantics for feature structures. In 24 th meet- 
ing Assoc. Comput. Ling., 1986. 
A. Kroch and A.K. Joshi. Linguistic Rele- 
vance of Tree Adjoining Grammars. Technical 
Report MS-CIS-85-18, Department o f  Com- 
puter and Information Science, University of 
Pennsylvania, Philadelphia, 1985. to appear 
in Linguistics and Philosophy, 1989. 
W. C. Rounds and R. Kasper. A complete 
logical calculus for record structures repre- 
senting linguistic information. In IEEE Sym- 
posium on Logic and Computer Science, 1986. 
Y. Schabes, A. Abeille, and A. K. Joshi. New 
parsing strategies for tree adjoining gram- 
mars. In 12 th International Conference on 
Assoc. Comput. Ling., 1988. 
K. Vijayashanker. A Study of Tee Adjoining 
Grammars. PhD thesis, University of Penn- 
sylvania, Philadelphia, Pa, 1987. 
K. Vijay-Shanker and A. K. Joshi. Fea- 
ture structure based tree adjoining rammars. 
In 12 th International Conference on Comput. 
Ling., 1988. 
K. Vijay-Shanker and A.K. Joshi. Unification 
based approach to tree adjoining grammar. 
1989. forthcoming. 
K. Vijay-Shanker, D. J. Weir, and A. K. 
Joshi. Characterizing structural descriptions 
produced by various grammatical formalisms. 
In 25 th meeting Assoc. Comput. Ling., 1987. 
D. J. Weir and A. K. Joshi. Combinatory cat- 
egorial grammars: generative power and rela- 
tionship to linear context-free rewriting sys- 
tems. In 26 ta meeting Assoc. Comput. Ling., 
1988. 
227 
