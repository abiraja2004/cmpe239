Some Methodological  Issues in 
Natural Language Understanding Research 
W. ~oods 
Bolt Beranek ~nd Inc. Newman, 
Cambridge MA 02138 
I. INTRODUCTION 
Natural language understanding has 
suddenly emerged as a central focus for many 
different discipl ines. Appl icat ions are 
emerging all over the field of computer 
science in which language understanding and 
the communicat ion of complex intentions to 
mach ines  is a crucial part. Moreover, 
psychologists, l inguists, and phi losophers 
have found the models emerging from 
computat ional  l inguist ics research to 
provide new stimulus and new methods for 
increasing our understanding of the process 
of human language use and the nature of 
communication. In this paper I want to 
discuss some of the methodological  problems 
I see in the  development of this area of 
research and some of the things which I 
think are needed in order for the field to 
be product ive of real scienti f ic insight and 
useful results. 
In order to discuss methodologies,  we 
had best first understand the 
different tasks for which the methodologies 
are to be used. There are at least two 
primary interests which one can have in 
studying natural language understanding -- 
construct ing intel l igent machines and 
understanding human language performance. 
These two different object ives are not 
mutual ly exclusive, and I wil l  attempt to 
argue that a large portion of the research 
necessary to either of them is shared by the 
other. This common portion consists of a 
pure attempt to understand the process of 
language understanding, independent of what 
device (human or machine) does the 
understanding. However, there are elements 
of the dif ferent points of view which are 
not shared, and drawing the dist inct ion 
between object ives at the outset is, I 
think, useful. 
I would claim that both the development 
of useful mechanical  devices for 
understanding language and the understanding 
of human language performance depend heavi ly 
on what we might call "device independent" 
language understanding theory. That is, a 
Joint study of human and machine language 
understanding, attempting to devise 
a lgor i thms and system organizat ions which 
wil l  have the functional performance of 
language understanding without speci f ica l ly  
trying to model the performance aspects of 
human beings. Theoret ical  and empir ical  
studies of this sort provide the foundat ions 
on which models of human language processing 
are built which are then subject to 
empir ical  ver i f icat ion.  They also provide 
the "bag of tr icks" out of which useful 
mechanical  language understanding systems 
can be constructed. Outside the common area 
of endeavor, these two different object ives 
have different goals. For both objectives, 
however, a major component of the research 
should  be to study the device independent 
language understanding problem. 
This paper is an attempt to set down my 
biases on some issues of methodology for 
construct ing natural language understanding 
systems and for performing research in 
computat ional  l inguist ics and language 
understanding. In it I wil l discuss some of 
the methods that I have found either 
effective and/or needed for performing 
useful work in the area of human and 
mechanical  language understanding. 
For theoret ical  studies, I wil l argue 
strongly for a methodology which stresses 
communicable and comprehensible theories, 
with precise uses of terms and an evaluat ion 
of formal isms which stresses the cognit ive 
eff ic iency of the representat ions of the 
formal ism itself. I wil l  attempt to cite 
several examples of the di f ferences in 
cognit ive eff ic iency between formalisms. 
The thrust of many of my comments wil l  
deal with the problems of complexity. My 
thesis is that natural language, unlike many 
physical systems is complex in that it takes 
a large number of facts, rules, or what have 
you to character ize its behavior rather than 
a small number of equations (of whatever  
theoret ical  sophist icat ion or depth). It is 
re lat ively easy to construct a grammar or 
other character izat ion for a fair ly small 
subset of the language (at least it is 
becoming more and more so today), but it is 
not so easy to cope with the complexity of 
the speci f icat ion when one begins to put in 
the magnitude of facts of language which are 
necessary to deal with a s igni f icant 
fract ion of human language performance. 
Theories for natural language understanding 
w i l l  have to deal ef fect ively with problems 
of scale the number of facts embodied in the 
theory. 
Since this paper is largely designed to 
promote discussion, the set of issues 
covered herein makes no effort to be 
complete. My goal is to raise some issues 
for considerat ion and debate. 
If. A PROGRAM FOR THEORETICAL L INGUISTICS 
AND PSYCHOLOGY 
The first point that I would like to 
make is that in the pursuit of theoret ical  
understanding in l inguist ics or 
psychol inguist ics,  studies will be much more 
product ive if pursued in the context of 
total language understanding systems and not 
in isolation. The subdivis ion of the total 
process into components such as syntax and 
semantics and concentrat ing on one such 
component is an effective way of l imit ing 
scope. However, it is only just i f iable if 
one has at least some reason to bel ieve that 
his hypothesized interfaces to those other 
components are real ist ic (and certain ly only 
if he has precisely specif ied those 
interfaces).  One cannot expect to pursue 
some small niche of the language 
understanding process without an active 
interest in the entire process and an 
understanding of the role of his specialty 
area in that overal l  process. Otherwise it 
is too easy to push problems off on someone 
I 
i 
I 
i 
I 
I 
t 
! 
I 
I 
i 
I 
I 
i 
i 
13~ m 
I 
I 
I 
I 
1 
I 
else, who may not be there to catch them. 
(In part icular there is considerable risk 
that the problems left for someone else may 
be insoluble due to a false assumption about 
the overall  organization. Studies pursued 
under such false assumptions are l ikely to 
turn out worthless.)  
III. THEORETICAL AND EMPIRICAL METHODOLOGIES 
There is need in the field of natural 
language understanding for both 
theoret ic ians and builders of systems. 
However, neither can pursue their ends in 
isolation. As in many other fields, the 
theoretical  and experimental  components go 
hand in hand in advancing the understanding 
of the problem. In the case of language 
understanding, the theoret ical  
invest igat ions consist largely of 
formulation of frameworks and systems for 
expressing language understanding rules or 
facts of language and for expressing other 
types of knowledge which impact the 
understanding process. On the experimental  
side, it is necessary to take a theory which 
may appear beaut i fu l ly  consistent and 
logical ly adequate in its abstract 
consideration, and verify that when faced 
with the practical  real ity of implementing a 
signif icant portion of the facts of 
language, the formalism is capable of 
expressing all the facts and is not too 
cumbersome or ineff ic ient for practical ity. 
The day is past when one could devise a new 
grammar formalism, write a few examples in 
it, and tout its advantages without putt ing 
it to the test of real use. 
Today's language theoret ic ians must 
have a concrete appreciat ion of the 
mechanisms used by computerized language 
understanding systems and not merely 
training in a classical  school of 
l inguist ics or philosophy. (On the other 
hand, they should not be ignorant of 
l inguist ics and phi losophy either.) Some 
mechanism must be found for increasing the  
"bag of tr icks" of the people who formulate 
such theories -- including people outside 
the current computat ional  l inguist ics and 
art i f ic ia l  intel l igence camps. Hopeful ly,  
th is  conference will make a beginning in 
this direction. 
IV. MODELS AND FORMALISMS 
One of the depressing methodological  
problems that currently faces the field of 
art i f ic ia l  intel l igence and computat ional  
l inguist ics is a general tendency to use 
terms imprecisely and for many people to use 
the same term for different things and 
different terms for the same thing. This 
tendency greatly hampers communicat ion of 
theories and results among researchers. 
One part icular imprecis ion of terms 
that I would like to mention here is a 
confusion that frequently arises about 
models. 
One frequently hears people refer to 
the transformat ional  grammar, model, or the 
augmented transit ion network grammar model, 
and asks what predict ions these models make 
that can be empir ical ly verified. However, 
when one looks careful ly at what is being 
referred to as a model in these cases, we 
find not a model, but rather a formal ism in 
which any of a number of models (or 
theories) can be expressed. The 
transformat ional  grammar formalism and the 
ATN formalism may suggest hypotheses which 
can be tested, but it is only the attachment 
of some behavioral  s ignif icance to some 
aspect of the formal ism which gives rise to 
a testable model. 
Argume:nts for or against a model are 
whether it is true -- i.e. whether the 
predict ions of the model are borne out by 
experiments. Arguments for or against a 
formalism or a methodology are its 
productiveness, economy of expression, 
suggest iveness of good models, ease of 
incorporat ing new features necessary to new 
hypothesized models (i. e. range of 
possible models expressible),  etc. One 
needs at the very least that the formal ism 
used must be capable of representing the 
correct model. But one doesn't know ahead 
of time and may never know what the correct 
model is. Hence it is desirable to have a 
formalism that can represent all conceivable 
models that could be correct. If there is a 
class of models which the formalism cannot 
account for then there should be an argument 
that no members of that class could possibly 
be correct, otherwise a formalism which 
included that class would be better (in one 
dimension). Dimensions of goodness of 
formalisms include range of possible models, 
eff ic iency of expression (perspicuity or 
cognit ive eff ic iency of the formalism), 
existence of eff ic ient simulators for the 
formal ism for use in ver i fy ing the 
correctness of a model, or for f inding 
inadequacies of a model, or for determining 
predict ions of the model, etc. 
V. HUMAN LANGUAGE PERFORMANCE 
In order to perform good work in 
computat ional  l inguist ics and in 
understanding human language performance, 
one needs to keep always in mind a good 
overview of how people use language and for 
what. Indeed, a prime focus of this 
conference is the development of such a 
overview. My own picture of the role of 
language in human behavior goes roughly  like 
this: 
There is some internal representat ion 
of knowledge of the world which is 
prel inguist ic,  and we probably share most of 
it with the other higher animals -- I would 
guess we share a lot of it with cats and 
dogs, and certainly with apes and 
chimpanzees. (What dif ferences of qual i ty 
or quantity set us apart from these animals 
or set the chimps apart from the dogs I 
would not care to speculate. ) 
Nevertheless, it is clear that cats and dogs 
without our l inguist ic machinery and without 
spoken languages do manage to store and 
remember and use fairly complex pieces of 
knowledge of the world, such as how to open 
I 135 
doors, how to find their way around, where 
they left things, which dish is theirs, what 
funny sequence of sounds their owners use to 
call them (i. e. their names), and the 
s igni f icance (to them) of all sorts of 
things that go on in the world around them. 
Humans probably remember large numbers of 
such things also without specif ic need for 
language. We presumably have in our head 
something which is like a language in many 
respects, but which probably does not share 
the peculiar l inear character ist ics  o f  
spoken and written language (which derives 
from the temporal order imposed on speech 
and reading). 
It no doubt helps us to remember a 
larger number of things to correlate them 
with l inguist ic labels or a pronounceable 
sequence of sounds, and this no doubt gives 
a greater abi l i ty for abstract thought. 
However, it is doubtful  that a language as 
we speak it or write it is a prerequis i te 
for an organism to have what we might call 
thought. Many of the things which we "know" 
are not expressed in language, and the fact 
that f inding the appropr iate words to 
describe things that we understand is 
sometimes very di f f icult  should give us a 
clue that the representat ion which we use in 
our heads is not a simple transcr ipt ion of 
the language that we use to communicate with 
others. Rather, there are a variety of 
exposit ion problems which need to be solved 
in order to translate even ideas which .are 
clearly understood into a l inear sequence of 
l inguist ic symbols which wil l  be l ikely to 
arouse or create the same idea in the head 
of our l istener. It seems l ikely then that 
the notat ion or whatever  convent ions that we 
use to store ideas and information in our 
heads is not the same as the language that 
we speak to communicate with others. 
The language that we speak and write, 
then, appears to be a device or a disc ip l ine 
evolved for the purpose of attempt ing to 
arouse in the head of the l istener something 
similar to that which is encoded in the head 
of the speaker. 
The process of communicat ion 
necessar i ly  involves elements of problem 
solving. What terms does my l istener know? 
What concepts can I rely on his 
understanding so that I can express what I 
want to say in terms of them? How can I 
build a speci f icat ion out of these pieces 
which wil l  cause him to construct in his 
memory the thing which I am trying to 
communicate? An account of human language 
use must deal with all of these questions. 
The above picture of the overal l  role 
of language in human communicat ion may not 
be correct in many respects. Hopeful ly  a 
consensus of this workshop wil l  produce a 
better one. However, I am afraid that a 
complete understanding of human language use 
wil l  have to go hand in hand with an 
understanding of the pre l inguist ic  
capabi l i t ies for knowledge representat ion 
and use which the human has. This level of 
human abi l i ty is unfortunate ly  very 
diff icult  to get one s hands on since it, 
like Joe Becket's problems of intermediate 
136 
cognition, is a process which we are not 
general ly aware of (since it takes place 
below the level of our conscious awareness) 
and consequent ly  we have no direct abi l i t ies 
to see it. Rather we have to be able to 
infer its presence and its nature from 
theoret ical  considerat ions and the effects 
that it has on the overt behavior we can 
see. A methodology for working in this area 
is extremely diff icult  to work out. 
A pr incipal  component of such a 
methodology, I feel, should be a theoret ical  
attempt to construct models which do things 
humans do and which do them well. That is, 
one should try to design intel l igent 
machines which can do what humans do, and 
let the concepts that emerge from such 
designs make predict ions about what 
performance one should see at the overt 
behavior interface. It is important 
however, that such studies go as far as to 
produce overt behavior which can be 
evaluated. A so called "theoretical" study 
which has no measurable performance is 
foundationless.  There is no way to evaluate 
whether it is doing anything or not. In 
particular, many studies of so cal led 
"semantic representat ions"  need clear 
statements of what wil l  be done with their 
representat ions and how one can decide 
whether a representat ion is correct or 
incorrect.  Without such an understanding,  
the entire exercise is one of aesthet ics and 
without sc ient i f ic  contr ibut ion.  In ta lk ing 
about semantic representat ions,  one must  be 
wi l l ing to face the questions of how the 
device knows what those representat ions 
mean. What events in the world wil l  be in 
contradict ion to the knowledge encoded in 
the representat ion and what ones wil l  be 
consistent with it? How wil l  a person (or a 
machine) know whether an event perceived is 
consistent with his semantic representat ions 
or not? How does he decide what to record 
when he perceives an event -- i. e. what 
process transforms ("transforms" is hot 
real ly the right word for this) an observed 
event into a l inguist ic  descr ipt ion of it? 
What intervening processes take place? These 
and similar quest ions must be spec i f ica l ly  
faced. 
V I .  EXPLANATORY MODELS 
The goal in trying to model human 
behavior should be to find explanatory  
models, not just descr ipt ive models. If, 
for example, one discovers that there is a 
react ion time lag in processing certa in 
types of sentences, a model which s imulated 
this behavior by insert ing a delay into a 
certain s tage  of the processing would be a 
descr ipt ive model, whereas another model  
which took longer for processing these types 
of sentences because of some extra 
processing which they required due to the 
organizat ion of the program would be an 
explanatory model. In my own work, the 
things which have excited me and made me 
feel that I was d iscover ing something about 
the way the people understand language, have 
been a lgor i thms that are mot ivated by 
considerat ions of ef f ic iency and "good 
engineer ing design" for a specif ic task 
I 
1 
I 
! 
1 
! 
I 
I 
i 
i 
i 
I 
I 
i 
I 
I 
! 
I 
I 
which then turn out to have  predict ions 
which are borne out in human performance. 
An example of this is some of the work of 
Ron Kaplan and Eric Wanner using ATN 
grammars to model aspects of human 
l inguist ic processing. (The basic ATN 
grammar formal ism was designed for 
ef f ic iency of operation, and not 
speci f ica l ly  for human performance 
modeling.) When such an experiment has 
positive results, one has not only a 
descr ipt ion of some aspect of human 
behavior, but also a reason for the 
behavior. 
VII. COPING WITH COMPLEXITY 
A crit ical need for all studies in 
language understanding is effect ive 
mechanisms for coping with the complexity of 
the phenomenon we are trying to understand 
and explain. The models that are required 
for descr ibing human language performance 
are more compl icated than the comparat ive ly  
simple physical  phenomena in most other 
areas of science. Only the models in 
art i f ic ia l  inte l l igence and computat ional  
l inguistics, and perhaps some kinds of 
theoret ical  chemistry reach  the level of 
having theories which comprise thousands of 
rules (or equations) that interact in 
compl icated ways. If the results of 
detai led studies of l inguist ic phenomena are 
to be disseminated and the field is to g row 
from the exchange of information and the 
continued accumulat ion of a body of known 
facts, then the facts must be capable of 
being communicated. We have then, at the 
core of the methodology of language 
understanding research, a crit ical need for 
some of the byproducts of our own research 
-- we need to develop effective formal isms 
for representat ion and for communicat ion of 
our theories. The expression of a theory of 
language in a formal system which is 
incomprehensib le  or tedious to comprehend 
wil l  contr ibute l itt le to this endeavor. 
What is required then, as a fundamental  tool 
for research in language understanding is a 
formal ism for expressing theories o f  
language ( involving large numbers of 
e lementary facts) in ways which are 
cognit ively eff ic ient -- i. e. which 
minimize the inte l lectual  effort required to 
grasp and remember the functions of 
individual  e lements of the theory and the 
way in which they interact. 
A good example of cognit ive ef f ic iency 
of representat ion occurs in the 
representat ions of transit ion network 
grammars, compared with the intermediate 
stages of a t ransformat ional  der ivat ion in a 
conventional  t ransformat ional  grammar. It 
is well  known, that humans find it easier to 
remember l ists of famil iar elements which 
fit together in structured ways than to 
remember dynamical ly  varying lists of 
unfami l iar  things. In a transit ion network 
grammar, the stages of intermediate 
processing of a sentence proceed through a 
sequence of transit ions through named states 
in the grammar. Each of these states has a 
name which has mnemonic value and 
corresponds to a part icular  mi lestone or 
137 
landmark in the course of processing a 
sentence. A student of the language or a 
grammar designer or someone studying someone 
else's grammar can become famil iar with each 
of these states as a known entity, can 
remember it by name, and become famil iar 
with a variety of information associated 
with that state -- such as what kinds of 
l inguist ic construct ions preceeded it, what 
construct ions to expect to the right, 
prosodic cues which can be expected to 
accompany it, potential  ambiguit ies and 
disambiguat ion strategies, etc. The 
corresponding intermediate stages of a 
t ransformat ional  g rammar  go through a 
sequence of intermediate phrase marke~s 
which do not exist ahead of time, are not 
named, have no mnemonic value, are 
constructed dynamical ly  during a parsing, 
and in general provide none of the above 
mentioned useful cognit ive aids to the 
student of the grammar. 
Similarly, the information remembered 
during the course of a parsing with an ATN 
is stored in named registers, again with 
mnemonic value, while the corresponding 
informat ion in a t ransformat ional  
intermediate structure is indicated solely 
by posit ional  information in the 
intermediate tree structure with no such 
mnemonic aid, with an attendant d i f f icul ty 
for memory, and with the added di f f icul ty 
that it is possible to construct a structure 
acc identa l ly  which matches the input pattern 
of a rule that one did not intend it to 
activate. The chance of doing this 
acc identa l ly  with a mnemonica l ly  named 
register or condit ion is negligible. 
Many other techniques for expressing 
compl icated systems with cognit ive 
ef f ic iency are being developed by 
programmers in sophist icated languages such 
as INTERLISP, where some programmers are 
adopt ing styles of programming which make 
the understanding of the program by human 
programmers and students easier. A major 
technique of these programming styles from 
the standpoint of cognit ive ef f ic iency is 
the use of a h ierarchy of subrout ines with 
speci f ied function and mnemonic names to 
produce program structures which match 
closely the human conceptual  model of what 
the program is doing. In such systems, one 
can verify the successful  operat ion of an 
a lgor i thm by a method called recurs ion 
induction, which ef fect ively says that if 
all of the subrout ines do the right thing, 
then the main routine wil l  also do the right 
thing. If one is suf f ic ient ly  systematic 
and careful  in his programming style, then 
the assurance that each level of the program 
does the right thing can be guaranteed by 
inspect ion and the chances of wr i t ing 
programs with hidden bugs or compl icated 
programs whose function cannot be easi ly 
understood is greatly reduced. 
As an example, consider a technique 
which I use extensively in my own 
programming in LISP. Suppose that I have a 
data object cal led a conf igurat ion which is 
represented as a list of 5 elements and the 
second element of the list is the state of 
the conf igurat ion.  It is a simple matter of 
programming discipl ine to extract the state 
name from such a data object with a function 
called CONFIG.STATE rather than the LISP 
function CADR, with the result that the 
program is almost self documenting instead 
of incomprehensible.  It is easy in 
INTERLISP to define the two functions 
ident ical ly and to cause them to compile 
identical ly so that no cost in running time 
is necessi tated by such programming 
techniques. (In my case I have a LISP 
function called EQUIVALENCE which takes care 
of all the details if I s imply call 
(EQUIVALENCE (CONFIG.STATE CADDR)).) 
Recently, new features have been added to 
INTERLISP which further faci l i tate such 
programming conventions by providing the 
user with a general ized facil ity for record 
naming and field extraction. 
Another example of the principle of 
cognit ive eff ic iency arises in the now 
famous go-to controversy of the programming 
language theorists. One school argues that 
one should program in a structural  
discipl ine which makes go-to instruct ions 
unnecessary and that such a disc ipl ine 
should be forced on a programmer because the 
code he will write under such a disc ipl ine 
will be better. This extreme point of view 
is presumably in contrast to the s i tuat ion 
in the language FORTRAN where one can handle 
branching only by "naming" each of the 
branches with (unmnemonic) numeric labels 
and speci fy ing go-to instruct ions in terms 
of such labels. However, I would argue that 
in many other situations, with a language 
which permits mnemonic labels, a programmer 
can insert a go-to instruct ion for the same 
kinds of reasons that he creates many 
subrout ines -- i.e., there is a s ignif icant 
chunk of operat ion which in his mind is a 
unit (for which he has or can coin a name) 
and which he would like to represent in his 
code in a way that wil l  enable him to read 
port ions of the code at a level of detai l  
which is cognit ively eff icient. When go-to 
instruct ions are used in this way, they have 
the same value that the abi l i ty to write 
subrout ines provides (not only eff ic iency of 
wr i t ing a given portion of code once whi le 
being able to enter it for execution from 
several places, but also the cognit ive 
ef f ic iency of being able to ignore detai ls 
of how some process operates by referr ing to 
it by name or label in situations where it 
is the purpose or goal of a procedure or 
block of code which is important and not the 
details). 
VIII. THE NEED FOR A COMPREHENSIBLE 
FRAMEWORK 
Not only must the individual rules of a 
complex system be comprehensible to the 
system designer and the student, but also 
the control f ramework into which these rules 
fit must be understood. Again, there is a 
pr inciple of cognit ive eff ic iency in 
operation. A control  f ramework which is 
simple to explain and easi ly remembered by 
the student of the system as he studies it, 
is far preferable to one which constant ly  
misleads the student into thinking that 
something happens in one way when it 
actual ly happens di f ferent ly or not at all. 
One cannot write rules for a system when he 
is not sure how it will apply the rules or 
when. Languages which take away from the 
programmer the burden of speci fy ing the 
details of control  structure should not also 
take away his abi l i ty to easi ly understand 
and forsee what wil l  happen in response to 
his rules. 
IX. COGNITIVE EFFICIENCY IN GRAMMARS 
One of the di lemmas of the field of 
computat ional  l inguist ics has been the 
di f f iculty of evaluat ing the qual ity of a 
grammar which someone has written. What is 
the scope of grammatical  phenomena which it 
covers? It is one thing to say that a 
grammar handles questions, imperatives, 
comparatives, adverbs, etc. It is another 
thing to discover that what this means is 
that certain yes/no and simple wh- quest ions 
are handled, that a certain class of 
comparat ives (the easy ones) are handled, 
and that only single word adverbs before or 
after the main verb are handled. A list of 
phenomena supposedly dealt with is obviously  
not suff icient.  
A common attempt to specify the class 
of sentences accepted by a grammar is to 
list a sample set of the sentences covered. 
This tends to give a feel ing for what the 
grammar can handle, but depending on the 
scrupulousness of the author in point ing out 
the things that his grammar doesn't handle 
(assuming he real izes what it doesn't 
handle) it is very easy for the reader  to 
overgeneral ize the range actual ly handled. 
When the author l ists several examples of 
dif ferent kinds of comparatives, how does 
the reader decide whether all poss ib i l i t ies  
are handled or Just those cases that are 
listed. The problem is that what one wants 
is a precise, compact, and comprehensib le  
representat ion of exact ly the class of 
sentences which are acceptable and how they 
are handled. But, notice that to the extent 
that such a speci f icat ion is real izable,  
that is exact ly what a grammar should be. 
Hence, the thing that is needed is a 
formal ism for grammar speci f icat ion which is 
precise, compact, and comprehensib le to a 
human grammar designer. In short, we need a 
formal ism for grammar speci f icat ion which is 
cognit ively eff ic ient -- enough so that a 
grammarian can tell by inspect ion of the 
grammar whether a sentence is acceptable or 
not. While this may not be real izable to 
this extent, it seems to focus on the 
hopelessness of attempting to find some 
other speci f icat ion of what a grammar does 
which wil l  somehow be clearer than the 
grammar itself. Instead, it shifts the 
emphasis to making the grammar formal ism 
suf f ic ient ly  perspicuous that one can study 
it and understand it directly. 
The only other method I know of at the 
present to obtain answers to specif ic  
quest ions about what a grammar does is to 
get your hands on the system and probe it 
with your theories of what it handles and 
what it doesn't. This has its own 
I 
i 
I 
! 
I 
I 
i 
I 
138 I 
disadvantages in the other direction, since 
it is indeed possible for a sentence to fail 
for a trivial reason that is a simpl e bug in 
a program and not because the grammar is 
incorrect or the theory is inadequate. 
Moreover, it is almost impossible for anyone 
but the designer and implementer of the 
system to tell whether it is a simple bug or 
a real conceptual  di f f iculty and one 
certainly can't simply take on faith a 
statement of "Oh that's just a bug." 
However, I think that it is inevitable that 
natural language grammars wil l  reach a level 
of complexity, no matter how perspicuous one 
makes the grammar, where computer aid in 
checking out theories and finding out what 
is or is not handled is an essential  tool. 
Th isdoes  not obviate the need for cognit ive 
eff iciency, however. 
To make the matter more complicated, in 
many systems, now, the syntactic component 
is not separable from the semantics and 
pragmatics of the system so that a sentence 
can fail to be handled correct ly not only 
due to incorrect syntax (i. e. the grammar 
does not match the real i ty of what people 
say) but also due to concepts which the 
system does not know or things which the 
system finds inappropr iate to the context. 
For such systems, it is almost impossible to 
judge the capabi l i ty  of the individual  
components of the system in any object ive 
and non id iosyncrat ic  terms. Each system is 
unique in the scope of what it is t ry ing  to 
do and f inding any equivalent grounds on 
which to compare two of them is di f f icult  if 
not impossible. The abi l i ty to understand 
the formal ism in which the author expresses 
his theory and presents it to the world is 
crit ical. 
comprehension as well as mechanical  
implementat ion.  In addition, I have 
discussed the need to perform research in 
the specia l ized areas of language 
understanding within the framework of a 
global picture of the entire language 
understanding process. I have called for 
more care in the precise use of terms and 
the use where possible of accepted exist ing 
terms rather than inventing unnecessary new 
ones. I have also stressed the necessity 
that models must produce some overt behavior 
which can be evaluated, and have noted the 
desirabi l i ty of f inding explanatory models 
rather than mere descr ipt ive models if one 
is really to produce an understanding of the 
language understanding process. I hope that 
the paper wil l  serve as a useful basis for 
discussion. 
REFERENCES 
Becker, J.D. "An Information Processing 
Model of Intermediate-Level  Cognit ion,"  
Memo AI-119, Stanford Art i f ic ia l  
Inte l l igence Project, Stanford 
University,  Stanford, Calif., May, 1970. 
Internat ional  Joint Conference on Art i f ic ia l  
Intel l igence, London, England, 
September, 1971. 
Woods, W.A. "Transit ion Network Grammars 
for Natural  Language Analysis,"  Comm. 
ACM, Vol 13, No. 10, (October, 1970). 
X. CONCLUSION 
In conclusion, the major thrust of this 
paper has been to stress the complexity of 
scale which must be dealt with in 
represent ing theories of natural language 
understanding and especial ly  in 
communicat ing them to other people. My 
major methodologica l  weapon against this 
complexity, is to develop speci f icat ion 
languages and notat ions which are 
cognit ively eff ic ient in the sense that they 
minimize the human intel lectual  effort 
necessary to understand, remember, design, 
and use such formalisms. We should strive 
for notat ions that can be used to publ ish 
grammars, semantic specif ications, and 
knowledge bases in a form that one can 
real ist ica l ly  expect other people to read 
and understand. Simple things such as 
naming functions with names that wil l  invoke 
the correct concept in the head of the 
person studying the formal ism (rather than a 
clever name the author fancies, or the first 
thing he happened to name it, or the name it 
used to have when he used it for something 
else, etc.) can make an enormous di f ference 
in the cognit ive eff ic iency of a formalism. 
In short, I am making a plea for making the 
speci f icat ion language used for theory 
development in natural language 
understanding be a communicat ion language 
intended and engineered for human 
139 
